{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7f4fa3641e80>\n"
     ]
    }
   ],
   "source": [
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['B']\n",
      "['C']\n",
      "-----\n",
      "{'A'}\n",
      "{'A'}\n",
      "set()\n",
      "-----\n",
      "{'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'B']\n",
      "Connected Edges:  [('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'B']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3]\n",
      "-----\n",
      "{'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'C']\n",
      "Connected Edges:  [('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A']\n",
      "Connected Edges:  [('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'B'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'C']\n",
      "Connected Edges:  [('B', 'C')]\n",
      "New node added--1\n",
      "['B', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "-----\n",
      "{'B'}\n",
      "{'B', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "New node added--1\n",
      "['B', 'A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A']\n",
      "Connected Edges:  [('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'B']\n",
      "Connected Edges:  [('C', 'B')]\n",
      "-----\n",
      "{'C'}\n",
      "{'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('C', 'B'), ('A', 'B')]\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'B', 'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'B', 'A', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "{'B', 'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'B', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'B', 'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'B', 'A', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "{'C', 'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B'), ('C', 'B')]\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'C', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'B', 'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'B', 'A', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'A'}\n",
      "{'B', 'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A'), ('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'B', 'C'}\n",
      "set()\n",
      "-----\n",
      "{'B', 'C'}\n",
      "{'B', 'A', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'A'}\n",
      "{'B', 'C'}\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'B'}\n",
      "{'C', 'A'}\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'C'}\n",
      "{'B', 'A'}\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'B', 'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'B', 'A', 'C'}\n",
      "{'B', 'A', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n"
     ]
    }
   ],
   "source": [
    "base_input = '../input_files/trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 3): 0, (0, 4): 1, (0, 6): 5, (1, 3): 0, (1, 5): 2, (1, 6): 3, (2, 4): 1, (2, 5): 2, (2, 6): 4, (3, 6): 4, (4, 6): 3, (5, 6): 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "Parameter containing:\n",
      "tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = [1000.0,1000.0,1000.0,1000.0,1000.0,1000.0]*np.array([1e0])  #Poor yield Simruntime = 1sec\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Equilibrium Solution ##\n",
    "First we will find the equilibrium solution for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No aceeptable solution found\n",
      "No Equilibrium solution\n",
      "Parameter containing:\n",
      "tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vec_rn.update_reaction_net(rn,1)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve()\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 0}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 1}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 2}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C', 'A'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 3}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'C'}, {'B', 'A'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 4}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B', 'C'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'AB': 3, 'AC': 4, 'BC': 5, 'ABC': 6}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*solution[edge[1]] - temp_kon*(solution[edge[0]])*(solution[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Free Energy: \",vec_rn.rxn_score_vec[uid])\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(solution[edge[0]])*(solution[node_map[react]])- koff*solution[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "\n",
    "if solution != None:\n",
    "    for n in rn.network.nodes():\n",
    "\n",
    "        n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "\n",
    "        paths = [n_str]\n",
    "        kon_sum = 0\n",
    "        temp_node = n\n",
    "        max_edge = True\n",
    "        consumption_rate = 0\n",
    "        if n < len(rn.network.nodes()):#num_monomers:\n",
    "    #         print(\"Current node: \")\n",
    "    #         print(n_str)\n",
    "            while max_edge:\n",
    "                max_edge = get_max_edge(temp_node)\n",
    "                if max_edge:\n",
    "                    total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                    temp_node = max_edge[1]\n",
    "                    kon_sum += max_edge[0].item()\n",
    "\n",
    "\n",
    "    #                 print(\"Next node: \")\n",
    "    #                 print(temp_node)\n",
    "\n",
    "                    paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "                else:\n",
    "                    break\n",
    "            pathway.append(paths)\n",
    "            kon_sumarray.append(kon_sum)\n",
    "            paths=[]\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"|                                                                             |\")\n",
    "        node_flux = get_node_flux(n)\n",
    "        net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "        print(\"|                                                                             |\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(pathway)\n",
    "    print(kon_sumarray)\n",
    "    #print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if solution != None:\n",
    "    for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if solution !=None:\n",
    "    for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer with a 1 second simulation runtime ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64,\n",
      "       requires_grad=True)]\n",
      "Using CPU\n",
      "Next time:  tensor(163297.0706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 0 was 57.0%\n",
      "current params: tensor([ 990.0148,  990.0148,  990.0145, 1009.9852, 1009.9852, 1009.9856],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(166308.9305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1 was 57.4%\n",
      "current params: tensor([ 982.9075,  982.9053,  982.8997, 1017.0236, 1017.0177, 1017.0345],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(168498.6975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2 was 57.7%\n",
      "current params: tensor([ 977.0740,  977.0705,  977.0597, 1022.7648, 1022.7558, 1022.7849],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(170325.4196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 3 was 57.9%\n",
      "current params: tensor([ 971.9990,  971.9947,  971.9787, 1027.7362, 1027.7250, 1027.7649],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(171936.8861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 4 was 58.1%\n",
      "current params: tensor([ 967.4408,  967.4359,  967.4147, 1032.1839, 1032.1713, 1032.2211],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(173402.3744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 5 was 58.3%\n",
      "current params: tensor([ 963.2634,  963.2580,  963.2314, 1036.2464, 1036.2327, 1036.2920],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(174760.8430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 6 was 58.5%\n",
      "current params: tensor([ 959.3811,  959.3753,  959.3435, 1040.0104, 1039.9958, 1040.0642],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(176036.7433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 7 was 58.6%\n",
      "current params: tensor([ 955.7363,  955.7302,  955.6931, 1043.5346, 1043.5192, 1043.5966],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(177246.6002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 8 was 58.8%\n",
      "current params: tensor([ 952.2877,  952.2813,  952.2388, 1046.8605, 1046.8446, 1046.9307],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(178402.1951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 9 was 58.9%\n",
      "current params: tensor([ 949.0045,  948.9979,  948.9501, 1050.0194, 1050.0029, 1050.0977],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(179512.2744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 10 was 59.0%\n",
      "current params: tensor([ 945.8634,  945.8566,  945.8034, 1053.0348, 1053.0178, 1053.1212],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(180583.5408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 11 was 59.2%\n",
      "current params: tensor([ 942.8459,  942.8389,  942.7802, 1055.9255, 1055.9081, 1056.0200],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(181621.2642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 12 was 59.3%\n",
      "current params: tensor([ 939.9371,  939.9300,  939.8658, 1058.7064, 1058.6887, 1058.8090],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(182629.6756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 13 was 59.4%\n",
      "current params: tensor([ 937.1248,  937.1176,  937.0480, 1061.3897, 1061.3717, 1061.5005],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(183612.2337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 14 was 59.5%\n",
      "current params: tensor([ 934.3991,  934.3917,  934.3167, 1063.9858, 1063.9675, 1064.1046],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(184571.8076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 15 was 59.6%\n",
      "current params: tensor([ 931.7514,  931.7439,  931.6634, 1066.5030, 1066.4844, 1066.6299],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(185510.8092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 16 was 59.7%\n",
      "current params: tensor([ 929.1746,  929.1670,  929.0810, 1068.9486, 1068.9298, 1069.0836],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(186431.2882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 17 was 59.8%\n",
      "current params: tensor([ 926.6625,  926.6548,  926.5633, 1071.3289, 1071.3099, 1071.4719],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(187335.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 18 was 59.9%\n",
      "current params: tensor([ 924.2097,  924.2018,  924.1049, 1073.6492, 1073.6300, 1073.8003],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(188223.4831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 19 was 60.0%\n",
      "current params: tensor([ 921.8115,  921.8036,  921.7011, 1075.9143, 1075.8949, 1076.0734],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(189098.0536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 20 was 60.1%\n",
      "current params: tensor([ 919.4639,  919.4559,  919.3480, 1078.1282, 1078.1087, 1078.2954],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(189959.8861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 21 was 60.2%\n",
      "current params: tensor([ 917.1632,  917.1552,  917.0417, 1080.2947, 1080.2750, 1080.4699],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(190810.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 22 was 60.3%\n",
      "current params: tensor([ 914.9063,  914.8981,  914.7791, 1082.4170, 1082.3971, 1082.6002],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(191649.3619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 23 was 60.4%\n",
      "current params: tensor([ 912.6901,  912.6819,  912.5574, 1084.4979, 1084.4779, 1084.6892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(192478.7496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 24 was 60.5%\n",
      "current params: tensor([ 910.5122,  910.5039,  910.3738, 1086.5402, 1086.5200, 1086.7395],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(193298.9187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 25 was 60.6%\n",
      "current params: tensor([ 908.3701,  908.3618,  908.2262, 1088.5460, 1088.5258, 1088.7534],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(194110.5377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 26 was 60.7%\n",
      "current params: tensor([ 906.2619,  906.2535,  906.1123, 1090.5177, 1090.4973, 1090.7331],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(194914.2125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 27 was 60.7%\n",
      "current params: tensor([ 904.1854,  904.1770,  904.0303, 1092.4570, 1092.4366, 1092.6805],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(195710.4947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 28 was 60.8%\n",
      "current params: tensor([ 902.1391,  902.1306,  901.9783, 1094.3659, 1094.3453, 1094.5974],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(196499.8879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 29 was 60.9%\n",
      "current params: tensor([ 900.1212,  900.1127,  899.9548, 1096.2458, 1096.2251, 1096.4853],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(197282.8536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 30 was 61.0%\n",
      "current params: tensor([ 898.1304,  898.1218,  897.9583, 1098.0983, 1098.0775, 1098.3459],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(198059.8161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 31 was 61.1%\n",
      "current params: tensor([ 896.1652,  896.1565,  895.9875, 1099.9248, 1099.9039, 1100.1804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(198831.1662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 32 was 61.1%\n",
      "current params: tensor([ 894.2244,  894.2157,  894.0411, 1101.7264, 1101.7055, 1101.9901],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(199597.2654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 33 was 61.2%\n",
      "current params: tensor([ 892.3068,  892.2980,  892.1178, 1103.5044, 1103.4834, 1103.7761],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(200358.4486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 34 was 61.3%\n",
      "current params: tensor([ 890.4113,  890.4025,  890.2168, 1105.2599, 1105.2388, 1105.5396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(201115.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 35 was 61.4%\n",
      "current params: tensor([ 888.5371,  888.5282,  888.3369, 1106.9938, 1106.9727, 1107.2816],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(201867.2903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 36 was 61.4%\n",
      "current params: tensor([ 886.6830,  886.6741,  886.4772, 1108.7072, 1108.6859, 1109.0030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(202615.5087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 37 was 61.5%\n",
      "current params: tensor([ 884.8483,  884.8394,  884.6368, 1110.4008, 1110.3795, 1110.7046],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(203359.9350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 38 was 61.6%\n",
      "current params: tensor([ 883.0322,  883.0232,  882.8150, 1112.0754, 1112.0541, 1112.3873],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(204100.8059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 39 was 61.7%\n",
      "current params: tensor([ 881.2338,  881.2248,  881.0110, 1113.7320, 1113.7105, 1114.0519],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(204838.3436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 40 was 61.7%\n",
      "current params: tensor([ 879.4525,  879.4435,  879.2241, 1115.3710, 1115.3495, 1115.6990],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(205572.7572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 41 was 61.8%\n",
      "current params: tensor([ 877.6877,  877.6786,  877.4536, 1116.9933, 1116.9718, 1117.3293],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(206304.2433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 42 was 61.9%\n",
      "current params: tensor([ 875.9385,  875.9295,  875.6988, 1118.5995, 1118.5779, 1118.9435],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(207032.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 43 was 61.9%\n",
      "current params: tensor([ 874.2046,  874.1955,  873.9592, 1120.1902, 1120.1685, 1120.5422],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(207759.1658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 44 was 62.0%\n",
      "current params: tensor([ 872.4853,  872.4761,  872.2342, 1121.7658, 1121.7441, 1122.1259],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(208482.9436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 45 was 62.1%\n",
      "current params: tensor([ 870.7801,  870.7709,  870.5233, 1123.3270, 1123.3053, 1123.6952],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(209204.4785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 46 was 62.1%\n",
      "current params: tensor([ 869.0885,  869.0792,  868.8260, 1124.8743, 1124.8525, 1125.2505],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(209923.9198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 47 was 62.2%\n",
      "current params: tensor([ 867.4100,  867.4007,  867.1419, 1126.4081, 1126.3863, 1126.7924],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(210641.4093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 48 was 62.3%\n",
      "current params: tensor([ 865.7441,  865.7348,  865.4704, 1127.9289, 1127.9070, 1128.3212],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(211357.0820, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 49 was 62.3%\n",
      "current params: tensor([ 864.0905,  864.0812,  863.8111, 1129.4371, 1129.4152, 1129.8374],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(212071.0666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 50 was 62.4%\n",
      "current params: tensor([ 862.4488,  862.4394,  862.1637, 1130.9331, 1130.9111, 1131.3415],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(212783.4856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 51 was 62.5%\n",
      "current params: tensor([ 860.8185,  860.8091,  860.5277, 1132.4174, 1132.3953, 1132.8338],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(213494.4564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 52 was 62.5%\n",
      "current params: tensor([ 859.1992,  859.1899,  858.9028, 1133.8902, 1133.8681, 1134.3146],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(214204.0908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 53 was 62.6%\n",
      "current params: tensor([ 857.5908,  857.5814,  857.2886, 1135.3519, 1135.3298, 1135.7844],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(214912.4960, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 54 was 62.6%\n",
      "current params: tensor([ 855.9927,  855.9833,  855.6849, 1136.8028, 1136.7807, 1137.2434],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(215619.7747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 55 was 62.7%\n",
      "current params: tensor([ 854.4047,  854.3953,  854.0912, 1138.2434, 1138.2212, 1138.6920],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(216326.0254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 56 was 62.8%\n",
      "current params: tensor([ 852.8265,  852.8170,  852.5073, 1139.6738, 1139.6516, 1140.1305],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(217031.3427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 57 was 62.8%\n",
      "current params: tensor([ 851.2578,  851.2483,  850.9329, 1141.0944, 1141.0722, 1141.5591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(217735.8175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 58 was 62.9%\n",
      "current params: tensor([ 849.6984,  849.6888,  849.3678, 1142.5055, 1142.4832, 1142.9782],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(218439.5370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 59 was 63.0%\n",
      "current params: tensor([ 848.1478,  848.1383,  847.8116, 1143.9072, 1143.8849, 1144.3881],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(219142.5855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 60 was 63.0%\n",
      "current params: tensor([ 846.6060,  846.5964,  846.2640, 1145.3000, 1145.2776, 1145.7888],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(219845.0439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 61 was 63.1%\n",
      "current params: tensor([ 845.0726,  845.0630,  844.7250, 1146.6839, 1146.6615, 1147.1808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(220546.9906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 62 was 63.1%\n",
      "current params: tensor([ 843.5475,  843.5379,  843.1941, 1148.0593, 1148.0369, 1148.5643],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(221248.5010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 63 was 63.2%\n",
      "current params: tensor([ 842.0304,  842.0207,  841.6713, 1149.4263, 1149.4039, 1149.9394],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(221949.6480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 64 was 63.3%\n",
      "current params: tensor([ 840.5210,  840.5113,  840.1562, 1150.7853, 1150.7628, 1151.3064],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(222650.5022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 65 was 63.3%\n",
      "current params: tensor([ 839.0192,  839.0095,  838.6488, 1152.1364, 1152.1139, 1152.6655],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(223351.1318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 66 was 63.4%\n",
      "current params: tensor([ 837.5248,  837.5151,  837.1486, 1153.4797, 1153.4572, 1154.0170],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(224051.6029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 67 was 63.4%\n",
      "current params: tensor([ 836.0376,  836.0279,  835.6557, 1154.8155, 1154.7930, 1155.3609],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(224751.9795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 68 was 63.5%\n",
      "current params: tensor([ 834.5574,  834.5476,  834.1698, 1156.1441, 1156.1215, 1156.6974],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(225452.3238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 69 was 63.5%\n",
      "current params: tensor([ 833.0840,  833.0742,  832.6907, 1157.4654, 1157.4428, 1158.0269],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(226152.6960, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 70 was 63.6%\n",
      "current params: tensor([ 831.6172,  831.6074,  831.2182, 1158.7798, 1158.7572, 1159.3493],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(226853.1548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 71 was 63.7%\n",
      "current params: tensor([ 830.1570,  830.1472,  829.7523, 1160.0874, 1160.0648, 1160.6650],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(227553.7569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 72 was 63.7%\n",
      "current params: tensor([ 828.7030,  828.6932,  828.2926, 1161.3883, 1161.3657, 1161.9740],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(228254.5579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 73 was 63.8%\n",
      "current params: tensor([ 827.2553,  827.2454,  826.8392, 1162.6828, 1162.6601, 1163.2765],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(228955.6116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 74 was 63.8%\n",
      "current params: tensor([ 825.8136,  825.8037,  825.3917, 1163.9709, 1163.9482, 1164.5727],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(229656.9705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 75 was 63.9%\n",
      "current params: tensor([ 824.3777,  824.3678,  823.9502, 1165.2528, 1165.2300, 1165.8627],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(230358.6858, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 76 was 63.9%\n",
      "current params: tensor([ 822.9476,  822.9377,  822.5144, 1166.5286, 1166.5058, 1167.1466],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(231060.8073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 77 was 64.0%\n",
      "current params: tensor([ 821.5231,  821.5132,  821.0841, 1167.7985, 1167.7757, 1168.4245],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(231763.3837, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 78 was 64.0%\n",
      "current params: tensor([ 820.1041,  820.0942,  819.6594, 1169.0626, 1169.0398, 1169.6967],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(232466.4627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 79 was 64.1%\n",
      "current params: tensor([ 818.6904,  818.6805,  818.2400, 1170.3210, 1170.2982, 1170.9632],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(233170.0905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 80 was 64.2%\n",
      "current params: tensor([ 817.2820,  817.2720,  816.8259, 1171.5739, 1171.5511, 1172.2242],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(233874.3127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 81 was 64.2%\n",
      "current params: tensor([ 815.8787,  815.8687,  815.4169, 1172.8214, 1172.7985, 1173.4797],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(234579.1736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 82 was 64.3%\n",
      "current params: tensor([ 814.4804,  814.4704,  814.0128, 1174.0635, 1174.0406, 1174.7300],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(235284.7167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 83 was 64.3%\n",
      "current params: tensor([ 813.0869,  813.0769,  812.6137, 1175.3004, 1175.2775, 1175.9750],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(235990.9847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 84 was 64.4%\n",
      "current params: tensor([ 811.6983,  811.6883,  811.2193, 1176.5323, 1176.5093, 1177.2149],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(236698.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 85 was 64.4%\n",
      "current params: tensor([ 810.3144,  810.3043,  809.8297, 1177.7591, 1177.7362, 1178.4498],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(237405.8610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 86 was 64.5%\n",
      "current params: tensor([ 808.9350,  808.9249,  808.4446, 1178.9810, 1178.9581, 1179.6798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(238114.5504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 87 was 64.5%\n",
      "current params: tensor([ 807.5601,  807.5500,  807.0640, 1180.1982, 1180.1752, 1180.9051],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(238824.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 88 was 64.6%\n",
      "current params: tensor([ 806.1896,  806.1795,  805.6877, 1181.4106, 1181.3876, 1182.1256],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(239534.6288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 89 was 64.6%\n",
      "current params: tensor([ 804.8234,  804.8132,  804.3158, 1182.6184, 1182.5954, 1183.3415],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(240246.0943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 90 was 64.7%\n",
      "current params: tensor([ 803.4613,  803.4512,  802.9481, 1183.8218, 1183.7987, 1184.5529],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(240958.5606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 91 was 64.8%\n",
      "current params: tensor([ 802.1034,  802.0933,  801.5845, 1185.0206, 1184.9976, 1185.7599],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(241672.0645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 92 was 64.8%\n",
      "current params: tensor([ 800.7496,  800.7394,  800.2249, 1186.2152, 1186.1921, 1186.9626],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(242386.6421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 93 was 64.9%\n",
      "current params: tensor([ 799.3997,  799.3895,  798.8693, 1187.4054, 1187.3824, 1188.1609],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(243102.3291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 94 was 64.9%\n",
      "current params: tensor([ 798.0536,  798.0435,  797.5175, 1188.5915, 1188.5685, 1189.3551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(243819.1603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 95 was 65.0%\n",
      "current params: tensor([ 796.7114,  796.7012,  796.1696, 1189.7735, 1189.7504, 1190.5452],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(244537.1703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 96 was 65.0%\n",
      "current params: tensor([ 795.3729,  795.3627,  794.8253, 1190.9515, 1190.9284, 1191.7313],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(245256.3931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 97 was 65.1%\n",
      "current params: tensor([ 794.0380,  794.0278,  793.4848, 1192.1255, 1192.1024, 1192.9134],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(245976.8622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 98 was 65.1%\n",
      "current params: tensor([ 792.7067,  792.6964,  792.1477, 1193.2956, 1193.2725, 1194.0916],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(246698.6107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 99 was 65.2%\n",
      "current params: tensor([ 791.3789,  791.3686,  790.8142, 1194.4619, 1194.4388, 1195.2660],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(247421.6713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 100 was 65.2%\n",
      "current params: tensor([ 790.0545,  790.0442,  789.4841, 1195.6245, 1195.6013, 1196.4366],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(248146.0763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 101 was 65.3%\n",
      "current params: tensor([ 788.7335,  788.7232,  788.1574, 1196.7833, 1196.7602, 1197.6036],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(248871.8574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 102 was 65.3%\n",
      "current params: tensor([ 787.4158,  787.4055,  786.8340, 1197.9386, 1197.9154, 1198.7670],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(249599.0461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 103 was 65.4%\n",
      "current params: tensor([ 786.1014,  786.0911,  785.5139, 1199.0903, 1199.0671, 1199.9268],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(250327.6736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 104 was 65.4%\n",
      "current params: tensor([ 784.7901,  784.7798,  784.1969, 1200.2385, 1200.2153, 1201.0832],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(251057.7706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 105 was 65.5%\n",
      "current params: tensor([ 783.4819,  783.4716,  782.8830, 1201.3833, 1201.3601, 1202.2361],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(251789.3676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 106 was 65.5%\n",
      "current params: tensor([ 782.1768,  782.1665,  781.5722, 1202.5248, 1202.5015, 1203.3856],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(252522.4948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 107 was 65.6%\n",
      "current params: tensor([ 780.8748,  780.8644,  780.2644, 1203.6629, 1203.6396, 1204.5318],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(253257.1818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 108 was 65.6%\n",
      "current params: tensor([ 779.5756,  779.5652,  778.9596, 1204.7977, 1204.7745, 1205.6748],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(253993.4584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 109 was 65.7%\n",
      "current params: tensor([ 778.2794,  778.2690,  777.6577, 1205.9294, 1205.9061, 1206.8146],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(254731.3538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 110 was 65.7%\n",
      "current params: tensor([ 776.9860,  776.9755,  776.3585, 1207.0579, 1207.0346, 1207.9512],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(255470.8970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 111 was 65.8%\n",
      "current params: tensor([ 775.6954,  775.6849,  775.0622, 1208.1833, 1208.1600, 1209.0847],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(256212.1168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 112 was 65.8%\n",
      "current params: tensor([ 774.4075,  774.3970,  773.7687, 1209.3057, 1209.2824, 1210.2152],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(256955.0418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 113 was 65.9%\n",
      "current params: tensor([ 773.1223,  773.1118,  772.4778, 1210.4250, 1210.4017, 1211.3427],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(257699.7002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 114 was 65.9%\n",
      "current params: tensor([ 771.8398,  771.8293,  771.1896, 1211.5414, 1211.5181, 1212.4672],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(258446.1202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 115 was 66.0%\n",
      "current params: tensor([ 770.5598,  770.5493,  769.9039, 1212.6549, 1212.6316, 1213.5888],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(259194.3298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 116 was 66.0%\n",
      "current params: tensor([ 769.2824,  769.2719,  768.6208, 1213.7656, 1213.7423, 1214.7076],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(259944.3565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 117 was 66.1%\n",
      "current params: tensor([ 768.0075,  767.9970,  767.3402, 1214.8734, 1214.8501, 1215.8235],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(260696.2280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 118 was 66.1%\n",
      "current params: tensor([ 766.7351,  766.7245,  766.0621, 1215.9785, 1215.9552, 1216.9367],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(261449.9716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 119 was 66.2%\n",
      "current params: tensor([ 765.4651,  765.4545,  764.7864, 1217.0809, 1217.0575, 1218.0472],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(262205.6146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 120 was 66.2%\n",
      "current params: tensor([ 764.1974,  764.1869,  763.5131, 1218.1805, 1218.1572, 1219.1550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(262963.1840, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 121 was 66.3%\n",
      "current params: tensor([ 762.9321,  762.9215,  762.2421, 1219.2776, 1219.2542, 1220.2602],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(263722.7066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 122 was 66.3%\n",
      "current params: tensor([ 761.6691,  761.6585,  760.9734, 1220.3720, 1220.3486, 1221.3627],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(264484.2094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 123 was 66.4%\n",
      "current params: tensor([ 760.4083,  760.3977,  759.7070, 1221.4639, 1221.4405, 1222.4627],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(265247.7188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 124 was 66.4%\n",
      "current params: tensor([ 759.1498,  759.1392,  758.4428, 1222.5533, 1222.5298, 1223.5602],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(266013.2617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 125 was 66.5%\n",
      "current params: tensor([ 757.8934,  757.8828,  757.1807, 1223.6401, 1223.6167, 1224.6552],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(266780.8640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 126 was 66.5%\n",
      "current params: tensor([ 756.6392,  756.6286,  755.9208, 1224.7246, 1224.7011, 1225.7477],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(267550.5523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 127 was 66.6%\n",
      "current params: tensor([ 755.3871,  755.3764,  754.6630, 1225.8066, 1225.7831, 1226.8379],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(268322.3527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 128 was 66.6%\n",
      "current params: tensor([ 754.1370,  754.1263,  753.4073, 1226.8862, 1226.8628, 1227.9257],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(269096.2915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 129 was 66.7%\n",
      "current params: tensor([ 752.8890,  752.8783,  752.1536, 1227.9635, 1227.9401, 1229.0111],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(269872.3945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 130 was 66.7%\n",
      "current params: tensor([ 751.6430,  751.6323,  750.9020, 1229.0385, 1229.0151, 1230.0942],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(270650.6878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 131 was 66.8%\n",
      "current params: tensor([ 750.3989,  750.3882,  749.6522, 1230.1113, 1230.0878, 1231.1751],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(271431.1973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 132 was 66.8%\n",
      "current params: tensor([ 749.1568,  749.1461,  748.4045, 1231.1817, 1231.1583, 1232.2537],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(272213.9487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 133 was 66.9%\n",
      "current params: tensor([ 747.9166,  747.9059,  747.1586, 1232.2500, 1232.2265, 1233.3301],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(272998.9678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 134 was 66.9%\n",
      "current params: tensor([ 746.6782,  746.6675,  745.9146, 1233.3161, 1233.2926, 1234.4043],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(273786.2803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 135 was 67.0%\n",
      "current params: tensor([ 745.4417,  745.4310,  744.6725, 1234.3801, 1234.3566, 1235.4764],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(274575.9119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 136 was 67.0%\n",
      "current params: tensor([ 744.2070,  744.1963,  743.4321, 1235.4419, 1235.4184, 1236.5464],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(275367.8882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 137 was 67.1%\n",
      "current params: tensor([ 742.9741,  742.9634,  742.1936, 1236.5017, 1236.4782, 1237.6142],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(276162.2347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 138 was 67.1%\n",
      "current params: tensor([ 741.7430,  741.7322,  740.9568, 1237.5594, 1237.5359, 1238.6801],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(276958.9770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 139 was 67.2%\n",
      "current params: tensor([ 740.5135,  740.5027,  739.7217, 1238.6151, 1238.5916, 1239.7439],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(277758.1406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 140 was 67.2%\n",
      "current params: tensor([ 739.2858,  739.2750,  738.4884, 1239.6688, 1239.6452, 1240.8057],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(274289.1396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 141 was 66.6%\n",
      "current params: tensor([ 737.9847,  737.9738,  737.2262, 1240.7950, 1240.7715, 1241.8737],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(275131.6016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 142 was 66.7%\n",
      "current params: tensor([ 736.6865,  736.6757,  735.9666, 1241.9180, 1241.8944, 1242.9395],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(275976.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 143 was 66.7%\n",
      "current params: tensor([ 735.3913,  735.3805,  734.7095, 1243.0377, 1243.0141, 1244.0030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(276822.7511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 144 was 66.8%\n",
      "current params: tensor([ 734.0990,  734.0881,  733.4548, 1244.1543, 1244.1307, 1245.0643],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(277671.5095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 145 was 66.9%\n",
      "current params: tensor([ 732.8094,  732.7986,  732.2026, 1245.2678, 1245.2442, 1246.1234],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(278522.4355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 146 was 66.9%\n",
      "current params: tensor([ 731.5227,  731.5118,  730.9527, 1246.3782, 1246.3547, 1247.1804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(279375.5627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 147 was 67.0%\n",
      "current params: tensor([ 730.2387,  730.2278,  729.7051, 1247.4857, 1247.4621, 1248.2353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(280230.9244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 148 was 67.0%\n",
      "current params: tensor([ 728.9574,  728.9465,  728.4598, 1248.5902, 1248.5666, 1249.2881],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(281088.5538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 149 was 67.1%\n",
      "current params: tensor([ 727.6787,  727.6677,  727.2167, 1249.6918, 1249.6682, 1250.3388],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(281948.4840, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 150 was 67.1%\n",
      "current params: tensor([ 726.4025,  726.3916,  725.9758, 1250.7905, 1250.7669, 1251.3875],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(282810.7477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 151 was 67.2%\n",
      "current params: tensor([ 725.1290,  725.1180,  724.7371, 1251.8864, 1251.8628, 1252.4342],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(283675.3779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 152 was 67.2%\n",
      "current params: tensor([ 723.8579,  723.8469,  723.5004, 1252.9795, 1252.9559, 1253.4789],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(284542.4067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 153 was 67.3%\n",
      "current params: tensor([ 722.5892,  722.5782,  722.2659, 1254.0700, 1254.0463, 1254.5217],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(285411.8666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 154 was 67.3%\n",
      "current params: tensor([ 721.3230,  721.3120,  721.0334, 1255.1577, 1255.1340, 1255.5625],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(286283.7901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 155 was 67.4%\n",
      "current params: tensor([ 720.0591,  720.0481,  719.8029, 1256.2428, 1256.2191, 1256.6015],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(287158.2091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 156 was 67.4%\n",
      "current params: tensor([ 718.7975,  718.7865,  718.5744, 1257.3252, 1257.3016, 1257.6386],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(288035.1558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 157 was 67.5%\n",
      "current params: tensor([ 717.5382,  717.5272,  717.3478, 1258.4051, 1258.3815, 1258.6739],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(288914.6621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 158 was 67.5%\n",
      "current params: tensor([ 716.2812,  716.2702,  716.1231, 1259.4825, 1259.4589, 1259.7074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(289796.7599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 159 was 67.6%\n",
      "current params: tensor([ 715.0264,  715.0153,  714.9003, 1260.5574, 1260.5338, 1260.7391],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(290681.4809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 160 was 67.6%\n",
      "current params: tensor([ 713.7737,  713.7627,  713.6794, 1261.6299, 1261.6062, 1261.7690],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(291568.8571, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 161 was 67.7%\n",
      "current params: tensor([ 712.5232,  712.5121,  712.4602, 1262.6999, 1262.6762, 1262.7972],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(292458.9197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 162 was 67.7%\n",
      "current params: tensor([ 711.2747,  711.2636,  711.2428, 1263.7675, 1263.7439, 1263.8237],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(293351.7004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 163 was 67.8%\n",
      "current params: tensor([ 710.0283,  710.0172,  710.0272, 1264.8328, 1264.8092, 1264.8484],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(294247.2309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 164 was 67.8%\n",
      "current params: tensor([ 708.7840,  708.7729,  708.8133, 1265.8958, 1265.8721, 1265.8715],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(295145.5449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 165 was 67.9%\n",
      "current params: tensor([ 707.5416,  707.5303,  707.6013, 1266.9587, 1266.9328, 1266.8910],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(296046.6776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 166 was 67.9%\n",
      "current params: tensor([ 706.3012,  706.2896,  706.3909, 1268.0193, 1267.9913, 1267.9087],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(296950.6552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 167 was 68.0%\n",
      "current params: tensor([ 705.0627,  705.0509,  705.1822, 1269.0778, 1269.0475, 1268.9248],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(297857.5088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 168 was 68.0%\n",
      "current params: tensor([ 703.8261,  703.8140,  703.9751, 1270.1341, 1270.1016, 1269.9392],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(298767.2700, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 169 was 68.1%\n",
      "current params: tensor([ 702.5913,  702.5790,  702.7696, 1271.1884, 1271.1535, 1270.9520],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(299679.9702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 170 was 68.1%\n",
      "current params: tensor([ 701.3584,  701.3458,  701.5657, 1272.2406, 1272.2033, 1271.9633],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(300595.6404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 171 was 68.2%\n",
      "current params: tensor([ 700.1273,  700.1144,  700.3633, 1273.2908, 1273.2510, 1272.9729],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(301514.3123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 172 was 68.2%\n",
      "current params: tensor([ 698.8980,  698.8847,  699.1624, 1274.3390, 1274.2966, 1273.9809],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(302436.0170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 173 was 68.3%\n",
      "current params: tensor([ 697.6704,  697.6568,  697.9630, 1275.3852, 1275.3402, 1274.9875],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(303360.7862, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 174 was 68.3%\n",
      "current params: tensor([ 696.4445,  696.4306,  696.7651, 1276.4294, 1276.3818, 1275.9925],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(304288.6510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 175 was 68.4%\n",
      "current params: tensor([ 695.2203,  695.2060,  695.5686, 1277.4717, 1277.4214, 1276.9960],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(305219.6430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 176 was 68.4%\n",
      "current params: tensor([ 693.9978,  693.9831,  694.3736, 1278.5121, 1278.4590, 1277.9980],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(306153.7936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 177 was 68.5%\n",
      "current params: tensor([ 692.7769,  692.7618,  693.1799, 1279.5507, 1279.4948, 1278.9985],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(307091.1342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 178 was 68.5%\n",
      "current params: tensor([ 691.5576,  691.5421,  691.9876, 1280.5874, 1280.5286, 1279.9976],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(308031.6967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 179 was 68.6%\n",
      "current params: tensor([ 690.3398,  690.3240,  690.7966, 1281.6223, 1281.5605, 1280.9953],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(308975.5121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 180 was 68.6%\n",
      "current params: tensor([ 689.1237,  689.1074,  689.6070, 1282.6554, 1282.5906, 1281.9915],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(309922.6124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 181 was 68.7%\n",
      "current params: tensor([ 687.9090,  687.8923,  688.4187, 1283.6867, 1283.6189, 1282.9864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(310873.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 182 was 68.7%\n",
      "current params: tensor([ 686.6959,  686.6787,  687.2316, 1284.7162, 1284.6453, 1283.9799],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(311826.7943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 183 was 68.8%\n",
      "current params: tensor([ 685.4843,  685.4665,  686.0459, 1285.7441, 1285.6700, 1284.9720],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(312783.9394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 184 was 68.8%\n",
      "current params: tensor([ 684.2741,  684.2559,  684.8613, 1286.7702, 1286.6929, 1285.9627],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(313744.4965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 185 was 68.9%\n",
      "current params: tensor([ 683.0653,  683.0466,  683.6781, 1287.7946, 1287.7141, 1286.9522],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(314708.4974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 186 was 68.9%\n",
      "current params: tensor([ 681.8580,  681.8387,  682.4960, 1288.8174, 1288.7336, 1287.9403],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(315675.9744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 187 was 69.0%\n",
      "current params: tensor([ 680.6520,  680.6322,  681.3151, 1289.8386, 1289.7514, 1288.9271],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(316646.9594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 188 was 69.0%\n",
      "current params: tensor([ 679.4474,  679.4271,  680.1353, 1290.8581, 1290.7675, 1289.9126],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(317621.4847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 189 was 69.1%\n",
      "current params: tensor([ 678.2442,  678.2233,  678.9567, 1291.8760, 1291.7820, 1290.8969],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(318599.5826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 190 was 69.1%\n",
      "current params: tensor([ 677.0423,  677.0208,  677.7793, 1292.8924, 1292.7948, 1291.8799],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(319581.2857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 191 was 69.2%\n",
      "current params: tensor([ 675.8416,  675.8195,  676.6029, 1293.9072, 1293.8060, 1292.8616],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(320566.6262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 192 was 69.2%\n",
      "current params: tensor([ 674.6423,  674.6196,  675.4277, 1294.9204, 1294.8157, 1293.8422],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(321555.6369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 193 was 69.3%\n",
      "current params: tensor([ 673.4443,  673.4209,  674.2535, 1295.9322, 1295.8237, 1294.8215],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(322548.3505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 194 was 69.3%\n",
      "current params: tensor([ 672.2474,  672.2234,  673.0804, 1296.9424, 1296.8303, 1295.7996],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(323544.7998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 195 was 69.4%\n",
      "current params: tensor([ 671.0519,  671.0271,  671.9084, 1297.9512, 1297.8353, 1296.7766],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(324545.0179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 196 was 69.4%\n",
      "current params: tensor([ 669.8575,  669.8321,  670.7373, 1298.9585, 1298.8387, 1297.7523],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(325549.0378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 197 was 69.5%\n",
      "current params: tensor([ 668.6643,  668.6382,  669.5673, 1299.9643, 1299.8407, 1298.7269],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(326556.8928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 198 was 69.5%\n",
      "current params: tensor([ 667.4723,  667.4454,  668.3983, 1300.9688, 1300.8412, 1299.7004],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(327568.6162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 199 was 69.6%\n",
      "current params: tensor([ 666.2814,  666.2538,  667.2303, 1301.9718, 1301.8403, 1300.6727],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(328584.2416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 200 was 69.6%\n",
      "current params: tensor([ 665.0916,  665.0633,  666.0632, 1302.9734, 1302.8379, 1301.6439],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(329603.8026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 201 was 69.7%\n",
      "current params: tensor([ 663.9030,  663.8739,  664.8971, 1303.9737, 1303.8341, 1302.6140],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(330627.3329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 202 was 69.7%\n",
      "current params: tensor([ 662.7155,  662.6856,  663.7319, 1304.9726, 1304.8289, 1303.5830],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(331654.8666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 203 was 69.8%\n",
      "current params: tensor([ 661.5291,  661.4983,  662.5676, 1305.9701, 1305.8223, 1304.5509],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(332686.4377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 204 was 69.8%\n",
      "current params: tensor([ 660.3437,  660.3121,  661.4043, 1306.9663, 1306.8143, 1305.5177],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(333722.0807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 205 was 69.9%\n",
      "current params: tensor([ 659.1594,  659.1269,  660.2418, 1307.9612, 1307.8050, 1306.4835],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(334761.8296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 206 was 69.9%\n",
      "current params: tensor([ 657.9761,  657.9428,  659.0802, 1308.9548, 1308.7943, 1307.4483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(335805.7192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 207 was 70.0%\n",
      "current params: tensor([ 656.7938,  656.7596,  657.9195, 1309.9472, 1309.7823, 1308.4119],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(336853.7842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 208 was 70.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 655.6125,  655.5774,  656.7596, 1310.9382, 1310.7690, 1309.3746],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(337906.0596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 209 was 70.1%\n",
      "current params: tensor([ 654.4322,  654.3962,  655.6006, 1311.9280, 1311.7544, 1310.3362],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(338962.5805, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 210 was 70.1%\n",
      "current params: tensor([ 653.2529,  653.2160,  654.4424, 1312.9166, 1312.7385, 1311.2969],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(340023.3822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 211 was 70.2%\n",
      "current params: tensor([ 652.0746,  652.0366,  653.2850, 1313.9040, 1313.7213, 1312.2565],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(341088.5002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 212 was 70.2%\n",
      "current params: tensor([ 650.8971,  650.8582,  652.1284, 1314.8901, 1314.7029, 1313.2152],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(342157.9701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 213 was 70.3%\n",
      "current params: tensor([ 649.7207,  649.6807,  650.9726, 1315.8750, 1315.6833, 1314.1729],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(343231.8278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 214 was 70.3%\n",
      "current params: tensor([ 648.5451,  648.5042,  649.8176, 1316.8588, 1316.6624, 1315.1296],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(344310.1094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 215 was 70.4%\n",
      "current params: tensor([ 647.3704,  647.3284,  648.6634, 1317.8414, 1317.6403, 1316.0853],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(345392.8511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 216 was 70.4%\n",
      "current params: tensor([ 646.1966,  646.1536,  647.5098, 1318.8228, 1318.6170, 1317.0401],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(346480.0894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 217 was 70.4%\n",
      "current params: tensor([ 645.0237,  644.9796,  646.3571, 1319.8031, 1319.5926, 1317.9940],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(347571.8611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 218 was 70.5%\n",
      "current params: tensor([ 643.8516,  643.8065,  645.2050, 1320.7823, 1320.5669, 1318.9470],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(348668.2029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 219 was 70.5%\n",
      "current params: tensor([ 642.6804,  642.6341,  644.0537, 1321.7603, 1321.5401, 1319.8990],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(349769.1521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 220 was 70.6%\n",
      "current params: tensor([ 641.5101,  641.4626,  642.9031, 1322.7373, 1322.5122, 1320.8501],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(350874.7459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 221 was 70.6%\n",
      "current params: tensor([ 640.3405,  640.2919,  641.7532, 1323.7131, 1323.4831, 1321.8004],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(351985.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 222 was 70.7%\n",
      "current params: tensor([ 639.1717,  639.1220,  640.6039, 1324.6879, 1324.4529, 1322.7497],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(353100.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 223 was 70.7%\n",
      "current params: tensor([ 638.0038,  637.9528,  639.4554, 1325.6616, 1325.4215, 1323.6982],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(354219.7723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 224 was 70.8%\n",
      "current params: tensor([ 636.8366,  636.7845,  638.3075, 1326.6342, 1326.3891, 1324.6457],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(355344.3228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 225 was 70.8%\n",
      "current params: tensor([ 635.6702,  635.6168,  637.1602, 1327.6058, 1327.3556, 1325.5925],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(356473.7081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 226 was 70.9%\n",
      "current params: tensor([ 634.5046,  634.4499,  636.0136, 1328.5764, 1328.3210, 1326.5383],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(357607.9671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 227 was 70.9%\n",
      "current params: tensor([ 633.3397,  633.2838,  634.8677, 1329.5459, 1329.2854, 1327.4833],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(358747.1387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 228 was 71.0%\n",
      "current params: tensor([ 632.1755,  632.1183,  633.7223, 1330.5144, 1330.2487, 1328.4275],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(359891.2622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 229 was 71.0%\n",
      "current params: tensor([ 631.0121,  630.9536,  632.5776, 1331.4819, 1331.2109, 1329.3709],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(361040.3771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 230 was 71.1%\n",
      "current params: tensor([ 629.8494,  629.7896,  631.4334, 1332.4484, 1332.1722, 1330.3134],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(362194.5232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 231 was 71.1%\n",
      "current params: tensor([ 628.6874,  628.6262,  630.2899, 1333.4140, 1333.1324, 1331.2551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(363353.7406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 232 was 71.2%\n",
      "current params: tensor([ 627.5260,  627.4635,  629.1469, 1334.3785, 1334.0916, 1332.1960],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(364518.0696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 233 was 71.2%\n",
      "current params: tensor([ 626.3654,  626.3015,  628.0046, 1335.3421, 1335.0497, 1333.1361],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(365687.5508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 234 was 71.3%\n",
      "current params: tensor([ 625.2054,  625.1401,  626.8627, 1336.3048, 1336.0069, 1334.0754],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(366862.2251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 235 was 71.3%\n",
      "current params: tensor([ 624.0461,  623.9794,  625.7215, 1337.2665, 1336.9632, 1335.0139],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(368042.1337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 236 was 71.4%\n",
      "current params: tensor([ 622.8875,  622.8193,  624.5808, 1338.2273, 1337.9184, 1335.9517],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(369227.3180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 237 was 71.4%\n",
      "current params: tensor([ 621.7294,  621.6598,  623.4406, 1339.1871, 1338.8727, 1336.8886],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(370417.8198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 238 was 71.5%\n",
      "current params: tensor([ 620.5721,  620.5009,  622.3009, 1340.1460, 1339.8260, 1337.8249],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(371613.6812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 239 was 71.5%\n",
      "current params: tensor([ 619.4153,  619.3427,  621.1618, 1341.1041, 1340.7784, 1338.7603],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(372814.9444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 240 was 71.6%\n",
      "current params: tensor([ 618.2591,  618.1850,  620.0232, 1342.0612, 1341.7299, 1339.6950],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(374021.6524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 241 was 71.6%\n",
      "current params: tensor([ 617.1036,  617.0279,  618.8851, 1343.0174, 1342.6804, 1340.6290],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(375233.8477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 242 was 71.7%\n",
      "current params: tensor([ 615.9486,  615.8714,  617.7475, 1343.9728, 1343.6300, 1341.5622],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(376451.5738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 243 was 71.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 614.7942,  614.7154,  616.6104, 1344.9273, 1344.5787, 1342.4947],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(377674.8743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 244 was 71.8%\n",
      "current params: tensor([ 613.6404,  613.5600,  615.4738, 1345.8809, 1345.5265, 1343.4265],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(378903.7931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 245 was 71.8%\n",
      "current params: tensor([ 612.4872,  612.4051,  614.3376, 1346.8337, 1346.4734, 1344.3575],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(380138.3745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 246 was 71.8%\n",
      "current params: tensor([ 611.3345,  611.2508,  613.2019, 1347.7856, 1347.4195, 1345.2879],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(381378.6631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 247 was 71.9%\n",
      "current params: tensor([ 610.1824,  610.0970,  612.0667, 1348.7367, 1348.3646, 1346.2175],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(382624.7038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 248 was 71.9%\n",
      "current params: tensor([ 609.0308,  608.9437,  610.9319, 1349.6870, 1349.3089, 1347.1464],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(383876.5418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 249 was 72.0%\n",
      "current params: tensor([ 607.8797,  607.7910,  609.7976, 1350.6364, 1350.2524, 1348.0747],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(385134.2229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 250 was 72.0%\n",
      "current params: tensor([ 606.7292,  606.6387,  608.6637, 1351.5850, 1351.1950, 1349.0022],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(386397.7929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 251 was 72.1%\n",
      "current params: tensor([ 605.5791,  605.4869,  607.5302, 1352.5329, 1352.1367, 1349.9291],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(387667.2982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 252 was 72.1%\n",
      "current params: tensor([ 604.4296,  604.3356,  606.3971, 1353.4799, 1353.0777, 1350.8553],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(388942.7855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 253 was 72.2%\n",
      "current params: tensor([ 603.2806,  603.1848,  605.2645, 1354.4261, 1354.0178, 1351.7809],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(390224.3017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 254 was 72.2%\n",
      "current params: tensor([ 602.1320,  602.0345,  604.1323, 1355.3716, 1354.9570, 1352.7057],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(391511.8945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 255 was 72.3%\n",
      "current params: tensor([ 600.9840,  600.8846,  603.0004, 1356.3162, 1355.8955, 1353.6299],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(392805.6115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 256 was 72.3%\n",
      "current params: tensor([ 599.8364,  599.7352,  601.8690, 1357.2601, 1356.8332, 1354.5535],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(394105.5009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 257 was 72.4%\n",
      "current params: tensor([ 598.6893,  598.5862,  600.7380, 1358.2033, 1357.7700, 1355.4764],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(395411.6114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 258 was 72.4%\n",
      "current params: tensor([ 597.5426,  597.4377,  599.6073, 1359.1456, 1358.7061, 1356.3987],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(396723.9918, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 259 was 72.5%\n",
      "current params: tensor([ 596.3964,  596.2895,  598.4770, 1360.0873, 1359.6414, 1357.3203],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(398042.6915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 260 was 72.5%\n",
      "current params: tensor([ 595.2506,  595.1419,  597.3471, 1361.0282, 1360.5759, 1358.2413],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(399367.7603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 261 was 72.6%\n",
      "current params: tensor([ 594.1053,  593.9946,  596.2176, 1361.9683, 1361.5097, 1359.1617],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(400699.2484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 262 was 72.6%\n",
      "current params: tensor([ 592.9604,  592.8477,  595.0884, 1362.9077, 1362.4427, 1360.0815],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(402037.2066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 263 was 72.7%\n",
      "current params: tensor([ 591.8159,  591.7013,  593.9595, 1363.8464, 1363.3749, 1361.0006],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(403381.6853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 264 was 72.7%\n",
      "current params: tensor([ 590.6719,  590.5552,  592.8310, 1364.7844, 1364.3064, 1361.9191],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(404732.7364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 265 was 72.8%\n",
      "current params: tensor([ 589.5282,  589.4095,  591.7028, 1365.7217, 1365.2371, 1362.8370],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(406090.4116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 266 was 72.8%\n",
      "current params: tensor([ 588.3850,  588.2642,  590.5750, 1366.6583, 1366.1671, 1363.7543],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(407454.7632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 267 was 72.9%\n",
      "current params: tensor([ 587.2421,  587.1193,  589.4475, 1367.5941, 1367.0964, 1364.6711],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(408825.8439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 268 was 72.9%\n",
      "current params: tensor([ 586.0996,  585.9748,  588.3203, 1368.5293, 1368.0249, 1365.5872],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(410203.7069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 269 was 73.0%\n",
      "current params: tensor([ 584.9576,  584.8306,  587.1934, 1369.4638, 1368.9528, 1366.5027],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(411588.4059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 270 was 73.0%\n",
      "current params: tensor([ 583.8158,  583.6867,  586.0669, 1370.3976, 1369.8799, 1367.4177],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(412979.9949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 271 was 73.0%\n",
      "current params: tensor([ 582.6745,  582.5432,  584.9406, 1371.3307, 1370.8063, 1368.3320],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(414378.5285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 272 was 73.1%\n",
      "current params: tensor([ 581.5335,  581.4001,  583.8147, 1372.2632, 1371.7320, 1369.2458],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(415784.0617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 273 was 73.1%\n",
      "current params: tensor([ 580.3929,  580.2573,  582.6890, 1373.1950, 1372.6570, 1370.1591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(417196.6500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 274 was 73.2%\n",
      "current params: tensor([ 579.2526,  579.1148,  581.5636, 1374.1261, 1373.5813, 1371.0717],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(418616.3493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 275 was 73.2%\n",
      "current params: tensor([ 578.1127,  577.9727,  580.4385, 1375.0566, 1374.5050, 1371.9838],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(420043.2162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 276 was 73.3%\n",
      "current params: tensor([ 576.9731,  576.8308,  579.3137, 1375.9864, 1375.4279, 1372.8953],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(421477.3076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 277 was 73.3%\n",
      "current params: tensor([ 575.8338,  575.6893,  578.1892, 1376.9156, 1376.3502, 1373.8063],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(422918.6809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 278 was 73.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 574.6949,  574.5481,  577.0649, 1377.8442, 1377.2719, 1374.7167],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(424367.3941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 279 was 73.4%\n",
      "current params: tensor([ 573.5563,  573.4072,  575.9409, 1378.7721, 1378.1928, 1375.6266],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(425823.5058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 280 was 73.5%\n",
      "current params: tensor([ 572.4180,  572.2665,  574.8172, 1379.6994, 1379.1131, 1376.5360],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(427287.0748, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 281 was 73.5%\n",
      "current params: tensor([ 571.2800,  571.1262,  573.6937, 1380.6261, 1380.0328, 1377.4448],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(428758.1608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 282 was 73.6%\n",
      "current params: tensor([ 570.1423,  569.9862,  572.5704, 1381.5521, 1380.9518, 1378.3530],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(430236.8237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 283 was 73.6%\n",
      "current params: tensor([ 569.0049,  568.8464,  571.4474, 1382.4775, 1381.8701, 1379.2607],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(431723.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 284 was 73.7%\n",
      "current params: tensor([ 567.8678,  567.7069,  570.3246, 1383.4024, 1382.7878, 1380.1679],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(433217.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 285 was 73.7%\n",
      "current params: tensor([ 566.7310,  566.5676,  569.2021, 1384.3266, 1383.7049, 1381.0746],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(434718.8833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 286 was 73.8%\n",
      "current params: tensor([ 565.5944,  565.4287,  568.0798, 1385.2502, 1384.6214, 1381.9808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(436228.4659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 287 was 73.8%\n",
      "current params: tensor([ 564.4582,  564.2899,  566.9577, 1386.1733, 1385.5372, 1382.8864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(437745.9339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 288 was 73.9%\n",
      "current params: tensor([ 563.3222,  563.1515,  565.8358, 1387.0957, 1386.4524, 1383.7915],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(439271.3509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 289 was 73.9%\n",
      "current params: tensor([ 562.1865,  562.0133,  564.7142, 1388.0175, 1387.3670, 1384.6961],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(440804.7808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 290 was 74.0%\n",
      "current params: tensor([ 561.0510,  560.8753,  563.5928, 1388.9388, 1388.2810, 1385.6002],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(442346.2882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 291 was 74.0%\n",
      "current params: tensor([ 559.9158,  559.7375,  562.4716, 1389.8595, 1389.1944, 1386.5038],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(443895.9384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 292 was 74.1%\n",
      "current params: tensor([ 558.7809,  558.6000,  561.3505, 1390.7796, 1390.1072, 1387.4069],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(445453.7970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 293 was 74.1%\n",
      "current params: tensor([ 557.6462,  557.4627,  560.2297, 1391.6991, 1391.0194, 1388.3095],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(447019.9306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 294 was 74.2%\n",
      "current params: tensor([ 556.5117,  556.3257,  559.1091, 1392.6181, 1391.9310, 1389.2116],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(448594.4061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 295 was 74.2%\n",
      "current params: tensor([ 555.3775,  555.1888,  557.9886, 1393.5365, 1392.8420, 1390.1132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(450177.2911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 296 was 74.3%\n",
      "current params: tensor([ 554.2435,  554.0522,  556.8684, 1394.4544, 1393.7524, 1391.0143],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(451768.6541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 297 was 74.3%\n",
      "current params: tensor([ 553.1097,  552.9158,  555.7483, 1395.3717, 1394.6622, 1391.9150],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(453368.5638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 298 was 74.3%\n",
      "current params: tensor([ 551.9762,  551.7795,  554.6284, 1396.2885, 1395.5715, 1392.8151],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(454977.0899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 299 was 74.4%\n",
      "current params: tensor([ 550.8428,  550.6435,  553.5087, 1397.2047, 1396.4802, 1393.7148],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(456594.3027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 300 was 74.4%\n",
      "current params: tensor([ 549.7097,  549.5077,  552.3892, 1398.1203, 1397.3883, 1394.6140],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(458220.2730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 301 was 74.5%\n",
      "current params: tensor([ 548.5768,  548.3720,  551.2698, 1399.0354, 1398.2958, 1395.5127],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(459855.0725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 302 was 74.5%\n",
      "current params: tensor([ 547.4441,  547.2365,  550.1506, 1399.9500, 1399.2028, 1396.4109],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(461498.7735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 303 was 74.6%\n",
      "current params: tensor([ 546.3116,  546.1013,  549.0316, 1400.8641, 1400.1092, 1397.3087],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(463151.4489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 304 was 74.6%\n",
      "current params: tensor([ 545.1793,  544.9661,  547.9127, 1401.7776, 1401.0151, 1398.2060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(464813.1724, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 305 was 74.7%\n",
      "current params: tensor([ 544.0472,  543.8312,  546.7939, 1402.6906, 1401.9204, 1399.1029],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(466484.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 306 was 74.7%\n",
      "current params: tensor([ 542.9152,  542.6964,  545.6754, 1403.6031, 1402.8252, 1399.9992],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(468164.0622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 307 was 74.8%\n",
      "current params: tensor([ 541.7835,  541.5618,  544.5569, 1404.5150, 1403.7294, 1400.8952],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(469853.3795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 308 was 74.8%\n",
      "current params: tensor([ 540.6519,  540.4274,  543.4386, 1405.4265, 1404.6331, 1401.7906],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(471552.0470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 309 was 74.9%\n",
      "current params: tensor([ 539.5205,  539.2931,  542.3204, 1406.3374, 1405.5363, 1402.6856],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(473260.1420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 310 was 74.9%\n",
      "current params: tensor([ 538.3893,  538.1589,  541.2024, 1407.2478, 1406.4389, 1403.5802],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(474977.7426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 311 was 75.0%\n",
      "current params: tensor([ 537.2582,  537.0249,  540.0845, 1408.1577, 1407.3409, 1404.4743],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(476704.9279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 312 was 75.0%\n",
      "current params: tensor([ 536.1273,  535.8911,  538.9668, 1409.0671, 1408.2425, 1405.3680],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(478441.7773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 313 was 75.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 534.9966,  534.7574,  537.8491, 1409.9760, 1409.1435, 1406.2612],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(480188.3713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 314 was 75.1%\n",
      "current params: tensor([ 533.8660,  533.6238,  536.7316, 1410.8844, 1410.0440, 1407.1539],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(481944.7913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 315 was 75.2%\n",
      "current params: tensor([ 532.7355,  532.4903,  535.6142, 1411.7923, 1410.9440, 1408.0463],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(483711.1194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 316 was 75.2%\n",
      "current params: tensor([ 531.6052,  531.3570,  534.4969, 1412.6997, 1411.8435, 1408.9382],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(485487.4384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 317 was 75.3%\n",
      "current params: tensor([ 530.4751,  530.2238,  533.3797, 1413.6067, 1412.7424, 1409.8296],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(487273.8321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 318 was 75.3%\n",
      "current params: tensor([ 529.3451,  529.0907,  532.2627, 1414.5131, 1413.6409, 1410.7207],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(489070.3852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 319 was 75.4%\n",
      "current params: tensor([ 528.2152,  527.9577,  531.1457, 1415.4191, 1414.5388, 1411.6112],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(490877.1830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 320 was 75.4%\n",
      "current params: tensor([ 527.0855,  526.8249,  530.0289, 1416.3245, 1415.4362, 1412.5014],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(492694.3118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 321 was 75.5%\n",
      "current params: tensor([ 525.9559,  525.6921,  528.9121, 1417.2295, 1416.3332, 1413.3911],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(494521.8590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 322 was 75.5%\n",
      "current params: tensor([ 524.8264,  524.5595,  527.7954, 1418.1341, 1417.2296, 1414.2804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(496359.9124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 323 was 75.6%\n",
      "current params: tensor([ 523.6970,  523.4269,  526.6789, 1419.0381, 1418.1255, 1415.1693],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(498208.5613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 324 was 75.6%\n",
      "current params: tensor([ 522.5677,  522.2945,  525.5624, 1419.9417, 1419.0210, 1416.0578],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(500067.8954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 325 was 75.7%\n",
      "current params: tensor([ 521.4386,  521.1621,  524.4460, 1420.8448, 1419.9159, 1416.9458],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(501938.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 326 was 75.7%\n",
      "current params: tensor([ 520.3096,  520.0299,  523.3297, 1421.7474, 1420.8104, 1417.8334],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(503818.9836, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 327 was 75.8%\n",
      "current params: tensor([ 519.1807,  518.8977,  522.2135, 1422.6496, 1421.7043, 1418.7206],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(505710.9222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 328 was 75.8%\n",
      "current params: tensor([ 518.0518,  517.7656,  521.0974, 1423.5513, 1422.5978, 1419.6074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(507613.9151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 329 was 75.9%\n",
      "current params: tensor([ 516.9231,  516.6336,  519.9813, 1424.4525, 1423.4908, 1420.4938],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(509528.0569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 330 was 75.9%\n",
      "current params: tensor([ 515.7945,  515.5017,  518.8653, 1425.3533, 1424.3834, 1421.3798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(511453.4434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 331 was 76.0%\n",
      "current params: tensor([ 514.6660,  514.3698,  517.7494, 1426.2537, 1425.2754, 1422.2653],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(513390.1711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 332 was 76.0%\n",
      "current params: tensor([ 513.5375,  513.2380,  516.6336, 1427.1536, 1426.1670, 1423.1505],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(515338.3377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 333 was 76.1%\n",
      "current params: tensor([ 512.4092,  512.1063,  515.5178, 1428.0530, 1427.0581, 1424.0352],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(517298.0419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 334 was 76.1%\n",
      "current params: tensor([ 511.2809,  510.9747,  514.4021, 1428.9520, 1427.9487, 1424.9195],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(519269.3835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 335 was 76.2%\n",
      "current params: tensor([ 510.1527,  509.8431,  513.2864, 1429.8505, 1428.8389, 1425.8034],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(521252.4634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 336 was 76.2%\n",
      "current params: tensor([ 509.0246,  508.7115,  512.1708, 1430.7486, 1429.7285, 1426.6870],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(523247.3833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 337 was 76.2%\n",
      "current params: tensor([ 507.8966,  507.5801,  511.0553, 1431.6462, 1430.6178, 1427.5701],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(525254.2462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 338 was 76.3%\n",
      "current params: tensor([ 506.7686,  506.4486,  509.9398, 1432.5434, 1431.5065, 1428.4528],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(527273.1565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 339 was 76.3%\n",
      "current params: tensor([ 505.6407,  505.3172,  508.8244, 1433.4402, 1432.3948, 1429.3351],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(529304.2189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 340 was 76.4%\n",
      "current params: tensor([ 504.5129,  504.1859,  507.7090, 1434.3365, 1433.2827, 1430.2171],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(531347.5399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 341 was 76.4%\n",
      "current params: tensor([ 503.3851,  503.0546,  506.5937, 1435.2324, 1434.1701, 1431.0986],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(533403.2270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 342 was 76.5%\n",
      "current params: tensor([ 502.2574,  501.9234,  505.4784, 1436.1279, 1435.0570, 1431.9797],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(535471.3888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 343 was 76.5%\n",
      "current params: tensor([ 501.1298,  500.7921,  504.3631, 1437.0229, 1435.9435, 1432.8605],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(537552.1351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 344 was 76.6%\n",
      "current params: tensor([ 500.0022,  499.6610,  503.2479, 1437.9175, 1436.8295, 1433.7408],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(539645.5770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 345 was 76.6%\n",
      "current params: tensor([ 498.8746,  498.5298,  502.1327, 1438.8117, 1437.7151, 1434.6208],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(541751.8266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 346 was 76.7%\n",
      "current params: tensor([ 497.7471,  497.3987,  501.0176, 1439.7054, 1438.6002, 1435.5003],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(543870.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 347 was 76.7%\n",
      "current params: tensor([ 496.6197,  496.2676,  499.9025, 1440.5987, 1439.4849, 1436.3795],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(546003.2042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 348 was 76.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 495.4922,  495.1365,  498.7874, 1441.4916, 1440.3691, 1437.2583],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(548148.5628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 349 was 76.8%\n",
      "current params: tensor([ 494.3649,  494.0055,  497.6724, 1442.3840, 1441.2529, 1438.1367],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(550307.1904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 350 was 76.9%\n",
      "current params: tensor([ 493.2375,  492.8744,  496.5573, 1443.2761, 1442.1363, 1439.0147],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(552479.2056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 351 was 76.9%\n",
      "current params: tensor([ 492.1102,  491.7434,  495.4423, 1444.1677, 1443.0192, 1439.8924],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(554664.7283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 352 was 77.0%\n",
      "current params: tensor([ 490.9829,  490.6124,  494.3274, 1445.0589, 1443.9017, 1440.7696],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(556863.8796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 353 was 77.0%\n",
      "current params: tensor([ 489.8557,  489.4814,  493.2124, 1445.9497, 1444.7837, 1441.6465],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(559076.7820, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 354 was 77.1%\n",
      "current params: tensor([ 488.7285,  488.3504,  492.0975, 1446.8400, 1445.6653, 1442.5230],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(561303.5595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 355 was 77.1%\n",
      "current params: tensor([ 487.6013,  487.2194,  490.9825, 1447.7300, 1446.5465, 1443.3991],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(563544.3374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 356 was 77.2%\n",
      "current params: tensor([ 486.4741,  486.0884,  489.8676, 1448.6195, 1447.4272, 1444.2748],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(565799.2423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 357 was 77.2%\n",
      "current params: tensor([ 485.3469,  484.9574,  488.7527, 1449.5086, 1448.3075, 1445.1502],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(568068.4024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 358 was 77.3%\n",
      "current params: tensor([ 484.2198,  483.8264,  487.6378, 1450.3974, 1449.1874, 1446.0251],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(570351.9473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 359 was 77.3%\n",
      "current params: tensor([ 483.0926,  482.6954,  486.5229, 1451.2857, 1450.0668, 1446.8997],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(572650.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 360 was 77.4%\n",
      "current params: tensor([ 481.9655,  481.5644,  485.4081, 1452.1735, 1450.9459, 1447.7740],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(574962.7170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 361 was 77.4%\n",
      "current params: tensor([ 480.8384,  480.4333,  484.2932, 1453.0610, 1451.8245, 1448.6478],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(577290.2085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 362 was 77.5%\n",
      "current params: tensor([ 479.7113,  479.3023,  483.1783, 1453.9481, 1452.7026, 1449.5213],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(579632.6180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 363 was 77.5%\n",
      "current params: tensor([ 478.5842,  478.1712,  482.0634, 1454.8348, 1453.5804, 1450.3944],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(581990.0827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 364 was 77.6%\n",
      "current params: tensor([ 477.4571,  477.0401,  480.9485, 1455.7210, 1454.4577, 1451.2671],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(584362.7413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 365 was 77.6%\n",
      "current params: tensor([ 476.3299,  475.9090,  479.8336, 1456.6069, 1455.3346, 1452.1394],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(586750.7343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 366 was 77.7%\n",
      "current params: tensor([ 475.2028,  474.7779,  478.7187, 1457.4923, 1456.2111, 1453.0114],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(589154.2033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 367 was 77.7%\n",
      "current params: tensor([ 474.0757,  473.6468,  477.6038, 1458.3774, 1457.0871, 1453.8830],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(591573.2921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 368 was 77.8%\n",
      "current params: tensor([ 472.9486,  472.5156,  476.4889, 1459.2620, 1457.9628, 1454.7543],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(594008.1459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 369 was 77.8%\n",
      "current params: tensor([ 471.8214,  471.3843,  475.3740, 1460.1463, 1458.8380, 1455.6251],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(596458.9118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 370 was 77.9%\n",
      "current params: tensor([ 470.6942,  470.2531,  474.2591, 1461.0301, 1459.7128, 1456.4956],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(598925.7383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 371 was 77.9%\n",
      "current params: tensor([ 469.5670,  469.1218,  473.1441, 1461.9136, 1460.5872, 1457.3657],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(601408.7760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 372 was 78.0%\n",
      "current params: tensor([ 468.4398,  467.9905,  472.0291, 1462.7966, 1461.4611, 1458.2355],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(603908.1771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 373 was 78.0%\n",
      "current params: tensor([ 467.3126,  466.8591,  470.9141, 1463.6793, 1462.3347, 1459.1049],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(606424.0955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 374 was 78.1%\n",
      "current params: tensor([ 466.1854,  465.7277,  469.7991, 1464.5616, 1463.2078, 1459.9739],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(608956.6871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 375 was 78.1%\n",
      "current params: tensor([ 465.0581,  464.5962,  468.6841, 1465.4434, 1464.0806, 1460.8425],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(611506.1094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 376 was 78.2%\n",
      "current params: tensor([ 463.9308,  463.4647,  467.5690, 1466.3249, 1464.9529, 1461.7108],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(614072.5222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 377 was 78.2%\n",
      "current params: tensor([ 462.8034,  462.3332,  466.4540, 1467.2059, 1465.8248, 1462.5787],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(616656.0868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 378 was 78.3%\n",
      "current params: tensor([ 461.6761,  461.2015,  465.3388, 1468.0866, 1466.6963, 1463.4463],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(619256.9667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 379 was 78.3%\n",
      "current params: tensor([ 460.5487,  460.0699,  464.2237, 1468.9669, 1467.5674, 1464.3135],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(621875.3270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 380 was 78.4%\n",
      "current params: tensor([ 459.4212,  458.9381,  463.1085, 1469.8468, 1468.4381, 1465.1803],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(624511.3353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 381 was 78.4%\n",
      "current params: tensor([ 458.2937,  457.8064,  461.9933, 1470.7263, 1469.3083, 1466.0467],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(627165.1609, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 382 was 78.5%\n",
      "current params: tensor([ 457.1662,  456.6745,  460.8781, 1471.6054, 1470.1782, 1466.9128],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(629836.9751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 383 was 78.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 456.0386,  455.5426,  459.7628, 1472.4841, 1471.0476, 1467.7785],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(632526.9514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 384 was 78.6%\n",
      "current params: tensor([ 454.9110,  454.4106,  458.6475, 1473.3624, 1471.9167, 1468.6439],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(635235.2655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 385 was 78.6%\n",
      "current params: tensor([ 453.7833,  453.2786,  457.5321, 1474.2403, 1472.7853, 1469.5089],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(637962.0951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 386 was 78.7%\n",
      "current params: tensor([ 452.6556,  452.1464,  456.4167, 1475.1179, 1473.6536, 1470.3735],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(640707.6201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 387 was 78.7%\n",
      "current params: tensor([ 451.5278,  451.0142,  455.3013, 1475.9950, 1474.5214, 1471.2377],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(643472.0226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 388 was 78.8%\n",
      "current params: tensor([ 450.4000,  449.8820,  454.1858, 1476.8718, 1475.3888, 1472.1016],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(646255.4870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 389 was 78.8%\n",
      "current params: tensor([ 449.2721,  448.7496,  453.0703, 1477.7481, 1476.2558, 1472.9652],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(649058.2000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 390 was 78.9%\n",
      "current params: tensor([ 448.1442,  447.6172,  451.9547, 1478.6241, 1477.1225, 1473.8283],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(651880.3504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 391 was 78.9%\n",
      "current params: tensor([ 447.0162,  446.4847,  450.8391, 1479.4997, 1477.9887, 1474.6911],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(654722.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 392 was 79.0%\n",
      "current params: tensor([ 445.8881,  445.3521,  449.7235, 1480.3749, 1478.8545, 1475.5536],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(657583.7314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 393 was 79.0%\n",
      "current params: tensor([ 444.7600,  444.2194,  448.6077, 1481.2497, 1479.7199, 1476.4156],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(660465.3520, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 394 was 79.1%\n",
      "current params: tensor([ 443.6317,  443.0867,  447.4920, 1482.1241, 1480.5849, 1477.2773],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(663367.1895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 395 was 79.1%\n",
      "current params: tensor([ 442.5035,  441.9538,  446.3761, 1482.9982, 1481.4495, 1478.1387],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(666289.4452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 396 was 79.2%\n",
      "current params: tensor([ 441.3751,  440.8209,  445.2603, 1483.8718, 1482.3137, 1478.9997],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(669232.3227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 397 was 79.3%\n",
      "current params: tensor([ 440.2467,  439.6878,  444.1443, 1484.7450, 1483.1774, 1479.8603],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(672196.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 398 was 79.3%\n",
      "current params: tensor([ 439.1182,  438.5547,  443.0283, 1485.6179, 1484.0408, 1480.7205],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(675180.7704, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 399 was 79.4%\n",
      "current params: tensor([ 437.9896,  437.4215,  441.9123, 1486.4904, 1484.9038, 1481.5804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(678186.7607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 400 was 79.4%\n",
      "current params: tensor([ 436.8610,  436.2881,  440.7962, 1487.3625, 1485.7664, 1482.4399],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(681214.2134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 401 was 79.5%\n",
      "current params: tensor([ 435.7322,  435.1547,  439.6800, 1488.2341, 1486.6286, 1483.2990],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(684263.3452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 402 was 79.5%\n",
      "current params: tensor([ 434.6034,  434.0211,  438.5638, 1489.1055, 1487.4904, 1484.1578],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(687334.3757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 403 was 79.6%\n",
      "current params: tensor([ 433.4745,  432.8875,  437.4475, 1489.9764, 1488.3517, 1485.0162],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(690427.5276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 404 was 79.6%\n",
      "current params: tensor([ 432.3455,  431.7537,  436.3311, 1490.8469, 1489.2127, 1485.8743],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(693543.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 405 was 79.7%\n",
      "current params: tensor([ 431.2164,  430.6199,  435.2147, 1491.7170, 1490.0733, 1486.7320],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(696681.0991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 406 was 79.7%\n",
      "current params: tensor([ 430.0872,  429.4859,  434.0982, 1492.5868, 1490.9335, 1487.5893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(699841.9783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 407 was 79.8%\n",
      "current params: tensor([ 428.9580,  428.3518,  432.9816, 1493.4561, 1491.7932, 1488.4462],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(703025.8978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 408 was 79.8%\n",
      "current params: tensor([ 427.8286,  427.2176,  431.8649, 1494.3251, 1492.6526, 1489.3028],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(706233.0947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 409 was 79.9%\n",
      "current params: tensor([ 426.6991,  426.0832,  430.7482, 1495.1937, 1493.5116, 1490.1590],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(709463.8095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 410 was 79.9%\n",
      "current params: tensor([ 425.5695,  424.9488,  429.6314, 1496.0619, 1494.3701, 1491.0148],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(712718.2857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 411 was 80.0%\n",
      "current params: tensor([ 424.4399,  423.8142,  428.5146, 1496.9297, 1495.2283, 1491.8703],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(715996.7700, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 412 was 80.0%\n",
      "current params: tensor([ 423.3101,  422.6795,  427.3977, 1497.7971, 1496.0860, 1492.7254],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(719299.5124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 413 was 80.1%\n",
      "current params: tensor([ 422.1802,  421.5447,  426.2806, 1498.6641, 1496.9434, 1493.5801],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(722626.7662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 414 was 80.1%\n",
      "current params: tensor([ 421.0502,  420.4098,  425.1635, 1499.5307, 1497.8003, 1494.4345],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(725978.7881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 415 was 80.2%\n",
      "current params: tensor([ 419.9201,  419.2747,  424.0464, 1500.3969, 1498.6569, 1495.2885],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(729355.8382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 416 was 80.2%\n",
      "current params: tensor([ 418.7899,  418.1395,  422.9291, 1501.2627, 1499.5130, 1496.1421],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(732758.1800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 417 was 80.3%\n",
      "current params: tensor([ 417.6596,  417.0041,  421.8118, 1502.1282, 1500.3687, 1496.9954],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(736186.0806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 418 was 80.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 416.5292,  415.8686,  420.6944, 1502.9932, 1501.2241, 1497.8482],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(739639.8107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 419 was 80.4%\n",
      "current params: tensor([ 415.3986,  414.7330,  419.5769, 1503.8579, 1502.0790, 1498.7007],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(743119.6446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 420 was 80.4%\n",
      "current params: tensor([ 414.2680,  413.5972,  418.4593, 1504.7221, 1502.9335, 1499.5529],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(746625.8605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 421 was 80.5%\n",
      "current params: tensor([ 413.1372,  412.4613,  417.3416, 1505.5860, 1503.7876, 1500.4046],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(750158.7399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 422 was 80.5%\n",
      "current params: tensor([ 412.0063,  411.3253,  416.2239, 1506.4495, 1504.6413, 1501.2560],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(753718.5686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 423 was 80.6%\n",
      "current params: tensor([ 410.8752,  410.1891,  415.1060, 1507.3125, 1505.4946, 1502.1070],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(757305.6362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 424 was 80.6%\n",
      "current params: tensor([ 409.7441,  409.0527,  413.9881, 1508.1752, 1506.3475, 1502.9576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(760920.2361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 425 was 80.7%\n",
      "current params: tensor([ 408.6128,  407.9163,  412.8701, 1509.0375, 1507.2000, 1503.8078],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(764562.6659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 426 was 80.8%\n",
      "current params: tensor([ 407.4813,  406.7796,  411.7519, 1509.8994, 1508.0520, 1504.6577],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(768233.2271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 427 was 80.8%\n",
      "current params: tensor([ 406.3498,  405.6428,  410.6337, 1510.7608, 1508.9037, 1505.5072],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(771932.2257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 428 was 80.9%\n",
      "current params: tensor([ 405.2181,  404.5059,  409.5154, 1511.6219, 1509.7549, 1506.3563],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(775659.9717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 429 was 80.9%\n",
      "current params: tensor([ 404.0863,  403.3688,  408.3970, 1512.4826, 1510.6058, 1507.2050],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(779416.7793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 430 was 81.0%\n",
      "current params: tensor([ 402.9543,  402.2315,  407.2786, 1513.3429, 1511.4562, 1508.0533],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(783202.9673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 431 was 81.0%\n",
      "current params: tensor([ 401.8222,  401.0941,  406.1600, 1514.2027, 1512.3062, 1508.9013],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(787018.8589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 432 was 81.1%\n",
      "current params: tensor([ 400.6900,  399.9565,  405.0413, 1515.0622, 1513.1558, 1509.7489],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(790864.7819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 433 was 81.1%\n",
      "current params: tensor([ 399.5576,  398.8187,  403.9225, 1515.9213, 1514.0050, 1510.5961],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(794741.0685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 434 was 81.2%\n",
      "current params: tensor([ 398.4251,  397.6808,  402.8036, 1516.7799, 1514.8538, 1511.4429],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(798648.0558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 435 was 81.2%\n",
      "current params: tensor([ 397.2924,  396.5427,  401.6846, 1517.6382, 1515.7021, 1512.2893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(802586.0855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 436 was 81.3%\n",
      "current params: tensor([ 396.1596,  395.4044,  400.5656, 1518.4960, 1516.5501, 1513.1353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(806555.5044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 437 was 81.3%\n",
      "current params: tensor([ 395.0266,  394.2660,  399.4464, 1519.3534, 1517.3976, 1513.9810],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(810556.6640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 438 was 81.4%\n",
      "current params: tensor([ 393.8935,  393.1274,  398.3271, 1520.2105, 1518.2447, 1514.8262],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(814589.9209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 439 was 81.4%\n",
      "current params: tensor([ 392.7602,  391.9886,  397.2077, 1521.0671, 1519.0914, 1515.6711],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(818655.6369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 440 was 81.5%\n",
      "current params: tensor([ 391.6268,  390.8496,  396.0882, 1521.9233, 1519.9377, 1516.5155],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(822754.1789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 441 was 81.5%\n",
      "current params: tensor([ 390.4932,  389.7105,  394.9686, 1522.7791, 1520.7835, 1517.3596],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(826885.9192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 442 was 81.6%\n",
      "current params: tensor([ 389.3594,  388.5711,  393.8489, 1523.6345, 1521.6289, 1518.2033],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(831051.2353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 443 was 81.7%\n",
      "current params: tensor([ 388.2255,  387.4316,  392.7291, 1524.4894, 1522.4739, 1519.0466],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(835250.5104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 444 was 81.7%\n",
      "current params: tensor([ 387.0915,  386.2919,  391.6091, 1525.3440, 1523.3185, 1519.8895],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(839484.1331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 445 was 81.8%\n",
      "current params: tensor([ 385.9572,  385.1520,  390.4891, 1526.1981, 1524.1627, 1520.7320],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(843752.4979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 446 was 81.8%\n",
      "current params: tensor([ 384.8228,  384.0119,  389.3690, 1527.0518, 1525.0064, 1521.5741],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(848056.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 447 was 81.9%\n",
      "current params: tensor([ 383.6882,  382.8717,  388.2487, 1527.9051, 1525.8497, 1522.4158],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(852395.0603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 448 was 81.9%\n",
      "current params: tensor([ 382.5535,  381.7312,  387.1283, 1528.7580, 1526.6926, 1523.2571],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(856770.0759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 449 was 82.0%\n",
      "current params: tensor([ 381.4186,  380.5905,  386.0079, 1529.6104, 1527.5350, 1524.0979],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(861181.4698, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 450 was 82.0%\n",
      "current params: tensor([ 380.2835,  379.4497,  384.8873, 1530.4625, 1528.3770, 1524.9384],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(865629.6666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 451 was 82.1%\n",
      "current params: tensor([ 379.1482,  378.3086,  383.7666, 1531.3141, 1529.2186, 1525.7785],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(870115.0968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 452 was 82.1%\n",
      "current params: tensor([ 378.0128,  377.1673,  382.6457, 1532.1652, 1530.0598, 1526.6182],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(874638.1977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 453 was 82.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 376.8772,  376.0259,  381.5248, 1533.0160, 1530.9005, 1527.4574],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(879199.4128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 454 was 82.2%\n",
      "current params: tensor([ 375.7414,  374.8842,  380.4037, 1533.8663, 1531.7407, 1528.2963],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(883799.1926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 455 was 82.3%\n",
      "current params: tensor([ 374.6054,  373.7423,  379.2826, 1534.7162, 1532.5806, 1529.1347],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(888437.9942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 456 was 82.4%\n",
      "current params: tensor([ 373.4692,  372.6002,  378.1613, 1535.5657, 1533.4200, 1529.9728],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(893116.2817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 457 was 82.4%\n",
      "current params: tensor([ 372.3329,  371.4579,  377.0399, 1536.4147, 1534.2590, 1530.8104],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(897834.5263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 458 was 82.5%\n",
      "current params: tensor([ 371.1963,  370.3154,  375.9184, 1537.2633, 1535.0975, 1531.6476],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(902593.2064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 459 was 82.5%\n",
      "current params: tensor([ 370.0596,  369.1727,  374.7967, 1538.1114, 1535.9356, 1532.4844],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(907392.8075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 460 was 82.6%\n",
      "current params: tensor([ 368.9227,  368.0297,  373.6749, 1538.9591, 1536.7732, 1533.3207],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(912233.8229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 461 was 82.6%\n",
      "current params: tensor([ 367.7855,  366.8865,  372.5530, 1539.8064, 1537.6104, 1534.1567],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(917116.7532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 462 was 82.7%\n",
      "current params: tensor([ 366.6482,  365.7431,  371.4310, 1540.6533, 1538.4471, 1534.9922],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(922042.1070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 463 was 82.7%\n",
      "current params: tensor([ 365.5107,  364.5995,  370.3089, 1541.4997, 1539.2834, 1535.8273],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(927010.4006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 464 was 82.8%\n",
      "current params: tensor([ 364.3730,  363.4557,  369.1866, 1542.3456, 1540.1193, 1536.6620],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(932022.1583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 465 was 82.8%\n",
      "current params: tensor([ 363.2351,  362.3116,  368.0643, 1543.1911, 1540.9546, 1537.4962],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(937077.9129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 466 was 82.9%\n",
      "current params: tensor([ 362.0970,  361.1673,  366.9417, 1544.0362, 1541.7896, 1538.3300],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(942178.2052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 467 was 82.9%\n",
      "current params: tensor([ 360.9586,  360.0227,  365.8191, 1544.8808, 1542.6241, 1539.1634],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(947323.5847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 468 was 83.0%\n",
      "current params: tensor([ 359.8201,  358.8780,  364.6964, 1545.7249, 1543.4581, 1539.9964],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(952514.6096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 469 was 83.1%\n",
      "current params: tensor([ 358.6814,  357.7330,  363.5735, 1546.5686, 1544.2917, 1540.8289],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(957751.8467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 470 was 83.1%\n",
      "current params: tensor([ 357.5424,  356.5877,  362.4505, 1547.4118, 1545.1248, 1541.6610],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(963035.8722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 471 was 83.2%\n",
      "current params: tensor([ 356.4033,  355.4422,  361.3273, 1548.2546, 1545.9574, 1542.4926],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(968367.2712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 472 was 83.2%\n",
      "current params: tensor([ 355.2639,  354.2965,  360.2040, 1549.0970, 1546.7896, 1543.3238],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(973746.6384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 473 was 83.3%\n",
      "current params: tensor([ 354.1243,  353.1505,  359.0806, 1549.9388, 1547.6213, 1544.1546],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(979174.5775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 474 was 83.3%\n",
      "current params: tensor([ 352.9845,  352.0043,  357.9571, 1550.7802, 1548.4525, 1544.9849],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(984651.7026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 475 was 83.4%\n",
      "current params: tensor([ 351.8445,  350.8578,  356.8335, 1551.6212, 1549.2833, 1545.8148],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(990178.6373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 476 was 83.4%\n",
      "current params: tensor([ 350.7042,  349.7111,  355.7097, 1552.4616, 1550.1136, 1546.6442],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(995756.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 477 was 83.5%\n",
      "current params: tensor([ 349.5637,  348.5641,  354.5858, 1553.3016, 1550.9435, 1547.4732],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1001384.4819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 478 was 83.6%\n",
      "current params: tensor([ 348.4230,  347.4169,  353.4617, 1554.1411, 1551.7728, 1548.3017],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1007064.6906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 479 was 83.6%\n",
      "current params: tensor([ 347.2821,  346.2694,  352.3375, 1554.9802, 1552.6017, 1549.1298],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1012797.3075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 480 was 83.7%\n",
      "current params: tensor([ 346.1409,  345.1216,  351.2132, 1555.8188, 1553.4301, 1549.9574],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1018583.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 481 was 83.7%\n",
      "current params: tensor([ 344.9995,  343.9736,  350.0887, 1556.6569, 1554.2580, 1550.7846],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1024422.4823, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 482 was 83.8%\n",
      "current params: tensor([ 343.8579,  342.8253,  348.9642, 1557.4945, 1555.0854, 1551.6113],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1030316.4271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 483 was 83.8%\n",
      "current params: tensor([ 342.7160,  341.6767,  347.8394, 1558.3316, 1555.9124, 1552.4375],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1036265.5537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 484 was 83.9%\n",
      "current params: tensor([ 341.5739,  340.5279,  346.7146, 1559.1683, 1556.7388, 1553.2633],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1042270.5847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 485 was 83.9%\n",
      "current params: tensor([ 340.4316,  339.3788,  345.5896, 1560.0044, 1557.5648, 1554.0886],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1048332.2549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 486 was 84.0%\n",
      "current params: tensor([ 339.2890,  338.2295,  344.4645, 1560.8401, 1558.3903, 1554.9134],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1054451.3112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 487 was 84.1%\n",
      "current params: tensor([ 338.1462,  337.0798,  343.3392, 1561.6753, 1559.2153, 1555.7377],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1060628.5134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 488 was 84.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 337.0031,  335.9299,  342.2138, 1562.5099, 1560.0398, 1556.5616],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1066864.6339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 489 was 84.2%\n",
      "current params: tensor([ 335.8598,  334.7797,  341.0883, 1563.3441, 1560.8637, 1557.3850],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1073160.4584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 490 was 84.2%\n",
      "current params: tensor([ 334.7162,  333.6292,  339.9626, 1564.1778, 1561.6872, 1558.2080],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1079516.7861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 491 was 84.3%\n",
      "current params: tensor([ 333.5723,  332.4784,  338.8368, 1565.0110, 1562.5102, 1559.0304],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1085934.4298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 492 was 84.3%\n",
      "current params: tensor([ 332.4283,  331.3273,  337.7109, 1565.8437, 1563.3327, 1559.8524],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1092414.2163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 493 was 84.4%\n",
      "current params: tensor([ 331.2839,  330.1760,  336.5848, 1566.6758, 1564.1546, 1560.6739],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1098956.9866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 494 was 84.5%\n",
      "current params: tensor([ 330.1393,  329.0243,  335.4586, 1567.5075, 1564.9761, 1561.4948],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1105563.5965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 495 was 84.5%\n",
      "current params: tensor([ 328.9945,  327.8724,  334.3322, 1568.3386, 1565.7970, 1562.3153],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1112234.9164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 496 was 84.6%\n",
      "current params: tensor([ 327.8493,  326.7201,  333.2058, 1569.1692, 1566.6174, 1563.1353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1118971.8323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 497 was 84.6%\n",
      "current params: tensor([ 326.7040,  325.5676,  332.0791, 1569.9993, 1567.4373, 1563.9548],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1125775.2455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 498 was 84.7%\n",
      "current params: tensor([ 325.5583,  324.4147,  330.9524, 1570.8289, 1568.2567, 1564.7738],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1132646.0730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 499 was 84.7%\n",
      "current params: tensor([ 324.4124,  323.2616,  329.8254, 1571.6580, 1569.0756, 1565.5924],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1139585.2481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 500 was 84.8%\n",
      "current params: tensor([ 323.2662,  322.1081,  328.6984, 1572.4865, 1569.8939, 1566.4103],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1146593.7211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 501 was 84.9%\n",
      "current params: tensor([ 322.1197,  320.9543,  327.5712, 1573.3145, 1570.7117, 1567.2278],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1153672.4586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 502 was 84.9%\n",
      "current params: tensor([ 320.9730,  319.8002,  326.4439, 1574.1420, 1571.5289, 1568.0448],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1160822.4449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 503 was 85.0%\n",
      "current params: tensor([ 319.8259,  318.6458,  325.3164, 1574.9689, 1572.3456, 1568.8613],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1168044.6818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 504 was 85.0%\n",
      "current params: tensor([ 318.6786,  317.4911,  324.1888, 1575.7953, 1573.1618, 1569.6772],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1175340.1891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 505 was 85.1%\n",
      "current params: tensor([ 317.5310,  316.3361,  323.0611, 1576.6212, 1573.9775, 1570.4927],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1182710.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 506 was 85.1%\n",
      "current params: tensor([ 316.3832,  315.1807,  321.9332, 1577.4465, 1574.7926, 1571.3076],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1190155.1876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 507 was 85.2%\n",
      "current params: tensor([ 315.2350,  314.0250,  320.8051, 1578.2712, 1575.6071, 1572.1219],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1197676.8124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 508 was 85.3%\n",
      "current params: tensor([ 314.0866,  312.8689,  319.6770, 1579.0954, 1576.4211, 1572.9358],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1205275.9758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 509 was 85.3%\n",
      "current params: tensor([ 312.9378,  311.7126,  318.5487, 1579.9191, 1577.2345, 1573.7491],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1212953.7943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 510 was 85.4%\n",
      "current params: tensor([ 311.7888,  310.5559,  317.4202, 1580.7422, 1578.0474, 1574.5619],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1220711.4047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 511 was 85.4%\n",
      "current params: tensor([ 310.6394,  309.3988,  316.2916, 1581.5647, 1578.8597, 1575.3741],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1228549.9651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 512 was 85.5%\n",
      "current params: tensor([ 309.4898,  308.2414,  315.1629, 1582.3867, 1579.6715, 1576.1859],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1236470.6551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 513 was 85.5%\n",
      "current params: tensor([ 308.3399,  307.0837,  314.0341, 1583.2080, 1580.4827, 1576.9970],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1244474.6762, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 514 was 85.6%\n",
      "current params: tensor([ 307.1896,  305.9256,  312.9051, 1584.0289, 1581.2933, 1577.8076],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1252563.2525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 515 was 85.7%\n",
      "current params: tensor([ 306.0391,  304.7672,  311.7759, 1584.8491, 1582.1034, 1578.6177],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1260737.6312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 516 was 85.7%\n",
      "current params: tensor([ 304.8882,  303.6084,  310.6466, 1585.6688, 1582.9128, 1579.4272],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1268999.0831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 517 was 85.8%\n",
      "current params: tensor([ 303.7371,  302.4493,  309.5172, 1586.4878, 1583.7217, 1580.2361],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1277348.9031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 518 was 85.8%\n",
      "current params: tensor([ 302.5856,  301.2898,  308.3876, 1587.3063, 1584.5300, 1581.0445],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1285788.4107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 519 was 85.9%\n",
      "current params: tensor([ 301.4338,  300.1299,  307.2579, 1588.1242, 1585.3377, 1581.8524],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1294318.9508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 520 was 86.0%\n",
      "current params: tensor([ 300.2817,  298.9697,  306.1281, 1588.9415, 1586.1449, 1582.6596],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1302941.8944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 521 was 86.0%\n",
      "current params: tensor([ 299.1293,  297.8091,  304.9981, 1589.7583, 1586.9514, 1583.4663],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1311658.6381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 522 was 86.1%\n",
      "current params: tensor([ 297.9765,  296.6481,  303.8680, 1590.5744, 1587.7573, 1584.2724],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1320470.6064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 523 was 86.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([ 296.8234,  295.4868,  302.7378, 1591.3899, 1588.5626, 1585.0779],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1329379.2514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 524 was 86.2%\n",
      "current params: tensor([ 295.6700,  294.3251,  301.6074, 1592.2048, 1589.3674, 1585.8829],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1338386.0533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 525 was 86.2%\n",
      "current params: tensor([ 294.5162,  293.1630,  300.4769, 1593.0190, 1590.1715, 1586.6873],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1347492.5217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 526 was 86.3%\n",
      "current params: tensor([ 293.3622,  292.0005,  299.3462, 1593.8327, 1590.9750, 1587.4910],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1356700.1958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 527 was 86.4%\n",
      "current params: tensor([ 292.2077,  290.8376,  298.2154, 1594.6457, 1591.7779, 1588.2942],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1366010.6452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 528 was 86.4%\n",
      "current params: tensor([ 291.0530,  289.6743,  297.0845, 1595.4581, 1592.5801, 1589.0968],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1375425.4709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 529 was 86.5%\n",
      "current params: tensor([ 289.8979,  288.5106,  295.9534, 1596.2699, 1593.3818, 1589.8988],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1384946.3058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 530 was 86.5%\n",
      "current params: tensor([ 288.7424,  287.3466,  294.8222, 1597.0811, 1594.1828, 1590.7001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1394574.8156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 531 was 86.6%\n",
      "current params: tensor([ 287.5866,  286.1821,  293.6909, 1597.8916, 1594.9831, 1591.5009],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1404312.6994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 532 was 86.7%\n",
      "current params: tensor([ 286.4305,  285.0172,  292.5594, 1598.7014, 1595.7829, 1592.3010],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1414161.6910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 533 was 86.7%\n",
      "current params: tensor([ 285.2740,  283.8519,  291.4278, 1599.5106, 1596.5820, 1593.1006],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1424123.5592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 534 was 86.8%\n",
      "current params: tensor([ 284.1171,  282.6862,  290.2961, 1600.3192, 1597.3804, 1593.8995],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1434200.1090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 535 was 86.8%\n",
      "current params: tensor([ 282.9599,  281.5201,  289.1642, 1601.1271, 1598.1782, 1594.6977],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1444393.1824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 536 was 86.9%\n",
      "current params: tensor([ 281.8023,  280.3535,  288.0322, 1601.9344, 1598.9753, 1595.4954],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1431564.7095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 537 was 86.6%\n",
      "current params: tensor([ 280.6049,  279.1575,  286.8603, 1602.7443, 1599.8085, 1596.3285],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1442223.3244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 538 was 86.7%\n",
      "current params: tensor([ 279.4077,  277.9615,  285.6889, 1603.5534, 1600.6406, 1597.1606],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1453005.8239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 539 was 86.8%\n",
      "current params: tensor([ 278.2107,  276.7657,  284.5178, 1604.3616, 1601.4716, 1597.9916],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1463914.2921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 540 was 86.8%\n",
      "current params: tensor([ 277.0138,  275.5700,  283.3471, 1605.1689, 1602.3015, 1598.8215],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1474950.8313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 541 was 86.9%\n",
      "current params: tensor([ 275.8171,  274.3744,  282.1768, 1605.9754, 1603.1303, 1599.6504],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1486117.5881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 542 was 87.0%\n",
      "current params: tensor([ 274.6205,  273.1789,  281.0070, 1606.7810, 1603.9580, 1600.4781],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1497416.7539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 543 was 87.0%\n",
      "current params: tensor([ 273.4241,  271.9834,  279.8375, 1607.5857, 1604.7845, 1601.3048],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1508850.5672, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 544 was 87.1%\n",
      "current params: tensor([ 272.2278,  270.7880,  278.6683, 1608.3896, 1605.6100, 1602.1304],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1520421.3146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 545 was 87.2%\n",
      "current params: tensor([ 271.0317,  269.5927,  277.4996, 1609.1926, 1606.4344, 1602.9550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1532131.3309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 546 was 87.2%\n",
      "current params: tensor([ 269.8356,  268.3974,  276.3312, 1609.9947, 1607.2576, 1603.7785],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1543983.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 547 was 87.3%\n",
      "current params: tensor([ 268.6396,  267.2022,  275.1632, 1610.7959, 1608.0797, 1604.6008],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1555978.7667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 548 was 87.4%\n",
      "current params: tensor([ 267.4438,  266.0069,  273.9956, 1611.5962, 1608.9008, 1605.4221],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1568121.1149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 549 was 87.4%\n",
      "current params: tensor([ 266.2480,  264.8117,  272.8283, 1612.3957, 1609.7207, 1606.2424],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1580412.5927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 550 was 87.5%\n",
      "current params: tensor([ 265.0522,  263.6165,  271.6613, 1613.1942, 1610.5395, 1607.0615],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1592855.8020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 551 was 87.5%\n",
      "current params: tensor([ 263.8566,  262.4213,  270.4947, 1613.9919, 1611.3572, 1607.8796],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1605453.4016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 552 was 87.6%\n",
      "current params: tensor([ 262.6609,  261.2261,  269.3285, 1614.7886, 1612.1737, 1608.6965],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1618208.1103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 553 was 87.7%\n",
      "current params: tensor([ 261.4654,  260.0308,  268.1625, 1615.5845, 1612.9892, 1609.5124],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1631122.7074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 554 was 87.7%\n",
      "current params: tensor([ 260.2698,  258.8355,  266.9969, 1616.3794, 1613.8035, 1610.3272],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1644200.0348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 555 was 87.8%\n",
      "current params: tensor([ 259.0743,  257.6401,  265.8317, 1617.1735, 1614.6167, 1611.1409],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1657442.9985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 556 was 87.9%\n",
      "current params: tensor([ 257.8788,  256.4447,  264.6667, 1617.9666, 1615.4288, 1611.9535],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1670854.5705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 557 was 87.9%\n",
      "current params: tensor([ 256.6832,  255.2492,  263.5021, 1618.7589, 1616.2398, 1612.7650],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1684437.7906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 558 was 88.0%\n",
      "current params: tensor([ 255.4877,  254.0536,  262.3378, 1619.5502, 1617.0496, 1613.5755],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1698195.7688, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 559 was 88.1%\n",
      "current params: tensor([ 254.2922,  252.8579,  261.1738, 1620.3405, 1617.8583, 1614.3848],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1712131.6857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 560 was 88.1%\n",
      "current params: tensor([ 253.0966,  251.6621,  260.0101, 1621.1300, 1618.6658, 1615.1930],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1726248.7966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 561 was 88.2%\n",
      "current params: tensor([ 251.9010,  250.4663,  258.8467, 1621.9185, 1619.4723, 1616.0001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1740550.4323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 562 was 88.3%\n",
      "current params: tensor([ 250.7053,  249.2702,  257.6836, 1622.7061, 1620.2775, 1616.8061],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1755040.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 563 was 88.3%\n",
      "current params: tensor([ 249.5096,  248.0741,  256.5209, 1623.4927, 1621.0817, 1617.6109],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1769720.9931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 564 was 88.4%\n",
      "current params: tensor([ 248.3138,  246.8778,  255.3584, 1624.2784, 1621.8846, 1618.4147],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1784596.9788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 565 was 88.5%\n",
      "current params: tensor([ 247.1179,  245.6814,  254.1962, 1625.0632, 1622.6865, 1619.2173],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1799671.6149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 566 was 88.5%\n",
      "current params: tensor([ 245.9220,  244.4848,  253.0343, 1625.8470, 1623.4872, 1620.0189],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1814948.6452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 567 was 88.6%\n",
      "current params: tensor([ 244.7259,  243.2880,  251.8727, 1626.6298, 1624.2867, 1620.8193],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1830431.9039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 568 was 88.7%\n",
      "current params: tensor([ 243.5298,  242.0910,  250.7114, 1627.4117, 1625.0850, 1621.6185],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1846125.3168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 569 was 88.7%\n",
      "current params: tensor([ 242.3335,  240.8938,  249.5503, 1628.1926, 1625.8822, 1622.4167],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1862032.9058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 570 was 88.8%\n",
      "current params: tensor([ 241.1371,  239.6965,  248.3896, 1628.9725, 1626.6783, 1623.2137],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1878158.7910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 571 was 88.9%\n",
      "current params: tensor([ 239.9406,  238.4989,  247.2291, 1629.7515, 1627.4731, 1624.0095],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1894507.1934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 572 was 88.9%\n",
      "current params: tensor([ 238.7439,  237.3010,  246.0689, 1630.5294, 1628.2668, 1624.8043],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1911082.4382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 573 was 89.0%\n",
      "current params: tensor([ 237.5471,  236.1030,  244.9090, 1631.3064, 1629.0593, 1625.5978],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1927888.9580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 574 was 89.1%\n",
      "current params: tensor([ 236.3501,  234.9047,  243.7494, 1632.0824, 1629.8506, 1626.3903],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1944931.2959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 575 was 89.1%\n",
      "current params: tensor([ 235.1529,  233.7061,  242.5900, 1632.8574, 1630.6407, 1627.1815],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1962214.1090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 576 was 89.2%\n",
      "current params: tensor([ 233.9556,  232.5073,  241.4310, 1633.6313, 1631.4296, 1627.9716],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1979742.1722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 577 was 89.3%\n",
      "current params: tensor([ 232.7581,  231.3081,  240.2722, 1634.4043, 1632.2173, 1628.7606],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1997520.3806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 578 was 89.3%\n",
      "current params: tensor([ 231.5603,  230.1087,  239.1137, 1635.1762, 1633.0038, 1629.5483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2015553.7549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 579 was 89.4%\n",
      "current params: tensor([ 230.3624,  228.9090,  237.9554, 1635.9471, 1633.7892, 1630.3349],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2033847.4445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 580 was 89.5%\n",
      "current params: tensor([ 229.1642,  227.7090,  236.7974, 1636.7170, 1634.5732, 1631.1203],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2052406.7314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 581 was 89.5%\n",
      "current params: tensor([ 227.9658,  226.5086,  235.6397, 1637.4859, 1635.3561, 1631.9046],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2071237.0347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 582 was 89.6%\n",
      "current params: tensor([ 226.7672,  225.3079,  234.4823, 1638.2537, 1636.1378, 1632.6876],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2090343.9148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 583 was 89.7%\n",
      "current params: tensor([ 225.5683,  224.1068,  233.3252, 1639.0204, 1636.9182, 1633.4695],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2109733.0781, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 584 was 89.7%\n",
      "current params: tensor([ 224.3692,  222.9054,  232.1683, 1639.7861, 1637.6973, 1634.2501],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2129410.3814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 585 was 89.8%\n",
      "current params: tensor([ 223.1697,  221.7037,  231.0118, 1640.5507, 1638.4753, 1635.0295],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2149381.8370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 586 was 89.9%\n",
      "current params: tensor([ 221.9700,  220.5015,  229.8555, 1641.3142, 1639.2519, 1635.8078],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2169653.6177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 587 was 90.0%\n",
      "current params: tensor([ 220.7701,  219.2989,  228.6994, 1642.0767, 1640.0274, 1636.5848],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2190232.0622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 588 was 90.0%\n",
      "current params: tensor([ 219.5698,  218.0960,  227.5437, 1642.8381, 1640.8015, 1637.3606],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2211123.6796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 589 was 90.1%\n",
      "current params: tensor([ 218.3692,  216.8926,  226.3883, 1643.5983, 1641.5744, 1638.1351],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2232335.1568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 590 was 90.2%\n",
      "current params: tensor([ 217.1683,  215.6888,  225.2331, 1644.3575, 1642.3460, 1638.9084],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2253873.3628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 591 was 90.2%\n",
      "current params: tensor([ 215.9670,  214.4845,  224.0782, 1645.1156, 1643.1164, 1639.6805],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2275745.3559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 592 was 90.3%\n",
      "current params: tensor([ 214.7654,  213.2798,  222.9237, 1645.8725, 1643.8854, 1640.4513],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(2297958.3891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 593 was 90.4%\n",
      "current params: tensor([ 213.5635,  212.0746,  221.7694, 1646.6283, 1644.6532, 1641.2209],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2320519.9177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 594 was 90.4%\n",
      "current params: tensor([ 212.3611,  210.8689,  220.6154, 1647.3830, 1645.4196, 1641.9892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2343437.6053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 595 was 90.5%\n",
      "current params: tensor([ 211.1585,  209.6628,  219.4618, 1648.1365, 1646.1848, 1642.7562],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2366719.3315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 596 was 90.6%\n",
      "current params: tensor([ 209.9554,  208.4561,  218.3084, 1648.8889, 1646.9486, 1643.5220],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2390373.1993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 597 was 90.6%\n",
      "current params: tensor([ 208.7519,  207.2490,  217.1553, 1649.6401, 1647.7111, 1644.2865],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2414407.5426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 598 was 90.7%\n",
      "current params: tensor([ 207.5480,  206.0412,  216.0026, 1650.3901, 1648.4722, 1645.0497],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2438830.9347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 599 was 90.8%\n",
      "current params: tensor([ 206.3438,  204.8330,  214.8502, 1651.1390, 1649.2320, 1645.8116],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2463652.1957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 600 was 90.9%\n",
      "current params: tensor([ 205.1390,  203.6242,  213.6981, 1651.8866, 1649.9905, 1646.5721],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2488880.4026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 601 was 90.9%\n",
      "current params: tensor([ 203.9339,  202.4148,  212.5464, 1652.6331, 1650.7476, 1647.3314],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2514524.8978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 602 was 91.0%\n",
      "current params: tensor([ 202.7283,  201.2048,  211.3950, 1653.3784, 1651.5033, 1648.0893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2540595.2984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 603 was 91.1%\n",
      "current params: tensor([ 201.5222,  199.9943,  210.2439, 1654.1224, 1652.2577, 1648.8459],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2567101.5066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 604 was 91.1%\n",
      "current params: tensor([ 200.3156,  198.7831,  209.0932, 1654.8652, 1653.0107, 1649.6012],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2594053.7195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 605 was 91.2%\n",
      "current params: tensor([ 199.1086,  197.5713,  207.9428, 1655.6068, 1653.7622, 1650.3551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2621462.4404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 606 was 91.3%\n",
      "current params: tensor([ 197.9010,  196.3588,  206.7929, 1656.3471, 1654.5124, 1651.1077],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2649338.4895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 607 was 91.4%\n",
      "current params: tensor([ 196.6930,  195.1457,  205.6432, 1657.0861, 1655.2612, 1651.8589],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2677693.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 608 was 91.4%\n",
      "current params: tensor([ 195.4844,  193.9319,  204.4940, 1657.8239, 1656.0085, 1652.6087],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2706537.5112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 609 was 91.5%\n",
      "current params: tensor([ 194.2753,  192.7174,  203.3452, 1658.5604, 1656.7544, 1653.3571],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2735883.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 610 was 91.6%\n",
      "current params: tensor([ 193.0656,  191.5022,  202.1967, 1659.2956, 1657.4988, 1654.1042],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2765744.1519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 611 was 91.6%\n",
      "current params: tensor([ 191.8554,  190.2863,  201.0487, 1660.0295, 1658.2418, 1654.8498],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2796131.1027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 612 was 91.7%\n",
      "current params: tensor([ 190.6446,  189.0697,  199.9011, 1660.7621, 1658.9834, 1655.5940],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2827057.6611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 613 was 91.8%\n",
      "current params: tensor([ 189.4332,  187.8523,  198.7539, 1661.4933, 1659.7234, 1656.3368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2858537.2277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 614 was 91.9%\n",
      "current params: tensor([ 188.2212,  186.6342,  197.6072, 1662.2232, 1660.4620, 1657.0782],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2890583.6304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 615 was 91.9%\n",
      "current params: tensor([ 187.0086,  185.4152,  196.4609, 1662.9518, 1661.1991, 1657.8181],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2923211.1409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 616 was 92.0%\n",
      "current params: tensor([ 185.7954,  184.1955,  195.3151, 1663.6789, 1661.9346, 1658.5566],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2956434.4927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 617 was 92.1%\n",
      "current params: tensor([ 184.5815,  182.9749,  194.1698, 1664.4047, 1662.6687, 1659.2936],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2990268.8985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 618 was 92.1%\n",
      "current params: tensor([ 183.3669,  181.7535,  193.0249, 1665.1292, 1663.4012, 1660.0291],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3024730.0705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 619 was 92.2%\n",
      "current params: tensor([ 182.1517,  180.5312,  191.8806, 1665.8522, 1664.1322, 1660.7631],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3059834.2400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 620 was 92.3%\n",
      "current params: tensor([ 180.9358,  179.3080,  190.7368, 1666.5737, 1664.8616, 1661.4956],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3095598.1770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 621 was 92.4%\n",
      "current params: tensor([ 179.7192,  178.0840,  189.5935, 1667.2939, 1665.5894, 1662.2267],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3132039.2153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 622 was 92.4%\n",
      "current params: tensor([ 178.5019,  176.8590,  188.4507, 1668.0126, 1666.3157, 1662.9561],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3169175.2731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 623 was 92.5%\n",
      "current params: tensor([ 177.2838,  175.6331,  187.3086, 1668.7298, 1667.0403, 1663.6841],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3207024.8784, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 624 was 92.6%\n",
      "current params: tensor([ 176.0650,  174.4062,  186.1670, 1669.4456, 1667.7634, 1664.4105],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3245607.1942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 625 was 92.7%\n",
      "current params: tensor([ 174.8454,  173.1783,  185.0261, 1670.1599, 1668.4848, 1665.1353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3284942.0451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 626 was 92.7%\n",
      "current params: tensor([ 173.6251,  171.9495,  183.8857, 1670.8727, 1669.2046, 1665.8586],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3325049.9458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 627 was 92.8%\n",
      "current params: tensor([ 172.4039,  170.7196,  182.7460, 1671.5839, 1669.9227, 1666.5803],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(3365952.1301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 628 was 92.9%\n",
      "current params: tensor([ 171.1819,  169.4887,  181.6070, 1672.2936, 1670.6392, 1667.3004],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3407670.5825, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 629 was 93.0%\n",
      "current params: tensor([ 169.9591,  168.2567,  180.4687, 1673.0018, 1671.3539, 1668.0188],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3450228.0705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 630 was 93.0%\n",
      "current params: tensor([ 168.7354,  167.0236,  179.3310, 1673.7084, 1672.0670, 1668.7357],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3493648.1780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 631 was 93.1%\n",
      "current params: tensor([ 167.5109,  165.7894,  178.1941, 1674.4134, 1672.7784, 1669.4508],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3537955.3433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 632 was 93.2%\n",
      "current params: tensor([ 166.2854,  164.5540,  177.0580, 1675.1168, 1673.4880, 1670.1644],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3583174.8959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 633 was 93.3%\n",
      "current params: tensor([ 165.0591,  163.3175,  175.9227, 1675.8185, 1674.1960, 1670.8762],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3629333.0966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 634 was 93.3%\n",
      "current params: tensor([ 163.8318,  162.0797,  174.7881, 1676.5187, 1674.9021, 1671.5864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3676457.1798, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 635 was 93.4%\n",
      "current params: tensor([ 162.6036,  160.8408,  173.6544, 1677.2172, 1675.6065, 1672.2949],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3724575.3979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 636 was 93.5%\n",
      "current params: tensor([ 161.3744,  159.6006,  172.5216, 1677.9140, 1676.3090, 1673.0016],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3773717.0684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 637 was 93.6%\n",
      "current params: tensor([ 160.1442,  158.3591,  171.3897, 1678.6091, 1677.0098, 1673.7066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3823912.6233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 638 was 93.6%\n",
      "current params: tensor([ 158.9130,  157.1163,  170.2587, 1679.3025, 1677.7087, 1674.4099],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3875193.6614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 639 was 93.7%\n",
      "current params: tensor([ 157.6807,  155.8721,  169.1287, 1679.9942, 1678.4058, 1675.1114],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3927593.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 640 was 93.8%\n",
      "current params: tensor([ 156.4474,  154.6266,  167.9997, 1680.6842, 1679.1011, 1675.8111],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3981144.7470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 641 was 93.9%\n",
      "current params: tensor([ 155.2130,  153.3797,  166.8717, 1681.3723, 1679.7944, 1676.5090],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4035884.3377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 642 was 93.9%\n",
      "current params: tensor([ 153.9775,  152.1314,  165.7448, 1682.0587, 1680.4858, 1677.2051],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4091848.6234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 643 was 94.0%\n",
      "current params: tensor([ 152.7409,  150.8815,  164.6190, 1682.7433, 1681.1753, 1677.8993],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4149075.9292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 644 was 94.1%\n",
      "current params: tensor([ 151.5031,  149.6302,  163.4944, 1683.4260, 1681.8629, 1678.5917],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4207606.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 645 was 94.2%\n",
      "current params: tensor([ 150.2641,  148.3773,  162.3710, 1684.1069, 1682.5485, 1679.2822],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4267480.7238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 646 was 94.3%\n",
      "current params: tensor([ 149.0240,  147.1229,  161.2488, 1684.7859, 1683.2322, 1679.9708],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4328742.9221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 647 was 94.3%\n",
      "current params: tensor([ 147.7825,  145.8668,  160.1280, 1685.4630, 1683.9138, 1680.6576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4391437.7273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 648 was 94.4%\n",
      "current params: tensor([ 146.5399,  144.6090,  159.0085, 1686.1382, 1684.5934, 1681.3423],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4455612.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 649 was 94.5%\n",
      "current params: tensor([ 145.2959,  143.3496,  157.8903, 1686.8114, 1685.2709, 1682.0251],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4521314.7137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 650 was 94.6%\n",
      "current params: tensor([ 144.0506,  142.0884,  156.7737, 1687.4827, 1685.9464, 1682.7060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4588596.7405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 651 was 94.7%\n",
      "current params: tensor([ 142.8039,  140.8254,  155.6585, 1688.1520, 1686.6198, 1683.3848],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4657511.2811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 652 was 94.7%\n",
      "current params: tensor([ 141.5559,  139.5606,  154.5449, 1688.8193, 1687.2911, 1684.0617],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4728113.8231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 653 was 94.8%\n",
      "current params: tensor([ 140.3064,  138.2939,  153.4330, 1689.4845, 1687.9602, 1684.7365],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4800462.2989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 654 was 94.9%\n",
      "current params: tensor([ 139.0555,  137.0253,  152.3227, 1690.1476, 1688.6271, 1685.4092],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4874617.2179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 655 was 95.0%\n",
      "current params: tensor([ 137.8031,  135.7547,  151.2143, 1690.8087, 1689.2919, 1686.0798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4950641.8113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 656 was 95.1%\n",
      "current params: tensor([ 136.5491,  134.4820,  150.1076, 1691.4676, 1689.9545, 1686.7483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5028602.1831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 657 was 95.1%\n",
      "current params: tensor([ 135.2936,  133.2073,  149.0029, 1692.1244, 1690.6148, 1687.4147],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5108567.4727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 658 was 95.2%\n",
      "current params: tensor([ 134.0365,  131.9304,  147.9001, 1692.7790, 1691.2728, 1688.0790],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5190610.0287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 659 was 95.3%\n",
      "current params: tensor([ 132.7778,  130.6513,  146.7995, 1693.4314, 1691.9286, 1688.7410],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5274805.5945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 660 was 95.4%\n",
      "current params: tensor([ 131.5173,  129.3700,  145.7009, 1694.0815, 1692.5820, 1689.4009],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5361233.5077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 661 was 95.5%\n",
      "current params: tensor([ 130.2552,  128.0863,  144.6047, 1694.7294, 1693.2330, 1690.0585],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5449976.9109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 662 was 95.5%\n",
      "current params: tensor([ 128.9913,  126.8002,  143.5107, 1695.3750, 1693.8817, 1690.7138],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5541122.9833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 663 was 95.6%\n",
      "current params: tensor([ 127.7256,  125.5117,  142.4192, 1696.0183, 1694.5280, 1691.3669],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5634763.1834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 664 was 95.7%\n",
      "current params: tensor([ 126.4580,  124.2206,  141.3303, 1696.6591, 1695.1718, 1692.0176],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5730993.5127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 665 was 95.8%\n",
      "current params: tensor([ 125.1885,  122.9270,  140.2440, 1697.2976, 1695.8131, 1692.6660],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5829914.7989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 666 was 95.9%\n",
      "current params: tensor([ 123.9170,  121.6306,  139.1605, 1697.9337, 1696.4520, 1693.3120],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5931633.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 667 was 96.0%\n",
      "current params: tensor([ 122.6436,  120.3315,  138.0798, 1698.5673, 1697.0883, 1693.9556],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6036259.5329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 668 was 96.0%\n",
      "current params: tensor([ 121.3681,  119.0295,  137.0022, 1699.1983, 1697.7220, 1694.5968],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6143911.6255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 669 was 96.1%\n",
      "current params: tensor([ 120.0904,  117.7246,  135.9276, 1699.8269, 1698.3531, 1695.2355],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6254712.7007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 670 was 96.2%\n",
      "current params: tensor([ 118.8106,  116.4167,  134.8564, 1700.4528, 1698.9816, 1695.8717],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6368792.7878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 671 was 96.3%\n",
      "current params: tensor([ 117.5286,  115.1057,  133.7886, 1701.0762, 1699.6074, 1696.5054],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6486288.9696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 672 was 96.4%\n",
      "current params: tensor([ 116.2443,  113.7914,  132.7244, 1701.6969, 1700.2305, 1697.1364],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6607345.8640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 673 was 96.5%\n",
      "current params: tensor([ 114.9576,  112.4738,  131.6638, 1702.3149, 1700.8508, 1697.7649],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6732116.1514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 674 was 96.6%\n",
      "current params: tensor([ 113.6684,  111.1528,  130.6072, 1702.9301, 1701.4683, 1698.3907],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6860761.1427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 675 was 96.6%\n",
      "current params: tensor([ 112.3768,  109.8282,  129.5547, 1703.5426, 1702.0830, 1699.0139],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(6993451.3991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 676 was 96.7%\n",
      "current params: tensor([ 111.0826,  108.5000,  128.5064, 1704.1522, 1702.6948, 1699.6343],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(7130367.4048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 677 was 96.8%\n",
      "current params: tensor([ 109.7858,  107.1680,  127.4626, 1704.7590, 1703.3037, 1700.2519],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(7271700.3051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 678 was 96.9%\n",
      "current params: tensor([ 108.4863,  105.8320,  126.4234, 1705.3628, 1703.9096, 1700.8668],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(7417652.7074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 679 was 97.0%\n",
      "current params: tensor([ 107.1839,  104.4920,  125.3891, 1705.9637, 1704.5125, 1701.4788],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(7568439.5602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 680 was 97.1%\n",
      "current params: tensor([ 105.8787,  103.1479,  124.3599, 1706.5616, 1705.1124, 1702.0879],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(7724289.1125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 681 was 97.2%\n",
      "current params: tensor([ 104.5705,  101.7993,  123.3361, 1707.1563, 1705.7091, 1702.6941],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(7885443.9728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 682 was 97.3%\n",
      "current params: tensor([ 103.2592,  100.4463,  122.3179, 1707.7480, 1706.3027, 1703.2973],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8052162.2656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 683 was 97.4%\n",
      "current params: tensor([ 101.9448,   99.0886,  121.3055, 1708.3365, 1706.8931, 1703.8975],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8224718.9094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 684 was 97.4%\n",
      "current params: tensor([ 100.6272,   97.7261,  120.2992, 1708.9217, 1707.4803, 1704.4945],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8403407.0223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 685 was 97.5%\n",
      "current params: tensor([  99.3061,   96.3585,  119.2994, 1709.5037, 1708.0641, 1705.0885],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8588539.4803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 686 was 97.6%\n",
      "current params: tensor([  97.9817,   94.9857,  118.3063, 1710.0823, 1708.6446, 1705.6792],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8780450.6382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 687 was 97.7%\n",
      "current params: tensor([  96.6536,   93.6075,  117.3203, 1710.6575, 1709.2216, 1706.2667],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8979498.2373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 688 was 97.8%\n",
      "current params: tensor([  95.3219,   92.2237,  116.3417, 1711.2292, 1709.7952, 1706.8510],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(9186065.5329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 689 was 97.9%\n",
      "current params: tensor([  93.9864,   90.8340,  115.3709, 1711.7974, 1710.3652, 1707.4318],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(9400563.6582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 690 was 98.0%\n",
      "current params: tensor([  92.6470,   89.4382,  114.4083, 1712.3619, 1710.9316, 1708.0092],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(9623434.2632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 691 was 98.1%\n",
      "current params: tensor([  91.3035,   88.0360,  113.4542, 1712.9228, 1711.4944, 1708.5831],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(9855152.4761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 692 was 98.2%\n",
      "current params: tensor([  89.9558,   86.6273,  112.5092, 1713.4799, 1712.0534, 1709.1535],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10096230.2140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 693 was 98.3%\n",
      "current params: tensor([  88.6039,   85.2116,  111.5736, 1714.0331, 1712.6086, 1709.7202],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10347219.9186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 694 was 98.4%\n",
      "current params: tensor([  87.2474,   83.7887,  110.6479, 1714.5825, 1713.1599, 1710.2832],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10608718.7606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 695 was 98.5%\n",
      "current params: tensor([  85.8864,   82.3584,  109.7327, 1715.1278, 1713.7072, 1710.8424],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10881373.3947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 696 was 98.6%\n",
      "current params: tensor([  84.5207,   80.9201,  108.8284, 1715.6690, 1714.2505, 1711.3978],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(11165885.3589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 697 was 98.7%\n",
      "current params: tensor([  83.1500,   79.4737,  107.9357, 1716.2061, 1714.7897, 1711.9491],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(11463017.2038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 698 was 98.8%\n",
      "current params: tensor([  81.7743,   78.0187,  107.0551, 1716.7388, 1715.3246, 1712.4964],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(11773599.4971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 699 was 98.9%\n",
      "current params: tensor([  80.3933,   76.5547,  106.1873, 1717.2672, 1715.8553, 1713.0396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(12098538.8285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 700 was 99.0%\n",
      "current params: tensor([  79.0070,   75.0813,  105.3328, 1717.7911, 1716.3815, 1713.5785],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(12438827.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 701 was 99.1%\n",
      "current params: tensor([  77.6151,   73.5981,  104.4925, 1718.3104, 1716.9033, 1714.1130],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(12795551.6670, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 702 was 99.2%\n",
      "current params: tensor([  76.2174,   72.1045,  103.6670, 1718.8250, 1717.4204, 1714.6431],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(13169908.5017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 703 was 99.3%\n",
      "current params: tensor([  74.8139,   70.6000,  102.8571, 1719.3347, 1717.9329, 1715.1685],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(13563215.5012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 704 was 99.4%\n",
      "current params: tensor([  73.4043,   69.0842,  102.0637, 1719.8394, 1718.4405, 1715.6892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(13976929.5175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 705 was 99.5%\n",
      "current params: tensor([  71.9884,   67.5563,  101.2875, 1720.3391, 1718.9432, 1716.2050],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(14412665.6490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 706 was 99.6%\n",
      "current params: tensor([  70.5661,   66.0158,  100.5295, 1720.8335, 1719.4409, 1716.7157],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(14872220.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 707 was 99.7%\n",
      "current params: tensor([  69.1373,   64.4620,   99.7905, 1721.3225, 1719.9333, 1717.2213],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(15357596.6848, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 708 was 99.8%\n",
      "current params: tensor([  67.7017,   62.8942,   99.0717, 1721.8059, 1720.4204, 1717.7215],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(15871039.4834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 709 was 99.9%\n",
      "current params: tensor([  66.2592,   61.3115,   98.3739, 1722.2836, 1720.9020, 1718.2162],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 710 was 93.4%\n",
      "current params: tensor([  64.8096,   59.7132,   97.6984, 1722.7554, 1721.3779, 1718.7051],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 711 was 93.5%\n",
      "current params: tensor([  63.3530,   58.0984,   97.0461, 1723.2210, 1721.8481, 1719.1880],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 712 was 93.6%\n",
      "current params: tensor([  61.8891,   56.4660,   96.4182, 1723.6803, 1722.3122, 1719.6647],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 713 was 93.8%\n",
      "current params: tensor([  60.4180,   54.8150,   95.8160, 1724.1331, 1722.7702, 1720.1350],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 714 was 93.9%\n",
      "current params: tensor([  58.9397,   53.1442,   95.2406, 1724.5790, 1723.2218, 1720.5985],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 715 was 94.0%\n",
      "current params: tensor([  57.4541,   51.4524,   94.6933, 1725.0179, 1723.6669, 1721.0550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 716 was 94.1%\n",
      "current params: tensor([  55.9615,   49.7383,   94.1754, 1725.4494, 1724.1051, 1721.5042],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 717 was 94.3%\n",
      "current params: tensor([  54.4620,   48.0003,   93.6881, 1725.8733, 1724.5363, 1721.9457],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 718 was 94.4%\n",
      "current params: tensor([  52.9561,   46.2367,   93.2327, 1726.2893, 1724.9601, 1722.3791],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 719 was 94.5%\n",
      "current params: tensor([  51.4440,   44.4458,   92.8104, 1726.6968, 1725.3764, 1722.8040],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 720 was 94.7%\n",
      "current params: tensor([  49.9267,   42.6255,   92.4226, 1727.0957, 1725.7848, 1723.2200],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 721 was 94.8%\n",
      "current params: tensor([  48.4048,   40.7734,   92.0704, 1727.4854, 1726.1850, 1723.6265],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 722 was 95.0%\n",
      "current params: tensor([  46.8796,   38.8871,   91.7549, 1727.8655, 1726.5766, 1724.0231],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 723 was 95.1%\n",
      "current params: tensor([  45.3527,   36.9635,   91.4770, 1728.2354, 1726.9593, 1724.4090],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 724 was 95.3%\n",
      "current params: tensor([  43.8259,   34.9992,   91.2377, 1728.5945, 1727.3326, 1724.7837],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 725 was 95.5%\n",
      "current params: tensor([  42.3018,   32.9903,   91.0376, 1728.9423, 1727.6962, 1725.1464],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 726 was 95.6%\n",
      "current params: tensor([  40.7837,   30.9320,   90.8771, 1729.2780, 1728.0495, 1725.4964],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 727 was 95.8%\n",
      "current params: tensor([  39.2758,   28.8188,   90.7564, 1729.6007, 1728.3919, 1725.8328],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 728 was 96.0%\n",
      "current params: tensor([  37.7835,   26.6437,   90.6753, 1729.9095, 1728.7229, 1726.1545],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 729 was 96.2%\n",
      "current params: tensor([  36.3139,   24.3980,   90.6331, 1730.2033, 1729.0418, 1726.4605],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 730 was 96.4%\n",
      "current params: tensor([  34.8761,   22.0706,   90.6288, 1730.4808, 1729.3477, 1726.7495],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 731 was 96.6%\n",
      "current params: tensor([  33.4819,   19.6471,   90.6605, 1730.7403, 1729.6396, 1727.0202],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 732 was 96.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  32.1474,   17.1077,   90.7256, 1730.9799, 1729.9162, 1727.2707],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 733 was 97.1%\n",
      "current params: tensor([  30.8937,   14.4244,   90.8206, 1731.1969, 1730.1759, 1727.4991],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 734 was 97.4%\n",
      "current params: tensor([  29.7497,   11.5560,   90.9403, 1731.3880, 1730.4162, 1727.7028],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 735 was 97.8%\n",
      "current params: tensor([  28.7552,    8.4374,   91.0771, 1731.5484, 1730.6329, 1727.8780],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 736 was 98.2%\n",
      "current params: tensor([  27.9665,   18.4374,   91.2181, 1731.6715, 1730.8189, 1728.0189],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 737 was 97.2%\n",
      "current params: tensor([  26.4095,   18.4366,   91.3350, 1731.8995, 1731.0743, 1728.2455],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 738 was 97.2%\n",
      "current params: tensor([  24.7653,   18.4358,   91.4624, 1732.1262, 1731.3238, 1728.4666],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 739 was 97.3%\n",
      "current params: tensor([  23.0231,   18.4351,   91.6004, 1732.3511, 1731.5663, 1728.6812],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 740 was 97.4%\n",
      "current params: tensor([  21.1694,   18.4344,   91.7487, 1732.5736, 1731.8008, 1728.8886],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 741 was 97.5%\n",
      "current params: tensor([  19.1871,   18.4337,   91.9070, 1732.7931, 1732.0256, 1729.0873],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 742 was 97.6%\n",
      "current params: tensor([  17.0542,   18.4331,   92.0743, 1733.0085, 1732.2387, 1729.2761],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 743 was 97.7%\n",
      "current params: tensor([  14.7378,   18.4325,   92.2495, 1733.2107, 1732.4455, 1729.4530],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 744 was 97.9%\n",
      "current params: tensor([  12.1984,   18.4319,   92.4302, 1733.4055, 1732.6344, 1729.6157],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 745 was 98.1%\n",
      "current params: tensor([   9.3720,   18.4315,   92.6125, 1733.5898, 1732.8005, 1729.7608],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 746 was 98.4%\n",
      "current params: tensor([  19.3720,   18.4311,   92.7885, 1733.7580, 1732.9368, 1729.8835],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 747 was 97.6%\n",
      "current params: tensor([  19.3714,   18.4304,   92.9613, 1733.9788, 1733.1561, 1730.0772],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 748 was 97.6%\n",
      "current params: tensor([  19.3708,   18.4297,   93.1353, 1734.2006, 1733.3763, 1730.2717],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 749 was 97.6%\n",
      "current params: tensor([  19.3702,   18.4291,   93.3105, 1734.4233, 1733.5974, 1730.4670],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 750 was 97.6%\n",
      "current params: tensor([  19.3696,   18.4284,   93.4870, 1734.6471, 1733.8196, 1730.6631],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 751 was 97.6%\n",
      "current params: tensor([  19.3690,   18.4277,   93.6647, 1734.8718, 1734.0427, 1730.8599],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 752 was 97.6%\n",
      "current params: tensor([  19.3684,   18.4270,   93.8437, 1735.0974, 1734.2667, 1731.0575],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 753 was 97.6%\n",
      "current params: tensor([  19.3678,   18.4264,   94.0240, 1735.3241, 1734.4918, 1731.2559],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 754 was 97.6%\n",
      "current params: tensor([  19.3672,   18.4257,   94.2055, 1735.5518, 1734.7178, 1731.4551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 755 was 97.6%\n",
      "current params: tensor([  19.3666,   18.4250,   94.3883, 1735.7804, 1734.9448, 1731.6551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 756 was 97.6%\n",
      "current params: tensor([  19.3660,   18.4243,   94.5723, 1736.0101, 1735.1728, 1731.8559],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 757 was 97.6%\n",
      "current params: tensor([  19.3654,   18.4236,   94.7577, 1736.2407, 1735.4017, 1732.0574],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 758 was 97.6%\n",
      "current params: tensor([  19.3648,   18.4229,   94.9443, 1736.4724, 1735.6317, 1732.2598],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 759 was 97.6%\n",
      "current params: tensor([  19.3642,   18.4222,   95.1323, 1736.7050, 1735.8626, 1732.4630],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 760 was 97.6%\n",
      "current params: tensor([  19.3635,   18.4215,   95.3215, 1736.9387, 1736.0946, 1732.6669],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 761 was 97.6%\n",
      "current params: tensor([  19.3629,   18.4208,   95.5121, 1737.1734, 1736.3275, 1732.8716],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 762 was 97.6%\n",
      "current params: tensor([  19.3623,   18.4201,   95.7039, 1737.4091, 1736.5615, 1733.0772],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 763 was 97.6%\n",
      "current params: tensor([  19.3617,   18.4193,   95.8971, 1737.6458, 1736.7964, 1733.2835],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 764 was 97.6%\n",
      "current params: tensor([  19.3610,   18.4186,   96.0916, 1737.8835, 1737.0324, 1733.4907],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 765 was 97.6%\n",
      "current params: tensor([  19.3604,   18.4179,   96.2875, 1738.1223, 1737.2693, 1733.6986],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 766 was 97.6%\n",
      "current params: tensor([  19.3597,   18.4172,   96.4847, 1738.3621, 1737.5073, 1733.9074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 767 was 97.6%\n",
      "current params: tensor([  19.3591,   18.4164,   96.6832, 1738.6029, 1737.7463, 1734.1169],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 768 was 97.6%\n",
      "current params: tensor([  19.3584,   18.4157,   96.8831, 1738.8448, 1737.9863, 1734.3273],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 769 was 97.6%\n",
      "current params: tensor([  19.3578,   18.4149,   97.0843, 1739.0876, 1738.2273, 1734.5385],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 770 was 97.6%\n",
      "current params: tensor([  19.3571,   18.4142,   97.2869, 1739.3316, 1738.4694, 1734.7505],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 771 was 97.6%\n",
      "current params: tensor([  19.3565,   18.4135,   97.4909, 1739.5766, 1738.7125, 1734.9633],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 772 was 97.6%\n",
      "current params: tensor([  19.3558,   18.4127,   97.6963, 1739.8226, 1738.9566, 1735.1769],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 773 was 97.6%\n",
      "current params: tensor([  19.3552,   18.4119,   97.9030, 1740.0697, 1739.2018, 1735.3913],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 774 was 97.6%\n",
      "current params: tensor([  19.3545,   18.4112,   98.1111, 1740.3178, 1739.4480, 1735.6066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 775 was 97.6%\n",
      "current params: tensor([  19.3538,   18.4104,   98.3206, 1740.5670, 1739.6952, 1735.8226],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 776 was 97.6%\n",
      "current params: tensor([  19.3532,   18.4097,   98.5315, 1740.8172, 1739.9435, 1736.0395],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 777 was 97.6%\n",
      "current params: tensor([  19.3525,   18.4089,   98.7438, 1741.0685, 1740.1928, 1736.2572],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 778 was 97.6%\n",
      "current params: tensor([  19.3518,   18.4081,   98.9576, 1741.3209, 1740.4432, 1736.4757],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 779 was 97.6%\n",
      "current params: tensor([  19.3511,   18.4073,   99.1727, 1741.5743, 1740.6946, 1736.6951],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 780 was 97.6%\n",
      "current params: tensor([  19.3504,   18.4065,   99.3892, 1741.8288, 1740.9471, 1736.9153],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 781 was 97.6%\n",
      "current params: tensor([  19.3497,   18.4058,   99.6072, 1742.0844, 1741.2006, 1737.1363],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 782 was 97.6%\n",
      "current params: tensor([  19.3490,   18.4050,   99.8266, 1742.3411, 1741.4552, 1737.3581],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 783 was 97.6%\n",
      "current params: tensor([  19.3483,   18.4042,  100.0474, 1742.5988, 1741.7109, 1737.5808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 784 was 97.6%\n",
      "current params: tensor([  19.3476,   18.4034,  100.2697, 1742.8577, 1741.9676, 1737.8043],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 785 was 97.6%\n",
      "current params: tensor([  19.3469,   18.4026,  100.4934, 1743.1176, 1742.2254, 1738.0286],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 786 was 97.6%\n",
      "current params: tensor([  19.3462,   18.4018,  100.7186, 1743.3786, 1742.4843, 1738.2538],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 787 was 97.6%\n",
      "current params: tensor([  19.3455,   18.4010,  100.9452, 1743.6407, 1742.7442, 1738.4797],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 788 was 97.6%\n",
      "current params: tensor([  19.3448,   18.4001,  101.1733, 1743.9039, 1743.0053, 1738.7066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 789 was 97.6%\n",
      "current params: tensor([  19.3441,   18.3993,  101.4029, 1744.1682, 1743.2674, 1738.9342],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 790 was 97.6%\n",
      "current params: tensor([  19.3434,   18.3985,  101.6339, 1744.4336, 1743.5306, 1739.1627],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 791 was 97.6%\n",
      "current params: tensor([  19.3426,   18.3977,  101.8664, 1744.7001, 1743.7949, 1739.3921],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 792 was 97.6%\n",
      "current params: tensor([  19.3419,   18.3968,  102.1004, 1744.9677, 1744.0602, 1739.6223],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 793 was 97.6%\n",
      "current params: tensor([  19.3412,   18.3960,  102.3358, 1745.2364, 1744.3267, 1739.8533],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 794 was 97.6%\n",
      "current params: tensor([  19.3404,   18.3952,  102.5728, 1745.5062, 1744.5942, 1740.0851],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 795 was 97.6%\n",
      "current params: tensor([  19.3397,   18.3943,  102.8112, 1745.7772, 1744.8629, 1740.3178],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 796 was 97.6%\n",
      "current params: tensor([  19.3389,   18.3935,  103.0512, 1746.0492, 1745.1326, 1740.5514],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 797 was 97.6%\n",
      "current params: tensor([  19.3382,   18.3926,  103.2926, 1746.3224, 1745.4035, 1740.7858],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 798 was 97.6%\n",
      "current params: tensor([  19.3374,   18.3918,  103.5355, 1746.5967, 1745.6755, 1741.0210],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 799 was 97.6%\n",
      "current params: tensor([  19.3367,   18.3909,  103.7800, 1746.8722, 1745.9485, 1741.2571],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 800 was 97.6%\n",
      "current params: tensor([  19.3359,   18.3900,  104.0260, 1747.1488, 1746.2227, 1741.4941],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 801 was 97.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.3352,   18.3892,  104.2735, 1747.4265, 1746.4980, 1741.7319],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 802 was 97.7%\n",
      "current params: tensor([  19.3344,   18.3883,  104.5225, 1747.7053, 1746.7744, 1741.9705],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 803 was 97.7%\n",
      "current params: tensor([  19.3336,   18.3874,  104.7730, 1747.9853, 1747.0520, 1742.2100],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 804 was 97.7%\n",
      "current params: tensor([  19.3329,   18.3865,  105.0251, 1748.2664, 1747.3306, 1742.4504],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 805 was 97.7%\n",
      "current params: tensor([  19.3321,   18.3856,  105.2787, 1748.5487, 1747.6104, 1742.6916],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 806 was 97.7%\n",
      "current params: tensor([  19.3313,   18.3848,  105.5339, 1748.8321, 1747.8913, 1742.9336],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 807 was 97.7%\n",
      "current params: tensor([  19.3305,   18.3839,  105.7906, 1749.1167, 1748.1734, 1743.1765],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 808 was 97.7%\n",
      "current params: tensor([  19.3297,   18.3830,  106.0488, 1749.4024, 1748.4565, 1743.4203],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 809 was 97.7%\n",
      "current params: tensor([  19.3289,   18.3821,  106.3086, 1749.6893, 1748.7409, 1743.6649],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 810 was 97.7%\n",
      "current params: tensor([  19.3281,   18.3811,  106.5699, 1749.9774, 1749.0263, 1743.9104],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 811 was 97.7%\n",
      "current params: tensor([  19.3273,   18.3802,  106.8328, 1750.2666, 1749.3129, 1744.1567],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 812 was 97.7%\n",
      "current params: tensor([  19.3265,   18.3793,  107.0973, 1750.5569, 1749.6006, 1744.4039],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 813 was 97.7%\n",
      "current params: tensor([  19.3257,   18.3784,  107.3633, 1750.8485, 1749.8895, 1744.6520],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 814 was 97.7%\n",
      "current params: tensor([  19.3249,   18.3775,  107.6309, 1751.1412, 1750.1795, 1744.9009],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 815 was 97.7%\n",
      "current params: tensor([  19.3241,   18.3765,  107.9001, 1751.4350, 1750.4707, 1745.1507],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 816 was 97.7%\n",
      "current params: tensor([  19.3232,   18.3756,  108.1708, 1751.7301, 1750.7630, 1745.4014],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 817 was 97.7%\n",
      "current params: tensor([  19.3224,   18.3747,  108.4431, 1752.0263, 1751.0565, 1745.6529],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 818 was 97.7%\n",
      "current params: tensor([  19.3216,   18.3737,  108.7170, 1752.3237, 1751.3511, 1745.9052],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 819 was 97.7%\n",
      "current params: tensor([  19.3208,   18.3728,  108.9925, 1752.6223, 1751.6469, 1746.1585],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 820 was 97.7%\n",
      "current params: tensor([  19.3199,   18.3718,  109.2695, 1752.9221, 1751.9439, 1746.4126],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 821 was 97.7%\n",
      "current params: tensor([  19.3191,   18.3708,  109.5482, 1753.2231, 1752.2420, 1746.6676],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 822 was 97.7%\n",
      "current params: tensor([  19.3182,   18.3699,  109.8284, 1753.5252, 1752.5413, 1746.9234],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 823 was 97.7%\n",
      "current params: tensor([  19.3174,   18.3689,  110.1102, 1753.8286, 1752.8418, 1747.1801],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 824 was 97.7%\n",
      "current params: tensor([  19.3165,   18.3679,  110.3937, 1754.1331, 1753.1434, 1747.4377],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 825 was 97.7%\n",
      "current params: tensor([  19.3157,   18.3669,  110.6787, 1754.4389, 1753.4462, 1747.6962],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 826 was 97.7%\n",
      "current params: tensor([  19.3148,   18.3660,  110.9653, 1754.7458, 1753.7502, 1747.9555],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 827 was 97.7%\n",
      "current params: tensor([  19.3139,   18.3650,  111.2535, 1755.0540, 1754.0554, 1748.2157],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 828 was 97.7%\n",
      "current params: tensor([  19.3131,   18.3640,  111.5433, 1755.3633, 1754.3617, 1748.4767],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 829 was 97.7%\n",
      "current params: tensor([  19.3122,   18.3630,  111.8348, 1755.6739, 1754.6693, 1748.7387],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 830 was 97.7%\n",
      "current params: tensor([  19.3113,   18.3620,  112.1278, 1755.9856, 1754.9780, 1749.0015],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 831 was 97.7%\n",
      "current params: tensor([  19.3104,   18.3610,  112.4225, 1756.2986, 1755.2879, 1749.2651],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 832 was 97.7%\n",
      "current params: tensor([  19.3095,   18.3600,  112.7187, 1756.6128, 1755.5990, 1749.5297],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 833 was 97.7%\n",
      "current params: tensor([  19.3086,   18.3589,  113.0166, 1756.9283, 1755.9113, 1749.7951],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 834 was 97.7%\n",
      "current params: tensor([  19.3077,   18.3579,  113.3161, 1757.2449, 1756.2248, 1750.0614],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 835 was 97.7%\n",
      "current params: tensor([  19.3068,   18.3569,  113.6172, 1757.5628, 1756.5394, 1750.3286],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 836 was 97.7%\n",
      "current params: tensor([  19.3059,   18.3559,  113.9199, 1757.8818, 1756.8553, 1750.5966],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 837 was 97.7%\n",
      "current params: tensor([  19.3050,   18.3548,  114.2242, 1758.2021, 1757.1724, 1750.8656],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 838 was 97.7%\n",
      "current params: tensor([  19.3041,   18.3538,  114.5302, 1758.5237, 1757.4907, 1751.1354],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 839 was 97.7%\n",
      "current params: tensor([  19.3032,   18.3527,  114.8378, 1758.8465, 1757.8102, 1751.4060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 840 was 97.7%\n",
      "current params: tensor([  19.3022,   18.3517,  115.1470, 1759.1705, 1758.1309, 1751.6776],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 841 was 97.7%\n",
      "current params: tensor([  19.3013,   18.3506,  115.4578, 1759.4957, 1758.4528, 1751.9500],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 842 was 97.7%\n",
      "current params: tensor([  19.3004,   18.3495,  115.7702, 1759.8222, 1758.7759, 1752.2233],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 843 was 97.7%\n",
      "current params: tensor([  19.2994,   18.3485,  116.0843, 1760.1499, 1759.1002, 1752.4975],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 844 was 97.7%\n",
      "current params: tensor([  19.2985,   18.3474,  116.4000, 1760.4789, 1759.4257, 1752.7726],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 845 was 97.7%\n",
      "current params: tensor([  19.2976,   18.3463,  116.7173, 1760.8091, 1759.7525, 1753.0485],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 846 was 97.7%\n",
      "current params: tensor([  19.2966,   18.3452,  117.0363, 1761.1405, 1760.0805, 1753.3253],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 847 was 97.7%\n",
      "current params: tensor([  19.2956,   18.3441,  117.3569, 1761.4732, 1760.4097, 1753.6030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 848 was 97.7%\n",
      "current params: tensor([  19.2947,   18.3430,  117.6791, 1761.8072, 1760.7401, 1753.8816],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 849 was 97.7%\n",
      "current params: tensor([  19.2937,   18.3419,  118.0029, 1762.1424, 1761.0717, 1754.1611],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 850 was 97.7%\n",
      "current params: tensor([  19.2927,   18.3408,  118.3284, 1762.4788, 1761.4046, 1754.4414],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 851 was 97.7%\n",
      "current params: tensor([  19.2918,   18.3397,  118.6555, 1762.8166, 1761.7387, 1754.7226],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 852 was 97.7%\n",
      "current params: tensor([  19.2908,   18.3386,  118.9842, 1763.1555, 1762.0740, 1755.0047],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 853 was 97.7%\n",
      "current params: tensor([  19.2898,   18.3375,  119.3146, 1763.4958, 1762.4106, 1755.2877],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 854 was 97.7%\n",
      "current params: tensor([  19.2888,   18.3364,  119.6465, 1763.8373, 1762.7484, 1755.5716],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 855 was 97.7%\n",
      "current params: tensor([  19.2878,   18.3352,  119.9801, 1764.1800, 1763.0874, 1755.8563],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 856 was 97.7%\n",
      "current params: tensor([  19.2868,   18.3341,  120.3154, 1764.5241, 1763.4277, 1756.1419],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 857 was 97.7%\n",
      "current params: tensor([  19.2858,   18.3329,  120.6522, 1764.8694, 1763.7692, 1756.4284],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 858 was 97.7%\n",
      "current params: tensor([  19.2848,   18.3318,  120.9907, 1765.2159, 1764.1119, 1756.7158],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 859 was 97.7%\n",
      "current params: tensor([  19.2838,   18.3306,  121.3308, 1765.5638, 1764.4559, 1757.0041],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 860 was 97.7%\n",
      "current params: tensor([  19.2828,   18.3295,  121.6726, 1765.9129, 1764.8012, 1757.2932],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 861 was 97.7%\n",
      "current params: tensor([  19.2817,   18.3283,  122.0159, 1766.2633, 1765.1476, 1757.5833],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 862 was 97.7%\n",
      "current params: tensor([  19.2807,   18.3271,  122.3609, 1766.6149, 1765.4954, 1757.8742],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 863 was 97.7%\n",
      "current params: tensor([  19.2797,   18.3260,  122.7076, 1766.9679, 1765.8443, 1758.1660],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 864 was 97.7%\n",
      "current params: tensor([  19.2786,   18.3248,  123.0558, 1767.3221, 1766.1946, 1758.4586],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 865 was 97.7%\n",
      "current params: tensor([  19.2776,   18.3236,  123.4056, 1767.6776, 1766.5460, 1758.7522],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 866 was 97.7%\n",
      "current params: tensor([  19.2765,   18.3224,  123.7571, 1768.0344, 1766.8987, 1759.0466],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 867 was 97.7%\n",
      "current params: tensor([  19.2755,   18.3212,  124.1102, 1768.3925, 1767.2527, 1759.3419],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 868 was 97.7%\n",
      "current params: tensor([  19.2744,   18.3200,  124.4649, 1768.7518, 1767.6080, 1759.6381],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 869 was 97.7%\n",
      "current params: tensor([  19.2734,   18.3188,  124.8213, 1769.1125, 1767.9644, 1759.9352],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 870 was 97.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.2723,   18.3175,  125.1792, 1769.4744, 1768.3222, 1760.2332],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 871 was 97.7%\n",
      "current params: tensor([  19.2712,   18.3163,  125.5388, 1769.8376, 1768.6812, 1760.5320],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 872 was 97.7%\n",
      "current params: tensor([  19.2701,   18.3151,  125.8999, 1770.2022, 1769.0415, 1760.8318],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 873 was 97.7%\n",
      "current params: tensor([  19.2691,   18.3139,  126.2627, 1770.5680, 1769.4030, 1761.1324],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 874 was 97.7%\n",
      "current params: tensor([  19.2680,   18.3126,  126.6271, 1770.9351, 1769.7658, 1761.4338],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 875 was 97.7%\n",
      "current params: tensor([  19.2669,   18.3114,  126.9931, 1771.3035, 1770.1298, 1761.7362],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 876 was 97.7%\n",
      "current params: tensor([  19.2658,   18.3101,  127.3607, 1771.6732, 1770.4952, 1762.0395],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 877 was 97.7%\n",
      "current params: tensor([  19.2647,   18.3088,  127.7299, 1772.0442, 1770.8617, 1762.3436],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 878 was 97.7%\n",
      "current params: tensor([  19.2635,   18.3076,  128.1007, 1772.4165, 1771.2296, 1762.6486],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 879 was 97.7%\n",
      "current params: tensor([  19.2624,   18.3063,  128.4731, 1772.7902, 1771.5987, 1762.9545],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 880 was 97.8%\n",
      "current params: tensor([  19.2613,   18.3050,  128.8471, 1773.1651, 1771.9691, 1763.2613],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 881 was 97.8%\n",
      "current params: tensor([  19.2602,   18.3037,  129.2227, 1773.5413, 1772.3408, 1763.5689],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 882 was 97.8%\n",
      "current params: tensor([  19.2591,   18.3025,  129.5999, 1773.9188, 1772.7137, 1763.8775],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 883 was 97.8%\n",
      "current params: tensor([  19.2579,   18.3012,  129.9786, 1774.2977, 1773.0879, 1764.1869],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 884 was 97.8%\n",
      "current params: tensor([  19.2568,   18.2999,  130.3590, 1774.6778, 1773.4634, 1764.4972],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 885 was 97.8%\n",
      "current params: tensor([  19.2556,   18.2985,  130.7409, 1775.0593, 1773.8402, 1764.8083],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 886 was 97.8%\n",
      "current params: tensor([  19.2545,   18.2972,  131.1244, 1775.4420, 1774.2182, 1765.1204],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 887 was 97.8%\n",
      "current params: tensor([  19.2533,   18.2959,  131.5095, 1775.8261, 1774.5976, 1765.4333],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 888 was 97.8%\n",
      "current params: tensor([  19.2521,   18.2946,  131.8962, 1776.2115, 1774.9782, 1765.7471],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 889 was 97.8%\n",
      "current params: tensor([  19.2510,   18.2932,  132.2844, 1776.5982, 1775.3600, 1766.0618],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 890 was 97.8%\n",
      "current params: tensor([  19.2498,   18.2919,  132.6742, 1776.9863, 1775.7432, 1766.3774],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 891 was 97.8%\n",
      "current params: tensor([  19.2486,   18.2906,  133.0656, 1777.3756, 1776.1276, 1766.6938],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 892 was 97.8%\n",
      "current params: tensor([  19.2474,   18.2892,  133.4586, 1777.7663, 1776.5133, 1767.0111],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 893 was 97.8%\n",
      "current params: tensor([  19.2462,   18.2878,  133.8531, 1778.1582, 1776.9003, 1767.3293],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 894 was 97.8%\n",
      "current params: tensor([  19.2450,   18.2865,  134.2491, 1778.5515, 1777.2886, 1767.6484],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 895 was 97.8%\n",
      "current params: tensor([  19.2438,   18.2851,  134.6467, 1778.9462, 1777.6782, 1767.9684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 896 was 97.8%\n",
      "current params: tensor([  19.2426,   18.2837,  135.0459, 1779.3421, 1778.0690, 1768.2892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 897 was 97.8%\n",
      "current params: tensor([  19.2414,   18.2823,  135.4466, 1779.7394, 1778.4612, 1768.6109],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 898 was 97.8%\n",
      "current params: tensor([  19.2402,   18.2809,  135.8489, 1780.1380, 1778.8546, 1768.9335],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 899 was 97.8%\n",
      "current params: tensor([  19.2390,   18.2795,  136.2526, 1780.5379, 1779.2493, 1769.2569],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 900 was 97.8%\n",
      "current params: tensor([  19.2377,   18.2781,  136.6580, 1780.9391, 1779.6453, 1769.5813],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 901 was 97.8%\n",
      "current params: tensor([  19.2365,   18.2767,  137.0648, 1781.3417, 1780.0426, 1769.9065],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 902 was 97.8%\n",
      "current params: tensor([  19.2352,   18.2753,  137.4732, 1781.7455, 1780.4412, 1770.2326],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 903 was 97.8%\n",
      "current params: tensor([  19.2340,   18.2739,  137.8831, 1782.1507, 1780.8410, 1770.5595],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 904 was 97.8%\n",
      "current params: tensor([  19.2327,   18.2724,  138.2946, 1782.5573, 1781.2422, 1770.8873],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 905 was 97.8%\n",
      "current params: tensor([  19.2315,   18.2710,  138.7075, 1782.9652, 1781.6446, 1771.2160],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 906 was 97.8%\n",
      "current params: tensor([  19.2302,   18.2696,  139.1220, 1783.3743, 1782.0484, 1771.5456],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 907 was 97.8%\n",
      "current params: tensor([  19.2289,   18.2681,  139.5380, 1783.7849, 1782.4534, 1771.8761],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 908 was 97.8%\n",
      "current params: tensor([  19.2277,   18.2667,  139.9554, 1784.1967, 1782.8597, 1772.2074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 909 was 97.8%\n",
      "current params: tensor([  19.2264,   18.2652,  140.3744, 1784.6099, 1783.2673, 1772.5396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 910 was 97.8%\n",
      "current params: tensor([  19.2251,   18.2637,  140.7949, 1785.0244, 1783.6762, 1772.8726],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 911 was 97.8%\n",
      "current params: tensor([  19.2238,   18.2622,  141.2169, 1785.4403, 1784.0864, 1773.2066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 912 was 97.8%\n",
      "current params: tensor([  19.2225,   18.2607,  141.6403, 1785.8574, 1784.4979, 1773.5414],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 913 was 97.8%\n",
      "current params: tensor([  19.2212,   18.2593,  142.0653, 1786.2759, 1784.9107, 1773.8770],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 914 was 97.8%\n",
      "current params: tensor([  19.2198,   18.2577,  142.4917, 1786.6958, 1785.3248, 1774.2136],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 915 was 97.8%\n",
      "current params: tensor([  19.2185,   18.2562,  142.9196, 1787.1169, 1785.7401, 1774.5510],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 916 was 97.8%\n",
      "current params: tensor([  19.2172,   18.2547,  143.3489, 1787.5394, 1786.1568, 1774.8893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 917 was 97.8%\n",
      "current params: tensor([  19.2159,   18.2532,  143.7798, 1787.9633, 1786.5747, 1775.2284],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 918 was 97.8%\n",
      "current params: tensor([  19.2145,   18.2517,  144.2121, 1788.3885, 1786.9940, 1775.5684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 919 was 97.8%\n",
      "current params: tensor([  19.2132,   18.2501,  144.6458, 1788.8150, 1787.4145, 1775.9093],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 920 was 97.8%\n",
      "current params: tensor([  19.2118,   18.2486,  145.0810, 1789.2428, 1787.8363, 1776.2510],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 921 was 97.8%\n",
      "current params: tensor([  19.2105,   18.2470,  145.5177, 1789.6720, 1788.2595, 1776.5937],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 922 was 97.8%\n",
      "current params: tensor([  19.2091,   18.2455,  145.9558, 1790.1025, 1788.6839, 1776.9371],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 923 was 97.8%\n",
      "current params: tensor([  19.2077,   18.2439,  146.3953, 1790.5343, 1789.1096, 1777.2815],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 924 was 97.8%\n",
      "current params: tensor([  19.2063,   18.2423,  146.8363, 1790.9675, 1789.5366, 1777.6267],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 925 was 97.8%\n",
      "current params: tensor([  19.2050,   18.2408,  147.2787, 1791.4020, 1789.9649, 1777.9727],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 926 was 97.8%\n",
      "current params: tensor([  19.2036,   18.2392,  147.7225, 1791.8378, 1790.3945, 1778.3197],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 927 was 97.8%\n",
      "current params: tensor([  19.2022,   18.2376,  148.1677, 1792.2750, 1790.8254, 1778.6675],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 928 was 97.8%\n",
      "current params: tensor([  19.2008,   18.2360,  148.6144, 1792.7135, 1791.2576, 1779.0161],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 929 was 97.8%\n",
      "current params: tensor([  19.1994,   18.2344,  149.0624, 1793.1533, 1791.6911, 1779.3656],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 930 was 97.8%\n",
      "current params: tensor([  19.1979,   18.2328,  149.5119, 1793.5945, 1792.1258, 1779.7160],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 931 was 97.8%\n",
      "current params: tensor([  19.1965,   18.2311,  149.9628, 1794.0370, 1792.5619, 1780.0672],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 932 was 97.8%\n",
      "current params: tensor([  19.1951,   18.2295,  150.4150, 1794.4809, 1792.9992, 1780.4193],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 933 was 97.8%\n",
      "current params: tensor([  19.1937,   18.2279,  150.8686, 1794.9260, 1793.4379, 1780.7723],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 934 was 97.8%\n",
      "current params: tensor([  19.1922,   18.2262,  151.3237, 1795.3725, 1793.8778, 1781.1261],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 935 was 97.8%\n",
      "current params: tensor([  19.1908,   18.2246,  151.7801, 1795.8204, 1794.3191, 1781.4808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 936 was 97.8%\n",
      "current params: tensor([  19.1893,   18.2229,  152.2379, 1796.2695, 1794.7616, 1781.8363],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 937 was 97.8%\n",
      "current params: tensor([  19.1878,   18.2212,  152.6970, 1796.7201, 1795.2054, 1782.1927],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 938 was 97.8%\n",
      "current params: tensor([  19.1864,   18.2196,  153.1575, 1797.1719, 1795.6505, 1782.5499],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 939 was 97.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.1849,   18.2179,  153.6194, 1797.6251, 1796.0969, 1782.9080],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 940 was 97.8%\n",
      "current params: tensor([  19.1834,   18.2162,  154.0826, 1798.0796, 1796.5446, 1783.2670],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 941 was 97.9%\n",
      "current params: tensor([  19.1819,   18.2145,  154.5471, 1798.5354, 1796.9936, 1783.6268],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 942 was 97.9%\n",
      "current params: tensor([  19.1804,   18.2128,  155.0130, 1798.9925, 1797.4438, 1783.9874],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 943 was 97.9%\n",
      "current params: tensor([  19.1789,   18.2111,  155.4803, 1799.4510, 1797.8954, 1784.3489],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 944 was 97.9%\n",
      "current params: tensor([  19.1774,   18.2093,  155.9488, 1799.9109, 1798.3482, 1784.7113],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 945 was 97.9%\n",
      "current params: tensor([  19.1759,   18.2076,  156.4187, 1800.3720, 1798.8023, 1785.0745],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 946 was 97.9%\n",
      "current params: tensor([  19.1744,   18.2059,  156.8899, 1800.8345, 1799.2578, 1785.4386],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 947 was 97.9%\n",
      "current params: tensor([  19.1729,   18.2041,  157.3625, 1801.2983, 1799.7145, 1785.8035],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 948 was 97.9%\n",
      "current params: tensor([  19.1713,   18.2024,  157.8363, 1801.7634, 1800.1724, 1786.1693],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 949 was 97.9%\n",
      "current params: tensor([  19.1698,   18.2006,  158.3114, 1802.2299, 1800.6317, 1786.5359],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 950 was 97.9%\n",
      "current params: tensor([  19.1682,   18.1988,  158.7878, 1802.6977, 1801.0923, 1786.9033],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 951 was 97.9%\n",
      "current params: tensor([  19.1667,   18.1970,  159.2656, 1803.1668, 1801.5541, 1787.2716],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 952 was 97.9%\n",
      "current params: tensor([  19.1651,   18.1953,  159.7446, 1803.6372, 1802.0172, 1787.6408],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 953 was 97.9%\n",
      "current params: tensor([  19.1635,   18.1935,  160.2248, 1804.1089, 1802.4816, 1788.0108],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 954 was 97.9%\n",
      "current params: tensor([  19.1619,   18.1917,  160.7064, 1804.5820, 1802.9473, 1788.3816],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 955 was 97.9%\n",
      "current params: tensor([  19.1604,   18.1898,  161.1892, 1805.0564, 1803.4143, 1788.7533],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 956 was 97.9%\n",
      "current params: tensor([  19.1588,   18.1880,  161.6733, 1805.5321, 1803.8825, 1789.1258],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 957 was 97.9%\n",
      "current params: tensor([  19.1572,   18.1862,  162.1586, 1806.0092, 1804.3520, 1789.4992],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 958 was 97.9%\n",
      "current params: tensor([  19.1556,   18.1844,  162.6452, 1806.4875, 1804.8228, 1789.8734],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 959 was 97.9%\n",
      "current params: tensor([  19.1539,   18.1825,  163.1331, 1806.9672, 1805.2949, 1790.2485],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 960 was 97.9%\n",
      "current params: tensor([  19.1523,   18.1807,  163.6222, 1807.4482, 1805.7683, 1790.6244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 961 was 97.9%\n",
      "current params: tensor([  19.1507,   18.1788,  164.1125, 1807.9305, 1806.2429, 1791.0011],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 962 was 97.9%\n",
      "current params: tensor([  19.1490,   18.1769,  164.6040, 1808.4142, 1806.7188, 1791.3787],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 963 was 97.9%\n",
      "current params: tensor([  19.1474,   18.1750,  165.0968, 1808.8991, 1807.1960, 1791.7571],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 964 was 97.9%\n",
      "current params: tensor([  19.1458,   18.1732,  165.5908, 1809.3853, 1807.6744, 1792.1364],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 965 was 97.9%\n",
      "current params: tensor([  19.1441,   18.1713,  166.0859, 1809.8729, 1808.1541, 1792.5164],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 966 was 97.9%\n",
      "current params: tensor([  19.1424,   18.1694,  166.5823, 1810.3618, 1808.6351, 1792.8974],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 967 was 97.9%\n",
      "current params: tensor([  19.1408,   18.1674,  167.0799, 1810.8520, 1809.1173, 1793.2791],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 968 was 97.9%\n",
      "current params: tensor([  19.1391,   18.1655,  167.5787, 1811.3435, 1809.6009, 1793.6617],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 969 was 97.9%\n",
      "current params: tensor([  19.1374,   18.1636,  168.0787, 1811.8363, 1810.0856, 1794.0452],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 970 was 97.9%\n",
      "current params: tensor([  19.1357,   18.1617,  168.5798, 1812.3304, 1810.5717, 1794.4294],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 971 was 97.9%\n",
      "current params: tensor([  19.1340,   18.1597,  169.0822, 1812.8258, 1811.0590, 1794.8145],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 972 was 97.9%\n",
      "current params: tensor([  19.1323,   18.1577,  169.5857, 1813.3225, 1811.5476, 1795.2004],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 973 was 97.9%\n",
      "current params: tensor([  19.1305,   18.1558,  170.0903, 1813.8205, 1812.0374, 1795.5872],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 974 was 97.9%\n",
      "current params: tensor([  19.1288,   18.1538,  170.5962, 1814.3198, 1812.5285, 1795.9748],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 975 was 97.9%\n",
      "current params: tensor([  19.1271,   18.1518,  171.1031, 1814.8205, 1813.0209, 1796.3632],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 976 was 97.9%\n",
      "current params: tensor([  19.1253,   18.1498,  171.6113, 1815.3224, 1813.5145, 1796.7525],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 977 was 97.9%\n",
      "current params: tensor([  19.1236,   18.1478,  172.1205, 1815.8256, 1814.0093, 1797.1425],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 978 was 97.9%\n",
      "current params: tensor([  19.1218,   18.1458,  172.6309, 1816.3301, 1814.5055, 1797.5334],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 979 was 97.9%\n",
      "current params: tensor([  19.1201,   18.1438,  173.1424, 1816.8359, 1815.0028, 1797.9252],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 980 was 97.9%\n",
      "current params: tensor([  19.1183,   18.1418,  173.6551, 1817.3430, 1815.5015, 1798.3177],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 981 was 97.9%\n",
      "current params: tensor([  19.1165,   18.1397,  174.1689, 1817.8514, 1816.0014, 1798.7111],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 982 was 97.9%\n",
      "current params: tensor([  19.1147,   18.1377,  174.6837, 1818.3611, 1816.5025, 1799.1053],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 983 was 97.9%\n",
      "current params: tensor([  19.1129,   18.1356,  175.1997, 1818.8720, 1817.0049, 1799.5003],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 984 was 97.9%\n",
      "current params: tensor([  19.1111,   18.1336,  175.7168, 1819.3843, 1817.5085, 1799.8961],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 985 was 97.9%\n",
      "current params: tensor([  19.1093,   18.1315,  176.2350, 1819.8978, 1818.0133, 1800.2928],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 986 was 97.9%\n",
      "current params: tensor([  19.1075,   18.1294,  176.7542, 1820.4126, 1818.5194, 1800.6903],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 987 was 97.9%\n",
      "current params: tensor([  19.1057,   18.1273,  177.2746, 1820.9287, 1819.0268, 1801.0886],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 988 was 97.9%\n",
      "current params: tensor([  19.1038,   18.1252,  177.7960, 1821.4461, 1819.5354, 1801.4877],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 989 was 97.9%\n",
      "current params: tensor([  19.1020,   18.1231,  178.3185, 1821.9648, 1820.0452, 1801.8877],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 990 was 97.9%\n",
      "current params: tensor([  19.1001,   18.1210,  178.8420, 1822.4847, 1820.5563, 1802.2884],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 991 was 97.9%\n",
      "current params: tensor([  19.0983,   18.1189,  179.3667, 1823.0059, 1821.0686, 1802.6900],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 992 was 97.9%\n",
      "current params: tensor([  19.0964,   18.1167,  179.8923, 1823.5284, 1821.5821, 1803.0924],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 993 was 97.9%\n",
      "current params: tensor([  19.0945,   18.1146,  180.4190, 1824.0521, 1822.0969, 1803.4956],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 994 was 98.0%\n",
      "current params: tensor([  19.0926,   18.1124,  180.9468, 1824.5771, 1822.6128, 1803.8996],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 995 was 98.0%\n",
      "current params: tensor([  19.0907,   18.1102,  181.4756, 1825.1034, 1823.1301, 1804.3044],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 996 was 98.0%\n",
      "current params: tensor([  19.0888,   18.1081,  182.0054, 1825.6310, 1823.6485, 1804.7100],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 997 was 98.0%\n",
      "current params: tensor([  19.0869,   18.1059,  182.5363, 1826.1598, 1824.1682, 1805.1165],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 998 was 98.0%\n",
      "current params: tensor([  19.0850,   18.1037,  183.0681, 1826.6899, 1824.6891, 1805.5237],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 999 was 98.0%\n",
      "current params: tensor([  19.0831,   18.1015,  183.6010, 1827.2212, 1825.2112, 1805.9318],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1000 was 98.0%\n",
      "current params: tensor([  19.0811,   18.0993,  184.1349, 1827.7538, 1825.7345, 1806.3407],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1001 was 98.0%\n",
      "current params: tensor([  19.0792,   18.0970,  184.6698, 1828.2876, 1826.2591, 1806.7504],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1002 was 98.0%\n",
      "current params: tensor([  19.0772,   18.0948,  185.2056, 1828.8227, 1826.7848, 1807.1608],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1003 was 98.0%\n",
      "current params: tensor([  19.0753,   18.0925,  185.7425, 1829.3591, 1827.3118, 1807.5721],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1004 was 98.0%\n",
      "current params: tensor([  19.0733,   18.0903,  186.2803, 1829.8967, 1827.8400, 1807.9842],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1005 was 98.0%\n",
      "current params: tensor([  19.0713,   18.0880,  186.8192, 1830.4355, 1828.3694, 1808.3971],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1006 was 98.0%\n",
      "current params: tensor([  19.0693,   18.0857,  187.3590, 1830.9756, 1828.9000, 1808.8108],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1007 was 98.0%\n",
      "current params: tensor([  19.0673,   18.0835,  187.8997, 1831.5169, 1829.4318, 1809.2253],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1008 was 98.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.0653,   18.0812,  188.4415, 1832.0595, 1829.9648, 1809.6406],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1009 was 98.0%\n",
      "current params: tensor([  19.0633,   18.0789,  188.9841, 1832.6033, 1830.4991, 1810.0567],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1010 was 98.0%\n",
      "current params: tensor([  19.0613,   18.0765,  189.5278, 1833.1483, 1831.0345, 1810.4736],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1011 was 98.0%\n",
      "current params: tensor([  19.0593,   18.0742,  190.0724, 1833.6946, 1831.5711, 1810.8913],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1012 was 98.0%\n",
      "current params: tensor([  19.0572,   18.0719,  190.6179, 1834.2421, 1832.1089, 1811.3098],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1013 was 98.0%\n",
      "current params: tensor([  19.0552,   18.0695,  191.1643, 1834.7909, 1832.6479, 1811.7291],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1014 was 98.0%\n",
      "current params: tensor([  19.0531,   18.0672,  191.7117, 1835.3408, 1833.1881, 1812.1492],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1015 was 98.0%\n",
      "current params: tensor([  19.0511,   18.0648,  192.2600, 1835.8920, 1833.7295, 1812.5700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1016 was 98.0%\n",
      "current params: tensor([  19.0490,   18.0624,  192.8092, 1836.4444, 1834.2721, 1812.9917],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1017 was 98.0%\n",
      "current params: tensor([  19.0469,   18.0600,  193.3593, 1836.9981, 1834.8158, 1813.4142],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1018 was 98.0%\n",
      "current params: tensor([  19.0448,   18.0576,  193.9103, 1837.5529, 1835.3608, 1813.8374],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1019 was 98.0%\n",
      "current params: tensor([  19.0427,   18.0552,  194.4623, 1838.1090, 1835.9069, 1814.2615],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1020 was 98.0%\n",
      "current params: tensor([  19.0406,   18.0528,  195.0151, 1838.6663, 1836.4542, 1814.6863],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1021 was 98.0%\n",
      "current params: tensor([  19.0385,   18.0504,  195.5688, 1839.2247, 1837.0027, 1815.1119],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1022 was 98.0%\n",
      "current params: tensor([  19.0363,   18.0479,  196.1234, 1839.7844, 1837.5524, 1815.5383],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1023 was 98.0%\n",
      "current params: tensor([  19.0342,   18.0455,  196.6789, 1840.3453, 1838.1032, 1815.9655],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1024 was 98.0%\n",
      "current params: tensor([  19.0321,   18.0430,  197.2352, 1840.9074, 1838.6552, 1816.3934],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1025 was 98.0%\n",
      "current params: tensor([  19.0299,   18.0405,  197.7924, 1841.4707, 1839.2083, 1816.8222],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1026 was 98.0%\n",
      "current params: tensor([  19.0277,   18.0381,  198.3505, 1842.0352, 1839.7627, 1817.2517],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1027 was 98.0%\n",
      "current params: tensor([  19.0255,   18.0356,  198.9094, 1842.6009, 1840.3182, 1817.6820],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1028 was 98.0%\n",
      "current params: tensor([  19.0234,   18.0331,  199.4692, 1843.1678, 1840.8748, 1818.1131],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1029 was 98.0%\n",
      "current params: tensor([  19.0212,   18.0305,  200.0299, 1843.7359, 1841.4326, 1818.5450],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1030 was 98.0%\n",
      "current params: tensor([  19.0190,   18.0280,  200.5913, 1844.3052, 1841.9916, 1818.9777],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1031 was 98.0%\n",
      "current params: tensor([  19.0167,   18.0255,  201.1536, 1844.8756, 1842.5517, 1819.4111],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1032 was 98.0%\n",
      "current params: tensor([  19.0145,   18.0229,  201.7168, 1845.4472, 1843.1130, 1819.8453],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1033 was 98.0%\n",
      "current params: tensor([  19.0123,   18.0204,  202.2807, 1846.0200, 1843.6754, 1820.2803],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1034 was 98.0%\n",
      "current params: tensor([  19.0100,   18.0178,  202.8455, 1846.5940, 1844.2390, 1820.7160],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1035 was 98.0%\n",
      "current params: tensor([  19.0078,   18.0152,  203.4111, 1847.1692, 1844.8037, 1821.1525],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1036 was 98.0%\n",
      "current params: tensor([  19.0055,   18.0126,  203.9775, 1847.7455, 1845.3696, 1821.5898],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1037 was 98.0%\n",
      "current params: tensor([  19.0033,   18.0100,  204.5447, 1848.3230, 1845.9365, 1822.0279],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1038 was 98.0%\n",
      "current params: tensor([  19.0010,   18.0074,  205.1127, 1848.9017, 1846.5047, 1822.4667],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1039 was 98.0%\n",
      "current params: tensor([  18.9987,   18.0047,  205.6815, 1849.4815, 1847.0739, 1822.9063],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1040 was 98.0%\n",
      "current params: tensor([  18.9964,   18.0021,  206.2511, 1850.0625, 1847.6443, 1823.3467],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1041 was 98.0%\n",
      "current params: tensor([  18.9941,   17.9994,  206.8215, 1850.6446, 1848.2159, 1823.7878],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1042 was 98.0%\n",
      "current params: tensor([  18.9918,   17.9968,  207.3926, 1851.2279, 1848.7885, 1824.2297],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1043 was 98.0%\n",
      "current params: tensor([  18.9894,   17.9941,  207.9646, 1851.8123, 1849.3623, 1824.6724],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1044 was 98.0%\n",
      "current params: tensor([  18.9871,   17.9914,  208.5373, 1852.3979, 1849.9372, 1825.1158],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1045 was 98.1%\n",
      "current params: tensor([  18.9847,   17.9887,  209.1107, 1852.9847, 1850.5132, 1825.5600],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1046 was 98.1%\n",
      "current params: tensor([  18.9824,   17.9860,  209.6849, 1853.5726, 1851.0904, 1826.0049],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1047 was 98.1%\n",
      "current params: tensor([  18.9800,   17.9833,  210.2599, 1854.1616, 1851.6686, 1826.4506],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1048 was 98.1%\n",
      "current params: tensor([  18.9776,   17.9806,  210.8356, 1854.7517, 1852.2480, 1826.8971],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1049 was 98.1%\n",
      "current params: tensor([  18.9752,   17.9778,  211.4121, 1855.3430, 1852.8284, 1827.3443],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1050 was 98.1%\n",
      "current params: tensor([  18.9728,   17.9751,  211.9893, 1855.9354, 1853.4100, 1827.7923],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1051 was 98.1%\n",
      "current params: tensor([  18.9704,   17.9723,  212.5673, 1856.5290, 1853.9927, 1828.2410],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1052 was 98.1%\n",
      "current params: tensor([  18.9680,   17.9695,  213.1459, 1857.1237, 1854.5765, 1828.6905],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1053 was 98.1%\n",
      "current params: tensor([  18.9656,   17.9667,  213.7253, 1857.7195, 1855.1614, 1829.1407],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1054 was 98.1%\n",
      "current params: tensor([  18.9631,   17.9639,  214.3055, 1858.3164, 1855.7473, 1829.5917],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1055 was 98.1%\n",
      "current params: tensor([  18.9607,   17.9611,  214.8863, 1858.9144, 1856.3344, 1830.0434],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1056 was 98.1%\n",
      "current params: tensor([  18.9582,   17.9582,  215.4679, 1859.5136, 1856.9226, 1830.4959],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1057 was 98.1%\n",
      "current params: tensor([  18.9557,   17.9554,  216.0501, 1860.1138, 1857.5118, 1830.9491],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1058 was 98.1%\n",
      "current params: tensor([  18.9532,   17.9526,  216.6331, 1860.7152, 1858.1021, 1831.4030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1059 was 98.1%\n",
      "current params: tensor([  18.9508,   17.9497,  217.2167, 1861.3176, 1858.6935, 1831.8578],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1060 was 98.1%\n",
      "current params: tensor([  18.9482,   17.9468,  217.8011, 1861.9212, 1859.2860, 1832.3132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1061 was 98.1%\n",
      "current params: tensor([  18.9457,   17.9439,  218.3861, 1862.5259, 1859.8796, 1832.7694],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1062 was 98.1%\n",
      "current params: tensor([  18.9432,   17.9410,  218.9719, 1863.1316, 1860.4743, 1833.2263],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1063 was 98.1%\n",
      "current params: tensor([  18.9407,   17.9381,  219.5583, 1863.7384, 1861.0700, 1833.6840],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1064 was 98.1%\n",
      "current params: tensor([  18.9381,   17.9352,  220.1453, 1864.3464, 1861.6667, 1834.1424],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1065 was 98.1%\n",
      "current params: tensor([  18.9356,   17.9322,  220.7331, 1864.9554, 1862.2646, 1834.6016],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1066 was 98.1%\n",
      "current params: tensor([  18.9330,   17.9293,  221.3215, 1865.5655, 1862.8635, 1835.0614],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1067 was 98.1%\n",
      "current params: tensor([  18.9304,   17.9263,  221.9106, 1866.1767, 1863.4635, 1835.5220],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1068 was 98.1%\n",
      "current params: tensor([  18.9278,   17.9233,  222.5003, 1866.7889, 1864.0645, 1835.9834],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1069 was 98.1%\n",
      "current params: tensor([  18.9252,   17.9203,  223.0907, 1867.4022, 1864.6666, 1836.4455],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1070 was 98.1%\n",
      "current params: tensor([  18.9226,   17.9173,  223.6817, 1868.0166, 1865.2697, 1836.9083],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1071 was 98.1%\n",
      "current params: tensor([  18.9200,   17.9143,  224.2734, 1868.6321, 1865.8739, 1837.3718],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1072 was 98.1%\n",
      "current params: tensor([  18.9173,   17.9113,  224.8658, 1869.2486, 1866.4791, 1837.8361],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1073 was 98.1%\n",
      "current params: tensor([  18.9147,   17.9082,  225.4587, 1869.8662, 1867.0854, 1838.3011],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1074 was 98.1%\n",
      "current params: tensor([  18.9120,   17.9052,  226.0523, 1870.4848, 1867.6927, 1838.7668],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1075 was 98.1%\n",
      "current params: tensor([  18.9094,   17.9021,  226.6465, 1871.1045, 1868.3011, 1839.2332],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1076 was 98.1%\n",
      "current params: tensor([  18.9067,   17.8990,  227.2414, 1871.7252, 1868.9105, 1839.7004],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1077 was 98.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  18.9040,   17.8959,  227.8368, 1872.3470, 1869.5209, 1840.1682],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1078 was 98.1%\n",
      "current params: tensor([  18.9013,   17.8928,  228.4329, 1872.9698, 1870.1323, 1840.6368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1079 was 98.1%\n",
      "current params: tensor([  18.8986,   17.8897,  229.0296, 1873.5937, 1870.7448, 1841.1061],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1080 was 98.1%\n",
      "current params: tensor([  18.8959,   17.8865,  229.6269, 1874.2185, 1871.3583, 1841.5762],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1081 was 98.1%\n",
      "current params: tensor([  18.8931,   17.8834,  230.2248, 1874.8445, 1871.9728, 1842.0469],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1082 was 98.1%\n",
      "current params: tensor([  18.8904,   17.8802,  230.8233, 1875.4714, 1872.5883, 1842.5184],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1083 was 98.1%\n",
      "current params: tensor([  18.8876,   17.8770,  231.4224, 1876.0994, 1873.2049, 1842.9905],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1084 was 98.1%\n",
      "current params: tensor([  18.8848,   17.8738,  232.0221, 1876.7284, 1873.8224, 1843.4634],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1085 was 98.1%\n",
      "current params: tensor([  18.8821,   17.8706,  232.6224, 1877.3584, 1874.4410, 1843.9370],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1086 was 98.1%\n",
      "current params: tensor([  18.8793,   17.8674,  233.2232, 1877.9894, 1875.0605, 1844.4113],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1087 was 98.1%\n",
      "current params: tensor([  18.8765,   17.8642,  233.8247, 1878.6215, 1875.6811, 1844.8863],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1088 was 98.1%\n",
      "current params: tensor([  18.8736,   17.8609,  234.4267, 1879.2545, 1876.3027, 1845.3620],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1089 was 98.1%\n",
      "current params: tensor([  18.8708,   17.8577,  235.0293, 1879.8886, 1876.9252, 1845.8384],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1090 was 98.1%\n",
      "current params: tensor([  18.8680,   17.8544,  235.6325, 1880.5236, 1877.5488, 1846.3155],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1091 was 98.1%\n",
      "current params: tensor([  18.8651,   17.8511,  236.2362, 1881.1597, 1878.1733, 1846.7934],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1092 was 98.1%\n",
      "current params: tensor([  18.8623,   17.8478,  236.8405, 1881.7967, 1878.7989, 1847.2719],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1093 was 98.1%\n",
      "current params: tensor([  18.8594,   17.8445,  237.4453, 1882.4348, 1879.4254, 1847.7511],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1094 was 98.1%\n",
      "current params: tensor([  18.8565,   17.8412,  238.0507, 1883.0738, 1880.0529, 1848.2310],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1095 was 98.1%\n",
      "current params: tensor([  18.8536,   17.8378,  238.6567, 1883.7138, 1880.6814, 1848.7116],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1096 was 98.2%\n",
      "current params: tensor([  18.8507,   17.8345,  239.2632, 1884.3548, 1881.3108, 1849.1929],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1097 was 98.2%\n",
      "current params: tensor([  18.8477,   17.8311,  239.8702, 1884.9967, 1881.9412, 1849.6749],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1098 was 98.2%\n",
      "current params: tensor([  18.8448,   17.8277,  240.4778, 1885.6397, 1882.5726, 1850.1576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1099 was 98.2%\n",
      "current params: tensor([  18.8419,   17.8243,  241.0859, 1886.2836, 1883.2050, 1850.6409],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1100 was 98.2%\n",
      "current params: tensor([  18.8389,   17.8209,  241.6945, 1886.9285, 1883.8383, 1851.1250],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1101 was 98.2%\n",
      "current params: tensor([  18.8359,   17.8174,  242.3037, 1887.5743, 1884.4726, 1851.6097],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1102 was 98.2%\n",
      "current params: tensor([  18.8329,   17.8140,  242.9134, 1888.2211, 1885.1078, 1852.0951],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1103 was 98.2%\n",
      "current params: tensor([  18.8299,   17.8105,  243.5236, 1888.8688, 1885.7440, 1852.5812],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1104 was 98.2%\n",
      "current params: tensor([  18.8269,   17.8071,  244.1344, 1889.5175, 1886.3811, 1853.0680],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1105 was 98.2%\n",
      "current params: tensor([  18.8239,   17.8036,  244.7456, 1890.1672, 1887.0192, 1853.5555],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1106 was 98.2%\n",
      "current params: tensor([  18.8208,   17.8001,  245.3574, 1890.8178, 1887.6582, 1854.0436],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1107 was 98.2%\n",
      "current params: tensor([  18.8178,   17.7965,  245.9697, 1891.4693, 1888.2982, 1854.5325],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1108 was 98.2%\n",
      "current params: tensor([  18.8147,   17.7930,  246.5825, 1892.1218, 1888.9391, 1855.0220],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1109 was 98.2%\n",
      "current params: tensor([  18.8117,   17.7895,  247.1958, 1892.7752, 1889.5809, 1855.5121],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1110 was 98.2%\n",
      "current params: tensor([  18.8086,   17.7859,  247.8096, 1893.4295, 1890.2237, 1856.0030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1111 was 98.2%\n",
      "current params: tensor([  18.8055,   17.7823,  248.4238, 1894.0848, 1890.8674, 1856.4945],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1112 was 98.2%\n",
      "current params: tensor([  18.8024,   17.7787,  249.0386, 1894.7410, 1891.5120, 1856.9867],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1113 was 98.2%\n",
      "current params: tensor([  18.7992,   17.7751,  249.6539, 1895.3981, 1892.1576, 1857.4795],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1114 was 98.2%\n",
      "current params: tensor([  18.7961,   17.7715,  250.2696, 1896.0561, 1892.8040, 1857.9730],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1115 was 98.2%\n",
      "current params: tensor([  18.7929,   17.7678,  250.8859, 1896.7150, 1893.4514, 1858.4672],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1116 was 98.2%\n",
      "current params: tensor([  18.7898,   17.7642,  251.5026, 1897.3749, 1894.0997, 1858.9621],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1117 was 98.2%\n",
      "current params: tensor([  18.7866,   17.7605,  252.1198, 1898.0356, 1894.7489, 1859.4576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1118 was 98.2%\n",
      "current params: tensor([  18.7834,   17.7568,  252.7374, 1898.6973, 1895.3990, 1859.9537],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1119 was 98.2%\n",
      "current params: tensor([  18.7802,   17.7531,  253.3556, 1899.3598, 1896.0500, 1860.4505],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1120 was 98.2%\n",
      "current params: tensor([  18.7770,   17.7494,  253.9742, 1900.0233, 1896.7019, 1860.9480],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1121 was 98.2%\n",
      "current params: tensor([  18.7737,   17.7456,  254.5932, 1900.6876, 1897.3547, 1861.4462],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1122 was 98.2%\n",
      "current params: tensor([  18.7705,   17.7419,  255.2128, 1901.3528, 1898.0084, 1861.9449],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1123 was 98.2%\n",
      "current params: tensor([  18.7672,   17.7381,  255.8328, 1902.0189, 1898.6630, 1862.4444],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1124 was 98.2%\n",
      "current params: tensor([  18.7639,   17.7343,  256.4532, 1902.6859, 1899.3184, 1862.9445],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1125 was 98.2%\n",
      "current params: tensor([  18.7607,   17.7305,  257.0741, 1903.3537, 1899.9748, 1863.4452],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1126 was 98.2%\n",
      "current params: tensor([  18.7574,   17.7267,  257.6955, 1904.0225, 1900.6320, 1863.9466],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1127 was 98.2%\n",
      "current params: tensor([  18.7540,   17.7229,  258.3173, 1904.6921, 1901.2901, 1864.4486],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1128 was 98.2%\n",
      "current params: tensor([  18.7507,   17.7190,  258.9395, 1905.3625, 1901.9491, 1864.9513],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1129 was 98.2%\n",
      "current params: tensor([  18.7474,   17.7152,  259.5622, 1906.0339, 1902.6090, 1865.4546],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1130 was 98.2%\n",
      "current params: tensor([  18.7440,   17.7113,  260.1853, 1906.7060, 1903.2697, 1865.9585],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1131 was 98.2%\n",
      "current params: tensor([  18.7406,   17.7074,  260.8089, 1907.3791, 1903.9313, 1866.4631],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1132 was 98.2%\n",
      "current params: tensor([  18.7373,   17.7035,  261.4329, 1908.0530, 1904.5937, 1866.9684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1133 was 98.2%\n",
      "current params: tensor([  18.7339,   17.6995,  262.0573, 1908.7277, 1905.2570, 1867.4742],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1134 was 98.2%\n",
      "current params: tensor([  18.7305,   17.6956,  262.6821, 1909.4033, 1905.9212, 1867.9807],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1135 was 98.2%\n",
      "current params: tensor([  18.7270,   17.6916,  263.3074, 1910.0797, 1906.5862, 1868.4878],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1136 was 98.2%\n",
      "current params: tensor([  18.7236,   17.6876,  263.9331, 1910.7569, 1907.2520, 1868.9956],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1137 was 98.2%\n",
      "current params: tensor([  18.7201,   17.6836,  264.5592, 1911.4350, 1907.9187, 1869.5040],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1138 was 98.2%\n",
      "current params: tensor([  18.7167,   17.6796,  265.1858, 1912.1139, 1908.5863, 1870.0130],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1139 was 98.2%\n",
      "current params: tensor([  18.7132,   17.6756,  265.8127, 1912.7936, 1909.2547, 1870.5226],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1140 was 98.2%\n",
      "current params: tensor([  18.7097,   17.6716,  266.4401, 1913.4742, 1909.9239, 1871.0329],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1141 was 98.2%\n",
      "current params: tensor([  18.7062,   17.6675,  267.0679, 1914.1556, 1910.5939, 1871.5438],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1142 was 98.2%\n",
      "current params: tensor([  18.7026,   17.6634,  267.6961, 1914.8377, 1911.2648, 1872.0553],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1143 was 98.2%\n",
      "current params: tensor([  18.6991,   17.6593,  268.3247, 1915.5207, 1911.9365, 1872.5674],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1144 was 98.2%\n",
      "current params: tensor([  18.6955,   17.6552,  268.9537, 1916.2045, 1912.6090, 1873.0801],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1145 was 98.2%\n",
      "current params: tensor([  18.6920,   17.6510,  269.5831, 1916.8891, 1913.2823, 1873.5935],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1146 was 98.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  18.6884,   17.6469,  270.2128, 1917.5745, 1913.9565, 1874.1074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1147 was 98.3%\n",
      "current params: tensor([  18.6848,   17.6427,  270.8430, 1918.2607, 1914.6314, 1874.6220],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1148 was 98.3%\n",
      "current params: tensor([  18.6812,   17.6385,  271.4736, 1918.9477, 1915.3072, 1875.1372],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1149 was 98.3%\n",
      "current params: tensor([  18.6775,   17.6343,  272.1046, 1919.6355, 1915.9838, 1875.6530],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1150 was 98.3%\n",
      "current params: tensor([  18.6739,   17.6301,  272.7359, 1920.3241, 1916.6612, 1876.1694],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1151 was 98.3%\n",
      "current params: tensor([  18.6702,   17.6259,  273.3677, 1921.0134, 1917.3393, 1876.6864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1152 was 98.3%\n",
      "current params: tensor([  18.6666,   17.6216,  273.9998, 1921.7035, 1918.0183, 1877.2040],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1153 was 98.3%\n",
      "current params: tensor([  18.6629,   17.6173,  274.6323, 1922.3944, 1918.6981, 1877.7222],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1154 was 98.3%\n",
      "current params: tensor([  18.6592,   17.6130,  275.2652, 1923.0860, 1919.3786, 1878.2410],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1155 was 98.3%\n",
      "current params: tensor([  18.6554,   17.6087,  275.8985, 1923.7785, 1920.0600, 1878.7604],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1156 was 98.3%\n",
      "current params: tensor([  18.6517,   17.6044,  276.5321, 1924.4716, 1920.7421, 1879.2804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1157 was 98.3%\n",
      "current params: tensor([  18.6480,   17.6000,  277.1661, 1925.1656, 1921.4250, 1879.8010],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1158 was 98.3%\n",
      "current params: tensor([  18.6442,   17.5957,  277.8005, 1925.8603, 1922.1087, 1880.3222],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1159 was 98.3%\n",
      "current params: tensor([  18.6404,   17.5913,  278.4353, 1926.5557, 1922.7931, 1880.8440],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1160 was 98.3%\n",
      "current params: tensor([  18.6366,   17.5869,  279.0704, 1927.2519, 1923.4783, 1881.3663],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1161 was 98.3%\n",
      "current params: tensor([  18.6328,   17.5824,  279.7059, 1927.9489, 1924.1643, 1881.8893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1162 was 98.3%\n",
      "current params: tensor([  18.6290,   17.5780,  280.3417, 1928.6465, 1924.8510, 1882.4128],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1163 was 98.3%\n",
      "current params: tensor([  18.6251,   17.5735,  280.9779, 1929.3449, 1925.5385, 1882.9369],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1164 was 98.3%\n",
      "current params: tensor([  18.6213,   17.5690,  281.6145, 1930.0441, 1926.2268, 1883.4616],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1165 was 98.3%\n",
      "current params: tensor([  18.6174,   17.5645,  282.2514, 1930.7439, 1926.9158, 1883.9869],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1166 was 98.3%\n",
      "current params: tensor([  18.6135,   17.5600,  282.8887, 1931.4445, 1927.6056, 1884.5128],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1167 was 98.3%\n",
      "current params: tensor([  18.6096,   17.5555,  283.5263, 1932.1459, 1928.2961, 1885.0392],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1168 was 98.3%\n",
      "current params: tensor([  18.6057,   17.5509,  284.1642, 1932.8479, 1928.9873, 1885.5662],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1169 was 98.3%\n",
      "current params: tensor([  18.6017,   17.5464,  284.8026, 1933.5506, 1929.6793, 1886.0938],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1170 was 98.3%\n",
      "current params: tensor([  18.5978,   17.5418,  285.4412, 1934.2541, 1930.3720, 1886.6220],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1171 was 98.3%\n",
      "current params: tensor([  18.5938,   17.5371,  286.0802, 1934.9583, 1931.0655, 1887.1507],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1172 was 98.3%\n",
      "current params: tensor([  18.5898,   17.5325,  286.7196, 1935.6631, 1931.7597, 1887.6800],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1173 was 98.3%\n",
      "current params: tensor([  18.5858,   17.5278,  287.3593, 1936.3687, 1932.4546, 1888.2098],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1174 was 98.3%\n",
      "current params: tensor([  18.5818,   17.5232,  287.9993, 1937.0750, 1933.1502, 1888.7402],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1175 was 98.3%\n",
      "current params: tensor([  18.5777,   17.5185,  288.6396, 1937.7819, 1933.8465, 1889.2712],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1176 was 98.3%\n",
      "current params: tensor([  18.5737,   17.5138,  289.2803, 1938.4896, 1934.5436, 1889.8028],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1177 was 98.3%\n",
      "current params: tensor([  18.5696,   17.5090,  289.9213, 1939.1979, 1935.2414, 1890.3349],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1178 was 98.3%\n",
      "current params: tensor([  18.5655,   17.5043,  290.5627, 1939.9069, 1935.9399, 1890.8675],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1179 was 98.3%\n",
      "current params: tensor([  18.5614,   17.4995,  291.2044, 1940.6166, 1936.6391, 1891.4007],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1180 was 98.3%\n",
      "current params: tensor([  18.5573,   17.4947,  291.8464, 1941.3269, 1937.3390, 1891.9345],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1181 was 98.3%\n",
      "current params: tensor([  18.5531,   17.4899,  292.4887, 1942.0380, 1938.0396, 1892.4688],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1182 was 98.3%\n",
      "current params: tensor([  18.5490,   17.4851,  293.1313, 1942.7497, 1938.7409, 1893.0036],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1183 was 98.3%\n",
      "current params: tensor([  18.5448,   17.4802,  293.7743, 1943.4620, 1939.4428, 1893.5390],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1184 was 98.3%\n",
      "current params: tensor([  18.5406,   17.4753,  294.4176, 1944.1750, 1940.1455, 1894.0750],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1185 was 98.3%\n",
      "current params: tensor([  18.5364,   17.4704,  295.0612, 1944.8887, 1940.8489, 1894.6115],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1186 was 98.3%\n",
      "current params: tensor([  18.5322,   17.4655,  295.7051, 1945.6030, 1941.5529, 1895.1485],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1187 was 98.3%\n",
      "current params: tensor([  18.5280,   17.4606,  296.3494, 1946.3180, 1942.2577, 1895.6861],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1188 was 98.3%\n",
      "current params: tensor([  18.5237,   17.4556,  296.9939, 1947.0336, 1942.9631, 1896.2242],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1189 was 98.3%\n",
      "current params: tensor([  18.5194,   17.4506,  297.6388, 1947.7499, 1943.6691, 1896.7629],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1190 was 98.3%\n",
      "current params: tensor([  18.5151,   17.4456,  298.2839, 1948.4668, 1944.3759, 1897.3020],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1191 was 98.3%\n",
      "current params: tensor([  18.5108,   17.4406,  298.9294, 1949.1843, 1945.0833, 1897.8418],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1192 was 98.3%\n",
      "current params: tensor([  18.5065,   17.4356,  299.5752, 1949.9025, 1945.7914, 1898.3820],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1193 was 98.3%\n",
      "current params: tensor([  18.5021,   17.4305,  300.2212, 1950.6213, 1946.5001, 1898.9228],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1194 was 98.3%\n",
      "current params: tensor([  18.4978,   17.4254,  300.8676, 1951.3407, 1947.2095, 1899.4641],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1195 was 98.3%\n",
      "current params: tensor([  18.4934,   17.4203,  301.5143, 1952.0607, 1947.9195, 1900.0059],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1196 was 98.3%\n",
      "current params: tensor([  18.4890,   17.4152,  302.1613, 1952.7814, 1948.6302, 1900.5482],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1197 was 98.3%\n",
      "current params: tensor([  18.4846,   17.4100,  302.8085, 1953.5026, 1949.3416, 1901.0911],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1198 was 98.3%\n",
      "current params: tensor([  18.4801,   17.4049,  303.4561, 1954.2245, 1950.0536, 1901.6345],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1199 was 98.4%\n",
      "current params: tensor([  18.4757,   17.3997,  304.1040, 1954.9470, 1950.7662, 1902.1784],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1200 was 98.4%\n",
      "current params: tensor([  18.4712,   17.3945,  304.7521, 1955.6701, 1951.4794, 1902.7228],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1201 was 98.4%\n",
      "current params: tensor([  18.4667,   17.3892,  305.4005, 1956.3937, 1952.1933, 1903.2677],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1202 was 98.4%\n",
      "current params: tensor([  18.4622,   17.3840,  306.0493, 1957.1180, 1952.9079, 1903.8132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1203 was 98.4%\n",
      "current params: tensor([  18.4576,   17.3787,  306.6983, 1957.8429, 1953.6230, 1904.3591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1204 was 98.4%\n",
      "current params: tensor([  18.4531,   17.3734,  307.3476, 1958.5683, 1954.3388, 1904.9056],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1205 was 98.4%\n",
      "current params: tensor([  18.4485,   17.3680,  307.9972, 1959.2944, 1955.0552, 1905.4525],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1206 was 98.4%\n",
      "current params: tensor([  18.4439,   17.3627,  308.6470, 1960.0210, 1955.7722, 1906.0000],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1207 was 98.4%\n",
      "current params: tensor([  18.4393,   17.3573,  309.2972, 1960.7482, 1956.4899, 1906.5480],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1208 was 98.4%\n",
      "current params: tensor([  18.4347,   17.3519,  309.9476, 1961.4759, 1957.2081, 1907.0964],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1209 was 98.4%\n",
      "current params: tensor([  18.4301,   17.3465,  310.5983, 1962.2043, 1957.9270, 1907.6454],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1210 was 98.4%\n",
      "current params: tensor([  18.4254,   17.3411,  311.2493, 1962.9332, 1958.6464, 1908.1949],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1211 was 98.4%\n",
      "current params: tensor([  18.4207,   17.3356,  311.9005, 1963.6626, 1959.3665, 1908.7448],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1212 was 98.4%\n",
      "current params: tensor([  18.4160,   17.3301,  312.5521, 1964.3927, 1960.0871, 1909.2953],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1213 was 98.4%\n",
      "current params: tensor([  18.4113,   17.3246,  313.2039, 1965.1233, 1960.8084, 1909.8462],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1214 was 98.4%\n",
      "current params: tensor([  18.4066,   17.3191,  313.8559, 1965.8544, 1961.5302, 1910.3976],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1215 was 98.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  18.4018,   17.3135,  314.5083, 1966.5861, 1962.2527, 1910.9495],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1216 was 98.4%\n",
      "current params: tensor([  18.3970,   17.3079,  315.1609, 1967.3183, 1962.9757, 1911.5019],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1217 was 98.4%\n",
      "current params: tensor([  18.3922,   17.3023,  315.8137, 1968.0511, 1963.6993, 1912.0548],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1218 was 98.4%\n",
      "current params: tensor([  18.3874,   17.2967,  316.4669, 1968.7844, 1964.4235, 1912.6081],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1219 was 98.4%\n",
      "current params: tensor([  18.3826,   17.2911,  317.1202, 1969.5183, 1965.1482, 1913.1620],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1220 was 98.4%\n",
      "current params: tensor([  18.3777,   17.2854,  317.7739, 1970.2526, 1965.8736, 1913.7163],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1221 was 98.4%\n",
      "current params: tensor([  18.3729,   17.2797,  318.4278, 1970.9876, 1966.5995, 1914.2711],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1222 was 98.4%\n",
      "current params: tensor([  18.3680,   17.2740,  319.0820, 1971.7230, 1967.3259, 1914.8263],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1223 was 98.4%\n",
      "current params: tensor([  18.3631,   17.2682,  319.7364, 1972.4590, 1968.0530, 1915.3820],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1224 was 98.4%\n",
      "current params: tensor([  18.3581,   17.2625,  320.3911, 1973.1954, 1968.7806, 1915.9382],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1225 was 98.4%\n",
      "current params: tensor([  18.3532,   17.2567,  321.0460, 1973.9324, 1969.5087, 1916.4949],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1226 was 98.4%\n",
      "current params: tensor([  18.3482,   17.2508,  321.7012, 1974.6699, 1970.2374, 1917.0520],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1227 was 98.4%\n",
      "current params: tensor([  18.3432,   17.2450,  322.3567, 1975.4080, 1970.9667, 1917.6096],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1228 was 98.4%\n",
      "current params: tensor([  18.3382,   17.2391,  323.0124, 1976.1465, 1971.6965, 1918.1676],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1229 was 98.4%\n",
      "current params: tensor([  18.3331,   17.2332,  323.6683, 1976.8855, 1972.4268, 1918.7262],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1230 was 98.4%\n",
      "current params: tensor([  18.3281,   17.2273,  324.3245, 1977.6250, 1973.1577, 1919.2851],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1231 was 98.4%\n",
      "current params: tensor([  18.3230,   17.2214,  324.9810, 1978.3651, 1973.8891, 1919.8445],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1232 was 98.4%\n",
      "current params: tensor([  18.3179,   17.2154,  325.6376, 1979.1056, 1974.6211, 1920.4044],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1233 was 98.4%\n",
      "current params: tensor([  18.3128,   17.2094,  326.2946, 1979.8466, 1975.3536, 1920.9647],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1234 was 98.4%\n",
      "current params: tensor([  18.3076,   17.2034,  326.9517, 1980.5881, 1976.0866, 1921.5255],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1235 was 98.4%\n",
      "current params: tensor([  18.3025,   17.1974,  327.6091, 1981.3300, 1976.8201, 1922.0867],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1236 was 98.4%\n",
      "current params: tensor([  18.2973,   17.1913,  328.2668, 1982.0725, 1977.5542, 1922.6483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1237 was 98.4%\n",
      "current params: tensor([  18.2921,   17.1852,  328.9247, 1982.8154, 1978.2888, 1923.2104],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1238 was 98.4%\n",
      "current params: tensor([  18.2869,   17.1791,  329.5828, 1983.5588, 1979.0239, 1923.7730],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1239 was 98.4%\n",
      "current params: tensor([  18.2816,   17.1729,  330.2411, 1984.3027, 1979.7595, 1924.3359],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1240 was 98.4%\n",
      "current params: tensor([  18.2763,   17.1667,  330.8997, 1985.0470, 1980.4956, 1924.8994],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1241 was 98.4%\n",
      "current params: tensor([  18.2711,   17.1605,  331.5586, 1985.7918, 1981.2323, 1925.4632],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1242 was 98.4%\n",
      "current params: tensor([  18.2657,   17.1543,  332.2176, 1986.5370, 1981.9694, 1926.0275],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1243 was 98.4%\n",
      "current params: tensor([  18.2604,   17.1481,  332.8769, 1987.2827, 1982.7070, 1926.5922],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1244 was 98.4%\n",
      "current params: tensor([  18.2551,   17.1418,  333.5364, 1988.0289, 1983.4452, 1927.1573],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1245 was 98.4%\n",
      "current params: tensor([  18.2497,   17.1355,  334.1962, 1988.7755, 1984.1838, 1927.7229],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1246 was 98.4%\n",
      "current params: tensor([  18.2443,   17.1292,  334.8561, 1989.5226, 1984.9229, 1928.2889],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1247 was 98.4%\n",
      "current params: tensor([  18.2389,   17.1228,  335.5163, 1990.2701, 1985.6625, 1928.8553],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1248 was 98.4%\n",
      "current params: tensor([  18.2334,   17.1164,  336.1768, 1991.0180, 1986.4026, 1929.4221],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1249 was 98.4%\n",
      "current params: tensor([  18.2279,   17.1100,  336.8374, 1991.7664, 1987.1432, 1929.9893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1250 was 98.4%\n",
      "current params: tensor([  18.2225,   17.1036,  337.4983, 1992.5152, 1987.8843, 1930.5570],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1251 was 98.4%\n",
      "current params: tensor([  18.2170,   17.0971,  338.1593, 1993.2644, 1988.6258, 1931.1250],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1252 was 98.4%\n",
      "current params: tensor([  18.2114,   17.0906,  338.8207, 1994.0141, 1989.3678, 1931.6935],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1253 was 98.5%\n",
      "current params: tensor([  18.2059,   17.0841,  339.4822, 1994.7642, 1990.1103, 1932.2624],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1254 was 98.5%\n",
      "current params: tensor([  18.2003,   17.0775,  340.1439, 1995.5147, 1990.8532, 1932.8317],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1255 was 98.5%\n",
      "current params: tensor([  18.1947,   17.0710,  340.8059, 1996.2656, 1991.5966, 1933.4014],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1256 was 98.5%\n",
      "current params: tensor([  18.1891,   17.0644,  341.4680, 1997.0169, 1992.3405, 1933.9715],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1257 was 98.5%\n",
      "current params: tensor([  18.1834,   17.0577,  342.1304, 1997.7687, 1993.0848, 1934.5420],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1258 was 98.5%\n",
      "current params: tensor([  18.1777,   17.0511,  342.7930, 1998.5209, 1993.8296, 1935.1129],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1259 was 98.5%\n",
      "current params: tensor([  18.1721,   17.0444,  343.4558, 1999.2734, 1994.5748, 1935.6842],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1260 was 98.5%\n",
      "current params: tensor([  18.1663,   17.0377,  344.1188, 2000.0264, 1995.3205, 1936.2559],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1261 was 98.5%\n",
      "current params: tensor([  18.1606,   17.0309,  344.7820, 2000.7798, 1996.0667, 1936.8280],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1262 was 98.5%\n",
      "current params: tensor([  18.1548,   17.0241,  345.4455, 2001.5335, 1996.8132, 1937.4005],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1263 was 98.5%\n",
      "current params: tensor([  18.1490,   17.0173,  346.1091, 2002.2877, 1997.5602, 1937.9734],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1264 was 98.5%\n",
      "current params: tensor([  18.1432,   17.0105,  346.7729, 2003.0422, 1998.3077, 1938.5466],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1265 was 98.5%\n",
      "current params: tensor([  18.1374,   17.0037,  347.4370, 2003.7972, 1999.0556, 1939.1203],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1266 was 98.5%\n",
      "current params: tensor([  18.1315,   16.9968,  348.1012, 2004.5525, 1999.8039, 1939.6943],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1267 was 98.5%\n",
      "current params: tensor([  18.1257,   16.9899,  348.7657, 2005.3082, 2000.5527, 1940.2687],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1268 was 98.5%\n",
      "current params: tensor([  18.1198,   16.9829,  349.4303, 2006.0642, 2001.3018, 1940.8434],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1269 was 98.5%\n",
      "current params: tensor([  18.1138,   16.9759,  350.0951, 2006.8207, 2002.0514, 1941.4186],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1270 was 98.5%\n",
      "current params: tensor([  18.1079,   16.9689,  350.7602, 2007.5775, 2002.8014, 1941.9941],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1271 was 98.5%\n",
      "current params: tensor([  18.1019,   16.9619,  351.4254, 2008.3347, 2003.5519, 1942.5700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1272 was 98.5%\n",
      "current params: tensor([  18.0959,   16.9548,  352.0908, 2009.0922, 2004.3027, 1943.1463],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1273 was 98.5%\n",
      "current params: tensor([  18.0899,   16.9477,  352.7565, 2009.8501, 2005.0540, 1943.7229],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1274 was 98.5%\n",
      "current params: tensor([  18.0838,   16.9406,  353.4223, 2010.6084, 2005.8056, 1944.2999],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1275 was 98.5%\n",
      "current params: tensor([  18.0777,   16.9335,  354.0883, 2011.3670, 2006.5577, 1944.8773],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1276 was 98.5%\n",
      "current params: tensor([  18.0716,   16.9263,  354.7545, 2012.1260, 2007.3102, 1945.4550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1277 was 98.5%\n",
      "current params: tensor([  18.0655,   16.9191,  355.4209, 2012.8854, 2008.0630, 1946.0330],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1278 was 98.5%\n",
      "current params: tensor([  18.0594,   16.9118,  356.0875, 2013.6450, 2008.8163, 1946.6115],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1279 was 98.5%\n",
      "current params: tensor([  18.0532,   16.9045,  356.7542, 2014.4051, 2009.5700, 1947.1903],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1280 was 98.5%\n",
      "current params: tensor([  18.0470,   16.8972,  357.4212, 2015.1654, 2010.3240, 1947.7694],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1281 was 98.5%\n",
      "current params: tensor([  18.0408,   16.8899,  358.0883, 2015.9261, 2011.0785, 1948.3489],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1282 was 98.5%\n",
      "current params: tensor([  18.0345,   16.8825,  358.7556, 2016.6871, 2011.8333, 1948.9287],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1283 was 98.5%\n",
      "current params: tensor([  18.0282,   16.8751,  359.4231, 2017.4485, 2012.5885, 1949.5089],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1284 was 98.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  18.0219,   16.8677,  360.0908, 2018.2102, 2013.3441, 1950.0894],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1285 was 98.5%\n",
      "current params: tensor([  18.0156,   16.8602,  360.7586, 2018.9722, 2014.1000, 1950.6703],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1286 was 98.5%\n",
      "current params: tensor([  18.0093,   16.8527,  361.4267, 2019.7346, 2014.8564, 1951.2515],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1287 was 98.5%\n",
      "current params: tensor([  18.0029,   16.8452,  362.0949, 2020.4972, 2015.6131, 1951.8330],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1288 was 98.5%\n",
      "current params: tensor([  17.9965,   16.8376,  362.7633, 2021.2602, 2016.3702, 1952.4149],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1289 was 98.5%\n",
      "current params: tensor([  17.9900,   16.8300,  363.4318, 2022.0235, 2017.1276, 1952.9971],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1290 was 98.5%\n",
      "current params: tensor([  17.9836,   16.8224,  364.1006, 2022.7871, 2017.8854, 1953.5796],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1291 was 98.5%\n",
      "current params: tensor([  17.9771,   16.8148,  364.7695, 2023.5511, 2018.6436, 1954.1625],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1292 was 98.5%\n",
      "current params: tensor([  17.9706,   16.8071,  365.4386, 2024.3153, 2019.4021, 1954.7457],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1293 was 98.5%\n",
      "current params: tensor([  17.9640,   16.7994,  366.1078, 2025.0798, 2020.1609, 1955.3292],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1294 was 98.5%\n",
      "current params: tensor([  17.9575,   16.7916,  366.7772, 2025.8446, 2020.9202, 1955.9130],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1295 was 98.5%\n",
      "current params: tensor([  17.9509,   16.7838,  367.4468, 2026.6098, 2021.6797, 1956.4971],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1296 was 98.5%\n",
      "current params: tensor([  17.9443,   16.7760,  368.1166, 2027.3752, 2022.4397, 1957.0816],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1297 was 98.5%\n",
      "current params: tensor([  17.9376,   16.7681,  368.7865, 2028.1409, 2023.1999, 1957.6664],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1298 was 98.5%\n",
      "current params: tensor([  17.9310,   16.7603,  369.4566, 2028.9069, 2023.9605, 1958.2514],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1299 was 98.5%\n",
      "current params: tensor([  17.9243,   16.7523,  370.1268, 2029.6732, 2024.7215, 1958.8368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1300 was 98.5%\n",
      "current params: tensor([  17.9175,   16.7444,  370.7972, 2030.4398, 2025.4827, 1959.4225],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1301 was 98.5%\n",
      "current params: tensor([  17.9108,   16.7364,  371.4678, 2031.2066, 2026.2443, 1960.0085],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1302 was 98.5%\n",
      "current params: tensor([  17.9040,   16.7284,  372.1385, 2031.9738, 2027.0063, 1960.5949],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1303 was 98.5%\n",
      "current params: tensor([  17.8972,   16.7203,  372.8094, 2032.7412, 2027.7685, 1961.1815],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1304 was 98.5%\n",
      "current params: tensor([  17.8904,   16.7122,  373.4805, 2033.5088, 2028.5311, 1961.7684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1305 was 98.5%\n",
      "current params: tensor([  17.8835,   16.7041,  374.1517, 2034.2768, 2029.2940, 1962.3556],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1306 was 98.5%\n",
      "current params: tensor([  17.8766,   16.6960,  374.8230, 2035.0450, 2030.0572, 1962.9431],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1307 was 98.6%\n",
      "current params: tensor([  17.8697,   16.6878,  375.4946, 2035.8135, 2030.8208, 1963.5309],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1308 was 98.6%\n",
      "current params: tensor([  17.8627,   16.6795,  376.1662, 2036.5822, 2031.5846, 1964.1189],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1309 was 98.6%\n",
      "current params: tensor([  17.8557,   16.6713,  376.8380, 2037.3512, 2032.3488, 1964.7073],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1310 was 98.6%\n",
      "current params: tensor([  17.8487,   16.6630,  377.5100, 2038.1205, 2033.1133, 1965.2959],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1311 was 98.6%\n",
      "current params: tensor([  17.8417,   16.6546,  378.1821, 2038.8900, 2033.8780, 1965.8849],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1312 was 98.6%\n",
      "current params: tensor([  17.8346,   16.6463,  378.8544, 2039.6597, 2034.6431, 1966.4741],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1313 was 98.6%\n",
      "current params: tensor([  17.8276,   16.6379,  379.5268, 2040.4297, 2035.4085, 1967.0636],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1314 was 98.6%\n",
      "current params: tensor([  17.8204,   16.6294,  380.1994, 2041.2000, 2036.1742, 1967.6533],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1315 was 98.6%\n",
      "current params: tensor([  17.8133,   16.6210,  380.8721, 2041.9705, 2036.9401, 1968.2433],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1316 was 98.6%\n",
      "current params: tensor([  17.8061,   16.6125,  381.5449, 2042.7412, 2037.7064, 1968.8336],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1317 was 98.6%\n",
      "current params: tensor([  17.7989,   16.6039,  382.2179, 2043.5121, 2038.4729, 1969.4242],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1318 was 98.6%\n",
      "current params: tensor([  17.7917,   16.5953,  382.8910, 2044.2833, 2039.2398, 1970.0150],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1319 was 98.6%\n",
      "current params: tensor([  17.7844,   16.5867,  383.5643, 2045.0548, 2040.0069, 1970.6061],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1320 was 98.6%\n",
      "current params: tensor([  17.7771,   16.5780,  384.2377, 2045.8264, 2040.7743, 1971.1975],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1321 was 98.6%\n",
      "current params: tensor([  17.7698,   16.5694,  384.9113, 2046.5983, 2041.5419, 1971.7891],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1322 was 98.6%\n",
      "current params: tensor([  17.7624,   16.5606,  385.5850, 2047.3704, 2042.3099, 1972.3810],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1323 was 98.6%\n",
      "current params: tensor([  17.7550,   16.5519,  386.2588, 2048.1427, 2043.0781, 1972.9731],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1324 was 98.6%\n",
      "current params: tensor([  17.7476,   16.5431,  386.9327, 2048.9153, 2043.8466, 1973.5655],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1325 was 98.6%\n",
      "current params: tensor([  17.7402,   16.5342,  387.6068, 2049.6880, 2044.6154, 1974.1581],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1326 was 98.6%\n",
      "current params: tensor([  17.7327,   16.5253,  388.2810, 2050.4610, 2045.3844, 1974.7510],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1327 was 98.6%\n",
      "current params: tensor([  17.7252,   16.5164,  388.9554, 2051.2342, 2046.1537, 1975.3441],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1328 was 98.6%\n",
      "current params: tensor([  17.7177,   16.5075,  389.6299, 2052.0076, 2046.9232, 1975.9375],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1329 was 98.6%\n",
      "current params: tensor([  17.7101,   16.4985,  390.3045, 2052.7812, 2047.6930, 1976.5311],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1330 was 98.6%\n",
      "current params: tensor([  17.7025,   16.4894,  390.9792, 2053.5550, 2048.4631, 1977.1249],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1331 was 98.6%\n",
      "current params: tensor([  17.6949,   16.4804,  391.6541, 2054.3289, 2049.2334, 1977.7190],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1332 was 98.6%\n",
      "current params: tensor([  17.6872,   16.4713,  392.3290, 2055.1031, 2050.0040, 1978.3133],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1333 was 98.6%\n",
      "current params: tensor([  17.6795,   16.4621,  393.0041, 2055.8775, 2050.7748, 1978.9078],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1334 was 98.6%\n",
      "current params: tensor([  17.6718,   16.4529,  393.6794, 2056.6521, 2051.5458, 1979.5025],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1335 was 98.6%\n",
      "current params: tensor([  17.6641,   16.4437,  394.3547, 2057.4269, 2052.3171, 1980.0975],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1336 was 98.6%\n",
      "current params: tensor([  17.6563,   16.4344,  395.0302, 2058.2018, 2053.0887, 1980.6927],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1337 was 98.6%\n",
      "current params: tensor([  17.6485,   16.4251,  395.7058, 2058.9769, 2053.8604, 1981.2881],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1338 was 98.6%\n",
      "current params: tensor([  17.6406,   16.4158,  396.3815, 2059.7523, 2054.6325, 1981.8838],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1339 was 98.6%\n",
      "current params: tensor([  17.6327,   16.4064,  397.0573, 2060.5277, 2055.4047, 1982.4796],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1340 was 98.6%\n",
      "current params: tensor([  17.6248,   16.3970,  397.7332, 2061.3034, 2056.1772, 1983.0757],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1341 was 98.6%\n",
      "current params: tensor([  17.6169,   16.3875,  398.4093, 2062.0793, 2056.9499, 1983.6720],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1342 was 98.6%\n",
      "current params: tensor([  17.6089,   16.3780,  399.0854, 2062.8553, 2057.7228, 1984.2684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1343 was 98.6%\n",
      "current params: tensor([  17.6009,   16.3685,  399.7617, 2063.6314, 2058.4959, 1984.8651],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1344 was 98.6%\n",
      "current params: tensor([  17.5928,   16.3589,  400.4381, 2064.4078, 2059.2693, 1985.4620],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1345 was 98.6%\n",
      "current params: tensor([  17.5848,   16.3492,  401.1146, 2065.1843, 2060.0429, 1986.0591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1346 was 98.6%\n",
      "current params: tensor([  17.5767,   16.3396,  401.7912, 2065.9610, 2060.8167, 1986.6564],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1347 was 98.6%\n",
      "current params: tensor([  17.5685,   16.3299,  402.4679, 2066.7378, 2061.5907, 1987.2539],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1348 was 98.6%\n",
      "current params: tensor([  17.5603,   16.3201,  403.1447, 2067.5148, 2062.3649, 1987.8516],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1349 was 98.6%\n",
      "current params: tensor([  17.5521,   16.3103,  403.8216, 2068.2919, 2063.1393, 1988.4494],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1350 was 98.6%\n",
      "current params: tensor([  17.5439,   16.3005,  404.4986, 2069.0692, 2063.9139, 1989.0475],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1351 was 98.6%\n",
      "current params: tensor([  17.5356,   16.2906,  405.1757, 2069.8466, 2064.6888, 1989.6457],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1352 was 98.6%\n",
      "current params: tensor([  17.5273,   16.2807,  405.8529, 2070.6242, 2065.4638, 1990.2441],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1353 was 98.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  17.5190,   16.2707,  406.5302, 2071.4019, 2066.2390, 1990.8427],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1354 was 98.6%\n",
      "current params: tensor([  17.5106,   16.2607,  407.2076, 2072.1798, 2067.0144, 1991.4415],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1355 was 98.6%\n",
      "current params: tensor([  17.5022,   16.2507,  407.8851, 2072.9578, 2067.7900, 1992.0404],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1356 was 98.6%\n",
      "current params: tensor([  17.4938,   16.2406,  408.5627, 2073.7359, 2068.5658, 1992.6395],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1357 was 98.6%\n",
      "current params: tensor([  17.4853,   16.2305,  409.2404, 2074.5142, 2069.3418, 1993.2388],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1358 was 98.6%\n",
      "current params: tensor([  17.4768,   16.2203,  409.9182, 2075.2926, 2070.1180, 1993.8383],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1359 was 98.6%\n",
      "current params: tensor([  17.4682,   16.2101,  410.5961, 2076.0711, 2070.8943, 1994.4379],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1360 was 98.6%\n",
      "current params: tensor([  17.4597,   16.1998,  411.2740, 2076.8498, 2071.6709, 1995.0377],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1361 was 98.6%\n",
      "current params: tensor([  17.4510,   16.1895,  411.9521, 2077.6285, 2072.4476, 1995.6376],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1362 was 98.7%\n",
      "current params: tensor([  17.4424,   16.1791,  412.6302, 2078.4074, 2073.2245, 1996.2377],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1363 was 98.7%\n",
      "current params: tensor([  17.4337,   16.1687,  413.3085, 2079.1865, 2074.0015, 1996.8380],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1364 was 98.7%\n",
      "current params: tensor([  17.4250,   16.1583,  413.9868, 2079.9656, 2074.7788, 1997.4384],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1365 was 98.7%\n",
      "current params: tensor([  17.4162,   16.1478,  414.6652, 2080.7448, 2075.5562, 1998.0389],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1366 was 98.7%\n",
      "current params: tensor([  17.4074,   16.1373,  415.3436, 2081.5242, 2076.3337, 1998.6396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1367 was 98.7%\n",
      "current params: tensor([  17.3986,   16.1267,  416.0222, 2082.3036, 2077.1115, 1999.2405],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1368 was 98.7%\n",
      "current params: tensor([  17.3898,   16.1161,  416.7008, 2083.0832, 2077.8893, 1999.8414],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1369 was 98.7%\n",
      "current params: tensor([  17.3809,   16.1054,  417.3795, 2083.8629, 2078.6674, 2000.4426],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1370 was 98.7%\n",
      "current params: tensor([  17.3719,   16.0947,  418.0583, 2084.6426, 2079.4456, 2001.0438],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1371 was 98.7%\n",
      "current params: tensor([  17.3630,   16.0840,  418.7372, 2085.4225, 2080.2239, 2001.6452],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1372 was 98.7%\n",
      "current params: tensor([  17.3539,   16.0732,  419.4161, 2086.2025, 2081.0025, 2002.2467],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1373 was 98.7%\n",
      "current params: tensor([  17.3449,   16.0623,  420.0951, 2086.9825, 2081.7811, 2002.8483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1374 was 98.7%\n",
      "current params: tensor([  17.3358,   16.0514,  420.7742, 2087.7627, 2082.5599, 2003.4501],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1375 was 98.7%\n",
      "current params: tensor([  17.3267,   16.0405,  421.4533, 2088.5429, 2083.3388, 2004.0520],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1376 was 98.7%\n",
      "current params: tensor([  17.3176,   16.0295,  422.1325, 2089.3232, 2084.1179, 2004.6540],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1377 was 98.7%\n",
      "current params: tensor([  17.3084,   16.0184,  422.8118, 2090.1036, 2084.8972, 2005.2561],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1378 was 98.7%\n",
      "current params: tensor([  17.2991,   16.0074,  423.4912, 2090.8841, 2085.6765, 2005.8584],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1379 was 98.7%\n",
      "current params: tensor([  17.2899,   15.9962,  424.1706, 2091.6647, 2086.4560, 2006.4607],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1380 was 98.7%\n",
      "current params: tensor([  17.2806,   15.9850,  424.8500, 2092.4453, 2087.2356, 2007.0632],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1381 was 98.7%\n",
      "current params: tensor([  17.2712,   15.9738,  425.5296, 2093.2260, 2088.0154, 2007.6657],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1382 was 98.7%\n",
      "current params: tensor([  17.2619,   15.9625,  426.2092, 2094.0068, 2088.7953, 2008.2684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1383 was 98.7%\n",
      "current params: tensor([  17.2524,   15.9512,  426.8888, 2094.7877, 2089.5753, 2008.8712],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1384 was 98.7%\n",
      "current params: tensor([  17.2430,   15.9398,  427.5685, 2095.5686, 2090.3554, 2009.4740],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1385 was 98.7%\n",
      "current params: tensor([  17.2335,   15.9284,  428.2483, 2096.3496, 2091.1357, 2010.0770],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1386 was 98.7%\n",
      "current params: tensor([  17.2240,   15.9169,  428.9281, 2097.1306, 2091.9161, 2010.6800],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1387 was 98.7%\n",
      "current params: tensor([  17.2144,   15.9054,  429.6080, 2097.9117, 2092.6965, 2011.2831],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1388 was 98.7%\n",
      "current params: tensor([  17.2048,   15.8939,  430.2879, 2098.6929, 2093.4771, 2011.8864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1389 was 98.7%\n",
      "current params: tensor([  17.1951,   15.8822,  430.9678, 2099.4741, 2094.2578, 2012.4897],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1390 was 98.7%\n",
      "current params: tensor([  17.1855,   15.8706,  431.6479, 2100.2554, 2095.0387, 2013.0931],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1391 was 98.7%\n",
      "current params: tensor([  17.1757,   15.8588,  432.3279, 2101.0367, 2095.8196, 2013.6965],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1392 was 98.7%\n",
      "current params: tensor([  17.1660,   15.8471,  433.0080, 2101.8181, 2096.6006, 2014.3001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1393 was 98.7%\n",
      "current params: tensor([  17.1562,   15.8353,  433.6882, 2102.5995, 2097.3818, 2014.9037],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1394 was 98.7%\n",
      "current params: tensor([  17.1463,   15.8234,  434.3684, 2103.3809, 2098.1630, 2015.5073],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1395 was 98.7%\n",
      "current params: tensor([  17.1365,   15.8115,  435.0486, 2104.1624, 2098.9443, 2016.1111],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1396 was 98.7%\n",
      "current params: tensor([  17.1265,   15.7995,  435.7289, 2104.9440, 2099.7257, 2016.7149],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1397 was 98.7%\n",
      "current params: tensor([  17.1166,   15.7875,  436.4092, 2105.7255, 2100.5072, 2017.3188],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1398 was 98.7%\n",
      "current params: tensor([  17.1066,   15.7754,  437.0896, 2106.5071, 2101.2889, 2017.9227],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1399 was 98.7%\n",
      "current params: tensor([  17.0965,   15.7632,  437.7700, 2107.2888, 2102.0705, 2018.5267],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1400 was 98.7%\n",
      "current params: tensor([  17.0864,   15.7511,  438.4504, 2108.0704, 2102.8523, 2019.1307],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1401 was 98.7%\n",
      "current params: tensor([  17.0763,   15.7388,  439.1308, 2108.8521, 2103.6342, 2019.7348],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1402 was 98.7%\n",
      "current params: tensor([  17.0662,   15.7265,  439.8113, 2109.6338, 2104.4161, 2020.3389],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1403 was 98.7%\n",
      "current params: tensor([  17.0559,   15.7142,  440.4918, 2110.4156, 2105.1981, 2020.9431],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1404 was 98.7%\n",
      "current params: tensor([  17.0457,   15.7018,  441.1723, 2111.1973, 2105.9802, 2021.5473],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1405 was 98.7%\n",
      "current params: tensor([  17.0354,   15.6894,  441.8529, 2111.9791, 2106.7624, 2022.1515],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1406 was 98.7%\n",
      "current params: tensor([  17.0251,   15.6769,  442.5335, 2112.7608, 2107.5447, 2022.7558],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1407 was 98.7%\n",
      "current params: tensor([  17.0147,   15.6643,  443.2141, 2113.5426, 2108.3270, 2023.3601],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1408 was 98.7%\n",
      "current params: tensor([  17.0043,   15.6517,  443.8947, 2114.3244, 2109.1093, 2023.9645],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1409 was 98.7%\n",
      "current params: tensor([  16.9938,   15.6390,  444.5754, 2115.1062, 2109.8918, 2024.5688],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1410 was 98.7%\n",
      "current params: tensor([  16.9833,   15.6263,  445.2561, 2115.8880, 2110.6743, 2025.1732],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1411 was 98.7%\n",
      "current params: tensor([  16.9728,   15.6135,  445.9367, 2116.6698, 2111.4569, 2025.7776],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1412 was 98.7%\n",
      "current params: tensor([  16.9622,   15.6007,  446.6174, 2117.4517, 2112.2395, 2026.3820],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1413 was 98.7%\n",
      "current params: tensor([  16.9516,   15.5878,  447.2982, 2118.2335, 2113.0222, 2026.9865],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1414 was 98.7%\n",
      "current params: tensor([  16.9409,   15.5749,  447.9789, 2119.0153, 2113.8049, 2027.5909],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1415 was 98.7%\n",
      "current params: tensor([  16.9302,   15.5619,  448.6596, 2119.7970, 2114.5877, 2028.1954],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1416 was 98.8%\n",
      "current params: tensor([  16.9195,   15.5488,  449.3404, 2120.5788, 2115.3705, 2028.7998],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1417 was 98.8%\n",
      "current params: tensor([  16.9087,   15.5357,  450.0211, 2121.3606, 2116.1534, 2029.4043],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1418 was 98.8%\n",
      "current params: tensor([  16.8978,   15.5225,  450.7019, 2122.1423, 2116.9363, 2030.0088],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1419 was 98.8%\n",
      "current params: tensor([  16.8869,   15.5093,  451.3826, 2122.9241, 2117.7193, 2030.6132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1420 was 98.8%\n",
      "current params: tensor([  16.8760,   15.4960,  452.0634, 2123.7058, 2118.5023, 2031.2176],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1421 was 98.8%\n",
      "current params: tensor([  16.8651,   15.4827,  452.7442, 2124.4875, 2119.2853, 2031.8221],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1422 was 98.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  16.8540,   15.4693,  453.4249, 2125.2692, 2120.0684, 2032.4265],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1423 was 98.8%\n",
      "current params: tensor([  16.8430,   15.4558,  454.1057, 2126.0508, 2120.8515, 2033.0309],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1424 was 98.8%\n",
      "current params: tensor([  16.8319,   15.4423,  454.7864, 2126.8324, 2121.6346, 2033.6353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1425 was 98.8%\n",
      "current params: tensor([  16.8207,   15.4288,  455.4672, 2127.6140, 2122.4178, 2034.2396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1426 was 98.8%\n",
      "current params: tensor([  16.8095,   15.4151,  456.1479, 2128.3955, 2123.2010, 2034.8440],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1427 was 98.8%\n",
      "current params: tensor([  16.7983,   15.4014,  456.8286, 2129.1770, 2123.9842, 2035.4483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1428 was 98.8%\n",
      "current params: tensor([  16.7870,   15.3877,  457.5093, 2129.9585, 2124.7675, 2036.0525],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1429 was 98.8%\n",
      "current params: tensor([  16.7757,   15.3739,  458.1901, 2130.7399, 2125.5507, 2036.6568],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1430 was 98.8%\n",
      "current params: tensor([  16.7643,   15.3600,  458.8707, 2131.5213, 2126.3340, 2037.2609],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1431 was 98.8%\n",
      "current params: tensor([  16.7529,   15.3461,  459.5514, 2132.3026, 2127.1173, 2037.8651],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1432 was 98.8%\n",
      "current params: tensor([  16.7414,   15.3321,  460.2321, 2133.0839, 2127.9006, 2038.4692],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1433 was 98.8%\n",
      "current params: tensor([  16.7299,   15.3180,  460.9127, 2133.8651, 2128.6839, 2039.0732],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1434 was 98.8%\n",
      "current params: tensor([  16.7184,   15.3039,  461.5933, 2134.6463, 2129.4672, 2039.6772],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1435 was 98.8%\n",
      "current params: tensor([  16.7067,   15.2898,  462.2739, 2135.4274, 2130.2505, 2040.2812],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1436 was 98.8%\n",
      "current params: tensor([  16.6951,   15.2755,  462.9545, 2136.2085, 2131.0338, 2040.8851],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1437 was 98.8%\n",
      "current params: tensor([  16.6834,   15.2612,  463.6350, 2136.9895, 2131.8172, 2041.4889],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1438 was 98.8%\n",
      "current params: tensor([  16.6717,   15.2469,  464.3155, 2137.7704, 2132.6005, 2042.0927],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1439 was 98.8%\n",
      "current params: tensor([  16.6599,   15.2324,  464.9960, 2138.5513, 2133.3838, 2042.6963],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1440 was 98.8%\n",
      "current params: tensor([  16.6480,   15.2180,  465.6764, 2139.3321, 2134.1671, 2043.3000],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1441 was 98.8%\n",
      "current params: tensor([  16.6361,   15.2034,  466.3568, 2140.1128, 2134.9504, 2043.9035],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1442 was 98.8%\n",
      "current params: tensor([  16.6242,   15.1888,  467.0372, 2140.8935, 2135.7337, 2044.5070],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1443 was 98.8%\n",
      "current params: tensor([  16.6122,   15.1741,  467.7175, 2141.6741, 2136.5170, 2045.1103],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1444 was 98.8%\n",
      "current params: tensor([  16.6002,   15.1594,  468.3978, 2142.4546, 2137.3003, 2045.7136],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1445 was 98.8%\n",
      "current params: tensor([  16.5881,   15.1446,  469.0781, 2143.2350, 2138.0835, 2046.3168],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1446 was 98.8%\n",
      "current params: tensor([  16.5760,   15.1297,  469.7583, 2144.0153, 2138.8667, 2046.9199],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1447 was 98.8%\n",
      "current params: tensor([  16.5638,   15.1148,  470.4384, 2144.7956, 2139.6499, 2047.5230],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1448 was 98.8%\n",
      "current params: tensor([  16.5516,   15.0998,  471.1185, 2145.5757, 2140.4331, 2048.1259],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1449 was 98.8%\n",
      "current params: tensor([  16.5393,   15.0847,  471.7986, 2146.3558, 2141.2163, 2048.7287],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1450 was 98.8%\n",
      "current params: tensor([  16.5270,   15.0696,  472.4786, 2147.1358, 2141.9994, 2049.3314],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1451 was 98.8%\n",
      "current params: tensor([  16.5146,   15.0544,  473.1586, 2147.9156, 2142.7825, 2049.9340],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1452 was 98.8%\n",
      "current params: tensor([  16.5022,   15.0391,  473.8385, 2148.6954, 2143.5655, 2050.5365],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1453 was 98.8%\n",
      "current params: tensor([  16.4898,   15.0238,  474.5183, 2149.4751, 2144.3486, 2051.1389],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1454 was 98.8%\n",
      "current params: tensor([  16.4772,   15.0084,  475.1981, 2150.2547, 2145.1315, 2051.7411],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1455 was 98.8%\n",
      "current params: tensor([  16.4647,   14.9929,  475.8778, 2151.0341, 2145.9145, 2052.3432],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1456 was 98.8%\n",
      "current params: tensor([  16.4521,   14.9774,  476.5575, 2151.8135, 2146.6974, 2052.9452],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1457 was 98.8%\n",
      "current params: tensor([  16.4394,   14.9618,  477.2371, 2152.5927, 2147.4802, 2053.5471],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1458 was 98.8%\n",
      "current params: tensor([  16.4267,   14.9461,  477.9166, 2153.3718, 2148.2630, 2054.1488],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1459 was 98.8%\n",
      "current params: tensor([  16.4139,   14.9304,  478.5961, 2154.1508, 2149.0458, 2054.7504],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1460 was 98.8%\n",
      "current params: tensor([  16.4011,   14.9146,  479.2755, 2154.9297, 2149.8285, 2055.3519],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1461 was 98.8%\n",
      "current params: tensor([  16.3882,   14.8987,  479.9548, 2155.7085, 2150.6111, 2055.9532],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1462 was 98.8%\n",
      "current params: tensor([  16.3753,   14.8828,  480.6340, 2156.4871, 2151.3937, 2056.5544],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1463 was 98.8%\n",
      "current params: tensor([  16.3623,   14.8668,  481.3132, 2157.2657, 2152.1762, 2057.1554],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1464 was 98.8%\n",
      "current params: tensor([  16.3493,   14.8507,  481.9923, 2158.0440, 2152.9587, 2057.7562],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1465 was 98.8%\n",
      "current params: tensor([  16.3362,   14.8345,  482.6713, 2158.8223, 2153.7411, 2058.3569],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1466 was 98.8%\n",
      "current params: tensor([  16.3231,   14.8183,  483.3502, 2159.6004, 2154.5234, 2058.9575],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1467 was 98.8%\n",
      "current params: tensor([  16.3099,   14.8020,  484.0290, 2160.3784, 2155.3057, 2059.5578],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1468 was 98.9%\n",
      "current params: tensor([  16.2967,   14.7856,  484.7078, 2161.1562, 2156.0879, 2060.1580],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1469 was 98.9%\n",
      "current params: tensor([  16.2834,   14.7692,  485.3864, 2161.9339, 2156.8700, 2060.7581],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1470 was 98.9%\n",
      "current params: tensor([  16.2700,   14.7527,  486.0650, 2162.7115, 2157.6520, 2061.3579],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1471 was 98.9%\n",
      "current params: tensor([  16.2566,   14.7361,  486.7435, 2163.4889, 2158.4340, 2061.9576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1472 was 98.9%\n",
      "current params: tensor([  16.2432,   14.7194,  487.4218, 2164.2661, 2159.2159, 2062.5570],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1473 was 98.9%\n",
      "current params: tensor([  16.2297,   14.7027,  488.1001, 2165.0432, 2159.9977, 2063.1563],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1474 was 98.9%\n",
      "current params: tensor([  16.2162,   14.6859,  488.7783, 2165.8201, 2160.7794, 2063.7554],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1475 was 98.9%\n",
      "current params: tensor([  16.2025,   14.6690,  489.4564, 2166.5969, 2161.5610, 2064.3543],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1476 was 98.9%\n",
      "current params: tensor([  16.1889,   14.6520,  490.1343, 2167.3735, 2162.3425, 2064.9530],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1477 was 98.9%\n",
      "current params: tensor([  16.1752,   14.6350,  490.8122, 2168.1500, 2163.1240, 2065.5515],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1478 was 98.9%\n",
      "current params: tensor([  16.1614,   14.6179,  491.4899, 2168.9262, 2163.9053, 2066.1498],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1479 was 98.9%\n",
      "current params: tensor([  16.1476,   14.6007,  492.1676, 2169.7024, 2164.6866, 2066.7479],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1480 was 98.9%\n",
      "current params: tensor([  16.1337,   14.5834,  492.8451, 2170.4783, 2165.4677, 2067.3458],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1481 was 98.9%\n",
      "current params: tensor([  16.1198,   14.5661,  493.5225, 2171.2541, 2166.2487, 2067.9434],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1482 was 98.9%\n",
      "current params: tensor([  16.1058,   14.5487,  494.1998, 2172.0296, 2167.0297, 2068.5408],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1483 was 98.9%\n",
      "current params: tensor([  16.0918,   14.5312,  494.8770, 2172.8050, 2167.8105, 2069.1380],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1484 was 98.9%\n",
      "current params: tensor([  16.0777,   14.5136,  495.5540, 2173.5802, 2168.5912, 2069.7350],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1485 was 98.9%\n",
      "current params: tensor([  16.0635,   14.4960,  496.2310, 2174.3553, 2169.3718, 2070.3317],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1486 was 98.9%\n",
      "current params: tensor([  16.0493,   14.4783,  496.9078, 2175.1301, 2170.1523, 2070.9282],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1487 was 98.9%\n",
      "current params: tensor([  16.0350,   14.4605,  497.5844, 2175.9048, 2170.9327, 2071.5244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1488 was 98.9%\n",
      "current params: tensor([  16.0207,   14.4426,  498.2610, 2176.6792, 2171.7129, 2072.1204],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1489 was 98.9%\n",
      "current params: tensor([  16.0063,   14.4246,  498.9374, 2177.4535, 2172.4930, 2072.7162],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1490 was 98.9%\n",
      "current params: tensor([  15.9919,   14.4066,  499.6136, 2178.2275, 2173.2730, 2073.3117],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1491 was 98.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  15.9774,   14.3885,  500.2897, 2179.0013, 2174.0529, 2073.9069],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1492 was 98.9%\n",
      "current params: tensor([  15.9629,   14.3703,  500.9657, 2179.7750, 2174.8327, 2074.5019],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1493 was 98.9%\n",
      "current params: tensor([  15.9483,   14.3520,  501.6416, 2180.5484, 2175.6123, 2075.0966],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1494 was 98.9%\n",
      "current params: tensor([  15.9336,   14.3337,  502.3172, 2181.3216, 2176.3917, 2075.6910],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1495 was 98.9%\n",
      "current params: tensor([  15.9189,   14.3152,  502.9928, 2182.0946, 2177.1711, 2076.2852],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1496 was 98.9%\n",
      "current params: tensor([  15.9041,   14.2967,  503.6682, 2182.8674, 2177.9503, 2076.8790],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1497 was 98.9%\n",
      "current params: tensor([  15.8893,   14.2781,  504.3434, 2183.6400, 2178.7293, 2077.4726],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1498 was 98.9%\n",
      "current params: tensor([  15.8744,   14.2594,  505.0185, 2184.4123, 2179.5082, 2078.0659],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1499 was 98.9%\n",
      "current params: tensor([  15.8594,   14.2406,  505.6934, 2185.1844, 2180.2870, 2078.6589],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1500 was 98.9%\n",
      "current params: tensor([  15.8444,   14.2218,  506.3681, 2185.9563, 2181.0656, 2079.2516],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1501 was 98.9%\n",
      "current params: tensor([  15.8294,   14.2028,  507.0427, 2186.7279, 2181.8440, 2079.8440],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1502 was 98.9%\n",
      "current params: tensor([  15.8142,   14.1838,  507.7172, 2187.4993, 2182.6223, 2080.4361],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1503 was 98.9%\n",
      "current params: tensor([  15.7990,   14.1647,  508.3914, 2188.2705, 2183.4005, 2081.0279],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1504 was 98.9%\n",
      "current params: tensor([  15.7838,   14.1455,  509.0655, 2189.0414, 2184.1784, 2081.6194],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1505 was 98.9%\n",
      "current params: tensor([  15.7685,   14.1262,  509.7394, 2189.8120, 2184.9563, 2082.2106],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1506 was 98.9%\n",
      "current params: tensor([  15.7531,   14.1068,  510.4131, 2190.5825, 2185.7339, 2082.8014],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1507 was 98.9%\n",
      "current params: tensor([  15.7377,   14.0874,  511.0867, 2191.3526, 2186.5114, 2083.3919],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1508 was 98.9%\n",
      "current params: tensor([  15.7222,   14.0678,  511.7600, 2192.1225, 2187.2887, 2083.9821],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1509 was 98.9%\n",
      "current params: tensor([  15.7067,   14.0482,  512.4332, 2192.8922, 2188.0658, 2084.5719],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1510 was 98.9%\n",
      "current params: tensor([  15.6911,   14.0285,  513.1062, 2193.6616, 2188.8428, 2085.1614],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1511 was 98.9%\n",
      "current params: tensor([  15.6754,   14.0087,  513.7790, 2194.4307, 2189.6195, 2085.7506],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1512 was 98.9%\n",
      "current params: tensor([  15.6597,   13.9888,  514.4516, 2195.1996, 2190.3961, 2086.3394],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1513 was 98.9%\n",
      "current params: tensor([  15.6439,   13.9688,  515.1240, 2195.9681, 2191.1725, 2086.9279],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1514 was 98.9%\n",
      "current params: tensor([  15.6280,   13.9487,  515.7963, 2196.7365, 2191.9488, 2087.5160],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1515 was 98.9%\n",
      "current params: tensor([  15.6121,   13.9286,  516.4683, 2197.5045, 2192.7248, 2088.1037],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1516 was 98.9%\n",
      "current params: tensor([  15.5962,   13.9083,  517.1401, 2198.2722, 2193.5006, 2088.6911],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1517 was 98.9%\n",
      "current params: tensor([  15.5801,   13.8880,  517.8117, 2199.0397, 2194.2763, 2089.2781],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1518 was 98.9%\n",
      "current params: tensor([  15.5640,   13.8675,  518.4831, 2199.8069, 2195.0517, 2089.8647],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1519 was 99.0%\n",
      "current params: tensor([  15.5479,   13.8470,  519.1542, 2200.5738, 2195.8269, 2090.4509],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1520 was 99.0%\n",
      "current params: tensor([  15.5317,   13.8264,  519.8252, 2201.3404, 2196.6020, 2091.0368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1521 was 99.0%\n",
      "current params: tensor([  15.5154,   13.8057,  520.4959, 2202.1067, 2197.3768, 2091.6222],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1522 was 99.0%\n",
      "current params: tensor([  15.4990,   13.7848,  521.1664, 2202.8727, 2198.1514, 2092.2073],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1523 was 99.0%\n",
      "current params: tensor([  15.4826,   13.7639,  521.8367, 2203.6383, 2198.9258, 2092.7919],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1524 was 99.0%\n",
      "current params: tensor([  15.4661,   13.7429,  522.5068, 2204.4037, 2199.7000, 2093.3762],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1525 was 99.0%\n",
      "current params: tensor([  15.4496,   13.7219,  523.1766, 2205.1688, 2200.4739, 2093.9600],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1526 was 99.0%\n",
      "current params: tensor([  15.4330,   13.7007,  523.8462, 2205.9335, 2201.2477, 2094.5435],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1527 was 99.0%\n",
      "current params: tensor([  15.4163,   13.6794,  524.5156, 2206.6980, 2202.0212, 2095.1265],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1528 was 99.0%\n",
      "current params: tensor([  15.3996,   13.6580,  525.1847, 2207.4621, 2202.7945, 2095.7091],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1529 was 99.0%\n",
      "current params: tensor([  15.3828,   13.6365,  525.8536, 2208.2259, 2203.5676, 2096.2912],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1530 was 99.0%\n",
      "current params: tensor([  15.3660,   13.6150,  526.5222, 2208.9893, 2204.3404, 2096.8729],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1531 was 99.0%\n",
      "current params: tensor([  15.3490,   13.5933,  527.1906, 2209.7525, 2205.1130, 2097.4542],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1532 was 99.0%\n",
      "current params: tensor([  15.3321,   13.5715,  527.8587, 2210.5152, 2205.8854, 2098.0351],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1533 was 99.0%\n",
      "current params: tensor([  15.3150,   13.5496,  528.5266, 2211.2777, 2206.6575, 2098.6155],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1534 was 99.0%\n",
      "current params: tensor([  15.2979,   13.5277,  529.1942, 2212.0398, 2207.4293, 2099.1954],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1535 was 99.0%\n",
      "current params: tensor([  15.2807,   13.5056,  529.8616, 2212.8016, 2208.2010, 2099.7749],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1536 was 99.0%\n",
      "current params: tensor([  15.2635,   13.4834,  530.5287, 2213.5630, 2208.9723, 2100.3539],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1537 was 99.0%\n",
      "current params: tensor([  15.2462,   13.4612,  531.1955, 2214.3240, 2209.7435, 2100.9324],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1538 was 99.0%\n",
      "current params: tensor([  15.2288,   13.4388,  531.8620, 2215.0847, 2210.5143, 2101.5105],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1539 was 99.0%\n",
      "current params: tensor([  15.2113,   13.4163,  532.5283, 2215.8450, 2211.2849, 2102.0881],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1540 was 99.0%\n",
      "current params: tensor([  15.1938,   13.3938,  533.1943, 2216.6050, 2212.0553, 2102.6652],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1541 was 99.0%\n",
      "current params: tensor([  15.1762,   13.3711,  533.8600, 2217.3646, 2212.8253, 2103.2418],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1542 was 99.0%\n",
      "current params: tensor([  15.1586,   13.3483,  534.5255, 2218.1238, 2213.5951, 2103.8179],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1543 was 99.0%\n",
      "current params: tensor([  15.1409,   13.3254,  535.1906, 2218.8827, 2214.3647, 2104.3935],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1544 was 99.0%\n",
      "current params: tensor([  15.1231,   13.3024,  535.8554, 2219.6411, 2215.1339, 2104.9687],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1545 was 99.0%\n",
      "current params: tensor([  15.1053,   13.2793,  536.5200, 2220.3992, 2215.9029, 2105.5433],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1546 was 99.0%\n",
      "current params: tensor([  15.0873,   13.2561,  537.1843, 2221.1569, 2216.6716, 2106.1173],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1547 was 99.0%\n",
      "current params: tensor([  15.0694,   13.2328,  537.8482, 2221.9142, 2217.4400, 2106.6909],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1548 was 99.0%\n",
      "current params: tensor([  15.0513,   13.2094,  538.5119, 2222.6711, 2218.2081, 2107.2639],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1549 was 99.0%\n",
      "current params: tensor([  15.0332,   13.1859,  539.1752, 2223.4276, 2218.9760, 2107.8364],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1550 was 99.0%\n",
      "current params: tensor([  15.0150,   13.1622,  539.8382, 2224.1837, 2219.7435, 2108.4084],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1551 was 99.0%\n",
      "current params: tensor([  14.9968,   13.1385,  540.5009, 2224.9393, 2220.5108, 2108.9798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1552 was 99.0%\n",
      "current params: tensor([  14.9784,   13.1146,  541.1633, 2225.6946, 2221.2777, 2109.5507],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1553 was 99.0%\n",
      "current params: tensor([  14.9600,   13.0907,  541.8254, 2226.4495, 2222.0443, 2110.1210],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1554 was 99.0%\n",
      "current params: tensor([  14.9416,   13.0666,  542.4871, 2227.2039, 2222.8107, 2110.6907],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1555 was 99.0%\n",
      "current params: tensor([  14.9231,   13.0424,  543.1485, 2227.9579, 2223.5767, 2111.2599],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1556 was 99.0%\n",
      "current params: tensor([  14.9045,   13.0181,  543.8096, 2228.7114, 2224.3424, 2111.8285],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1557 was 99.0%\n",
      "current params: tensor([  14.8858,   12.9937,  544.4703, 2229.4646, 2225.1078, 2112.3966],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1558 was 99.0%\n",
      "current params: tensor([  14.8670,   12.9692,  545.1307, 2230.2173, 2225.8729, 2112.9640],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1559 was 99.0%\n",
      "current params: tensor([  14.8482,   12.9446,  545.7908, 2230.9695, 2226.6376, 2113.5309],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1560 was 99.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  14.8294,   12.9198,  546.4505, 2231.7213, 2227.4020, 2114.0972],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1561 was 99.0%\n",
      "current params: tensor([  14.8104,   12.8950,  547.1098, 2232.4727, 2228.1661, 2114.6628],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1562 was 99.0%\n",
      "current params: tensor([  14.7914,   12.8700,  547.7688, 2233.2236, 2228.9299, 2115.2279],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1563 was 99.0%\n",
      "current params: tensor([  14.7723,   12.8449,  548.4274, 2233.9740, 2229.6933, 2115.7923],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1564 was 99.0%\n",
      "current params: tensor([  14.7531,   12.8197,  549.0857, 2234.7240, 2230.4564, 2116.3561],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1565 was 99.0%\n",
      "current params: tensor([  14.7339,   12.7944,  549.7436, 2235.4735, 2231.2191, 2116.9194],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1566 was 99.1%\n",
      "current params: tensor([  14.7146,   12.7689,  550.4011, 2236.2225, 2231.9815, 2117.4819],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1567 was 99.1%\n",
      "current params: tensor([  14.6952,   12.7434,  551.0582, 2236.9710, 2232.7435, 2118.0439],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1568 was 99.1%\n",
      "current params: tensor([  14.6758,   12.7177,  551.7150, 2237.7191, 2233.5052, 2118.6051],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1569 was 99.1%\n",
      "current params: tensor([  14.6563,   12.6919,  552.3714, 2238.4667, 2234.2665, 2119.1658],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1570 was 99.1%\n",
      "current params: tensor([  14.6367,   12.6659,  553.0273, 2239.2137, 2235.0275, 2119.7258],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1571 was 99.1%\n",
      "current params: tensor([  14.6170,   12.6399,  553.6829, 2239.9603, 2235.7880, 2120.2851],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1572 was 99.1%\n",
      "current params: tensor([  14.5973,   12.6137,  554.3381, 2240.7064, 2236.5483, 2120.8438],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1573 was 99.1%\n",
      "current params: tensor([  14.5775,   12.5874,  554.9929, 2241.4519, 2237.3081, 2121.4017],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1574 was 99.1%\n",
      "current params: tensor([  14.5576,   12.5610,  555.6473, 2242.1970, 2238.0676, 2121.9590],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1575 was 99.1%\n",
      "current params: tensor([  14.5377,   12.5345,  556.3013, 2242.9415, 2238.8267, 2122.5157],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1576 was 99.1%\n",
      "current params: tensor([  14.5176,   12.5078,  556.9548, 2243.6855, 2239.5854, 2123.0716],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1577 was 99.1%\n",
      "current params: tensor([  14.4976,   12.4810,  557.6080, 2244.4290, 2240.3437, 2123.6268],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1578 was 99.1%\n",
      "current params: tensor([  14.4774,   12.4541,  558.2607, 2245.1720, 2241.1016, 2124.1813],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1579 was 99.1%\n",
      "current params: tensor([  14.4571,   12.4271,  558.9130, 2245.9144, 2241.8591, 2124.7351],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1580 was 99.1%\n",
      "current params: tensor([  14.4368,   12.3999,  559.5648, 2246.6562, 2242.6162, 2125.2882],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1581 was 99.1%\n",
      "current params: tensor([  14.4164,   12.3726,  560.2162, 2247.3975, 2243.3730, 2125.8406],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1582 was 99.1%\n",
      "current params: tensor([  14.3960,   12.3452,  560.8672, 2248.1383, 2244.1293, 2126.3922],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1583 was 99.1%\n",
      "current params: tensor([  14.3754,   12.3176,  561.5177, 2248.8785, 2244.8852, 2126.9431],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1584 was 99.1%\n",
      "current params: tensor([  14.3548,   12.2899,  562.1678, 2249.6181, 2245.6407, 2127.4932],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1585 was 99.1%\n",
      "current params: tensor([  14.3342,   12.2621,  562.8174, 2250.3572, 2246.3957, 2128.0426],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1586 was 99.1%\n",
      "current params: tensor([  14.3134,   12.2342,  563.4666, 2251.0957, 2247.1504, 2128.5912],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1587 was 99.1%\n",
      "current params: tensor([  14.2926,   12.2061,  564.1153, 2251.8336, 2247.9046, 2129.1391],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1588 was 99.1%\n",
      "current params: tensor([  14.2717,   12.1779,  564.7635, 2252.5709, 2248.6584, 2129.6862],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1589 was 99.1%\n",
      "current params: tensor([  14.2507,   12.1495,  565.4112, 2253.3077, 2249.4117, 2130.2325],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1590 was 99.1%\n",
      "current params: tensor([  14.2296,   12.1210,  566.0585, 2254.0438, 2250.1646, 2130.7780],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1591 was 99.1%\n",
      "current params: tensor([  14.2085,   12.0924,  566.7053, 2254.7793, 2250.9171, 2131.3227],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1592 was 99.1%\n",
      "current params: tensor([  14.1873,   12.0636,  567.3516, 2255.5142, 2251.6691, 2131.8667],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1593 was 99.1%\n",
      "current params: tensor([  14.1660,   12.0347,  567.9974, 2256.2485, 2252.4206, 2132.4098],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1594 was 99.1%\n",
      "current params: tensor([  14.1447,   12.0057,  568.6427, 2256.9822, 2253.1717, 2132.9521],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1595 was 99.1%\n",
      "current params: tensor([  14.1232,   11.9765,  569.2875, 2257.7152, 2253.9224, 2133.4936],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1596 was 99.1%\n",
      "current params: tensor([  14.1017,   11.9472,  569.9318, 2258.4477, 2254.6725, 2134.0342],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1597 was 99.1%\n",
      "current params: tensor([  14.0802,   11.9177,  570.5755, 2259.1794, 2255.4222, 2134.5740],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1598 was 99.1%\n",
      "current params: tensor([  14.0585,   11.8881,  571.2188, 2259.9106, 2256.1715, 2135.1130],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1599 was 99.1%\n",
      "current params: tensor([  14.0368,   11.8584,  571.8615, 2260.6410, 2256.9202, 2135.6511],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1600 was 99.1%\n",
      "current params: tensor([  14.0150,   11.8285,  572.5037, 2261.3709, 2257.6685, 2136.1883],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1601 was 99.1%\n",
      "current params: tensor([  13.9931,   11.7984,  573.1454, 2262.1000, 2258.4163, 2136.7247],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1602 was 99.1%\n",
      "current params: tensor([  13.9711,   11.7683,  573.7865, 2262.8285, 2259.1635, 2137.2602],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1603 was 99.1%\n",
      "current params: tensor([  13.9491,   11.7379,  574.4271, 2263.5563, 2259.9103, 2137.7949],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1604 was 99.1%\n",
      "current params: tensor([  13.9270,   11.7074,  575.0671, 2264.2834, 2260.6566, 2138.3286],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1605 was 99.1%\n",
      "current params: tensor([  13.9048,   11.6768,  575.7065, 2265.0099, 2261.4024, 2138.8614],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1606 was 99.1%\n",
      "current params: tensor([  13.8825,   11.6460,  576.3454, 2265.7356, 2262.1476, 2139.3934],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1607 was 99.1%\n",
      "current params: tensor([  13.8602,   11.6151,  576.9838, 2266.4606, 2262.8924, 2139.9244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1608 was 99.1%\n",
      "current params: tensor([  13.8378,   11.5840,  577.6215, 2267.1849, 2263.6366, 2140.4545],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1609 was 99.1%\n",
      "current params: tensor([  13.8153,   11.5528,  578.2587, 2267.9085, 2264.3803, 2140.9837],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1610 was 99.2%\n",
      "current params: tensor([  13.7927,   11.5214,  578.8953, 2268.6314, 2265.1235, 2141.5119],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1611 was 99.2%\n",
      "current params: tensor([  13.7701,   11.4899,  579.5313, 2269.3535, 2265.8661, 2142.0392],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1612 was 99.2%\n",
      "current params: tensor([  13.7474,   11.4582,  580.1667, 2270.0749, 2266.6082, 2142.5655],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1613 was 99.2%\n",
      "current params: tensor([  13.7246,   11.4263,  580.8014, 2270.7956, 2267.3497, 2143.0909],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1614 was 99.2%\n",
      "current params: tensor([  13.7017,   11.3943,  581.4356, 2271.5155, 2268.0907, 2143.6153],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1615 was 99.2%\n",
      "current params: tensor([  13.6788,   11.3621,  582.0692, 2272.2346, 2268.8311, 2144.1387],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1616 was 99.2%\n",
      "current params: tensor([  13.6557,   11.3298,  582.7021, 2272.9530, 2269.5710, 2144.6611],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1617 was 99.2%\n",
      "current params: tensor([  13.6326,   11.2973,  583.3344, 2273.6706, 2270.3103, 2145.1826],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1618 was 99.2%\n",
      "current params: tensor([  13.6095,   11.2647,  583.9661, 2274.3874, 2271.0490, 2145.7030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1619 was 99.2%\n",
      "current params: tensor([  13.5862,   11.2319,  584.5972, 2275.1034, 2271.7872, 2146.2224],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1620 was 99.2%\n",
      "current params: tensor([  13.5629,   11.1989,  585.2275, 2275.8187, 2272.5248, 2146.7408],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1621 was 99.2%\n",
      "current params: tensor([  13.5395,   11.1657,  585.8573, 2276.5331, 2273.2618, 2147.2582],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1622 was 99.2%\n",
      "current params: tensor([  13.5160,   11.1324,  586.4864, 2277.2467, 2273.9981, 2147.7746],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1623 was 99.2%\n",
      "current params: tensor([  13.4924,   11.0989,  587.1148, 2277.9595, 2274.7339, 2148.2898],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1624 was 99.2%\n",
      "current params: tensor([  13.4688,   11.0653,  587.7425, 2278.6714, 2275.4691, 2148.8041],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1625 was 99.2%\n",
      "current params: tensor([  13.4451,   11.0315,  588.3695, 2279.3825, 2276.2037, 2149.3172],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1626 was 99.2%\n",
      "current params: tensor([  13.4213,   10.9975,  588.9959, 2280.0928, 2276.9377, 2149.8293],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1627 was 99.2%\n",
      "current params: tensor([  13.3974,   10.9633,  589.6216, 2280.8022, 2277.6710, 2150.3404],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1628 was 99.2%\n",
      "current params: tensor([  13.3735,   10.9290,  590.2466, 2281.5107, 2278.4037, 2150.8503],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1629 was 99.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  13.3495,   10.8945,  590.8708, 2282.2184, 2279.1358, 2151.3591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1630 was 99.2%\n",
      "current params: tensor([  13.3254,   10.8598,  591.4944, 2282.9251, 2279.8672, 2151.8668],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1631 was 99.2%\n",
      "current params: tensor([  13.3012,   10.8249,  592.1172, 2283.6310, 2280.5980, 2152.3734],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1632 was 99.2%\n",
      "current params: tensor([  13.2770,   10.7899,  592.7393, 2284.3360, 2281.3281, 2152.8789],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1633 was 99.2%\n",
      "current params: tensor([  13.2527,   10.7547,  593.3606, 2285.0401, 2282.0576, 2153.3832],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1634 was 99.2%\n",
      "current params: tensor([  13.2283,   10.7193,  593.9812, 2285.7433, 2282.7864, 2153.8864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1635 was 99.2%\n",
      "current params: tensor([  13.2038,   10.6837,  594.6011, 2286.4455, 2283.5146, 2154.3884],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1636 was 99.2%\n",
      "current params: tensor([  13.1793,   10.6479,  595.2202, 2287.1468, 2284.2420, 2154.8892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1637 was 99.2%\n",
      "current params: tensor([  13.1546,   10.6120,  595.8386, 2287.8471, 2284.9688, 2155.3889],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1638 was 99.2%\n",
      "current params: tensor([  13.1300,   10.5758,  596.4561, 2288.5465, 2285.6949, 2155.8874],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1639 was 99.2%\n",
      "current params: tensor([  13.1052,   10.5395,  597.0729, 2289.2450, 2286.4203, 2156.3847],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1640 was 99.2%\n",
      "current params: tensor([  13.0803,   10.5030,  597.6889, 2289.9424, 2287.1450, 2156.8808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1641 was 99.2%\n",
      "current params: tensor([  13.0554,   10.4663,  598.3041, 2290.6389, 2287.8690, 2157.3756],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1642 was 99.2%\n",
      "current params: tensor([  13.0304,   10.4293,  598.9185, 2291.3343, 2288.5923, 2157.8693],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1643 was 99.2%\n",
      "current params: tensor([  13.0054,   10.3923,  599.5320, 2292.0288, 2289.3148, 2158.3617],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1644 was 99.2%\n",
      "current params: tensor([  12.9802,   10.3550,  600.1448, 2292.7222, 2290.0367, 2158.8528],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1645 was 99.2%\n",
      "current params: tensor([  12.9550,   10.3175,  600.7567, 2293.4146, 2290.7577, 2159.3427],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1646 was 99.2%\n",
      "current params: tensor([  12.9297,   10.2798,  601.3678, 2294.1060, 2291.4781, 2159.8313],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1647 was 99.2%\n",
      "current params: tensor([  12.9044,   10.2419,  601.9780, 2294.7963, 2292.1977, 2160.3187],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1648 was 99.2%\n",
      "current params: tensor([  12.8789,   10.2038,  602.5874, 2295.4856, 2292.9165, 2160.8048],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1649 was 99.2%\n",
      "current params: tensor([  12.8534,   10.1655,  603.1959, 2296.1738, 2293.6346, 2161.2895],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1650 was 99.2%\n",
      "current params: tensor([  12.8279,   10.1270,  603.8035, 2296.8609, 2294.3519, 2161.7730],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1651 was 99.3%\n",
      "current params: tensor([  12.8022,   10.0883,  604.4103, 2297.5469, 2295.0684, 2162.2551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1652 was 99.3%\n",
      "current params: tensor([  12.7765,   10.0494,  605.0161, 2298.2318, 2295.7841, 2162.7359],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1653 was 99.3%\n",
      "current params: tensor([  12.7507,   10.0102,  605.6211, 2298.9156, 2296.4990, 2163.2153],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1654 was 99.3%\n",
      "current params: tensor([  12.7248,    9.9709,  606.2252, 2299.5983, 2297.2131, 2163.6934],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1655 was 99.3%\n",
      "current params: tensor([  12.6989,   19.9704,  606.8283, 2300.2798, 2297.9265, 2164.1702],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1656 was 99.0%\n",
      "current params: tensor([  12.6542,   19.9702,  607.7153, 2301.2816, 2298.8388, 2165.0519],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1657 was 99.0%\n",
      "current params: tensor([  12.6092,   19.9699,  608.5997, 2302.2807, 2299.7481, 2165.9301],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1658 was 99.0%\n",
      "current params: tensor([  12.5639,   19.9697,  609.4814, 2303.2770, 2300.6546, 2166.8046],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1659 was 99.0%\n",
      "current params: tensor([  12.5183,   19.9695,  610.3606, 2304.2706, 2301.5580, 2167.6756],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1660 was 99.0%\n",
      "current params: tensor([  12.4724,   19.9692,  611.2372, 2305.2616, 2302.4586, 2168.5431],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1661 was 99.0%\n",
      "current params: tensor([  12.4263,   19.9690,  612.1112, 2306.2498, 2303.3562, 2169.4070],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1662 was 99.0%\n",
      "current params: tensor([  12.3799,   19.9687,  612.9826, 2307.2354, 2304.2509, 2170.2674],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1663 was 99.0%\n",
      "current params: tensor([  12.3331,   19.9685,  613.8515, 2308.2184, 2305.1428, 2171.1244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1664 was 99.0%\n",
      "current params: tensor([  12.2861,   19.9683,  614.7179, 2309.1988, 2306.0317, 2171.9778],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1665 was 99.0%\n",
      "current params: tensor([  12.2388,   19.9680,  615.5817, 2310.1765, 2306.9178, 2172.8279],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1666 was 99.0%\n",
      "current params: tensor([  12.1911,   19.9678,  616.4430, 2311.1517, 2307.8010, 2173.6745],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1667 was 99.0%\n",
      "current params: tensor([  12.1432,   19.9675,  617.3019, 2312.1244, 2308.6813, 2174.5177],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1668 was 99.0%\n",
      "current params: tensor([  12.0950,   19.9673,  618.1582, 2313.0945, 2309.5588, 2175.3575],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1669 was 99.0%\n",
      "current params: tensor([  12.0464,   19.9671,  619.0121, 2314.0621, 2310.4334, 2176.1939],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1670 was 99.0%\n",
      "current params: tensor([  11.9975,   19.9668,  619.8635, 2315.0271, 2311.3051, 2177.0270],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1671 was 99.0%\n",
      "current params: tensor([  11.9483,   19.9666,  620.7125, 2315.9897, 2312.1740, 2177.8567],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1672 was 99.0%\n",
      "current params: tensor([  11.8988,   19.9663,  621.5590, 2316.9498, 2313.0401, 2178.6830],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1673 was 99.0%\n",
      "current params: tensor([  11.8490,   19.9661,  622.4030, 2317.9074, 2313.9033, 2179.5060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1674 was 99.0%\n",
      "current params: tensor([  11.7988,   19.9659,  623.2447, 2318.8626, 2314.7636, 2180.3257],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1675 was 99.0%\n",
      "current params: tensor([  11.7483,   19.9656,  624.0839, 2319.8153, 2315.6211, 2181.1421],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1676 was 99.0%\n",
      "current params: tensor([  11.6975,   19.9654,  624.9206, 2320.7656, 2316.4758, 2181.9552],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1677 was 99.0%\n",
      "current params: tensor([  11.6463,   19.9651,  625.7550, 2321.7134, 2317.3277, 2182.7650],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1678 was 99.0%\n",
      "current params: tensor([  11.5948,   19.9649,  626.5869, 2322.6589, 2318.1766, 2183.5715],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1679 was 99.0%\n",
      "current params: tensor([  11.5429,   19.9646,  627.4165, 2323.6019, 2319.0228, 2184.3748],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1680 was 99.0%\n",
      "current params: tensor([  11.4907,   19.9644,  628.2436, 2324.5425, 2319.8661, 2185.1747],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1681 was 99.0%\n",
      "current params: tensor([  11.4381,   19.9642,  629.0683, 2325.4808, 2320.7065, 2185.9714],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1682 was 99.0%\n",
      "current params: tensor([  11.3852,   19.9639,  629.8907, 2326.4166, 2321.5441, 2186.7649],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1683 was 99.0%\n",
      "current params: tensor([  11.3319,   19.9637,  630.7106, 2327.3501, 2322.3789, 2187.5550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1684 was 99.0%\n",
      "current params: tensor([  11.2782,   19.9634,  631.5282, 2328.2812, 2323.2107, 2188.3420],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1685 was 99.1%\n",
      "current params: tensor([  11.2242,   19.9632,  632.3433, 2329.2100, 2324.0397, 2189.1256],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1686 was 99.1%\n",
      "current params: tensor([  11.1698,   19.9629,  633.1561, 2330.1364, 2324.8658, 2189.9060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1687 was 99.1%\n",
      "current params: tensor([  11.1150,   19.9627,  633.9664, 2331.0604, 2325.6891, 2190.6832],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1688 was 99.1%\n",
      "current params: tensor([  11.0598,   19.9625,  634.7744, 2331.9820, 2326.5094, 2191.4571],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1689 was 99.1%\n",
      "current params: tensor([  11.0043,   19.9622,  635.5800, 2332.9014, 2327.3269, 2192.2278],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1690 was 99.1%\n",
      "current params: tensor([  10.9483,   19.9620,  636.3832, 2333.8183, 2328.1414, 2192.9952],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1691 was 99.1%\n",
      "current params: tensor([  10.8920,   19.9617,  637.1839, 2334.7329, 2328.9530, 2193.7593],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1692 was 99.1%\n",
      "current params: tensor([  10.8352,   19.9615,  637.9823, 2335.6452, 2329.7617, 2194.5202],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1693 was 99.1%\n",
      "current params: tensor([  10.7781,   19.9612,  638.7783, 2336.5551, 2330.5675, 2195.2778],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1694 was 99.1%\n",
      "current params: tensor([  10.7205,   19.9610,  639.5718, 2337.4627, 2331.3703, 2196.0322],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1695 was 99.1%\n",
      "current params: tensor([  10.6625,   19.9608,  640.3630, 2338.3679, 2332.1701, 2196.7833],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1696 was 99.1%\n",
      "current params: tensor([  10.6041,   19.9605,  641.1517, 2339.2707, 2332.9669, 2197.5311],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1697 was 99.1%\n",
      "current params: tensor([  10.5453,   19.9603,  641.9380, 2340.1712, 2333.7608, 2198.2756],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1698 was 99.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  10.4861,   19.9600,  642.7218, 2341.0693, 2334.5516, 2199.0168],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1699 was 99.1%\n",
      "current params: tensor([  10.4264,   19.9598,  643.5033, 2341.9651, 2335.3394, 2199.7547],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1700 was 99.1%\n",
      "current params: tensor([  10.3662,   19.9596,  644.2822, 2342.8584, 2336.1242, 2200.4893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1701 was 99.1%\n",
      "current params: tensor([  10.3056,   19.9593,  645.0587, 2343.7494, 2336.9059, 2201.2206],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1702 was 99.1%\n",
      "current params: tensor([  10.2446,   19.9591,  645.8328, 2344.6380, 2337.6845, 2201.9486],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1703 was 99.1%\n",
      "current params: tensor([  10.1831,   19.9588,  646.6043, 2345.5242, 2338.4601, 2202.6732],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1704 was 99.1%\n",
      "current params: tensor([  10.1211,   19.9586,  647.3734, 2346.4081, 2339.2325, 2203.3944],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1705 was 99.1%\n",
      "current params: tensor([  10.0587,   19.9583,  648.1399, 2347.2894, 2340.0017, 2204.1123],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1706 was 99.1%\n",
      "current params: tensor([   9.9958,   19.9581,  648.9040, 2348.1684, 2340.7678, 2204.8268],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1707 was 99.1%\n",
      "current params: tensor([  19.9954,   19.9579,  649.6655, 2349.0449, 2341.5308, 2205.5379],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1708 was 98.7%\n",
      "current params: tensor([  19.9951,   19.9574,  650.8084, 2350.2569, 2342.7279, 2206.8050],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1709 was 98.7%\n",
      "current params: tensor([  19.9948,   19.9570,  651.9468, 2351.4640, 2343.9205, 2208.0647],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1710 was 98.7%\n",
      "current params: tensor([  19.9944,   19.9565,  653.0809, 2352.6664, 2345.1086, 2209.3171],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1711 was 98.7%\n",
      "current params: tensor([  19.9941,   19.9561,  654.2107, 2353.8640, 2346.2923, 2210.5624],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1712 was 98.7%\n",
      "current params: tensor([  19.9938,   19.9556,  655.3362, 2355.0571, 2347.4716, 2211.8006],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1713 was 98.7%\n",
      "current params: tensor([  19.9934,   19.9552,  656.4577, 2356.2457, 2348.6467, 2213.0321],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1714 was 98.7%\n",
      "current params: tensor([  19.9931,   19.9547,  657.5751, 2357.4300, 2349.8177, 2214.2570],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1715 was 98.7%\n",
      "current params: tensor([  19.9928,   19.9543,  658.6885, 2358.6099, 2350.9845, 2215.4754],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1716 was 98.7%\n",
      "current params: tensor([  19.9924,   19.9538,  659.7981, 2359.7856, 2352.1474, 2216.6875],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1717 was 98.7%\n",
      "current params: tensor([  19.9921,   19.9534,  660.9038, 2360.9571, 2353.3063, 2217.8933],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1718 was 98.7%\n",
      "current params: tensor([  19.9917,   19.9529,  662.0059, 2362.1246, 2354.4613, 2219.0931],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1719 was 98.7%\n",
      "current params: tensor([  19.9914,   19.9525,  663.1042, 2363.2881, 2355.6126, 2220.2870],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1720 was 98.7%\n",
      "current params: tensor([  19.9911,   19.9520,  664.1989, 2364.4477, 2356.7602, 2221.4751],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1721 was 98.7%\n",
      "current params: tensor([  19.9907,   19.9515,  665.2901, 2365.6034, 2357.9041, 2222.6575],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1722 was 98.7%\n",
      "current params: tensor([  19.9904,   19.9511,  666.3778, 2366.7554, 2359.0444, 2223.8344],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1723 was 98.7%\n",
      "current params: tensor([  19.9900,   19.9506,  667.4621, 2367.9037, 2360.1813, 2225.0059],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1724 was 98.7%\n",
      "current params: tensor([  19.9897,   19.9501,  668.5430, 2369.0484, 2361.3146, 2226.1720],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1725 was 98.7%\n",
      "current params: tensor([  19.9893,   19.9497,  669.6207, 2370.1894, 2362.4446, 2227.3330],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1726 was 98.7%\n",
      "current params: tensor([  19.9890,   19.9492,  670.6951, 2371.3270, 2363.5713, 2228.4888],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1727 was 98.7%\n",
      "current params: tensor([  19.9886,   19.9487,  671.7663, 2372.4612, 2364.6947, 2229.6397],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1728 was 98.7%\n",
      "current params: tensor([  19.9882,   19.9482,  672.8344, 2373.5919, 2365.8148, 2230.7857],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1729 was 98.7%\n",
      "current params: tensor([  19.9879,   19.9478,  673.8995, 2374.7194, 2366.9319, 2231.9268],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1730 was 98.7%\n",
      "current params: tensor([  19.9875,   19.9473,  674.9615, 2375.8436, 2368.0458, 2233.0633],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1731 was 98.7%\n",
      "current params: tensor([  19.9872,   19.9468,  676.0206, 2376.9645, 2369.1566, 2234.1952],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1732 was 98.7%\n",
      "current params: tensor([  19.9868,   19.9463,  677.0768, 2378.0824, 2370.2645, 2235.3225],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1733 was 98.8%\n",
      "current params: tensor([  19.9864,   19.9458,  678.1301, 2379.1971, 2371.3694, 2236.4455],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1734 was 98.8%\n",
      "current params: tensor([  19.9861,   19.9453,  679.1805, 2380.3088, 2372.4714, 2237.5640],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1735 was 98.8%\n",
      "current params: tensor([  19.9857,   19.9448,  680.2282, 2381.4175, 2373.5705, 2238.6783],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1736 was 98.8%\n",
      "current params: tensor([  19.9853,   19.9444,  681.2732, 2382.5233, 2374.6669, 2239.7885],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1737 was 98.8%\n",
      "current params: tensor([  19.9850,   19.9439,  682.3155, 2383.6261, 2375.7605, 2240.8945],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1738 was 98.8%\n",
      "current params: tensor([  19.9846,   19.9434,  683.3552, 2384.7261, 2376.8514, 2241.9965],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1739 was 98.8%\n",
      "current params: tensor([  19.9842,   19.9429,  684.3923, 2385.8234, 2377.9396, 2243.0945],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1740 was 98.8%\n",
      "current params: tensor([  19.9839,   19.9424,  685.4268, 2386.9178, 2379.0252, 2244.1887],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1741 was 98.8%\n",
      "current params: tensor([  19.9835,   19.9419,  686.4589, 2388.0096, 2380.1082, 2245.2791],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1742 was 98.8%\n",
      "current params: tensor([  19.9831,   19.9414,  687.4884, 2389.0987, 2381.1886, 2246.3657],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1743 was 98.8%\n",
      "current params: tensor([  19.9827,   19.9408,  688.5155, 2390.1852, 2382.2666, 2247.4486],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1744 was 98.8%\n",
      "current params: tensor([  19.9823,   19.9403,  689.5403, 2391.2691, 2383.3421, 2248.5279],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1745 was 98.8%\n",
      "current params: tensor([  19.9820,   19.9398,  690.5627, 2392.3505, 2384.4151, 2249.6037],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1746 was 98.8%\n",
      "current params: tensor([  19.9816,   19.9393,  691.5827, 2393.4293, 2385.4858, 2250.6759],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1747 was 98.8%\n",
      "current params: tensor([  19.9812,   19.9388,  692.6005, 2394.5058, 2386.5542, 2251.7448],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1748 was 98.8%\n",
      "current params: tensor([  19.9808,   19.9383,  693.6161, 2395.5798, 2387.6202, 2252.8103],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1749 was 98.8%\n",
      "current params: tensor([  19.9804,   19.9378,  694.6294, 2396.6514, 2388.6840, 2253.8724],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1750 was 98.8%\n",
      "current params: tensor([  19.9800,   19.9372,  695.6406, 2397.7206, 2389.7455, 2254.9313],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1751 was 98.8%\n",
      "current params: tensor([  19.9796,   19.9367,  696.6496, 2398.7876, 2390.8048, 2255.9871],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1752 was 98.8%\n",
      "current params: tensor([  19.9792,   19.9362,  697.6565, 2399.8523, 2391.8619, 2257.0396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1753 was 98.8%\n",
      "current params: tensor([  19.9788,   19.9357,  698.6614, 2400.9147, 2392.9169, 2258.0891],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1754 was 98.8%\n",
      "current params: tensor([  19.9784,   19.9351,  699.6642, 2401.9750, 2393.9698, 2259.1355],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1755 was 98.8%\n",
      "current params: tensor([  19.9780,   19.9346,  700.6649, 2403.0330, 2395.0206, 2260.1789],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1756 was 98.8%\n",
      "current params: tensor([  19.9776,   19.9341,  701.6637, 2404.0890, 2396.0693, 2261.2194],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1757 was 98.8%\n",
      "current params: tensor([  19.9772,   19.9335,  702.6606, 2405.1428, 2397.1161, 2262.2570],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1758 was 98.8%\n",
      "current params: tensor([  19.9768,   19.9330,  703.6555, 2406.1945, 2398.1608, 2263.2918],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1759 was 98.8%\n",
      "current params: tensor([  19.9764,   19.9324,  704.6485, 2407.2442, 2399.2036, 2264.3237],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1760 was 98.8%\n",
      "current params: tensor([  19.9760,   19.9319,  705.6397, 2408.2919, 2400.2445, 2265.3529],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1761 was 98.8%\n",
      "current params: tensor([  19.9756,   19.9313,  706.6290, 2409.3376, 2401.2835, 2266.3793],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1762 was 98.8%\n",
      "current params: tensor([  19.9752,   19.9308,  707.6165, 2410.3814, 2402.3206, 2267.4031],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1763 was 98.8%\n",
      "current params: tensor([  19.9748,   19.9302,  708.6022, 2411.4232, 2403.3558, 2268.4242],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1764 was 98.8%\n",
      "current params: tensor([  19.9744,   19.9297,  709.5861, 2412.4631, 2404.3893, 2269.4428],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1765 was 98.8%\n",
      "current params: tensor([  19.9740,   19.9291,  710.5683, 2413.5012, 2405.4209, 2270.4588],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1766 was 98.8%\n",
      "current params: tensor([  19.9736,   19.9286,  711.5488, 2414.5374, 2406.4508, 2271.4723],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1767 was 98.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.9731,   19.9280,  712.5276, 2415.5718, 2407.4789, 2272.4833],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1768 was 98.8%\n",
      "current params: tensor([  19.9727,   19.9275,  713.5047, 2416.6043, 2408.5053, 2273.4919],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1769 was 98.8%\n",
      "current params: tensor([  19.9723,   19.9269,  714.4802, 2417.6352, 2409.5300, 2274.4980],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1770 was 98.8%\n",
      "current params: tensor([  19.9719,   19.9263,  715.4541, 2418.6642, 2410.5531, 2275.5018],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1771 was 98.8%\n",
      "current params: tensor([  19.9714,   19.9258,  716.4264, 2419.6916, 2411.5745, 2276.5033],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1772 was 98.8%\n",
      "current params: tensor([  19.9710,   19.9252,  717.3971, 2420.7173, 2412.5942, 2277.5025],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1773 was 98.8%\n",
      "current params: tensor([  19.9706,   19.9246,  718.3663, 2421.7413, 2413.6124, 2278.4994],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1774 was 98.8%\n",
      "current params: tensor([  19.9702,   19.9240,  719.3339, 2422.7636, 2414.6290, 2279.4941],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1775 was 98.8%\n",
      "current params: tensor([  19.9697,   19.9234,  720.3001, 2423.7843, 2415.6440, 2280.4866],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1776 was 98.8%\n",
      "current params: tensor([  19.9693,   19.9229,  721.2647, 2424.8035, 2416.6575, 2281.4769],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1777 was 98.8%\n",
      "current params: tensor([  19.9689,   19.9223,  722.2279, 2425.8210, 2417.6695, 2282.4651],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1778 was 98.8%\n",
      "current params: tensor([  19.9684,   19.9217,  723.1896, 2426.8370, 2418.6800, 2283.4512],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1779 was 98.8%\n",
      "current params: tensor([  19.9680,   19.9211,  724.1499, 2427.8514, 2419.6890, 2284.4353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1780 was 98.8%\n",
      "current params: tensor([  19.9675,   19.9205,  725.1088, 2428.8644, 2420.6966, 2285.4172],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1781 was 98.8%\n",
      "current params: tensor([  19.9671,   19.9199,  726.0664, 2429.8758, 2421.7027, 2286.3972],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1782 was 98.8%\n",
      "current params: tensor([  19.9666,   19.9193,  727.0225, 2430.8857, 2422.7074, 2287.3752],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1783 was 98.8%\n",
      "current params: tensor([  19.9662,   19.9187,  727.9773, 2431.8942, 2423.7107, 2288.3512],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1784 was 98.8%\n",
      "current params: tensor([  19.9658,   19.9181,  728.9308, 2432.9013, 2424.7127, 2289.3253],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1785 was 98.8%\n",
      "current params: tensor([  19.9653,   19.9175,  729.8830, 2433.9070, 2425.7132, 2290.2975],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1786 was 98.8%\n",
      "current params: tensor([  19.9648,   19.9169,  730.8338, 2434.9112, 2426.7125, 2291.2679],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1787 was 98.8%\n",
      "current params: tensor([  19.9644,   19.9163,  731.7834, 2435.9141, 2427.7104, 2292.2363],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1788 was 98.8%\n",
      "current params: tensor([  19.9639,   19.9157,  732.7317, 2436.9156, 2428.7070, 2293.2030],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1789 was 98.8%\n",
      "current params: tensor([  19.9635,   19.9151,  733.6788, 2437.9157, 2429.7023, 2294.1678],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1790 was 98.8%\n",
      "current params: tensor([  19.9630,   19.9144,  734.6247, 2438.9146, 2430.6963, 2295.1309],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1791 was 98.8%\n",
      "current params: tensor([  19.9626,   19.9138,  735.5693, 2439.9121, 2431.6891, 2296.0922],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1792 was 98.8%\n",
      "current params: tensor([  19.9621,   19.9132,  736.5128, 2440.9083, 2432.6806, 2297.0518],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1793 was 98.8%\n",
      "current params: tensor([  19.9616,   19.9126,  737.4551, 2441.9033, 2433.6710, 2298.0097],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1794 was 98.8%\n",
      "current params: tensor([  19.9612,   19.9120,  738.3962, 2442.8970, 2434.6601, 2298.9659],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1795 was 98.8%\n",
      "current params: tensor([  19.9607,   19.9113,  739.3361, 2443.8894, 2435.6480, 2299.9205],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1796 was 98.8%\n",
      "current params: tensor([  19.9602,   19.9107,  740.2750, 2444.8807, 2436.6347, 2300.8734],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1797 was 98.8%\n",
      "current params: tensor([  19.9597,   19.9100,  741.2127, 2445.8707, 2437.6203, 2301.8247],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1798 was 98.8%\n",
      "current params: tensor([  19.9593,   19.9094,  742.1493, 2446.8595, 2438.6047, 2302.7744],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1799 was 98.8%\n",
      "current params: tensor([  19.9588,   19.9088,  743.0848, 2447.8472, 2439.5880, 2303.7225],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1800 was 98.8%\n",
      "current params: tensor([  19.9583,   19.9081,  744.0193, 2448.8336, 2440.5702, 2304.6691],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1801 was 98.8%\n",
      "current params: tensor([  19.9578,   19.9075,  744.9526, 2449.8190, 2441.5513, 2305.6142],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1802 was 98.8%\n",
      "current params: tensor([  19.9573,   19.9068,  745.8850, 2450.8032, 2442.5313, 2306.5577],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1803 was 98.8%\n",
      "current params: tensor([  19.9568,   19.9062,  746.8163, 2451.7862, 2443.5102, 2307.4997],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1804 was 98.8%\n",
      "current params: tensor([  19.9564,   19.9055,  747.7466, 2452.7682, 2444.4880, 2308.4403],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1805 was 98.8%\n",
      "current params: tensor([  19.9559,   19.9049,  748.6758, 2453.7491, 2445.4648, 2309.3794],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1806 was 98.8%\n",
      "current params: tensor([  19.9554,   19.9042,  749.6041, 2454.7289, 2446.4406, 2310.3171],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1807 was 98.8%\n",
      "current params: tensor([  19.9549,   19.9035,  750.5314, 2455.7076, 2447.4153, 2311.2534],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1808 was 98.8%\n",
      "current params: tensor([  19.9544,   19.9029,  751.4577, 2456.6853, 2448.3890, 2312.1882],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1809 was 98.8%\n",
      "current params: tensor([  19.9539,   19.9022,  752.3831, 2457.6619, 2449.3617, 2313.1217],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1810 was 98.8%\n",
      "current params: tensor([  19.9534,   19.9015,  753.3075, 2458.6375, 2450.3335, 2314.0538],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1811 was 98.8%\n",
      "current params: tensor([  19.9529,   19.9009,  754.2310, 2459.6121, 2451.3042, 2314.9846],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1812 was 98.8%\n",
      "current params: tensor([  19.9524,   19.9002,  755.1536, 2460.5857, 2452.2740, 2315.9141],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1813 was 98.8%\n",
      "current params: tensor([  19.9519,   19.8995,  756.0753, 2461.5583, 2453.2429, 2316.8422],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1814 was 98.8%\n",
      "current params: tensor([  19.9513,   19.8988,  756.9960, 2462.5299, 2454.2108, 2317.7690],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1815 was 98.8%\n",
      "current params: tensor([  19.9508,   19.8981,  757.9159, 2463.5006, 2455.1778, 2318.6946],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1816 was 98.8%\n",
      "current params: tensor([  19.9503,   19.8974,  758.8349, 2464.4703, 2456.1439, 2319.6189],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1817 was 98.8%\n",
      "current params: tensor([  19.9498,   19.8967,  759.7531, 2465.4391, 2457.1090, 2320.5419],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1818 was 98.8%\n",
      "current params: tensor([  19.9493,   19.8960,  760.6704, 2466.4069, 2458.0733, 2321.4637],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1819 was 98.8%\n",
      "current params: tensor([  19.9488,   19.8953,  761.5868, 2467.3738, 2459.0367, 2322.3843],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1820 was 98.8%\n",
      "current params: tensor([  19.9482,   19.8946,  762.5024, 2468.3398, 2459.9992, 2323.3037],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1821 was 98.8%\n",
      "current params: tensor([  19.9477,   19.8939,  763.4172, 2469.3049, 2460.9609, 2324.2219],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1822 was 98.8%\n",
      "current params: tensor([  19.9472,   19.8932,  764.3312, 2470.2692, 2461.9217, 2325.1389],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1823 was 98.8%\n",
      "current params: tensor([  19.9467,   19.8925,  765.2444, 2471.2325, 2462.8816, 2326.0547],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1824 was 98.8%\n",
      "current params: tensor([  19.9461,   19.8918,  766.1568, 2472.1950, 2463.8408, 2326.9695],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1825 was 98.8%\n",
      "current params: tensor([  19.9456,   19.8911,  767.0684, 2473.1566, 2464.7991, 2327.8830],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1826 was 98.8%\n",
      "current params: tensor([  19.9451,   19.8904,  767.9792, 2474.1174, 2465.7566, 2328.7955],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1827 was 98.8%\n",
      "current params: tensor([  19.9445,   19.8896,  768.8893, 2475.0774, 2466.7133, 2329.7069],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1828 was 98.8%\n",
      "current params: tensor([  19.9440,   19.8889,  769.7986, 2476.0365, 2467.6692, 2330.6171],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1829 was 98.8%\n",
      "current params: tensor([  19.9434,   19.8882,  770.7072, 2476.9948, 2468.6243, 2331.5263],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1830 was 98.8%\n",
      "current params: tensor([  19.9429,   19.8875,  771.6151, 2477.9523, 2469.5787, 2332.4344],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1831 was 98.8%\n",
      "current params: tensor([  19.9423,   19.8867,  772.5222, 2478.9091, 2470.5323, 2333.3415],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1832 was 98.8%\n",
      "current params: tensor([  19.9418,   19.8860,  773.4286, 2479.8650, 2471.4851, 2334.2475],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1833 was 98.8%\n",
      "current params: tensor([  19.9412,   19.8852,  774.3343, 2480.8201, 2472.4372, 2335.1525],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1834 was 98.8%\n",
      "current params: tensor([  19.9407,   19.8845,  775.2393, 2481.7745, 2473.3885, 2336.0565],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1835 was 98.8%\n",
      "current params: tensor([  19.9401,   19.8837,  776.1436, 2482.7281, 2474.3391, 2336.9595],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1836 was 98.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.9396,   19.8830,  777.0472, 2483.6810, 2475.2890, 2337.8614],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1837 was 98.8%\n",
      "current params: tensor([  19.9390,   19.8822,  777.9502, 2484.6332, 2476.2382, 2338.7624],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1838 was 98.8%\n",
      "current params: tensor([  19.9384,   19.8815,  778.8525, 2485.5846, 2477.1867, 2339.6625],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1839 was 98.8%\n",
      "current params: tensor([  19.9379,   19.8807,  779.7541, 2486.5352, 2478.1345, 2340.5615],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1840 was 98.9%\n",
      "current params: tensor([  19.9373,   19.8799,  780.6551, 2487.4852, 2479.0816, 2341.4597],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1841 was 98.9%\n",
      "current params: tensor([  19.9367,   19.8792,  781.5555, 2488.4345, 2480.0280, 2342.3569],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1842 was 98.9%\n",
      "current params: tensor([  19.9361,   19.8784,  782.4552, 2489.3830, 2480.9738, 2343.2531],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1843 was 98.9%\n",
      "current params: tensor([  19.9356,   19.8776,  783.3543, 2490.3309, 2481.9189, 2344.1485],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1844 was 98.9%\n",
      "current params: tensor([  19.9350,   19.8769,  784.2528, 2491.2781, 2482.8633, 2345.0429],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1845 was 98.9%\n",
      "current params: tensor([  19.9344,   19.8761,  785.1506, 2492.2246, 2483.8071, 2345.9364],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1846 was 98.9%\n",
      "current params: tensor([  19.9338,   19.8753,  786.0479, 2493.1704, 2484.7503, 2346.8291],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1847 was 98.9%\n",
      "current params: tensor([  19.9332,   19.8745,  786.9445, 2494.1156, 2485.6928, 2347.7209],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1848 was 98.9%\n",
      "current params: tensor([  19.9326,   19.8737,  787.8406, 2495.0601, 2486.6347, 2348.6118],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1849 was 98.9%\n",
      "current params: tensor([  19.9320,   19.8729,  788.7361, 2496.0040, 2487.5759, 2349.5019],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1850 was 98.9%\n",
      "current params: tensor([  19.9315,   19.8721,  789.6310, 2496.9473, 2488.5166, 2350.3911],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1851 was 98.9%\n",
      "current params: tensor([  19.9309,   19.8713,  790.5254, 2497.8899, 2489.4566, 2351.2795],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1852 was 98.9%\n",
      "current params: tensor([  19.9303,   19.8705,  791.4192, 2498.8319, 2490.3961, 2352.1671],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1853 was 98.9%\n",
      "current params: tensor([  19.9297,   19.8697,  792.3124, 2499.7733, 2491.3350, 2353.0538],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1854 was 98.9%\n",
      "current params: tensor([  19.9290,   19.8689,  793.2051, 2500.7141, 2492.2732, 2353.9398],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1855 was 98.9%\n",
      "current params: tensor([  19.9284,   19.8681,  794.0973, 2501.6542, 2493.2109, 2354.8249],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1856 was 98.9%\n",
      "current params: tensor([  19.9278,   19.8672,  794.9889, 2502.5938, 2494.1481, 2355.7093],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1857 was 98.9%\n",
      "current params: tensor([  19.9272,   19.8664,  795.8800, 2503.5328, 2495.0846, 2356.5929],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1858 was 98.9%\n",
      "current params: tensor([  19.9266,   19.8656,  796.7706, 2504.4712, 2496.0206, 2357.4757],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1859 was 98.9%\n",
      "current params: tensor([  19.9260,   19.8648,  797.6607, 2505.4090, 2496.9561, 2358.3577],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1860 was 98.9%\n",
      "current params: tensor([  19.9254,   19.8639,  798.5502, 2506.3463, 2497.8910, 2359.2390],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1861 was 98.9%\n",
      "current params: tensor([  19.9247,   19.8631,  799.4393, 2507.2830, 2498.8254, 2360.1195],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1862 was 98.9%\n",
      "current params: tensor([  19.9241,   19.8623,  800.3279, 2508.2192, 2499.7592, 2360.9993],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1863 was 98.9%\n",
      "current params: tensor([  19.9235,   19.8614,  801.2159, 2509.1548, 2500.6925, 2361.8784],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1864 was 98.9%\n",
      "current params: tensor([  19.9228,   19.8606,  802.1035, 2510.0898, 2501.6253, 2362.7568],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1865 was 98.9%\n",
      "current params: tensor([  19.9222,   19.8597,  802.9906, 2511.0243, 2502.5576, 2363.6344],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1866 was 98.9%\n",
      "current params: tensor([  19.9216,   19.8589,  803.8773, 2511.9583, 2503.4894, 2364.5113],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1867 was 98.9%\n",
      "current params: tensor([  19.9209,   19.8580,  804.7634, 2512.8918, 2504.4206, 2365.3876],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1868 was 98.9%\n",
      "current params: tensor([  19.9203,   19.8571,  805.6492, 2513.8247, 2505.3514, 2366.2631],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1869 was 98.9%\n",
      "current params: tensor([  19.9196,   19.8563,  806.5344, 2514.7572, 2506.2817, 2367.1380],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1870 was 98.9%\n",
      "current params: tensor([  19.9190,   19.8554,  807.4192, 2515.6891, 2507.2115, 2368.0122],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1871 was 98.9%\n",
      "current params: tensor([  19.9183,   19.8545,  808.3036, 2516.6205, 2508.1408, 2368.8857],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1872 was 98.9%\n",
      "current params: tensor([  19.9177,   19.8536,  809.1875, 2517.5515, 2509.0696, 2369.7585],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1873 was 98.9%\n",
      "current params: tensor([  19.9170,   19.8528,  810.0710, 2518.4819, 2509.9980, 2370.6307],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1874 was 98.9%\n",
      "current params: tensor([  19.9164,   19.8519,  810.9541, 2519.4118, 2510.9258, 2371.5023],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1875 was 98.9%\n",
      "current params: tensor([  19.9157,   19.8510,  811.8367, 2520.3413, 2511.8533, 2372.3732],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1876 was 98.9%\n",
      "current params: tensor([  19.9151,   19.8501,  812.7190, 2521.2703, 2512.7803, 2373.2435],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1877 was 98.9%\n",
      "current params: tensor([  19.9144,   19.8492,  813.6008, 2522.1988, 2513.7068, 2374.1132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1878 was 98.9%\n",
      "current params: tensor([  19.9137,   19.8483,  814.4822, 2523.1269, 2514.6329, 2374.9822],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1879 was 98.9%\n",
      "current params: tensor([  19.9130,   19.8474,  815.3632, 2524.0545, 2515.5585, 2375.8506],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1880 was 98.9%\n",
      "current params: tensor([  19.9124,   19.8465,  816.2438, 2524.9816, 2516.4837, 2376.7184],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1881 was 98.9%\n",
      "current params: tensor([  19.9117,   19.8456,  817.1240, 2525.9083, 2517.4085, 2377.5857],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1882 was 98.9%\n",
      "current params: tensor([  19.9110,   19.8446,  818.0038, 2526.8346, 2518.3328, 2378.4523],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1883 was 98.9%\n",
      "current params: tensor([  19.9103,   19.8437,  818.8833, 2527.7604, 2519.2568, 2379.3183],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1884 was 98.9%\n",
      "current params: tensor([  19.9096,   19.8428,  819.7623, 2528.6858, 2520.1803, 2380.1838],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1885 was 98.9%\n",
      "current params: tensor([  19.9089,   19.8419,  820.6410, 2529.6107, 2521.1034, 2381.0487],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1886 was 98.9%\n",
      "current params: tensor([  19.9082,   19.8409,  821.5193, 2530.5353, 2522.0261, 2381.9130],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1887 was 98.9%\n",
      "current params: tensor([  19.9075,   19.8400,  822.3973, 2531.4594, 2522.9484, 2382.7767],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1888 was 98.9%\n",
      "current params: tensor([  19.9068,   19.8391,  823.2749, 2532.3831, 2523.8702, 2383.6399],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1889 was 98.9%\n",
      "current params: tensor([  19.9061,   19.8381,  824.1521, 2533.3063, 2524.7917, 2384.5026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1890 was 98.9%\n",
      "current params: tensor([  19.9054,   19.8372,  825.0290, 2534.2292, 2525.7129, 2385.3647],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1891 was 98.9%\n",
      "current params: tensor([  19.9047,   19.8362,  825.9055, 2535.1517, 2526.6336, 2386.2263],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1892 was 98.9%\n",
      "current params: tensor([  19.9040,   19.8352,  826.7817, 2536.0738, 2527.5539, 2387.0873],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1893 was 98.9%\n",
      "current params: tensor([  19.9033,   19.8343,  827.6576, 2536.9954, 2528.4739, 2387.9478],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1894 was 98.9%\n",
      "current params: tensor([  19.9026,   19.8333,  828.5331, 2537.9167, 2529.3935, 2388.8078],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1895 was 98.9%\n",
      "current params: tensor([  19.9018,   19.8323,  829.4083, 2538.8376, 2530.3127, 2389.6672],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1896 was 98.9%\n",
      "current params: tensor([  19.9011,   19.8314,  830.2832, 2539.7582, 2531.2316, 2390.5262],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1897 was 98.9%\n",
      "current params: tensor([  19.9004,   19.8304,  831.1577, 2540.6783, 2532.1501, 2391.3846],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1898 was 98.9%\n",
      "current params: tensor([  19.8997,   19.8294,  832.0319, 2541.5981, 2533.0682, 2392.2426],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1899 was 98.9%\n",
      "current params: tensor([  19.8989,   19.8284,  832.9058, 2542.5175, 2533.9860, 2393.1000],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1900 was 98.9%\n",
      "current params: tensor([  19.8982,   19.8274,  833.7794, 2543.4365, 2534.9034, 2393.9570],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1901 was 98.9%\n",
      "current params: tensor([  19.8974,   19.8264,  834.6527, 2544.3552, 2535.8205, 2394.8134],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1902 was 98.9%\n",
      "current params: tensor([  19.8967,   19.8254,  835.5257, 2545.2735, 2536.7373, 2395.6694],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1903 was 98.9%\n",
      "current params: tensor([  19.8959,   19.8244,  836.3984, 2546.1915, 2537.6537, 2396.5250],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1904 was 98.9%\n",
      "current params: tensor([  19.8952,   19.8234,  837.2708, 2547.1091, 2538.5698, 2397.3800],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1905 was 98.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.8944,   19.8224,  838.1429, 2548.0264, 2539.4855, 2398.2346],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1906 was 98.9%\n",
      "current params: tensor([  19.8937,   19.8214,  839.0147, 2548.9433, 2540.4009, 2399.0887],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1907 was 98.9%\n",
      "current params: tensor([  19.8929,   19.8204,  839.8862, 2549.8599, 2541.3160, 2399.9424],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1908 was 98.9%\n",
      "current params: tensor([  19.8922,   19.8193,  840.7574, 2550.7762, 2542.2308, 2400.7956],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1909 was 98.9%\n",
      "current params: tensor([  19.8914,   19.8183,  841.6284, 2551.6921, 2543.1453, 2401.6483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1910 was 98.9%\n",
      "current params: tensor([  19.8906,   19.8173,  842.4991, 2552.6077, 2544.0595, 2402.5007],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1911 was 98.9%\n",
      "current params: tensor([  19.8898,   19.8162,  843.3695, 2553.5230, 2544.9733, 2403.3526],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1912 was 98.9%\n",
      "current params: tensor([  19.8891,   19.8152,  844.2396, 2554.4380, 2545.8868, 2404.2040],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1913 was 98.9%\n",
      "current params: tensor([  19.8883,   19.8141,  845.1095, 2555.3526, 2546.8001, 2405.0550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1914 was 98.9%\n",
      "current params: tensor([  19.8875,   19.8131,  845.9791, 2556.2669, 2547.7130, 2405.9056],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1915 was 98.9%\n",
      "current params: tensor([  19.8867,   19.8120,  846.8485, 2557.1810, 2548.6256, 2406.7558],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1916 was 98.9%\n",
      "current params: tensor([  19.8859,   19.8109,  847.7176, 2558.0947, 2549.5380, 2407.6056],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1917 was 98.9%\n",
      "current params: tensor([  19.8851,   19.8099,  848.5865, 2559.0081, 2550.4500, 2408.4549],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1918 was 98.9%\n",
      "current params: tensor([  19.8843,   19.8088,  849.4551, 2559.9212, 2551.3618, 2409.3039],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1919 was 98.9%\n",
      "current params: tensor([  19.8835,   19.8077,  850.3234, 2560.8340, 2552.2733, 2410.1524],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1920 was 98.9%\n",
      "current params: tensor([  19.8827,   19.8066,  851.1916, 2561.7465, 2553.1845, 2411.0006],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1921 was 98.9%\n",
      "current params: tensor([  19.8819,   19.8056,  852.0594, 2562.6588, 2554.0954, 2411.8483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1922 was 98.9%\n",
      "current params: tensor([  19.8811,   19.8045,  852.9271, 2563.5707, 2555.0061, 2412.6957],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1923 was 98.9%\n",
      "current params: tensor([  19.8803,   19.8034,  853.7945, 2564.4824, 2555.9165, 2413.5426],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1924 was 98.9%\n",
      "current params: tensor([  19.8795,   19.8023,  854.6617, 2565.3937, 2556.8266, 2414.3892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1925 was 98.9%\n",
      "current params: tensor([  19.8786,   19.8012,  855.5286, 2566.3048, 2557.7364, 2415.2354],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1926 was 98.9%\n",
      "current params: tensor([  19.8778,   19.8000,  856.3954, 2567.2156, 2558.6460, 2416.0812],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1927 was 98.9%\n",
      "current params: tensor([  19.8770,   19.7989,  857.2619, 2568.1262, 2559.5553, 2416.9267],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1928 was 98.9%\n",
      "current params: tensor([  19.8762,   19.7978,  858.1282, 2569.0365, 2560.4644, 2417.7718],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1929 was 98.9%\n",
      "current params: tensor([  19.8753,   19.7967,  858.9942, 2569.9465, 2561.3732, 2418.6165],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1930 was 98.9%\n",
      "current params: tensor([  19.8745,   19.7955,  859.8601, 2570.8562, 2562.2818, 2419.4609],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1931 was 98.9%\n",
      "current params: tensor([  19.8736,   19.7944,  860.7258, 2571.7657, 2563.1901, 2420.3049],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1932 was 98.9%\n",
      "current params: tensor([  19.8728,   19.7933,  861.5912, 2572.6749, 2564.0982, 2421.1485],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1933 was 98.9%\n",
      "current params: tensor([  19.8719,   19.7921,  862.4564, 2573.5839, 2565.0060, 2421.9918],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1934 was 98.9%\n",
      "current params: tensor([  19.8711,   19.7910,  863.3215, 2574.4926, 2565.9136, 2422.8348],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1935 was 98.9%\n",
      "current params: tensor([  19.8702,   19.7898,  864.1863, 2575.4011, 2566.8209, 2423.6774],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1936 was 98.9%\n",
      "current params: tensor([  19.8694,   19.7887,  865.0509, 2576.3093, 2567.7280, 2424.5197],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1937 was 98.9%\n",
      "current params: tensor([  19.8685,   19.7875,  865.9154, 2577.2173, 2568.6349, 2425.3616],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1938 was 98.9%\n",
      "current params: tensor([  19.8676,   19.7863,  866.7796, 2578.1250, 2569.5415, 2426.2032],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1939 was 98.9%\n",
      "current params: tensor([  19.8667,   19.7851,  867.6437, 2579.0325, 2570.4480, 2427.0445],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1940 was 98.9%\n",
      "current params: tensor([  19.8659,   19.7840,  868.5076, 2579.9398, 2571.3541, 2427.8854],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1941 was 98.9%\n",
      "current params: tensor([  19.8650,   19.7828,  869.3712, 2580.8468, 2572.2601, 2428.7260],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1942 was 98.9%\n",
      "current params: tensor([  19.8641,   19.7816,  870.2347, 2581.7536, 2573.1659, 2429.5663],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1943 was 98.9%\n",
      "current params: tensor([  19.8632,   19.7804,  871.0981, 2582.6601, 2574.0714, 2430.4063],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1944 was 98.9%\n",
      "current params: tensor([  19.8623,   19.7792,  871.9612, 2583.5665, 2574.9767, 2431.2460],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1945 was 98.9%\n",
      "current params: tensor([  19.8614,   19.7780,  872.8242, 2584.4726, 2575.8818, 2432.0853],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1946 was 98.9%\n",
      "current params: tensor([  19.8605,   19.7768,  873.6870, 2585.3785, 2576.7867, 2432.9244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1947 was 98.9%\n",
      "current params: tensor([  19.8596,   19.7755,  874.5496, 2586.2841, 2577.6913, 2433.7631],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1948 was 98.9%\n",
      "current params: tensor([  19.8587,   19.7743,  875.4121, 2587.1896, 2578.5958, 2434.6016],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1949 was 98.9%\n",
      "current params: tensor([  19.8578,   19.7731,  876.2744, 2588.0948, 2579.5001, 2435.4397],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1950 was 98.9%\n",
      "current params: tensor([  19.8569,   19.7718,  877.1365, 2588.9998, 2580.4041, 2436.2776],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1951 was 98.9%\n",
      "current params: tensor([  19.8559,   19.7706,  877.9985, 2589.9046, 2581.3080, 2437.1151],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1952 was 98.9%\n",
      "current params: tensor([  19.8550,   19.7694,  878.8603, 2590.8092, 2582.2116, 2437.9524],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1953 was 98.9%\n",
      "current params: tensor([  19.8541,   19.7681,  879.7219, 2591.7136, 2583.1151, 2438.7893],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1954 was 98.9%\n",
      "current params: tensor([  19.8532,   19.7669,  880.5834, 2592.6178, 2584.0184, 2439.6260],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1955 was 98.9%\n",
      "current params: tensor([  19.8522,   19.7656,  881.4448, 2593.5218, 2584.9214, 2440.4624],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1956 was 98.9%\n",
      "current params: tensor([  19.8513,   19.7643,  882.3059, 2594.4255, 2585.8243, 2441.2986],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1957 was 98.9%\n",
      "current params: tensor([  19.8503,   19.7630,  883.1670, 2595.3291, 2586.7270, 2442.1344],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1958 was 98.9%\n",
      "current params: tensor([  19.8494,   19.7618,  884.0279, 2596.2325, 2587.6295, 2442.9700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1959 was 98.9%\n",
      "current params: tensor([  19.8484,   19.7605,  884.8886, 2597.1357, 2588.5319, 2443.8053],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1960 was 98.9%\n",
      "current params: tensor([  19.8475,   19.7592,  885.7492, 2598.0387, 2589.4340, 2444.6403],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1961 was 98.9%\n",
      "current params: tensor([  19.8465,   19.7579,  886.6097, 2598.9415, 2590.3360, 2445.4751],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1962 was 98.9%\n",
      "current params: tensor([  19.8455,   19.7566,  887.4700, 2599.8441, 2591.2378, 2446.3096],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1963 was 98.9%\n",
      "current params: tensor([  19.8446,   19.7553,  888.3302, 2600.7465, 2592.1394, 2447.1438],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1964 was 98.9%\n",
      "current params: tensor([  19.8436,   19.7540,  889.1903, 2601.6488, 2593.0408, 2447.9778],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1965 was 98.9%\n",
      "current params: tensor([  19.8426,   19.7527,  890.0502, 2602.5509, 2593.9421, 2448.8115],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1966 was 98.9%\n",
      "current params: tensor([  19.8416,   19.7513,  890.9100, 2603.4527, 2594.8431, 2449.6450],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1967 was 98.9%\n",
      "current params: tensor([  19.8406,   19.7500,  891.7696, 2604.3544, 2595.7441, 2450.4782],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1968 was 98.9%\n",
      "current params: tensor([  19.8396,   19.7487,  892.6291, 2605.2560, 2596.6448, 2451.3112],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1969 was 98.9%\n",
      "current params: tensor([  19.8386,   19.7473,  893.4885, 2606.1573, 2597.5454, 2452.1439],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1970 was 98.9%\n",
      "current params: tensor([  19.8376,   19.7460,  894.3478, 2607.0585, 2598.4458, 2452.9764],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1971 was 98.9%\n",
      "current params: tensor([  19.8366,   19.7446,  895.2070, 2607.9595, 2599.3461, 2453.8086],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1972 was 98.9%\n",
      "current params: tensor([  19.8356,   19.7433,  896.0660, 2608.8604, 2600.2462, 2454.6406],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1973 was 98.9%\n",
      "current params: tensor([  19.8346,   19.7419,  896.9249, 2609.7610, 2601.1461, 2455.4724],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1974 was 98.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.8336,   19.7405,  897.7837, 2610.6615, 2602.0459, 2456.3039],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1975 was 98.9%\n",
      "current params: tensor([  19.8326,   19.7391,  898.6424, 2611.5619, 2602.9455, 2457.1352],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1976 was 99.0%\n",
      "current params: tensor([  19.8315,   19.7377,  899.5009, 2612.4620, 2603.8450, 2457.9662],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1977 was 99.0%\n",
      "current params: tensor([  19.8305,   19.7364,  900.3594, 2613.3621, 2604.7443, 2458.7971],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1978 was 99.0%\n",
      "current params: tensor([  19.8295,   19.7350,  901.2177, 2614.2619, 2605.6435, 2459.6277],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1979 was 99.0%\n",
      "current params: tensor([  19.8284,   19.7336,  902.0760, 2615.1616, 2606.5425, 2460.4580],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1980 was 99.0%\n",
      "current params: tensor([  19.8274,   19.7321,  902.9341, 2616.0612, 2607.4414, 2461.2882],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1981 was 99.0%\n",
      "current params: tensor([  19.8263,   19.7307,  903.7921, 2616.9605, 2608.3402, 2462.1181],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1982 was 99.0%\n",
      "current params: tensor([  19.8253,   19.7293,  904.6500, 2617.8598, 2609.2387, 2462.9478],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1983 was 99.0%\n",
      "current params: tensor([  19.8242,   19.7279,  905.5078, 2618.7589, 2610.1372, 2463.7773],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1984 was 99.0%\n",
      "current params: tensor([  19.8232,   19.7264,  906.3655, 2619.6578, 2611.0355, 2464.6066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1985 was 99.0%\n",
      "current params: tensor([  19.8221,   19.7250,  907.2231, 2620.5566, 2611.9336, 2465.4357],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1986 was 99.0%\n",
      "current params: tensor([  19.8210,   19.7236,  908.0806, 2621.4552, 2612.8317, 2466.2645],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1987 was 99.0%\n",
      "current params: tensor([  19.8199,   19.7221,  908.9381, 2622.3537, 2613.7296, 2467.0932],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1988 was 99.0%\n",
      "current params: tensor([  19.8188,   19.7206,  909.7954, 2623.2520, 2614.6273, 2467.9216],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1989 was 99.0%\n",
      "current params: tensor([  19.8178,   19.7192,  910.6526, 2624.1502, 2615.5249, 2468.7499],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1990 was 99.0%\n",
      "current params: tensor([  19.8167,   19.7177,  911.5097, 2625.0483, 2616.4224, 2469.5779],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1991 was 99.0%\n",
      "current params: tensor([  19.8156,   19.7162,  912.3667, 2625.9462, 2617.3198, 2470.4057],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1992 was 99.0%\n",
      "current params: tensor([  19.8145,   19.7147,  913.2237, 2626.8440, 2618.2170, 2471.2333],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1993 was 99.0%\n",
      "current params: tensor([  19.8134,   19.7132,  914.0805, 2627.7417, 2619.1141, 2472.0608],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1994 was 99.0%\n",
      "current params: tensor([  19.8122,   19.7117,  914.9373, 2628.6392, 2620.0111, 2472.8880],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1995 was 99.0%\n",
      "current params: tensor([  19.8111,   19.7102,  915.7940, 2629.5366, 2620.9079, 2473.7150],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1996 was 99.0%\n",
      "current params: tensor([  19.8100,   19.7087,  916.6506, 2630.4338, 2621.8046, 2474.5419],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1997 was 99.0%\n",
      "current params: tensor([  19.8089,   19.7072,  917.5071, 2631.3309, 2622.7012, 2475.3686],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1998 was 99.0%\n",
      "current params: tensor([  19.8077,   19.7057,  918.3635, 2632.2279, 2623.5977, 2476.1950],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1999 was 99.0%\n",
      "current params: tensor([  19.8066,   19.7041,  919.2199, 2633.1248, 2624.4940, 2477.0213],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2000 was 99.0%\n",
      "current params: tensor([  19.8055,   19.7026,  920.0762, 2634.0215, 2625.3903, 2477.8474],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2001 was 99.0%\n",
      "current params: tensor([  19.8043,   19.7011,  920.9323, 2634.9181, 2626.2864, 2478.6733],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2002 was 99.0%\n",
      "current params: tensor([  19.8032,   19.6995,  921.7885, 2635.8146, 2627.1824, 2479.4990],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2003 was 99.0%\n",
      "current params: tensor([  19.8020,   19.6979,  922.6445, 2636.7109, 2628.0783, 2480.3246],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2004 was 99.0%\n",
      "current params: tensor([  19.8008,   19.6964,  923.5005, 2637.6072, 2628.9740, 2481.1499],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2005 was 99.0%\n",
      "current params: tensor([  19.7997,   19.6948,  924.3564, 2638.5033, 2629.8697, 2481.9751],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2006 was 99.0%\n",
      "current params: tensor([  19.7985,   19.6932,  925.2122, 2639.3993, 2630.7652, 2482.8001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2007 was 99.0%\n",
      "current params: tensor([  19.7973,   19.6916,  926.0679, 2640.2951, 2631.6607, 2483.6250],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2008 was 99.0%\n",
      "current params: tensor([  19.7961,   19.6900,  926.9236, 2641.1909, 2632.5560, 2484.4496],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2009 was 99.0%\n",
      "current params: tensor([  19.7950,   19.6884,  927.7792, 2642.0865, 2633.4512, 2485.2741],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2010 was 99.0%\n",
      "current params: tensor([  19.7938,   19.6868,  928.6347, 2642.9820, 2634.3463, 2486.0984],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2011 was 99.0%\n",
      "current params: tensor([  19.7926,   19.6852,  929.4902, 2643.8774, 2635.2413, 2486.9226],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2012 was 99.0%\n",
      "current params: tensor([  19.7914,   19.6836,  930.3456, 2644.7727, 2636.1362, 2487.7466],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2013 was 99.0%\n",
      "current params: tensor([  19.7902,   19.6820,  931.2010, 2645.6679, 2637.0310, 2488.5704],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2014 was 99.0%\n",
      "current params: tensor([  19.7889,   19.6803,  932.0562, 2646.5630, 2637.9257, 2489.3940],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2015 was 99.0%\n",
      "current params: tensor([  19.7877,   19.6787,  932.9115, 2647.4580, 2638.8203, 2490.2175],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2016 was 99.0%\n",
      "current params: tensor([  19.7865,   19.6770,  933.7666, 2648.3528, 2639.7148, 2491.0408],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2017 was 99.0%\n",
      "current params: tensor([  19.7853,   19.6754,  934.6217, 2649.2476, 2640.6091, 2491.8640],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2018 was 99.0%\n",
      "current params: tensor([  19.7840,   19.6737,  935.4768, 2650.1422, 2641.5034, 2492.6870],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2019 was 99.0%\n",
      "current params: tensor([  19.7828,   19.6720,  936.3317, 2651.0367, 2642.3976, 2493.5099],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2020 was 99.0%\n",
      "current params: tensor([  19.7815,   19.6703,  937.1867, 2651.9312, 2643.2917, 2494.3326],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2021 was 99.0%\n",
      "current params: tensor([  19.7803,   19.6687,  938.0415, 2652.8255, 2644.1857, 2495.1551],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2022 was 99.0%\n",
      "current params: tensor([  19.7790,   19.6670,  938.8963, 2653.7197, 2645.0796, 2495.9775],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2023 was 99.0%\n",
      "current params: tensor([  19.7778,   19.6652,  939.7511, 2654.6138, 2645.9734, 2496.7997],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2024 was 99.0%\n",
      "current params: tensor([  19.7765,   19.6635,  940.6058, 2655.5079, 2646.8671, 2497.6218],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2025 was 99.0%\n",
      "current params: tensor([  19.7752,   19.6618,  941.4604, 2656.4018, 2647.7607, 2498.4437],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2026 was 99.0%\n",
      "current params: tensor([  19.7739,   19.6601,  942.3150, 2657.2956, 2648.6543, 2499.2655],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2027 was 99.0%\n",
      "current params: tensor([  19.7727,   19.6584,  943.1696, 2658.1893, 2649.5477, 2500.0871],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2028 was 99.0%\n",
      "current params: tensor([  19.7714,   19.6566,  944.0241, 2659.0830, 2650.4410, 2500.9086],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2029 was 99.0%\n",
      "current params: tensor([  19.7701,   19.6549,  944.8785, 2659.9765, 2651.3343, 2501.7299],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2030 was 99.0%\n",
      "current params: tensor([  19.7688,   19.6531,  945.7329, 2660.8699, 2652.2275, 2502.5511],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2031 was 99.0%\n",
      "current params: tensor([  19.7675,   19.6513,  946.5873, 2661.7633, 2653.1206, 2503.3722],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2032 was 99.0%\n",
      "current params: tensor([  19.7661,   19.6496,  947.4416, 2662.6565, 2654.0136, 2504.1931],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2033 was 99.0%\n",
      "current params: tensor([  19.7648,   19.6478,  948.2959, 2663.5497, 2654.9065, 2505.0138],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2034 was 99.0%\n",
      "current params: tensor([  19.7635,   19.6460,  949.1501, 2664.4428, 2655.7993, 2505.8344],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2035 was 99.0%\n",
      "current params: tensor([  19.7622,   19.6442,  950.0042, 2665.3357, 2656.6921, 2506.6549],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2036 was 99.0%\n",
      "current params: tensor([  19.7608,   19.6424,  950.8584, 2666.2286, 2657.5847, 2507.4753],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2037 was 99.0%\n",
      "current params: tensor([  19.7595,   19.6406,  951.7125, 2667.1214, 2658.4773, 2508.2955],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2038 was 99.0%\n",
      "current params: tensor([  19.7581,   19.6387,  952.5665, 2668.0141, 2659.3698, 2509.1156],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2039 was 99.0%\n",
      "current params: tensor([  19.7568,   19.6369,  953.4205, 2668.9068, 2660.2622, 2509.9355],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2040 was 99.0%\n",
      "current params: tensor([  19.7554,   19.6351,  954.2745, 2669.7993, 2661.1546, 2510.7553],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2041 was 99.0%\n",
      "current params: tensor([  19.7541,   19.6332,  955.1284, 2670.6918, 2662.0468, 2511.5750],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2042 was 99.0%\n",
      "current params: tensor([  19.7527,   19.6314,  955.9823, 2671.5841, 2662.9390, 2512.3945],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2043 was 99.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.7513,   19.6295,  956.8362, 2672.4764, 2663.8311, 2513.2139],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2044 was 99.0%\n",
      "current params: tensor([  19.7499,   19.6276,  957.6900, 2673.3686, 2664.7232, 2514.0332],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2045 was 99.0%\n",
      "current params: tensor([  19.7485,   19.6258,  958.5438, 2674.2607, 2665.6151, 2514.8524],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2046 was 99.0%\n",
      "current params: tensor([  19.7471,   19.6239,  959.3975, 2675.1528, 2666.5070, 2515.6714],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2047 was 99.0%\n",
      "current params: tensor([  19.7457,   19.6220,  960.2513, 2676.0447, 2667.3988, 2516.4903],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2048 was 99.0%\n",
      "current params: tensor([  19.7443,   19.6201,  961.1049, 2676.9366, 2668.2906, 2517.3090],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2049 was 99.0%\n",
      "current params: tensor([  19.7429,   19.6182,  961.9586, 2677.8284, 2669.1822, 2518.1277],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2050 was 99.0%\n",
      "current params: tensor([  19.7415,   19.6162,  962.8122, 2678.7201, 2670.0738, 2518.9462],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2051 was 99.0%\n",
      "current params: tensor([  19.7400,   19.6143,  963.6658, 2679.6118, 2670.9653, 2519.7646],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2052 was 99.0%\n",
      "current params: tensor([  19.7386,   19.6124,  964.5193, 2680.5033, 2671.8568, 2520.5829],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2053 was 99.0%\n",
      "current params: tensor([  19.7372,   19.6104,  965.3729, 2681.3948, 2672.7482, 2521.4010],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2054 was 99.0%\n",
      "current params: tensor([  19.7357,   19.6085,  966.2264, 2682.2862, 2673.6395, 2522.2191],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2055 was 99.0%\n",
      "current params: tensor([  19.7343,   19.6065,  967.0798, 2683.1776, 2674.5307, 2523.0370],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2056 was 99.0%\n",
      "current params: tensor([  19.7328,   19.6045,  967.9333, 2684.0688, 2675.4219, 2523.8548],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2057 was 99.0%\n",
      "current params: tensor([  19.7313,   19.6025,  968.7867, 2684.9600, 2676.3130, 2524.6724],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2058 was 99.0%\n",
      "current params: tensor([  19.7299,   19.6006,  969.6400, 2685.8511, 2677.2040, 2525.4900],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2059 was 99.0%\n",
      "current params: tensor([  19.7284,   19.5986,  970.4934, 2686.7422, 2678.0950, 2526.3074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2060 was 99.0%\n",
      "current params: tensor([  19.7269,   19.5965,  971.3467, 2687.6332, 2678.9859, 2527.1248],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2061 was 99.0%\n",
      "current params: tensor([  19.7254,   19.5945,  972.2000, 2688.5241, 2679.8768, 2527.9420],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2062 was 99.0%\n",
      "current params: tensor([  19.7239,   19.5925,  973.0533, 2689.4149, 2680.7676, 2528.7591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2063 was 99.0%\n",
      "current params: tensor([  19.7224,   19.5905,  973.9066, 2690.3056, 2681.6583, 2529.5760],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2064 was 99.0%\n",
      "current params: tensor([  19.7209,   19.5884,  974.7598, 2691.1963, 2682.5489, 2530.3929],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2065 was 99.0%\n",
      "current params: tensor([  19.7194,   19.5864,  975.6130, 2692.0870, 2683.4395, 2531.2097],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2066 was 99.0%\n",
      "current params: tensor([  19.7178,   19.5843,  976.4662, 2692.9775, 2684.3301, 2532.0263],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2067 was 99.0%\n",
      "current params: tensor([  19.7163,   19.5822,  977.3194, 2693.8680, 2685.2205, 2532.8428],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2068 was 99.0%\n",
      "current params: tensor([  19.7148,   19.5801,  978.1725, 2694.7584, 2686.1109, 2533.6593],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2069 was 99.0%\n",
      "current params: tensor([  19.7132,   19.5781,  979.0257, 2695.6488, 2687.0013, 2534.4756],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2070 was 99.0%\n",
      "current params: tensor([  19.7117,   19.5760,  979.8788, 2696.5390, 2687.8916, 2535.2918],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2071 was 99.0%\n",
      "current params: tensor([  19.7101,   19.5738,  980.7318, 2697.4293, 2688.7818, 2536.1079],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2072 was 99.0%\n",
      "current params: tensor([  19.7085,   19.5717,  981.5849, 2698.3194, 2689.6720, 2536.9239],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2073 was 99.0%\n",
      "current params: tensor([  19.7070,   19.5696,  982.4380, 2699.2095, 2690.5621, 2537.7398],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2074 was 99.0%\n",
      "current params: tensor([  19.7054,   19.5675,  983.2910, 2700.0995, 2691.4522, 2538.5555],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2075 was 99.0%\n",
      "current params: tensor([  19.7038,   19.5653,  984.1440, 2700.9895, 2692.3422, 2539.3712],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2076 was 99.0%\n",
      "current params: tensor([  19.7022,   19.5632,  984.9970, 2701.8794, 2693.2321, 2540.1868],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2077 was 99.0%\n",
      "current params: tensor([  19.7006,   19.5610,  985.8500, 2702.7692, 2694.1220, 2541.0022],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2078 was 99.0%\n",
      "current params: tensor([  19.6990,   19.5588,  986.7029, 2703.6590, 2695.0118, 2541.8176],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2079 was 99.0%\n",
      "current params: tensor([  19.6974,   19.5566,  987.5559, 2704.5487, 2695.9016, 2542.6329],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2080 was 99.0%\n",
      "current params: tensor([  19.6957,   19.5544,  988.4088, 2705.4384, 2696.7913, 2543.4480],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2081 was 99.0%\n",
      "current params: tensor([  19.6941,   19.5522,  989.2617, 2706.3279, 2697.6810, 2544.2631],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2082 was 99.0%\n",
      "current params: tensor([  19.6925,   19.5500,  990.1146, 2707.2175, 2698.5706, 2545.0780],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2083 was 99.0%\n",
      "current params: tensor([  19.6908,   19.5478,  990.9675, 2708.1070, 2699.4602, 2545.8929],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2084 was 99.0%\n",
      "current params: tensor([  19.6892,   19.5455,  991.8204, 2708.9964, 2700.3497, 2546.7076],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2085 was 99.0%\n",
      "current params: tensor([  19.6875,   19.5433,  992.6733, 2709.8857, 2701.2391, 2547.5222],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2086 was 99.0%\n",
      "current params: tensor([  19.6858,   19.5410,  993.5261, 2710.7750, 2702.1285, 2548.3368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2087 was 99.0%\n",
      "current params: tensor([  19.6842,   19.5388,  994.3789, 2711.6642, 2703.0179, 2549.1512],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2088 was 99.0%\n",
      "current params: tensor([  19.6825,   19.5365,  995.2318, 2712.5534, 2703.9072, 2549.9656],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2089 was 99.0%\n",
      "current params: tensor([  19.6808,   19.5342,  996.0846, 2713.4426, 2704.7965, 2550.7799],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2090 was 99.0%\n",
      "current params: tensor([  19.6791,   19.5319,  996.9374, 2714.3316, 2705.6857, 2551.5940],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2091 was 99.0%\n",
      "current params: tensor([  19.6774,   19.5296,  997.7902, 2715.2206, 2706.5748, 2552.4081],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2092 was 99.0%\n",
      "current params: tensor([  19.6757,   19.5273,  998.6430, 2716.1096, 2707.4639, 2553.2220],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2093 was 99.0%\n",
      "current params: tensor([  19.6740,   19.5250,  999.4957, 2716.9985, 2708.3530, 2554.0359],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2094 was 99.0%\n",
      "current params: tensor([  19.6722,   19.5226, 1000.3485, 2717.8873, 2709.2420, 2554.8497],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2095 was 99.0%\n",
      "current params: tensor([  19.6705,   19.5203, 1001.2012, 2718.7761, 2710.1309, 2555.6634],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2096 was 99.0%\n",
      "current params: tensor([  19.6688,   19.5179, 1002.0540, 2719.6649, 2711.0198, 2556.4769],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2097 was 99.0%\n",
      "current params: tensor([  19.6670,   19.5155, 1002.9067, 2720.5535, 2711.9087, 2557.2904],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2098 was 99.0%\n",
      "current params: tensor([  19.6653,   19.5132, 1003.7595, 2721.4422, 2712.7975, 2558.1038],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2099 was 99.0%\n",
      "current params: tensor([  19.6635,   19.5108, 1004.6122, 2722.3307, 2713.6863, 2558.9171],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2100 was 99.0%\n",
      "current params: tensor([  19.6617,   19.5084, 1005.4649, 2723.2193, 2714.5750, 2559.7303],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2101 was 99.0%\n",
      "current params: tensor([  19.6599,   19.5060, 1006.3176, 2724.1077, 2715.4637, 2560.5434],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2102 was 99.0%\n",
      "current params: tensor([  19.6581,   19.5035, 1007.1703, 2724.9961, 2716.3523, 2561.3565],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2103 was 99.0%\n",
      "current params: tensor([  19.6564,   19.5011, 1008.0230, 2725.8845, 2717.2409, 2562.1694],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2104 was 99.0%\n",
      "current params: tensor([  19.6545,   19.4987, 1008.8757, 2726.7728, 2718.1294, 2562.9822],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2105 was 99.0%\n",
      "current params: tensor([  19.6527,   19.4962, 1009.7283, 2727.6611, 2719.0179, 2563.7950],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2106 was 99.0%\n",
      "current params: tensor([  19.6509,   19.4937, 1010.5810, 2728.5493, 2719.9064, 2564.6077],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2107 was 99.0%\n",
      "current params: tensor([  19.6491,   19.4913, 1011.4337, 2729.4375, 2720.7948, 2565.4202],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2108 was 99.0%\n",
      "current params: tensor([  19.6472,   19.4888, 1012.2863, 2730.3256, 2721.6832, 2566.2327],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2109 was 99.0%\n",
      "current params: tensor([  19.6454,   19.4863, 1013.1390, 2731.2136, 2722.5715, 2567.0451],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2110 was 99.0%\n",
      "current params: tensor([  19.6435,   19.4838, 1013.9916, 2732.1016, 2723.4598, 2567.8574],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2111 was 99.0%\n",
      "current params: tensor([  19.6417,   19.4812, 1014.8443, 2732.9896, 2724.3480, 2568.6696],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2112 was 99.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([  19.6398,   19.4787, 1015.6969, 2733.8775, 2725.2362, 2569.4817],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2113 was 99.0%\n",
      "current params: tensor([  19.6379,   19.4762, 1016.5496, 2734.7654, 2726.1243, 2570.2938],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2114 was 99.0%\n",
      "current params: tensor([  19.6361,   19.4736, 1017.4022, 2735.6532, 2727.0125, 2571.1057],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2115 was 99.0%\n",
      "current params: tensor([  19.6342,   19.4710, 1018.2548, 2736.5410, 2727.9005, 2571.9176],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2116 was 99.0%\n",
      "current params: tensor([  19.6323,   19.4685, 1019.1075, 2737.4287, 2728.7885, 2572.7293],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2117 was 99.0%\n",
      "current params: tensor([  19.6303,   19.4659, 1019.9601, 2738.3164, 2729.6765, 2573.5410],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2118 was 99.0%\n",
      "current params: tensor([  19.6284,   19.4633, 1020.8127, 2739.2040, 2730.5645, 2574.3526],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2119 was 99.0%\n",
      "current params: tensor([  19.6265,   19.4606, 1021.6653, 2740.0916, 2731.4524, 2575.1641],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2120 was 99.0%\n",
      "current params: tensor([  19.6246,   19.4580, 1022.5180, 2740.9791, 2732.3402, 2575.9755],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2121 was 99.0%\n",
      "current params: tensor([  19.6226,   19.4554, 1023.3706, 2741.8666, 2733.2281, 2576.7869],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2122 was 99.0%\n",
      "current params: tensor([  19.6207,   19.4527, 1024.2232, 2742.7540, 2734.1158, 2577.5981],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2123 was 99.0%\n",
      "current params: tensor([  19.6187,   19.4501, 1025.0758, 2743.6414, 2735.0036, 2578.4093],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2124 was 99.0%\n",
      "current params: tensor([  19.6167,   19.4474, 1025.9284, 2744.5288, 2735.8913, 2579.2204],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2125 was 99.0%\n",
      "current params: tensor([  19.6147,   19.4447, 1026.7810, 2745.4161, 2736.7789, 2580.0314],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2126 was 99.0%\n",
      "current params: tensor([  19.6128,   19.4420, 1027.6336, 2746.3033, 2737.6666, 2580.8423],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2127 was 99.0%\n",
      "current params: tensor([  19.6108,   19.4393, 1028.4862, 2747.1905, 2738.5542, 2581.6531],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2128 was 99.0%\n",
      "current params: tensor([  19.6087,   19.4366, 1029.3388, 2748.0777, 2739.4417, 2582.4638],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2129 was 99.0%\n",
      "current params: tensor([  19.6067,   19.4338, 1030.1914, 2748.9648, 2740.3292, 2583.2745],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2130 was 99.0%\n",
      "current params: tensor([  19.6047,   19.4311, 1031.0440, 2749.8519, 2741.2167, 2584.0851],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2131 was 99.0%\n",
      "current params: tensor([  19.6027,   19.4283, 1031.8966, 2750.7389, 2742.1041, 2584.8956],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2132 was 99.0%\n",
      "current params: tensor([  19.6006,   19.4256, 1032.7492, 2751.6259, 2742.9915, 2585.7060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2133 was 99.0%\n",
      "current params: tensor([  19.5986,   19.4228, 1033.6018, 2752.5128, 2743.8789, 2586.5163],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2134 was 99.1%\n",
      "current params: tensor([  19.5965,   19.4200, 1034.4545, 2753.3997, 2744.7662, 2587.3265],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2135 was 99.1%\n",
      "current params: tensor([  19.5944,   19.4172, 1035.3071, 2754.2866, 2745.6535, 2588.1367],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2136 was 99.1%\n",
      "current params: tensor([  19.5924,   19.4144, 1036.1597, 2755.1734, 2746.5407, 2588.9467],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2137 was 99.1%\n",
      "current params: tensor([  19.5903,   19.4115, 1037.0123, 2756.0602, 2747.4279, 2589.7567],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2138 was 99.1%\n",
      "current params: tensor([  19.5882,   19.4087, 1037.8649, 2756.9469, 2748.3151, 2590.5666],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2139 was 99.1%\n",
      "current params: tensor([  19.5861,   19.4058, 1038.7175, 2757.8336, 2749.2022, 2591.3764],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2140 was 99.1%\n",
      "current params: tensor([  19.5840,   19.4029, 1039.5701, 2758.7202, 2750.0893, 2592.1862],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=10000,\n",
    "                  learning_rate=1,\n",
    "                  device='cpu',method='RMSprop')\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optim.yield_per_iter[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in rn.network.nodes():\n",
    "    print(gtostr(rn.network.nodes[n]['struct']), \" : \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nodes_list = ['A','B','C','ABC','AB','BC','AC']\n",
    "#nodes_list = ['AB','BMS','ABS','AMS','ABMS','AM','BM','MS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([1, 5, 10]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i])\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
