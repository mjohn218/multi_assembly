{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7fbdc98ab9e8>\n"
     ]
    }
   ],
   "source": [
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['A']\n",
      "100.0\n",
      "['B']\n",
      "100.0\n",
      "['C']\n",
      "100.0\n",
      "Parsing rule...\n",
      "['A(a)+B(a)<->A(a!1).B(a!1)', 'G=-20']\n",
      "['A', 'B', '']\n",
      "['A(a)+B(a)', 'A(a!1).B(a!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['A(b)+C(b)<->A(b!1).C(b!1)', 'G=-20']\n",
      "['A', 'C', '']\n",
      "['A(b)+C(b)', 'A(b!1).C(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['B(b)+C(a)<->B(b!1).C(a!1)', 'G=-20']\n",
      "['B', 'C', '']\n",
      "['B(b)+C(a)', 'B(b!1).C(a!1)']\n",
      "GGGGGGGGGgg\n",
      "False\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A'}\n",
      "{'A'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "[]\n",
      "Connected item Edges:  [('A', 'B')]\n",
      "New node added--1\n",
      "['A', 'B']\n",
      "Adding an new edge-- 0 3\n",
      "New bonds:  [('A', 'B')]\n",
      "Adding an new edge-- 1 3\n",
      "New node added--2\n",
      "[0, 1, 2, 3]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "[]\n",
      "Connected item Edges:  [('A', 'C')]\n",
      "New node added--1\n",
      "['A', 'C']\n",
      "Adding an new edge-- 0 4\n",
      "New bonds:  [('A', 'C')]\n",
      "Adding an new edge-- 2 4\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "[(3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('B', 'A')]\n",
      "$$$$$$$\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'B'}\n",
      "{'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('B', 'C')]\n",
      "New node added--1\n",
      "['B', 'C']\n",
      "Adding an new edge-- 1 5\n",
      "New bonds:  [('B', 'C')]\n",
      "Adding an new edge-- 2 5\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'B'}\n",
      "{'A', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('A', 'C')]\n",
      "Item edges:  [('A', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "New node added--1\n",
      "['B', 'A', 'C']\n",
      "Adding an new edge-- 1 6\n",
      "New bonds:  [('A', 'B'), ('B', 'C')]\n",
      "Adding an new edge-- 4 6\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "[(4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('C', 'A')]\n",
      "$$$$$$$\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'C'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "############################3\n",
      "[(5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('C', 'B')]\n",
      "$$$$$$$\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'C'}\n",
      "{'C'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('A', 'B')]\n",
      "Item edges:  [('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "############################3\n",
      "[(6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('C', 'A'), ('C', 'B'), ('A', 'B')]\n",
      "Adding an new edge-- 2 6\n",
      "New bonds:  [('A', 'C'), ('B', 'C')]\n",
      "Adding an new edge-- 3 6\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'C'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "False\n",
      "Orig edges:  [('A', 'B')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "############################3\n",
      "[(6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('A', 'B')]\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "False\n",
      "Orig edges:  [('A', 'C')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('A', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "############################3\n",
      "[(6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('A', 'C'), ('A', 'B'), ('C', 'B')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'C'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('A', 'C')]\n",
      "False\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "False\n",
      "Orig edges:  [('B', 'C')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('B', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "[(6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('B', 'C'), ('B', 'A'), ('C', 'A')]\n",
      "Adding an new edge-- 5 6\n",
      "New bonds:  [('A', 'B'), ('A', 'C')]\n",
      "Adding an new edge-- 0 6\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('B', 'C')]\n",
      "False\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32fd5c50>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7fbd34188a58>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2ac8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7fbd32bb2be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fca20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7fbd328fc780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7fbd3289b470>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "False\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "base_input = '../input_files/trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "print(rn.rxn_coupling)\n",
    "rn.resolve_tree()\n",
    "print(rn.rxn_coupling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_monomers(n1,monomer_set):\n",
    "        if len(rn.network.in_edges(n1)) == 0:\n",
    "            return(True,monomer_set)\n",
    "        else:\n",
    "            for incoming_edge in rn.network.in_edges(n1):\n",
    "                flag,monomer_set = decompose_monomers(incoming_edge[0],monomer_set)\n",
    "                if flag:\n",
    "                    monomer_set.append(incoming_edge[0])\n",
    "            return(False,monomer_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Node -  A -- set()\n",
      "1\n",
      "Node -  B -- set()\n",
      "2\n",
      "Node -  C -- set()\n",
      "3\n",
      "Node -  AB -- {0, 1}\n",
      "4\n",
      "Node -  AC -- {0, 2}\n",
      "5\n",
      "Node -  BC -- {1, 2}\n",
      "6\n",
      "Node -  ABC -- {0, 1, 2}\n",
      "{(0, 3): 0, (0, 4): 1, (0, 6): 5, (1, 3): 0, (1, 5): 2, (1, 6): 3, (2, 4): 1, (2, 5): 2, (2, 6): 4, (3, 6): 4, (4, 6): 3, (5, 6): 5}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    \n",
    "    flag,monomer_set = decompose_monomers(n,[])\n",
    "    \n",
    "    print(\"Node - \", gtostr(rn.network.nodes[n]['struct']), \"--\", set(monomer_set))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)\n",
    "# print(rn.mon_rxns)\n",
    "# print(gtostr(rn.network.nodes[3]['struct']),rn.network.nodes[3]['struct'].number_of_edges())\n",
    "\n",
    "# print(rn.network.edges(data=True))\n",
    "\n",
    "# print(rn.uid_map)\n",
    "\n",
    "print(rn.rxn_cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "A\n",
      "Reactant Sets:\n",
      "B\n",
      "Reactant Sets:\n",
      "C\n",
      "Reactant Sets:\n",
      "AB\n",
      "Reactant Sets:\n",
      "(0, 1)\n",
      "AC\n",
      "Reactant Sets:\n",
      "(0, 2)\n",
      "BC\n",
      "Reactant Sets:\n",
      "(1, 2)\n",
      "ABC\n",
      "Reactant Sets:\n",
      "(2, 3)\n",
      "(1, 4)\n",
      "(0, 5)\n",
      "tensor([[-1., -1.,  0.,  0.,  0., -1.,  1.,  1., -0., -0., -0.,  1.],\n",
      "        [-1.,  0., -1., -1.,  0.,  0.,  1., -0.,  1.,  1., -0., -0.],\n",
      "        [ 0., -1., -1.,  0., -1.,  0., -0.,  1.,  1., -0.,  1., -0.],\n",
      "        [ 1.,  0.,  0.,  0., -1.,  0., -1., -0., -0., -0.,  1., -0.],\n",
      "        [ 0.,  1.,  0., -1.,  0.,  0., -0., -1., -0.,  1., -0., -0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0., -1., -0., -0., -1., -0., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  1.,  1.,  1., -0., -0., -0., -1., -1., -1.]],\n",
      "       dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = [1.0,1.0,1.0,1.0,1.0,1.0]*np.array([1e0])  #Poor yield Simruntime = 1sec\n",
    "# new_kon = [ 0.1411,  0.1917,  0.1205, 42.6304, 42.7995, 42.6389]*np.array([1e0])\n",
    "# new_kon = [0.4052, 0.4145, 0.4049, 5.0401, 5.9947, 5.9940]\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "# vec_rn = VectorizedRxnNet(rn, dev='cpu',rxn_coupling=True,rx_cid={3:[1],4:[0],5:[2]})\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu',assoc_is_param=False,dissoc_is_param=True)\n",
    "print(vec_rn.kon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Equilibrium Solution ##\n",
    "First we will find the equilibrium solution for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No aceeptable solution found\n",
      "No Equilibrium solution\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "vec_rn.update_reaction_net(rn,1)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve()\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(vec_rn.rxn_coupling)\n",
    "print(rn.rxn_coupling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557, 'uid': 0}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557, 'uid': 1}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557, 'uid': 2}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'A', 'C'}), 'kon': 1.0, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.248354255291587e-12, 'uid': 3}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'C'}, {'A', 'B'}), 'kon': 1.0, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.248354255291587e-12, 'uid': 4}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C', 'B'}), 'kon': 1.0, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.248354255291587e-12, 'uid': 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'AB': 3, 'AC': 4, 'BC': 5, 'ABC': 6}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*solution[edge[1]] - temp_kon*(solution[edge[0]])*(solution[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Free Energy: \",vec_rn.rxn_score_vec[uid])\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(solution[edge[0]])*(solution[node_map[react]])- koff*solution[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "\n",
    "if solution != None:\n",
    "    for n in rn.network.nodes():\n",
    "\n",
    "        n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "\n",
    "        paths = [n_str]\n",
    "        kon_sum = 0\n",
    "        temp_node = n\n",
    "        max_edge = True\n",
    "        consumption_rate = 0\n",
    "        if n < len(rn.network.nodes()):#num_monomers:\n",
    "    #         print(\"Current node: \")\n",
    "    #         print(n_str)\n",
    "            while max_edge:\n",
    "                max_edge = get_max_edge(temp_node)\n",
    "                if max_edge:\n",
    "                    total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                    temp_node = max_edge[1]\n",
    "                    kon_sum += max_edge[0].item()\n",
    "\n",
    "\n",
    "    #                 print(\"Next node: \")\n",
    "    #                 print(temp_node)\n",
    "\n",
    "                    paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "                else:\n",
    "                    break\n",
    "            pathway.append(paths)\n",
    "            kon_sumarray.append(kon_sum)\n",
    "            paths=[]\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"|                                                                             |\")\n",
    "        node_flux = get_node_flux(n)\n",
    "        net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "        print(\"|                                                                             |\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(pathway)\n",
    "    print(kon_sumarray)\n",
    "    #print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if solution != None:\n",
    "    for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if solution !=None:\n",
    "    for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer with a 1 second simulation runtime ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2484e-12, 4.2484e-12, 4.2484e-12],\n",
      "       dtype=torch.float64, requires_grad=True)]\n",
      "Using CPU\n",
      "Next time:  tensor(10.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 0 was 66.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7183, 2.7183, 2.7183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2584e-12, 4.2384e-12, 4.2584e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1 was 66.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7247, 2.7119, 2.7247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2610e-12, 4.2432e-12, 4.2654e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2 was 66.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7264, 2.7150, 2.7292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2635e-12, 4.2475e-12, 4.2712e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3 was 67.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7280, 2.7177, 2.7330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2660e-12, 4.2515e-12, 4.2763e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4 was 67.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7296, 2.7203, 2.7362], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2684e-12, 4.2552e-12, 4.2808e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 5 was 67.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7312, 2.7227, 2.7391], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2708e-12, 4.2587e-12, 4.2849e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 6 was 67.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7327, 2.7249, 2.7418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2731e-12, 4.2620e-12, 4.2887e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 7 was 67.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7342, 2.7270, 2.7442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2754e-12, 4.2651e-12, 4.2923e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 8 was 67.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7356, 2.7290, 2.7466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2776e-12, 4.2681e-12, 4.2957e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 9 was 67.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7370, 2.7310, 2.7488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2797e-12, 4.2710e-12, 4.2989e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 10 was 67.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7384, 2.7328, 2.7508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2819e-12, 4.2738e-12, 4.3020e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0772, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 11 was 67.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7398, 2.7346, 2.7528], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2840e-12, 4.2765e-12, 4.3050e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 12 was 67.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7412, 2.7364, 2.7548], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2860e-12, 4.2791e-12, 4.3078e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 13 was 67.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7425, 2.7380, 2.7566], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2880e-12, 4.2817e-12, 4.3106e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 14 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7438, 2.7397, 2.7584], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2900e-12, 4.2841e-12, 4.3132e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 15 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7451, 2.7413, 2.7601], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2920e-12, 4.2865e-12, 4.3158e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.0971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 16 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7464, 2.7428, 2.7618], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2939e-12, 4.2889e-12, 4.3183e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 17 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7476, 2.7443, 2.7634], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2958e-12, 4.2912e-12, 4.3208e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 18 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7488, 2.7458, 2.7650], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2977e-12, 4.2934e-12, 4.3232e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(10.1079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 19 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7501, 2.7473, 2.7666], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.2996e-12, 4.2956e-12, 4.3255e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 20 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7513, 2.7487, 2.7681], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3014e-12, 4.2978e-12, 4.3278e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 21 was 67.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7525, 2.7501, 2.7696], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3032e-12, 4.2999e-12, 4.3300e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 22 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7536, 2.7515, 2.7710], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3050e-12, 4.3020e-12, 4.3322e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 23 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7548, 2.7528, 2.7725], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3068e-12, 4.3040e-12, 4.3343e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 24 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7559, 2.7541, 2.7739], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3086e-12, 4.3060e-12, 4.3365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 25 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7571, 2.7554, 2.7752], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3103e-12, 4.3080e-12, 4.3385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 26 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7582, 2.7567, 2.7766], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3120e-12, 4.3099e-12, 4.3406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 27 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7593, 2.7580, 2.7779], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3137e-12, 4.3118e-12, 4.3426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 28 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7604, 2.7592, 2.7792], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3154e-12, 4.3137e-12, 4.3446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 29 was 67.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7615, 2.7604, 2.7805], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3171e-12, 4.3156e-12, 4.3465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 30 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7626, 2.7616, 2.7818], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3187e-12, 4.3174e-12, 4.3484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 31 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7637, 2.7628, 2.7831], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3204e-12, 4.3192e-12, 4.3503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 32 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7648, 2.7640, 2.7843], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3220e-12, 4.3210e-12, 4.3522e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 33 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7658, 2.7652, 2.7855], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3236e-12, 4.3228e-12, 4.3540e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 34 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7669, 2.7663, 2.7868], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3252e-12, 4.3246e-12, 4.3559e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 35 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7679, 2.7675, 2.7879], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3268e-12, 4.3263e-12, 4.3577e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(10.1163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 36 was 67.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7689, 2.7686, 2.7891], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3333e-12, 4.3208e-12, 4.3595e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(9.1410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 37 was 67.5%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7732, 2.7651, 2.7903], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3382e-12, 4.3170e-12, 4.3613e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(6.3695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 38 was 67.8%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7764, 2.7626, 2.7915], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3376e-12, 4.3161e-12, 4.3676e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.9045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 39 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7760, 2.7620, 2.7957], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3373e-12, 4.3156e-12, 4.3725e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.5904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 40 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7758, 2.7617, 2.7989], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3371e-12, 4.3153e-12, 4.3767e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 41 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7757, 2.7615, 2.8016], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3371e-12, 4.3152e-12, 4.3803e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 42 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7757, 2.7614, 2.8040], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3371e-12, 4.3152e-12, 4.3836e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 43 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7757, 2.7614, 2.8062], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3372e-12, 4.3153e-12, 4.3866e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 44 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7757, 2.7615, 2.8082], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3279e-12, 4.3253e-12, 4.3767e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 45 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8016], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3768e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 46 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8017], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3770e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 47 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8018], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3771e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 48 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8019], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3773e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 49 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8021], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3775e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 50 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8022], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3776e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 51 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7680, 2.8023], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3778e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 52 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7680, 2.8024], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3780e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 53 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7680, 2.8025], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3781e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 54 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8026], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3783e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 55 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8027], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3785e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2741, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 56 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8028], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3786e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 57 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8029], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3788e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 58 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8030], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3790e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 59 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8032], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3791e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 60 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8033], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3793e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 61 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8034], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3795e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 62 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8035], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3797e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 63 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8036], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3798e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 64 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8037], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3800e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1960, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 65 was 67.9%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8038], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3802e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 66 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8039], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3803e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 67 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8041], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3805e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 68 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8042], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3807e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 69 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8043], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3809e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 70 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8044], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3810e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 71 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8045], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3253e-12, 4.3812e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 72 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8046], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3814e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 73 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8047], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3816e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 74 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8049], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3817e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 75 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8050], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3819e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 76 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7679, 2.8051], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3253e-12, 4.3821e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 77 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7680, 2.8052], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3823e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 78 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8053], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3824e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 79 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8055], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3826e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 80 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8056], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3253e-12, 4.3828e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 81 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8057], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3279e-12, 4.3253e-12, 4.3830e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 82 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8058], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3279e-12, 4.3253e-12, 4.3832e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 83 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7680, 2.8059], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3279e-12, 4.3253e-12, 4.3833e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 84 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7697, 2.7680, 2.8060], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3279e-12, 4.3253e-12, 4.3835e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 85 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7697, 2.7680, 2.8062], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3280e-12, 4.3253e-12, 4.3837e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 86 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7697, 2.7680, 2.8063], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3280e-12, 4.3253e-12, 4.3839e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 87 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7697, 2.7680, 2.8064], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3281e-12, 4.3253e-12, 4.3841e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 88 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7698, 2.7680, 2.8065], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3281e-12, 4.3253e-12, 4.3843e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 89 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7698, 2.7680, 2.8066], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3281e-12, 4.3253e-12, 4.3844e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 90 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7698, 2.7680, 2.8068], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3282e-12, 4.3253e-12, 4.3846e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 91 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7698, 2.7680, 2.8069], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3282e-12, 4.3253e-12, 4.3848e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 92 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7699, 2.7680, 2.8070], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3283e-12, 4.3253e-12, 4.3850e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 93 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7699, 2.7680, 2.8071], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3283e-12, 4.3254e-12, 4.3852e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 94 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7699, 2.7680, 2.8073], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3284e-12, 4.3254e-12, 4.3854e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 95 was 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7700, 2.7680, 2.8074], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3284e-12, 4.3254e-12, 4.3856e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 96 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7700, 2.7680, 2.8075], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3285e-12, 4.3254e-12, 4.3857e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 97 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7700, 2.7680, 2.8076], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3285e-12, 4.3254e-12, 4.3859e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 98 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7701, 2.7680, 2.8078], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3286e-12, 4.3254e-12, 4.3861e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 99 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7701, 2.7680, 2.8079], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3286e-12, 4.3254e-12, 4.3863e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 100 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7701, 2.7680, 2.8080], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3287e-12, 4.3254e-12, 4.3865e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 101 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7702, 2.7680, 2.8081], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3288e-12, 4.3254e-12, 4.3867e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 102 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7702, 2.7680, 2.8083], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3288e-12, 4.3254e-12, 4.3869e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 103 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7703, 2.7680, 2.8084], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3289e-12, 4.3254e-12, 4.3871e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 104 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7703, 2.7680, 2.8085], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3290e-12, 4.3254e-12, 4.3873e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8836, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 105 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7703, 2.7681, 2.8086], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3290e-12, 4.3254e-12, 4.3875e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 106 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7704, 2.7681, 2.8088], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3291e-12, 4.3255e-12, 4.3877e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 107 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7704, 2.7681, 2.8089], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3292e-12, 4.3255e-12, 4.3878e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 108 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7705, 2.7681, 2.8090], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3292e-12, 4.3255e-12, 4.3880e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 109 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7705, 2.7681, 2.8091], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3293e-12, 4.3255e-12, 4.3882e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 110 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7706, 2.7681, 2.8093], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3294e-12, 4.3255e-12, 4.3884e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 111 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7706, 2.7681, 2.8094], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3295e-12, 4.3255e-12, 4.3886e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 112 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7707, 2.7681, 2.8095], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3296e-12, 4.3255e-12, 4.3888e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 113 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7707, 2.7681, 2.8097], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3296e-12, 4.3255e-12, 4.3890e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 114 was 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7708, 2.7681, 2.8098], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3297e-12, 4.3255e-12, 4.3892e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 115 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7709, 2.7681, 2.8099], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3298e-12, 4.3256e-12, 4.3894e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 116 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7709, 2.7681, 2.8101], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3299e-12, 4.3256e-12, 4.3896e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 117 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7710, 2.7681, 2.8102], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3300e-12, 4.3256e-12, 4.3898e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 118 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7710, 2.7681, 2.8103], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3301e-12, 4.3256e-12, 4.3900e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 119 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7711, 2.7682, 2.8105], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3302e-12, 4.3256e-12, 4.3902e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 120 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7711, 2.7682, 2.8106], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3303e-12, 4.3256e-12, 4.3904e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 121 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7712, 2.7682, 2.8107], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3304e-12, 4.3256e-12, 4.3906e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 122 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7713, 2.7682, 2.8109], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3305e-12, 4.3256e-12, 4.3908e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 123 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7713, 2.7682, 2.8110], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3306e-12, 4.3257e-12, 4.3910e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 124 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7714, 2.7682, 2.8111], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3307e-12, 4.3257e-12, 4.3912e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 125 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7715, 2.7682, 2.8113], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3308e-12, 4.3257e-12, 4.3914e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 126 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7715, 2.7682, 2.8114], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3309e-12, 4.3257e-12, 4.3916e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 127 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7716, 2.7682, 2.8115], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3310e-12, 4.3257e-12, 4.3918e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 128 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7717, 2.7682, 2.8117], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3311e-12, 4.3257e-12, 4.3921e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 129 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7718, 2.7682, 2.8118], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3312e-12, 4.3257e-12, 4.3923e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 130 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7718, 2.7683, 2.8119], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3313e-12, 4.3258e-12, 4.3925e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 131 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7719, 2.7683, 2.8121], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3315e-12, 4.3258e-12, 4.3927e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 132 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7720, 2.7683, 2.8122], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3316e-12, 4.3258e-12, 4.3929e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 133 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7721, 2.7683, 2.8124], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3317e-12, 4.3258e-12, 4.3931e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6862, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 134 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7721, 2.7683, 2.8125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3318e-12, 4.3258e-12, 4.3933e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 135 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7722, 2.7683, 2.8126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3320e-12, 4.3258e-12, 4.3935e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6733, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 136 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7723, 2.7683, 2.8128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3321e-12, 4.3259e-12, 4.3937e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 137 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7724, 2.7683, 2.8129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3322e-12, 4.3259e-12, 4.3939e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 138 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7725, 2.7683, 2.8131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3323e-12, 4.3259e-12, 4.3942e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 139 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7726, 2.7683, 2.8132], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3325e-12, 4.3259e-12, 4.3944e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 140 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7726, 2.7684, 2.8133], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3326e-12, 4.3259e-12, 4.3946e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 141 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7727, 2.7684, 2.8135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3327e-12, 4.3259e-12, 4.3948e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 142 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7728, 2.7684, 2.8136], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3329e-12, 4.3260e-12, 4.3950e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 143 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7729, 2.7684, 2.8138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3330e-12, 4.3260e-12, 4.3952e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 144 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7730, 2.7684, 2.8139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3332e-12, 4.3260e-12, 4.3955e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 145 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7731, 2.7684, 2.8140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3333e-12, 4.3260e-12, 4.3957e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 146 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7732, 2.7684, 2.8142], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3335e-12, 4.3260e-12, 4.3959e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 147 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7733, 2.7684, 2.8143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3336e-12, 4.3261e-12, 4.3961e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 148 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7734, 2.7685, 2.8145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3338e-12, 4.3261e-12, 4.3963e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.8183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 149 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7735, 2.7685, 2.8146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3256e-12, 4.3345e-12, 4.3879e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 150 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7681, 2.7740, 2.8091], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3256e-12, 4.3345e-12, 4.3881e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 151 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7682, 2.7740, 2.8092], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3256e-12, 4.3346e-12, 4.3882e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 152 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7682, 2.7740, 2.8092], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3257e-12, 4.3346e-12, 4.3883e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 153 was 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7682, 2.7740, 2.8093], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3257e-12, 4.3346e-12, 4.3885e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 154 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7682, 2.7740, 2.8094], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3257e-12, 4.3346e-12, 4.3886e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 155 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7682, 2.7740, 2.8095], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3258e-12, 4.3346e-12, 4.3887e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 156 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7683, 2.7740, 2.8096], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3258e-12, 4.3346e-12, 4.3889e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 157 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7683, 2.7740, 2.8097], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3258e-12, 4.3346e-12, 4.3890e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 158 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7683, 2.7740, 2.8098], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3259e-12, 4.3346e-12, 4.3891e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 159 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7683, 2.7740, 2.8099], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3259e-12, 4.3346e-12, 4.3893e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 160 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7684, 2.7740, 2.8100], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3260e-12, 4.3346e-12, 4.3894e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 161 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7684, 2.7740, 2.8101], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3260e-12, 4.3346e-12, 4.3895e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 162 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7684, 2.7740, 2.8101], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3260e-12, 4.3346e-12, 4.3897e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 163 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7684, 2.7740, 2.8102], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3261e-12, 4.3346e-12, 4.3898e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 164 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7685, 2.7740, 2.8103], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3261e-12, 4.3346e-12, 4.3900e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8762, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 165 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7685, 2.7740, 2.8104], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3262e-12, 4.3346e-12, 4.3901e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 166 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7685, 2.7740, 2.8105], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3262e-12, 4.3346e-12, 4.3902e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 167 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7686, 2.7741, 2.8106], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3263e-12, 4.3346e-12, 4.3904e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 168 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7686, 2.7741, 2.8107], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3263e-12, 4.3347e-12, 4.3905e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 169 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7686, 2.7741, 2.8108], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3264e-12, 4.3347e-12, 4.3907e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 170 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7687, 2.7741, 2.8109], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3264e-12, 4.3347e-12, 4.3908e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 171 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7687, 2.7741, 2.8110], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3265e-12, 4.3347e-12, 4.3910e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 172 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7687, 2.7741, 2.8111], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3265e-12, 4.3347e-12, 4.3911e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 173 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7688, 2.7741, 2.8112], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3266e-12, 4.3347e-12, 4.3912e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 174 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7688, 2.7741, 2.8113], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3266e-12, 4.3347e-12, 4.3914e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 175 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7688, 2.7741, 2.8114], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3267e-12, 4.3347e-12, 4.3915e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 176 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7689, 2.7741, 2.8115], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3268e-12, 4.3347e-12, 4.3917e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 177 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7689, 2.7741, 2.8116], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3268e-12, 4.3347e-12, 4.3918e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 178 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7689, 2.7741, 2.8117], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3269e-12, 4.3347e-12, 4.3920e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 179 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7690, 2.7741, 2.8117], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3269e-12, 4.3347e-12, 4.3921e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 180 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7690, 2.7741, 2.8118], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3270e-12, 4.3347e-12, 4.3923e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 181 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7691, 2.7741, 2.8119], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3271e-12, 4.3348e-12, 4.3924e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 182 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7691, 2.7741, 2.8120], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3271e-12, 4.3348e-12, 4.3926e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 183 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7692, 2.7741, 2.8121], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3272e-12, 4.3348e-12, 4.3927e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 184 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7692, 2.7741, 2.8122], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3273e-12, 4.3348e-12, 4.3929e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 185 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7692, 2.7741, 2.8123], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3273e-12, 4.3348e-12, 4.3930e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 186 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7693, 2.7742, 2.8124], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3274e-12, 4.3348e-12, 4.3932e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 187 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7693, 2.7742, 2.8125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3275e-12, 4.3348e-12, 4.3933e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 188 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7694, 2.7742, 2.8126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3275e-12, 4.3348e-12, 4.3935e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 189 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7694, 2.7742, 2.8127], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3276e-12, 4.3348e-12, 4.3936e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 190 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7742, 2.8128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3277e-12, 4.3348e-12, 4.3938e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 191 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7695, 2.7742, 2.8129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3348e-12, 4.3939e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 192 was 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7742, 2.8130], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3278e-12, 4.3349e-12, 4.3941e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 193 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7696, 2.7742, 2.8131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3279e-12, 4.3349e-12, 4.3942e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 194 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7697, 2.7742, 2.8132], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3280e-12, 4.3349e-12, 4.3944e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 195 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7697, 2.7742, 2.8134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3281e-12, 4.3349e-12, 4.3946e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 196 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7698, 2.7742, 2.8135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3282e-12, 4.3349e-12, 4.3947e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 197 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7698, 2.7742, 2.8136], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3282e-12, 4.3349e-12, 4.3949e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 198 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7699, 2.7742, 2.8137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3283e-12, 4.3349e-12, 4.3950e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 199 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7699, 2.7742, 2.8138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3284e-12, 4.3349e-12, 4.3952e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 200 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7700, 2.7742, 2.8139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3285e-12, 4.3349e-12, 4.3953e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 201 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7700, 2.7743, 2.8140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3286e-12, 4.3350e-12, 4.3955e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 202 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7701, 2.7743, 2.8141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3287e-12, 4.3350e-12, 4.3957e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6805, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 203 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7702, 2.7743, 2.8142], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3288e-12, 4.3350e-12, 4.3958e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 204 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7702, 2.7743, 2.8143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3289e-12, 4.3350e-12, 4.3960e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 205 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7703, 2.7743, 2.8144], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3290e-12, 4.3350e-12, 4.3961e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 206 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7703, 2.7743, 2.8145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3291e-12, 4.3350e-12, 4.3963e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 207 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7704, 2.7743, 2.8146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3291e-12, 4.3350e-12, 4.3965e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 208 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7705, 2.7743, 2.8147], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3292e-12, 4.3350e-12, 4.3966e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 209 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7705, 2.7743, 2.8148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3293e-12, 4.3351e-12, 4.3968e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 210 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7706, 2.7743, 2.8149], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3294e-12, 4.3351e-12, 4.3970e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 211 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7707, 2.7743, 2.8150], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3295e-12, 4.3351e-12, 4.3971e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 212 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7707, 2.7743, 2.8152], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3297e-12, 4.3351e-12, 4.3973e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 213 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7708, 2.7744, 2.8153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3298e-12, 4.3351e-12, 4.3975e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 214 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7709, 2.7744, 2.8154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3299e-12, 4.3351e-12, 4.3976e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 215 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7709, 2.7744, 2.8155], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3300e-12, 4.3351e-12, 4.3978e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 216 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7710, 2.7744, 2.8156], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3301e-12, 4.3352e-12, 4.3980e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 217 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7711, 2.7744, 2.8157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3302e-12, 4.3352e-12, 4.3981e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 218 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7712, 2.7744, 2.8158], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3303e-12, 4.3352e-12, 4.3983e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 219 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7712, 2.7744, 2.8159], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3304e-12, 4.3352e-12, 4.3985e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 220 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7713, 2.7744, 2.8160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3305e-12, 4.3352e-12, 4.3986e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 221 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7714, 2.7744, 2.8162], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3306e-12, 4.3352e-12, 4.3988e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 222 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7714, 2.7744, 2.8163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3308e-12, 4.3352e-12, 4.3990e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 223 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7715, 2.7745, 2.8164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3309e-12, 4.3353e-12, 4.3992e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 224 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7716, 2.7745, 2.8165], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3310e-12, 4.3353e-12, 4.3993e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 225 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7717, 2.7745, 2.8166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3311e-12, 4.3353e-12, 4.3995e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 226 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7718, 2.7745, 2.8167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3313e-12, 4.3353e-12, 4.3997e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5635, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 227 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7718, 2.7745, 2.8169], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3314e-12, 4.3353e-12, 4.3999e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 228 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7719, 2.7745, 2.8170], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3315e-12, 4.3353e-12, 4.4000e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 229 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7720, 2.7745, 2.8171], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3316e-12, 4.3354e-12, 4.4002e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 230 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7721, 2.7745, 2.8172], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3318e-12, 4.3354e-12, 4.4004e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 231 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7722, 2.7745, 2.8173], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3319e-12, 4.3354e-12, 4.4006e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 232 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7723, 2.7745, 2.8174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3320e-12, 4.3354e-12, 4.4007e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 233 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7723, 2.7746, 2.8176], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3322e-12, 4.3354e-12, 4.4009e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 234 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7724, 2.7746, 2.8177], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3323e-12, 4.3354e-12, 4.4011e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 235 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7725, 2.7746, 2.8178], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3324e-12, 4.3355e-12, 4.4013e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 236 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7726, 2.7746, 2.8179], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3326e-12, 4.3355e-12, 4.4015e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 237 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7727, 2.7746, 2.8180], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3327e-12, 4.3355e-12, 4.4016e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 238 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7728, 2.7746, 2.8182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3329e-12, 4.3355e-12, 4.4018e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 239 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7729, 2.7746, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3929e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 240 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8124], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3930e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 241 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8124], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3931e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 242 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8125], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3932e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 243 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3933e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 244 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8126], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3934e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 245 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8127], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3935e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 246 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3936e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 247 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8128], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3937e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 248 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8129], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3332e-12, 4.3938e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9859, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 249 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8130], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3939e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 250 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8130], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3940e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 251 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8131], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3941e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 252 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8132], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3942e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 253 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8132], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3943e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 254 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8133], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3944e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 255 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3945e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 256 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8134], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3946e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 257 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3947e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 258 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8136], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3332e-12, 4.3948e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 259 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8136], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3949e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 260 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7731, 2.8137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3950e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 261 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7732, 2.8138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3951e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 262 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7732, 2.8138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3952e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 263 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7732, 2.8139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3953e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 264 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7732, 2.8140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3955e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 265 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7732, 2.8140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3956e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 266 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3957e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 267 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8142], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3958e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8960, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 268 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3959e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 269 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3960e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 270 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8144], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3961e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 271 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3962e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 272 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3963e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 273 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3964e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 274 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8147], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3965e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 275 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3333e-12, 4.3966e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 276 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3334e-12, 4.3968e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 277 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8149], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3334e-12, 4.3969e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 278 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8150], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3429e-12, 4.3334e-12, 4.3970e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 279 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8151], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3971e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 280 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8151], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3972e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 281 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8152], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3973e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 282 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7732, 2.8153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3974e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 283 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3975e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 284 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3977e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 285 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8155], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3978e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 286 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8156], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3334e-12, 4.3979e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 287 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3980e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 288 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3981e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 289 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8158], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3982e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 290 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8159], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3984e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 291 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3985e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 292 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3986e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 293 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8161], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3987e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 294 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8162], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3988e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 295 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3430e-12, 4.3335e-12, 4.3989e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 296 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7795, 2.7733, 2.8164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3991e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 297 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7733, 2.8164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3992e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 298 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8165], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3993e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 299 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3994e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 300 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3995e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 301 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8168], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3997e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 302 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8168], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3998e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 303 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8169], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3336e-12, 4.3999e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 304 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8170], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3337e-12, 4.4000e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 305 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8171], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3337e-12, 4.4002e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 306 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8172], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3337e-12, 4.4003e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 307 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8172], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3337e-12, 4.4004e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 308 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7734, 2.8173], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3431e-12, 4.3337e-12, 4.4005e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 309 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7735, 2.8174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3337e-12, 4.4007e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 310 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7735, 2.8175], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3338e-12, 4.4008e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 311 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7735, 2.8176], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3338e-12, 4.4009e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 312 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7735, 2.8177], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3338e-12, 4.4010e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 313 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7735, 2.8177], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3338e-12, 4.4012e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 314 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7796, 2.7735, 2.8178], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3338e-12, 4.4013e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 315 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7735, 2.8179], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3338e-12, 4.4014e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 316 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7735, 2.8180], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3339e-12, 4.4015e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 317 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7735, 2.8181], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3339e-12, 4.4017e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 318 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7736, 2.8182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3339e-12, 4.4018e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 319 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7736, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3432e-12, 4.3339e-12, 4.4019e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 320 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7736, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3433e-12, 4.3339e-12, 4.4021e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 321 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7797, 2.7736, 2.8184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3947e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 322 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8135], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3948e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 323 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8136], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3949e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 324 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3950e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 325 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8137], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3951e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 326 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8138], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3952e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 327 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3953e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 328 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8139], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3954e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 329 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8140], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3955e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 330 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3956e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 331 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8141], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3957e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 332 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8142], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3958e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0687, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 333 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3959e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 334 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8143], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3960e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 335 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8144], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3961e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 336 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8145], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3962e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 337 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3963e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 338 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8146], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3964e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 339 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8147], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3965e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 340 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3966e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 341 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8148], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3968e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 342 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8149], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3969e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 343 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8150], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3970e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 344 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8151], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3971e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 345 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8151], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3972e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 346 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8152], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3973e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 347 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8153], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3974e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 348 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3975e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 349 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8154], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3976e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 350 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8155], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3978e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 351 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8156], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3979e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 352 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8156], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3980e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 353 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8157], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3981e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9571, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 354 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8158], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3982e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 355 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7787, 2.7796, 2.8159], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3983e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 356 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3984e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 357 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8160], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3985e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 358 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8161], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3987e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 359 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8162], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3988e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 360 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3989e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 361 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8163], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3990e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 362 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8164], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3991e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 363 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7796, 2.8165], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3418e-12, 4.3432e-12, 4.3992e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 364 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.3994e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 365 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8166], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.3995e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 366 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8167], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.3996e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 367 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8168], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.3997e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 368 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8169], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.3998e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 369 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8170], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4000e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 370 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8170], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4001e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 371 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8171], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4002e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 372 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8172], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4003e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 373 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8173], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4004e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 374 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4006e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 375 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8174], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4007e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 376 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8175], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3432e-12, 4.4008e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 377 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8176], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3433e-12, 4.4009e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 378 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8177], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3433e-12, 4.4011e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 379 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8178], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3433e-12, 4.4012e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 380 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8178], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3433e-12, 4.4013e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 381 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8179], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3419e-12, 4.3433e-12, 4.4014e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 382 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8180], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4016e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 383 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8181], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4017e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 384 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4018e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 385 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7788, 2.7797, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4019e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 386 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4021e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 387 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4022e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 388 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4023e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 389 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8186], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4024e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 390 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4026e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 391 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8188], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4027e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 392 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8189], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3433e-12, 4.4028e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 393 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7797, 2.8189], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3420e-12, 4.3434e-12, 4.4030e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 394 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4031e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 395 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8191], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4032e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 396 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4034e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 397 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8193], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4035e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 398 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4036e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 399 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8195], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4038e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 400 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4039e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 401 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7789, 2.7798, 2.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4040e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 402 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3421e-12, 4.3434e-12, 4.4042e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 403 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8198], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3434e-12, 4.4043e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 404 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8199], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3434e-12, 4.4044e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 405 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8200], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3435e-12, 4.4046e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 406 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3435e-12, 4.4047e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 407 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8202], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3435e-12, 4.4048e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 408 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8203], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3435e-12, 4.4050e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 409 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8204], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3435e-12, 4.4051e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 410 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7798, 2.8205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3422e-12, 4.3435e-12, 4.4052e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 411 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7799, 2.8205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3423e-12, 4.3435e-12, 4.4054e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 412 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7799, 2.8206], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3423e-12, 4.3435e-12, 4.4055e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 413 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7790, 2.7799, 2.8207], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3423e-12, 4.3435e-12, 4.4057e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 414 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3423e-12, 4.3435e-12, 4.4058e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 415 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8209], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3423e-12, 4.3436e-12, 4.4059e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 416 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8210], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3423e-12, 4.3436e-12, 4.4061e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 417 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8211], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3424e-12, 4.3436e-12, 4.4062e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 418 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8212], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3424e-12, 4.3436e-12, 4.4064e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 419 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8213], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3424e-12, 4.3436e-12, 4.4065e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 420 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8214], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3424e-12, 4.3436e-12, 4.4067e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 421 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3424e-12, 4.3436e-12, 4.4068e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 422 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7791, 2.7799, 2.8216], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3424e-12, 4.3436e-12, 4.4069e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 423 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7799, 2.8217], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3425e-12, 4.3437e-12, 4.4071e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5778, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 424 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8218], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3425e-12, 4.3437e-12, 4.4072e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5724, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 425 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8219], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3425e-12, 4.3437e-12, 4.4074e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 426 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3425e-12, 4.3437e-12, 4.4075e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 427 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8221], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3425e-12, 4.3437e-12, 4.4077e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 428 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3425e-12, 4.3437e-12, 4.4078e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 429 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3426e-12, 4.3437e-12, 4.4080e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 430 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3426e-12, 4.3438e-12, 4.4081e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 431 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7792, 2.7800, 2.8224], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3426e-12, 4.3438e-12, 4.4083e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 432 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7800, 2.8225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3426e-12, 4.3438e-12, 4.4084e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 433 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7800, 2.8226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3426e-12, 4.3438e-12, 4.4086e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 434 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7800, 2.8227], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3427e-12, 4.3438e-12, 4.4087e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 435 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7801, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3427e-12, 4.3438e-12, 4.4089e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 436 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7801, 2.8229], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3427e-12, 4.3438e-12, 4.4090e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 437 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7801, 2.8230], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3427e-12, 4.3439e-12, 4.4092e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 438 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7793, 2.7801, 2.8231], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3427e-12, 4.3439e-12, 4.4093e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 439 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7801, 2.8232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3439e-12, 4.4095e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 440 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7801, 2.8233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3439e-12, 4.4096e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4850, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 441 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7801, 2.8234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3428e-12, 4.3439e-12, 4.4098e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 442 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7794, 2.7801, 2.8235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4018e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 443 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4019e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 444 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4020e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 445 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4021e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 446 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4022e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 447 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4023e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 448 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8186], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4024e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 449 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4025e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 450 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4026e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 451 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8188], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4028e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 452 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8189], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4029e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 453 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4030e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 454 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4031e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 455 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8191], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4032e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 456 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4033e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 457 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8193], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4034e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8813, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 458 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8193], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4035e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 459 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4036e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 460 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8195], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4038e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 461 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4039e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 462 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4040e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 463 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7789, 2.8197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4041e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 464 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8198], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4042e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 465 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8199], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4043e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8397, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 466 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8199], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4045e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 467 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8200], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3421e-12, 4.4046e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 468 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4047e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 469 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8202], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4048e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 470 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8203], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4049e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 471 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8203], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4050e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 472 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8204], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4052e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 473 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4053e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 474 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8206], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4054e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 475 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8206], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4055e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 476 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8207], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4056e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7823, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 477 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3520e-12, 4.3422e-12, 4.4058e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 478 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8209], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3422e-12, 4.4059e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 479 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7854, 2.7790, 2.8210], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3422e-12, 4.4060e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 480 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7790, 2.8210], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3422e-12, 4.4061e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 481 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7790, 2.8211], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3422e-12, 4.4062e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 482 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7790, 2.8212], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4064e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 483 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7790, 2.8213], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4065e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 484 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7790, 2.8214], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4066e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 485 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7790, 2.8215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4067e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 486 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4069e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 487 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8216], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4070e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 488 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8217], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4071e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 489 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8218], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4072e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 490 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8219], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4074e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 491 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3423e-12, 4.4075e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 492 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3424e-12, 4.4076e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 493 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8221], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3521e-12, 4.3424e-12, 4.4077e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 494 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3424e-12, 4.4079e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 495 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3424e-12, 4.4080e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 496 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8224], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3424e-12, 4.4081e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 497 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3424e-12, 4.4083e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 498 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3424e-12, 4.4084e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 499 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7791, 2.8226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3424e-12, 4.4085e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 500 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7792, 2.8227], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3522e-12, 4.3425e-12, 4.4087e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 501 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7855, 2.7792, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4014e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 502 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8180], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4015e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 503 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8180], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4016e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 504 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8181], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4017e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 505 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4018e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 506 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8182], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4019e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 507 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8183], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4020e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 508 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8184], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4021e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 509 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4022e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 510 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8185], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4023e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 511 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8186], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4024e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 512 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4025e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 513 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8187], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4026e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 514 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8188], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4027e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 515 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8189], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4029e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 516 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4030e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 517 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8190], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4031e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 518 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8191], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4032e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 519 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4033e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 520 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8192], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4034e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 521 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8193], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4035e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 522 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8194], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4036e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 523 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8195], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4037e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 524 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8195], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4039e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 525 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8196], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4040e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 526 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8197], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4041e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 527 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8198], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4042e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 528 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8198], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4043e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 529 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8199], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4044e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 530 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8200], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4045e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 531 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4046e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 532 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8201], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4048e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 533 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8202], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4049e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 534 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8203], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4050e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 535 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8204], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4051e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9639, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 536 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4052e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 537 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8205], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4053e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 538 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8206], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4055e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 539 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8207], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4056e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 540 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4057e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 541 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8208], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4058e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 542 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8209], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4059e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 543 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8210], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4061e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 544 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8211], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4062e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 545 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8212], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4063e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 546 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8212], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4064e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 547 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8213], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4065e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 548 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8214], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4067e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 549 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4068e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 550 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8216], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4069e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 551 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8217], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4070e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 552 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8217], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4072e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 553 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8218], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4073e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 554 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8219], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4074e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 555 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4075e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 556 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8221], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4077e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 557 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8221], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4078e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 558 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4079e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 559 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4080e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 560 was 68.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8224], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4082e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 561 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4083e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 562 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4084e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 563 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8227], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3515e-12, 4.4085e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 564 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8227], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4087e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 565 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4088e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 566 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7846, 2.7851, 2.8229], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4089e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 567 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8230], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4091e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 568 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8231], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3508e-12, 4.3516e-12, 4.4092e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 569 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4093e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 570 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4095e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 571 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4096e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 572 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4097e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 573 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4099e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 574 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7851, 2.8236], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4100e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 575 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8237], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4101e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 576 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4103e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 577 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8239], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4104e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 578 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8240], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4105e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 579 was 68.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8240], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4107e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 580 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4108e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 581 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3509e-12, 4.3516e-12, 4.4109e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 582 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8243], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3516e-12, 4.4111e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 583 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4112e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 584 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8245], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4113e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 585 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8246], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4115e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 586 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7847, 2.7852, 2.8247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4116e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 587 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8248], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4118e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 588 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8249], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4119e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 589 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4120e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 590 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8251], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4122e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 591 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8251], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3510e-12, 4.3517e-12, 4.4123e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 592 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3517e-12, 4.4125e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 593 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8253], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3517e-12, 4.4126e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 594 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8254], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3517e-12, 4.4127e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 595 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7852, 2.8255], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3518e-12, 4.4129e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 596 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7853, 2.8256], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3518e-12, 4.4130e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 597 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7853, 2.8257], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3518e-12, 4.4132e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 598 was 68.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7853, 2.8258], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3518e-12, 4.4133e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 599 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7848, 2.7853, 2.8259], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3511e-12, 4.3518e-12, 4.4135e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 600 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8260], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3518e-12, 4.4136e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 601 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8261], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3518e-12, 4.4137e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5840, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 602 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8262], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3518e-12, 4.4139e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 603 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8263], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3518e-12, 4.4140e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 604 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3518e-12, 4.4142e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 605 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3519e-12, 4.4143e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 606 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3512e-12, 4.3519e-12, 4.4145e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 607 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3513e-12, 4.3519e-12, 4.4146e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 608 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8268], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3513e-12, 4.3519e-12, 4.4148e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5438, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 609 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7849, 2.7853, 2.8269], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3513e-12, 4.3519e-12, 4.4149e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 610 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8270], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3513e-12, 4.3519e-12, 4.4151e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 611 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3513e-12, 4.3519e-12, 4.4152e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 612 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8272], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3513e-12, 4.3519e-12, 4.4154e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 613 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8273], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3514e-12, 4.3520e-12, 4.4155e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 614 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3514e-12, 4.3520e-12, 4.4157e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 615 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3514e-12, 4.3520e-12, 4.4158e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 616 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8276], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3514e-12, 4.3520e-12, 4.4160e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 617 was 68.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3514e-12, 4.3520e-12, 4.4161e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 618 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7850, 2.7854, 2.8278], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3515e-12, 4.3520e-12, 4.4163e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 619 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7851, 2.7854, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3515e-12, 4.3520e-12, 4.4164e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 620 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7851, 2.7854, 2.8280], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3515e-12, 4.3521e-12, 4.4166e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 621 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7851, 2.7855, 2.8281], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4084e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 622 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4085e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 623 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8227], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4086e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 624 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4087e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 625 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4088e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 626 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8229], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4089e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 627 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8230], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4090e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 628 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8231], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4091e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 629 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8231], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4092e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 630 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4093e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 631 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4094e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 632 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4096e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 633 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4097e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 634 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4098e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 635 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4099e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 636 was 68.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8236], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4100e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 637 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8237], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4101e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 638 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7911, 2.7842, 2.8238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4102e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 639 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4103e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 640 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8239], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4104e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 641 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8240], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4105e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 642 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4106e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 643 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4108e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8641, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 644 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4109e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 645 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8243], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4110e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 646 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3501e-12, 4.4111e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 647 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3607e-12, 4.3502e-12, 4.4112e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 648 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8245], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4113e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 649 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8246], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4114e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 650 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4115e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 651 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4117e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 652 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8248], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4118e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 653 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8249], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4119e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 654 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4120e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 655 was 68.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4121e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 656 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8251], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4122e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 657 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4124e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 658 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8253], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4125e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 659 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8253], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4126e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 660 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8254], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4127e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 661 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8255], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4128e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 662 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8256], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4129e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 663 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8257], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4131e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 664 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8257], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4132e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 665 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8258], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4133e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 666 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7842, 2.8259], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4134e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 667 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8260], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4135e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 668 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8261], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4137e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 669 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8261], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3502e-12, 4.4138e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 670 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8262], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4139e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 671 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8263], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4140e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 672 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4142e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 673 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4143e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 674 was 68.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4144e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 675 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4145e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 676 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3608e-12, 4.3503e-12, 4.4147e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 677 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7912, 2.7843, 2.8268], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4067e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 678 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8215], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4068e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 679 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8216], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4069e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 680 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8216], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4070e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 681 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8217], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4071e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 682 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8218], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4072e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 683 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8218], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4073e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 684 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8219], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4074e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 685 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4075e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 686 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8220], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4076e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 687 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8221], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4076e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 688 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8221], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4077e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 689 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8222], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4078e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 690 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7904, 2.8223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4079e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 691 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7904, 2.8223], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4080e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1762, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 692 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7904, 2.8224], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4081e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 693 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4082e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 694 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8225], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4083e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 695 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4084e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 696 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8226], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4085e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 697 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8227], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4086e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 698 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4087e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 699 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8228], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4088e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 700 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8229], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4089e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 701 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8230], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4090e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 702 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8230], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4091e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 703 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8231], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4092e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 704 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4093e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 705 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8232], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4094e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 706 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8233], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4095e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 707 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4096e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 708 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8234], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4097e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 709 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8235], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4098e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0778, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 710 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8236], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4099e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 711 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8236], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4100e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 712 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8237], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4101e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 713 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4102e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 714 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8238], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4103e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 715 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8239], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4104e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 716 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8240], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4105e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 717 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8240], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4106e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 718 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8241], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4107e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 719 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4108e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 720 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8242], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3596e-12, 4.4109e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 721 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8243], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4110e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 722 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4111e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 723 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8244], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4112e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 724 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8245], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4113e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 725 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8246], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4114e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 726 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4115e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 727 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8247], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4117e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 728 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8248], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4118e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9732, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 729 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8249], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4119e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9677, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 730 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8249], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4120e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 731 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8250], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4121e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9566, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 732 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8251], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4122e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 733 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4123e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 734 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8252], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4124e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 735 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8253], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4125e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 736 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8254], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4126e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 737 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8255], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4127e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 738 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8255], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4129e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 739 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8256], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4130e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 740 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8257], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4131e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 741 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8258], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4132e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 742 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8258], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4133e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 743 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8259], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4134e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 744 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8260], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4135e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 745 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8261], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4136e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 746 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8261], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4138e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 747 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8262], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4139e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 748 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8263], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4140e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 749 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4141e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 750 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4142e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 751 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4143e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 752 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4145e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 753 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4146e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 754 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4147e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 755 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8268], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4148e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 756 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7903, 2.8269], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4149e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 757 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8270], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4150e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 758 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4152e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 759 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4153e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 760 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8272], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4154e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 761 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8273], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4155e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 762 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4156e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 763 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4158e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 764 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4159e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 765 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8276], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4160e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 766 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4161e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 767 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8278], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4163e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 768 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4164e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 769 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3595e-12, 4.4165e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 770 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8280], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3590e-12, 4.3596e-12, 4.4166e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 771 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8281], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4167e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 772 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8282], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4169e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 773 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7900, 2.7904, 2.8283], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4170e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 774 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8284], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4171e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 775 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8284], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4173e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 776 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4174e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 777 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8286], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4175e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 778 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8287], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4176e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 779 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8288], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4178e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 780 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8289], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4179e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 781 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8289], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4180e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 782 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8290], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4181e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6734, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 783 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8291], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4183e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 784 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4184e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 785 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8293], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3591e-12, 4.3596e-12, 4.4185e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 786 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8294], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4187e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 787 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4188e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 788 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4189e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 789 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4191e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 790 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8297], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3596e-12, 4.4192e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 791 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4193e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 792 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4195e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 793 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7901, 2.7904, 2.8300], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4196e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 794 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7904, 2.8301], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4197e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 795 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7904, 2.8302], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3592e-12, 4.3597e-12, 4.4199e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 796 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8303], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4200e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 797 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4201e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 798 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4203e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 799 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8305], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4204e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 800 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8306], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4205e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5734, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 801 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4207e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 802 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4208e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 803 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8309], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3593e-12, 4.3597e-12, 4.4210e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 804 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3597e-12, 4.4211e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 805 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3598e-12, 4.4212e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 806 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7902, 2.7905, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3598e-12, 4.4214e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 807 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8313], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3598e-12, 4.4215e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 808 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3598e-12, 4.4217e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 809 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3598e-12, 4.4218e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 810 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3594e-12, 4.3598e-12, 4.4219e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 811 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3598e-12, 4.4221e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 812 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8317], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3598e-12, 4.4222e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 813 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7905, 2.8318], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3598e-12, 4.4224e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 814 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7906, 2.8319], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3598e-12, 4.4225e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 815 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7906, 2.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3599e-12, 4.4227e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 816 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7903, 2.7906, 2.8321], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3599e-12, 4.4228e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 817 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7904, 2.7906, 2.8322], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3595e-12, 4.3599e-12, 4.4229e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 818 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7904, 2.7906, 2.8323], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3596e-12, 4.3599e-12, 4.4231e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.9407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 819 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7904, 2.7906, 2.8324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4153e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9778, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 820 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8272], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4154e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 821 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8273], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4155e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 822 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4156e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 823 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4157e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 824 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4158e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 825 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8276], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4159e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 826 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4160e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 827 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4162e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 828 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8278], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4163e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 829 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4164e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 830 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3584e-12, 4.4165e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 831 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8280], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4166e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 832 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8281], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4167e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 833 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8282], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4168e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 834 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8282], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4169e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 835 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8283], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4170e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 836 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8284], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4172e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 837 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4173e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 838 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4174e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 839 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8286], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4175e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 840 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8287], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4176e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 841 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8288], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4177e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 842 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8288], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4178e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 843 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8289], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4180e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 844 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8290], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4181e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 845 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8291], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4182e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 846 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4183e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 847 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4184e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 848 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8293], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4185e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 849 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8294], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4187e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 850 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4188e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 851 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4189e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 852 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4190e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 853 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8297], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4191e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 854 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4193e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7813, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 855 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4194e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 856 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4195e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7700, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 857 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8300], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4196e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 858 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8301], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4197e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 859 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8302], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4199e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 860 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8303], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4200e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 861 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8303], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3687e-12, 4.3583e-12, 4.4201e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 862 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4202e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 863 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8305], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4204e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 864 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8306], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4205e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 865 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4206e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 866 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4207e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 867 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4209e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 868 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8309], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4210e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 869 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4211e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 870 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3688e-12, 4.3584e-12, 4.4212e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 871 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7964, 2.7896, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3676e-12, 4.3673e-12, 4.4140e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 872 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3676e-12, 4.3673e-12, 4.4141e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 873 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8264], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3676e-12, 4.3673e-12, 4.4142e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 874 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8265], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4143e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 875 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8266], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4144e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 876 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4145e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 877 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8267], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4147e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 878 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8268], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4148e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 879 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8269], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4149e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1748, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 880 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8269], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4150e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 881 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8270], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4151e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 882 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3672e-12, 4.4152e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 883 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8271], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3672e-12, 4.4153e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 884 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8272], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4154e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 885 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8273], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4155e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 886 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4156e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 887 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8274], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4157e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 888 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8275], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4158e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 889 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8276], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4159e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 890 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4161e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 891 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8277], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4162e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 892 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8278], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4163e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 893 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4164e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 894 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8279], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4165e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 895 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8280], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4166e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 896 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8281], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3672e-12, 4.4167e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 897 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8282], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3672e-12, 4.4168e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 898 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8282], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4169e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 899 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8283], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4171e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 900 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8284], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4172e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 901 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4173e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 902 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8285], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4174e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 903 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8286], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4175e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 904 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8287], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4176e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 905 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8288], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4177e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 906 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8289], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4179e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 907 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8289], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4180e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 908 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8290], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4181e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 909 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8291], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4182e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 910 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4183e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 911 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8292], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4184e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 912 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8293], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4186e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 913 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8294], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4187e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 914 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8295], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4188e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 915 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4189e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 916 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8296], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4190e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 917 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8297], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4191e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 918 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8298], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4193e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 919 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4194e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 920 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4195e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 921 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8300], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4196e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 922 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8301], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4198e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 923 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8302], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4199e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 924 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8303], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4200e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 925 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4201e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 926 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4202e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 927 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8305], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4204e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 928 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8306], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4205e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8688, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 929 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4206e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8626, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 930 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4207e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 931 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4209e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 932 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8309], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4210e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 933 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4211e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 934 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4212e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 935 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4214e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 936 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8313], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4215e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 937 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4216e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 938 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4217e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 939 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4219e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 940 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4220e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 941 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8317], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4221e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 942 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8318], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4223e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7823, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 943 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8319], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4224e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 944 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4225e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 945 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4227e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 946 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8321], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4228e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 947 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8322], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4229e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 948 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8323], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4230e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 949 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3670e-12, 4.4232e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 950 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8325], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4233e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 951 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8326], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4234e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 952 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4236e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 953 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4237e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 954 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8328], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4238e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 955 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8329], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4240e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 956 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4241e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 957 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4243e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 958 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4244e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6840, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 959 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8333], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4245e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 960 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8334], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4247e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 961 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8335], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4248e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 962 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3672e-12, 4.3671e-12, 4.4249e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 963 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4251e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 964 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8337], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4252e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 965 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8338], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4254e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 966 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4255e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 967 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8340], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4256e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 968 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7954, 2.7953, 2.8341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4258e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 969 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8342], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4259e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 970 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4261e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 971 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7953, 2.8344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4262e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 972 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4263e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 973 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8346], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4265e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 974 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3671e-12, 4.4266e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 975 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3672e-12, 4.4268e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 976 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8349], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3673e-12, 4.3672e-12, 4.4269e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 977 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8350], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4271e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 978 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4272e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 979 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4273e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 980 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8353], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4275e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 981 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4276e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 982 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4278e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 983 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4279e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 984 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7955, 2.7954, 2.8356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4281e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 985 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3674e-12, 4.3672e-12, 4.4282e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 986 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8358], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3672e-12, 4.4284e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 987 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8359], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3672e-12, 4.4285e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 988 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4287e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 989 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8361], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4288e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4962, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 990 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8362], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4290e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 991 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7954, 2.8363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4291e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 992 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3675e-12, 4.3673e-12, 4.4293e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.0934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 993 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7956, 2.7955, 2.8365], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3653e-12, 4.3760e-12, 4.4211e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 994 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3653e-12, 4.3760e-12, 4.4212e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 995 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4213e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 996 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4214e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 997 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8313], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4215e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 998 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4216e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 999 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4217e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1000 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4218e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1001 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4219e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1002 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8317], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4220e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1003 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8317], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4222e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1004 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8318], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4223e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1005 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8319], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4224e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1006 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8319], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3652e-12, 4.3760e-12, 4.4225e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1007 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7941, 2.8012, 2.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4226e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1008 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8321], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4227e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1009 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8321], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4228e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1010 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8322], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4229e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1011 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8323], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4230e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1012 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4231e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1013 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4232e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1014 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8325], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4233e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1015 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8326], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4235e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1016 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4236e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1017 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4237e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1018 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8328], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4238e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1019 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8329], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4239e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1020 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4240e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1021 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4241e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1022 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4242e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1023 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4243e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1024 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8333], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4245e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1025 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8333], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4246e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1026 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8334], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4247e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1027 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8335], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4248e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1028 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4249e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1029 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4250e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1030 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8337], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4251e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7801, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1031 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8338], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4253e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1032 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4254e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1033 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4255e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1034 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8340], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4256e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1035 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4257e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1036 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8342], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4259e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1037 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4260e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1038 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4261e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1039 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4262e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1040 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4263e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1041 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8346], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4264e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1042 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3651e-12, 4.3760e-12, 4.4266e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1043 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7940, 2.8012, 2.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3746e-12, 4.3749e-12, 4.4194e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1044 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8005, 2.8299], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3749e-12, 4.4195e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1045 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8005, 2.8300], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3749e-12, 4.4196e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1046 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8005, 2.8301], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3749e-12, 4.4197e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2626, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1047 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8005, 2.8301], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3749e-12, 4.4198e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1048 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8005, 2.8302], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3749e-12, 4.4199e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1049 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8303], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3749e-12, 4.4200e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1050 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8303], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3748e-12, 4.4201e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1051 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8304], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3748e-12, 4.4202e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1052 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8305], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3748e-12, 4.4203e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1053 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8306], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3748e-12, 4.4204e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1054 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8306], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3745e-12, 4.3748e-12, 4.4205e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1055 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8307], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3748e-12, 4.4206e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1056 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3748e-12, 4.4207e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1057 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8308], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3748e-12, 4.4208e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1058 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8002, 2.8004, 2.8309], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3748e-12, 4.4209e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1059 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8004, 2.8310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3748e-12, 4.4210e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1060 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8004, 2.8310], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3747e-12, 4.4211e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1061 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8004, 2.8311], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3747e-12, 4.4212e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1062 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8004, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3747e-12, 4.4213e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1063 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8004, 2.8312], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3747e-12, 4.4214e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1064 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8313], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3747e-12, 4.4216e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1065 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8314], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3744e-12, 4.3747e-12, 4.4217e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1066 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3747e-12, 4.4218e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1067 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8315], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3747e-12, 4.4219e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1068 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8316], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3747e-12, 4.4220e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1069 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8317], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3747e-12, 4.4221e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1070 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8318], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4222e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1071 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8318], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4223e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1072 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8319], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4224e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1073 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4225e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1074 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8320], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4226e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0829, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1075 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8321], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4227e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1076 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8322], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4229e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1077 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8323], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4230e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1078 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8001, 2.8003, 2.8323], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4231e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1079 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8003, 2.8324], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4232e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1080 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8003, 2.8325], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3746e-12, 4.4233e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1081 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8326], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3746e-12, 4.4234e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1082 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8326], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3746e-12, 4.4235e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1083 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8327], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4236e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1084 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8328], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4238e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1085 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8329], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4239e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1086 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8329], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4240e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1087 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8330], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4241e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1088 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8331], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4242e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1089 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4243e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1090 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8332], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4244e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1091 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8333], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4246e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1092 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8334], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4247e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1093 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8335], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4248e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1094 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4249e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1095 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8336], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4250e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9492, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1096 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8337], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4251e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1097 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8338], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4253e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1098 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3745e-12, 4.4254e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1099 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4255e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1100 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8340], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4256e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1101 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4257e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1102 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8342], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4259e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1103 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4260e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1104 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4261e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1105 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4262e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8859, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1106 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4263e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1107 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8346], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4265e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8733, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1108 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8001, 2.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4266e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8670, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1109 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4267e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1110 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4268e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1111 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8349], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4270e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1112 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8350], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4271e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1113 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4272e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1114 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4273e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1115 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4275e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1116 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8353], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4276e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1117 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4277e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1118 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4278e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1119 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4280e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1120 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4281e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1121 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8358], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4282e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1122 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8358], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4283e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1123 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8359], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4285e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1124 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4286e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1125 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8361], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4287e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1126 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8362], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4289e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1127 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4290e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1128 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4291e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1129 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4293e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1130 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8365], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4294e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1131 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8366], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4295e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1132 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4296e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1133 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8368], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4298e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1134 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4299e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1135 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8370], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4300e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1136 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8371], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4302e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1137 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8371], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4303e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1138 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8372], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4304e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1139 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4306e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1140 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4307e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1141 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8375], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4309e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1142 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8376], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4310e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1143 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4311e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1144 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8378], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4313e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1145 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8379], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4314e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1146 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.7999, 2.8001, 2.8380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4315e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1147 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8001, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4317e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1148 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4318e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1149 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8382], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4320e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1150 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4321e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1151 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8384], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4322e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1152 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4324e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1153 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8386], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3744e-12, 4.4325e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1154 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8387], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3741e-12, 4.3745e-12, 4.4327e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5805, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1155 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4328e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1156 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8389], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4329e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1157 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4331e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1158 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8391], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4332e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1159 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4334e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1160 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4335e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5437, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1161 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4337e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1162 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4338e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1163 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4339e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1164 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8397], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4341e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1165 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4342e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1166 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3745e-12, 4.4344e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1167 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3746e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1168 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3746e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.4949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1169 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8002, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3742e-12, 4.3746e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1170 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8003, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3743e-12, 4.3746e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.9430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1171 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8000, 2.8003, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3728e-12, 4.4271e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1172 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8058, 2.7991, 2.8351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3728e-12, 4.4272e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1173 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7991, 2.8351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3728e-12, 4.4273e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1174 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7991, 2.8352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4274e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1175 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8353], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4275e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1176 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4276e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1177 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4277e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1178 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4278e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1179 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4279e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1180 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4281e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1181 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4282e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1182 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8358], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3727e-12, 4.4283e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1183 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8359], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3726e-12, 4.4284e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1184 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3726e-12, 4.4285e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1185 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3829e-12, 4.3726e-12, 4.4286e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1186 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8361], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4287e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1187 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8362], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4288e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1188 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4290e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1189 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4291e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1190 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7990, 2.8364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4292e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1191 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8365], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4293e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1192 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8366], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4294e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1193 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8366], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4295e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1194 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4296e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1195 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8368], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3726e-12, 4.4298e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1196 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4299e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1197 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4300e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1198 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8370], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4301e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1199 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8371], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4302e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1200 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8372], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4303e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1201 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4305e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1202 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4306e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1203 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4307e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1204 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8375], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4308e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1205 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8376], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4309e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1206 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4311e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1207 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4312e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7820, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1208 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8378], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4313e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1209 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8379], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4314e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7700, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1210 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4315e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7641, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1211 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4317e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1212 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4318e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1213 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8382], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4319e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1214 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4320e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1215 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8384], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4321e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1216 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4323e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1217 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4324e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1218 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8386], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4325e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1219 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8387], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3828e-12, 4.3725e-12, 4.4326e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1220 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8057, 2.7989, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3817e-12, 4.3819e-12, 4.4252e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1221 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8051, 2.8338], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3817e-12, 4.3819e-12, 4.4253e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1222 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8051, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3817e-12, 4.3819e-12, 4.4254e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1223 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8051, 2.8339], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3819e-12, 4.4255e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1224 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8051, 2.8340], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3819e-12, 4.4256e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1225 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8051, 2.8341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3818e-12, 4.4257e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1226 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8050, 2.8341], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3818e-12, 4.4258e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1227 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8050, 2.8342], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3818e-12, 4.4259e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1228 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8050, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3818e-12, 4.4260e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1229 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8050, 2.8343], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3816e-12, 4.3818e-12, 4.4261e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1230 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8050, 2.8344], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3818e-12, 4.4262e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1231 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8049, 2.8050, 2.8345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3818e-12, 4.4263e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1232 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8345], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3818e-12, 4.4264e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1233 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8346], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3818e-12, 4.4265e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1234 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8347], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3817e-12, 4.4266e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1235 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3817e-12, 4.4267e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1236 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8348], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3817e-12, 4.4268e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1990, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1237 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8349], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3815e-12, 4.3817e-12, 4.4269e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1238 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8350], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4270e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1239 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8350], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4271e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1240 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8351], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4272e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1724, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1241 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8050, 2.8352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4273e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1242 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8049, 2.8352], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4274e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1243 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8048, 2.8049, 2.8353], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4275e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1244 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8354], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3817e-12, 4.4276e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1245 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3816e-12, 4.4278e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1246 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8355], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3814e-12, 4.3816e-12, 4.4279e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1247 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8356], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4280e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1248 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4281e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1249 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8357], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4282e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1250 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8358], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4283e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1251 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8359], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4284e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1252 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4285e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1253 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8360], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4286e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1254 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8361], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4287e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1255 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8362], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3813e-12, 4.3816e-12, 4.4288e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1256 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3816e-12, 4.4290e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1257 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8047, 2.8049, 2.8363], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4291e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1258 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8049, 2.8364], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4292e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1259 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8365], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4293e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1260 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8366], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4294e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1261 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8366], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4295e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1262 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8367], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4296e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1263 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8368], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4297e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0204, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1264 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4299e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1265 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8369], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3812e-12, 4.3815e-12, 4.4300e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1266 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8370], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3815e-12, 4.4301e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1267 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8371], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3815e-12, 4.4302e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1268 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8372], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3815e-12, 4.4303e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1269 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8372], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3815e-12, 4.4304e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1270 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3815e-12, 4.4306e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1271 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3815e-12, 4.4307e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1272 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8375], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4308e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1273 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8376], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4309e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1274 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8046, 2.8048, 2.8376], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4310e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1275 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4311e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1276 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8378], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4313e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1277 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8379], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4314e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1278 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8379], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4315e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1279 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4316e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1280 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4317e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1281 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8382], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4319e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1282 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4320e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1283 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4321e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1284 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8384], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4322e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1285 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4323e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1286 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8386], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4325e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1287 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8387], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4326e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1288 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4327e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1289 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4328e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1290 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8389], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4330e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1291 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4331e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1292 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8391], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4332e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1293 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4333e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1294 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4334e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1295 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4336e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1296 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4337e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1297 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4338e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1298 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4340e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1299 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8397], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4341e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7867, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1300 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4342e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1301 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4343e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1302 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1303 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1304 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1305 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1306 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1307 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1308 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1309 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4354e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1310 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4355e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1311 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1312 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4358e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1313 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1314 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1315 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4362e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1316 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1317 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6720, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1318 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1319 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1320 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1321 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1322 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8044, 2.8047, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1323 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1324 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1325 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1326 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1327 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3809e-12, 4.3813e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1328 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1329 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1330 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1331 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1332 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1333 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3813e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1334 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1335 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1336 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1337 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1338 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1339 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1340 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1341 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1342 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8047, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1343 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1344 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1345 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3810e-12, 4.3814e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1346 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3811e-12, 4.3814e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1347 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8045, 2.8048, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3798e-12, 4.4322e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1348 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8037, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3798e-12, 4.4323e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1349 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8037, 2.8386], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3798e-12, 4.4324e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1350 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8037, 2.8387], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4325e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1351 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8037, 2.8387], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4326e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1352 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8037, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4327e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1353 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8037, 2.8389], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4328e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1354 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8389], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4329e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1355 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4330e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1356 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8391], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3903e-12, 4.3797e-12, 4.4331e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1357 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8391], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3797e-12, 4.4332e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1358 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4333e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1359 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4334e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1360 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4335e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1361 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4336e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1362 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4338e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1363 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4339e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1364 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4340e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1365 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8036, 2.8397], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4341e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1366 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8397], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3796e-12, 4.4342e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1367 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4343e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1368 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4344e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1369 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1370 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1371 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1372 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1373 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4349e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1374 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1375 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1376 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8106, 2.8035, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1377 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8035, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3795e-12, 4.4353e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1378 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8035, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3794e-12, 4.4355e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1379 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8035, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3902e-12, 4.3794e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1380 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8035, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1381 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8035, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4358e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1382 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8035, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8518, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1383 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1384 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4361e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1385 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4362e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1386 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1387 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1388 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1389 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1390 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1391 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3794e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1392 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1393 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1394 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1395 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1396 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1397 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1398 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1399 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1400 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1401 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1402 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3901e-12, 4.3793e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1403 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8105, 2.8034, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3889e-12, 4.3887e-12, 4.4304e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1404 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8097, 2.8096, 2.8373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3889e-12, 4.3887e-12, 4.4305e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1405 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8097, 2.8096, 2.8373], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3889e-12, 4.3887e-12, 4.4306e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1406 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8097, 2.8096, 2.8374], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3888e-12, 4.3887e-12, 4.4307e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1407 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8097, 2.8096, 2.8375], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3888e-12, 4.3887e-12, 4.4307e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1408 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8097, 2.8096, 2.8375], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3888e-12, 4.3887e-12, 4.4308e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1409 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8097, 2.8096, 2.8376], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3888e-12, 4.3887e-12, 4.4309e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1410 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8376], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3888e-12, 4.3886e-12, 4.4310e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1411 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8377], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3888e-12, 4.3886e-12, 4.4311e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1412 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8378], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4312e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1413 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8378], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4313e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1414 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8379], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4314e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1415 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4315e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1416 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8380], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4316e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1417 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4317e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1418 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8381], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3887e-12, 4.3886e-12, 4.4318e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1419 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8096, 2.8095, 2.8382], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4319e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1420 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8095, 2.8383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4319e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1421 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8095, 2.8383], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4320e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1422 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8095, 2.8384], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4321e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1423 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8095, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4322e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1424 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8095, 2.8385], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4323e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1425 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8094, 2.8386], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3886e-12, 4.3885e-12, 4.4324e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1426 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8094, 2.8386], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3885e-12, 4.4325e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1427 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8094, 2.8387], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3885e-12, 4.4326e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1428 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8094, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3885e-12, 4.4327e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1429 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8095, 2.8094, 2.8388], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3884e-12, 4.4328e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1430 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8389], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3884e-12, 4.4329e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1431 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3884e-12, 4.4330e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1432 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8390], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3884e-12, 4.4331e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1813, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1433 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8391], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4332e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1434 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4333e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1435 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8392], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4334e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1436 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8393], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4335e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1437 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4336e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1438 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8394], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4337e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1439 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8395], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3884e-12, 4.4338e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1440 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8094, 2.8396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4339e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1441 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8396], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4340e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1442 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8397], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4341e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1443 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4342e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1444 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8398], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4343e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1445 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8399], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4344e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1446 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1447 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3883e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0859, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1448 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3883e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1449 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3883e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0732, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1450 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3883e-12, 4.4349e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1451 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3883e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1452 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3883e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1453 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8093, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3882e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1454 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8093, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3882e-12, 4.4353e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1455 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8093, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3882e-12, 4.4355e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1456 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8093, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3882e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1457 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8093, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1458 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8093, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4358e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1459 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8093, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1460 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1461 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4361e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1462 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4362e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1463 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1464 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1465 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9720, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1466 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3882e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1467 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8092, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1468 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1469 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1470 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1471 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1472 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1473 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1474 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1475 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1476 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1477 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1478 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3881e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1479 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3881e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8841, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1480 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3881e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8778, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1481 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3881e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1482 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3881e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1483 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3881e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1484 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3881e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1485 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8092, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1486 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8091, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1487 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8091, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1488 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1489 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1490 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1491 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1492 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1493 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1494 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1495 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7844, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1496 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1497 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7720, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1498 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1499 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1500 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1501 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1502 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1503 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1504 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1505 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1506 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1507 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1508 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1509 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1510 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1511 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1512 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6794, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1513 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6732, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1514 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1515 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1516 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1517 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1518 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1519 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1520 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1521 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1522 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1523 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1524 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1525 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1526 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1527 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1528 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1529 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1530 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1531 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1532 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1533 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1534 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1535 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1536 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1537 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1538 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1539 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1540 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3878e-12, 4.3880e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1541 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1542 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1543 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3880e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1544 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8090, 2.8091, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1545 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8082, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1546 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1547 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1548 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1549 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1550 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3865e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1551 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3864e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1552 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3864e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1553 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3864e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1554 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3864e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1555 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3864e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1556 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8081, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3864e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1557 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8080, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3864e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1558 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8080, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3864e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1559 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8080, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1560 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1561 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1562 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1563 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1564 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1565 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1566 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3863e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1567 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3862e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1568 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3862e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1569 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8080, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3862e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1570 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1571 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1572 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1573 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1574 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1575 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1576 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3862e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1577 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1578 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8752, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1579 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1580 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1581 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1582 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1583 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1584 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8079, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1585 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1586 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1587 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3861e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1588 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1589 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1590 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1591 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8151, 2.8078, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1592 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1593 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1594 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3970e-12, 4.3860e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1595 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3969e-12, 4.3860e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1596 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3969e-12, 4.3860e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1597 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3969e-12, 4.3860e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1598 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3969e-12, 4.3860e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1599 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3969e-12, 4.3860e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1600 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3969e-12, 4.3860e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1601 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8150, 2.8078, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.3952e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1602 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8139, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.3952e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1603 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8139, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.3952e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1604 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8139, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.3951e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1605 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8138, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.3951e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1606 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8138, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.3951e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1607 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8138, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.3951e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1608 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8138, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.3951e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1609 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8138, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.3951e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1610 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3951e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1611 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3951e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1612 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3950e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1613 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3950e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1614 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3950e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1615 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3950e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1616 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8138, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3950e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1617 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8137, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3950e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1618 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8137, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3950e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1619 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8137, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3950e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1620 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3950e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1621 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3949e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1622 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1623 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1624 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1625 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1626 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1627 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1628 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3949e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1629 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8137, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3949e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1630 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8137, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3948e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1631 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3948e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1632 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3948e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1633 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3948e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1634 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3948e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1635 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3948e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1636 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3948e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1637 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3948e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1638 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3948e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1639 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3947e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1640 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8136, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3947e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1641 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8136, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3947e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1642 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8136, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3947e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1643 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8136, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3947e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1644 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8136, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3947e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1645 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8136, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3947e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1646 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3947e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1647 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3947e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1648 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3947e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1649 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3947e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1650 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3946e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1651 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3946e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1652 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8135, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1653 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1654 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1655 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1656 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1657 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1658 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1659 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1660 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3946e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1661 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3946e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1662 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8135, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1663 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8134, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1664 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8134, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1665 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8134, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1666 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1667 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1668 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1669 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1670 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3945e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1671 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3945e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1672 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3945e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1673 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3945e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1674 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3945e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1675 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3945e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8781, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1676 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1677 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1678 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1679 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1680 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1681 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1682 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3949e-12, 4.3944e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1683 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8137, 2.8134, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1684 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8134, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1685 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8134, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1686 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8134, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1687 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1688 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1689 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1690 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1691 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1692 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1693 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1694 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1695 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1696 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3944e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1697 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3943e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1698 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3943e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1699 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.3943e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1700 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1701 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1702 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1703 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1704 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1705 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1706 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1707 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1708 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1709 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1710 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1711 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1712 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1713 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1714 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1715 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1716 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1717 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1718 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1719 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1720 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1721 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1722 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1723 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1724 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1725 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1726 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1727 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1728 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1729 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1730 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1731 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1732 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1733 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4513e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1734 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1735 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.3943e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.9162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1736 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8133, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4027e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1737 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4027e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1738 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4027e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1739 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4026e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1740 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4026e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1741 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4026e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1742 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4026e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1743 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4026e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1744 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4026e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9821, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1745 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4026e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1746 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4026e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1747 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8188, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4026e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1748 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4026e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1749 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4026e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1750 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4026e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1751 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4026e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1752 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4026e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1753 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4026e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1754 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4025e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1755 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8188, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1756 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1757 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1758 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1759 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1760 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1761 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4025e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1762 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1763 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1764 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1765 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1766 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1767 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8187, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1768 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4025e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1769 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4025e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1770 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4025e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1771 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4025e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1772 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4025e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1773 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4025e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1774 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4024e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7859, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1775 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4024e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1776 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4024e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1777 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4024e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1778 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4024e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1779 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4024e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1780 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8187, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4024e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1781 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8187, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4024e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1782 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8187, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4024e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1783 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8187, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4024e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1784 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8187, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4015e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1785 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8180, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4015e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1786 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8180, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4014e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1787 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8180, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4025e-12, 4.4023e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1788 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8188, 2.8186, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4031e-12, 4.4030e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.7445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1789 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8191, 2.8191, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3939e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1790 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3939e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1791 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3939e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1792 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3938e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1793 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3938e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1794 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3938e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1795 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3938e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1796 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1797 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4349e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1798 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4349e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.3604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1799 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1800 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8130, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1801 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1802 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1803 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1804 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4353e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1805 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3938e-12, 4.4353e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1806 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4354e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1807 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8129, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4354e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1808 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4355e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1809 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1810 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1811 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1812 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1813 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3937e-12, 4.4358e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1814 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3937e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1815 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3937e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1816 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3937e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1817 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3937e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1818 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3937e-12, 4.4361e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1819 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3937e-12, 4.4361e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1820 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4362e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1821 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8129, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1822 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1823 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1824 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1825 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1826 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1827 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1828 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1829 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1830 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1831 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.3936e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1832 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3936e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1833 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3936e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1834 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8128, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1835 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1836 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1837 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1838 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1839 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1840 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1841 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1842 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1843 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8128, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1844 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1845 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1846 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1847 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1848 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3935e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1849 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3934e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1850 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.3934e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1851 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1852 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1853 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1854 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1855 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1856 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1857 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1858 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1859 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1860 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1861 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1862 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1863 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8127, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1864 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8127, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3934e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1865 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8127, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3933e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0850, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1866 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8127, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3933e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1867 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3933e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1868 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3933e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1869 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3933e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1870 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.3933e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1871 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1872 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1873 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1874 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1875 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1876 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1877 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1878 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1879 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1880 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3933e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1881 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1882 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1883 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1884 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1885 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1886 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1887 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1888 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1889 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1890 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1891 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1892 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1893 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8126, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.3932e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1894 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8125, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3932e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1895 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8125, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3932e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1896 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8125, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3932e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1897 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8125, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3932e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1898 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3932e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1899 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3932e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1900 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1901 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1902 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1903 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1904 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1905 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1906 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1907 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1908 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1909 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1910 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8829, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1911 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1912 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1913 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1914 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1915 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1916 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1917 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1918 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1919 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1920 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1921 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.3931e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1922 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3931e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1923 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1924 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1925 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1926 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1927 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8125, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1928 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1929 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1930 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1931 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1932 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1933 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7752, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1934 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1935 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1936 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1937 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1938 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1939 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1940 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1941 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1942 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1943 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1944 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1945 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1946 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1947 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1948 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1949 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1950 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1951 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6892, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1952 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6843, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1953 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1954 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1955 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1956 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1957 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1958 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1959 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1960 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1961 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1962 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1963 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1964 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1965 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1966 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1967 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1968 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1969 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1970 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1971 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1972 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1973 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1974 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1975 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5724, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1976 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1977 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5626, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1978 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1979 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1980 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1981 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1982 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1983 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1984 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1985 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8124, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1986 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1987 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1988 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1989 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1990 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1991 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.3930e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.0939, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1992 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8124, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4010e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1993 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4010e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1994 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4010e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1995 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4010e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1996 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4010e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1997 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4009e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1998 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4009e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9844, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1999 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4009e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2000 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8177, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4009e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9734, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2001 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4009e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2002 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4009e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2003 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2004 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2005 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2006 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2007 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2008 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2009 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8177, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2010 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2011 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2012 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2013 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2014 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2015 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4009e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2016 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3922e-12, 4.4008e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2017 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2018 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2019 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2020 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8119, 2.8176, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2021 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2022 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2023 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2024 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2025 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2026 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2027 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2028 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2029 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2030 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2031 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2032 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2033 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.4008e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2034 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2035 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7805, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2036 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2037 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2038 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7639, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2039 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2040 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2041 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4008e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2042 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2043 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2044 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2045 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2046 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2047 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2048 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2049 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2050 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8176, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.4007e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2051 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8175, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3998e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2052 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8169, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3998e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2053 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8169, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3998e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2054 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8169, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3997e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2055 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8169, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3997e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2056 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8169, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3997e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2057 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8169, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3997e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2058 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8169, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3997e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2059 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8169, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3997e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2060 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3997e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2061 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2062 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2063 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2064 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2065 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2066 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2067 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3996e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1839, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2068 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3995e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2069 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3995e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2070 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8168, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3995e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2071 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8167, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3995e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2072 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8167, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3995e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2073 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3995e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2074 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3995e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2075 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3995e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2076 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3994e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2077 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3994e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2078 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3994e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2079 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3994e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2080 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3994e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2081 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3994e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2082 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8167, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3994e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2083 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3994e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2084 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2085 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2086 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2087 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2088 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2089 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2090 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2091 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2092 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2093 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2094 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2095 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2096 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2097 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2098 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2099 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9802, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2100 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2101 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3991e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2102 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3991e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9612, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2103 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3991e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2104 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3991e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2105 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2106 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2107 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2108 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2109 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8165, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2110 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8164, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2111 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8164, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3991e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2112 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8164, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3990e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2113 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8164, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.4000e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2114 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8171, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.3938e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2115 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8129, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.3938e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2116 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8129, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3938e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8820, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2117 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8129, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3938e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2118 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3938e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2119 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3938e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2120 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2121 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8555, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2122 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2123 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2124 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2125 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2126 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2127 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2128 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2129 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2130 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2131 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2132 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2133 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2134 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7862, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2135 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2136 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2137 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2138 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2139 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2140 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2141 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3937e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2142 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2143 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2144 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2145 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8129, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2146 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2147 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2148 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2149 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2150 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2151 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2152 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2153 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2154 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2155 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2156 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2157 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2158 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2159 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2160 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2161 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2162 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2163 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2164 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2165 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2166 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2167 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2168 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2169 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2170 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2171 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2172 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2173 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2174 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2175 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2176 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2177 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2178 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2179 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2180 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2181 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2182 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2183 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2184 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2185 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2186 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3936e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2187 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4021e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2188 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4021e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2189 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4020e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2190 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4020e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2191 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2192 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2193 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2194 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2195 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2196 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2197 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2198 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2199 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2200 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4020e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2201 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4020e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2202 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8184, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4020e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2203 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8184, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4020e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2204 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8184, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2205 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8184, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2206 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8184, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2207 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2208 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2209 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2210 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4019e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2211 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2212 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2213 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2214 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2215 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2216 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2217 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2218 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2219 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8183, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2220 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2221 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4019e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2222 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4018e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2223 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4018e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2224 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2225 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2226 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2227 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2228 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2229 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2230 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2231 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2232 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7778, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2233 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2234 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2235 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2236 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8183, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2237 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2238 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2239 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2240 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4018e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2241 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4018e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2242 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4018e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2243 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4018e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2244 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8182, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4018e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2245 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8182, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4018e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2246 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8182, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4020e-12, 4.4006e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2247 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8184, 2.8175, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4020e-12, 4.4006e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2248 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8184, 2.8174, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4020e-12, 4.4006e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2249 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8184, 2.8174, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4005e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2250 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8184, 2.8174, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4005e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2251 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8174, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4005e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2252 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8174, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4005e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2253 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8174, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4005e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2254 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8174, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4005e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2867, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2255 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8174, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4004e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2802, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2256 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8174, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4004e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2257 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4019e-12, 4.4004e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2672, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2258 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4004e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2259 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4004e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2260 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4004e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2261 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4003e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2262 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4003e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2263 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4003e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2264 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8173, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4003e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2265 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8182, 2.8173, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4003e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2266 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8182, 2.8172, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4024e-12, 4.4012e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2267 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8186, 2.8179, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4028e-12, 4.4019e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2268 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8189, 2.8184, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3995e-12, 4.3979e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2269 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8157, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3995e-12, 4.3979e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2270 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8157, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3995e-12, 4.3979e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2271 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8157, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3979e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1858, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2272 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8157, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3979e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2273 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2274 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2275 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1612, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2276 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2277 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2278 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2279 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8167, 2.8156, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3978e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2280 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8156, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3977e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2281 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8156, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3994e-12, 4.3977e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2282 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8156, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3977e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2283 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8156, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3977e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2284 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3977e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2285 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3977e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2286 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3977e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2287 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3977e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2288 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3976e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2289 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3976e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2290 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3976e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2291 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3976e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2292 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3976e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0566, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2293 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3993e-12, 4.3976e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2294 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3976e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2295 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8155, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3976e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2296 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8154, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2297 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8154, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2298 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8166, 2.8154, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2299 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2300 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2301 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2302 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2303 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9890, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2304 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3975e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9829, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2305 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3974e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2306 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3974e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2307 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3992e-12, 4.3974e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2308 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8154, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3974e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2309 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3974e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2310 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3974e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2311 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3974e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2312 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3974e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2313 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3974e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2314 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2315 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2316 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2317 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2318 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2319 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2320 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8165, 2.8153, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8850, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2321 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8153, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2322 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8153, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2323 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8153, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2324 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8153, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3991e-12, 4.3973e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2325 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2326 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2327 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2328 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2329 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2330 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2331 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2332 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2333 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2334 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2335 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2336 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2337 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2338 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3972e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2339 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2340 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2341 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2342 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2343 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2344 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2345 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8152, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2346 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2347 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2348 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3971e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2349 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2350 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2351 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2352 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2353 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2354 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2355 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2356 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2357 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2358 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2359 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4514e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2360 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3989e-12, 4.3971e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2361 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8151, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3996e-12, 4.3982e-12, 4.4521e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2362 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8168, 2.8158, 2.8518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2363 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2364 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2365 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4513e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2366 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2367 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2368 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4517e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2369 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4518e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2370 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4519e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2371 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4521e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2372 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4522e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2373 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8519], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4523e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2374 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4525e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2375 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4526e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2376 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4527e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2377 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8522], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4528e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2378 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3965e-12, 4.4530e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2379 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8147, 2.8524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3990e-12, 4.3976e-12, 4.4536e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2380 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8164, 2.8155, 2.8528], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3962e-12, 4.4526e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2381 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8145, 2.8522], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3962e-12, 4.4528e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2382 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8145, 2.8523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3962e-12, 4.4529e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2383 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8145, 2.8524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3962e-12, 4.4530e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2384 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8145, 2.8524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3967e-12, 4.4052e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2385 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8149, 2.8205, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.4058e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.4507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2386 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8209, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4034e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2387 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8193, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4034e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2388 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4034e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2389 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4034e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2390 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4034e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2391 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4034e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2392 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4034e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2393 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4033e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2394 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4033e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2395 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4033e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2396 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4033e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2397 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4033e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2398 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8193, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2399 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8193, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2400 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8193, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2401 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2402 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2403 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2404 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2405 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4033e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2406 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9802, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2407 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9741, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2408 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2409 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2410 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2411 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8192, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2412 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2413 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2414 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2415 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4032e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2416 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4032e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2417 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4032e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2418 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4032e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2419 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4032e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2420 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4032e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2421 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4032e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2422 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4031e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2423 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8192, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4031e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2424 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8191, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4031e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2425 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8191, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.4031e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2426 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8191, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2427 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8191, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2428 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2429 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2430 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2431 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2432 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2433 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2434 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2435 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2436 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2437 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2438 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.4031e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7839, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2439 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4031e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7778, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2440 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4031e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2441 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4031e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2442 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4031e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2443 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4030e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2444 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4030e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2445 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8191, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.4037e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2446 was 68.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8195, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2447 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8189, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2448 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2449 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2450 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2451 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2452 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2453 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2454 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4027e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2455 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8188, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4027e-12, 4.4017e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2456 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8189, 2.8182, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4032e-12, 4.4023e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2457 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8192, 2.8186, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3957e-12, 4.3945e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2458 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8134, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2459 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2460 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2461 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8134, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2462 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8134, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2463 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8134, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2464 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8133, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2465 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2466 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2467 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3944e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2468 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3943e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2469 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3943e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2470 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3943e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2471 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.3943e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2472 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3943e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2473 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3943e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2474 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3943e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2475 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3943e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2476 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3943e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2477 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3943e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2478 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2479 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8133, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2480 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2481 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2482 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1801, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2483 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2484 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1698, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2485 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.3942e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2486 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8132, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3942e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2487 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3942e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2488 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3942e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2489 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2490 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2491 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2492 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2493 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2494 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2495 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8132, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2496 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2497 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2498 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2499 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3941e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2500 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.3940e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0872, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2501 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0820, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2502 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2503 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2504 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2505 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2506 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2507 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2508 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2509 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8131, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2510 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8131, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2511 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8131, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2512 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8131, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3940e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2513 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8131, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3939e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2514 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8131, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3939e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2515 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3939e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2516 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3939e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2517 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3953e-12, 4.3939e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2518 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2519 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2520 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2521 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2522 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2523 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2524 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2525 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3939e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2526 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2527 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2528 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2529 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2530 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2531 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2532 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2533 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2534 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2535 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2536 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8130, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2537 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8129, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2538 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8129, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3952e-12, 4.3938e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2539 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8139, 2.8129, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3938e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2540 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3938e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2541 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3938e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8710, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2542 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3938e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2543 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2544 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2545 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2546 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2547 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2548 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2549 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2550 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2551 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2552 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2553 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2554 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2555 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7960, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2556 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2557 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2558 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2559 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2560 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2561 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2562 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2563 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2564 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3937e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2565 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3936e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2566 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3936e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2567 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8129, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3936e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2568 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3951e-12, 4.3936e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2569 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2570 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2571 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2572 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2573 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6990, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2574 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2575 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2576 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6828, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2577 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6774, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2578 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6720, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2579 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2580 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6612, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2581 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2582 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2583 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2584 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2585 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2586 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2587 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2588 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2589 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2590 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2591 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2592 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5962, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2593 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2594 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2595 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2596 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2597 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2598 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2599 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2600 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2601 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2602 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2603 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2604 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2605 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2606 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3950e-12, 4.3936e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.9726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2607 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8138, 2.8128, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4019e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2608 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8183, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4019e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2609 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8183, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4019e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2610 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8183, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4019e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2611 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8183, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4019e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2612 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8183, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4018e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2613 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4018e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2614 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4018e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2615 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.4018e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2616 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2617 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2618 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9896, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2619 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2620 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9774, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2621 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8183, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2622 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8182, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2623 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8182, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2624 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8182, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2625 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8182, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4018e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2626 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8182, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4018e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2627 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8182, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2628 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2629 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2630 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2631 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2632 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2633 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2634 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2635 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2636 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2637 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4017e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2638 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2639 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2640 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2641 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2642 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2643 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2644 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4017e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2645 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2646 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8182, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2647 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8182, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2648 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8182, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2649 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2650 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2651 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7890, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2652 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4016e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2653 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2654 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2655 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2656 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2657 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2658 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2659 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2660 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2661 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2662 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2663 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2664 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2665 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2666 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2667 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2668 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2669 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4016e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2670 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8181, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4026e-12, 4.4004e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2671 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8188, 2.8173, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4026e-12, 4.4003e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2672 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8188, 2.8173, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4032e-12, 4.4013e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2673 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8192, 2.8179, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4036e-12, 4.4020e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.1219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2674 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8194, 2.8184, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3925e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2675 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8121, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3925e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2676 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8400], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3925e-12, 4.4345e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3635, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2677 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3925e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2678 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4346e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2679 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2680 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8401], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4347e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2681 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2682 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8121, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2683 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8402], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4348e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2684 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4349e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2685 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3924e-12, 4.4349e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2686 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8403], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2687 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4350e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2688 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2689 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4351e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2690 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8404], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2691 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2692 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4352e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2693 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8405], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4353e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2694 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4353e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2695 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3924e-12, 4.4354e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2696 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8406], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4354e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2697 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4355e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2698 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4355e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2699 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2700 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8407], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4356e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2701 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2702 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2839, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2703 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8408], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4357e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2704 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4358e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2705 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4358e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2706 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8409], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2707 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4359e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2708 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3923e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2709 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8120, 2.8410], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3923e-12, 4.4360e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2710 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8119, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3923e-12, 4.4361e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2711 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8119, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3923e-12, 4.4361e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2712 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8411], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3923e-12, 4.4362e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2518, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2713 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3923e-12, 4.4362e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2714 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2715 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8412], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4363e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2716 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2717 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4364e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2718 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8413], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2719 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2720 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2721 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2722 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2723 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2724 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2725 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2726 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2727 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2728 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2729 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2730 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2731 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3922e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2732 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3921e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1851, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2733 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2734 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2735 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1748, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2736 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8119, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2737 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2738 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2739 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2740 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2741 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2742 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2743 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2744 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2745 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2746 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2747 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8118, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2748 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2749 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3921e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2750 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2751 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2752 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2753 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2754 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2755 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2756 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2757 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3941e-12, 4.3920e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2758 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2759 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2760 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2761 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0828, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2762 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2763 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2764 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8118, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2765 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2766 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2767 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2768 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3920e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0571, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2769 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2770 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2771 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2772 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2773 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2774 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2775 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2776 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2777 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2778 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2779 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2780 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2781 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2782 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2783 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.3919e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2784 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3919e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2785 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3919e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2786 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8117, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3919e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2787 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3919e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2788 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3919e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2789 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3919e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2790 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2791 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2792 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2793 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2794 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2795 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8117, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2796 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2797 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2798 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2799 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2800 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2801 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2802 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2803 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2804 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2805 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2806 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2807 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2808 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2809 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2810 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2811 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2812 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2813 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3918e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2814 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3917e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8794, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2815 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.3917e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2816 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2817 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2818 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2819 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2820 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2821 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2822 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2823 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2824 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2825 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2826 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2827 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2828 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2829 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2830 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2831 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2832 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2833 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2834 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2835 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8116, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2836 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8115, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2837 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8115, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7851, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2838 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8115, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2839 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8115, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2840 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8115, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2841 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2842 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2843 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2844 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3917e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2845 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2846 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2847 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2848 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2849 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2850 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2851 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2852 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2853 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2854 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2855 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2856 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2857 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2858 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2859 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6918, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2860 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2861 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2862 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2863 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2864 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2865 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2866 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2867 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2868 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2869 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2870 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2871 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2872 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2873 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2874 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2875 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2876 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2877 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2878 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2879 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2880 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2881 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2882 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2883 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2884 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5825, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2885 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5781, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2886 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2887 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2888 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2889 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2890 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2891 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2892 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2893 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2894 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.3916e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2895 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8115, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3994e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2896 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3994e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2897 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3994e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2898 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3994e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2899 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3993e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2900 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3993e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2901 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.3993e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2902 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2903 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2904 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2905 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2906 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2907 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2908 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2909 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9802, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2910 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2911 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8166, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2912 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2913 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2914 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2915 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.3993e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2916 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2917 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2918 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2919 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2920 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2921 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8166, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2922 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2923 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2924 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2925 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2926 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2927 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2928 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2929 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2930 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2931 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.3992e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2932 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3992e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2933 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3992e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2934 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3992e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2935 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8165, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3992e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2936 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3992e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2937 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3992e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2938 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2939 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2940 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2941 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2942 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2943 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2944 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2945 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2946 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2947 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7825, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2948 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2949 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7720, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2950 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2951 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2952 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2953 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2954 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.3991e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2955 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2956 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2957 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2958 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2959 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2960 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2961 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2962 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2963 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2964 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2965 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8165, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2966 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2967 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2968 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2969 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2970 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2971 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2972 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2973 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2974 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.3991e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1710, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2975 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8164, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3982e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2976 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8159, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3982e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1784, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2977 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3982e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2978 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3981e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2979 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3981e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2980 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3981e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2981 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3981e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2982 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3981e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2983 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3981e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2984 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3981e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2985 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8158, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3981e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2986 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8158, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2987 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8158, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2988 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8158, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2989 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8158, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2990 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0918, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2991 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2992 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0794, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2993 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0733, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2994 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4004e-12, 4.3980e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2995 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0609, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2996 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2997 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2998 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2999 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3000 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3001 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3002 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8157, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3003 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8156, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3979e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3004 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8173, 2.8156, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3978e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3005 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3978e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3006 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3978e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3007 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4003e-12, 4.3978e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3008 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3978e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3009 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3978e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3010 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3978e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3011 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3978e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3012 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3978e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3013 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3978e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3014 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9437, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3015 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3016 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3017 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8156, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3018 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3019 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3020 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3021 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3022 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4002e-12, 4.3977e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3023 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3977e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3024 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3977e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3025 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3026 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3027 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8172, 2.8155, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3028 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3029 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3030 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3031 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3032 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3033 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3034 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3035 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3036 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3037 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8155, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3038 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8154, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3976e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3039 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8154, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3975e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3040 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8154, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4001e-12, 4.3975e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3041 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8154, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3985e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.5306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3042 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8161, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7762, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3043 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3044 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3045 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3046 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3047 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3048 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3049 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3050 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3051 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8137, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3052 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3053 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3054 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3055 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3056 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3057 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3058 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3059 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3060 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3061 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3062 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3063 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3064 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3065 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3066 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3067 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3068 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3069 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3070 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3071 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3072 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3073 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3074 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3075 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3076 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3077 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4513e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5734, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3078 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4514e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3079 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3080 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4517e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3081 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3949e-12, 4.4518e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3082 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8137, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3962e-12, 4.4038e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3083 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8146, 2.8196, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3962e-12, 4.4038e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3084 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8196, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3962e-12, 4.4038e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3085 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8196, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3962e-12, 4.4038e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3086 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8196, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3962e-12, 4.4037e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3087 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3088 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3089 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3090 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3091 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3092 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3093 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8145, 2.8195, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3961e-12, 4.4037e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3094 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4037e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3095 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4037e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3096 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4037e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3097 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4037e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3098 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4036e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3099 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4036e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3100 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4036e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3101 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3960e-12, 4.4036e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3102 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3103 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3104 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3105 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8144, 2.8195, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3106 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3107 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3108 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3109 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3959e-12, 4.4036e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3110 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4036e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3111 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4036e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3112 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4035e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3113 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4035e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3114 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4035e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3115 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4035e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3116 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4035e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3117 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3958e-12, 4.4035e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3118 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8143, 2.8194, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3968e-12, 4.4041e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3119 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8149, 2.8198, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4008e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3120 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8176, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4008e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3121 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8176, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4007e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3122 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8176, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4007e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3123 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8176, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3124 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8176, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8889, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3125 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3126 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3127 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8720, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3128 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3129 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3130 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3131 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3132 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8437, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3133 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3134 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3135 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3925e-12, 4.4007e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3136 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3137 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3138 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3139 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8121, 2.8175, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3140 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3141 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3142 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3143 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4007e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3144 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3145 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3146 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3147 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3148 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3149 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3150 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3151 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3152 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3153 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.4006e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3154 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3155 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3156 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3157 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3158 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3159 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3160 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.4006e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3161 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8175, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3997e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3162 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8169, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3997e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3163 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3164 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3165 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3166 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3167 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3168 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3169 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3996e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3170 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3995e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3171 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3995e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3172 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8168, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3995e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3173 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3995e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3174 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3995e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3175 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3995e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3176 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3995e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3177 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3994e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1734, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3178 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8167, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3994e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3179 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8167, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3994e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3180 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8167, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.3994e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3181 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8167, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3994e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3182 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8167, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3994e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3183 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8167, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3994e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3184 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3994e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3185 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3993e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3186 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3993e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3187 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3993e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3188 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3993e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3189 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3993e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3190 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3993e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3191 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3993e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3192 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8166, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3193 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8166, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3194 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8166, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3195 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3196 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3197 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3198 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3199 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3200 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3992e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3201 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3991e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3202 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3991e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3203 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3991e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3204 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3991e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3205 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3991e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3206 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3991e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3207 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8165, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3991e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3208 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8164, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4013e-12, 4.4000e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.6883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3209 was 68.2%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8171, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3210 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8110, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3211 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8110, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3212 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8110, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3213 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8110, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3214 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3215 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3216 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3217 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3908e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3218 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3219 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3220 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9859, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3221 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3222 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3223 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3224 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3225 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3226 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3227 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9629, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3228 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3229 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3230 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3231 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3232 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3233 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3234 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3921e-12, 4.3907e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3235 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3236 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3237 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3238 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3239 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3240 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3241 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3242 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3243 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3244 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3245 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3907e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3246 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3247 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3248 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3249 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3250 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3251 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8811, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3252 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3253 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8741, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3254 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3255 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3256 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8109, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3257 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3258 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3259 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3260 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3261 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3262 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3263 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3264 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8118, 2.8108, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3265 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3266 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3267 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3268 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3269 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3270 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3271 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3272 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3273 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3274 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3275 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3276 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3277 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3278 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3920e-12, 4.3906e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7841, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3279 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3906e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3280 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3906e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3281 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3906e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3282 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3906e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3283 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3284 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3285 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3286 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3287 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3288 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3289 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3290 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3291 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3292 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3293 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3294 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3295 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3296 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3297 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3298 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3299 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3300 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3301 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3302 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3303 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3304 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6858, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3305 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3306 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3307 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3308 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3309 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3310 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3311 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3312 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3313 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3314 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3315 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3316 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3317 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3318 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3319 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3320 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3321 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3322 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3323 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3324 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3325 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3326 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3327 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3328 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3329 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3330 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3331 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3332 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3333 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5710, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3334 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3335 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5629, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3336 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3337 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3338 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3339 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3340 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3341 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3342 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3343 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3344 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3345 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3919e-12, 4.3905e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3346 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8117, 2.8108, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3347 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8160, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3348 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8160, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3349 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8160, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3350 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8160, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3351 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8160, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3352 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8160, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3353 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8112, 2.8159, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3354 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3355 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3911e-12, 4.3983e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3356 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3357 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3358 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3359 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3360 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3361 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3362 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3363 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3364 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3365 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3983e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3366 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3367 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3368 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3369 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3370 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3371 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3372 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3910e-12, 4.3982e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3373 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3374 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3375 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3376 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3377 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3378 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8111, 2.8159, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3379 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3380 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8786, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3381 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3382 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3383 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3384 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3385 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3386 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8159, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3387 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3388 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3389 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3390 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3391 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3909e-12, 4.3982e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3392 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3393 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3394 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3395 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3396 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3397 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3398 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3399 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3400 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3401 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3402 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3403 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3404 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3405 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3406 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3407 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3408 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3409 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3410 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3411 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3412 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3413 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3414 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3415 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8110, 2.8158, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3416 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3417 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3418 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3419 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3420 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3421 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3422 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3908e-12, 4.3981e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3423 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3907e-12, 4.3981e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6698, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3424 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3907e-12, 4.3981e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3425 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3907e-12, 4.3981e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3426 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8109, 2.8158, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3427 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8152, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3428 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8152, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3429 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8152, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3430 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3431 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3432 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3433 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3972e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3434 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3971e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3435 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3971e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3436 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3971e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3437 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8152, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3971e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3438 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3971e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3439 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3971e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3440 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3971e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3441 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3971e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3442 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3971e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3443 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3444 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3445 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3446 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3447 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8151, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3448 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8151, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3449 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8151, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3970e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3450 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8151, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3970e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3451 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8151, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3970e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3452 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3453 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3454 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3455 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3456 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3457 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3458 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3459 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3460 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3461 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3462 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3969e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3463 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3968e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9828, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3464 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3465 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3466 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3467 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8150, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3468 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8149, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3469 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3470 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3471 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3472 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3473 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3968e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3474 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3967e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3475 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3967e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3476 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3967e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3477 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3967e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3478 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3967e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3479 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8890, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3480 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3481 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8772, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3482 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3483 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3484 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3485 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3486 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8149, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3487 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3967e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3488 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3489 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3490 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3491 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3492 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3493 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3494 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3495 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3496 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8148, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3497 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3498 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3499 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3982e-12, 4.3966e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3500 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3966e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3501 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3966e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3502 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3966e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3503 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3966e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3504 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3966e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3505 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3966e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3506 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3507 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3508 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3509 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3510 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3511 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3512 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3513 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3514 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6841, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3515 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3516 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6724, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3517 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3518 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8148, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3519 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3520 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3521 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3522 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3523 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3524 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3525 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4513e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3526 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3527 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3528 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4517e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3529 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4518e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3530 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4519e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3531 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4521e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5851, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3532 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4522e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3533 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8519], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4523e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3534 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4524e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5677, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3535 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4526e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3536 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4527e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3537 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8522], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4528e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3538 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4529e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3539 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4531e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3540 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8525], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.3965e-12, 4.4532e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3541 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8147, 2.8526], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3542 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5962, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3543 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3544 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3545 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3546 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3547 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3548 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3549 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3550 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3551 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3552 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3553 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5843, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3554 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3555 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5821, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3556 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3557 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3558 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3559 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3560 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3561 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3562 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3563 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3564 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3565 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3566 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3567 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3568 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3569 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3570 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3571 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3572 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3573 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3574 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3575 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3576 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3577 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3578 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3579 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8082, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3580 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3581 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3582 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3583 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3584 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3585 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3586 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3587 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3588 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3589 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3590 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3591 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3592 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3593 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3594 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3595 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3596 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3597 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3598 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3599 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3600 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3601 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3602 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3603 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3866e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3604 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8082, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3605 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8106, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3606 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3607 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3608 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3609 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3610 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3611 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3612 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3613 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3614 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3615 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3616 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3617 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3618 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3619 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3620 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3621 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3622 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3623 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3624 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3625 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3626 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3627 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3628 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3629 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3630 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3631 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3632 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3633 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3634 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3635 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3636 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3637 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6828, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3638 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3639 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3640 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3641 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3642 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3643 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3644 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6704, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3645 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3646 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3647 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3648 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3649 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3650 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3651 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3652 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3653 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3654 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3655 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3656 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3657 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3658 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3659 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3660 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3661 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3662 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3663 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3664 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3665 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3666 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3667 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3668 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3669 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3670 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3671 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3672 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3673 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3674 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3675 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3676 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3677 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3678 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3901e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3679 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3680 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3681 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3682 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3683 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3684 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3685 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3686 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5892, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3687 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3688 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5850, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3689 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3690 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3691 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3692 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3693 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3694 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5724, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3695 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3696 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3697 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3698 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3879e-12, 4.3902e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5639, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3699 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3700 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3701 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3702 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3703 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3704 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3705 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3706 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3707 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8105, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3708 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8106, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3709 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8106, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3710 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8106, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3880e-12, 4.3902e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3711 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8091, 2.8106, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3712 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3713 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3714 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3715 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3716 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3717 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3718 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3719 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3720 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3721 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3722 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3897e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3723 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3724 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3725 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3726 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3727 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3728 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3729 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3730 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3731 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3732 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3733 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7837, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3734 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3735 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3736 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3924e-12, 4.3896e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3737 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3738 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3739 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3740 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7641, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3741 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3742 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3743 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3744 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3745 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3746 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3747 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3748 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3749 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3750 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3751 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3752 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3753 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3754 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3755 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3756 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3757 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3758 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3759 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3760 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3761 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3762 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3763 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3764 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3765 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3766 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3767 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3768 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3769 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3770 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3771 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3772 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3773 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3774 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3775 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3776 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3777 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3778 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3779 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3780 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3781 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3782 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3783 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3784 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3785 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3786 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3787 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3788 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3789 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3790 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3791 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3792 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3793 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3794 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3795 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3796 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3797 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3798 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3799 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5843, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3800 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3801 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3802 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3803 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3804 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3805 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3806 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3807 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3808 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3809 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3923e-12, 4.3896e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3810 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8120, 2.8102, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3811 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3812 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3813 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3814 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3815 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3816 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3817 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8116, 2.8148, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3818 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3819 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3820 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3821 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3917e-12, 4.3966e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3822 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3966e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3823 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3966e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3824 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3966e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3825 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3966e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3826 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3966e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3827 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3828 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3829 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3830 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3831 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3832 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3833 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3834 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3835 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3836 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8962, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3837 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3838 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8148, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3839 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3840 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3841 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3842 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3843 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8672, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3844 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3845 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3916e-12, 4.3965e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3846 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3847 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3848 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3849 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3850 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3851 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3852 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3853 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8115, 2.8147, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3854 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3855 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3965e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3856 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3857 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3858 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3859 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3860 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3861 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3862 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3863 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7825, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3864 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3865 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3866 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3867 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3868 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3869 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3870 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3871 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3872 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7437, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3873 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3874 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3875 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3876 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3877 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3878 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3879 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3915e-12, 4.3964e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3880 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3881 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3882 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3883 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3884 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3885 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3886 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3887 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3888 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3889 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3890 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3891 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3892 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3893 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3894 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3895 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3896 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3897 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3898 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3899 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3900 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3901 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3902 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3903 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3904 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3914e-12, 4.3964e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3905 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8114, 2.8147, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3987e-12, 4.3956e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3906 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8141, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3987e-12, 4.3956e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0850, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3907 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8141, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3908 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8141, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3909 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8141, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3910 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8141, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3911 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8162, 2.8141, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3912 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8141, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3913 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8141, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3914 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8141, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3915 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8141, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3916 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8141, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3955e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3917 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8141, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3954e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3918 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3954e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3919 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3954e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3920 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3954e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3921 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3986e-12, 4.3954e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3922 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3923 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3924 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3925 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3926 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3927 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3928 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3954e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3929 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3930 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3931 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3932 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3933 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3934 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3935 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8140, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3936 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8161, 2.8139, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3937 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3938 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3939 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3985e-12, 4.3953e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3940 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3953e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3941 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3953e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3942 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3943 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3944 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3945 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3946 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8700, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3947 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3948 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3949 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3950 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3951 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3952 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3953 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3954 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3955 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3956 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3957 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3952e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3958 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8139, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3951e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3959 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3951e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3960 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3951e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3961 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3951e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3962 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3984e-12, 4.3951e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3963 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3964 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7722, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3965 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3966 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3967 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3968 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3969 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3970 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3971 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3972 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3973 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8160, 2.8138, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3974 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3975 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3976 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3977 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3978 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3979 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3980 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3981 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6794, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3982 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3951e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3983 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6685, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3984 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3985 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3986 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3987 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3988 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3989 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3990 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3991 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3992 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3993 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3994 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3995 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3996 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4513e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3997 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4514e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3998 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3999 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4000 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4517e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4001 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4518e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4002 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3983e-12, 4.3950e-12, 4.4520e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.0544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4003 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8159, 2.8138, 2.8517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4035e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4004 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8194, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4035e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4005 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8194, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4035e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4006 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8194, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4035e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4007 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8194, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4035e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4008 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8194, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4034e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4009 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8194, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.4034e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4010 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8193, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3981e-12, 4.4041e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.5060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4011 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8158, 2.8198, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4012 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4365e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4013 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4014 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4015 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8414], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4366e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4016 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4017 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4018 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4367e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4019 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8415], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4020 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4021 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4368e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4022 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3945e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4023 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8416], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3944e-12, 4.4369e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4024 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3944e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4025 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3885e-12, 4.3944e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4026 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4370e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4027 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4028 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8417], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4029 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4371e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4030 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4031 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8418], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4372e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4032 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4033 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4034 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4373e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4035 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8419], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4036 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4374e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4037 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4038 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4039 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8420], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4375e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4040 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4041 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4042 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4376e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4043 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8421], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4044 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4377e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4045 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4046 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8134, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4378e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4047 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8422], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4048 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4049 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4379e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0518, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4050 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8423], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4051 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4380e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4052 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4053 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4054 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8424], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4381e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4055 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4056 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8094, 2.8133, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3884e-12, 4.3944e-12, 4.4382e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4057 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8425], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4058 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4383e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4059 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4060 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4061 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8426], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4384e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4062 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4063 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4385e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4064 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8427], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3944e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4065 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4386e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4066 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4067 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4387e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4068 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8428], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4069 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4070 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4388e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4071 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8429], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4072 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4389e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4073 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4074 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8430], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4390e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4075 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4076 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4391e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4077 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8431], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4078 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4392e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4079 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4080 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4393e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4081 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8432], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9687, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4082 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4083 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4394e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4084 was 68.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8433], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4085 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4395e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4086 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4087 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8434], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4396e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4088 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3883e-12, 4.3943e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4089 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4397e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4090 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8435], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4091 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4092 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4093 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4094 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4095 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4096 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4097 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4098 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4099 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4100 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4101 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4102 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4103 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4104 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4105 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4106 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4107 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8093, 2.8133, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4108 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4109 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4110 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3943e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8867, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4111 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4112 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4113 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4114 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8133, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4115 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4116 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4117 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4118 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4119 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4120 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4121 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4122 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4123 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4124 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4125 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3882e-12, 4.3942e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4126 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4127 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4128 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4129 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4130 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4131 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4132 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4133 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4134 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4135 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4136 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4137 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4138 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4139 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4140 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4141 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.7920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4142 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4143 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4144 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4145 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4146 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4147 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4148 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4149 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4150 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4151 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4152 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7566, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4153 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4154 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4155 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4156 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4157 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4158 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4159 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4160 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4161 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4162 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4163 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4164 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4165 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4166 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4167 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4168 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4169 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4170 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4171 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4172 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4173 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4174 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4175 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6798, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4176 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6764, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4177 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4178 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4179 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4180 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6626, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4181 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4182 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4183 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4184 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4185 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4186 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4187 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4188 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4189 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4190 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3881e-12, 4.3942e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4191 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8092, 2.8132, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4192 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4193 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4194 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0492, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4195 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4196 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4197 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4198 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4199 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4200 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4201 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4202 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.3936e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4203 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4204 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4205 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4206 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4207 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4208 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4209 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9848, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4210 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4211 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4212 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4213 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4214 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8128, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4215 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8128, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4216 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4217 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4218 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4219 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4220 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4221 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4222 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4223 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3935e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4224 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3934e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4225 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9145, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4226 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4227 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4228 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4229 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4230 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4231 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4232 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4233 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4234 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4235 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8698, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4236 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4237 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4238 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4239 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4240 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4241 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4242 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4243 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4244 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4245 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4246 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4247 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4248 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4249 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4250 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3934e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4251 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3933e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4252 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3933e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4253 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4254 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4255 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8127, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4256 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7741, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4257 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4258 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4259 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4260 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4261 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4262 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4263 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4264 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4265 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4266 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4267 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4268 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4269 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4270 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4271 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4272 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4273 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4274 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4275 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4276 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4277 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6762, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4278 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4279 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4280 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4281 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4282 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4283 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4284 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4285 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4286 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4287 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4288 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4289 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4290 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4291 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4292 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4293 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4294 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4295 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4296 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4297 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4298 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5764, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4299 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4300 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4301 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4302 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4303 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4304 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4305 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4306 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4307 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4308 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4309 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4310 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4311 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4312 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3933e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4313 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8126, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4008e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4314 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4008e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4315 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4008e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4316 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4008e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4317 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4008e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4318 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4008e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4319 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4008e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4320 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4008e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4321 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4008e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4322 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4323 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4324 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4325 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8176, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4326 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8175, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4327 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4328 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4329 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3932e-12, 4.4007e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4330 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4331 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4332 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4333 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4334 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4335 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8892, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4336 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8837, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4337 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4338 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4339 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4340 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4341 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4342 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4007e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4343 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4006e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4344 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4345 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4346 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8175, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4347 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4348 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4349 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4350 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4351 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4352 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7958, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4353 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4354 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4355 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4356 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4357 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4358 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4359 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4360 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4361 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4006e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4362 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8175, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4363 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4364 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4365 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4366 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4367 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4368 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4369 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4370 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4371 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4372 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4373 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4374 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4375 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4006e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4376 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8174, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3997e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4377 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8169, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3997e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4378 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8169, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3997e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4379 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8169, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3997e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4380 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8169, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3997e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4381 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8168, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3997e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4382 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8168, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3996e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4383 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3996e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4384 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4012e-12, 4.3996e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4385 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3996e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4386 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3996e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4387 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3996e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4388 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3996e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4389 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3996e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4390 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3995e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4391 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3995e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4392 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8168, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3995e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4393 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8167, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3995e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4394 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8167, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.3995e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4395 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8167, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3995e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4396 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8167, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3995e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4397 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8167, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3995e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4398 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4399 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4400 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4401 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4402 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0612, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4403 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4404 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8167, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4405 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8166, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.3994e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4406 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8166, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4016e-12, 4.4002e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4407 was 68.5%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8182, 2.8172, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4022e-12, 4.4008e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4408 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8185, 2.8176, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3988e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4409 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8162, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3988e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4410 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8162, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3987e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4411 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8162, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3987e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4412 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8162, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3987e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4413 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3987e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4414 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3987e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4415 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3987e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4416 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3987e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4417 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3987e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4418 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3987e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4419 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3987e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4420 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4421 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4422 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4423 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8162, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4424 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4425 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4426 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4427 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4428 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3986e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4429 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3986e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4430 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3986e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4431 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4432 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8161, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4433 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4434 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4435 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4436 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4437 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4438 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4439 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3985e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4440 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8169, 2.8161, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4005e-12, 4.3994e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0896, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4441 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8167, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3968e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4442 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3968e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4443 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3968e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4444 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3968e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4445 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3968e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4446 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3968e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4447 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3968e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4448 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3968e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4449 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3968e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4450 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4451 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4452 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4453 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4454 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4455 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4456 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4457 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4458 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4459 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4460 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4461 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4462 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4463 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4464 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4465 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.6927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4466 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4467 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4468 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4469 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4470 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4471 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4472 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4473 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4474 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4475 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4476 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4477 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4478 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4514e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4479 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4480 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4481 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4518e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4482 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4519e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4483 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4520e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4484 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4521e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.5765, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4485 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4523e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5704, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4486 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8519], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4524e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4487 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4525e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4488 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4527e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4489 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8522], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4528e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4490 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4529e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4491 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8524], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4530e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4492 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8525], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4532e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4493 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8525], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4533e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4494 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8526], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3967e-12, 4.4534e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4495 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8149, 2.8527], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3964e-12, 4.4056e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4496 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8146, 2.8208, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.4061e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4497 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8211, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4498 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4499 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4500 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4501 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4502 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4503 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3948e-12, 4.4044e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4504 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8200, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4505 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8199, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4506 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8199, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4507 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8136, 2.8199, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4508 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4509 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4510 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3947e-12, 4.4043e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4511 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4512 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4513 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4514 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4515 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4516 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4517 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4043e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4518 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3946e-12, 4.4042e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4519 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8135, 2.8199, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4520 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4521 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4522 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.9487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4523 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4524 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4525 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4526 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8199, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3945e-12, 4.4042e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4527 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8198, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4528 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8198, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4529 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8198, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4530 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8198, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4531 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8198, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4532 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8134, 2.8198, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4533 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8198, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4534 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8198, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4042e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4535 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8198, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4041e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4536 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8198, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.4041e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4537 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8198, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4538 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8202, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4539 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8193, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4540 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4541 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.8416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4542 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4543 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4544 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4545 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4546 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3934e-12, 4.4033e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4547 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4033e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4548 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8192, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4033e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4549 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4033e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4550 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4551 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4552 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4553 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7704, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4554 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4555 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4556 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4557 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4558 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4559 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4560 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3933e-12, 4.4032e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(4.3656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4561 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8126, 2.8192, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4022e-12, 4.4023e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4562 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8185, 2.8186, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4027e-12, 4.4029e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.2357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4563 was 68.5%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8189, 2.8190, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4031e-12, 4.4035e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.4505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4564 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8191, 2.8194, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4002e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4565 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8172, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4002e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4566 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8172, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4002e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4567 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8172, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4002e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4568 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8172, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4002e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.3063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4569 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8172, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4001e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4570 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8172, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4001e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4571 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4001e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4572 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4001e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4573 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4010e-12, 4.4001e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4574 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4001e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4575 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4001e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4576 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4000e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4577 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4000e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4578 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4000e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4579 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8177, 2.8171, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4000e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.2319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4580 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8171, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4000e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4581 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8171, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4009e-12, 4.4000e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4582 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.4000e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4583 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4584 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4585 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4586 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4587 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4588 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4589 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3999e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4590 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4008e-12, 4.3998e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4591 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8170, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3998e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4592 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8169, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3998e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4593 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8176, 2.8169, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3998e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4594 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3998e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4595 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3998e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4596 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3998e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4597 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3997e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4598 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3997e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.1043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4599 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3997e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4600 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4007e-12, 4.3997e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4601 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3997e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4602 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3997e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4603 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8169, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3997e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4604 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8168, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3997e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4605 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8168, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3997e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4606 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8168, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3996e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4607 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8168, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3996e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4608 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8168, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3996e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4609 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8168, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3996e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4610 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8168, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.3996e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4611 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8174, 2.8168, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4013e-12, 4.4005e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.3351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4612 was 68.5%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8179, 2.8174, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4012e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4613 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8183, 2.8178, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3994e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4614 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8171, 2.8166, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4615 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4616 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4000e-12, 4.3993e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4617 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(5.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4618 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4619 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4620 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4621 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4622 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4623 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3993e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9609, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4624 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4625 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4626 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8166, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4627 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4628 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3999e-12, 4.3992e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4629 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3992e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4630 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3998e-12, 4.3992e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4631 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8170, 2.8165, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4006e-12, 4.4001e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4632 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8175, 2.8171, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3941e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4633 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3941e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4634 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3941e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4635 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3941e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4636 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3941e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4637 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3940e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4638 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3940e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8760, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4639 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3940e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4640 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3944e-12, 4.3940e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4641 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4642 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4643 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4644 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4645 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4646 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4647 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4648 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4649 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4650 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4651 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4652 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4653 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4654 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4655 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4656 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3940e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4657 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4658 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4659 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8131, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4660 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4661 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4662 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4663 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4664 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4665 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4666 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4667 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4668 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4669 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4670 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4671 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4672 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4673 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4674 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4675 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4676 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4677 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4678 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4679 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4680 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4681 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4682 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4683 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4684 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4685 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4686 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4687 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4688 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4689 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4690 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5872, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4691 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4692 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4693 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4694 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4695 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4696 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4697 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4698 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4699 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4503e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4700 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4701 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8132, 2.8130, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4702 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5204, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4703 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3942e-12, 4.3939e-12, 4.4508e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4704 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4705 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4706 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3943e-12, 4.3939e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4707 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8133, 2.8130, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4026e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4708 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4026e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4709 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4026e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4710 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4026e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4711 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4026e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4712 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4025e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4713 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8188, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3931e-12, 4.4025e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4714 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8187, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4715 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8125, 2.8187, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4716 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4717 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4718 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4719 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4720 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4721 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4722 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3930e-12, 4.4025e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4723 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4025e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4724 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4025e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4725 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4025e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4726 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4025e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4727 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4025e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4728 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4024e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4729 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8124, 2.8187, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4024e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4730 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4024e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4731 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3929e-12, 4.4024e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4732 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4733 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4734 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4735 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4736 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4737 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4738 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8187, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4739 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4740 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4741 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4742 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3928e-12, 4.4024e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4743 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4024e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4744 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4024e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4745 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8123, 2.8186, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4024e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4746 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4024e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4747 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4748 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4749 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4750 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4751 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4752 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4753 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4754 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4755 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7828, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4756 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3927e-12, 4.4023e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4757 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4758 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4759 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4760 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4761 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4762 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4763 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4764 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4765 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4766 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3926e-12, 4.4023e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.1084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4767 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8122, 2.8186, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4014e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4768 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8180, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4014e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2871, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4769 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8180, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4014e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4770 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8180, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4014e-12, 4.4430e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4771 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8180, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4014e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4772 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8180, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4011e-12, 4.4014e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4773 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8178, 2.8180, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4018e-12, 4.4022e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4774 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8182, 2.8185, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.4023e-12, 4.4028e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.5919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4775 was 68.1%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8186, 2.8190, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3967e-12, 4.4398e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4776 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3967e-12, 4.4399e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4777 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8149, 2.8436], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3967e-12, 4.4400e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4778 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8148, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3966e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4779 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8148, 2.8437], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3978e-12, 4.3966e-12, 4.4401e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4780 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8148, 2.8438], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4402e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4781 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8148, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4403e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4782 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8148, 2.8439], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4404e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.2048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4783 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8156, 2.8148, 2.8440], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4784 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4785 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4786 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3966e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1798, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4787 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3965e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4788 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3965e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1674, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4789 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3977e-12, 4.3965e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1612, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4790 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8148, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3965e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4791 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3965e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4792 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3965e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4793 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3965e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4794 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3965e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4795 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3965e-12, 4.4417e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4796 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3964e-12, 4.4418e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4797 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8449], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3964e-12, 4.4419e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4798 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3964e-12, 4.4420e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4799 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8155, 2.8147, 2.8450], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3976e-12, 4.3964e-12, 4.4421e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4800 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8451], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3964e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4801 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3964e-12, 4.4422e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4802 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8452], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3964e-12, 4.4423e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0802, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4803 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8453], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3964e-12, 4.4424e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4804 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3964e-12, 4.4425e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4805 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8454], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3964e-12, 4.4426e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4806 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8147, 2.8455], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3963e-12, 4.4427e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4807 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3963e-12, 4.4428e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4808 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8456], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3963e-12, 4.4429e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4809 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8457], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3963e-12, 4.4431e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4810 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3963e-12, 4.4432e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4811 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8458], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3975e-12, 4.3963e-12, 4.4433e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4812 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8459], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3963e-12, 4.4434e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4813 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3963e-12, 4.4435e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4814 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8460], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3963e-12, 4.4436e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4815 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8461], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3963e-12, 4.4437e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4816 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8154, 2.8146, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3963e-12, 4.4438e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4817 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8462], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3963e-12, 4.4439e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9870, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4818 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8463], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4440e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4819 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4441e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4820 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8464], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4442e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9684, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4821 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8465], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4443e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4822 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8466], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4444e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4823 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8146, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4824 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3974e-12, 4.3962e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4825 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3962e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4826 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3962e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4827 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3962e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4828 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3962e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4829 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3962e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4830 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3962e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4831 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4832 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4833 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4834 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4835 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4836 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4837 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4838 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8153, 2.8145, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4839 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3973e-12, 4.3961e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4840 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4841 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4842 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4843 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4844 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4845 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4846 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8145, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3961e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4847 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4848 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4849 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4850 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4851 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4852 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4853 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4854 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4855 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4856 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4482e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4857 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4858 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4859 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4860 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4861 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4862 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4863 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3972e-12, 4.3960e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4864 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4865 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4866 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4867 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4868 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4869 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4870 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4871 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4500e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4872 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4873 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4874 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8506], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4504e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4875 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4505e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4876 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8507], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4506e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4877 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8508], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4507e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4878 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8509], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4509e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4879 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8510], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4510e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.6057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4880 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8511], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4511e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4881 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8512], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4512e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4882 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4514e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4883 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8513], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4515e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4884 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8514], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4516e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5753, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4885 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8515], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4518e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4886 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8516], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4519e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4887 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8517], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4520e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4888 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8518], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4521e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4889 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8519], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3959e-12, 4.4523e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4890 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8519], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4524e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4891 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8520], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4525e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4892 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8521], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4527e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.5270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4893 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8522], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3971e-12, 4.3960e-12, 4.4528e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.4775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4894 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8152, 2.8144, 2.8523], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.4049e-12, 4.4445e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4895 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8203, 2.8467], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.4049e-12, 4.4446e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4896 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8203, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.4049e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4897 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8142, 2.8203, 2.8468], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.4049e-12, 4.4447e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4898 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8469], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.4049e-12, 4.4448e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.1023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4899 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3956e-12, 4.4049e-12, 4.4449e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4900 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8470], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4450e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4901 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4451e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4902 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8471], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4903 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4904 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4905 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3955e-12, 4.4048e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4906 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8141, 2.8203, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4907 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4908 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4909 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4910 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4911 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4912 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3954e-12, 4.4048e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4913 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8140, 2.8202, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3965e-12, 4.4053e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4914 was 68.0%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8147, 2.8206, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4037e-12, 4.4452e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4915 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8195, 2.8472], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4037e-12, 4.4453e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(5.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4916 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8195, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3940e-12, 4.4037e-12, 4.4454e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4917 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8195, 2.8473], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4037e-12, 4.4455e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4918 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8131, 2.8195, 2.8474], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4037e-12, 4.4456e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4919 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4037e-12, 4.4457e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4920 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8475], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4037e-12, 4.4458e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4921 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4036e-12, 4.4459e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9701, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4922 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8476], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4036e-12, 4.4460e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4923 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8477], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4036e-12, 4.4461e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4924 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3939e-12, 4.4036e-12, 4.4462e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4925 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8478], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4463e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4926 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8479], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4927 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4464e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4928 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8480], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4465e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4929 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8481], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4466e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4930 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8130, 2.8195, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4467e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4931 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8195, 2.8482], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4468e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4932 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8483], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3938e-12, 4.4036e-12, 4.4469e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4933 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4470e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.9007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4934 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8484], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4471e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4935 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8485], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4472e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8892, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4936 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4473e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4937 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8486], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4474e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8776, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4938 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8487], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4475e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4939 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4036e-12, 4.4476e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4940 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8488], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4035e-12, 4.4477e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4941 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8489], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4035e-12, 4.4478e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4942 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3937e-12, 4.4035e-12, 4.4479e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4943 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8490], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4480e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4944 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8129, 2.8194, 2.8491], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4481e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4945 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4483e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4946 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8492], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4484e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4947 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8493], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4485e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4948 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8494], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4486e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4949 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4487e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4950 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8495], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4488e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.8027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4951 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8496], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4489e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4952 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4490e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4953 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8497], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3936e-12, 4.4035e-12, 4.4491e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4954 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8498], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4492e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4955 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4493e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4956 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8499], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4494e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4957 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8500], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4495e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4958 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8501], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4496e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4959 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4497e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4960 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8502], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4498e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4961 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8503], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4499e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4962 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8128, 2.8194, 2.8504], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4501e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4963 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8194, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3935e-12, 4.4035e-12, 4.4502e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(3.9077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4964 was 68.3%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8127, 2.8194, 2.8505], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4965 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4405e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4966 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4967 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4968 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4406e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4969 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8441], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4970 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4971 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4407e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4972 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4973 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4974 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8442], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4975 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4408e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4976 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4977 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4978 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4409e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4979 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8443], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4980 was 68.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4981 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4410e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4982 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7585, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4983 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4984 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8444], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4411e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4985 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4986 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4987 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4412e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4988 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8445], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4989 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4990 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4413e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4991 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4992 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4993 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8446], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4414e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4994 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4995 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4996 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4415e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4997 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8447], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4998 was 68.4%\n",
      "Current On rates:  tensor([2.7183, 2.7183, 2.7183, 2.8062, 2.8129, 2.8448], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward>)\n",
      "current params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(4.7322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4999 was 68.4%\n",
      "optimization complete\n",
      "Final params: tensor([2.0612e-03, 2.0612e-03, 2.0612e-03, 4.3836e-12, 4.3937e-12, 4.4416e-12],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<steric_free_simulator.vectorized_rxn_net.VectorizedRxnNet at 0x7fbd32f62b00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1.0,\n",
    "                  optim_iterations=5000,\n",
    "                  learning_rate=new_kon[0]/1e15,\n",
    "                  device='cpu',method=\"RMSprop\")\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6841099382838659\n"
     ]
    }
   ],
   "source": [
    "print(optim.yield_per_iter[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557, 'uid': 0}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557, 'uid': 1}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557, 'uid': 2}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'A', 'C'}), 'kon': 1.0, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.248354255291587e-12, 'uid': 3}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'C'}, {'A', 'B'}), 'kon': 1.0, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.248354255291587e-12, 'uid': 4}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C', 'B'}), 'kon': 1.0, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.248354255291587e-12, 'uid': 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'AB': 3, 'AC': 4, 'BC': 5, 'ABC': 6}\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  A + B  ->  AB\n",
      "Net flux:  tensor([15.5340], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  A + C  ->  AC\n",
      "Net flux:  tensor([15.4644], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  A + BC  ->  ABC\n",
      "Net flux:  tensor([62.4484], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  B + A  ->  AB\n",
      "Net flux:  tensor([15.5340], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  B + C  ->  BC\n",
      "Net flux:  tensor([15.7768], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  B + AC  ->  ABC\n",
      "Net flux:  tensor([67.2027], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  C + A  ->  AC\n",
      "Net flux:  tensor([15.4644], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  C + B  ->  BC\n",
      "Net flux:  tensor([15.7768], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  C + AB  ->  ABC\n",
      "Net flux:  tensor([66.3576], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  AB + C  ->  ABC\n",
      "Net flux:  tensor([66.3576], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  AB  ->  A + B\n",
      "Net flux:  tensor([-15.5340], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  AC + B  ->  ABC\n",
      "Net flux:  tensor([67.2027], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  AC  ->  A + C\n",
      "Net flux:  tensor([-15.4644], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  BC + A  ->  ABC\n",
      "Net flux:  tensor([62.4484], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  BC  ->  B + C\n",
      "Net flux:  tensor([-15.7768], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  ABC  ->  B + AC\n",
      "Net flux:  tensor([-67.2027], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  ABC  ->  C + AB\n",
      "Net flux:  tensor([-66.3576], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  ABC  ->  BC + A\n",
      "Net flux:  tensor([-62.4484], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "[['A', 'AB', 'ABC'], ['B', 'AB', 'ABC'], ['C', 'AC', 'ABC'], ['AB', 'ABC'], ['AC', 'ABC'], ['BC', 'ABC'], ['ABC']]\n",
      "[2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0]\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB  :  1.0\n",
      "AC  :  1.0\n",
      "BC  :  1.0\n",
      "A  :  3.0\n",
      "B  :  3.0\n",
      "C  :  3.0\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC  :  tensor([-196.0087], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "BC  :  tensor([46.6715], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AB  :  tensor([50.8237], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AC  :  tensor([51.7383], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "A  :  tensor([93.4468], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "C  :  tensor([97.5989], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "B  :  tensor([98.5135], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([2.9958e-01, 8.8776e-04, 5.4808e-02, 1.5672e+01, 1.5618e+01, 1.5916e+01,\n",
      "        6.8411e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  :  0\n",
      "B  :  1\n",
      "C  :  2\n",
      "AB  :  3\n",
      "AC  :  4\n",
      "BC  :  5\n",
      "ABC  :  6\n"
     ]
    }
   ],
   "source": [
    "for n in rn.network.nodes():\n",
    "    print(gtostr(rn.network.nodes[n]['struct']), \" : \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes_list = ['A','B','C','ABC','AB','BC','AC']\n",
    "#nodes_list = ['AB','BMS','ABS','AMS','ABMS','AM','BM','MS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbd0dbe9080>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(optim.yield_per_iter)\n",
    "f_dict = {'fontsize':22}\n",
    "ax.set_ylabel(\"Yield (%)\",fontdict=f_dict)\n",
    "ax.set_xlabel(\"Iterations\",fontdict=f_dict)\n",
    "plt.tick_params(axis='both',labelsize=14.0)\n",
    "ax.hlines(y=0.999,xmin=0,xmax=5000,linewidth=2.5,linestyle='dashed',label='Eq. yield')\n",
    "ax.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Next time:  tensor(13.9494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Using CPU\n",
      "Next time:  tensor(107.3490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Next time:  tensor(571.6966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Using CPU\n",
      "Next time:  tensor(1306.8425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([10, 100, 500,1000]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i])\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  A + B  ->  AB\n",
      "Net flux:  tensor([-5.3615e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  A + C  ->  AC\n",
      "Net flux:  tensor([-3.9386e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  A + BC  ->  ABC\n",
      "Net flux:  tensor([98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  B + A  ->  AB\n",
      "Net flux:  tensor([-5.3615e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  B + C  ->  BC\n",
      "Net flux:  tensor([0.0024], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  B + AC  ->  ABC\n",
      "Net flux:  tensor([98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  C + A  ->  AC\n",
      "Net flux:  tensor([-3.9386e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  C + B  ->  BC\n",
      "Net flux:  tensor([0.0024], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  C + AB  ->  ABC\n",
      "Net flux:  tensor([98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  AB + C  ->  ABC\n",
      "Net flux:  tensor([98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  AB  ->  A + B\n",
      "Net flux:  tensor([5.3615e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  AC + B  ->  ABC\n",
      "Net flux:  tensor([98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  AC  ->  A + C\n",
      "Net flux:  tensor([3.9386e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  BC + A  ->  ABC\n",
      "Net flux:  tensor([98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  BC  ->  B + C\n",
      "Net flux:  tensor([-0.0024], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  ABC  ->  B + AC\n",
      "Net flux:  tensor([-98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  ABC  ->  C + AB\n",
      "Net flux:  tensor([-98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  ABC  ->  BC + A\n",
      "Net flux:  tensor([-98.2455], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9825], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 4.248354255291587e-12, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "[['A', 'AB', 'ABC'], ['B', 'AB', 'ABC'], ['C', 'AC', 'ABC'], ['AB', 'ABC'], ['AC', 'ABC'], ['BC', 'ABC'], ['ABC']]\n",
      "[2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0]\n"
     ]
    }
   ],
   "source": [
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC  :  tensor([-294.7366], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "BC  :  tensor([98.2431], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "A  :  tensor([98.2454], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AC  :  tensor([98.2456], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AB  :  tensor([98.2456], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "B  :  tensor([98.2479], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "C  :  tensor([98.2479], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([8.6548e-03, 6.1948e-03, 6.1806e-03, 0.0000e+00, 1.4230e-05, 2.4743e-03,\n",
      "        9.9991e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Matrix([[0.0001015107], [0.0001015107], [0.0001015107], [4.591091e-6], [4.591091e-6], [4.591150e-6], [99.99989]])\n",
      "Equilibrium expected yield:  99.9998889160156 %\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix([[0.0001015107], [0.0001015107], [0.0001015107], [4.591091e-6], [4.591091e-6], [4.591150e-6], [99.99989]])\n",
      "Matrix([[0.09191163], [0.06966965], [0.05792693], [0.01618169], [0.02792583], [0.05017105], [99.86398]])\n",
      "Equilibrium expected yield:  99.8639782714844 %\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Data1/adip/software/anaconda3/envs/steric_free_sim/lib/python3.7/site-packages/numpy/lib/function_base.py:2526: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/media/Data1/adip/software/anaconda3/envs/steric_free_sim/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/media/Data1/adip/software/anaconda3/envs/steric_free_sim/lib/python3.7/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, '0.8 - 0.9 Yield range\\nNumber of samples: 0.02 %')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr_matrix(M):\n",
    "    return(np.corrcoef(M))\n",
    "\n",
    "#Select data range to calculate coorelations\n",
    "yield_thresh_min = 0.8\n",
    "yield_thresh_max = 0.9\n",
    "mask1 = (np.array(optim.final_yields) >= yield_thresh_min) & (np.array(optim.final_yields) < yield_thresh_max)\n",
    "print(mask1)\n",
    "\n",
    "coor_params = np.zeros((6,1))\n",
    "for i in range(len(mask1)):\n",
    "    if mask1[i]:\n",
    "        coor_params = np.concatenate((coor_params,np.reshape(optim.final_solns[i].numpy(),(6,1))),axis=1)\n",
    "\n",
    "corr_matrix = corr_matrix(coor_params)\n",
    "\n",
    "# %matplotlib notebook\n",
    "fig_c,ax_c = plt.subplots()\n",
    "hm = ax_c.imshow(corr_matrix)\n",
    "ax_labels=['k1','k2','k3','k4','k5','k6']\n",
    "ax_c.set_xticks(np.arange(len(ax_labels)))\n",
    "ax_c.set_yticks(np.arange(len(ax_labels)))\n",
    "ax_c.set_xticklabels(ax_labels)\n",
    "ax_c.set_yticklabels(ax_labels)\n",
    "plt.setp(ax_c.get_xticklabels(),rotation=45, ha='center',fontsize=10,va='top')\n",
    "plt.setp(ax_c.get_yticklabels(),va='center',fontsize=10)\n",
    "fig_c.colorbar(hm,ax=ax_c,aspect=40,label=\"Corr Coeff\",orientation='horizontal',panchor=(0.5,0.0),pad=0.2,shrink=0.5)\n",
    "# ax_c.grid()\n",
    "\n",
    "plt.show()\n",
    "label = \"Number of samples: %.2f %s\" %(coor_params.shape[1]*100/len(optim.final_solns),\"%\")\n",
    "yield_label = \"%.1f - %.1f Yield range\\n\" %(yield_thresh_min,yield_thresh_max)\n",
    "ax_c.set_title(yield_label+label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
