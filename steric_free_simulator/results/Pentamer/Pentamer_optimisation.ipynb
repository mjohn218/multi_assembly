{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_input = '../../input_files/pentamer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do modifications here\n",
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "new_kon = new_kon + Tensor([1.]*np.array(1e0))\n",
    "# new_kon = new_kon + Tensor([ 2.0250,  1.9631,  1.6295,  2.0319,  1.8428,  1.9629,  1.9462,  2.1415,\n",
    "#          3.0504,  1.9790,  2.2053,  1.8444,  2.0038,  2.8676,  1.8831,  2.2072,\n",
    "#          2.8235,  7.0827,  6.8401,  1.9636,  1.8379,  1.8441,  1.7327,  2.6644,\n",
    "#          2.5297,  6.1627,  5.6660,  2.5278,  5.7092,  7.7515, 14.7079,  2.0182,\n",
    "#          2.0557,  2.9554,  3.0558,  2.2752,  7.1661,  7.0257,  1.6925,  6.7420,\n",
    "#          7.1950, 14.4043,  0.0248,  0.0322,  0.0325,  3.5224,  0.0312,  0.0321,\n",
    "#          0.0305,  3.3910,  0.0346,  0.0212,  0.0342,  4.1594,  0.0320,  0.0323,\n",
    "#          0.0230,  3.4099,  2.5865,  0.0300,  4.6505,  1.9634,  0.0348,  3.6781,\n",
    "#          2.3943,  0.0309,  4.6222,  3.5830,  4.4373,  3.3184,  1.4508,  1.7639,\n",
    "#          2.4415,  3.0000,  7.3860,  7.3816,  5.2024,  6.9316,  1.8574,  2.2372,\n",
    "#          2.0936,  7.3989,  6.8460,  5.3782,  7.3621, 14.2158,  4.7405,  7.4420,\n",
    "#         14.2274, 15.2673])\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)\n",
    "\n",
    "#Changing initial concentrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Equilibrium Solution ##\n",
    "First we will find the equilibrium solution for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vec_rn.update_reaction_net(rn)\n",
    "# poly_system = EquilibriumSolver(rn)\n",
    "# solution = poly_system.solve()\n",
    "# print(solution)\n",
    "# if solution == None:\n",
    "#     print(\"No Equilibrium solution\")\n",
    "# else:\n",
    "#     print(solution)\n",
    "#     print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "# print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uid_dict = {}\n",
    "# sys.path.append(\"../\")\n",
    "# import numpy as np\n",
    "# from reaction_network import gtostr\n",
    "# from torch import DoubleTensor as Tensor\n",
    "\n",
    "# def get_max_edge(n):\n",
    "#     \"\"\"\n",
    "#     Calculates the max rate (k_on) for a given node\n",
    "#     To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "#     Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "#     Can tell which component is used quickly.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         edges = rn.network.out_edges(n)\n",
    "#         #Loop over all edges\n",
    "#         #Get attributes\n",
    "#         if len(edges)==0:\n",
    "#             return(False)\n",
    "#         kon_max = -1\n",
    "#         next_node = -1\n",
    "        \n",
    "#         kon_sum = 0\n",
    "#         for edge in edges:\n",
    "#             data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "#             #print(data)\n",
    "#             #Get uid\n",
    "#             uid = data['uid']\n",
    "#             #Get updated kon\n",
    "#             temp_kon = vec_rn.kon[uid]\n",
    "#             kon_sum+=temp_kon\n",
    "            \n",
    "# #             #Calculate k_off also\n",
    "# #             std_c = Tensor([1.])\n",
    "# #             l_kon = torch.log(temp_kon)\n",
    "# #             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "#             if temp_kon > kon_max:\n",
    "#                 kon_max = temp_kon\n",
    "#                 next_node=edge[1]\n",
    "#         return(kon_max,next_node,kon_sum)\n",
    "#     except Exception as err:\n",
    "#         raise(err)\n",
    "\n",
    "# pathway = []\n",
    "# kon_sumarray = []\n",
    "# total_con_rate = {}\n",
    "# for n in rn.network.nodes():\n",
    "    \n",
    "#     n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "#     paths = [n_str]\n",
    "#     kon_sum = 0\n",
    "#     temp_node = n\n",
    "#     max_edge = True\n",
    "#     consumption_rate = 0\n",
    "#     if n < len(rn.network.nodes()):#num_monomers:\n",
    "# #         print(\"Current node: \")\n",
    "# #         print(n_str)\n",
    "#         while max_edge:\n",
    "#             max_edge = get_max_edge(temp_node)\n",
    "#             if max_edge:\n",
    "#                 total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "#                 temp_node = max_edge[1]\n",
    "#                 kon_sum += max_edge[0].item()\n",
    "                \n",
    "# #                 print(\"Next node: \")\n",
    "# #                 print(temp_node)\n",
    "\n",
    "#                 paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "#             else:\n",
    "#                 break\n",
    "#         pathway.append(paths)\n",
    "#         kon_sumarray.append(kon_sum)\n",
    "#         paths=[]\n",
    "\n",
    "# print(pathway)\n",
    "# print(kon_sumarray)\n",
    "# #print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if solution != None:\n",
    "#     for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "#         print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if solution !=None:\n",
    "#     for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "#         print(k,\" : \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer with a 1 second simulation runtime ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=1000,\n",
    "                  learning_rate=new_kon[0].item()/1e2,\n",
    "                  device='cpu',method=\"RMSprop\")\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var(v1,v2):\n",
    "    sq_sum=0\n",
    "    for i in range(len(v1)):\n",
    "        sq_sum=(v1[i]-v2[i])**2+sq_sum\n",
    "    \n",
    "    sq_sum = ((sq_sum)**0.5)/(len(v1)-1)\n",
    "    return(sq_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    final_params.append(optim.final_solns[i].numpy())\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)[sort_indx]\n",
    "sorted_params = np.array(final_params)[sort_indx]\n",
    "\n",
    "p0 = sorted_params[0]\n",
    "var_params = []\n",
    "for i in range(len(sorted_params)):\n",
    "    var_params.append(calc_var(p0,sorted_params[i]))\n",
    "    \n",
    "arg_indx = np.argsort(np.array(var_params))\n",
    "sorted_var = np.array(var_params)[arg_indx]\n",
    "\n",
    "print(sorted_var[0])\n",
    "print(sorted_var[-1])\n",
    "print(\"Yield: \",sorted_yields[arg_indx[0]],\"\\nParams: \",sorted_params[arg_indx[0]])\n",
    "\n",
    "print(\"Yield: \",sorted_yields[arg_indx[-1]],\"\\nParams: \",sorted_params[arg_indx[-1]])\n",
    "print(\"Max Yield: \",sorted_yields[-1],\"\\nParams: \",sorted_params[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off']}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "#             #Calculate k_off also\n",
    "#             std_c = Tensor([1.])\n",
    "#             l_kon = torch.log(temp_kon)\n",
    "#             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nodes_list = ['A','B','S','M','AB','BMS','ABS','AMS','ABMS','AM','AS']\n",
    "#nodes_list = ['A','B','ABMS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([1, 8, 64]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i],)\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
