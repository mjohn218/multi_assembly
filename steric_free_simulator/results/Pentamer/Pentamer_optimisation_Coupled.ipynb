{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7f8f8b4829b0>\n"
     ]
    }
   ],
   "source": [
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['rxn_coupling', True]\n",
      "True\n",
      "['P']\n",
      "['Q']\n",
      "['R']\n",
      "['S']\n",
      "['T']\n",
      "Parsing rule...\n",
      "['P(a)+Q(b)<->P(a!1).Q(a!1)', '', 'G=-12']\n",
      "['P', 'Q', '']\n",
      "['P(a)+Q(b)', 'P(a!1).Q(a!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['P(b)+R(a)<->P(b!1).R(a!1)', '', 'G=-12']\n",
      "['P', 'R', '']\n",
      "['P(b)+R(a)', 'P(b!1).R(a!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['P(c)+S(a)<->P(c!1).S(a!1)', '', 'G=-12']\n",
      "['P', 'S', '']\n",
      "['P(c)+S(a)', 'P(c!1).S(a!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['P(b)+T(b)<->P(b!1).T(b!1)', '', 'G=-12']\n",
      "['P', 'T', '']\n",
      "['P(b)+T(b)', 'P(b!1).T(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['Q(c)+R(b)<->Q(c!1).R(b!1)', '', 'G=-12']\n",
      "['Q', 'R', '']\n",
      "['Q(c)+R(b)', 'Q(c!1).R(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['Q(c)+S(b)<->Q(c!1).S(b!1)', '', 'G=-12']\n",
      "['Q', 'S', '']\n",
      "['Q(c)+S(b)', 'Q(c!1).S(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['Q(c)+T(b)<->Q(c!1).T(b!1)', '', 'G=-12']\n",
      "['Q', 'T', '']\n",
      "['Q(c)+T(b)', 'Q(c!1).T(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['R(c)+S(b)<->R(c!1).S(b!1)', '', 'G=-12']\n",
      "['R', 'S', '']\n",
      "['R(c)+S(b)', 'R(c!1).S(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['R(c)+T(b)<->R(c!1).T(b!1)', '', 'G=-12']\n",
      "['R', 'T', '']\n",
      "['R(c)+T(b)', 'R(c!1).T(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "['S(c)+T(b)<->S(c!1).T(b!1)', '', 'G=-12']\n",
      "['S', 'T', '']\n",
      "['S(c)+T(b)', 'S(c!1).T(b!1)']\n",
      "GGGGGGGGGgg\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'Q'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('P', 'Q')]\n",
      "New node added--1\n",
      "['P', 'Q']\n",
      "Adding an new edge-- 0 5\n",
      "New bonds:  [('P', 'Q')]\n",
      "Adding an new edge-- 1 5\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'R'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('P', 'R')]\n",
      "New node added--1\n",
      "['P', 'R']\n",
      "Adding an new edge-- 0 6\n",
      "New bonds:  [('P', 'R')]\n",
      "Adding an new edge-- 2 6\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'S'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('P', 'S')]\n",
      "New node added--1\n",
      "['P', 'S']\n",
      "Adding an new edge-- 0 7\n",
      "New bonds:  [('P', 'S')]\n",
      "Adding an new edge-- 3 7\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'T'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('P', 'T')]\n",
      "New node added--1\n",
      "['P', 'T']\n",
      "Adding an new edge-- 0 8\n",
      "New bonds:  [('P', 'T')]\n",
      "Adding an new edge-- 4 8\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('Q', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'R'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'R')]\n",
      "New node added--1\n",
      "['Q', 'R']\n",
      "Adding an new edge-- 1 9\n",
      "New bonds:  [('Q', 'R')]\n",
      "Adding an new edge-- 2 9\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'S'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'S')]\n",
      "New node added--1\n",
      "['Q', 'S']\n",
      "Adding an new edge-- 1 10\n",
      "New bonds:  [('Q', 'S')]\n",
      "Adding an new edge-- 3 10\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'T'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'T')]\n",
      "New node added--1\n",
      "['Q', 'T']\n",
      "Adding an new edge-- 1 11\n",
      "New bonds:  [('Q', 'T')]\n",
      "Adding an new edge-- 4 11\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "New node added--1\n",
      "['Q', 'P', 'R']\n",
      "Adding an new edge-- 1 12\n",
      "New bonds:  [('P', 'Q'), ('Q', 'R')]\n",
      "Adding an new edge-- 6 12\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "New node added--1\n",
      "['Q', 'P', 'S']\n",
      "Adding an new edge-- 1 13\n",
      "New bonds:  [('P', 'Q'), ('Q', 'S')]\n",
      "Adding an new edge-- 7 13\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['Q', 'P', 'T']\n",
      "Adding an new edge-- 1 14\n",
      "New bonds:  [('P', 'Q'), ('Q', 'T')]\n",
      "Adding an new edge-- 8 14\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'P'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('R', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('R', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'S')]\n",
      "New node added--1\n",
      "['R', 'S']\n",
      "Adding an new edge-- 2 15\n",
      "New bonds:  [('R', 'S')]\n",
      "Adding an new edge-- 3 15\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'T')]\n",
      "New node added--1\n",
      "['R', 'T']\n",
      "Adding an new edge-- 2 16\n",
      "New bonds:  [('R', 'T')]\n",
      "Adding an new edge-- 4 16\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('P', 'Q')]\n",
      "Adding an new edge-- 2 12\n",
      "New bonds:  [('P', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 5 12\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "New node added--1\n",
      "['R', 'P', 'S']\n",
      "Adding an new edge-- 2 17\n",
      "New bonds:  [('P', 'R'), ('R', 'S')]\n",
      "Adding an new edge-- 7 17\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['R', 'P', 'T']\n",
      "Adding an new edge-- 2 18\n",
      "New bonds:  [('P', 'R'), ('R', 'T')]\n",
      "Adding an new edge-- 8 18\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "New node added--1\n",
      "['R', 'Q', 'S']\n",
      "Adding an new edge-- 2 19\n",
      "New bonds:  [('Q', 'R'), ('R', 'S')]\n",
      "Adding an new edge-- 10 19\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "New node added--1\n",
      "['R', 'Q', 'T']\n",
      "Adding an new edge-- 2 20\n",
      "New bonds:  [('Q', 'R'), ('R', 'T')]\n",
      "Adding an new edge-- 11 20\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "New node added--1\n",
      "['R', 'Q', 'P', 'S']\n",
      "Adding an new edge-- 2 21\n",
      "New bonds:  [('P', 'R'), ('Q', 'R'), ('R', 'S')]\n",
      "Adding an new edge-- 13 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 21\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['R', 'Q', 'P', 'T']\n",
      "Adding an new edge-- 2 22\n",
      "New bonds:  [('P', 'R'), ('Q', 'R'), ('R', 'T')]\n",
      "Adding an new edge-- 14 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 22\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'P'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('S', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('S', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'T')]\n",
      "New node added--1\n",
      "['S', 'T']\n",
      "Adding an new edge-- 3 23\n",
      "New bonds:  [('S', 'T')]\n",
      "Adding an new edge-- 4 23\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('P', 'Q')]\n",
      "Adding an new edge-- 3 13\n",
      "New bonds:  [('P', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 5 13\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 3 17\n",
      "New bonds:  [('P', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 6 17\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'P', 'T']\n",
      "Adding an new edge-- 3 24\n",
      "New bonds:  [('P', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 8 24\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'R', 'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 3 19\n",
      "New bonds:  [('Q', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 9 19\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "New node added--1\n",
      "['S', 'Q', 'T']\n",
      "Adding an new edge-- 3 25\n",
      "New bonds:  [('Q', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 11 25\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'R'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 3 21\n",
      "New bonds:  [('P', 'S'), ('Q', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 12 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 21\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'Q', 'P', 'T']\n",
      "Adding an new edge-- 3 26\n",
      "New bonds:  [('P', 'S'), ('Q', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 14 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 26\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'R', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'T']\n",
      "Adding an new edge-- 3 27\n",
      "New bonds:  [('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 16 27\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'P', 'T']\n",
      "Adding an new edge-- 3 28\n",
      "New bonds:  [('P', 'S'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 18 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 28\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'Q', 'T']\n",
      "Adding an new edge-- 3 29\n",
      "New bonds:  [('Q', 'S'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 20 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 29\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'Q', 'P', 'T']\n",
      "Adding an new edge-- 3 30\n",
      "New bonds:  [('P', 'S'), ('Q', 'S'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 22 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 30\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'P'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "Adding an new edge-- 4 14\n",
      "New bonds:  [('P', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 5 14\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 4 18\n",
      "New bonds:  [('P', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 6 18\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 24\n",
      "New bonds:  [('P', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 7 24\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 4 20\n",
      "New bonds:  [('Q', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 9 20\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 4 25\n",
      "New bonds:  [('Q', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 10 25\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('T', 'R'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 4 22\n",
      "New bonds:  [('P', 'T'), ('Q', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 12 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 22\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('T', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 26\n",
      "New bonds:  [('P', 'T'), ('Q', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 13 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 26\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 4 27\n",
      "New bonds:  [('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 15 27\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'R'), ('T', 'S'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 28\n",
      "New bonds:  [('P', 'T'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 17 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 28\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'Q'), ('T', 'R'), ('T', 'S'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 4 29\n",
      "New bonds:  [('Q', 'T'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 19 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 29\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('T', 'R'), ('T', 'S'), ('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 30\n",
      "New bonds:  [('P', 'T'), ('Q', 'T'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 21 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 30\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('Q', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'S'), ('Q', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'T'), ('Q', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('P', 'Q'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('P', 'S'), ('Q', 'R'), ('Q', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 5 21\n",
      "New bonds:  [('P', 'R'), ('P', 'S'), ('Q', 'R'), ('Q', 'S')]\n",
      "Adding an new edge-- 15 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('P', 'Q'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('P', 'T'), ('Q', 'R'), ('Q', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 5 22\n",
      "New bonds:  [('P', 'R'), ('P', 'T'), ('Q', 'R'), ('Q', 'T')]\n",
      "Adding an new edge-- 16 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('P', 'Q'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'S'), ('P', 'T'), ('Q', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 5 26\n",
      "New bonds:  [('P', 'S'), ('P', 'T'), ('Q', 'S'), ('Q', 'T')]\n",
      "Adding an new edge-- 23 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Item edges:  [('P', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('P', 'S'), ('P', 'T'), ('Q', 'R'), ('Q', 'S'), ('Q', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 5 30\n",
      "New bonds:  [('P', 'R'), ('P', 'S'), ('P', 'T'), ('Q', 'R'), ('Q', 'S'), ('Q', 'T')]\n",
      "Adding an new edge-- 27 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'Q')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('R', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'S'), ('R', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'T'), ('R', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('P', 'R'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('P', 'S'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 6 21\n",
      "New bonds:  [('P', 'Q'), ('P', 'S'), ('Q', 'R'), ('R', 'S')]\n",
      "Adding an new edge-- 10 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('P', 'R'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('P', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 6 22\n",
      "New bonds:  [('P', 'Q'), ('P', 'T'), ('Q', 'R'), ('R', 'T')]\n",
      "Adding an new edge-- 11 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('P', 'R'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'S'), ('P', 'T'), ('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 6 28\n",
      "New bonds:  [('P', 'S'), ('P', 'T'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 23 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Item edges:  [('P', 'R'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('P', 'S'), ('P', 'T'), ('R', 'Q'), ('R', 'S'), ('R', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 6 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'S'), ('P', 'T'), ('Q', 'R'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 25 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('S', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'R'), ('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('P', 'S'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('P', 'R'), ('S', 'Q'), ('S', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 7 21\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('Q', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 9 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('P', 'S'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('P', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 7 26\n",
      "New bonds:  [('P', 'Q'), ('P', 'T'), ('Q', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 11 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'T'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('P', 'S'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'R'), ('P', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 7 28\n",
      "New bonds:  [('P', 'R'), ('P', 'T'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 16 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Item edges:  [('P', 'S'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('P', 'R'), ('P', 'T'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 7 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('P', 'T'), ('Q', 'S'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 20 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'S'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('P', 'T'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('P', 'R'), ('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 8 22\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('Q', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 9 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('P', 'T'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('P', 'S'), ('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 8 26\n",
      "New bonds:  [('P', 'Q'), ('P', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 10 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'S'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('P', 'T'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'R'), ('P', 'S'), ('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 8 28\n",
      "New bonds:  [('P', 'R'), ('P', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 15 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Item edges:  [('P', 'T'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('P', 'R'), ('P', 'S'), ('T', 'Q'), ('T', 'R'), ('T', 'S'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 8 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('P', 'S'), ('Q', 'T'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 19 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('R', 'P')]\n",
      "Adding an new edge-- 9 12\n",
      "New bonds:  [('P', 'Q'), ('P', 'R')]\n",
      "Adding an new edge-- 0 12\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'S'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'S'), ('R', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'T'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'T'), ('R', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('Q', 'R'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('Q', 'S'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('Q', 'R'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('Q', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('Q', 'R'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'S'), ('Q', 'T'), ('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 9 29\n",
      "New bonds:  [('Q', 'S'), ('Q', 'T'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 23 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'R'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('Q', 'S'), ('Q', 'T'), ('R', 'P'), ('R', 'S'), ('R', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Adding an new edge-- 9 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('Q', 'S'), ('Q', 'T'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 24 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('S', 'P')]\n",
      "Adding an new edge-- 10 13\n",
      "New bonds:  [('P', 'Q'), ('P', 'S')]\n",
      "Adding an new edge-- 0 13\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'R'), ('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('Q', 'S'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('Q', 'R'), ('S', 'P'), ('S', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('Q', 'S'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('Q', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('Q', 'S'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'R'), ('Q', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 10 29\n",
      "New bonds:  [('Q', 'R'), ('Q', 'T'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 16 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'S'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('Q', 'R'), ('Q', 'T'), ('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Adding an new edge-- 10 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'S'), ('Q', 'R'), ('Q', 'T'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 18 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 11 14\n",
      "New bonds:  [('P', 'Q'), ('P', 'T')]\n",
      "Adding an new edge-- 0 14\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'R'), ('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('Q', 'T'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('Q', 'R'), ('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('Q', 'T'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('Q', 'S'), ('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('Q', 'T'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'R'), ('Q', 'S'), ('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 11 29\n",
      "New bonds:  [('Q', 'R'), ('Q', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 15 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Item edges:  [('Q', 'T'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('Q', 'R'), ('Q', 'S'), ('T', 'P'), ('T', 'R'), ('T', 'S'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 11 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'T'), ('Q', 'R'), ('Q', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 17 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('Q', 'S'), ('P', 'R'), ('P', 'S'), ('R', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('Q', 'T'), ('P', 'R'), ('P', 'T'), ('R', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'S'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('Q', 'S'), ('Q', 'T'), ('P', 'R'), ('P', 'S'), ('P', 'T'), ('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 12 30\n",
      "New bonds:  [('P', 'S'), ('P', 'T'), ('Q', 'S'), ('Q', 'T'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 23 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('Q', 'R'), ('P', 'S'), ('P', 'R'), ('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'S'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('Q', 'T'), ('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('Q', 'R'), ('Q', 'T'), ('P', 'S'), ('P', 'R'), ('P', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 13 30\n",
      "New bonds:  [('P', 'R'), ('P', 'T'), ('Q', 'R'), ('Q', 'T'), ('R', 'S'), ('S', 'T')]\n",
      "Adding an new edge-- 16 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'Q', 'S'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('Q', 'R'), ('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('Q', 'S'), ('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('Q', 'R'), ('Q', 'S'), ('P', 'T'), ('P', 'R'), ('P', 'S'), ('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 14 30\n",
      "New bonds:  [('P', 'R'), ('P', 'S'), ('Q', 'R'), ('Q', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 15 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'Q', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('S', 'P')]\n",
      "Adding an new edge-- 15 17\n",
      "New bonds:  [('P', 'R'), ('P', 'S')]\n",
      "Adding an new edge-- 0 17\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'Q'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'Q'), ('S', 'Q')]\n",
      "Adding an new edge-- 15 19\n",
      "New bonds:  [('Q', 'R'), ('Q', 'S')]\n",
      "Adding an new edge-- 1 19\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'T'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('R', 'S'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('R', 'Q'), ('S', 'P'), ('S', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('R', 'S'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('R', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('R', 'S'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'Q'), ('R', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('R', 'S'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'S'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 16 18\n",
      "New bonds:  [('P', 'R'), ('P', 'T')]\n",
      "Adding an new edge-- 0 18\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'Q'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 16 20\n",
      "New bonds:  [('Q', 'R'), ('Q', 'T')]\n",
      "Adding an new edge-- 1 20\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'S'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('S', 'T')\n",
      "############################3\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('R', 'T'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('R', 'Q'), ('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('R', 'T'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('R', 'S'), ('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('R', 'T'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'Q'), ('R', 'S'), ('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('R', 'T'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'S'), ('T', 'P'), ('T', 'Q'), ('T', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('R', 'Q'), ('P', 'S'), ('P', 'Q'), ('S', 'Q')]\n",
      "Adding an new edge-- 17 21\n",
      "New bonds:  [('P', 'Q'), ('Q', 'R'), ('Q', 'S')]\n",
      "Adding an new edge-- 1 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 21\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "{'P', 'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('R', 'T'), ('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('R', 'Q'), ('R', 'T'), ('P', 'S'), ('P', 'Q'), ('P', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'R', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R', 'S'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('R', 'Q'), ('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 18 22\n",
      "New bonds:  [('P', 'Q'), ('Q', 'R'), ('Q', 'T')]\n",
      "Adding an new edge-- 1 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 22\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "{'P', 'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('R', 'S'), ('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('R', 'Q'), ('R', 'S'), ('P', 'T'), ('P', 'Q'), ('P', 'S'), ('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'S', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('R', 'P'), ('Q', 'S'), ('Q', 'P'), ('S', 'P')]\n",
      "Adding an new edge-- 19 21\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('P', 'S')]\n",
      "Adding an new edge-- 0 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 21\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'Q'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'S'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('R', 'T'), ('Q', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('R', 'P'), ('R', 'T'), ('Q', 'S'), ('Q', 'P'), ('Q', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'S', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'T', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('R', 'P'), ('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 20 22\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('P', 'T')]\n",
      "Adding an new edge-- 0 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 22\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'Q'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('R', 'S'), ('Q', 'T'), ('Q', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('R', 'P'), ('R', 'S'), ('Q', 'T'), ('Q', 'P'), ('Q', 'S'), ('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'T', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'S', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'S'}\n",
      "{'P', 'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('R', 'T'), ('Q', 'P'), ('Q', 'S'), ('Q', 'T'), ('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('R', 'S'), ('Q', 'P'), ('Q', 'T'), ('Q', 'S'), ('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'T'}\n",
      "{'P', 'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 23 24\n",
      "New bonds:  [('P', 'S'), ('P', 'T')]\n",
      "Adding an new edge-- 0 24\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'Q'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 23 25\n",
      "New bonds:  [('Q', 'S'), ('Q', 'T')]\n",
      "Adding an new edge-- 1 25\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 23 27\n",
      "New bonds:  [('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 2 27\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('S', 'T'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('S', 'Q'), ('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'R'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('S', 'T'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('S', 'R'), ('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('S', 'T'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'Q'), ('S', 'R'), ('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Item edges:  [('S', 'T'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('S', 'Q'), ('S', 'R'), ('T', 'P'), ('T', 'Q'), ('T', 'R'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'S', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'T')]\n",
      "False\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('S', 'Q'), ('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 24 26\n",
      "New bonds:  [('P', 'Q'), ('Q', 'S'), ('Q', 'T')]\n",
      "Adding an new edge-- 1 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 26\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "{'P', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('S', 'R'), ('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 24 28\n",
      "New bonds:  [('P', 'R'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 2 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 28\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('S', 'P'), ('S', 'T'), ('P', 'T'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('S', 'Q'), ('S', 'R'), ('P', 'T'), ('P', 'Q'), ('P', 'R'), ('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'S', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "False\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "{'Q', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('S', 'P'), ('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 25 26\n",
      "New bonds:  [('P', 'Q'), ('P', 'S'), ('P', 'T')]\n",
      "Adding an new edge-- 0 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 26\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('S', 'R'), ('Q', 'T'), ('Q', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 25 29\n",
      "New bonds:  [('Q', 'R'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 2 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('S', 'P'), ('S', 'R'), ('Q', 'T'), ('Q', 'P'), ('Q', 'R'), ('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'S', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "{'Q', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('S', 'R'), ('Q', 'P'), ('Q', 'T'), ('Q', 'R'), ('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 26 30\n",
      "New bonds:  [('P', 'R'), ('Q', 'R'), ('R', 'S'), ('R', 'T')]\n",
      "Adding an new edge-- 2 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 30\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "{'R', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('S', 'P'), ('R', 'T'), ('R', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 27 28\n",
      "New bonds:  [('P', 'R'), ('P', 'S'), ('P', 'T')]\n",
      "Adding an new edge-- 0 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 28\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('S', 'Q'), ('R', 'T'), ('R', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 27 29\n",
      "New bonds:  [('Q', 'R'), ('Q', 'S'), ('Q', 'T')]\n",
      "Adding an new edge-- 1 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 29\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('S', 'R'), ('S', 'T'), ('R', 'T'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('S', 'P'), ('S', 'Q'), ('R', 'T'), ('R', 'P'), ('R', 'Q'), ('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'S', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "False\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P'}\n",
      "{'R', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('S', 'Q'), ('R', 'P'), ('R', 'T'), ('R', 'Q'), ('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 28 30\n",
      "New bonds:  [('P', 'Q'), ('Q', 'R'), ('Q', 'S'), ('Q', 'T')]\n",
      "Adding an new edge-- 1 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 30\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R'}\n",
      "{'P', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'S'}\n",
      "{'P', 'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'T'}\n",
      "{'P', 'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'R', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('S', 'P'), ('R', 'Q'), ('R', 'T'), ('R', 'P'), ('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 29 30\n",
      "New bonds:  [('P', 'Q'), ('P', 'R'), ('P', 'S'), ('P', 'T')]\n",
      "Adding an new edge-- 0 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 30\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4b94d68>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x7f8f884072e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d64908>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'S'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef5d649e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'T'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398d68>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d98d0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x7f8f88398e10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'R', 'T', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b0f0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'R', 'S', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447b4a8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f208>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9be0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9b00>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'Q', 'R'}\n",
      "{'S', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f278>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'Q', 'S'}\n",
      "{'R', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d95f8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'Q', 'T'}\n",
      "{'R', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e3c8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'S'}\n",
      "{'P', 'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'T'}\n",
      "{'P', 'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e400>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'R', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bc50>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'R', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'S', 'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449e630>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'T', 'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef449ee80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'R', 'S', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'R', 'T', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9e48>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'S', 'T'}\n",
      "{'P', 'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef44d9860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'S', 'T'}\n",
      "{'R', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef4d6be10>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'Q', 'S', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'Q', 'S', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef447bb38>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'S', 'T'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'P', 'R', 'S', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448fe80>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'R', 'S', 'T', 'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x7f8ef448f358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "{'S', 'R', 'T', 'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Coupling Reaction ID:  {7: [0, 4], 8: [0, 5], 9: [0, 6], 12: [1, 4], 13: [1, 10], 14: [1, 11], 15: [4, 10], 16: [4, 11], 17: [1, 4, 10], 18: [1, 4, 11], 20: [2, 5], 21: [2, 10], 22: [2, 19], 23: [5, 10], 24: [5, 19], 25: [2, 5, 10], 26: [2, 5, 19], 27: [10, 19], 28: [2, 10, 19], 29: [5, 10, 19], 30: [2, 5, 10, 19], 31: [3, 6], 32: [3, 11], 33: [3, 19], 34: [6, 11], 35: [6, 19], 36: [3, 6, 11], 37: [3, 6, 19], 38: [11, 19], 39: [3, 11, 19], 40: [6, 11, 19], 41: [3, 6, 11, 19], 42: [1, 2, 4, 5], 43: [1, 3, 4, 6], 44: [2, 3, 5, 6], 45: [1, 2, 3, 4, 5, 6], 46: [0, 2, 4, 10], 47: [0, 3, 4, 11], 48: [2, 3, 10, 11], 49: [0, 2, 3, 4, 10, 11], 50: [0, 1, 5, 10], 51: [0, 3, 5, 19], 52: [1, 3, 10, 19], 53: [0, 1, 3, 5, 10, 19], 54: [0, 1, 6, 11], 55: [0, 2, 6, 19], 56: [1, 2, 11, 19], 57: [0, 1, 2, 6, 11, 19], 58: [0, 1], 59: [5, 6, 10, 11], 60: [0, 5, 6, 1, 10, 11], 61: [0, 2], 62: [4, 6, 10, 19], 63: [0, 4, 6, 2, 10, 19], 64: [0, 3], 65: [4, 5, 11, 19], 66: [0, 4, 5, 3, 11, 19], 67: [2, 3, 5, 6, 10, 11], 68: [1, 3, 4, 6, 10, 19], 69: [1, 2, 4, 5, 11, 19], 70: [1, 2], 71: [4, 5], 72: [1, 3], 73: [4, 6], 74: [0, 4, 5], 75: [0, 4, 6], 76: [0, 1, 2], 77: [0, 1, 3], 78: [2, 3], 79: [5, 6], 80: [10, 11], 81: [0, 5, 6], 82: [1, 10, 11], 83: [0, 2, 3], 84: [4, 10, 11], 85: [1, 4, 10, 11], 86: [1, 2, 3], 87: [4, 5, 6], 88: [0, 4, 5, 6], 89: [0, 1, 2, 3]}\n",
      "P\n",
      "Reactant Sets:\n",
      "Q\n",
      "Reactant Sets:\n",
      "R\n",
      "Reactant Sets:\n",
      "S\n",
      "Reactant Sets:\n",
      "T\n",
      "Reactant Sets:\n",
      "PQ\n",
      "Reactant Sets:\n",
      "(0, 1)\n",
      "PR\n",
      "Reactant Sets:\n",
      "(0, 2)\n",
      "PS\n",
      "Reactant Sets:\n",
      "(0, 3)\n",
      "PT\n",
      "Reactant Sets:\n",
      "(0, 4)\n",
      "QR\n",
      "Reactant Sets:\n",
      "(1, 2)\n",
      "QS\n",
      "Reactant Sets:\n",
      "(1, 3)\n",
      "QT\n",
      "Reactant Sets:\n",
      "(1, 4)\n",
      "PQR\n",
      "Reactant Sets:\n",
      "(1, 6)\n",
      "(2, 5)\n",
      "(0, 9)\n",
      "PQS\n",
      "Reactant Sets:\n",
      "(3, 5)\n",
      "(1, 7)\n",
      "(0, 10)\n",
      "PQT\n",
      "Reactant Sets:\n",
      "(8, 1)\n",
      "(0, 11)\n",
      "(4, 5)\n",
      "RS\n",
      "Reactant Sets:\n",
      "(2, 3)\n",
      "RT\n",
      "Reactant Sets:\n",
      "(2, 4)\n",
      "PRS\n",
      "Reactant Sets:\n",
      "(0, 15)\n",
      "(2, 7)\n",
      "(3, 6)\n",
      "PRT\n",
      "Reactant Sets:\n",
      "(4, 6)\n",
      "(8, 2)\n",
      "(0, 16)\n",
      "QRS\n",
      "Reactant Sets:\n",
      "(2, 10)\n",
      "(1, 15)\n",
      "(9, 3)\n",
      "QRT\n",
      "Reactant Sets:\n",
      "(9, 4)\n",
      "(2, 11)\n",
      "(16, 1)\n",
      "PQRS\n",
      "Reactant Sets:\n",
      "(3, 12)\n",
      "(1, 17)\n",
      "(9, 7)\n",
      "(0, 19)\n",
      "(2, 13)\n",
      "(5, 15)\n",
      "(10, 6)\n",
      "PQRT\n",
      "Reactant Sets:\n",
      "(0, 20)\n",
      "(1, 18)\n",
      "(8, 9)\n",
      "(11, 6)\n",
      "(16, 5)\n",
      "(2, 14)\n",
      "(4, 12)\n",
      "ST\n",
      "Reactant Sets:\n",
      "(3, 4)\n",
      "PST\n",
      "Reactant Sets:\n",
      "(8, 3)\n",
      "(0, 23)\n",
      "(4, 7)\n",
      "QST\n",
      "Reactant Sets:\n",
      "(11, 3)\n",
      "(1, 23)\n",
      "(10, 4)\n",
      "PQST\n",
      "Reactant Sets:\n",
      "(0, 25)\n",
      "(11, 7)\n",
      "(24, 1)\n",
      "(4, 13)\n",
      "(3, 14)\n",
      "(5, 23)\n",
      "(8, 10)\n",
      "RST\n",
      "Reactant Sets:\n",
      "(4, 15)\n",
      "(16, 3)\n",
      "(2, 23)\n",
      "PRST\n",
      "Reactant Sets:\n",
      "(17, 4)\n",
      "(24, 2)\n",
      "(6, 23)\n",
      "(16, 7)\n",
      "(8, 15)\n",
      "(18, 3)\n",
      "(0, 27)\n",
      "QRST\n",
      "Reactant Sets:\n",
      "(19, 4)\n",
      "(25, 2)\n",
      "(9, 23)\n",
      "(16, 10)\n",
      "(11, 15)\n",
      "(3, 20)\n",
      "(1, 27)\n",
      "PQRST\n",
      "Reactant Sets:\n",
      "(24, 9)\n",
      "(14, 15)\n",
      "(16, 13)\n",
      "(18, 10)\n",
      "(27, 5)\n",
      "(12, 23)\n",
      "(25, 6)\n",
      "(1, 28)\n",
      "(2, 26)\n",
      "(20, 7)\n",
      "(17, 11)\n",
      "(0, 29)\n",
      "(3, 22)\n",
      "(4, 21)\n",
      "(8, 19)\n",
      "tensor([[-1., -1., -1.,  ..., -0., -0.,  1.],\n",
      "        [-1.,  0.,  0.,  ...,  1.,  1., -0.],\n",
      "        [ 0., -1.,  0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., -0.,  1., -0.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -0., -1., -1.]], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "base_input = '../../input_files/pentamer_coup.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 5): 0, (0, 6): 1, (0, 7): 2, (0, 8): 3, (0, 12): 58, (0, 13): 61, (0, 14): 64, (0, 17): 70, (0, 18): 72, (0, 21): 76, (0, 22): 77, (0, 24): 78, (0, 26): 83, (0, 28): 86, (0, 30): 89, (1, 5): 0, (1, 9): 4, (1, 10): 5, (1, 11): 6, (1, 12): 7, (1, 13): 8, (1, 14): 9, (1, 19): 71, (1, 20): 73, (1, 21): 74, (1, 22): 75, (1, 25): 79, (1, 26): 81, (1, 29): 87, (1, 30): 88, (2, 6): 1, (2, 9): 4, (2, 15): 10, (2, 16): 11, (2, 12): 12, (2, 17): 13, (2, 18): 14, (2, 19): 15, (2, 20): 16, (2, 21): 17, (2, 22): 18, (2, 27): 80, (2, 28): 82, (2, 29): 84, (2, 30): 85, (3, 7): 2, (3, 10): 5, (3, 15): 10, (3, 23): 19, (3, 13): 20, (3, 17): 21, (3, 24): 22, (3, 19): 23, (3, 25): 24, (3, 21): 25, (3, 26): 26, (3, 27): 27, (3, 28): 28, (3, 29): 29, (3, 30): 30, (4, 8): 3, (4, 11): 6, (4, 16): 11, (4, 23): 19, (4, 14): 31, (4, 18): 32, (4, 24): 33, (4, 20): 34, (4, 25): 35, (4, 22): 36, (4, 26): 37, (4, 27): 38, (4, 28): 39, (4, 29): 40, (4, 30): 41, (5, 12): 12, (5, 13): 20, (5, 14): 31, (5, 21): 42, (5, 22): 43, (5, 26): 44, (5, 30): 45, (6, 12): 7, (6, 17): 21, (6, 18): 32, (6, 21): 46, (6, 22): 47, (6, 28): 48, (6, 30): 49, (7, 13): 8, (7, 17): 13, (7, 24): 33, (7, 21): 50, (7, 26): 51, (7, 28): 52, (7, 30): 53, (8, 14): 9, (8, 18): 14, (8, 24): 22, (8, 22): 54, (8, 26): 55, (8, 28): 56, (8, 30): 57, (9, 19): 23, (9, 20): 34, (9, 21): 50, (9, 22): 54, (9, 12): 58, (9, 29): 59, (9, 30): 60, (10, 19): 15, (10, 25): 35, (10, 21): 46, (10, 26): 55, (10, 13): 61, (10, 29): 62, (10, 30): 63, (11, 20): 16, (11, 25): 24, (11, 22): 47, (11, 26): 51, (11, 14): 64, (11, 29): 65, (11, 30): 66, (12, 21): 25, (12, 22): 36, (12, 30): 67, (13, 21): 17, (13, 26): 37, (13, 30): 68, (14, 22): 18, (14, 26): 26, (14, 30): 69, (15, 27): 38, (15, 21): 42, (15, 28): 56, (15, 29): 65, (15, 30): 69, (15, 17): 70, (15, 19): 71, (16, 27): 27, (16, 22): 43, (16, 28): 52, (16, 29): 62, (16, 30): 68, (16, 18): 72, (16, 20): 73, (17, 28): 39, (17, 30): 66, (17, 21): 74, (18, 28): 28, (18, 30): 63, (18, 22): 75, (19, 29): 40, (19, 30): 57, (19, 21): 76, (20, 29): 29, (20, 30): 53, (20, 22): 77, (21, 30): 41, (22, 30): 30, (23, 26): 44, (23, 28): 48, (23, 29): 59, (23, 30): 67, (23, 24): 78, (23, 25): 79, (23, 27): 80, (24, 30): 60, (24, 26): 81, (24, 28): 82, (25, 30): 49, (25, 26): 83, (25, 29): 84, (26, 30): 85, (27, 30): 45, (27, 28): 86, (27, 29): 87, (28, 30): 88, (29, 30): 89}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 58}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 61}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 64}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 70}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 72}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 76}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 77}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 78}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 83}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 86}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 89}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 71}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 73}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 74}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 75}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 79}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 81}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 87}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 88}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 80}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 82}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 84}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 85}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 40}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 41}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 42}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 43}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 44}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 45}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 46}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 47}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 48}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 49}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 50}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 51}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 52}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 53}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 54}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 55}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 56}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 57}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 50}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 54}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 58}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 59}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 60}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 46}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 55}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 61}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 62}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 63}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 47}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 51}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 64}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 65}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 66}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 67}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 68}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 69}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 42}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 56}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 65}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 69}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 70}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 71}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 43}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 52}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 62}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 68}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 72}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 73}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 66}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 74}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 63}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 75}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 40}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 57}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 76}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 53}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 77}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 41}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 44}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 48}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 59}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 67}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 78}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 79}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 80}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 60}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 81}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 82}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 49}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 83}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 84}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 85}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 45}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 86}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 87}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 88}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 89}\n",
      "P\n",
      "Reactant Sets:\n",
      "Q\n",
      "Reactant Sets:\n",
      "R\n",
      "Reactant Sets:\n",
      "S\n",
      "Reactant Sets:\n",
      "T\n",
      "Reactant Sets:\n",
      "PQ\n",
      "Reactant Sets:\n",
      "(0, 1)\n",
      "PR\n",
      "Reactant Sets:\n",
      "(0, 2)\n",
      "PS\n",
      "Reactant Sets:\n",
      "(0, 3)\n",
      "PT\n",
      "Reactant Sets:\n",
      "(0, 4)\n",
      "QR\n",
      "Reactant Sets:\n",
      "(1, 2)\n",
      "QS\n",
      "Reactant Sets:\n",
      "(1, 3)\n",
      "QT\n",
      "Reactant Sets:\n",
      "(1, 4)\n",
      "PQR\n",
      "Reactant Sets:\n",
      "(1, 6)\n",
      "(2, 5)\n",
      "(0, 9)\n",
      "PQS\n",
      "Reactant Sets:\n",
      "(3, 5)\n",
      "(1, 7)\n",
      "(0, 10)\n",
      "PQT\n",
      "Reactant Sets:\n",
      "(8, 1)\n",
      "(0, 11)\n",
      "(4, 5)\n",
      "RS\n",
      "Reactant Sets:\n",
      "(2, 3)\n",
      "RT\n",
      "Reactant Sets:\n",
      "(2, 4)\n",
      "PRS\n",
      "Reactant Sets:\n",
      "(0, 15)\n",
      "(2, 7)\n",
      "(3, 6)\n",
      "PRT\n",
      "Reactant Sets:\n",
      "(4, 6)\n",
      "(8, 2)\n",
      "(0, 16)\n",
      "QRS\n",
      "Reactant Sets:\n",
      "(2, 10)\n",
      "(1, 15)\n",
      "(9, 3)\n",
      "QRT\n",
      "Reactant Sets:\n",
      "(9, 4)\n",
      "(2, 11)\n",
      "(16, 1)\n",
      "PQRS\n",
      "Reactant Sets:\n",
      "(3, 12)\n",
      "(1, 17)\n",
      "(9, 7)\n",
      "(0, 19)\n",
      "(2, 13)\n",
      "(5, 15)\n",
      "(10, 6)\n",
      "PQRT\n",
      "Reactant Sets:\n",
      "(0, 20)\n",
      "(1, 18)\n",
      "(8, 9)\n",
      "(11, 6)\n",
      "(16, 5)\n",
      "(2, 14)\n",
      "(4, 12)\n",
      "ST\n",
      "Reactant Sets:\n",
      "(3, 4)\n",
      "PST\n",
      "Reactant Sets:\n",
      "(8, 3)\n",
      "(0, 23)\n",
      "(4, 7)\n",
      "QST\n",
      "Reactant Sets:\n",
      "(11, 3)\n",
      "(1, 23)\n",
      "(10, 4)\n",
      "PQST\n",
      "Reactant Sets:\n",
      "(0, 25)\n",
      "(11, 7)\n",
      "(24, 1)\n",
      "(4, 13)\n",
      "(3, 14)\n",
      "(5, 23)\n",
      "(8, 10)\n",
      "RST\n",
      "Reactant Sets:\n",
      "(4, 15)\n",
      "(16, 3)\n",
      "(2, 23)\n",
      "PRST\n",
      "Reactant Sets:\n",
      "(17, 4)\n",
      "(24, 2)\n",
      "(6, 23)\n",
      "(16, 7)\n",
      "(8, 15)\n",
      "(18, 3)\n",
      "(0, 27)\n",
      "QRST\n",
      "Reactant Sets:\n",
      "(19, 4)\n",
      "(25, 2)\n",
      "(9, 23)\n",
      "(16, 10)\n",
      "(11, 15)\n",
      "(3, 20)\n",
      "(1, 27)\n",
      "PQRST\n",
      "Reactant Sets:\n",
      "(24, 9)\n",
      "(14, 15)\n",
      "(16, 13)\n",
      "(18, 10)\n",
      "(27, 5)\n",
      "(12, 23)\n",
      "(25, 6)\n",
      "(1, 28)\n",
      "(2, 26)\n",
      "(20, 7)\n",
      "(17, 11)\n",
      "(0, 29)\n",
      "(3, 22)\n",
      "(4, 21)\n",
      "(8, 19)\n",
      "tensor([[-1., -1., -1.,  ..., -0., -0.,  1.],\n",
      "        [-1.,  0.,  0.,  ...,  1.,  1., -0.],\n",
      "        [ 0., -1.,  0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., -0.,  1., -0.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -0., -1., -1.]], dtype=torch.float64)\n",
      "tensor([42.0247, 41.7901, 41.0026, 39.9100,  0.9985,  1.0029,  0.9985, 70.4319,\n",
      "        70.4319, 70.4319,  0.9986,  0.9980, 70.4319, 70.4319, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740,  0.9983, 70.4319, 70.4319, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740, 70.4319, 12.7740, 12.7740,  1.0001, 70.4319,\n",
      "        70.4319, 70.4319, 70.4319, 70.4319, 12.7740, 12.7740, 70.4319, 12.7740,\n",
      "        12.7740,  1.0001,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
      "         1.0001,  1.0000,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
      "         1.0001,  1.0000, 70.4319,  1.0001,  1.0000, 70.4319,  1.0001,  1.0000,\n",
      "        70.4319,  1.0001,  1.0000,  1.0000,  1.0000,  1.0000, 70.4319, 70.4319,\n",
      "        70.4319, 70.4319, 12.7740, 12.7740, 12.7740, 12.7740, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740, 12.7740, 12.7740,  1.0001, 12.7740, 12.7740,\n",
      "         1.0001,  1.0001], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "Parameter containing:\n",
      "tensor([42.0247, 41.7901, 41.0026, 39.9100,  0.9985,  1.0029,  0.9985, 70.4319,\n",
      "        70.4319, 70.4319,  0.9986,  0.9980, 70.4319, 70.4319, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740,  0.9983, 70.4319, 70.4319, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740, 70.4319, 12.7740, 12.7740,  1.0001, 70.4319,\n",
      "        70.4319, 70.4319, 70.4319, 70.4319, 12.7740, 12.7740, 70.4319, 12.7740,\n",
      "        12.7740,  1.0001,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
      "         1.0001,  1.0000,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
      "         1.0001,  1.0000, 70.4319,  1.0001,  1.0000, 70.4319,  1.0001,  1.0000,\n",
      "        70.4319,  1.0001,  1.0000,  1.0000,  1.0000,  1.0000, 70.4319, 70.4319,\n",
      "        70.4319, 70.4319, 12.7740, 12.7740, 12.7740, 12.7740, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740, 12.7740, 12.7740,  1.0001, 12.7740, 12.7740,\n",
      "         1.0001,  1.0001], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Do modifications here\n",
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "# new_kon = new_kon + Tensor([1.]*np.array(1e0))\n",
    "new_kon = new_kon + Tensor([42.0247, 41.7901, 41.0026, 39.9100,  0.9985,  1.0029,  0.9985, 70.4319,\n",
    "        70.4319, 70.4319,  0.9986,  0.9980, 70.4319, 70.4319, 70.4319, 70.4319,\n",
    "        70.4319, 12.7740, 12.7740,  0.9983, 70.4319, 70.4319, 70.4319, 70.4319,\n",
    "        70.4319, 12.7740, 12.7740, 70.4319, 12.7740, 12.7740,  1.0001, 70.4319,\n",
    "        70.4319, 70.4319, 70.4319, 70.4319, 12.7740, 12.7740, 70.4319, 12.7740,\n",
    "        12.7740,  1.0001,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
    "         1.0001,  1.0000,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
    "         1.0001,  1.0000, 70.4319,  1.0001,  1.0000, 70.4319,  1.0001,  1.0000,\n",
    "        70.4319,  1.0001,  1.0000,  1.0000,  1.0000,  1.0000, 70.4319, 70.4319,\n",
    "        70.4319, 70.4319, 12.7740, 12.7740, 12.7740, 12.7740, 70.4319, 70.4319,\n",
    "        70.4319, 12.7740, 12.7740, 12.7740, 12.7740,  1.0001, 12.7740, 12.7740,\n",
    "         1.0001,  1.0001])\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)\n",
    "\n",
    "#Changing initial concentrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Equilibrium Solution ##\n",
    "First we will find the equilibrium solution for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vec_rn.update_reaction_net(rn)\n",
    "# poly_system = EquilibriumSolver(rn)\n",
    "# solution = poly_system.solve()\n",
    "# print(solution)\n",
    "# if solution == None:\n",
    "#     print(\"No Equilibrium solution\")\n",
    "# else:\n",
    "#     print(solution)\n",
    "#     print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "# print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uid_dict = {}\n",
    "# sys.path.append(\"../\")\n",
    "# import numpy as np\n",
    "# from reaction_network import gtostr\n",
    "# from torch import DoubleTensor as Tensor\n",
    "\n",
    "# def get_max_edge(n):\n",
    "#     \"\"\"\n",
    "#     Calculates the max rate (k_on) for a given node\n",
    "#     To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "#     Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "#     Can tell which component is used quickly.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         edges = rn.network.out_edges(n)\n",
    "#         #Loop over all edges\n",
    "#         #Get attributes\n",
    "#         if len(edges)==0:\n",
    "#             return(False)\n",
    "#         kon_max = -1\n",
    "#         next_node = -1\n",
    "        \n",
    "#         kon_sum = 0\n",
    "#         for edge in edges:\n",
    "#             data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "#             #print(data)\n",
    "#             #Get uid\n",
    "#             uid = data['uid']\n",
    "#             #Get updated kon\n",
    "#             temp_kon = vec_rn.kon[uid]\n",
    "#             kon_sum+=temp_kon\n",
    "            \n",
    "# #             #Calculate k_off also\n",
    "# #             std_c = Tensor([1.])\n",
    "# #             l_kon = torch.log(temp_kon)\n",
    "# #             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "#             if temp_kon > kon_max:\n",
    "#                 kon_max = temp_kon\n",
    "#                 next_node=edge[1]\n",
    "#         return(kon_max,next_node,kon_sum)\n",
    "#     except Exception as err:\n",
    "#         raise(err)\n",
    "\n",
    "# pathway = []\n",
    "# kon_sumarray = []\n",
    "# total_con_rate = {}\n",
    "# for n in rn.network.nodes():\n",
    "    \n",
    "#     n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "#     paths = [n_str]\n",
    "#     kon_sum = 0\n",
    "#     temp_node = n\n",
    "#     max_edge = True\n",
    "#     consumption_rate = 0\n",
    "#     if n < len(rn.network.nodes()):#num_monomers:\n",
    "# #         print(\"Current node: \")\n",
    "# #         print(n_str)\n",
    "#         while max_edge:\n",
    "#             max_edge = get_max_edge(temp_node)\n",
    "#             if max_edge:\n",
    "#                 total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "#                 temp_node = max_edge[1]\n",
    "#                 kon_sum += max_edge[0].item()\n",
    "                \n",
    "# #                 print(\"Next node: \")\n",
    "# #                 print(temp_node)\n",
    "\n",
    "#                 paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "#             else:\n",
    "#                 break\n",
    "#         pathway.append(paths)\n",
    "#         kon_sumarray.append(kon_sum)\n",
    "#         paths=[]\n",
    "\n",
    "# print(pathway)\n",
    "# print(kon_sumarray)\n",
    "# #print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if solution != None:\n",
    "#     for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "#         print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if solution !=None:\n",
    "#     for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "#         print(k,\" : \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer with a 1 second simulation runtime ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([42.0247, 41.7901, 41.0026, 39.9100,  0.9985,  1.0029,  0.9985, 70.4319,\n",
      "        70.4319, 70.4319,  0.9986,  0.9980, 70.4319, 70.4319, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740,  0.9983, 70.4319, 70.4319, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740, 70.4319, 12.7740, 12.7740,  1.0001, 70.4319,\n",
      "        70.4319, 70.4319, 70.4319, 70.4319, 12.7740, 12.7740, 70.4319, 12.7740,\n",
      "        12.7740,  1.0001,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
      "         1.0001,  1.0000,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
      "         1.0001,  1.0000, 70.4319,  1.0001,  1.0000, 70.4319,  1.0001,  1.0000,\n",
      "        70.4319,  1.0001,  1.0000,  1.0000,  1.0000,  1.0000, 70.4319, 70.4319,\n",
      "        70.4319, 70.4319, 12.7740, 12.7740, 12.7740, 12.7740, 70.4319, 70.4319,\n",
      "        70.4319, 12.7740, 12.7740, 12.7740, 12.7740,  1.0001, 12.7740, 12.7740,\n",
      "         1.0001,  1.0001], dtype=torch.float64, requires_grad=True)]\n",
      "Using CPU\n",
      "Next time:  tensor(1.1128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 0 was 96.2%\n",
      "tensor([4.6320e-07, 3.3881e-21, 1.0483e-06, 4.3376e-07, 1.6922e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5769e-06, 2.7179e-06, 3.7522e-06,\n",
      "        1.0309e-05, 1.0190e-05, 1.1155e-05, 3.6764e-06, 3.8595e-06, 1.0244e-05,\n",
      "        1.1112e-05, 2.2002e-01, 2.2254e-01, 9.3513e-01, 9.3248e-01, 3.8873e-06,\n",
      "        1.1831e-05, 2.2655e-01, 9.2844e-01, 2.2668e-01, 9.2827e-01, 2.5937e-01,\n",
      "        9.6276e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([46.2262, 45.9913, 45.2036, 44.1106,  5.2010,  5.2054,  5.2010, 74.6333,\n",
      "        74.6333, 74.6333,  5.2011,  5.2005, 74.6333, 74.6333, 74.6333, 74.6333,\n",
      "        74.6333, 12.8693, 12.8693,  5.2008, 74.6333, 74.6333, 74.6333, 74.6333,\n",
      "        74.6333, 12.8693, 12.8693, 74.6333, 12.8693, 12.8693,  5.2026, 74.6333,\n",
      "        74.6333, 74.6333, 74.6333, 74.6333, 12.8693, 12.8693, 74.6333, 12.8693,\n",
      "        12.8693,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 74.6333,  5.2026,  5.2025, 74.6333,  5.2026,  5.2025,\n",
      "        74.6333,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 74.6333, 74.6333,\n",
      "        74.6333, 74.6333, 12.8693, 12.8693, 12.8693, 12.8693, 74.6333, 74.6333,\n",
      "        74.6333, 12.8693, 12.8693, 12.8693, 12.8693,  5.2026, 12.8693, 12.8693,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1 was 76.4%\n",
      "tensor([5.4018e-05, 1.2450e-05, 1.1433e-05, 1.1824e-05, 1.1948e-05, 0.0000e+00,\n",
      "        4.5784e-07, 8.5180e-07, 9.5993e-07, 1.8670e-05, 1.8814e-05, 1.9060e-05,\n",
      "        5.9900e-02, 6.0429e-02, 6.1886e-02, 1.8875e-05, 1.9093e-05, 6.0643e-02,\n",
      "        6.1999e-02, 1.3805e+00, 1.4015e+00, 5.8203e+00, 5.7966e+00, 1.9249e-05,\n",
      "        6.3026e-02, 1.4215e+00, 5.7750e+00, 1.4277e+00, 5.7684e+00, 1.7506e+00,\n",
      "        7.6472e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([50.2836, 50.0676, 49.2448, 48.1556,  5.1993,  5.1997,  5.1982, 77.6117,\n",
      "        77.6117, 77.6117,  5.1970,  5.1996, 77.6117, 77.6117, 77.6117, 77.6117,\n",
      "        77.6117, 12.9637, 12.9637,  5.1984, 77.6117, 77.6117, 77.6117, 77.6117,\n",
      "        77.6117, 12.9637, 12.9637, 77.6117, 12.9637, 12.9637,  5.2026, 77.6117,\n",
      "        77.6117, 77.6117, 77.6117, 77.6117, 12.9637, 12.9637, 77.6117, 12.9637,\n",
      "        12.9637,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 77.6117,  5.2026,  5.2025, 77.6117,  5.2026,  5.2025,\n",
      "        77.6117,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 77.6117, 77.6117,\n",
      "        77.6117, 77.6117, 12.9637, 12.9637, 12.9637, 12.9637, 77.6117, 77.6117,\n",
      "        77.6117, 12.9637, 12.9637, 12.9637, 12.9637,  5.2026, 12.9637, 12.9637,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(8.2162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2 was 78.2%\n",
      "tensor([1.0982e-18, 9.6652e-03, 9.6719e-03, 9.7048e-03, 9.7560e-03, 1.5773e-06,\n",
      "        1.5623e-06, 1.5577e-06, 1.6830e-06, 4.7197e-03, 4.7513e-03, 4.7971e-03,\n",
      "        3.9543e-02, 3.9926e-02, 4.0911e-02, 4.7597e-03, 4.8037e-03, 4.0037e-02,\n",
      "        4.0986e-02, 1.2673e+00, 1.2858e+00, 5.3967e+00, 5.3761e+00, 4.8310e-03,\n",
      "        4.1724e-02, 1.3022e+00, 5.3584e+00, 1.3078e+00, 5.3526e+00, 1.5964e+00,\n",
      "        7.8273e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([53.0465, 52.8113, 52.0648, 50.9582,  5.1962,  5.1941,  5.1973, 80.0499,\n",
      "        80.0499, 80.0499,  5.1960,  5.1953, 80.0499, 80.0499, 80.0499, 80.0499,\n",
      "        80.0499, 13.0574, 13.0574,  5.1959, 80.0499, 80.0499, 80.0499, 80.0499,\n",
      "        80.0499, 13.0574, 13.0574, 80.0499, 13.0574, 13.0574,  5.2026, 80.0499,\n",
      "        80.0499, 80.0499, 80.0499, 80.0499, 13.0574, 13.0574, 80.0499, 13.0574,\n",
      "        13.0574,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 80.0499,  5.2026,  5.2025, 80.0499,  5.2026,  5.2025,\n",
      "        80.0499,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 80.0499, 80.0499,\n",
      "        80.0499, 80.0499, 13.0574, 13.0574, 13.0574, 13.0574, 80.0499, 80.0499,\n",
      "        80.0499, 13.0574, 13.0574, 13.0574, 13.0574,  5.2026, 13.0574, 13.0574,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(166.9224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3 was 79.4%\n",
      "tensor([4.1226e-04, 1.8003e-01, 1.8015e-01, 1.8072e-01, 1.8173e-01, 1.2980e-05,\n",
      "        1.2922e-05, 1.2662e-05, 1.2430e-05, 9.0606e-02, 9.1137e-02, 9.1954e-02,\n",
      "        0.0000e+00, 1.5312e-04, 3.8904e-04, 9.1275e-02, 9.2120e-02, 2.5014e-04,\n",
      "        4.8928e-04, 1.0536e+00, 1.0688e+00, 5.1592e+00, 5.1408e+00, 9.2572e-02,\n",
      "        8.1632e-04, 1.0806e+00, 5.1269e+00, 1.0855e+00, 5.1214e+00, 1.4671e+00,\n",
      "        7.9449e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([55.1464, 54.9182, 54.2172, 53.0877,  5.1925,  5.1932,  5.1922, 82.1666,\n",
      "        82.1666, 82.1666,  5.1929,  5.1944, 82.1666, 82.1666, 82.1666, 82.1666,\n",
      "        82.1666, 13.1506, 13.1506,  5.1934, 82.1666, 82.1666, 82.1666, 82.1666,\n",
      "        82.1666, 13.1506, 13.1506, 82.1666, 13.1506, 13.1506,  5.2026, 82.1666,\n",
      "        82.1666, 82.1666, 82.1666, 82.1666, 13.1506, 13.1506, 82.1666, 13.1506,\n",
      "        13.1506,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 82.1666,  5.2026,  5.2025, 82.1666,  5.2026,  5.2025,\n",
      "        82.1666,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 82.1666, 82.1666,\n",
      "        82.1666, 82.1666, 13.1506, 13.1506, 13.1506, 13.1506, 82.1666, 82.1666,\n",
      "        82.1666, 13.1506, 13.1506, 13.1506, 13.1506,  5.2026, 13.1506, 13.1506,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(160.5692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4 was 80.2%\n",
      "tensor([1.5821e-04, 1.6085e-01, 1.6101e-01, 1.6148e-01, 1.6239e-01, 1.9328e-05,\n",
      "        1.9534e-05, 1.9697e-05, 1.8670e-05, 8.2748e-02, 8.3166e-02, 8.3915e-02,\n",
      "        0.0000e+00, 1.1452e-04, 3.0646e-04, 8.3329e-02, 8.4046e-02, 1.8961e-04,\n",
      "        3.8366e-04, 1.0230e+00, 1.0374e+00, 4.9617e+00, 4.9445e+00, 8.4445e-02,\n",
      "        6.2852e-04, 1.0476e+00, 4.9326e+00, 1.0524e+00, 4.9272e+00, 1.4104e+00,\n",
      "        8.0232e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([56.9408, 56.7218, 56.0499, 54.9017,  5.1909,  5.1902,  5.1913, 84.0647,\n",
      "        84.0647, 84.0647,  5.1913,  5.1894, 84.0647, 84.0647, 84.0647, 84.0647,\n",
      "        84.0647, 13.2433, 13.2433,  5.1895, 84.0647, 84.0647, 84.0647, 84.0647,\n",
      "        84.0647, 13.2433, 13.2433, 84.0647, 13.2433, 13.2433,  5.2026, 84.0647,\n",
      "        84.0647, 84.0647, 84.0647, 84.0647, 13.2433, 13.2433, 84.0647, 13.2433,\n",
      "        13.2433,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 84.0647,  5.2026,  5.2025, 84.0647,  5.2026,  5.2025,\n",
      "        84.0647,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 84.0647, 84.0647,\n",
      "        84.0647, 84.0647, 13.2433, 13.2433, 13.2433, 13.2433, 84.0647, 84.0647,\n",
      "        84.0647, 13.2433, 13.2433, 13.2433, 13.2433,  5.2026, 13.2433, 13.2433,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(155.5117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 5 was 80.8%\n",
      "tensor([0.0000e+00, 1.4666e-01, 1.4678e-01, 1.4719e-01, 1.4801e-01, 5.1156e-05,\n",
      "        5.0343e-05, 4.7859e-05, 4.4202e-05, 7.6796e-02, 7.7166e-02, 7.7810e-02,\n",
      "        3.4694e-18, 9.0706e-05, 2.5174e-04, 7.7267e-02, 7.7942e-02, 1.5012e-04,\n",
      "        3.1317e-04, 9.9756e-01, 1.0110e+00, 4.8018e+00, 4.7858e+00, 7.8279e-02,\n",
      "        5.0687e-04, 1.0203e+00, 4.7751e+00, 1.0243e+00, 4.7706e+00, 1.3645e+00,\n",
      "        8.0866e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([58.5264, 58.3173, 57.6665, 56.5019,  5.1882,  5.1886,  5.1875, 85.8017,\n",
      "        85.8017, 85.8017,  5.1864,  5.1886, 85.8017, 85.8017, 85.8017, 85.8017,\n",
      "        85.8017, 13.3356, 13.3356,  5.1876, 85.8017, 85.8017, 85.8017, 85.8017,\n",
      "        85.8017, 13.3356, 13.3356, 85.8017, 13.3356, 13.3356,  5.2026, 85.8017,\n",
      "        85.8017, 85.8017, 85.8017, 85.8017, 13.3356, 13.3356, 85.8017, 13.3356,\n",
      "        13.3356,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 85.8017,  5.2026,  5.2025, 85.8017,  5.2026,  5.2025,\n",
      "        85.8017,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 85.8017, 85.8017,\n",
      "        85.8017, 85.8017, 13.3356, 13.3356, 13.3356, 13.3356, 85.8017, 85.8017,\n",
      "        85.8017, 13.3356, 13.3356, 13.3356, 13.3356,  5.2026, 13.3356, 13.3356,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(151.3019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 6 was 81.4%\n",
      "tensor([0.0000e+00, 1.3551e-01, 1.3561e-01, 1.3599e-01, 1.3676e-01, 6.9897e-05,\n",
      "        6.8208e-05, 6.2996e-05, 5.6529e-05, 7.2017e-02, 7.2332e-02, 7.2951e-02,\n",
      "        0.0000e+00, 7.4357e-05, 2.1274e-04, 7.2449e-02, 7.3043e-02, 1.2241e-04,\n",
      "        2.6219e-04, 9.7521e-01, 9.8822e-01, 4.6672e+00, 4.6519e+00, 7.3357e-02,\n",
      "        4.2109e-04, 9.9675e-01, 4.6420e+00, 1.0004e+00, 4.6380e+00, 1.3257e+00,\n",
      "        8.1400e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([59.9576, 59.7590, 59.1247, 57.9455,  5.1854,  5.1838,  5.1867, 87.4139,\n",
      "        87.4139, 87.4139,  5.1855,  5.1849, 87.4139, 87.4139, 87.4139, 87.4139,\n",
      "        87.4139, 13.4275, 13.4275,  5.1851, 87.4139, 87.4139, 87.4139, 87.4139,\n",
      "        87.4139, 13.4275, 13.4275, 87.4139, 13.4275, 13.4275,  5.2026, 87.4139,\n",
      "        87.4139, 87.4139, 87.4139, 87.4139, 13.4275, 13.4275, 87.4139, 13.4275,\n",
      "        13.4275,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 87.4139,  5.2026,  5.2025, 87.4139,  5.2026,  5.2025,\n",
      "        87.4139,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 87.4139, 87.4139,\n",
      "        87.4139, 87.4139, 13.4275, 13.4275, 13.4275, 13.4275, 87.4139, 87.4139,\n",
      "        87.4139, 13.4275, 13.4275, 13.4275, 13.4275,  5.2026, 13.4275, 13.4275,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(149.1973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 7 was 81.8%\n",
      "tensor([1.2942e-04, 1.2780e-01, 1.2788e-01, 1.2822e-01, 1.2896e-01, 6.1353e-06,\n",
      "        5.6037e-06, 4.0294e-06, 3.2002e-06, 6.8757e-02, 6.9050e-02, 6.9611e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9128e-02, 6.9716e-02, 0.0000e+00,\n",
      "        4.0668e-05, 9.5435e-01, 9.6710e-01, 4.5506e+00, 4.5357e+00, 6.9991e-02,\n",
      "        1.7283e-04, 9.7497e-01, 4.5267e+00, 9.7813e-01, 4.5231e+00, 1.2922e+00,\n",
      "        8.1864e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([61.2684, 61.0835, 60.4606, 59.2645,  5.1827,  5.1829,  5.1819, 88.9257,\n",
      "        88.9257, 88.9257,  5.1819,  5.1840, 88.9257, 88.9257, 88.9257, 88.9257,\n",
      "        88.9257, 13.5191, 13.5191,  5.1825, 88.9257, 88.9257, 88.9257, 88.9257,\n",
      "        88.9257, 13.5191, 13.5191, 88.9257, 13.5191, 13.5191,  5.2026, 88.9257,\n",
      "        88.9257, 88.9257, 88.9257, 88.9257, 13.5191, 13.5191, 88.9257, 13.5191,\n",
      "        13.5191,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 88.9257,  5.2026,  5.2025, 88.9257,  5.2026,  5.2025,\n",
      "        88.9257,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 88.9257, 88.9257,\n",
      "        88.9257, 88.9257, 13.5191, 13.5191, 13.5191, 13.5191, 88.9257, 88.9257,\n",
      "        88.9257, 13.5191, 13.5191, 13.5191, 13.5191,  5.2026, 13.5191, 13.5191,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(145.9792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 8 was 82.2%\n",
      "tensor([2.9663e-03, 1.2030e-01, 1.2040e-01, 1.2068e-01, 1.2135e-01, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5348e-02, 6.5597e-02, 6.6146e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9389e-18, 6.5701e-02, 6.6223e-02, 0.0000e+00,\n",
      "        3.3110e-05, 9.3706e-01, 9.4940e-01, 4.4469e+00, 4.4325e+00, 6.6485e-02,\n",
      "        1.4648e-04, 9.5668e-01, 4.4242e+00, 9.5980e-01, 4.4207e+00, 1.2631e+00,\n",
      "        8.2274e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([62.4823, 62.3108, 61.6985, 60.4886,  5.1800,  5.1794,  5.1811, 90.3546,\n",
      "        90.3546, 90.3546,  5.1810,  5.1793, 90.3546, 90.3546, 90.3546, 90.3546,\n",
      "        90.3546, 13.6103, 13.6103,  5.1799, 90.3546, 90.3546, 90.3546, 90.3546,\n",
      "        90.3546, 13.6103, 13.6103, 90.3546, 13.6103, 13.6103,  5.2026, 90.3546,\n",
      "        90.3546, 90.3546, 90.3546, 90.3546, 13.6103, 13.6103, 90.3546, 13.6103,\n",
      "        13.6103,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 90.3546,  5.2026,  5.2025, 90.3546,  5.2026,  5.2025,\n",
      "        90.3546,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 90.3546, 90.3546,\n",
      "        90.3546, 90.3546, 13.6103, 13.6103, 13.6103, 13.6103, 90.3546, 90.3546,\n",
      "        90.3546, 13.6103, 13.6103, 13.6103, 13.6103,  5.2026, 13.6103, 13.6103,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(143.1205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 9 was 82.6%\n",
      "tensor([8.0535e-03, 1.1414e-01, 1.1420e-01, 1.1444e-01, 1.1501e-01, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2402e-02, 6.2649e-02, 6.3133e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2708e-02, 6.3221e-02, 0.0000e+00,\n",
      "        2.7118e-05, 9.2173e-01, 9.3354e-01, 4.3535e+00, 4.3398e+00, 6.3457e-02,\n",
      "        1.2554e-04, 9.4061e-01, 4.3317e+00, 9.4322e-01, 4.3288e+00, 1.2374e+00,\n",
      "        8.2641e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([63.6161, 63.4579, 62.8560, 61.6349,  5.1774,  5.1785,  5.1764, 91.7136,\n",
      "        91.7136, 91.7136,  5.1775,  5.1784, 91.7136, 91.7136, 91.7136, 91.7136,\n",
      "        91.7136, 13.7013, 13.7013,  5.1774, 91.7136, 91.7136, 91.7136, 91.7136,\n",
      "        91.7136, 13.7013, 13.7013, 91.7136, 13.7013, 13.7013,  5.2026, 91.7136,\n",
      "        91.7136, 91.7136, 91.7136, 91.7136, 13.7013, 13.7013, 91.7136, 13.7013,\n",
      "        13.7013,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 91.7136,  5.2026,  5.2025, 91.7136,  5.2026,  5.2025,\n",
      "        91.7136,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 91.7136, 91.7136,\n",
      "        91.7136, 91.7136, 13.7013, 13.7013, 13.7013, 13.7013, 91.7136, 91.7136,\n",
      "        91.7136, 13.7013, 13.7013, 13.7013, 13.7013,  5.2026, 13.7013, 13.7013,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(140.5489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 10 was 82.9%\n",
      "tensor([1.4606e-02, 1.0897e-01, 1.0902e-01, 1.0920e-01, 1.0967e-01, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9815e-02, 6.0030e-02, 6.0511e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.4694e-18, 6.0109e-02, 6.0563e-02, 0.0000e+00,\n",
      "        2.2304e-05, 9.0781e-01, 9.1924e-01, 4.2686e+00, 4.2553e+00, 6.0798e-02,\n",
      "        1.0854e-04, 9.2596e-01, 4.2477e+00, 9.2832e-01, 4.2451e+00, 1.2145e+00,\n",
      "        8.2973e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([64.6834, 64.5382, 63.9461, 62.7158,  5.1759,  5.1739,  5.1755, 93.0125,\n",
      "        93.0125, 93.0125,  5.1748,  5.1749, 93.0125, 93.0125, 93.0125, 93.0125,\n",
      "        93.0125, 13.7920, 13.7920,  5.1755, 93.0125, 93.0125, 93.0125, 93.0125,\n",
      "        93.0125, 13.7920, 13.7920, 93.0125, 13.7920, 13.7920,  5.2026, 93.0125,\n",
      "        93.0125, 93.0125, 93.0125, 93.0125, 13.7920, 13.7920, 93.0125, 13.7920,\n",
      "        13.7920,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 93.0125,  5.2026,  5.2025, 93.0125,  5.2026,  5.2025,\n",
      "        93.0125,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 93.0125, 93.0125,\n",
      "        93.0125, 93.0125, 13.7920, 13.7920, 13.7920, 13.7920, 93.0125, 93.0125,\n",
      "        93.0125, 13.7920, 13.7920, 13.7920, 13.7920,  5.2026, 13.7920, 13.7920,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(138.2113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 11 was 83.2%\n",
      "tensor([2.0083e-02, 1.0445e-01, 1.0448e-01, 1.0461e-01, 1.0499e-01, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7509e-02, 5.7723e-02, 5.8170e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.4694e-18, 5.7777e-02, 5.8227e-02, 0.0000e+00,\n",
      "        1.8400e-05, 8.9474e-01, 9.0604e-01, 4.1909e+00, 4.1778e+00, 5.8423e-02,\n",
      "        9.4540e-05, 9.1230e-01, 4.1707e+00, 9.1434e-01, 4.1685e+00, 1.1933e+00,\n",
      "        8.3279e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([65.6963, 65.5628, 64.9796, 63.7407,  5.1713,  5.1730,  5.1722, 94.2591,\n",
      "        94.2591, 94.2591,  5.1734,  5.1735, 94.2591, 94.2591, 94.2591, 94.2591,\n",
      "        94.2591, 13.8824, 13.8824,  5.1722, 94.2591, 94.2591, 94.2591, 94.2591,\n",
      "        94.2591, 13.8824, 13.8824, 94.2591, 13.8824, 13.8824,  5.2026, 94.2591,\n",
      "        94.2591, 94.2591, 94.2591, 94.2591, 13.8824, 13.8824, 94.2591, 13.8824,\n",
      "        13.8824,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 94.2591,  5.2026,  5.2025, 94.2591,  5.2026,  5.2025,\n",
      "        94.2591,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 94.2591, 94.2591,\n",
      "        94.2591, 94.2591, 13.8824, 13.8824, 13.8824, 13.8824, 94.2591, 94.2591,\n",
      "        94.2591, 13.8824, 13.8824, 13.8824, 13.8824,  5.2026, 13.8824, 13.8824,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(137.0711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 12 was 83.5%\n",
      "tensor([1.9527e-02, 1.0075e-01, 1.0080e-01, 1.0092e-01, 1.0125e-01, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5858e-02, 5.6048e-02, 5.6477e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6108e-02, 5.6526e-02, 0.0000e+00,\n",
      "        0.0000e+00, 8.8123e-01, 8.9207e-01, 4.1199e+00, 4.1075e+00, 5.6727e-02,\n",
      "        0.0000e+00, 8.9812e-01, 4.1006e+00, 9.0013e-01, 4.0984e+00, 1.1728e+00,\n",
      "        8.3561e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([66.6684, 66.5424, 65.9625, 64.7167,  5.1705,  5.1703,  5.1707, 95.4598,\n",
      "        95.4598, 95.4598,  5.1701,  5.1689, 95.4598, 95.4598, 95.4598, 95.4598,\n",
      "        95.4598, 13.9725, 13.9725,  5.1702, 95.4598, 95.4598, 95.4598, 95.4598,\n",
      "        95.4598, 13.9725, 13.9725, 95.4598, 13.9725, 13.9725,  5.2026, 95.4598,\n",
      "        95.4598, 95.4598, 95.4598, 95.4598, 13.9725, 13.9725, 95.4598, 13.9725,\n",
      "        13.9725,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 95.4598,  5.2026,  5.2025, 95.4598,  5.2026,  5.2025,\n",
      "        95.4598,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 95.4598, 95.4598,\n",
      "        95.4598, 95.4598, 13.9725, 13.9725, 13.9725, 13.9725, 95.4598, 95.4598,\n",
      "        95.4598, 13.9725, 13.9725, 13.9725, 13.9725,  5.2026, 13.9725, 13.9725,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(135.0357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 13 was 83.8%\n",
      "tensor([3.7270e-03, 9.5508e-02, 9.5539e-02, 9.5738e-02, 9.6219e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3946e-02, 5.4136e-02, 5.4538e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4173e-02, 5.4580e-02, 0.0000e+00,\n",
      "        0.0000e+00, 8.6722e-01, 8.7787e-01, 4.0557e+00, 4.0435e+00, 5.4764e-02,\n",
      "        5.2042e-18, 8.8377e-01, 4.0369e+00, 8.8529e-01, 4.0352e+00, 1.1511e+00,\n",
      "        8.3827e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([67.6108, 67.4875, 66.9068, 65.6492,  5.1672,  5.1681,  5.1662, 96.6197,\n",
      "        96.6197, 96.6197,  5.1686,  5.1680, 96.6197, 96.6197, 96.6197, 96.6197,\n",
      "        96.6197, 14.0624, 14.0624,  5.1676, 96.6197, 96.6197, 96.6197, 96.6197,\n",
      "        96.6197, 14.0624, 14.0624, 96.6197, 14.0624, 14.0624,  5.2026, 96.6197,\n",
      "        96.6197, 96.6197, 96.6197, 96.6197, 14.0624, 14.0624, 96.6197, 14.0624,\n",
      "        14.0624,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 96.6197,  5.2026,  5.2025, 96.6197,  5.2026,  5.2025,\n",
      "        96.6197,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 96.6197, 96.6197,\n",
      "        96.6197, 96.6197, 14.0624, 14.0624, 14.0624, 14.0624, 96.6197, 96.6197,\n",
      "        96.6197, 14.0624, 14.0624, 14.0624, 14.0624,  5.2026, 14.0624, 14.0624,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 14 was 84.0%\n",
      "tensor([2.3465e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0164e-20, 6.1516e-08,\n",
      "        6.2371e-08, 6.6993e-08, 7.7588e-08, 2.8599e-06, 2.8696e-06, 2.8906e-06,\n",
      "        9.1292e-03, 9.1734e-03, 9.4435e-03, 2.8722e-06, 2.8931e-06, 9.1842e-03,\n",
      "        9.4527e-03, 9.3911e-01, 9.5025e-01, 3.9825e+00, 3.9707e+00, 2.9032e-06,\n",
      "        9.5800e-03, 9.5655e-01, 3.9642e+00, 9.5847e-01, 3.9623e+00, 1.1447e+00,\n",
      "        8.4065e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([64.5609, 65.1132, 65.6625, 66.2003,  5.1778,  5.1711,  5.1799, 97.7430,\n",
      "        97.7430, 97.7430,  5.1667,  5.1722, 97.7430, 97.7430, 97.7430, 97.7430,\n",
      "        97.7430, 14.1521, 14.1521,  5.1784, 97.7430, 97.7430, 97.7430, 97.7430,\n",
      "        97.7430, 14.1521, 14.1521, 97.7430, 14.1521, 14.1521,  5.2026, 97.7430,\n",
      "        97.7430, 97.7430, 97.7430, 97.7430, 14.1521, 14.1521, 97.7430, 14.1521,\n",
      "        14.1521,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 97.7430,  5.2026,  5.2025, 97.7430,  5.2026,  5.2025,\n",
      "        97.7430,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 97.7430, 97.7430,\n",
      "        97.7430, 97.7430, 14.1521, 14.1521, 14.1521, 14.1521, 97.7430, 97.7430,\n",
      "        97.7430, 14.1521, 14.1521, 14.1521, 14.1521,  5.2026, 14.1521, 14.1521,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 15 was 83.6%\n",
      "tensor([9.8951e-05, 4.4792e-05, 8.0828e-05, 2.3737e-04, 7.2791e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7763e-20, 3.5850e-05, 0.0000e+00,\n",
      "        1.0859e-02, 1.0741e-02, 1.0692e-02, 5.7002e-05, 6.3648e-08, 1.0596e-02,\n",
      "        1.0560e-02, 9.8600e-01, 9.7947e-01, 4.0650e+00, 4.0720e+00, 0.0000e+00,\n",
      "        1.0490e-02, 9.7327e-01, 4.0782e+00, 9.6684e-01, 4.0848e+00, 1.1776e+00,\n",
      "        8.3636e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([64.9146, 65.7395, 66.7452, 67.9106,  5.1781,  5.1696,  5.1755, 98.8334,\n",
      "        98.8334, 98.8334,  5.1622,  5.1707, 98.8334, 98.8334, 98.8334, 98.8334,\n",
      "        98.8334, 14.2416, 14.2416,  5.1748, 98.8334, 98.8334, 98.8334, 98.8334,\n",
      "        98.8334, 14.2416, 14.2416, 98.8334, 14.2416, 14.2416,  5.2026, 98.8334,\n",
      "        98.8334, 98.8334, 98.8334, 98.8334, 14.2416, 14.2416, 98.8334, 14.2416,\n",
      "        14.2416,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 98.8334,  5.2026,  5.2025, 98.8334,  5.2026,  5.2025,\n",
      "        98.8334,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 98.8334, 98.8334,\n",
      "        98.8334, 98.8334, 14.2416, 14.2416, 14.2416, 14.2416, 98.8334, 98.8334,\n",
      "        98.8334, 14.2416, 14.2416, 14.2416, 14.2416,  5.2026, 14.2416, 14.2416,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 16 was 83.9%\n",
      "tensor([0.0000e+00, 6.9824e-06, 6.8305e-06, 6.6006e-06, 6.2635e-06, 1.8859e-07,\n",
      "        2.0685e-07, 2.5669e-07, 3.6447e-07, 1.2475e-05, 1.2392e-05, 1.2316e-05,\n",
      "        1.0030e-02, 9.8215e-03, 9.7354e-03, 1.2307e-05, 1.2256e-05, 9.6335e-03,\n",
      "        9.5452e-03, 9.7928e-01, 9.6376e-01, 3.9850e+00, 4.0008e+00, 1.2156e-05,\n",
      "        9.4433e-03, 9.5212e-01, 4.0128e+00, 9.4361e-01, 4.0217e+00, 1.1551e+00,\n",
      "        8.3922e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([65.2540, 66.3438, 67.7893, 69.4532,  5.1751,  5.1685,  5.1723, 99.8937,\n",
      "        99.8937, 99.8937,  5.1589,  5.1692, 99.8937, 99.8937, 99.8937, 99.8937,\n",
      "        99.8937, 14.3309, 14.3309,  5.1719, 99.8937, 99.8937, 99.8937, 99.8937,\n",
      "        99.8937, 14.3309, 14.3309, 99.8937, 14.3309, 14.3309,  5.2026, 99.8937,\n",
      "        99.8937, 99.8937, 99.8937, 99.8937, 14.3309, 14.3309, 99.8937, 14.3309,\n",
      "        14.3309,  5.2026,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025,  5.2026,  5.2026,  5.2026,  5.2025,  5.2026,  5.2026,\n",
      "         5.2026,  5.2025, 99.8937,  5.2026,  5.2025, 99.8937,  5.2026,  5.2025,\n",
      "        99.8937,  5.2026,  5.2025,  5.2025,  5.2025,  5.2025, 99.8937, 99.8937,\n",
      "        99.8937, 99.8937, 14.3309, 14.3309, 14.3309, 14.3309, 99.8937, 99.8937,\n",
      "        99.8937, 14.3309, 14.3309, 14.3309, 14.3309,  5.2026, 14.3309, 14.3309,\n",
      "         5.2026,  5.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 17 was 84.1%\n",
      "tensor([2.5196e-06, 6.8560e-06, 1.6127e-06, 0.0000e+00, 5.1934e-06, 6.5646e-08,\n",
      "        5.4212e-08, 4.1608e-08, 3.2004e-08, 1.4566e-05, 1.2157e-05, 1.4309e-05,\n",
      "        9.3178e-03, 9.0285e-03, 8.9186e-03, 3.0639e-06, 1.4211e-05, 8.8020e-03,\n",
      "        8.6845e-03, 9.7157e-01, 9.4955e-01, 3.9134e+00, 3.9359e+00, 1.4084e-05,\n",
      "        8.5644e-03, 9.3361e-01, 3.9523e+00, 9.2305e-01, 3.9633e+00, 1.1346e+00,\n",
      "        8.4182e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 65.4799,  67.0013,  68.9167,  70.8405,   5.1628,   5.1585,   5.1682,\n",
      "        100.9267, 100.9267, 100.9267,   5.1737,   5.1680, 100.9267, 100.9267,\n",
      "        100.9267, 100.9267, 100.9267,  14.4200,  14.4200,   5.1697, 100.9267,\n",
      "        100.9267, 100.9267, 100.9267, 100.9267,  14.4200,  14.4200, 100.9267,\n",
      "         14.4200,  14.4200,   5.2026, 100.9267, 100.9267, 100.9267, 100.9267,\n",
      "        100.9267,  14.4200,  14.4200, 100.9267,  14.4200,  14.4200,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 100.9267,   5.2026,   5.2025, 100.9267,   5.2026,\n",
      "          5.2025, 100.9267,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        100.9267, 100.9267, 100.9267, 100.9267,  14.4200,  14.4200,  14.4200,\n",
      "         14.4200, 100.9267, 100.9267, 100.9267,  14.4200,  14.4200,  14.4200,\n",
      "         14.4200,   5.2026,  14.4200,  14.4200,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 18 was 84.4%\n",
      "tensor([1.3442e-06, 6.9201e-06, 6.7466e-06, 6.5428e-06, 6.5904e-06, 1.4079e-07,\n",
      "        1.3357e-07, 1.2617e-07, 0.0000e+00, 1.2181e-05, 1.2054e-05, 1.1868e-05,\n",
      "        8.7145e-03, 8.3420e-03, 8.1982e-03, 1.1903e-05, 1.1770e-05, 8.0355e-03,\n",
      "        7.9338e-03, 9.6251e-01, 9.3656e-01, 3.8482e+00, 3.8746e+00, 1.1627e-05,\n",
      "        7.7992e-03, 9.1690e-01, 3.8948e+00, 9.0489e-01, 3.9077e+00, 1.1157e+00,\n",
      "        8.4426e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 65.7960,  67.5750,  69.8771,  72.1526,   5.1608,   5.1577,   5.1654,\n",
      "        101.9346, 101.9346, 101.9346,   5.1692,   5.1665, 101.9346, 101.9346,\n",
      "        101.9346, 101.9346, 101.9346,  14.5088,  14.5088,   5.1664, 101.9346,\n",
      "        101.9346, 101.9346, 101.9346, 101.9346,  14.5088,  14.5088, 101.9346,\n",
      "         14.5088,  14.5088,   5.2026, 101.9346, 101.9346, 101.9346, 101.9346,\n",
      "        101.9346,  14.5088,  14.5088, 101.9346,  14.5088,  14.5088,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 101.9346,   5.2026,   5.2025, 101.9346,   5.2026,\n",
      "          5.2025, 101.9346,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        101.9346, 101.9346, 101.9346, 101.9346,  14.5088,  14.5088,  14.5088,\n",
      "         14.5088, 101.9346, 101.9346, 101.9346,  14.5088,  14.5088,  14.5088,\n",
      "         14.5088,   5.2026,  14.5088,  14.5088,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 19 was 84.6%\n",
      "tensor([0.0000e+00, 6.8632e-06, 6.6631e-06, 6.4240e-06, 5.5133e-06, 1.3233e-07,\n",
      "        1.2442e-07, 1.1628e-07, 4.7152e-07, 1.2038e-05, 1.1882e-05, 1.1683e-05,\n",
      "        8.1674e-03, 7.7466e-03, 7.5983e-03, 1.1727e-05, 1.1562e-05, 7.4207e-03,\n",
      "        7.2999e-03, 9.5452e-01, 9.2508e-01, 3.7888e+00, 3.8187e+00, 1.1400e-05,\n",
      "        7.1581e-03, 9.0186e-01, 3.8425e+00, 8.8762e-01, 3.8576e+00, 1.0984e+00,\n",
      "        8.4647e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 66.1080,  68.1355,  70.7967,  73.3790,   5.1588,   5.1569,   5.1633,\n",
      "        102.9193, 102.9193, 102.9193,   5.1646,   5.1632, 102.9193, 102.9193,\n",
      "        102.9193, 102.9193, 102.9193,  14.5975,  14.5975,   5.1644, 102.9193,\n",
      "        102.9193, 102.9193, 102.9193, 102.9193,  14.5975,  14.5975, 102.9193,\n",
      "         14.5975,  14.5975,   5.2026, 102.9193, 102.9193, 102.9193, 102.9193,\n",
      "        102.9193,  14.5975,  14.5975, 102.9193,  14.5975,  14.5975,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 102.9193,   5.2026,   5.2025, 102.9193,   5.2026,\n",
      "          5.2025, 102.9193,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        102.9193, 102.9193, 102.9193, 102.9193,  14.5975,  14.5975,  14.5975,\n",
      "         14.5975, 102.9193, 102.9193, 102.9193,  14.5975,  14.5975,  14.5975,\n",
      "         14.5975,   5.2026,  14.5975,  14.5975,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 20 was 84.8%\n",
      "tensor([4.2352e-22, 6.8136e-06, 6.5882e-06, 6.3193e-06, 5.4183e-06, 1.2577e-07,\n",
      "        1.1723e-07, 1.0851e-07, 4.5284e-07, 1.1901e-05, 1.1725e-05, 1.1513e-05,\n",
      "        7.7378e-03, 7.2819e-03, 7.1333e-03, 1.1565e-05, 1.1377e-05, 6.9378e-03,\n",
      "        6.8076e-03, 9.4646e-01, 9.1408e-01, 3.7334e+00, 3.7662e+00, 1.1193e-05,\n",
      "        6.6592e-03, 8.8818e-01, 3.7929e+00, 8.7166e-01, 3.8103e+00, 1.0822e+00,\n",
      "        8.4855e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 66.4164,  68.6845,  71.6808,  74.5349,   5.1569,   5.1561,   5.1605,\n",
      "        103.8827, 103.8827, 103.8827,   5.1601,   5.1618, 103.8827, 103.8827,\n",
      "        103.8827, 103.8827, 103.8827,  14.6861,  14.6861,   5.1612, 103.8827,\n",
      "        103.8827, 103.8827, 103.8827, 103.8827,  14.6861,  14.6861, 103.8827,\n",
      "         14.6861,  14.6861,   5.2026, 103.8827, 103.8827, 103.8827, 103.8827,\n",
      "        103.8827,  14.6861,  14.6861, 103.8827,  14.6861,  14.6861,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 103.8827,   5.2026,   5.2025, 103.8827,   5.2026,\n",
      "          5.2025, 103.8827,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        103.8827, 103.8827, 103.8827, 103.8827,  14.6861,  14.6861,  14.6861,\n",
      "         14.6861, 103.8827, 103.8827, 103.8827,  14.6861,  14.6861,  14.6861,\n",
      "         14.6861,   5.2026,  14.6861,  14.6861,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 21 was 85.0%\n",
      "tensor([3.3881e-21, 6.7631e-06, 6.5146e-06, 6.2183e-06, 5.3315e-06, 1.1930e-07,\n",
      "        1.1024e-07, 1.0111e-07, 4.3350e-07, 1.1772e-05, 1.1573e-05, 1.1355e-05,\n",
      "        7.3230e-03, 6.8353e-03, 6.6862e-03, 1.1412e-05, 1.1201e-05, 6.4762e-03,\n",
      "        6.3347e-03, 9.3862e-01, 9.0402e-01, 3.6829e+00, 3.7179e+00, 1.1004e-05,\n",
      "        6.1846e-03, 8.7532e-01, 3.7473e+00, 8.5709e-01, 3.7663e+00, 1.0672e+00,\n",
      "        8.5046e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 66.7219,  69.2225,  72.5277,  75.6217,   5.1554,   5.1552,   5.1583,\n",
      "        104.8262, 104.8262, 104.8262,   5.1579,   5.1572, 104.8262, 104.8262,\n",
      "        104.8262, 104.8262, 104.8262,  14.7744,  14.7744,   5.1579, 104.8262,\n",
      "        104.8262, 104.8262, 104.8262, 104.8262,  14.7744,  14.7744, 104.8262,\n",
      "         14.7744,  14.7744,   5.2026, 104.8262, 104.8262, 104.8262, 104.8262,\n",
      "        104.8262,  14.7744,  14.7744, 104.8262,  14.7744,  14.7744,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 104.8262,   5.2026,   5.2025, 104.8262,   5.2026,\n",
      "          5.2025, 104.8262,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        104.8262, 104.8262, 104.8262, 104.8262,  14.7744,  14.7744,  14.7744,\n",
      "         14.7744, 104.8262, 104.8262, 104.8262,  14.7744,  14.7744,  14.7744,\n",
      "         14.7744,   5.2026,  14.7744,  14.7744,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 22 was 85.2%\n",
      "tensor([1.0588e-21, 6.7160e-06, 6.4461e-06, 6.1273e-06, 5.2547e-06, 1.1341e-07,\n",
      "        1.0397e-07, 9.4600e-08, 4.1608e-07, 1.1649e-05, 1.1436e-05, 1.1203e-05,\n",
      "        6.9423e-03, 6.4377e-03, 6.2885e-03, 1.1264e-05, 1.1043e-05, 6.0626e-03,\n",
      "        5.9256e-03, 9.3135e-01, 8.9425e-01, 3.6342e+00, 3.6718e+00, 1.0830e-05,\n",
      "        5.7741e-03, 8.6353e-01, 3.7034e+00, 8.4349e-01, 3.7243e+00, 1.0532e+00,\n",
      "        8.5229e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 67.0234,  69.7487,  73.3480,  76.6608,   5.1534,   5.1544,   5.1538,\n",
      "        105.7512, 105.7512, 105.7512,   5.1545,   5.1558, 105.7512, 105.7512,\n",
      "        105.7512, 105.7512, 105.7512,  14.8626,  14.8626,   5.1553, 105.7512,\n",
      "        105.7512, 105.7512, 105.7512, 105.7512,  14.8626,  14.8626, 105.7512,\n",
      "         14.8626,  14.8626,   5.2026, 105.7512, 105.7512, 105.7512, 105.7512,\n",
      "        105.7512,  14.8626,  14.8626, 105.7512,  14.8626,  14.8626,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 105.7512,   5.2026,   5.2025, 105.7512,   5.2026,\n",
      "          5.2025, 105.7512,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        105.7512, 105.7512, 105.7512, 105.7512,  14.8626,  14.8626,  14.8626,\n",
      "         14.8626, 105.7512, 105.7512, 105.7512,  14.8626,  14.8626,  14.8626,\n",
      "         14.8626,   5.2026,  14.8626,  14.8626,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 23 was 85.3%\n",
      "tensor([9.6634e-07, 6.6681e-06, 6.3788e-06, 6.0388e-06, 5.9114e-06, 1.0777e-07,\n",
      "        9.8018e-08, 8.8466e-08, 4.7646e-22, 1.1531e-05, 1.1301e-05, 1.1068e-05,\n",
      "        6.5854e-03, 6.0613e-03, 5.9164e-03, 1.1130e-05, 1.0889e-05, 5.6794e-03,\n",
      "        5.5361e-03, 9.2409e-01, 8.8511e-01, 3.5901e+00, 3.6294e+00, 1.0665e-05,\n",
      "        5.3841e-03, 8.5232e-01, 3.6629e+00, 8.3110e-01, 3.6850e+00, 1.0400e+00,\n",
      "        8.5398e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 67.3222,  70.2664,  74.1406,  77.6526,   5.1525,   5.1521,   5.1523,\n",
      "        106.6589, 106.6589, 106.6589,   5.1524,   5.1513, 106.6589, 106.6589,\n",
      "        106.6589, 106.6589, 106.6589,  14.9506,  14.9506,   5.1521, 106.6589,\n",
      "        106.6589, 106.6589, 106.6589, 106.6589,  14.9506,  14.9506, 106.6589,\n",
      "         14.9506,  14.9506,   5.2026, 106.6589, 106.6589, 106.6589, 106.6589,\n",
      "        106.6589,  14.9506,  14.9506, 106.6589,  14.9506,  14.9506,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 106.6589,   5.2026,   5.2025, 106.6589,   5.2026,\n",
      "          5.2025, 106.6589,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        106.6589, 106.6589, 106.6589, 106.6589,  14.9506,  14.9506,  14.9506,\n",
      "         14.9506, 106.6589, 106.6589, 106.6589,  14.9506,  14.9506,  14.9506,\n",
      "         14.9506,   5.2026,  14.9506,  14.9506,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 24 was 85.5%\n",
      "tensor([8.4703e-22, 6.6258e-06, 6.3175e-06, 5.9591e-06, 5.1144e-06, 1.0317e-07,\n",
      "        9.3145e-08, 8.3502e-08, 3.8518e-07, 1.1417e-05, 1.1180e-05, 1.0933e-05,\n",
      "        6.2884e-03, 5.7556e-03, 5.6101e-03, 1.0997e-05, 1.0752e-05, 5.3612e-03,\n",
      "        5.2228e-03, 9.1703e-01, 8.7637e-01, 3.5472e+00, 3.5881e+00, 1.0513e-05,\n",
      "        5.0700e-03, 8.4182e-01, 3.6234e+00, 8.1906e-01, 3.6471e+00, 1.0274e+00,\n",
      "        8.5561e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 67.6174,  70.7759,  74.9131,  78.6108,   5.1479,   5.1507,   5.1496,\n",
      "        107.5504, 107.5504, 107.5504,   5.1491,   5.1503, 107.5504, 107.5504,\n",
      "        107.5504, 107.5504, 107.5504,  15.0385,  15.0385,   5.1506, 107.5504,\n",
      "        107.5504, 107.5504, 107.5504, 107.5504,  15.0385,  15.0385, 107.5504,\n",
      "         15.0385,  15.0385,   5.2026, 107.5504, 107.5504, 107.5504, 107.5504,\n",
      "        107.5504,  15.0385,  15.0385, 107.5504,  15.0385,  15.0385,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 107.5504,   5.2026,   5.2025, 107.5504,   5.2026,\n",
      "          5.2025, 107.5504,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        107.5504, 107.5504, 107.5504, 107.5504,  15.0385,  15.0385,  15.0385,\n",
      "         15.0385, 107.5504, 107.5504, 107.5504,  15.0385,  15.0385,  15.0385,\n",
      "         15.0385,   5.2026,  15.0385,  15.0385,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 25 was 85.7%\n",
      "tensor([2.1176e-22, 6.5860e-06, 6.2602e-06, 5.8860e-06, 5.0532e-06, 9.9039e-08,\n",
      "        8.8793e-08, 7.9115e-08, 3.7307e-07, 1.1316e-05, 1.1061e-05, 1.0812e-05,\n",
      "        6.0208e-03, 5.4795e-03, 5.3412e-03, 1.0875e-05, 1.0616e-05, 5.0817e-03,\n",
      "        4.9453e-03, 9.0981e-01, 8.6792e-01, 3.5061e+00, 3.5485e+00, 1.0372e-05,\n",
      "        4.7986e-03, 8.3203e-01, 3.5853e+00, 8.0802e-01, 3.6102e+00, 1.0155e+00,\n",
      "        8.5718e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 67.9094,  71.2750,  75.6629,  79.5314,   5.1466,   5.1461,   5.1481,\n",
      "        108.4267, 108.4267, 108.4267,   5.1476,   5.1477, 108.4267, 108.4267,\n",
      "        108.4267, 108.4267, 108.4267,  15.1262,  15.1262,   5.1474, 108.4267,\n",
      "        108.4267, 108.4267, 108.4267, 108.4267,  15.1262,  15.1262, 108.4267,\n",
      "         15.1262,  15.1262,   5.2026, 108.4267, 108.4267, 108.4267, 108.4267,\n",
      "        108.4267,  15.1262,  15.1262, 108.4267,  15.1262,  15.1262,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 108.4267,   5.2026,   5.2025, 108.4267,   5.2026,\n",
      "          5.2025, 108.4267,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        108.4267, 108.4267, 108.4267, 108.4267,  15.1262,  15.1262,  15.1262,\n",
      "         15.1262, 108.4267, 108.4267, 108.4267,  15.1262,  15.1262,  15.1262,\n",
      "         15.1262,   5.2026,  15.1262,  15.1262,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 26 was 85.8%\n",
      "tensor([8.3006e-07, 6.5438e-06, 6.2019e-06, 5.8122e-06, 5.6328e-06, 9.4613e-08,\n",
      "        8.4245e-08, 7.4572e-08, 6.3527e-22, 1.1210e-05, 1.0953e-05, 1.0689e-05,\n",
      "        5.7419e-03, 5.1967e-03, 5.0573e-03, 1.0749e-05, 1.0491e-05, 4.7918e-03,\n",
      "        4.6618e-03, 9.0290e-01, 8.6014e-01, 3.4678e+00, 3.5110e+00, 1.0236e-05,\n",
      "        4.5142e-03, 8.2254e-01, 3.5495e+00, 7.9747e-01, 3.5756e+00, 1.0042e+00,\n",
      "        8.5866e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 68.1987,  71.7652,  76.3910,  80.4164,   5.1447,   5.1454,   5.1437,\n",
      "        109.2887, 109.2887, 109.2887,   5.1449,   5.1445, 109.2887, 109.2887,\n",
      "        109.2887, 109.2887, 109.2887,  15.2138,  15.2138,   5.1460, 109.2887,\n",
      "        109.2887, 109.2887, 109.2887, 109.2887,  15.2138,  15.2138, 109.2887,\n",
      "         15.2138,  15.2138,   5.2026, 109.2887, 109.2887, 109.2887, 109.2887,\n",
      "        109.2887,  15.2138,  15.2138, 109.2887,  15.2138,  15.2138,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 109.2887,   5.2026,   5.2025, 109.2887,   5.2026,\n",
      "          5.2025, 109.2887,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        109.2887, 109.2887, 109.2887, 109.2887,  15.2138,  15.2138,  15.2138,\n",
      "         15.2138, 109.2887, 109.2887, 109.2887,  15.2138,  15.2138,  15.2138,\n",
      "         15.2138,   5.2026,  15.2138,  15.2138,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 27 was 86.0%\n",
      "tensor([0.0000e+00, 6.5029e-06, 6.1454e-06, 5.7427e-06, 4.9388e-06, 9.0627e-08,\n",
      "        8.0139e-08, 7.0519e-08, 3.4674e-07, 1.1108e-05, 1.0843e-05, 1.0579e-05,\n",
      "        5.4902e-03, 4.9412e-03, 4.8055e-03, 1.0638e-05, 1.0370e-05, 4.5337e-03,\n",
      "        4.4032e-03, 8.9633e-01, 8.5228e-01, 3.4319e+00, 3.4763e+00, 1.0105e-05,\n",
      "        4.2560e-03, 8.1373e-01, 3.5156e+00, 7.8760e-01, 3.5426e+00, 9.9344e-01,\n",
      "        8.6005e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 68.4861,  72.2487,  77.0986,  81.2699,   5.1426,   5.1419,   5.1428,\n",
      "        110.1372, 110.1372, 110.1372,   5.1427,   5.1430, 110.1372, 110.1372,\n",
      "        110.1372, 110.1372, 110.1372,  15.3012,  15.3012,   5.1416, 110.1372,\n",
      "        110.1372, 110.1372, 110.1372, 110.1372,  15.3012,  15.3012, 110.1372,\n",
      "         15.3012,  15.3012,   5.2026, 110.1372, 110.1372, 110.1372, 110.1372,\n",
      "        110.1372,  15.3012,  15.3012, 110.1372,  15.3012,  15.3012,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 110.1372,   5.2026,   5.2025, 110.1372,   5.2026,\n",
      "          5.2025, 110.1372,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        110.1372, 110.1372, 110.1372, 110.1372,  15.3012,  15.3012,  15.3012,\n",
      "         15.3012, 110.1372, 110.1372, 110.1372,  15.3012,  15.3012,  15.3012,\n",
      "         15.3012,   5.2026,  15.3012,  15.3012,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 28 was 86.1%\n",
      "tensor([0.0000e+00, 6.4632e-06, 6.0917e-06, 5.6762e-06, 4.8873e-06, 8.6800e-08,\n",
      "        7.6252e-08, 6.6726e-08, 3.3463e-07, 1.1013e-05, 1.0739e-05, 1.0467e-05,\n",
      "        5.2509e-03, 4.6998e-03, 4.5666e-03, 1.0526e-05, 1.0254e-05, 4.2896e-03,\n",
      "        4.1636e-03, 8.8975e-01, 8.4522e-01, 3.3971e+00, 3.4419e+00, 9.9857e-06,\n",
      "        4.0204e-03, 8.0510e-01, 3.4828e+00, 7.7810e-01, 3.5107e+00, 9.8308e-01,\n",
      "        8.6140e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 68.7710,  72.7248,  77.7888,  82.0964,   5.1410,   5.1405,   5.1395,\n",
      "        110.9730, 110.9730, 110.9730,   5.1399,   5.1385, 110.9730, 110.9730,\n",
      "        110.9730, 110.9730, 110.9730,  15.3885,  15.3885,   5.1407, 110.9730,\n",
      "        110.9730, 110.9730, 110.9730, 110.9730,  15.3885,  15.3885, 110.9730,\n",
      "         15.3885,  15.3885,   5.2026, 110.9730, 110.9730, 110.9730, 110.9730,\n",
      "        110.9730,  15.3885,  15.3885, 110.9730,  15.3885,  15.3885,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 110.9730,   5.2026,   5.2025, 110.9730,   5.2026,\n",
      "          5.2025, 110.9730,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        110.9730, 110.9730, 110.9730, 110.9730,  15.3885,  15.3885,  15.3885,\n",
      "         15.3885, 110.9730, 110.9730, 110.9730,  15.3885,  15.3885,  15.3885,\n",
      "         15.3885,   5.2026,  15.3885,  15.3885,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 29 was 86.2%\n",
      "tensor([7.1836e-07, 6.4253e-06, 6.0398e-06, 5.6141e-06, 5.3985e-06, 8.3277e-08,\n",
      "        7.2687e-08, 6.3280e-08, 1.0588e-22, 1.0917e-05, 1.0640e-05, 1.0367e-05,\n",
      "        5.0276e-03, 4.4810e-03, 4.3505e-03, 1.0422e-05, 1.0148e-05, 4.0698e-03,\n",
      "        3.9466e-03, 8.8349e-01, 8.3806e-01, 3.3637e+00, 3.4095e+00, 9.8667e-06,\n",
      "        3.8049e-03, 7.9714e-01, 3.4511e+00, 7.6904e-01, 3.4802e+00, 9.7326e-01,\n",
      "        8.6270e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 69.0537,  73.1942,  78.4632,  82.8990,   5.1364,   5.1378,   5.1380,\n",
      "        111.7966, 111.7966, 111.7966,   5.1385,   5.1376, 111.7966, 111.7966,\n",
      "        111.7966, 111.7966, 111.7966,  15.4757,  15.4757,   5.1374, 111.7966,\n",
      "        111.7966, 111.7966, 111.7966, 111.7966,  15.4757,  15.4757, 111.7966,\n",
      "         15.4757,  15.4757,   5.2026, 111.7966, 111.7966, 111.7966, 111.7966,\n",
      "        111.7966,  15.4757,  15.4757, 111.7966,  15.4757,  15.4757,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 111.7966,   5.2026,   5.2025, 111.7966,   5.2026,\n",
      "          5.2025, 111.7966,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        111.7966, 111.7966, 111.7966, 111.7966,  15.4757,  15.4757,  15.4757,\n",
      "         15.4757, 111.7966, 111.7966, 111.7966,  15.4757,  15.4757,  15.4757,\n",
      "         15.4757,   5.2026,  15.4757,  15.4757,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 30 was 86.3%\n",
      "tensor([5.2940e-22, 6.3877e-06, 5.9899e-06, 5.5549e-06, 4.7933e-06, 7.9893e-08,\n",
      "        6.9323e-08, 6.0080e-08, 3.1271e-07, 1.0831e-05, 1.0543e-05, 1.0263e-05,\n",
      "        4.8161e-03, 4.2713e-03, 4.1450e-03, 1.0317e-05, 1.0040e-05, 3.8612e-03,\n",
      "        3.7441e-03, 8.7710e-01, 8.3119e-01, 3.3310e+00, 3.3773e+00, 9.7587e-06,\n",
      "        3.6089e-03, 7.8934e-01, 3.4201e+00, 7.6051e-01, 3.4499e+00, 9.6375e-01,\n",
      "        8.6397e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 69.3333,  73.6554,  79.1231,  83.6786,   5.1351,   5.1353,   5.1347,\n",
      "        112.6088, 112.6088, 112.6088,   5.1340,   5.1356, 112.6088, 112.6088,\n",
      "        112.6088, 112.6088, 112.6088,  15.5627,  15.5627,   5.1366, 112.6088,\n",
      "        112.6088, 112.6088, 112.6088, 112.6088,  15.5627,  15.5627, 112.6088,\n",
      "         15.5627,  15.5627,   5.2026, 112.6088, 112.6088, 112.6088, 112.6088,\n",
      "        112.6088,  15.5627,  15.5627, 112.6088,  15.5627,  15.5627,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 112.6088,   5.2026,   5.2025, 112.6088,   5.2026,\n",
      "          5.2025, 112.6088,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        112.6088, 112.6088, 112.6088, 112.6088,  15.5627,  15.5627,  15.5627,\n",
      "         15.5627, 112.6088, 112.6088, 112.6088,  15.5627,  15.5627,  15.5627,\n",
      "         15.5627,   5.2026,  15.5627,  15.5627,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 31 was 86.5%\n",
      "tensor([0.0000e+00, 6.3469e-06, 5.9371e-06, 5.4935e-06, 4.7501e-06, 7.5978e-08,\n",
      "        6.5499e-08, 5.6465e-08, 2.9914e-07, 1.0738e-05, 1.0448e-05, 1.0170e-05,\n",
      "        4.5758e-03, 4.0369e-03, 3.9148e-03, 1.0222e-05, 9.9367e-06, 3.6313e-03,\n",
      "        3.5146e-03, 8.7093e-01, 8.2475e-01, 3.3012e+00, 3.3478e+00, 9.6483e-06,\n",
      "        3.3804e-03, 7.8214e-01, 3.3913e+00, 7.5245e-01, 3.4220e+00, 9.5482e-01,\n",
      "        8.6515e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 69.6161,  74.1181,  79.7798,  84.4538,   5.1326,   5.1325,   5.1338,\n",
      "        113.4101, 113.4101, 113.4101,   5.1331,   5.1324, 113.4101, 113.4101,\n",
      "        113.4101, 113.4101, 113.4101,  15.6496,  15.6496,   5.1322, 113.4101,\n",
      "        113.4101, 113.4101, 113.4101, 113.4101,  15.6496,  15.6496, 113.4101,\n",
      "         15.6496,  15.6496,   5.2026, 113.4101, 113.4101, 113.4101, 113.4101,\n",
      "        113.4101,  15.6496,  15.6496, 113.4101,  15.6496,  15.6496,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 113.4101,   5.2026,   5.2025, 113.4101,   5.2026,\n",
      "          5.2025, 113.4101,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        113.4101, 113.4101, 113.4101, 113.4101,  15.6496,  15.6496,  15.6496,\n",
      "         15.6496, 113.4101, 113.4101, 113.4101,  15.6496,  15.6496,  15.6496,\n",
      "         15.6496,   5.2026,  15.6496,  15.6496,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 32 was 86.6%\n",
      "tensor([0.0000e+00, 6.3166e-06, 5.8947e-06, 5.4424e-06, 4.7052e-06, 7.4086e-08,\n",
      "        6.3536e-08, 5.4571e-08, 2.9426e-07, 1.0655e-05, 1.0359e-05, 1.0073e-05,\n",
      "        4.4517e-03, 3.9144e-03, 3.7943e-03, 1.0121e-05, 9.8409e-06, 3.5058e-03,\n",
      "        3.3967e-03, 8.6473e-01, 8.1815e-01, 3.2697e+00, 3.3167e+00, 9.5497e-06,\n",
      "        3.2677e-03, 7.7460e-01, 3.3611e+00, 7.4402e-01, 3.3927e+00, 9.4555e-01,\n",
      "        8.6638e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 69.8929,  74.5689,  80.4147,  85.1959,   5.1295,   5.1311,   5.1294,\n",
      "        114.2011, 114.2011, 114.2011,   5.1298,   5.1310, 114.2011, 114.2011,\n",
      "        114.2011, 114.2011, 114.2011,  15.7364,  15.7364,   5.1313, 114.2011,\n",
      "        114.2011, 114.2011, 114.2011, 114.2011,  15.7364,  15.7364, 114.2011,\n",
      "         15.7364,  15.7364,   5.2026, 114.2011, 114.2011, 114.2011, 114.2011,\n",
      "        114.2011,  15.7364,  15.7364, 114.2011,  15.7364,  15.7364,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 114.2011,   5.2026,   5.2025, 114.2011,   5.2026,\n",
      "          5.2025, 114.2011,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        114.2011, 114.2011, 114.2011, 114.2011,  15.7364,  15.7364,  15.7364,\n",
      "         15.7364, 114.2011, 114.2011, 114.2011,  15.7364,  15.7364,  15.7364,\n",
      "         15.7364,   5.2026,  15.7364,  15.7364,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 33 was 86.7%\n",
      "tensor([6.0900e-07, 6.2830e-06, 5.8502e-06, 5.3908e-06, 5.1457e-06, 7.1641e-08,\n",
      "        6.1094e-08, 5.2248e-08, 3.1764e-22, 1.0573e-05, 1.0270e-05, 9.9898e-06,\n",
      "        4.2984e-03, 3.7630e-03, 3.6490e-03, 1.0035e-05, 9.7445e-06, 3.3585e-03,\n",
      "        3.2490e-03, 8.5879e-01, 8.1175e-01, 3.2413e+00, 3.2886e+00, 9.4509e-06,\n",
      "        3.1233e-03, 7.6771e-01, 3.3334e+00, 7.3652e-01, 3.3655e+00, 9.3691e-01,\n",
      "        8.6750e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 70.1678,  75.0152,  81.0373,  85.9232,   5.1280,   5.1277,   5.1285,\n",
      "        114.9822, 114.9822, 114.9822,   5.1282,   5.1282, 114.9822, 114.9822,\n",
      "        114.9822, 114.9822, 114.9822,  15.8231,  15.8231,   5.1270, 114.9822,\n",
      "        114.9822, 114.9822, 114.9822, 114.9822,  15.8231,  15.8231, 114.9822,\n",
      "         15.8231,  15.8231,   5.2026, 114.9822, 114.9822, 114.9822, 114.9822,\n",
      "        114.9822,  15.8231,  15.8231, 114.9822,  15.8231,  15.8231,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 114.9822,   5.2026,   5.2025, 114.9822,   5.2026,\n",
      "          5.2025, 114.9822,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        114.9822, 114.9822, 114.9822, 114.9822,  15.8231,  15.8231,  15.8231,\n",
      "         15.8231, 114.9822, 114.9822, 114.9822,  15.8231,  15.8231,  15.8231,\n",
      "         15.8231,   5.2026,  15.8231,  15.8231,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 34 was 86.8%\n",
      "tensor([5.9259e-07, 6.2535e-06, 5.8103e-06, 5.3438e-06, 5.0946e-06, 6.9819e-08,\n",
      "        5.9255e-08, 5.0519e-08, 1.0588e-22, 1.0491e-05, 1.0188e-05, 9.9004e-06,\n",
      "        4.1783e-03, 3.6489e-03, 3.5384e-03, 9.9431e-06, 9.6565e-06, 3.2442e-03,\n",
      "        3.1419e-03, 8.5286e-01, 8.0567e-01, 3.2119e+00, 3.2595e+00, 9.3596e-06,\n",
      "        3.0207e-03, 7.6074e-01, 3.3052e+00, 7.2889e-01, 3.3381e+00, 9.2838e-01,\n",
      "        8.6865e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 70.4397,  75.4532,  81.6452,  86.6264,   5.1261,   5.1264,   5.1241,\n",
      "        115.7538, 115.7538, 115.7538,   5.1255,   5.1251, 115.7538, 115.7538,\n",
      "        115.7538, 115.7538, 115.7538,  15.9096,  15.9096,   5.1261, 115.7538,\n",
      "        115.7538, 115.7538, 115.7538, 115.7538,  15.9096,  15.9096, 115.7538,\n",
      "         15.9096,  15.9096,   5.2026, 115.7538, 115.7538, 115.7538, 115.7538,\n",
      "        115.7538,  15.9096,  15.9096, 115.7538,  15.9096,  15.9096,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 115.7538,   5.2026,   5.2025, 115.7538,   5.2026,\n",
      "          5.2025, 115.7538,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        115.7538, 115.7538, 115.7538, 115.7538,  15.9096,  15.9096,  15.9096,\n",
      "         15.9096, 115.7538, 115.7538, 115.7538,  15.9096,  15.9096,  15.9096,\n",
      "         15.9096,   5.2026,  15.9096,  15.9096,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 35 was 86.9%\n",
      "tensor([0.0000e+00, 6.2204e-06, 5.7673e-06, 5.2953e-06, 4.5865e-06, 6.7308e-08,\n",
      "        5.6823e-08, 4.8272e-08, 2.7335e-07, 1.0411e-05, 1.0105e-05, 9.8216e-06,\n",
      "        4.0216e-03, 3.4995e-03, 3.3931e-03, 9.8596e-06, 9.5701e-06, 3.0995e-03,\n",
      "        2.9988e-03, 8.4733e-01, 7.9968e-01, 3.1851e+00, 3.2330e+00, 9.2670e-06,\n",
      "        2.8806e-03, 7.5441e-01, 3.2792e+00, 7.2186e-01, 3.3127e+00, 9.2043e-01,\n",
      "        8.6970e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 70.7093,  75.8852,  82.2409,  87.3122,   5.1230,   5.1219,   5.1233,\n",
      "        116.5165, 116.5165, 116.5165,   5.1242,   5.1237, 116.5165, 116.5165,\n",
      "        116.5165, 116.5165, 116.5165,  15.9960,  15.9960,   5.1230, 116.5165,\n",
      "        116.5165, 116.5165, 116.5165, 116.5165,  15.9960,  15.9960, 116.5165,\n",
      "         15.9960,  15.9960,   5.2026, 116.5165, 116.5165, 116.5165, 116.5165,\n",
      "        116.5165,  15.9960,  15.9960, 116.5165,  15.9960,  15.9960,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 116.5165,   5.2026,   5.2025, 116.5165,   5.2026,\n",
      "          5.2025, 116.5165,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        116.5165, 116.5165, 116.5165, 116.5165,  15.9960,  15.9960,  15.9960,\n",
      "         15.9960, 116.5165, 116.5165, 116.5165,  15.9960,  15.9960,  15.9960,\n",
      "         15.9960,   5.2026,  15.9960,  15.9960,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 36 was 87.0%\n",
      "tensor([0.0000e+00, 6.1886e-06, 5.7269e-06, 5.2490e-06, 4.5507e-06, 6.5143e-08,\n",
      "        5.4726e-08, 4.6329e-08, 2.6642e-07, 1.0337e-05, 1.0028e-05, 9.7371e-06,\n",
      "        3.8873e-03, 3.3707e-03, 3.2665e-03, 9.7737e-06, 9.4858e-06, 2.9723e-03,\n",
      "        2.8773e-03, 8.4166e-01, 7.9406e-01, 3.1589e+00, 3.2068e+00, 9.1819e-06,\n",
      "        2.7625e-03, 7.4803e-01, 3.2537e+00, 7.1516e-01, 3.2876e+00, 9.1265e-01,\n",
      "        8.7074e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 70.9787,  76.3158,  82.8324,  87.9925,   5.1210,   5.1211,   5.1206,\n",
      "        117.2706, 117.2706, 117.2706,   5.1197,   5.1205, 117.2706, 117.2706,\n",
      "        117.2706, 117.2706, 117.2706,  16.0824,  16.0824,   5.1215, 117.2706,\n",
      "        117.2706, 117.2706, 117.2706, 117.2706,  16.0824,  16.0824, 117.2706,\n",
      "         16.0824,  16.0824,   5.2026, 117.2706, 117.2706, 117.2706, 117.2706,\n",
      "        117.2706,  16.0824,  16.0824, 117.2706,  16.0824,  16.0824,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 117.2706,   5.2026,   5.2025, 117.2706,   5.2026,\n",
      "          5.2025, 117.2706,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        117.2706, 117.2706, 117.2706, 117.2706,  16.0824,  16.0824,  16.0824,\n",
      "         16.0824, 117.2706, 117.2706, 117.2706,  16.0824,  16.0824,  16.0824,\n",
      "         16.0824,   5.2026,  16.0824,  16.0824,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 37 was 87.1%\n",
      "tensor([6.3527e-22, 6.1575e-06, 5.6862e-06, 5.2039e-06, 4.5158e-06, 6.3019e-08,\n",
      "        5.2667e-08, 4.4441e-08, 2.5946e-07, 1.0259e-05, 9.9479e-06, 9.6603e-06,\n",
      "        3.7538e-03, 3.2449e-03, 3.1452e-03, 9.6959e-06, 9.4038e-06, 2.8507e-03,\n",
      "        2.7575e-03, 8.3612e-01, 7.8839e-01, 3.1331e+00, 3.1812e+00, 9.0950e-06,\n",
      "        2.6459e-03, 7.4213e-01, 3.2284e+00, 7.0838e-01, 3.2631e+00, 9.0500e-01,\n",
      "        8.7176e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 71.2450,  76.7388,  83.4094,  88.6525,   5.1178,   5.1178,   5.1192,\n",
      "        118.0164, 118.0164, 118.0164,   5.1189,   5.1191, 118.0164, 118.0164,\n",
      "        118.0164, 118.0164, 118.0164,  16.1686,  16.1686,   5.1173, 118.0164,\n",
      "        118.0164, 118.0164, 118.0164, 118.0164,  16.1686,  16.1686, 118.0164,\n",
      "         16.1686,  16.1686,   5.2026, 118.0164, 118.0164, 118.0164, 118.0164,\n",
      "        118.0164,  16.1686,  16.1686, 118.0164,  16.1686,  16.1686,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 118.0164,   5.2026,   5.2025, 118.0164,   5.2026,\n",
      "          5.2025, 118.0164,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        118.0164, 118.0164, 118.0164, 118.0164,  16.1686,  16.1686,  16.1686,\n",
      "         16.1686, 118.0164, 118.0164, 118.0164,  16.1686,  16.1686,  16.1686,\n",
      "         16.1686,   5.2026,  16.1686,  16.1686,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 38 was 87.2%\n",
      "tensor([8.4703e-22, 6.1264e-06, 5.6469e-06, 5.1592e-06, 4.4813e-06, 6.0987e-08,\n",
      "        5.0717e-08, 4.2640e-08, 2.5264e-07, 1.0190e-05, 9.8738e-06, 9.5819e-06,\n",
      "        3.6314e-03, 3.1255e-03, 3.0266e-03, 9.6135e-06, 9.3244e-06, 2.7335e-03,\n",
      "        2.6434e-03, 8.3075e-01, 7.8312e-01, 3.1093e+00, 3.1571e+00, 9.0176e-06,\n",
      "        2.5349e-03, 7.3617e-01, 3.2048e+00, 7.0204e-01, 3.2398e+00, 8.9766e-01,\n",
      "        8.7271e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 71.5093,  77.1566,  83.9735,  89.2973,   5.1169,   5.1157,   5.1148,\n",
      "        118.7544, 118.7544, 118.7544,   5.1162,   5.1159, 118.7544, 118.7544,\n",
      "        118.7544, 118.7544, 118.7544,  16.2547,  16.2547,   5.1164, 118.7544,\n",
      "        118.7544, 118.7544, 118.7544, 118.7544,  16.2547,  16.2547, 118.7544,\n",
      "         16.2547,  16.2547,   5.2026, 118.7544, 118.7544, 118.7544, 118.7544,\n",
      "        118.7544,  16.2547,  16.2547, 118.7544,  16.2547,  16.2547,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 118.7544,   5.2026,   5.2025, 118.7544,   5.2026,\n",
      "          5.2025, 118.7544,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        118.7544, 118.7544, 118.7544, 118.7544,  16.2547,  16.2547,  16.2547,\n",
      "         16.2547, 118.7544, 118.7544, 118.7544,  16.2547,  16.2547,  16.2547,\n",
      "         16.2547,   5.2026,  16.2547,  16.2547,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 39 was 87.3%\n",
      "tensor([0.0000e+00, 6.0979e-06, 5.6104e-06, 5.1188e-06, 4.4483e-06, 5.9348e-08,\n",
      "        4.9135e-08, 4.1203e-08, 2.4762e-07, 1.0115e-05, 9.8011e-06, 9.5131e-06,\n",
      "        3.5259e-03, 3.0287e-03, 2.9339e-03, 9.5404e-06, 9.2490e-06, 2.6408e-03,\n",
      "        2.5529e-03, 8.2559e-01, 7.7767e-01, 3.0849e+00, 3.1330e+00, 8.9353e-06,\n",
      "        2.4468e-03, 7.3043e-01, 3.1810e+00, 6.9580e-01, 3.2166e+00, 8.9045e-01,\n",
      "        8.7367e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 71.7727,  77.5718,  84.5321,  89.9347,   5.1123,   5.1142,   5.1138,\n",
      "        119.4848, 119.4848, 119.4848,   5.1135,   5.1144, 119.4848, 119.4848,\n",
      "        119.4848, 119.4848, 119.4848,  16.3407,  16.3407,   5.1132, 119.4848,\n",
      "        119.4848, 119.4848, 119.4848, 119.4848,  16.3407,  16.3407, 119.4848,\n",
      "         16.3407,  16.3407,   5.2026, 119.4848, 119.4848, 119.4848, 119.4848,\n",
      "        119.4848,  16.3407,  16.3407, 119.4848,  16.3407,  16.3407,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 119.4848,   5.2026,   5.2025, 119.4848,   5.2026,\n",
      "          5.2025, 119.4848,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        119.4848, 119.4848, 119.4848, 119.4848,  16.3407,  16.3407,  16.3407,\n",
      "         16.3407, 119.4848, 119.4848, 119.4848,  16.3407,  16.3407,  16.3407,\n",
      "         16.3407,   5.2026,  16.3407,  16.3407,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 40 was 87.4%\n",
      "tensor([2.1176e-22, 6.0717e-06, 5.5762e-06, 5.0812e-06, 4.4170e-06, 5.8034e-08,\n",
      "        4.7856e-08, 4.0052e-08, 2.4404e-07, 1.0051e-05, 9.7270e-06, 9.4401e-06,\n",
      "        3.4407e-03, 2.9483e-03, 2.8588e-03, 9.4664e-06, 9.1728e-06, 2.5644e-03,\n",
      "        2.4803e-03, 8.2020e-01, 7.7237e-01, 3.0607e+00, 3.1088e+00, 8.8635e-06,\n",
      "        2.3806e-03, 7.2488e-01, 3.1571e+00, 6.8969e-01, 3.1932e+00, 8.8338e-01,\n",
      "        8.7464e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 72.0345,  77.9816,  85.0823,  90.5570,   5.1110,   5.1109,   5.1113,\n",
      "        120.2079, 120.2079, 120.2079,   5.1115,   5.1101, 120.2079, 120.2079,\n",
      "        120.2079, 120.2079, 120.2079,  16.4266,  16.4266,   5.1123, 120.2079,\n",
      "        120.2079, 120.2079, 120.2079, 120.2079,  16.4266,  16.4266, 120.2079,\n",
      "         16.4266,  16.4266,   5.2026, 120.2079, 120.2079, 120.2079, 120.2079,\n",
      "        120.2079,  16.4266,  16.4266, 120.2079,  16.4266,  16.4266,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 120.2079,   5.2026,   5.2025, 120.2079,   5.2026,\n",
      "          5.2025, 120.2079,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        120.2079, 120.2079, 120.2079, 120.2079,  16.4266,  16.4266,  16.4266,\n",
      "         16.4266, 120.2079, 120.2079, 120.2079,  16.4266,  16.4266,  16.4266,\n",
      "         16.4266,   5.2026,  16.4266,  16.4266,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 41 was 87.5%\n",
      "tensor([3.7058e-22, 6.0420e-06, 5.5393e-06, 5.0415e-06, 4.3863e-06, 5.6226e-08,\n",
      "        4.6155e-08, 3.8521e-08, 2.3795e-07, 9.9783e-06, 9.6602e-06, 9.3693e-06,\n",
      "        3.3282e-03, 2.8460e-03, 2.7575e-03, 9.3927e-06, 9.1040e-06, 2.4648e-03,\n",
      "        2.3847e-03, 8.1511e-01, 7.6718e-01, 3.0380e+00, 3.0862e+00, 8.7867e-06,\n",
      "        2.2859e-03, 7.1958e-01, 3.1346e+00, 6.8393e-01, 3.1712e+00, 8.7664e-01,\n",
      "        8.7554e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 72.2944,  78.3866,  85.6230,  91.1661,   5.1085,   5.1101,   5.1087,\n",
      "        120.9240, 120.9240, 120.9240,   5.1082,   5.1092, 120.9240, 120.9240,\n",
      "        120.9240, 120.9240, 120.9240,  16.5124,  16.5124,   5.1080, 120.9240,\n",
      "        120.9240, 120.9240, 120.9240, 120.9240,  16.5124,  16.5124, 120.9240,\n",
      "         16.5124,  16.5124,   5.2026, 120.9240, 120.9240, 120.9240, 120.9240,\n",
      "        120.9240,  16.5124,  16.5124, 120.9240,  16.5124,  16.5124,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 120.9240,   5.2026,   5.2025, 120.9240,   5.2026,\n",
      "          5.2025, 120.9240,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        120.9240, 120.9240, 120.9240, 120.9240,  16.5124,  16.5124,  16.5124,\n",
      "         16.5124, 120.9240, 120.9240, 120.9240,  16.5124,  16.5124,  16.5124,\n",
      "         16.5124,   5.2026,  16.5124,  16.5124,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 42 was 87.6%\n",
      "tensor([0.0000e+00, 6.0134e-06, 5.5036e-06, 5.0024e-06, 4.3553e-06, 5.4460e-08,\n",
      "        4.4508e-08, 3.7041e-08, 2.3200e-07, 9.9139e-06, 9.5875e-06, 9.3025e-06,\n",
      "        3.2216e-03, 2.7434e-03, 2.6602e-03, 9.3241e-06, 9.0285e-06, 2.3694e-03,\n",
      "        2.2902e-03, 8.1025e-01, 7.6231e-01, 3.0158e+00, 3.0640e+00, 8.7179e-06,\n",
      "        2.1964e-03, 7.1435e-01, 3.1128e+00, 6.7814e-01, 3.1499e+00, 8.7008e-01,\n",
      "        8.7642e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 72.5527,  78.7871,  86.1553,  91.7637,   5.1066,   5.1056,   5.1062,\n",
      "        121.6334, 121.6334, 121.6334,   5.1069,   5.1060, 121.6334, 121.6334,\n",
      "        121.6334, 121.6334, 121.6334,  16.5981,  16.5981,   5.1071, 121.6334,\n",
      "        121.6334, 121.6334, 121.6334, 121.6334,  16.5981,  16.5981, 121.6334,\n",
      "         16.5981,  16.5981,   5.2026, 121.6334, 121.6334, 121.6334, 121.6334,\n",
      "        121.6334,  16.5981,  16.5981, 121.6334,  16.5981,  16.5981,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 121.6334,   5.2026,   5.2025, 121.6334,   5.2026,\n",
      "          5.2025, 121.6334,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        121.6334, 121.6334, 121.6334, 121.6334,  16.5981,  16.5981,  16.5981,\n",
      "         16.5981, 121.6334, 121.6334, 121.6334,  16.5981,  16.5981,  16.5981,\n",
      "         16.5981,   5.2026,  16.5981,  16.5981,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 43 was 87.7%\n",
      "tensor([0.0000e+00, 5.9843e-06, 5.4686e-06, 4.9634e-06, 4.3195e-06, 5.2751e-08,\n",
      "        4.2929e-08, 3.5634e-08, 2.2676e-07, 9.8451e-06, 9.5251e-06, 9.2347e-06,\n",
      "        3.1162e-03, 2.6485e-03, 2.5658e-03, 9.2529e-06, 8.9634e-06, 2.2776e-03,\n",
      "        2.2027e-03, 8.0529e-01, 7.5745e-01, 2.9944e+00, 3.0425e+00, 8.6447e-06,\n",
      "        2.1096e-03, 7.0921e-01, 3.0915e+00, 6.7282e-01, 3.1289e+00, 8.6366e-01,\n",
      "        8.7728e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 72.8095,  79.1836,  86.6799,  92.3509,   5.1034,   5.1048,   5.1042,\n",
      "        122.3364, 122.3364, 122.3364,   5.1036,   5.1051, 122.3364, 122.3364,\n",
      "        122.3364, 122.3364, 122.3364,  16.6837,  16.6837,   5.1029, 122.3364,\n",
      "        122.3364, 122.3364, 122.3364, 122.3364,  16.6837,  16.6837, 122.3364,\n",
      "         16.6837,  16.6837,   5.2026, 122.3364, 122.3364, 122.3364, 122.3364,\n",
      "        122.3364,  16.6837,  16.6837, 122.3364,  16.6837,  16.6837,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 122.3364,   5.2026,   5.2025, 122.3364,   5.2026,\n",
      "          5.2025, 122.3364,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        122.3364, 122.3364, 122.3364, 122.3364,  16.6837,  16.6837,  16.6837,\n",
      "         16.6837, 122.3364, 122.3364, 122.3364,  16.6837,  16.6837,  16.6837,\n",
      "         16.6837,   5.2026,  16.6837,  16.6837,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 44 was 87.8%\n",
      "tensor([0.0000e+00, 5.9576e-06, 5.4358e-06, 4.9356e-06, 4.3437e-06, 5.1296e-08,\n",
      "        4.1572e-08, 3.4425e-08, 2.1656e-07, 9.7855e-06, 9.4558e-06, 9.1715e-06,\n",
      "        3.0278e-03, 2.5642e-03, 2.4859e-03, 9.1880e-06, 8.8937e-06, 2.1992e-03,\n",
      "        2.1252e-03, 8.0046e-01, 7.5286e-01, 2.9734e+00, 3.0213e+00, 8.5816e-06,\n",
      "        2.0371e-03, 7.0427e-01, 3.0707e+00, 6.6743e-01, 3.1084e+00, 8.5741e-01,\n",
      "        8.7812e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 73.0658,  79.5784,  87.2008,  92.9335,   5.1021,   5.1015,   5.1017,\n",
      "        123.0331, 123.0331, 123.0331,   5.1016,   5.1008, 123.0331, 123.0331,\n",
      "        123.0331, 123.0331, 123.0331,  16.7692,  16.7692,   5.1020, 123.0331,\n",
      "        123.0331, 123.0331, 123.0331, 123.0331,  16.7692,  16.7692, 123.0331,\n",
      "         16.7692,  16.7692,   5.2026, 123.0331, 123.0331, 123.0331, 123.0331,\n",
      "        123.0331,  16.7692,  16.7692, 123.0331,  16.7692,  16.7692,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 123.0331,   5.2026,   5.2025, 123.0331,   5.2026,\n",
      "          5.2025, 123.0331,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        123.0331, 123.0331, 123.0331, 123.0331,  16.7692,  16.7692,  16.7692,\n",
      "         16.7692, 123.0331, 123.0331, 123.0331,  16.7692,  16.7692,  16.7692,\n",
      "         16.7692,   5.2026,  16.7692,  16.7692,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 45 was 87.8%\n",
      "tensor([0.0000e+00, 5.9301e-06, 5.4015e-06, 4.8845e-06, 4.2318e-06, 4.9818e-08,\n",
      "        4.0209e-08, 3.3221e-08, 2.2947e-07, 9.7179e-06, 9.3947e-06, 9.1065e-06,\n",
      "        2.9357e-03, 2.4826e-03, 2.4049e-03, 9.1203e-06, 8.8317e-06, 2.1206e-03,\n",
      "        2.0503e-03, 7.9573e-01, 7.4810e-01, 2.9525e+00, 3.0004e+00, 8.5109e-06,\n",
      "        1.9630e-03, 6.9939e-01, 3.0499e+00, 6.6216e-01, 3.0881e+00, 8.5117e-01,\n",
      "        8.7895e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 73.3205,  79.9686,  87.7136,  93.5027,   5.0971,   5.1007,   5.0991,\n",
      "        123.7238, 123.7238, 123.7238,   5.0996,   5.1000, 123.7238, 123.7238,\n",
      "        123.7238, 123.7238, 123.7238,  16.8546,  16.8546,   5.0988, 123.7238,\n",
      "        123.7238, 123.7238, 123.7238, 123.7238,  16.8546,  16.8546, 123.7238,\n",
      "         16.8546,  16.8546,   5.2026, 123.7238, 123.7238, 123.7238, 123.7238,\n",
      "        123.7238,  16.8546,  16.8546, 123.7238,  16.8546,  16.8546,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 123.7238,   5.2026,   5.2025, 123.7238,   5.2026,\n",
      "          5.2025, 123.7238,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        123.7238, 123.7238, 123.7238, 123.7238,  16.8546,  16.8546,  16.8546,\n",
      "         16.8546, 123.7238, 123.7238, 123.7238,  16.8546,  16.8546,  16.8546,\n",
      "         16.8546,   5.2026,  16.8546,  16.8546,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 46 was 87.9%\n",
      "tensor([0.0000e+00, 5.9023e-06, 5.3306e-06, 4.4986e-06, 4.9128e-20, 4.8379e-08,\n",
      "        3.8903e-08, 3.2102e-08, 2.4604e-06, 9.6631e-06, 9.3294e-06, 9.0461e-06,\n",
      "        2.8486e-03, 2.4001e-03, 2.3264e-03, 9.0572e-06, 8.7648e-06, 2.0447e-03,\n",
      "        1.9755e-03, 7.9112e-01, 7.4349e-01, 2.9325e+00, 2.9804e+00, 8.4505e-06,\n",
      "        1.8930e-03, 6.9476e-01, 3.0299e+00, 6.5715e-01, 3.0685e+00, 8.4529e-01,\n",
      "        8.7975e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 73.5739,  80.3547,  88.2193,  94.0605,   5.0957,   5.0962,   5.0972,\n",
      "        124.4086, 124.4086, 124.4086,   5.0970,   5.0968, 124.4086, 124.4086,\n",
      "        124.4086, 124.4086, 124.4086,  16.9400,  16.9400,   5.0979, 124.4086,\n",
      "        124.4086, 124.4086, 124.4086, 124.4086,  16.9400,  16.9400, 124.4086,\n",
      "         16.9400,  16.9400,   5.2026, 124.4086, 124.4086, 124.4086, 124.4086,\n",
      "        124.4086,  16.9400,  16.9400, 124.4086,  16.9400,  16.9400,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 124.4086,   5.2026,   5.2025, 124.4086,   5.2026,\n",
      "          5.2025, 124.4086,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        124.4086, 124.4086, 124.4086, 124.4086,  16.9400,  16.9400,  16.9400,\n",
      "         16.9400, 124.4086, 124.4086, 124.4086,  16.9400,  16.9400,  16.9400,\n",
      "         16.9400,   5.2026,  16.9400,  16.9400,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 47 was 88.0%\n",
      "tensor([2.1176e-22, 5.8764e-06, 5.3346e-06, 4.7776e-06, 4.2058e-06, 4.6988e-08,\n",
      "        3.7630e-08, 3.0948e-08, 1.3883e-07, 9.5979e-06, 9.2718e-06, 8.9841e-06,\n",
      "        2.7638e-03, 2.3251e-03, 2.2519e-03, 8.9923e-06, 8.7059e-06, 1.9730e-03,\n",
      "        1.9075e-03, 7.8633e-01, 7.3906e-01, 2.9130e+00, 2.9606e+00, 8.3847e-06,\n",
      "        1.8253e-03, 6.9017e-01, 3.0102e+00, 6.5232e-01, 3.0491e+00, 8.3942e-01,\n",
      "        8.8054e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 73.8262,  80.7392,  88.7203,  94.6202,   5.0944,   5.0948,   5.0939,\n",
      "        125.0879, 125.0879, 125.0879,   5.0943,   5.0953, 125.0879, 125.0879,\n",
      "        125.0879, 125.0879, 125.0879,  17.0252,  17.0252,   5.0937, 125.0879,\n",
      "        125.0879, 125.0879, 125.0879, 125.0879,  17.0252,  17.0252, 125.0879,\n",
      "         17.0252,  17.0252,   5.2026, 125.0879, 125.0879, 125.0879, 125.0879,\n",
      "        125.0879,  17.0252,  17.0252, 125.0879,  17.0252,  17.0252,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 125.0879,   5.2026,   5.2025, 125.0879,   5.2026,\n",
      "          5.2025, 125.0879,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        125.0879, 125.0879, 125.0879, 125.0879,  17.0252,  17.0252,  17.0252,\n",
      "         17.0252, 125.0879, 125.0879, 125.0879,  17.0252,  17.0252,  17.0252,\n",
      "         17.0252,   5.2026,  17.0252,  17.0252,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 48 was 88.1%\n",
      "tensor([0.0000e+00, 5.8594e-06, 5.4923e-06, 6.0847e-06, 0.0000e+00, 4.5733e-08,\n",
      "        3.6503e-08, 3.0018e-08, 4.3643e-06, 9.5379e-06, 9.2076e-06, 8.9255e-06,\n",
      "        2.6857e-03, 2.2523e-03, 2.1828e-03, 8.9318e-06, 8.6418e-06, 1.9064e-03,\n",
      "        1.8417e-03, 7.8189e-01, 7.3472e-01, 2.8934e+00, 2.9408e+00, 8.3249e-06,\n",
      "        1.7632e-03, 6.8543e-01, 2.9909e+00, 6.4736e-01, 3.0299e+00, 8.3359e-01,\n",
      "        8.8132e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 74.0759,  81.1184,  89.2154,  95.1629,   5.0912,   5.0914,   5.0926,\n",
      "        125.7618, 125.7618, 125.7618,   5.0930,   5.0910, 125.7618, 125.7618,\n",
      "        125.7618, 125.7618, 125.7618,  17.1104,  17.1104,   5.0928, 125.7618,\n",
      "        125.7618, 125.7618, 125.7618, 125.7618,  17.1104,  17.1104, 125.7618,\n",
      "         17.1104,  17.1104,   5.2026, 125.7618, 125.7618, 125.7618, 125.7618,\n",
      "        125.7618,  17.1104,  17.1104, 125.7618,  17.1104,  17.1104,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 125.7618,   5.2026,   5.2025, 125.7618,   5.2026,\n",
      "          5.2025, 125.7618,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        125.7618, 125.7618, 125.7618, 125.7618,  17.1104,  17.1104,  17.1104,\n",
      "         17.1104, 125.7618, 125.7618, 125.7618,  17.1104,  17.1104,  17.1104,\n",
      "         17.1104,   5.2026,  17.1104,  17.1104,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 49 was 88.2%\n",
      "tensor([0.0000e+00, 5.8225e-06, 5.4073e-06, 5.9589e-06, 2.3717e-20, 4.4569e-08,\n",
      "        3.5434e-08, 2.9056e-08, 4.1313e-06, 9.4792e-06, 9.1525e-06, 8.8642e-06,\n",
      "        2.6154e-03, 2.1889e-03, 2.1189e-03, 8.8686e-06, 8.5864e-06, 1.8446e-03,\n",
      "        1.7833e-03, 7.7745e-01, 7.3031e-01, 2.8753e+00, 2.9226e+00, 8.2646e-06,\n",
      "        1.7054e-03, 6.8116e-01, 2.9724e+00, 6.4273e-01, 3.0117e+00, 8.2798e-01,\n",
      "        8.8206e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 74.3250,  81.4950,  89.7023,  95.6995,   5.0898,   5.0899,   5.0898,\n",
      "        126.4304, 126.4304, 126.4304,   5.0885,   5.0900, 126.4304, 126.4304,\n",
      "        126.4304, 126.4304, 126.4304,  17.1954,  17.1954,   5.0897, 126.4304,\n",
      "        126.4304, 126.4304, 126.4304, 126.4304,  17.1954,  17.1954, 126.4304,\n",
      "         17.1954,  17.1954,   5.2026, 126.4304, 126.4304, 126.4304, 126.4304,\n",
      "        126.4304,  17.1954,  17.1954, 126.4304,  17.1954,  17.1954,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 126.4304,   5.2026,   5.2025, 126.4304,   5.2026,\n",
      "          5.2025, 126.4304,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        126.4304, 126.4304, 126.4304, 126.4304,  17.1954,  17.1954,  17.1954,\n",
      "         17.1954, 126.4304, 126.4304, 126.4304,  17.1954,  17.1954,  17.1954,\n",
      "         17.1954,   5.2026,  17.1954,  17.1954,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 50 was 88.2%\n",
      "tensor([1.0588e-22, 3.4422e-06, 3.4584e-06, 3.5880e-06, 4.0295e-06, 6.3315e-08,\n",
      "        6.4299e-08, 7.2163e-08, 8.1349e-08, 2.9506e-06, 4.3703e-06, 5.4185e-06,\n",
      "        2.5398e-03, 2.1199e-03, 2.0536e-03, 5.4076e-06, 6.5903e-06, 1.7819e-03,\n",
      "        1.7214e-03, 7.7304e-01, 7.2620e-01, 2.8568e+00, 2.9038e+00, 8.3302e-06,\n",
      "        1.6462e-03, 6.7679e-01, 2.9538e+00, 6.3804e-01, 2.9934e+00, 8.2242e-01,\n",
      "        8.8281e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 74.5730,  81.8679,  90.1807,  96.2290,   5.0872,   5.0864,   5.0882,\n",
      "        127.0940, 127.0940, 127.0940,   5.0875,   5.0855, 127.0940, 127.0940,\n",
      "        127.0940, 127.0940, 127.0940,  17.2804,  17.2804,   5.0885, 127.0940,\n",
      "        127.0940, 127.0940, 127.0940, 127.0940,  17.2804,  17.2804, 127.0940,\n",
      "         17.2804,  17.2804,   5.2026, 127.0940, 127.0940, 127.0940, 127.0940,\n",
      "        127.0940,  17.2804,  17.2804, 127.0940,  17.2804,  17.2804,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 127.0940,   5.2026,   5.2025, 127.0940,   5.2026,\n",
      "          5.2025, 127.0940,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        127.0940, 127.0940, 127.0940, 127.0940,  17.2804,  17.2804,  17.2804,\n",
      "         17.2804, 127.0940, 127.0940, 127.0940,  17.2804,  17.2804,  17.2804,\n",
      "         17.2804,   5.2026,  17.2804,  17.2804,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 51 was 88.3%\n",
      "tensor([4.6581e-07, 2.8575e-06, 3.1867e-06, 3.4669e-06, 2.5758e-06, 2.9590e-08,\n",
      "        1.6821e-08, 6.1109e-09, 0.0000e+00, 1.7598e-06, 3.3822e-06, 4.7672e-06,\n",
      "        2.4672e-03, 2.0561e-03, 1.9900e-03, 4.8169e-06, 5.8584e-06, 1.7216e-03,\n",
      "        1.6638e-03, 7.6872e-01, 7.2201e-01, 2.8391e+00, 2.8859e+00, 8.2916e-06,\n",
      "        1.5900e-03, 6.7272e-01, 2.9358e+00, 6.3364e-01, 2.9757e+00, 8.1717e-01,\n",
      "        8.8352e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 74.8196,  82.2375,  90.6524,  96.7530,   5.0851,   5.0854,   5.0848,\n",
      "        127.7527, 127.7527, 127.7527,   5.0846,   5.0844, 127.7527, 127.7527,\n",
      "        127.7527, 127.7527, 127.7527,  17.3653,  17.3653,   5.0845, 127.7527,\n",
      "        127.7527, 127.7527, 127.7527, 127.7527,  17.3653,  17.3653, 127.7527,\n",
      "         17.3653,  17.3653,   5.2026, 127.7527, 127.7527, 127.7527, 127.7527,\n",
      "        127.7527,  17.3653,  17.3653, 127.7527,  17.3653,  17.3653,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 127.7527,   5.2026,   5.2025, 127.7527,   5.2026,\n",
      "          5.2025, 127.7527,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        127.7527, 127.7527, 127.7527, 127.7527,  17.3653,  17.3653,  17.3653,\n",
      "         17.3653, 127.7527, 127.7527, 127.7527,  17.3653,  17.3653,  17.3653,\n",
      "         17.3653,   5.2026,  17.3653,  17.3653,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 52 was 88.4%\n",
      "tensor([1.9358e-05, 5.2839e-06, 2.6719e-06, 0.0000e+00, 5.1907e-06, 4.0891e-08,\n",
      "        3.2127e-08, 2.6106e-08, 0.0000e+00, 9.3096e-06, 8.9809e-06, 8.7000e-06,\n",
      "        2.3982e-03, 1.9944e-03, 1.9323e-03, 8.6980e-06, 8.4136e-06, 1.6670e-03,\n",
      "        1.6108e-03, 7.6460e-01, 7.1788e-01, 2.8203e+00, 2.8672e+00, 8.0934e-06,\n",
      "        1.5407e-03, 6.6842e-01, 2.9174e+00, 6.2909e-01, 2.9577e+00, 8.1186e-01,\n",
      "        8.8426e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 75.0665,  82.6044,  91.1244,  97.2589,   5.0813,   5.0810,   5.0828,\n",
      "        128.4066, 128.4066, 128.4066,   5.0827,   5.0836, 128.4066, 128.4066,\n",
      "        128.4066, 128.4066, 128.4066,  17.4502,  17.4502,   5.0831, 128.4066,\n",
      "        128.4066, 128.4066, 128.4066, 128.4066,  17.4502,  17.4502, 128.4066,\n",
      "         17.4502,  17.4502,   5.2026, 128.4066, 128.4066, 128.4066, 128.4066,\n",
      "        128.4066,  17.4502,  17.4502, 128.4066,  17.4502,  17.4502,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 128.4066,   5.2026,   5.2025, 128.4066,   5.2026,\n",
      "          5.2025, 128.4066,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        128.4066, 128.4066, 128.4066, 128.4066,  17.4502,  17.4502,  17.4502,\n",
      "         17.4502, 128.4066, 128.4066, 128.4066,  17.4502,  17.4502,  17.4502,\n",
      "         17.4502,   5.2026,  17.4502,  17.4502,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 53 was 88.4%\n",
      "tensor([0.0000e+00, 5.4768e-06, 4.3019e-06, 3.6264e-06, 4.4308e-06, 3.9913e-08,\n",
      "        3.1323e-08, 2.5517e-08, 4.5321e-08, 9.2598e-06, 8.9310e-06, 8.6494e-06,\n",
      "        2.3321e-03, 1.9349e-03, 1.8744e-03, 8.6432e-06, 8.3618e-06, 1.6125e-03,\n",
      "        1.5585e-03, 7.6018e-01, 7.1405e-01, 2.8035e+00, 2.8499e+00, 8.0418e-06,\n",
      "        1.4903e-03, 6.6440e-01, 2.9003e+00, 6.2511e-01, 2.9406e+00, 8.0681e-01,\n",
      "        8.8495e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 75.3121,  82.9684,  91.5914,  97.7588,   5.0793,   5.0802,   5.0807,\n",
      "        129.0559, 129.0559, 129.0559,   5.0806,   5.0793, 129.0559, 129.0559,\n",
      "        129.0559, 129.0559, 129.0559,  17.5349,  17.5349,   5.0800, 129.0559,\n",
      "        129.0559, 129.0559, 129.0559, 129.0559,  17.5349,  17.5349, 129.0559,\n",
      "         17.5349,  17.5349,   5.2026, 129.0559, 129.0559, 129.0559, 129.0559,\n",
      "        129.0559,  17.5349,  17.5349, 129.0559,  17.5349,  17.5349,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 129.0559,   5.2026,   5.2025, 129.0559,   5.2026,\n",
      "          5.2025, 129.0559,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        129.0559, 129.0559, 129.0559, 129.0559,  17.5349,  17.5349,  17.5349,\n",
      "         17.5349, 129.0559, 129.0559, 129.0559,  17.5349,  17.5349,  17.5349,\n",
      "         17.5349,   5.2026,  17.5349,  17.5349,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 54 was 88.5%\n",
      "tensor([2.6975e-05, 2.1096e-05, 5.7719e-05, 6.8375e-05, 0.0000e+00, 3.3858e-08,\n",
      "        2.0352e-08, 0.0000e+00, 0.0000e+00, 8.8901e-06, 8.6516e-06, 8.4355e-06,\n",
      "        2.2713e-03, 1.8800e-03, 1.8203e-03, 8.4385e-06, 8.2151e-06, 1.5608e-03,\n",
      "        1.5087e-03, 7.5610e-01, 7.0993e-01, 2.7867e+00, 2.8331e+00, 7.9918e-06,\n",
      "        1.4421e-03, 6.6041e-01, 2.8832e+00, 6.2071e-01, 2.9237e+00, 8.0168e-01,\n",
      "        8.8563e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 75.5425,  83.3325,  92.0268,  98.3920,   5.0776,   5.0775,   5.0760,\n",
      "        129.7008, 129.7008, 129.7008,   5.0772,   5.0784, 129.7008, 129.7008,\n",
      "        129.7008, 129.7008, 129.7008,  17.6196,  17.6196,   5.0781, 129.7008,\n",
      "        129.7008, 129.7008, 129.7008, 129.7008,  17.6196,  17.6196, 129.7008,\n",
      "         17.6196,  17.6196,   5.2026, 129.7008, 129.7008, 129.7008, 129.7008,\n",
      "        129.7008,  17.6196,  17.6196, 129.7008,  17.6196,  17.6196,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 129.7008,   5.2026,   5.2025, 129.7008,   5.2026,\n",
      "          5.2025, 129.7008,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        129.7008, 129.7008, 129.7008, 129.7008,  17.6196,  17.6196,  17.6196,\n",
      "         17.6196, 129.7008, 129.7008, 129.7008,  17.6196,  17.6196,  17.6196,\n",
      "         17.6196,   5.2026,  17.6196,  17.6196,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 55 was 88.6%\n",
      "tensor([1.3570e-05, 1.8366e-05, 3.8220e-05, 3.7112e-05, 0.0000e+00, 4.1666e-08,\n",
      "        2.3337e-08, 0.0000e+00, 0.0000e+00, 8.0453e-06, 8.0207e-06, 7.9466e-06,\n",
      "        2.2093e-03, 1.8260e-03, 1.7679e-03, 7.9865e-06, 7.9380e-06, 1.5126e-03,\n",
      "        1.4596e-03, 7.5251e-01, 7.0553e-01, 2.7682e+00, 2.8154e+00, 7.9470e-06,\n",
      "        1.3954e-03, 6.5603e-01, 2.8654e+00, 6.1626e-01, 2.9060e+00, 7.9626e-01,\n",
      "        8.8635e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 75.7831,  83.6923,  92.4776,  98.9114,   5.0747,   5.0753,   5.0751,\n",
      "        130.3414, 130.3414, 130.3414,   5.0763,   5.0739, 130.3414, 130.3414,\n",
      "        130.3414, 130.3414, 130.3414,  17.7042,  17.7042,   5.0748, 130.3414,\n",
      "        130.3414, 130.3414, 130.3414, 130.3414,  17.7042,  17.7042, 130.3414,\n",
      "         17.7042,  17.7042,   5.2026, 130.3414, 130.3414, 130.3414, 130.3414,\n",
      "        130.3414,  17.7042,  17.7042, 130.3414,  17.7042,  17.7042,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 130.3414,   5.2026,   5.2025, 130.3414,   5.2026,\n",
      "          5.2025, 130.3414,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        130.3414, 130.3414, 130.3414, 130.3414,  17.7042,  17.7042,  17.7042,\n",
      "         17.7042, 130.3414, 130.3414, 130.3414,  17.7042,  17.7042,  17.7042,\n",
      "         17.7042,   5.2026,  17.7042,  17.7042,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 56 was 88.7%\n",
      "tensor([0.0000e+00, 4.3371e-06, 6.0063e-06, 1.6941e-21, 1.4754e-05, 2.4097e-07,\n",
      "        0.0000e+00, 1.8365e-07, 0.0000e+00, 9.0978e-06, 8.7708e-06, 8.4839e-06,\n",
      "        2.1755e-03, 1.7987e-03, 1.7418e-03, 8.4808e-06, 8.1977e-06, 1.4867e-03,\n",
      "        1.4374e-03, 7.4863e-01, 7.0134e-01, 2.7506e+00, 2.7980e+00, 7.8784e-06,\n",
      "        1.3759e-03, 6.5202e-01, 2.8480e+00, 6.1200e-01, 2.8888e+00, 7.9120e-01,\n",
      "        8.8705e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 76.0242,  84.0486,  92.9258,  99.4055,   5.0728,   5.0721,   5.0725,\n",
      "        130.9777, 130.9777, 130.9777,   5.0718,   5.0731, 130.9777, 130.9777,\n",
      "        130.9777, 130.9777, 130.9777,  17.7887,  17.7887,   5.0734, 130.9777,\n",
      "        130.9777, 130.9777, 130.9777, 130.9777,  17.7887,  17.7887, 130.9777,\n",
      "         17.7887,  17.7887,   5.2026, 130.9777, 130.9777, 130.9777, 130.9777,\n",
      "        130.9777,  17.7887,  17.7887, 130.9777,  17.7887,  17.7887,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 130.9777,   5.2026,   5.2025, 130.9777,   5.2026,\n",
      "          5.2025, 130.9777,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        130.9777, 130.9777, 130.9777, 130.9777,  17.7887,  17.7887,  17.7887,\n",
      "         17.7887, 130.9777, 130.9777, 130.9777,  17.7887,  17.7887,  17.7887,\n",
      "         17.7887,   5.2026,  17.7887,  17.7887,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 57 was 88.7%\n",
      "tensor([0.0000e+00, 4.3589e-06, 5.9781e-06, 2.7105e-20, 1.4577e-05, 2.3421e-07,\n",
      "        0.0000e+00, 1.7795e-07, 0.0000e+00, 9.0438e-06, 8.7198e-06, 8.4366e-06,\n",
      "        2.1173e-03, 1.7474e-03, 1.6933e-03, 8.4321e-06, 8.1454e-06, 1.4413e-03,\n",
      "        1.3927e-03, 7.4446e-01, 6.9770e-01, 2.7346e+00, 2.7816e+00, 7.8262e-06,\n",
      "        1.3327e-03, 6.4830e-01, 2.8316e+00, 6.0806e-01, 2.8726e+00, 7.8638e-01,\n",
      "        8.8770e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 76.2645,  84.4020,  93.3684,  99.8942,   5.0695,   5.0706,   5.0710,\n",
      "        131.6100, 131.6100, 131.6100,   5.0710,   5.0698, 131.6100, 131.6100,\n",
      "        131.6100, 131.6100, 131.6100,  17.8732,  17.8732,   5.0691, 131.6100,\n",
      "        131.6100, 131.6100, 131.6100, 131.6100,  17.8732,  17.8732, 131.6100,\n",
      "         17.8732,  17.8732,   5.2026, 131.6100, 131.6100, 131.6100, 131.6100,\n",
      "        131.6100,  17.8732,  17.8732, 131.6100,  17.8732,  17.8732,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 131.6100,   5.2026,   5.2025, 131.6100,   5.2026,\n",
      "          5.2025, 131.6100,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        131.6100, 131.6100, 131.6100, 131.6100,  17.8732,  17.8732,  17.8732,\n",
      "         17.8732, 131.6100, 131.6100, 131.6100,  17.8732,  17.8732,  17.8732,\n",
      "         17.8732,   5.2026,  17.8732,  17.8732,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 58 was 88.8%\n",
      "tensor([1.5149e-05, 1.4738e-19, 2.0544e-06, 1.4404e-05, 6.6970e-06, 3.0859e-06,\n",
      "        0.0000e+00, 2.3381e-06, 0.0000e+00, 9.0150e-06, 8.6867e-06, 8.4012e-06,\n",
      "        2.0659e-03, 1.7015e-03, 1.6481e-03, 8.3949e-06, 8.1125e-06, 1.3990e-03,\n",
      "        1.3525e-03, 7.4075e-01, 6.9397e-01, 2.7186e+00, 2.7656e+00, 7.7952e-06,\n",
      "        1.2948e-03, 6.4463e-01, 2.8155e+00, 6.0412e-01, 2.8568e+00, 7.8167e-01,\n",
      "        8.8834e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 76.5049,  84.7544,  93.8080, 100.3779,   5.0682,   5.0681,   5.0666,\n",
      "        132.2383, 132.2383, 132.2383,   5.0676,   5.0678, 132.2383, 132.2383,\n",
      "        132.2383, 132.2383, 132.2383,  17.9576,  17.9576,   5.0682, 132.2383,\n",
      "        132.2383, 132.2383, 132.2383, 132.2383,  17.9576,  17.9576, 132.2383,\n",
      "         17.9576,  17.9576,   5.2026, 132.2383, 132.2383, 132.2383, 132.2383,\n",
      "        132.2383,  17.9576,  17.9576, 132.2383,  17.9576,  17.9576,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 132.2383,   5.2026,   5.2025, 132.2383,   5.2026,\n",
      "          5.2025, 132.2383,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        132.2383, 132.2383, 132.2383, 132.2383,  17.9576,  17.9576,  17.9576,\n",
      "         17.9576, 132.2383, 132.2383, 132.2383,  17.9576,  17.9576,  17.9576,\n",
      "         17.9576,   5.2026,  17.9576,  17.9576,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 59 was 88.8%\n",
      "tensor([1.4620e-05, 0.0000e+00, 1.9946e-06, 1.4666e-05, 7.3778e-06, 2.9776e-06,\n",
      "        0.0000e+00, 2.2499e-06, 0.0000e+00, 8.9626e-06, 8.6373e-06, 8.3573e-06,\n",
      "        2.0126e-03, 1.6553e-03, 1.6042e-03, 8.3480e-06, 8.0633e-06, 1.3584e-03,\n",
      "        1.3124e-03, 7.3687e-01, 6.9026e-01, 2.7029e+00, 2.7497e+00, 7.7443e-06,\n",
      "        1.2560e-03, 6.4093e-01, 2.7996e+00, 6.0035e-01, 2.8410e+00, 7.7697e-01,\n",
      "        8.8898e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 76.7441,  85.1040,  94.2422, 100.8569,   5.0632,   5.0654,   5.0658,\n",
      "        132.8628, 132.8628, 132.8628,   5.0668,   5.0658, 132.8628, 132.8628,\n",
      "        132.8628, 132.8628, 132.8628,  18.0419,  18.0419,   5.0650, 132.8628,\n",
      "        132.8628, 132.8628, 132.8628, 132.8628,  18.0419,  18.0419, 132.8628,\n",
      "         18.0419,  18.0419,   5.2026, 132.8628, 132.8628, 132.8628, 132.8628,\n",
      "        132.8628,  18.0419,  18.0419, 132.8628,  18.0419,  18.0419,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 132.8628,   5.2026,   5.2025, 132.8628,   5.2026,\n",
      "          5.2025, 132.8628,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        132.8628, 132.8628, 132.8628, 132.8628,  18.0419,  18.0419,  18.0419,\n",
      "         18.0419, 132.8628, 132.8628, 132.8628,  18.0419,  18.0419,  18.0419,\n",
      "         18.0419,   5.2026,  18.0419,  18.0419,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 60 was 88.9%\n",
      "tensor([1.4226e-05, 7.2845e-20, 1.9548e-06, 1.4826e-05, 7.2033e-06, 2.8955e-06,\n",
      "        0.0000e+00, 2.1816e-06, 0.0000e+00, 8.9121e-06, 8.5829e-06, 8.2997e-06,\n",
      "        1.9617e-03, 1.6101e-03, 1.5597e-03, 8.2901e-06, 8.0093e-06, 1.3170e-03,\n",
      "        1.2733e-03, 7.3310e-01, 6.8661e-01, 2.6876e+00, 2.7343e+00, 7.6935e-06,\n",
      "        1.2192e-03, 6.3733e-01, 2.7841e+00, 5.9673e-01, 2.8255e+00, 7.7249e-01,\n",
      "        8.8960e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 76.9819,  85.4508,  94.6714, 101.3318,   5.0618,   5.0634,   5.0631,\n",
      "        133.4835, 133.4835, 133.4835,   5.0623,   5.0626, 133.4835, 133.4835,\n",
      "        133.4835, 133.4835, 133.4835,  18.1261,  18.1261,   5.0640, 133.4835,\n",
      "        133.4835, 133.4835, 133.4835, 133.4835,  18.1261,  18.1261, 133.4835,\n",
      "         18.1261,  18.1261,   5.2026, 133.4835, 133.4835, 133.4835, 133.4835,\n",
      "        133.4835,  18.1261,  18.1261, 133.4835,  18.1261,  18.1261,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 133.4835,   5.2026,   5.2025, 133.4835,   5.2026,\n",
      "          5.2025, 133.4835,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        133.4835, 133.4835, 133.4835, 133.4835,  18.1261,  18.1261,  18.1261,\n",
      "         18.1261, 133.4835, 133.4835, 133.4835,  18.1261,  18.1261,  18.1261,\n",
      "         18.1261,   5.2026,  18.1261,  18.1261,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 61 was 89.0%\n",
      "tensor([1.2852e-06, 6.5949e-06, 1.1762e-06, 1.6941e-21, 1.0583e-05, 0.0000e+00,\n",
      "        1.3560e-07, 0.0000e+00, 1.1529e-07, 9.1741e-06, 8.8360e-06, 8.5467e-06,\n",
      "        1.9121e-03, 1.5677e-03, 1.5193e-03, 8.5369e-06, 8.2438e-06, 1.2793e-03,\n",
      "        1.2362e-03, 7.2926e-01, 6.8301e-01, 2.6726e+00, 2.7190e+00, 7.9138e-06,\n",
      "        1.1833e-03, 6.3399e-01, 2.7686e+00, 5.9301e-01, 2.8104e+00, 7.6798e-01,\n",
      "        8.9021e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 77.2193,  85.7963,  95.1009, 101.7944,   5.0605,   5.0601,   5.0611,\n",
      "        134.1006, 134.1006, 134.1006,   5.0608,   5.0605, 134.1006, 134.1006,\n",
      "        134.1006, 134.1006, 134.1006,  18.2103,  18.2103,   5.0598, 134.1006,\n",
      "        134.1006, 134.1006, 134.1006, 134.1006,  18.2103,  18.2103, 134.1006,\n",
      "         18.2103,  18.2103,   5.2026, 134.1006, 134.1006, 134.1006, 134.1006,\n",
      "        134.1006,  18.2103,  18.2103, 134.1006,  18.2103,  18.2103,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 134.1006,   5.2026,   5.2025, 134.1006,   5.2026,\n",
      "          5.2025, 134.1006,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        134.1006, 134.1006, 134.1006, 134.1006,  18.2103,  18.2103,  18.2103,\n",
      "         18.2103, 134.1006, 134.1006, 134.1006,  18.2103,  18.2103,  18.2103,\n",
      "         18.2103,   5.2026,  18.2103,  18.2103,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 62 was 89.0%\n",
      "tensor([0.0000e+00, 5.2226e-06, 7.0639e-06, 8.0125e-06, 1.6941e-21, 1.1537e-07,\n",
      "        0.0000e+00, 8.6421e-08, 0.0000e+00, 9.3021e-06, 8.9602e-06, 8.6631e-06,\n",
      "        1.8643e-03, 1.5253e-03, 1.4778e-03, 8.6502e-06, 8.3554e-06, 1.2411e-03,\n",
      "        1.1999e-03, 7.2560e-01, 6.7965e-01, 2.6577e+00, 2.7039e+00, 8.0221e-06,\n",
      "        1.1484e-03, 6.3039e-01, 2.7537e+00, 5.8938e-01, 2.7955e+00, 7.6354e-01,\n",
      "        8.9081e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 77.4556,  86.1386,  95.5248, 102.2546,   5.0585,   5.0587,   5.0567,\n",
      "        134.7142, 134.7142, 134.7142,   5.0575,   5.0580, 134.7142, 134.7142,\n",
      "        134.7142, 134.7142, 134.7142,  18.2944,  18.2944,   5.0589, 134.7142,\n",
      "        134.7142, 134.7142, 134.7142, 134.7142,  18.2944,  18.2944, 134.7142,\n",
      "         18.2944,  18.2944,   5.2026, 134.7142, 134.7142, 134.7142, 134.7142,\n",
      "        134.7142,  18.2944,  18.2944, 134.7142,  18.2944,  18.2944,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 134.7142,   5.2026,   5.2025, 134.7142,   5.2026,\n",
      "          5.2025, 134.7142,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        134.7142, 134.7142, 134.7142, 134.7142,  18.2944,  18.2944,  18.2944,\n",
      "         18.2944, 134.7142, 134.7142, 134.7142,  18.2944,  18.2944,  18.2944,\n",
      "         18.2944,   5.2026,  18.2944,  18.2944,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 63 was 89.1%\n",
      "tensor([0.0000e+00, 5.3186e-06, 4.3885e-06, 8.4009e-06, 0.0000e+00, 1.1356e-07,\n",
      "        9.5594e-08, 8.4833e-08, 0.0000e+00, 9.7781e-06, 9.4177e-06, 9.1113e-06,\n",
      "        1.8168e-03, 1.4843e-03, 1.4388e-03, 9.0944e-06, 8.7806e-06, 1.2054e-03,\n",
      "        1.1645e-03, 7.2201e-01, 6.7612e-01, 2.6432e+00, 2.6893e+00, 8.4266e-06,\n",
      "        1.1144e-03, 6.2707e-01, 2.7389e+00, 5.8591e-01, 2.7809e+00, 7.5926e-01,\n",
      "        8.9139e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 77.6910,  86.4771,  95.9432, 102.7140,   5.0553,   5.0553,   5.0558,\n",
      "        135.3243, 135.3243, 135.3243,   5.0566,   5.0560, 135.3243, 135.3243,\n",
      "        135.3243, 135.3243, 135.3243,  18.3785,  18.3785,   5.0546, 135.3243,\n",
      "        135.3243, 135.3243, 135.3243, 135.3243,  18.3785,  18.3785, 135.3243,\n",
      "         18.3785,  18.3785,   5.2026, 135.3243, 135.3243, 135.3243, 135.3243,\n",
      "        135.3243,  18.3785,  18.3785, 135.3243,  18.3785,  18.3785,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 135.3243,   5.2026,   5.2025, 135.3243,   5.2026,\n",
      "          5.2025, 135.3243,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        135.3243, 135.3243, 135.3243, 135.3243,  18.3785,  18.3785,  18.3785,\n",
      "         18.3785, 135.3243, 135.3243, 135.3243,  18.3785,  18.3785,  18.3785,\n",
      "         18.3785,   5.2026,  18.3785,  18.3785,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 64 was 89.1%\n",
      "tensor([1.1634e-05, 1.0549e-05, 1.0600e-05, 8.4703e-20, 1.9036e-05, 2.9224e-08,\n",
      "        0.0000e+00, 0.0000e+00, 1.5257e-06, 1.1675e-05, 1.1242e-05, 1.0869e-05,\n",
      "        1.7713e-03, 1.4441e-03, 1.3991e-03, 1.0848e-05, 1.0478e-05, 1.1691e-03,\n",
      "        1.1302e-03, 7.1843e-01, 6.7275e-01, 2.6288e+00, 2.6747e+00, 1.0059e-05,\n",
      "        1.0818e-03, 6.2358e-01, 2.7244e+00, 5.8249e-01, 2.7662e+00, 7.5501e-01,\n",
      "        8.9198e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 77.9255,  86.8093,  96.3558, 103.1766,   5.0539,   5.0533,   5.0532,\n",
      "        135.9311, 135.9311, 135.9311,   5.0522,   5.0528, 135.9311, 135.9311,\n",
      "        135.9311, 135.9311, 135.9311,  18.4625,  18.4625,   5.0536, 135.9311,\n",
      "        135.9311, 135.9311, 135.9311, 135.9311,  18.4625,  18.4625, 135.9311,\n",
      "         18.4625,  18.4625,   5.2026, 135.9311, 135.9311, 135.9311, 135.9311,\n",
      "        135.9311,  18.4625,  18.4625, 135.9311,  18.4625,  18.4625,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 135.9311,   5.2026,   5.2025, 135.9311,   5.2026,\n",
      "          5.2025, 135.9311,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        135.9311, 135.9311, 135.9311, 135.9311,  18.4625,  18.4625,  18.4625,\n",
      "         18.4625, 135.9311, 135.9311, 135.9311,  18.4625,  18.4625,  18.4625,\n",
      "         18.4625,   5.2026,  18.4625,  18.4625,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 65 was 89.2%\n",
      "tensor([1.6453e-05, 1.3468e-05, 1.3698e-05, 0.0000e+00, 2.6068e-05, 3.2621e-08,\n",
      "        0.0000e+00, 0.0000e+00, 2.1486e-06, 1.2977e-05, 1.2498e-05, 1.2085e-05,\n",
      "        1.7256e-03, 1.4054e-03, 1.3622e-03, 1.2064e-05, 1.1646e-05, 1.1354e-03,\n",
      "        1.0971e-03, 7.1487e-01, 6.6935e-01, 2.6145e+00, 2.6602e+00, 1.1172e-05,\n",
      "        1.0497e-03, 6.2032e-01, 2.7098e+00, 5.7895e-01, 2.7519e+00, 7.5078e-01,\n",
      "        8.9256e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 78.1625,  87.1905,  96.7731, 103.5823,   5.0488,   5.0507,   5.0518,\n",
      "        136.5346, 136.5346, 136.5346,   5.0513,   5.0514, 136.5346, 136.5346,\n",
      "        136.5346, 136.5346, 136.5346,  18.5464,  18.5464,   5.0505, 136.5346,\n",
      "        136.5346, 136.5346, 136.5346, 136.5346,  18.5464,  18.5464, 136.5346,\n",
      "         18.5464,  18.5464,   5.2026, 136.5346, 136.5346, 136.5346, 136.5346,\n",
      "        136.5346,  18.5464,  18.5464, 136.5346,  18.5464,  18.5464,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 136.5346,   5.2026,   5.2025, 136.5346,   5.2026,\n",
      "          5.2025, 136.5346,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        136.5346, 136.5346, 136.5346, 136.5346,  18.5464,  18.5464,  18.5464,\n",
      "         18.5464, 136.5346, 136.5346, 136.5346,  18.5464,  18.5464,  18.5464,\n",
      "         18.5464,   5.2026,  18.5464,  18.5464,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 66 was 89.3%\n",
      "tensor([1.7552e-05, 1.4599e-05, 1.5054e-05, 1.3044e-19, 2.8057e-05, 2.8949e-08,\n",
      "        0.0000e+00, 0.0000e+00, 2.2833e-06, 1.3259e-05, 1.2761e-05, 1.2339e-05,\n",
      "        1.6850e-03, 1.3707e-03, 1.3284e-03, 1.2308e-05, 1.1888e-05, 1.1034e-03,\n",
      "        1.0668e-03, 7.1096e-01, 6.6608e-01, 2.6010e+00, 2.6460e+00, 1.1410e-05,\n",
      "        1.0216e-03, 6.1734e-01, 2.6954e+00, 5.7574e-01, 2.7377e+00, 7.4671e-01,\n",
      "        8.9312e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 78.4001,  87.5818,  97.1872, 103.9708,   5.0474,   5.0486,   5.0474,\n",
      "        137.1349, 137.1349, 137.1349,   5.0485,   5.0483, 137.1349, 137.1349,\n",
      "        137.1349, 137.1349, 137.1349,  18.6303,  18.6303,   5.0496, 137.1349,\n",
      "        137.1349, 137.1349, 137.1349, 137.1349,  18.6303,  18.6303, 137.1349,\n",
      "         18.6303,  18.6303,   5.2026, 137.1349, 137.1349, 137.1349, 137.1349,\n",
      "        137.1349,  18.6303,  18.6303, 137.1349,  18.6303,  18.6303,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 137.1349,   5.2026,   5.2025, 137.1349,   5.2026,\n",
      "          5.2025, 137.1349,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        137.1349, 137.1349, 137.1349, 137.1349,  18.6303,  18.6303,  18.6303,\n",
      "         18.6303, 137.1349, 137.1349, 137.1349,  18.6303,  18.6303,  18.6303,\n",
      "         18.6303,   5.2026,  18.6303,  18.6303,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 67 was 89.3%\n",
      "tensor([2.1149e-05, 1.7191e-05, 1.8630e-05, 2.7105e-20, 3.3705e-05, 7.5981e-09,\n",
      "        0.0000e+00, 0.0000e+00, 2.7386e-06, 1.4167e-05, 1.3642e-05, 1.3199e-05,\n",
      "        1.6429e-03, 1.3365e-03, 1.2963e-03, 1.3155e-05, 1.2705e-05, 1.0726e-03,\n",
      "        1.0369e-03, 7.0712e-01, 6.6259e-01, 2.5876e+00, 2.6322e+00, 1.2192e-05,\n",
      "        9.9260e-04, 6.1446e-01, 2.6809e+00, 5.7256e-01, 2.7236e+00, 7.4269e-01,\n",
      "        8.9368e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 78.6410,  88.0006,  97.5976, 104.3250,   5.0459,   5.0451,   5.0461,\n",
      "        137.7321, 137.7321, 137.7321,   5.0463,   5.0463, 137.7321, 137.7321,\n",
      "        137.7321, 137.7321, 137.7321,  18.7141,  18.7141,   5.0454, 137.7321,\n",
      "        137.7321, 137.7321, 137.7321, 137.7321,  18.7141,  18.7141, 137.7321,\n",
      "         18.7141,  18.7141,   5.2026, 137.7321, 137.7321, 137.7321, 137.7321,\n",
      "        137.7321,  18.7141,  18.7141, 137.7321,  18.7141,  18.7141,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 137.7321,   5.2026,   5.2025, 137.7321,   5.2026,\n",
      "          5.2025, 137.7321,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        137.7321, 137.7321, 137.7321, 137.7321,  18.7141,  18.7141,  18.7141,\n",
      "         18.7141, 137.7321, 137.7321, 137.7321,  18.7141,  18.7141,  18.7141,\n",
      "         18.7141,   5.2026,  18.7141,  18.7141,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 68 was 89.4%\n",
      "tensor([0.0000e+00, 1.0824e-05, 6.3246e-06, 2.5411e-19, 1.6163e-05, 7.0860e-08,\n",
      "        2.0002e-06, 2.7042e-06, 0.0000e+00, 1.2815e-05, 1.2343e-05, 1.1943e-05,\n",
      "        1.6034e-03, 1.3045e-03, 1.2656e-03, 1.1894e-05, 1.1494e-05, 1.0422e-03,\n",
      "        1.0084e-03, 7.0316e-01, 6.5957e-01, 2.5746e+00, 2.6183e+00, 1.1034e-05,\n",
      "        9.6571e-04, 6.1159e-01, 2.6669e+00, 5.6935e-01, 2.7099e+00, 7.3870e-01,\n",
      "        8.9423e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 78.8746,  88.3474,  98.0024, 104.7450,   5.0438,   5.0443,   5.0434,\n",
      "        138.3263, 138.3263, 138.3263,   5.0429,   5.0419, 138.3263, 138.3263,\n",
      "        138.3263, 138.3263, 138.3263,  18.7978,  18.7978,   5.0439, 138.3263,\n",
      "        138.3263, 138.3263, 138.3263, 138.3263,  18.7978,  18.7978, 138.3263,\n",
      "         18.7978,  18.7978,   5.2026, 138.3263, 138.3263, 138.3263, 138.3263,\n",
      "        138.3263,  18.7978,  18.7978, 138.3263,  18.7978,  18.7978,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 138.3263,   5.2026,   5.2025, 138.3263,   5.2026,\n",
      "          5.2025, 138.3263,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        138.3263, 138.3263, 138.3263, 138.3263,  18.7978,  18.7978,  18.7978,\n",
      "         18.7978, 138.3263, 138.3263, 138.3263,  18.7978,  18.7978,  18.7978,\n",
      "         18.7978,   5.2026,  18.7978,  18.7978,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 69 was 89.4%\n",
      "tensor([0.0000e+00, 5.3848e-06, 4.7501e-06, 4.2242e-06, 4.6680e-06, 5.6639e-08,\n",
      "        4.6999e-08, 4.1632e-08, 0.0000e+00, 8.4790e-06, 8.1668e-06, 7.9054e-06,\n",
      "        1.5681e-03, 1.2752e-03, 1.2374e-03, 7.8711e-06, 7.6073e-06, 1.0160e-03,\n",
      "        9.8291e-04, 6.9983e-01, 6.5637e-01, 2.5616e+00, 2.6052e+00, 7.3004e-06,\n",
      "        9.4147e-04, 6.0879e-01, 2.6533e+00, 5.6616e-01, 2.6967e+00, 7.3479e-01,\n",
      "        8.9476e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 79.1064,  88.7267,  98.4256, 105.1046,   5.0405,   5.0398,   5.0421,\n",
      "        138.9176, 138.9176, 138.9176,   5.0415,   5.0410, 138.9176, 138.9176,\n",
      "        138.9176, 138.9176, 138.9176,  18.8815,  18.8815,   5.0409, 138.9176,\n",
      "        138.9176, 138.9176, 138.9176, 138.9176,  18.8815,  18.8815, 138.9176,\n",
      "         18.8815,  18.8815,   5.2026, 138.9176, 138.9176, 138.9176, 138.9176,\n",
      "        138.9176,  18.8815,  18.8815, 138.9176,  18.8815,  18.8815,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 138.9176,   5.2026,   5.2025, 138.9176,   5.2026,\n",
      "          5.2025, 138.9176,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        138.9176, 138.9176, 138.9176, 138.9176,  18.8815,  18.8815,  18.8815,\n",
      "         18.8815, 138.9176, 138.9176, 138.9176,  18.8815,  18.8815,  18.8815,\n",
      "         18.8815,   5.2026,  18.8815,  18.8815,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 70 was 89.5%\n",
      "tensor([1.8198e-05, 1.7508e-05, 2.0502e-05, 0.0000e+00, 3.0768e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.2561e-06, 1.2448e-05, 1.1989e-05, 1.1599e-05,\n",
      "        1.5292e-03, 1.2420e-03, 1.2051e-03, 1.1536e-05, 1.1156e-05, 9.8571e-04,\n",
      "        9.5475e-04, 6.9583e-01, 6.5345e-01, 2.5490e+00, 2.5915e+00, 1.0705e-05,\n",
      "        9.1441e-04, 6.0591e-01, 2.6396e+00, 5.6314e-01, 2.6832e+00, 7.3098e-01,\n",
      "        8.9530e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 79.3608,  89.6736,  99.0074, 104.6970,   5.0379,   5.0387,   5.0393,\n",
      "        139.5059, 139.5059, 139.5059,   5.0373,   5.0392, 139.5059, 139.5059,\n",
      "        139.5059, 139.5059, 139.5059,  18.9651,  18.9651,   5.0402, 139.5059,\n",
      "        139.5059, 139.5059, 139.5059, 139.5059,  18.9651,  18.9651, 139.5059,\n",
      "         18.9651,  18.9651,   5.2026, 139.5059, 139.5059, 139.5059, 139.5059,\n",
      "        139.5059,  18.9651,  18.9651, 139.5059,  18.9651,  18.9651,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 139.5059,   5.2026,   5.2025, 139.5059,   5.2026,\n",
      "          5.2025, 139.5059,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        139.5059, 139.5059, 139.5059, 139.5059,  18.9651,  18.9651,  18.9651,\n",
      "         18.9651, 139.5059, 139.5059, 139.5059,  18.9651,  18.9651,  18.9651,\n",
      "         18.9651,   5.2026,  18.9651,  18.9651,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 71 was 89.5%\n",
      "tensor([0.0000e+00, 4.2931e-06, 2.9991e-06, 0.0000e+00, 1.3891e-05, 1.8298e-07,\n",
      "        1.4953e-07, 1.3302e-07, 0.0000e+00, 8.3750e-06, 8.0781e-06, 7.8621e-06,\n",
      "        1.4989e-03, 1.2285e-03, 1.1984e-03, 7.7634e-06, 7.5432e-06, 9.6011e-04,\n",
      "        9.3379e-04, 6.8766e-01, 6.5195e-01, 2.5438e+00, 2.5797e+00, 7.2533e-06,\n",
      "        8.9545e-04, 6.0678e-01, 2.6254e+00, 5.6130e-01, 2.6717e+00, 7.2822e-01,\n",
      "        8.9573e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 79.5897,  89.9864,  99.3960, 105.1354,   5.0358,   5.0366,   5.0360,\n",
      "        140.0915, 140.0915, 140.0915,   5.0364,   5.0371, 140.0915, 140.0915,\n",
      "        140.0915, 140.0915, 140.0915,  19.0487,  19.0487,   5.0358, 140.0915,\n",
      "        140.0915, 140.0915, 140.0915, 140.0915,  19.0487,  19.0487, 140.0915,\n",
      "         19.0487,  19.0487,   5.2026, 140.0915, 140.0915, 140.0915, 140.0915,\n",
      "        140.0915,  19.0487,  19.0487, 140.0915,  19.0487,  19.0487,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 140.0915,   5.2026,   5.2025, 140.0915,   5.2026,\n",
      "          5.2025, 140.0915,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        140.0915, 140.0915, 140.0915, 140.0915,  19.0487,  19.0487,  19.0487,\n",
      "         19.0487, 140.0915, 140.0915, 140.0915,  19.0487,  19.0487,  19.0487,\n",
      "         19.0487,   5.2026,  19.0487,  19.0487,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 72 was 89.6%\n",
      "tensor([8.1446e-06, 9.8798e-06, 9.5647e-06, 1.8635e-20, 1.6353e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.0016e-06, 9.9558e-06, 9.5981e-06, 9.3412e-06,\n",
      "        1.4648e-03, 1.1978e-03, 1.1686e-03, 9.2213e-06, 8.9569e-06, 9.3462e-04,\n",
      "        9.0879e-04, 6.8471e-01, 6.4885e-01, 2.5305e+00, 2.5665e+00, 8.6148e-06,\n",
      "        8.7187e-04, 6.0353e-01, 2.6124e+00, 5.5821e-01, 2.6586e+00, 7.2436e-01,\n",
      "        8.9626e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 79.8219,  90.2709,  99.7626, 105.6107,   5.0343,   5.0333,   5.0339,\n",
      "        140.6743, 140.6743, 140.6743,   5.0338,   5.0326, 140.6743, 140.6743,\n",
      "        140.6743, 140.6743, 140.6743,  19.1322,  19.1322,   5.0349, 140.6743,\n",
      "        140.6743, 140.6743, 140.6743, 140.6743,  19.1322,  19.1322, 140.6743,\n",
      "         19.1322,  19.1322,   5.2026, 140.6743, 140.6743, 140.6743, 140.6743,\n",
      "        140.6743,  19.1322,  19.1322, 140.6743,  19.1322,  19.1322,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 140.6743,   5.2026,   5.2025, 140.6743,   5.2026,\n",
      "          5.2025, 140.6743,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        140.6743, 140.6743, 140.6743, 140.6743,  19.1322,  19.1322,  19.1322,\n",
      "         19.1322, 140.6743, 140.6743, 140.6743,  19.1322,  19.1322,  19.1322,\n",
      "         19.1322,   5.2026,  19.1322,  19.1322,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 73 was 89.6%\n",
      "tensor([2.0775e-05, 1.8441e-05, 2.0391e-05, 1.5247e-19, 3.6963e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.4574e-06, 1.2389e-05, 1.1951e-05, 1.1619e-05,\n",
      "        1.4276e-03, 1.1665e-03, 1.1370e-03, 1.1473e-05, 1.1144e-05, 9.0843e-04,\n",
      "        8.8342e-04, 6.8179e-01, 6.4553e-01, 2.5173e+00, 2.5537e+00, 1.0700e-05,\n",
      "        8.4668e-04, 6.0037e-01, 2.5994e+00, 5.5511e-01, 2.6455e+00, 7.2058e-01,\n",
      "        8.9678e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 80.0574,  90.6053, 100.1275, 106.0350,   5.0302,   5.0324,   5.0313,\n",
      "        141.2545, 141.2545, 141.2545,   5.0318,   5.0317, 141.2545, 141.2545,\n",
      "        141.2545, 141.2545, 141.2545,  19.2156,  19.2156,   5.0305, 141.2545,\n",
      "        141.2545, 141.2545, 141.2545, 141.2545,  19.2156,  19.2156, 141.2545,\n",
      "         19.2156,  19.2156,   5.2026, 141.2545, 141.2545, 141.2545, 141.2545,\n",
      "        141.2545,  19.2156,  19.2156, 141.2545,  19.2156,  19.2156,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 141.2545,   5.2026,   5.2025, 141.2545,   5.2026,\n",
      "          5.2025, 141.2545,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        141.2545, 141.2545, 141.2545, 141.2545,  19.2156,  19.2156,  19.2156,\n",
      "         19.2156, 141.2545, 141.2545, 141.2545,  19.2156,  19.2156,  19.2156,\n",
      "         19.2156,   5.2026,  19.2156,  19.2156,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.3044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 74 was 90.0%\n",
      "tensor([1.1372e-04, 2.3673e-04, 7.2515e-04, 1.2535e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.6008e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.3104e-04, 3.8948e-05, 2.1684e-19, 0.0000e+00, 0.0000e+00, 5.1359e-07,\n",
      "        0.0000e+00, 6.4619e-01, 6.1132e-01, 2.4244e+00, 2.4599e+00, 8.5132e-06,\n",
      "        0.0000e+00, 5.6848e-01, 2.5026e+00, 5.2517e-01, 2.5457e+00, 7.2019e-01,\n",
      "        9.0067e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 80.2585,  90.9002, 100.4919, 106.4483,   5.0287,   5.0280,   5.0302,\n",
      "        141.8321, 141.8321, 141.8321,   5.0287,   5.0303, 141.8321, 141.8321,\n",
      "        141.8321, 141.8321, 141.8321,  19.2990,  19.2990,   5.0280, 141.8321,\n",
      "        141.8321, 141.8321, 141.8321, 141.8321,  19.2990,  19.2990, 141.8321,\n",
      "         19.2990,  19.2990,   5.2026, 141.8321, 141.8321, 141.8321, 141.8321,\n",
      "        141.8321,  19.2990,  19.2990, 141.8321,  19.2990,  19.2990,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 141.8321,   5.2026,   5.2025, 141.8321,   5.2026,\n",
      "          5.2025, 141.8321,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        141.8321, 141.8321, 141.8321, 141.8321,  19.2990,  19.2990,  19.2990,\n",
      "         19.2990, 141.8321, 141.8321, 141.8321,  19.2990,  19.2990,  19.2990,\n",
      "         19.2990,   5.2026,  19.2990,  19.2990,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 75 was 90.1%\n",
      "tensor([1.1357e-04, 1.8169e-04, 7.2557e-04, 1.2155e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.4129e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.2921e-04, 3.8435e-05, 4.3368e-19, 0.0000e+00, 0.0000e+00, 5.0352e-07,\n",
      "        0.0000e+00, 6.4341e-01, 6.0897e-01, 2.4133e+00, 2.4483e+00, 1.1639e-05,\n",
      "        0.0000e+00, 5.6588e-01, 2.4911e+00, 5.2262e-01, 2.5340e+00, 7.1672e-01,\n",
      "        9.0113e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 80.4606,  91.1947, 100.8576, 106.8504,   5.0267,   5.0271,   5.0278,\n",
      "        142.4071, 142.4071, 142.4071,   5.0261,   5.0269, 142.4071, 142.4071,\n",
      "        142.4071, 142.4071, 142.4071,  19.3824,  19.3824,   5.0252, 142.4071,\n",
      "        142.4071, 142.4071, 142.4071, 142.4071,  19.3824,  19.3824, 142.4071,\n",
      "         19.3824,  19.3824,   5.2026, 142.4071, 142.4071, 142.4071, 142.4071,\n",
      "        142.4071,  19.3824,  19.3824, 142.4071,  19.3824,  19.3824,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 142.4071,   5.2026,   5.2025, 142.4071,   5.2026,\n",
      "          5.2025, 142.4071,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        142.4071, 142.4071, 142.4071, 142.4071,  19.3824,  19.3824,  19.3824,\n",
      "         19.3824, 142.4071, 142.4071, 142.4071,  19.3824,  19.3824,  19.3824,\n",
      "         19.3824,   5.2026,  19.3824,  19.3824,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 76 was 89.8%\n",
      "tensor([1.1416e-06, 5.4427e-06, 5.0081e-06, 8.2153e-06, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 6.9943e-08, 7.5825e-06, 7.4629e-06, 7.3598e-06,\n",
      "        1.3411e-03, 1.0907e-03, 1.0630e-03, 7.3150e-06, 7.2030e-06, 8.4344e-04,\n",
      "        8.1990e-04, 6.7303e-01, 6.3695e-01, 2.4818e+00, 2.5179e+00, 7.0781e-06,\n",
      "        7.8635e-04, 5.9199e-01, 2.5633e+00, 5.4648e-01, 2.6095e+00, 7.0992e-01,\n",
      "        8.9822e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 80.6933,  91.5036, 101.2451, 107.2371,   5.0256,   5.0235,   5.0225,\n",
      "        142.9796, 142.9796, 142.9796,   5.0245,   5.0234, 142.9796, 142.9796,\n",
      "        142.9796, 142.9796, 142.9796,  19.4657,  19.4657,   5.0255, 142.9796,\n",
      "        142.9796, 142.9796, 142.9796, 142.9796,  19.4657,  19.4657, 142.9796,\n",
      "         19.4657,  19.4657,   5.2026, 142.9796, 142.9796, 142.9796, 142.9796,\n",
      "        142.9796,  19.4657,  19.4657, 142.9796,  19.4657,  19.4657,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 142.9796,   5.2026,   5.2025, 142.9796,   5.2026,\n",
      "          5.2025, 142.9796,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        142.9796, 142.9796, 142.9796, 142.9796,  19.4657,  19.4657,  19.4657,\n",
      "         19.4657, 142.9796, 142.9796, 142.9796,  19.4657,  19.4657,  19.4657,\n",
      "         19.4657,   5.2026,  19.4657,  19.4657,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0837, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 77 was 89.8%\n",
      "tensor([4.1398e-05, 9.2822e-06, 2.0628e-05, 1.3030e-05, 3.2742e-05, 1.1784e-07,\n",
      "        3.8353e-08, 6.0815e-06, 0.0000e+00, 0.0000e+00, 1.7130e-06, 2.7994e-06,\n",
      "        1.3089e-03, 1.0640e-03, 1.0371e-03, 3.8616e-06, 4.8092e-06, 8.2143e-04,\n",
      "        7.9841e-04, 6.7000e-01, 6.3399e-01, 2.4699e+00, 2.5060e+00, 7.1600e-06,\n",
      "        7.6494e-04, 5.8910e-01, 2.5512e+00, 5.4389e-01, 2.5972e+00, 7.0647e-01,\n",
      "        8.9870e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 80.9307,  91.8143, 101.6327, 107.6020,   5.0219,   5.0218,   5.0206,\n",
      "        143.5496, 143.5496, 143.5496,   5.0216,   5.0205, 143.5496, 143.5496,\n",
      "        143.5496, 143.5496, 143.5496,  19.5489,  19.5489,   5.0239, 143.5496,\n",
      "        143.5496, 143.5496, 143.5496, 143.5496,  19.5489,  19.5489, 143.5496,\n",
      "         19.5489,  19.5489,   5.2026, 143.5496, 143.5496, 143.5496, 143.5496,\n",
      "        143.5496,  19.5489,  19.5489, 143.5496,  19.5489,  19.5489,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 143.5496,   5.2026,   5.2025, 143.5496,   5.2026,\n",
      "          5.2025, 143.5496,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        143.5496, 143.5496, 143.5496, 143.5496,  19.5489,  19.5489,  19.5489,\n",
      "         19.5489, 143.5496, 143.5496, 143.5496,  19.5489,  19.5489,  19.5489,\n",
      "         19.5489,   5.2026,  19.5489,  19.5489,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 78 was 89.9%\n",
      "tensor([8.4360e-07, 4.6354e-06, 5.1287e-06, 0.0000e+00, 7.1486e-06, 8.6076e-08,\n",
      "        0.0000e+00, 6.1640e-08, 0.0000e+00, 7.3109e-06, 7.2365e-06, 7.1410e-06,\n",
      "        1.2810e-03, 1.0397e-03, 1.0137e-03, 7.1367e-06, 7.0304e-06, 8.0125e-04,\n",
      "        7.7899e-04, 6.6668e-01, 6.3111e-01, 2.4586e+00, 2.4943e+00, 7.0064e-06,\n",
      "        7.4625e-04, 5.8658e-01, 2.5392e+00, 5.4132e-01, 2.5852e+00, 7.0308e-01,\n",
      "        8.9917e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 81.1623,  92.1208, 102.0136, 107.9839,   5.0187,   5.0189,   5.0186,\n",
      "        144.1173, 144.1173, 144.1173,   5.0199,   5.0189, 144.1173, 144.1173,\n",
      "        144.1173, 144.1173, 144.1173,  19.6321,  19.6321,   5.0206, 144.1173,\n",
      "        144.1173, 144.1173, 144.1173, 144.1173,  19.6321,  19.6321, 144.1173,\n",
      "         19.6321,  19.6321,   5.2026, 144.1173, 144.1173, 144.1173, 144.1173,\n",
      "        144.1173,  19.6321,  19.6321, 144.1173,  19.6321,  19.6321,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 144.1173,   5.2026,   5.2025, 144.1173,   5.2026,\n",
      "          5.2025, 144.1173,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        144.1173, 144.1173, 144.1173, 144.1173,  19.6321,  19.6321,  19.6321,\n",
      "         19.6321, 144.1173, 144.1173, 144.1173,  19.6321,  19.6321,  19.6321,\n",
      "         19.6321,   5.2026,  19.6321,  19.6321,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 79 was 89.9%\n",
      "tensor([3.0910e-06, 6.8695e-06, 5.4988e-06, 0.0000e+00, 4.7057e-06, 0.0000e+00,\n",
      "        0.0000e+00, 3.0671e-07, 0.0000e+00, 8.0682e-06, 7.7783e-06, 7.5640e-06,\n",
      "        1.2544e-03, 1.0168e-03, 9.9190e-04, 7.4646e-06, 7.2506e-06, 7.8290e-04,\n",
      "        7.6177e-04, 6.6361e-01, 6.2832e-01, 2.4463e+00, 2.4817e+00, 6.9648e-06,\n",
      "        7.3053e-04, 5.8370e-01, 2.5269e+00, 5.3861e-01, 2.5728e+00, 6.9962e-01,\n",
      "        8.9967e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 81.3840,  92.4214, 102.3770, 108.4046,   5.0166,   5.0167,   5.0177,\n",
      "        144.6827, 144.6827, 144.6827,   5.0165,   5.0168, 144.6827, 144.6827,\n",
      "        144.6827, 144.6827, 144.6827,  19.7153,  19.7153,   5.0162, 144.6827,\n",
      "        144.6827, 144.6827, 144.6827, 144.6827,  19.7153,  19.7153, 144.6827,\n",
      "         19.7153,  19.7153,   5.2026, 144.6827, 144.6827, 144.6827, 144.6827,\n",
      "        144.6827,  19.7153,  19.7153, 144.6827,  19.7153,  19.7153,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 144.6827,   5.2026,   5.2025, 144.6827,   5.2026,\n",
      "          5.2025, 144.6827,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        144.6827, 144.6827, 144.6827, 144.6827,  19.7153,  19.7153,  19.7153,\n",
      "         19.7153, 144.6827, 144.6827, 144.6827,  19.7153,  19.7153,  19.7153,\n",
      "         19.7153,   5.2026,  19.7153,  19.7153,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 80 was 90.0%\n",
      "tensor([1.1606e-06, 6.1553e-06, 4.1407e-06, 1.5247e-20, 5.1430e-06, 0.0000e+00,\n",
      "        0.0000e+00, 1.1717e-07, 0.0000e+00, 1.1119e-05, 1.0714e-05, 1.0416e-05,\n",
      "        1.2278e-03, 9.9365e-04, 9.6904e-04, 1.0280e-05, 9.9833e-06, 7.6337e-04,\n",
      "        7.4277e-04, 6.6073e-01, 6.2567e-01, 2.4345e+00, 2.4697e+00, 9.5879e-06,\n",
      "        7.1271e-04, 5.8092e-01, 2.5150e+00, 5.3567e-01, 2.5610e+00, 6.9611e-01,\n",
      "        9.0014e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 81.6044,  92.7207, 102.7343, 108.8304,   5.0144,   5.0140,   5.0131,\n",
      "        145.2458, 145.2458, 145.2458,   5.0151,   5.0135, 145.2458, 145.2458,\n",
      "        145.2458, 145.2458, 145.2458,  19.7984,  19.7984,   5.0152, 145.2458,\n",
      "        145.2458, 145.2458, 145.2458, 145.2458,  19.7984,  19.7984, 145.2458,\n",
      "         19.7984,  19.7984,   5.2026, 145.2458, 145.2458, 145.2458, 145.2458,\n",
      "        145.2458,  19.7984,  19.7984, 145.2458,  19.7984,  19.7984,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 145.2458,   5.2026,   5.2025, 145.2458,   5.2026,\n",
      "          5.2025, 145.2458,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        145.2458, 145.2458, 145.2458, 145.2458,  19.7984,  19.7984,  19.7984,\n",
      "         19.7984, 145.2458, 145.2458, 145.2458,  19.7984,  19.7984,  19.7984,\n",
      "         19.7984,   5.2026,  19.7984,  19.7984,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 81 was 90.0%\n",
      "tensor([1.2506e-05, 1.1631e-05, 1.8017e-05, 0.0000e+00, 8.8621e-06, 0.0000e+00,\n",
      "        0.0000e+00, 1.2510e-06, 0.0000e+00, 1.6608e-05, 1.6010e-05, 1.5564e-05,\n",
      "        1.1989e-03, 9.6951e-04, 9.4541e-04, 1.5359e-05, 1.4915e-05, 7.4366e-04,\n",
      "        7.2329e-04, 6.5802e-01, 6.2255e-01, 2.4226e+00, 2.4582e+00, 1.4311e-05,\n",
      "        6.9372e-04, 5.7806e-01, 2.5032e+00, 5.3306e-01, 2.5490e+00, 6.9271e-01,\n",
      "        9.0062e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 81.8223,  93.0178, 103.0814, 109.2653,   5.0109,   5.0125,   5.0123,\n",
      "        145.8067, 145.8067, 145.8067,   5.0117,   5.0120, 145.8067, 145.8067,\n",
      "        145.8067, 145.8067, 145.8067,  19.8814,  19.8814,   5.0108, 145.8067,\n",
      "        145.8067, 145.8067, 145.8067, 145.8067,  19.8814,  19.8814, 145.8067,\n",
      "         19.8814,  19.8814,   5.2026, 145.8067, 145.8067, 145.8067, 145.8067,\n",
      "        145.8067,  19.8814,  19.8814, 145.8067,  19.8814,  19.8814,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 145.8067,   5.2026,   5.2025, 145.8067,   5.2026,\n",
      "          5.2025, 145.8067,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        145.8067, 145.8067, 145.8067, 145.8067,  19.8814,  19.8814,  19.8814,\n",
      "         19.8814, 145.8067, 145.8067, 145.8067,  19.8814,  19.8814,  19.8814,\n",
      "         19.8814,   5.2026,  19.8814,  19.8814,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 82 was 90.1%\n",
      "tensor([2.6448e-06, 6.3947e-06, 4.7846e-06, 2.8799e-20, 4.5076e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.6128e-07, 0.0000e+00, 7.9550e-06, 7.6628e-06, 7.4483e-06,\n",
      "        1.1769e-03, 9.4986e-04, 9.2623e-04, 7.3544e-06, 7.1368e-06, 7.2710e-04,\n",
      "        7.0678e-04, 6.5532e-01, 6.1979e-01, 2.4114e+00, 2.4470e+00, 6.8575e-06,\n",
      "        6.7835e-04, 5.7537e-01, 2.4918e+00, 5.3023e-01, 2.5377e+00, 6.8924e-01,\n",
      "        9.0107e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 82.0445,  93.3157, 103.4475, 109.6629,   5.0099,   5.0078,   5.0089,\n",
      "        146.3654, 146.3654, 146.3654,   5.0095,   5.0092, 146.3654, 146.3654,\n",
      "        146.3654, 146.3654, 146.3654,  19.9644,  19.9644,   5.0098, 146.3654,\n",
      "        146.3654, 146.3654, 146.3654, 146.3654,  19.9644,  19.9644, 146.3654,\n",
      "         19.9644,  19.9644,   5.2026, 146.3654, 146.3654, 146.3654, 146.3654,\n",
      "        146.3654,  19.9644,  19.9644, 146.3654,  19.9644,  19.9644,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 146.3654,   5.2026,   5.2025, 146.3654,   5.2026,\n",
      "          5.2025, 146.3654,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        146.3654, 146.3654, 146.3654, 146.3654,  19.9644,  19.9644,  19.9644,\n",
      "         19.9644, 146.3654, 146.3654, 146.3654,  19.9644,  19.9644,  19.9644,\n",
      "         19.9644,   5.2026,  19.9644,  19.9644,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 83 was 90.1%\n",
      "tensor([2.6133e-06, 6.8452e-06, 4.7528e-06, 3.1340e-20, 4.4818e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.5716e-07, 0.0000e+00, 7.9153e-06, 7.6305e-06, 7.4142e-06,\n",
      "        1.1507e-03, 9.2810e-04, 9.0480e-04, 7.3195e-06, 7.1040e-06, 7.0907e-04,\n",
      "        6.8945e-04, 6.5246e-01, 6.1706e-01, 2.4001e+00, 2.4356e+00, 6.8207e-06,\n",
      "        6.6120e-04, 5.7260e-01, 2.4804e+00, 5.2770e-01, 2.5261e+00, 6.8592e-01,\n",
      "        9.0153e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 82.2661,  93.6122, 103.8110, 110.0581,   5.0051,   5.0068,   5.0073,\n",
      "        146.9219, 146.9219, 146.9219,   5.0067,   5.0076, 146.9219, 146.9219,\n",
      "        146.9219, 146.9219, 146.9219,  20.0473,  20.0473,   5.0066, 146.9219,\n",
      "        146.9219, 146.9219, 146.9219, 146.9219,  20.0473,  20.0473, 146.9219,\n",
      "         20.0473,  20.0473,   5.2026, 146.9219, 146.9219, 146.9219, 146.9219,\n",
      "        146.9219,  20.0473,  20.0473, 146.9219,  20.0473,  20.0473,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 146.9219,   5.2026,   5.2025, 146.9219,   5.2026,\n",
      "          5.2025, 146.9219,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        146.9219, 146.9219, 146.9219, 146.9219,  20.0473,  20.0473,  20.0473,\n",
      "         20.0473, 146.9219, 146.9219, 146.9219,  20.0473,  20.0473,  20.0473,\n",
      "         20.0473,   5.2026,  20.0473,  20.0473,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 84 was 90.1%\n",
      "tensor([0.0000e+00, 4.6958e-06, 4.4512e-06, 4.4948e-06, 3.6827e-06, 4.2947e-08,\n",
      "        3.4496e-08, 0.0000e+00, 2.9318e-08, 7.8833e-06, 7.5920e-06, 7.3785e-06,\n",
      "        1.1265e-03, 9.0670e-04, 8.8411e-04, 7.2846e-06, 7.0686e-06, 6.9157e-04,\n",
      "        6.7222e-04, 6.4954e-01, 6.1439e-01, 2.3891e+00, 2.4243e+00, 6.7899e-06,\n",
      "        6.4523e-04, 5.7003e-01, 2.4691e+00, 5.2513e-01, 2.5147e+00, 6.8265e-01,\n",
      "        9.0198e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 82.4869,  93.9074, 104.1718, 110.4516,   5.0041,   5.0039,   5.0038,\n",
      "        147.4764, 147.4764, 147.4764,   5.0045,   5.0030, 147.4764, 147.4764,\n",
      "        147.4764, 147.4764, 147.4764,  20.1302,  20.1302,   5.0056, 147.4764,\n",
      "        147.4764, 147.4764, 147.4764, 147.4764,  20.1302,  20.1302, 147.4764,\n",
      "         20.1302,  20.1302,   5.2026, 147.4764, 147.4764, 147.4764, 147.4764,\n",
      "        147.4764,  20.1302,  20.1302, 147.4764,  20.1302,  20.1302,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 147.4764,   5.2026,   5.2025, 147.4764,   5.2026,\n",
      "          5.2025, 147.4764,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        147.4764, 147.4764, 147.4764, 147.4764,  20.1302,  20.1302,  20.1302,\n",
      "         20.1302, 147.4764, 147.4764, 147.4764,  20.1302,  20.1302,  20.1302,\n",
      "         20.1302,   5.2026,  20.1302,  20.1302,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 85 was 90.2%\n",
      "tensor([2.6703e-06, 2.5668e-06, 4.8648e-06, 0.0000e+00, 4.4718e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.6026e-07, 0.0000e+00, 7.8437e-06, 7.5592e-06, 7.3449e-06,\n",
      "        1.1015e-03, 8.8619e-04, 8.6387e-04, 7.2507e-06, 7.0376e-06, 6.7452e-04,\n",
      "        6.5582e-04, 6.4681e-01, 6.1152e-01, 2.3780e+00, 2.4134e+00, 6.7546e-06,\n",
      "        6.2895e-04, 5.6747e-01, 2.4578e+00, 5.2262e-01, 2.5033e+00, 6.7944e-01,\n",
      "        9.0243e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 82.7070,  94.2016, 104.5304, 110.8422,   5.0011,   5.0023,   5.0022,\n",
      "        148.0288, 148.0288, 148.0288,   5.0010,   5.0020, 148.0288, 148.0288,\n",
      "        148.0288, 148.0288, 148.0288,  20.2131,  20.2131,   5.0011, 148.0288,\n",
      "        148.0288, 148.0288, 148.0288, 148.0288,  20.2131,  20.2131, 148.0288,\n",
      "         20.2131,  20.2131,   5.2026, 148.0288, 148.0288, 148.0288, 148.0288,\n",
      "        148.0288,  20.2131,  20.2131, 148.0288,  20.2131,  20.2131,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 148.0288,   5.2026,   5.2025, 148.0288,   5.2026,\n",
      "          5.2025, 148.0288,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        148.0288, 148.0288, 148.0288, 148.0288,  20.2131,  20.2131,  20.2131,\n",
      "         20.2131, 148.0288, 148.0288, 148.0288,  20.2131,  20.2131,  20.2131,\n",
      "         20.2131,   5.2026,  20.2131,  20.2131,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 86 was 90.2%\n",
      "tensor([0.0000e+00, 5.4747e-06, 2.8724e-06, 4.2352e-21, 1.4308e-05, 0.0000e+00,\n",
      "        1.2624e-07, 1.1143e-07, 0.0000e+00, 7.8112e-06, 7.5219e-06, 7.3106e-06,\n",
      "        1.0980e-03, 8.8405e-04, 8.6318e-04, 7.2172e-06, 7.0018e-06, 6.7409e-04,\n",
      "        6.5606e-04, 6.4389e-01, 6.0888e-01, 2.3664e+00, 2.4015e+00, 6.7245e-06,\n",
      "        6.3092e-04, 5.6473e-01, 2.4460e+00, 5.1982e-01, 2.4916e+00, 6.7605e-01,\n",
      "        9.0290e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 82.9283,  94.4956, 104.8912, 111.2252,   4.9990,   4.9976,   4.9990,\n",
      "        148.5792, 148.5792, 148.5792,   5.0001,   4.9993, 148.5792, 148.5792,\n",
      "        148.5792, 148.5792, 148.5792,  20.2959,  20.2959,   4.9996, 148.5792,\n",
      "        148.5792, 148.5792, 148.5792, 148.5792,  20.2959,  20.2959, 148.5792,\n",
      "         20.2959,  20.2959,   5.2026, 148.5792, 148.5792, 148.5792, 148.5792,\n",
      "        148.5792,  20.2959,  20.2959, 148.5792,  20.2959,  20.2959,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 148.5792,   5.2026,   5.2025, 148.5792,   5.2026,\n",
      "          5.2025, 148.5792,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        148.5792, 148.5792, 148.5792, 148.5792,  20.2959,  20.2959,  20.2959,\n",
      "         20.2959, 148.5792, 148.5792, 148.5792,  20.2959,  20.2959,  20.2959,\n",
      "         20.2959,   5.2026,  20.2959,  20.2959,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 87 was 90.3%\n",
      "tensor([0.0000e+00, 5.4516e-06, 2.8679e-06, 0.0000e+00, 1.4313e-05, 0.0000e+00,\n",
      "        1.2459e-07, 1.0990e-07, 0.0000e+00, 7.7753e-06, 7.4917e-06, 7.2771e-06,\n",
      "        1.0754e-03, 8.6508e-04, 8.4434e-04, 7.1822e-06, 6.9704e-06, 6.5843e-04,\n",
      "        6.4128e-04, 6.4116e-01, 6.0619e-01, 2.3556e+00, 2.3907e+00, 6.6913e-06,\n",
      "        6.1631e-04, 5.6209e-01, 2.4352e+00, 5.1749e-01, 2.4804e+00, 6.7289e-01,\n",
      "        9.0333e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 83.1484,  94.7923, 105.2519, 111.6008,   4.9962,   4.9967,   4.9975,\n",
      "        149.1277, 149.1277, 149.1277,   4.9954,   4.9972, 149.1277, 149.1277,\n",
      "        149.1277, 149.1277, 149.1277,  20.3787,  20.3787,   4.9964, 149.1277,\n",
      "        149.1277, 149.1277, 149.1277, 149.1277,  20.3787,  20.3787, 149.1277,\n",
      "         20.3787,  20.3787,   5.2026, 149.1277, 149.1277, 149.1277, 149.1277,\n",
      "        149.1277,  20.3787,  20.3787, 149.1277,  20.3787,  20.3787,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 149.1277,   5.2026,   5.2025, 149.1277,   5.2026,\n",
      "          5.2025, 149.1277,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        149.1277, 149.1277, 149.1277, 149.1277,  20.3787,  20.3787,  20.3787,\n",
      "         20.3787, 149.1277, 149.1277, 149.1277,  20.3787,  20.3787,  20.3787,\n",
      "         20.3787,   5.2026,  20.3787,  20.3787,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 88 was 90.3%\n",
      "tensor([8.1096e-07, 4.9636e-06, 4.9617e-06, 5.3297e-06, 3.3881e-20, 5.3644e-08,\n",
      "        0.0000e+00, 0.0000e+00, 3.6521e-08, 7.7411e-06, 7.4543e-06, 7.2442e-06,\n",
      "        1.0535e-03, 8.4621e-04, 8.2632e-04, 7.1506e-06, 6.9376e-06, 6.4300e-04,\n",
      "        6.2599e-04, 6.3827e-01, 6.0374e-01, 2.3451e+00, 2.3797e+00, 6.6610e-06,\n",
      "        6.0201e-04, 5.5968e-01, 2.4242e+00, 5.1491e-01, 2.4695e+00, 6.6976e-01,\n",
      "        9.0377e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 83.3680,  95.0863, 105.6096, 111.9763,   4.9941,   4.9939,   4.9928,\n",
      "        149.6743, 149.6743, 149.6743,   4.9945,   4.9939, 149.6743, 149.6743,\n",
      "        149.6743, 149.6743, 149.6743,  20.4614,  20.4614,   4.9948, 149.6743,\n",
      "        149.6743, 149.6743, 149.6743, 149.6743,  20.4614,  20.4614, 149.6743,\n",
      "         20.4614,  20.4614,   5.2026, 149.6743, 149.6743, 149.6743, 149.6743,\n",
      "        149.6743,  20.4614,  20.4614, 149.6743,  20.4614,  20.4614,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 149.6743,   5.2026,   5.2025, 149.6743,   5.2026,\n",
      "          5.2025, 149.6743,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        149.6743, 149.6743, 149.6743, 149.6743,  20.4614,  20.4614,  20.4614,\n",
      "         20.4614, 149.6743, 149.6743, 149.6743,  20.4614,  20.4614,  20.4614,\n",
      "         20.4614,   5.2026,  20.4614,  20.4614,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 89 was 90.4%\n",
      "tensor([8.0126e-07, 4.9483e-06, 4.9370e-06, 5.3004e-06, 8.4703e-21, 5.2666e-08,\n",
      "        0.0000e+00, 0.0000e+00, 3.5799e-08, 7.7051e-06, 7.4220e-06, 7.2133e-06,\n",
      "        1.0315e-03, 8.2790e-04, 8.0837e-04, 7.1168e-06, 6.9064e-06, 6.2817e-04,\n",
      "        6.1156e-04, 6.3564e-01, 6.0100e-01, 2.3345e+00, 2.3692e+00, 6.6279e-06,\n",
      "        5.8790e-04, 5.5715e-01, 2.4134e+00, 5.1258e-01, 2.4586e+00, 6.6665e-01,\n",
      "        9.0420e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 83.5871,  95.3769, 105.9640, 112.3528,   4.9907,   4.9924,   4.9920,\n",
      "        150.2189, 150.2189, 150.2189,   4.9910,   4.9923, 150.2189, 150.2189,\n",
      "        150.2189, 150.2189, 150.2189,  20.5441,  20.5441,   4.9904, 150.2189,\n",
      "        150.2189, 150.2189, 150.2189, 150.2189,  20.5441,  20.5441, 150.2189,\n",
      "         20.5441,  20.5441,   5.2026, 150.2189, 150.2189, 150.2189, 150.2189,\n",
      "        150.2189,  20.5441,  20.5441, 150.2189,  20.5441,  20.5441,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 150.2189,   5.2026,   5.2025, 150.2189,   5.2026,\n",
      "          5.2025, 150.2189,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        150.2189, 150.2189, 150.2189, 150.2189,  20.5441,  20.5441,  20.5441,\n",
      "         20.5441, 150.2189, 150.2189, 150.2189,  20.5441,  20.5441,  20.5441,\n",
      "         20.5441,   5.2026,  20.5441,  20.5441,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 90 was 90.4%\n",
      "tensor([0.0000e+00, 5.3850e-06, 2.8498e-06, 0.0000e+00, 1.4370e-05, 0.0000e+00,\n",
      "        1.1996e-07, 1.0565e-07, 0.0000e+00, 7.6744e-06, 7.3863e-06, 7.1802e-06,\n",
      "        1.0109e-03, 8.0967e-04, 7.9100e-04, 7.0856e-06, 6.8732e-06, 6.1343e-04,\n",
      "        5.9707e-04, 6.3292e-01, 5.9859e-01, 2.3241e+00, 2.3585e+00, 6.6002e-06,\n",
      "        5.7452e-04, 5.5472e-01, 2.4028e+00, 5.1009e-01, 2.4480e+00, 6.6359e-01,\n",
      "        9.0462e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 83.8057,  95.6663, 106.3163, 112.7272,   4.9893,   4.9876,   4.9893,\n",
      "        150.7618, 150.7618, 150.7618,   4.9889,   4.9890, 150.7618, 150.7618,\n",
      "        150.7618, 150.7618, 150.7618,  20.6267,  20.6267,   4.9894, 150.7618,\n",
      "        150.7618, 150.7618, 150.7618, 150.7618,  20.6267,  20.6267, 150.7618,\n",
      "         20.6267,  20.6267,   5.2026, 150.7618, 150.7618, 150.7618, 150.7618,\n",
      "        150.7618,  20.6267,  20.6267, 150.7618,  20.6267,  20.6267,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 150.7618,   5.2026,   5.2025, 150.7618,   5.2026,\n",
      "          5.2025, 150.7618,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        150.7618, 150.7618, 150.7618, 150.7618,  20.6267,  20.6267,  20.6267,\n",
      "         20.6267, 150.7618, 150.7618, 150.7618,  20.6267,  20.6267,  20.6267,\n",
      "         20.6267,   5.2026,  20.6267,  20.6267,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 91 was 90.5%\n",
      "tensor([0.0000e+00, 5.3624e-06, 2.8435e-06, 0.0000e+00, 1.4394e-05, 0.0000e+00,\n",
      "        1.1849e-07, 1.0429e-07, 0.0000e+00, 7.6374e-06, 7.3566e-06, 7.1471e-06,\n",
      "        9.8958e-04, 7.9223e-04, 7.7362e-04, 7.0521e-06, 6.8436e-06, 5.9899e-04,\n",
      "        5.8344e-04, 6.3021e-01, 5.9603e-01, 2.3137e+00, 2.3480e+00, 6.5666e-06,\n",
      "        5.6090e-04, 5.5224e-01, 2.3921e+00, 5.0775e-01, 2.4372e+00, 6.6052e-01,\n",
      "        9.0505e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 84.0236,  95.9544, 106.6665, 113.0996,   4.9858,   4.9868,   4.9858,\n",
      "        151.3028, 151.3028, 151.3028,   4.9873,   4.9875, 151.3028, 151.3028,\n",
      "        151.3028, 151.3028, 151.3028,  20.7093,  20.7093,   4.9849, 151.3028,\n",
      "        151.3028, 151.3028, 151.3028, 151.3028,  20.7093,  20.7093, 151.3028,\n",
      "         20.7093,  20.7093,   5.2026, 151.3028, 151.3028, 151.3028, 151.3028,\n",
      "        151.3028,  20.7093,  20.7093, 151.3028,  20.7093,  20.7093,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 151.3028,   5.2026,   5.2025, 151.3028,   5.2026,\n",
      "          5.2025, 151.3028,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        151.3028, 151.3028, 151.3028, 151.3028,  20.7093,  20.7093,  20.7093,\n",
      "         20.7093, 151.3028, 151.3028, 151.3028,  20.7093,  20.7093,  20.7093,\n",
      "         20.7093,   5.2026,  20.7093,  20.7093,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 92 was 90.5%\n",
      "tensor([0.0000e+00, 5.3457e-06, 2.9036e-06, 1.5247e-20, 1.3989e-05, 0.0000e+00,\n",
      "        1.1353e-07, 9.9868e-08, 0.0000e+00, 7.6074e-06, 7.3214e-06, 7.1165e-06,\n",
      "        9.6985e-04, 7.7486e-04, 7.5694e-04, 7.0205e-06, 6.8111e-06, 5.8518e-04,\n",
      "        5.6970e-04, 6.2766e-01, 5.9352e-01, 2.3035e+00, 2.3377e+00, 6.5393e-06,\n",
      "        5.4821e-04, 5.4973e-01, 2.3819e+00, 5.0547e-01, 2.4268e+00, 6.5757e-01,\n",
      "        9.0546e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 84.2442,  96.2436, 107.0163, 113.4626,   4.9844,   4.9839,   4.9838,\n",
      "        151.8420, 151.8420, 151.8420,   4.9839,   4.9829, 151.8420, 151.8420,\n",
      "        151.8420, 151.8420, 151.8420,  20.7919,  20.7919,   4.9839, 151.8420,\n",
      "        151.8420, 151.8420, 151.8420, 151.8420,  20.7919,  20.7919, 151.8420,\n",
      "         20.7919,  20.7919,   5.2026, 151.8420, 151.8420, 151.8420, 151.8420,\n",
      "        151.8420,  20.7919,  20.7919, 151.8420,  20.7919,  20.7919,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 151.8420,   5.2026,   5.2025, 151.8420,   5.2026,\n",
      "          5.2025, 151.8420,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        151.8420, 151.8420, 151.8420, 151.8420,  20.7919,  20.7919,  20.7919,\n",
      "         20.7919, 151.8420, 151.8420, 151.8420,  20.7919,  20.7919,  20.7919,\n",
      "         20.7919,   5.2026,  20.7919,  20.7919,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 93 was 90.5%\n",
      "tensor([0.0000e+00, 5.3238e-06, 2.8953e-06, 0.0000e+00, 1.4016e-05, 0.0000e+00,\n",
      "        1.1217e-07, 9.8632e-08, 0.0000e+00, 7.5708e-06, 7.2899e-06, 7.0843e-06,\n",
      "        9.4954e-04, 7.5848e-04, 7.4072e-04, 6.9888e-06, 6.7829e-06, 5.7159e-04,\n",
      "        5.5670e-04, 6.2498e-01, 5.9103e-01, 2.2934e+00, 2.3274e+00, 6.5065e-06,\n",
      "        5.3539e-04, 5.4743e-01, 2.3714e+00, 5.0305e-01, 2.4163e+00, 6.5455e-01,\n",
      "        9.0588e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 84.4630,  96.5307, 107.3643, 113.8259,   4.9790,   4.9805,   4.9823,\n",
      "        152.3796, 152.3796, 152.3796,   4.9824,   4.9820, 152.3796, 152.3796,\n",
      "        152.3796, 152.3796, 152.3796,  20.8744,  20.8744,   4.9812, 152.3796,\n",
      "        152.3796, 152.3796, 152.3796, 152.3796,  20.8744,  20.8744, 152.3796,\n",
      "         20.8744,  20.8744,   5.2026, 152.3796, 152.3796, 152.3796, 152.3796,\n",
      "        152.3796,  20.8744,  20.8744, 152.3796,  20.8744,  20.8744,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 152.3796,   5.2026,   5.2025, 152.3796,   5.2026,\n",
      "          5.2025, 152.3796,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        152.3796, 152.3796, 152.3796, 152.3796,  20.8744,  20.8744,  20.8744,\n",
      "         20.8744, 152.3796, 152.3796, 152.3796,  20.8744,  20.8744,  20.8744,\n",
      "         20.8744,   5.2026,  20.8744,  20.8744,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 94 was 90.6%\n",
      "tensor([0.0000e+00, 5.2979e-06, 2.8286e-06, 0.0000e+00, 1.4443e-05, 0.0000e+00,\n",
      "        1.1401e-07, 1.0019e-07, 0.0000e+00, 7.5436e-06, 7.2598e-06, 7.0522e-06,\n",
      "        9.3053e-04, 7.4203e-04, 7.2447e-04, 6.9557e-06, 6.7527e-06, 5.5822e-04,\n",
      "        5.4396e-04, 6.2227e-01, 5.8863e-01, 2.2836e+00, 2.3173e+00, 6.4795e-06,\n",
      "        5.2342e-04, 5.4511e-01, 2.3612e+00, 5.0090e-01, 2.4060e+00, 6.5168e-01,\n",
      "        9.0628e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 84.6798,  96.8138, 107.7109, 114.1908,   4.9775,   4.9790,   4.9788,\n",
      "        152.9154, 152.9154, 152.9154,   4.9777,   4.9793, 152.9154, 152.9154,\n",
      "        152.9154, 152.9154, 152.9154,  20.9569,  20.9569,   4.9797, 152.9154,\n",
      "        152.9154, 152.9154, 152.9154, 152.9154,  20.9569,  20.9569, 152.9154,\n",
      "         20.9569,  20.9569,   5.2026, 152.9154, 152.9154, 152.9154, 152.9154,\n",
      "        152.9154,  20.9569,  20.9569, 152.9154,  20.9569,  20.9569,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 152.9154,   5.2026,   5.2025, 152.9154,   5.2026,\n",
      "          5.2025, 152.9154,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        152.9154, 152.9154, 152.9154, 152.9154,  20.9569,  20.9569,  20.9569,\n",
      "         20.9569, 152.9154, 152.9154, 152.9154,  20.9569,  20.9569,  20.9569,\n",
      "         20.9569,   5.2026,  20.9569,  20.9569,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 95 was 90.6%\n",
      "tensor([0.0000e+00, 5.2763e-06, 2.8227e-06, 3.3881e-21, 1.4470e-05, 0.0000e+00,\n",
      "        1.1262e-07, 9.8919e-08, 0.0000e+00, 7.5078e-06, 7.2247e-06, 7.0233e-06,\n",
      "        9.1124e-04, 7.2590e-04, 7.0930e-04, 6.9281e-06, 6.7217e-06, 5.4553e-04,\n",
      "        5.3119e-04, 6.1960e-01, 5.8616e-01, 2.2737e+00, 2.3072e+00, 6.4482e-06,\n",
      "        5.1118e-04, 5.4281e-01, 2.3509e+00, 4.9861e-01, 2.3957e+00, 6.4876e-01,\n",
      "        9.0669e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 84.8961,  97.0959, 108.0556, 114.5539,   4.9761,   4.9760,   4.9773,\n",
      "        153.4495, 153.4495, 153.4495,   4.9761,   4.9759, 153.4495, 153.4495,\n",
      "        153.4495, 153.4495, 153.4495,  21.0393,  21.0393,   4.9752, 153.4495,\n",
      "        153.4495, 153.4495, 153.4495, 153.4495,  21.0393,  21.0393, 153.4495,\n",
      "         21.0393,  21.0393,   5.2026, 153.4495, 153.4495, 153.4495, 153.4495,\n",
      "        153.4495,  21.0393,  21.0393, 153.4495,  21.0393,  21.0393,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 153.4495,   5.2026,   5.2025, 153.4495,   5.2026,\n",
      "          5.2025, 153.4495,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        153.4495, 153.4495, 153.4495, 153.4495,  21.0393,  21.0393,  21.0393,\n",
      "         21.0393, 153.4495, 153.4495, 153.4495,  21.0393,  21.0393,  21.0393,\n",
      "         21.0393,   5.2026,  21.0393,  21.0393,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 96 was 90.7%\n",
      "tensor([0.0000e+00, 5.2557e-06, 2.8161e-06, 8.4703e-22, 1.4496e-05, 0.0000e+00,\n",
      "        1.1129e-07, 9.7677e-08, 0.0000e+00, 7.4752e-06, 7.1950e-06, 6.9905e-06,\n",
      "        8.9311e-04, 7.1046e-04, 6.9377e-04, 6.8947e-06, 6.6930e-06, 5.3273e-04,\n",
      "        5.1916e-04, 6.1711e-01, 5.8384e-01, 2.2638e+00, 2.2972e+00, 6.4208e-06,\n",
      "        4.9953e-04, 5.4045e-01, 2.3409e+00, 4.9622e-01, 2.3857e+00, 6.4586e-01,\n",
      "        9.0709e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 85.1118,  97.3768, 108.3985, 114.9152,   4.9727,   4.9746,   4.9726,\n",
      "        153.9820, 153.9820, 153.9820,   4.9726,   4.9744, 153.9820, 153.9820,\n",
      "        153.9820, 153.9820, 153.9820,  21.1217,  21.1217,   4.9742, 153.9820,\n",
      "        153.9820, 153.9820, 153.9820, 153.9820,  21.1217,  21.1217, 153.9820,\n",
      "         21.1217,  21.1217,   5.2026, 153.9820, 153.9820, 153.9820, 153.9820,\n",
      "        153.9820,  21.1217,  21.1217, 153.9820,  21.1217,  21.1217,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 153.9820,   5.2026,   5.2025, 153.9820,   5.2026,\n",
      "          5.2025, 153.9820,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        153.9820, 153.9820, 153.9820, 153.9820,  21.1217,  21.1217,  21.1217,\n",
      "         21.1217, 153.9820, 153.9820, 153.9820,  21.1217,  21.1217,  21.1217,\n",
      "         21.1217,   5.2026,  21.1217,  21.1217,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 97 was 90.7%\n",
      "tensor([1.2057e-05, 5.2625e-06, 0.0000e+00, 0.0000e+00, 1.4361e-05, 0.0000e+00,\n",
      "        2.0769e-06, 1.8220e-06, 0.0000e+00, 7.8411e-06, 7.5452e-06, 7.3363e-06,\n",
      "        8.7387e-04, 6.9399e-04, 6.7852e-04, 7.2370e-06, 7.0208e-06, 5.2022e-04,\n",
      "        5.0640e-04, 6.1458e-01, 5.8131e-01, 2.2540e+00, 2.2874e+00, 6.7386e-06,\n",
      "        4.8753e-04, 5.3816e-01, 2.3309e+00, 4.9412e-01, 2.3755e+00, 6.4306e-01,\n",
      "        9.0748e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 85.3290,  97.6672, 108.7314, 115.2726,   4.9699,   4.9697,   4.9717,\n",
      "        154.5129, 154.5129, 154.5129,   4.9716,   4.9711, 154.5129, 154.5129,\n",
      "        154.5129, 154.5129, 154.5129,  21.2040,  21.2040,   4.9715, 154.5129,\n",
      "        154.5129, 154.5129, 154.5129, 154.5129,  21.2040,  21.2040, 154.5129,\n",
      "         21.2040,  21.2040,   5.2026, 154.5129, 154.5129, 154.5129, 154.5129,\n",
      "        154.5129,  21.2040,  21.2040, 154.5129,  21.2040,  21.2040,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 154.5129,   5.2026,   5.2025, 154.5129,   5.2026,\n",
      "          5.2025, 154.5129,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        154.5129, 154.5129, 154.5129, 154.5129,  21.2040,  21.2040,  21.2040,\n",
      "         21.2040, 154.5129, 154.5129, 154.5129,  21.2040,  21.2040,  21.2040,\n",
      "         21.2040,   5.2026,  21.2040,  21.2040,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 98 was 90.7%\n",
      "tensor([1.1752e-05, 5.2636e-06, 0.0000e+00, 0.0000e+00, 1.4018e-05, 0.0000e+00,\n",
      "        2.0181e-06, 1.7699e-06, 0.0000e+00, 7.6608e-06, 7.3743e-06, 7.1657e-06,\n",
      "        8.5667e-04, 6.8019e-04, 6.6424e-04, 7.0670e-06, 6.8612e-06, 5.0852e-04,\n",
      "        4.9562e-04, 6.1200e-01, 5.7898e-01, 2.2444e+00, 2.2775e+00, 6.5829e-06,\n",
      "        4.7693e-04, 5.3588e-01, 2.3210e+00, 4.9194e-01, 2.3655e+00, 6.4021e-01,\n",
      "        9.0788e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 85.5463,  97.9562, 109.0637, 115.6262,   4.9677,   4.9689,   4.9671,\n",
      "        155.0423, 155.0423, 155.0423,   4.9681,   4.9695, 155.0423, 155.0423,\n",
      "        155.0423, 155.0423, 155.0423,  21.2864,  21.2864,   4.9688, 155.0423,\n",
      "        155.0423, 155.0423, 155.0423, 155.0423,  21.2864,  21.2864, 155.0423,\n",
      "         21.2864,  21.2864,   5.2026, 155.0423, 155.0423, 155.0423, 155.0423,\n",
      "        155.0423,  21.2864,  21.2864, 155.0423,  21.2864,  21.2864,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 155.0423,   5.2026,   5.2025, 155.0423,   5.2026,\n",
      "          5.2025, 155.0423,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        155.0423, 155.0423, 155.0423, 155.0423,  21.2864,  21.2864,  21.2864,\n",
      "         21.2864, 155.0423, 155.0423, 155.0423,  21.2864,  21.2864,  21.2864,\n",
      "         21.2864,   5.2026,  21.2864,  21.2864,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 99 was 90.8%\n",
      "tensor([9.5356e-06, 5.1893e-06, 6.1169e-07, 2.1938e-19, 1.1958e-05, 0.0000e+00,\n",
      "        1.6324e-06, 1.4311e-06, 0.0000e+00, 7.3939e-06, 7.1149e-06, 6.9176e-06,\n",
      "        8.4051e-04, 6.6649e-04, 6.5165e-04, 6.8224e-06, 6.6191e-06, 4.9804e-04,\n",
      "        4.8491e-04, 6.0956e-01, 5.7660e-01, 2.2350e+00, 2.2680e+00, 6.3521e-06,\n",
      "        4.6695e-04, 5.3363e-01, 2.3113e+00, 4.8983e-01, 2.3557e+00, 6.3743e-01,\n",
      "        9.0826e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 85.7616,  98.2503, 109.3891, 115.9766,   4.9656,   4.9652,   4.9662,\n",
      "        155.5701, 155.5701, 155.5701,   4.9664,   4.9650, 155.5701, 155.5701,\n",
      "        155.5701, 155.5701, 155.5701,  21.3686,  21.3686,   4.9660, 155.5701,\n",
      "        155.5701, 155.5701, 155.5701, 155.5701,  21.3686,  21.3686, 155.5701,\n",
      "         21.3686,  21.3686,   5.2026, 155.5701, 155.5701, 155.5701, 155.5701,\n",
      "        155.5701,  21.3686,  21.3686, 155.5701,  21.3686,  21.3686,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 155.5701,   5.2026,   5.2025, 155.5701,   5.2026,\n",
      "          5.2025, 155.5701,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        155.5701, 155.5701, 155.5701, 155.5701,  21.3686,  21.3686,  21.3686,\n",
      "         21.3686, 155.5701, 155.5701, 155.5701,  21.3686,  21.3686,  21.3686,\n",
      "         21.3686,   5.2026,  21.3686,  21.3686,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 100 was 90.8%\n",
      "tensor([2.2795e-05, 7.9867e-06, 3.3312e-06, 2.6809e-19, 5.8173e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6322e-06, 7.3459e-06, 7.1348e-06,\n",
      "        8.2405e-04, 6.5354e-04, 6.3836e-04, 7.0331e-06, 6.8278e-06, 4.8690e-04,\n",
      "        4.7461e-04, 6.0712e-01, 5.7421e-01, 2.2255e+00, 2.2585e+00, 6.5442e-06,\n",
      "        4.5685e-04, 5.3147e-01, 2.3015e+00, 4.8764e-01, 2.3459e+00, 6.3463e-01,\n",
      "        9.0865e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 85.9840,  98.6212, 109.6342, 116.2899,   4.9630,   4.9641,   4.9633,\n",
      "        156.0963, 156.0963, 156.0963,   4.9613,   4.9643, 156.0963, 156.0963,\n",
      "        156.0963, 156.0963, 156.0963,  21.4509,  21.4509,   4.9634, 156.0963,\n",
      "        156.0963, 156.0963, 156.0963, 156.0963,  21.4509,  21.4509, 156.0963,\n",
      "         21.4509,  21.4509,   5.2026, 156.0963, 156.0963, 156.0963, 156.0963,\n",
      "        156.0963,  21.4509,  21.4509, 156.0963,  21.4509,  21.4509,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 156.0963,   5.2026,   5.2025, 156.0963,   5.2026,\n",
      "          5.2025, 156.0963,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        156.0963, 156.0963, 156.0963, 156.0963,  21.4509,  21.4509,  21.4509,\n",
      "         21.4509, 156.0963, 156.0963, 156.0963,  21.4509,  21.4509,  21.4509,\n",
      "         21.4509,   5.2026,  21.4509,  21.4509,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(83.2743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 101 was 91.1%\n",
      "tensor([0.0000e+00, 7.1197e-04, 8.1016e-04, 6.0286e-04, 0.0000e+00, 1.5114e-05,\n",
      "        0.0000e+00, 5.9995e-06, 4.7185e-04, 7.2238e-04, 6.9491e-04, 6.7573e-04,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 6.6649e-04, 6.4481e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.7520e-01, 5.4380e-01, 2.1455e+00, 2.1774e+00, 6.1839e-04,\n",
      "        0.0000e+00, 5.0375e-01, 2.2179e+00, 4.6168e-01, 2.2602e+00, 6.3486e-01,\n",
      "        9.1199e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 86.1811,  98.8687, 109.9542, 116.6364,   4.9609,   4.9608,   4.9619,\n",
      "        156.6211, 156.6211, 156.6211,   4.9603,   4.9598, 156.6211, 156.6211,\n",
      "        156.6211, 156.6211, 156.6211,  21.5331,  21.5331,   4.9608, 156.6211,\n",
      "        156.6211, 156.6211, 156.6211, 156.6211,  21.5331,  21.5331, 156.6211,\n",
      "         21.5331,  21.5331,   5.2026, 156.6211, 156.6211, 156.6211, 156.6211,\n",
      "        156.6211,  21.5331,  21.5331, 156.6211,  21.5331,  21.5331,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 156.6211,   5.2026,   5.2025, 156.6211,   5.2026,\n",
      "          5.2025, 156.6211,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        156.6211, 156.6211, 156.6211, 156.6211,  21.5331,  21.5331,  21.5331,\n",
      "         21.5331, 156.6211, 156.6211, 156.6211,  21.5331,  21.5331,  21.5331,\n",
      "         21.5331,   5.2026,  21.5331,  21.5331,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(83.1177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 102 was 91.2%\n",
      "tensor([0.0000e+00, 7.2002e-04, 8.2899e-04, 6.1516e-04, 0.0000e+00, 1.6392e-05,\n",
      "        0.0000e+00, 5.4992e-06, 4.6243e-04, 7.0456e-04, 6.7857e-04, 6.5863e-04,\n",
      "        3.2526e-19, 0.0000e+00, 0.0000e+00, 6.4929e-04, 6.3010e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.7315e-01, 5.4184e-01, 2.1370e+00, 2.1688e+00, 6.0318e-04,\n",
      "        0.0000e+00, 5.0182e-01, 2.2093e+00, 4.5974e-01, 2.2516e+00, 6.3225e-01,\n",
      "        9.1233e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 86.3778,  99.1156, 110.2728, 116.9817,   4.9570,   4.9593,   4.9573,\n",
      "        157.1444, 157.1444, 157.1444,   4.9589,   4.9589, 157.1444, 157.1444,\n",
      "        157.1444, 157.1444, 157.1444,  21.6153,  21.6153,   4.9583, 157.1444,\n",
      "        157.1444, 157.1444, 157.1444, 157.1444,  21.6153,  21.6153, 157.1444,\n",
      "         21.6153,  21.6153,   5.2026, 157.1444, 157.1444, 157.1444, 157.1444,\n",
      "        157.1444,  21.6153,  21.6153, 157.1444,  21.6153,  21.6153,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 157.1444,   5.2026,   5.2025, 157.1444,   5.2026,\n",
      "          5.2025, 157.1444,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        157.1444, 157.1444, 157.1444, 157.1444,  21.6153,  21.6153,  21.6153,\n",
      "         21.6153, 157.1444, 157.1444, 157.1444,  21.6153,  21.6153,  21.6153,\n",
      "         21.6153,   5.2026,  21.6153,  21.6153,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.9593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 103 was 91.2%\n",
      "tensor([0.0000e+00, 7.2768e-04, 8.4785e-04, 6.2720e-04, 0.0000e+00, 1.7675e-05,\n",
      "        0.0000e+00, 4.9883e-06, 4.5329e-04, 6.8736e-04, 6.6056e-04, 6.4272e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3230e-04, 6.1298e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.7122e-01, 5.3976e-01, 2.1285e+00, 2.1605e+00, 5.8769e-04,\n",
      "        0.0000e+00, 4.9984e-01, 2.2009e+00, 4.5803e-01, 2.2429e+00, 6.2968e-01,\n",
      "        9.1267e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 86.5743,  99.3620, 110.5903, 117.3257,   4.9555,   4.9547,   4.9559,\n",
      "        157.6663, 157.6663, 157.6663,   4.9563,   4.9557, 157.6663, 157.6663,\n",
      "        157.6663, 157.6663, 157.6663,  21.6974,  21.6974,   4.9568, 157.6663,\n",
      "        157.6663, 157.6663, 157.6663, 157.6663,  21.6974,  21.6974, 157.6663,\n",
      "         21.6974,  21.6974,   5.2026, 157.6663, 157.6663, 157.6663, 157.6663,\n",
      "        157.6663,  21.6974,  21.6974, 157.6663,  21.6974,  21.6974,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 157.6663,   5.2026,   5.2025, 157.6663,   5.2026,\n",
      "          5.2025, 157.6663,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        157.6663, 157.6663, 157.6663, 157.6663,  21.6974,  21.6974,  21.6974,\n",
      "         21.6974, 157.6663, 157.6663, 157.6663,  21.6974,  21.6974,  21.6974,\n",
      "         21.6974,   5.2026,  21.6974,  21.6974,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.8050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 104 was 91.3%\n",
      "tensor([0.0000e+00, 7.3406e-04, 8.6553e-04, 6.3899e-04, 0.0000e+00, 1.8916e-05,\n",
      "        0.0000e+00, 4.5357e-06, 4.4432e-04, 6.6843e-04, 6.4407e-04, 6.2505e-04,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 6.1541e-04, 5.9714e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.6908e-01, 5.3785e-01, 2.1203e+00, 2.1521e+00, 5.7144e-04,\n",
      "        0.0000e+00, 4.9792e-01, 2.1925e+00, 4.5625e-01, 2.2344e+00, 6.2711e-01,\n",
      "        9.1301e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 86.7705,  99.6079, 110.9061, 117.6687,   4.9533,   4.9539,   4.9531,\n",
      "        158.1868, 158.1868, 158.1868,   4.9529,   4.9542, 158.1868, 158.1868,\n",
      "        158.1868, 158.1868, 158.1868,  21.7795,  21.7795,   4.9525, 158.1868,\n",
      "        158.1868, 158.1868, 158.1868, 158.1868,  21.7795,  21.7795, 158.1868,\n",
      "         21.7795,  21.7795,   5.2026, 158.1868, 158.1868, 158.1868, 158.1868,\n",
      "        158.1868,  21.7795,  21.7795, 158.1868,  21.7795,  21.7795,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 158.1868,   5.2026,   5.2025, 158.1868,   5.2026,\n",
      "          5.2025, 158.1868,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        158.1868, 158.1868, 158.1868, 158.1868,  21.7795,  21.7795,  21.7795,\n",
      "         21.7795, 158.1868, 158.1868, 158.1868,  21.7795,  21.7795,  21.7795,\n",
      "         21.7795,   5.2026,  21.7795,  21.7795,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.6477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 105 was 91.3%\n",
      "tensor([0.0000e+00, 7.3983e-04, 8.8308e-04, 6.5077e-04, 0.0000e+00, 2.0206e-05,\n",
      "        0.0000e+00, 4.0747e-06, 4.3563e-04, 6.4892e-04, 6.2428e-04, 6.0694e-04,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 5.9789e-04, 5.7911e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.6713e-01, 5.3602e-01, 2.1120e+00, 2.1436e+00, 5.5546e-04,\n",
      "        0.0000e+00, 4.9596e-01, 2.1842e+00, 4.5437e-01, 2.2260e+00, 6.2455e-01,\n",
      "        9.1334e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 86.9665,  99.8535, 111.2205, 118.0113,   4.9500,   4.9505,   4.9517,\n",
      "        158.7059, 158.7059, 158.7059,   4.9515,   4.9497, 158.7059, 158.7059,\n",
      "        158.7059, 158.7059, 158.7059,  21.8616,  21.8616,   4.9515, 158.7059,\n",
      "        158.7059, 158.7059, 158.7059, 158.7059,  21.8616,  21.8616, 158.7059,\n",
      "         21.8616,  21.8616,   5.2026, 158.7059, 158.7059, 158.7059, 158.7059,\n",
      "        158.7059,  21.8616,  21.8616, 158.7059,  21.8616,  21.8616,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 158.7059,   5.2026,   5.2025, 158.7059,   5.2026,\n",
      "          5.2025, 158.7059,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        158.7059, 158.7059, 158.7059, 158.7059,  21.8616,  21.8616,  21.8616,\n",
      "         21.8616, 158.7059, 158.7059, 158.7059,  21.8616,  21.8616,  21.8616,\n",
      "         21.8616,   5.2026,  21.8616,  21.8616,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(82.4929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 106 was 91.3%\n",
      "tensor([0.0000e+00, 7.4426e-04, 8.9940e-04, 6.6153e-04, 0.0000e+00, 2.1444e-05,\n",
      "        0.0000e+00, 3.6131e-06, 4.2716e-04, 6.2906e-04, 6.0535e-04, 5.8729e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7859e-04, 5.6200e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.6511e-01, 5.3403e-01, 2.1038e+00, 2.1355e+00, 5.3739e-04,\n",
      "        0.0000e+00, 4.9417e-01, 2.1758e+00, 4.5261e-01, 2.2175e+00, 6.2205e-01,\n",
      "        9.1367e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 87.1622, 100.0986, 111.5335, 118.3531,   4.9479,   4.9490,   4.9472,\n",
      "        159.2236, 159.2236, 159.2236,   4.9487,   4.9487, 159.2236, 159.2236,\n",
      "        159.2236, 159.2236, 159.2236,  21.9436,  21.9436,   4.9483, 159.2236,\n",
      "        159.2236, 159.2236, 159.2236, 159.2236,  21.9436,  21.9436, 159.2236,\n",
      "         21.9436,  21.9436,   5.2026, 159.2236, 159.2236, 159.2236, 159.2236,\n",
      "        159.2236,  21.9436,  21.9436, 159.2236,  21.9436,  21.9436,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 159.2236,   5.2026,   5.2025, 159.2236,   5.2026,\n",
      "          5.2025, 159.2236,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        159.2236, 159.2236, 159.2236, 159.2236,  21.9436,  21.9436,  21.9436,\n",
      "         21.9436, 159.2236, 159.2236, 159.2236,  21.9436,  21.9436,  21.9436,\n",
      "         21.9436,   5.2026,  21.9436,  21.9436,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.3383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 107 was 91.4%\n",
      "tensor([1.8792e-05, 7.4735e-04, 9.1496e-04, 6.7202e-04, 0.0000e+00, 2.2686e-05,\n",
      "        0.0000e+00, 3.1428e-06, 4.1881e-04, 6.0674e-04, 5.8347e-04, 5.6762e-04,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 5.5842e-04, 5.4136e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.6319e-01, 5.3211e-01, 2.0956e+00, 2.1272e+00, 5.1859e-04,\n",
      "        0.0000e+00, 4.9221e-01, 2.1676e+00, 4.5084e-01, 2.2091e+00, 6.1952e-01,\n",
      "        9.1400e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 87.3574, 100.3432, 111.8448, 118.6944,   4.9458,   4.9443,   4.9463,\n",
      "        159.7400, 159.7400, 159.7400,   4.9461,   4.9455, 159.7400, 159.7400,\n",
      "        159.7400, 159.7400, 159.7400,  22.0256,  22.0256,   4.9468, 159.7400,\n",
      "        159.7400, 159.7400, 159.7400, 159.7400,  22.0256,  22.0256, 159.7400,\n",
      "         22.0256,  22.0256,   5.2026, 159.7400, 159.7400, 159.7400, 159.7400,\n",
      "        159.7400,  22.0256,  22.0256, 159.7400,  22.0256,  22.0256,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 159.7400,   5.2026,   5.2025, 159.7400,   5.2026,\n",
      "          5.2025, 159.7400,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        159.7400, 159.7400, 159.7400, 159.7400,  22.0256,  22.0256,  22.0256,\n",
      "         22.0256, 159.7400, 159.7400, 159.7400,  22.0256,  22.0256,  22.0256,\n",
      "         22.0256,   5.2026,  22.0256,  22.0256,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.1847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 108 was 91.4%\n",
      "tensor([5.5380e-05, 7.4818e-04, 9.2816e-04, 6.8133e-04, 0.0000e+00, 2.3819e-05,\n",
      "        0.0000e+00, 2.7023e-06, 4.1072e-04, 5.8390e-04, 5.6277e-04, 5.4569e-04,\n",
      "        3.2526e-19, 0.0000e+00, 0.0000e+00, 5.3758e-04, 5.2160e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.6112e-01, 5.3025e-01, 2.0876e+00, 2.1191e+00, 4.9874e-04,\n",
      "        0.0000e+00, 4.9039e-01, 2.1594e+00, 4.4911e-01, 2.2008e+00, 6.1706e-01,\n",
      "        9.1433e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 87.5523, 100.5873, 112.1542, 119.0356,   4.9431,   4.9435,   4.9429,\n",
      "        160.2551, 160.2551, 160.2551,   4.9433,   4.9445, 160.2551, 160.2551,\n",
      "        160.2551, 160.2551, 160.2551,  22.1076,  22.1076,   4.9424, 160.2551,\n",
      "        160.2551, 160.2551, 160.2551, 160.2551,  22.1076,  22.1076, 160.2551,\n",
      "         22.1076,  22.1076,   5.2026, 160.2551, 160.2551, 160.2551, 160.2551,\n",
      "        160.2551,  22.1076,  22.1076, 160.2551,  22.1076,  22.1076,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 160.2551,   5.2026,   5.2025, 160.2551,   5.2026,\n",
      "          5.2025, 160.2551,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        160.2551, 160.2551, 160.2551, 160.2551,  22.1076,  22.1076,  22.1076,\n",
      "         22.1076, 160.2551, 160.2551, 160.2551,  22.1076,  22.1076,  22.1076,\n",
      "         22.1076,   5.2026,  22.1076,  22.1076,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 109 was 91.4%\n",
      "tensor([9.2565e-05, 7.4687e-04, 9.4016e-04, 6.8982e-04, 0.0000e+00, 2.4954e-05,\n",
      "        0.0000e+00, 2.2359e-06, 4.0267e-04, 5.5880e-04, 5.3739e-04, 5.2237e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1436e-04, 4.9814e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.5920e-01, 5.2843e-01, 2.0795e+00, 2.1109e+00, 4.7773e-04,\n",
      "        0.0000e+00, 4.8842e-01, 2.1513e+00, 4.4736e-01, 2.1925e+00, 6.1459e-01,\n",
      "        9.1466e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 87.7467, 100.8310, 112.4619, 119.3769,   4.9409,   4.9401,   4.9415,\n",
      "        160.7689, 160.7689, 160.7689,   4.9407,   4.9400, 160.7689, 160.7689,\n",
      "        160.7689, 160.7689, 160.7689,  22.1895,  22.1895,   4.9414, 160.7689,\n",
      "        160.7689, 160.7689, 160.7689, 160.7689,  22.1895,  22.1895, 160.7689,\n",
      "         22.1895,  22.1895,   5.2026, 160.7689, 160.7689, 160.7689, 160.7689,\n",
      "        160.7689,  22.1895,  22.1895, 160.7689,  22.1895,  22.1895,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 160.7689,   5.2026,   5.2025, 160.7689,   5.2026,\n",
      "          5.2025, 160.7689,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        160.7689, 160.7689, 160.7689, 160.7689,  22.1895,  22.1895,  22.1895,\n",
      "         22.1895, 160.7689, 160.7689, 160.7689,  22.1895,  22.1895,  22.1895,\n",
      "         22.1895,   5.2026,  22.1895,  22.1895,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.8763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 110 was 91.4%\n",
      "tensor([1.2882e-04, 7.4276e-04, 9.4934e-04, 6.9667e-04, 0.0000e+00, 2.5999e-05,\n",
      "        0.0000e+00, 1.7611e-06, 3.9483e-04, 5.3119e-04, 5.1159e-04, 4.9624e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8913e-04, 4.7459e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.5725e-01, 5.2651e-01, 2.0715e+00, 2.1028e+00, 4.5357e-04,\n",
      "        0.0000e+00, 4.8670e-01, 2.1431e+00, 4.4557e-01, 2.1844e+00, 6.1212e-01,\n",
      "        9.1498e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 87.9406, 101.0741, 112.7675, 119.7185,   4.9374,   4.9392,   4.9368,\n",
      "        161.2814, 161.2814, 161.2814,   4.9386,   4.9390, 161.2814, 161.2814,\n",
      "        161.2814, 161.2814, 161.2814,  22.2714,  22.2714,   4.9382, 161.2814,\n",
      "        161.2814, 161.2814, 161.2814, 161.2814,  22.2714,  22.2714, 161.2814,\n",
      "         22.2714,  22.2714,   5.2026, 161.2814, 161.2814, 161.2814, 161.2814,\n",
      "        161.2814,  22.2714,  22.2714, 161.2814,  22.2714,  22.2714,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 161.2814,   5.2026,   5.2025, 161.2814,   5.2026,\n",
      "          5.2025, 161.2814,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        161.2814, 161.2814, 161.2814, 161.2814,  22.2714,  22.2714,  22.2714,\n",
      "         22.2714, 161.2814, 161.2814, 161.2814,  22.2714,  22.2714,  22.2714,\n",
      "         22.2714,   5.2026,  22.2714,  22.2714,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(81.7202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 111 was 91.5%\n",
      "tensor([1.6475e-04, 7.3530e-04, 9.5603e-04, 7.0180e-04, 0.0000e+00, 2.6973e-05,\n",
      "        0.0000e+00, 1.2640e-06, 3.8715e-04, 5.0130e-04, 4.8150e-04, 4.6868e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6099e-04, 4.4656e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.5544e-01, 5.2457e-01, 2.0634e+00, 2.0949e+00, 4.2776e-04,\n",
      "        0.0000e+00, 4.8483e-01, 2.1351e+00, 4.4389e-01, 2.1762e+00, 6.0971e-01,\n",
      "        9.1530e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 88.1340, 101.3168, 113.0711, 120.0608,   4.9353,   4.9345,   4.9360,\n",
      "        161.7927, 161.7927, 161.7927,   4.9359,   4.9357, 161.7927, 161.7927,\n",
      "        161.7927, 161.7927, 161.7927,  22.3533,  22.3533,   4.9367, 161.7927,\n",
      "        161.7927, 161.7927, 161.7927, 161.7927,  22.3533,  22.3533, 161.7927,\n",
      "         22.3533,  22.3533,   5.2026, 161.7927, 161.7927, 161.7927, 161.7927,\n",
      "        161.7927,  22.3533,  22.3533, 161.7927,  22.3533,  22.3533,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 161.7927,   5.2026,   5.2025, 161.7927,   5.2026,\n",
      "          5.2025, 161.7927,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        161.7927, 161.7927, 161.7927, 161.7927,  22.3533,  22.3533,  22.3533,\n",
      "         22.3533, 161.7927, 161.7927, 161.7927,  22.3533,  22.3533,  22.3533,\n",
      "         22.3533,   5.2026,  22.3533,  22.3533,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.5671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 112 was 91.5%\n",
      "tensor([1.9937e-04, 7.2322e-04, 9.5837e-04, 7.0487e-04, 0.0000e+00, 2.7779e-05,\n",
      "        1.5966e-08, 7.7820e-07, 3.7956e-04, 4.6801e-04, 4.5069e-04, 4.3703e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3051e-04, 4.1745e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.5340e-01, 5.2272e-01, 2.0556e+00, 2.0869e+00, 3.9899e-04,\n",
      "        0.0000e+00, 4.8304e-01, 2.1270e+00, 4.4220e-01, 2.1680e+00, 6.0728e-01,\n",
      "        9.1562e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 88.3267, 101.5589, 113.3722, 120.4044,   4.9331,   4.9337,   4.9325,\n",
      "        162.3027, 162.3027, 162.3027,   4.9331,   4.9341, 162.3027, 162.3027,\n",
      "        162.3027, 162.3027, 162.3027,  22.4351,  22.4351,   4.9322, 162.3027,\n",
      "        162.3027, 162.3027, 162.3027, 162.3027,  22.4351,  22.4351, 162.3027,\n",
      "         22.4351,  22.4351,   5.2026, 162.3027, 162.3027, 162.3027, 162.3027,\n",
      "        162.3027,  22.4351,  22.4351, 162.3027,  22.4351,  22.4351,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 162.3027,   5.2026,   5.2025, 162.3027,   5.2026,\n",
      "          5.2025, 162.3027,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        162.3027, 162.3027, 162.3027, 162.3027,  22.4351,  22.4351,  22.4351,\n",
      "         22.4351, 162.3027, 162.3027, 162.3027,  22.4351,  22.4351,  22.4351,\n",
      "         22.4351,   5.2026,  22.4351,  22.4351,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(82.1475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 113 was 91.5%\n",
      "tensor([0.0000e+00, 1.4905e-03, 1.3844e-03, 1.0274e-03, 2.9719e-04, 2.4104e-05,\n",
      "        0.0000e+00, 1.9163e-05, 3.7584e-04, 1.9810e-03, 1.9055e-03, 1.8523e-03,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 1.8260e-03, 1.7693e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.5129e-01, 5.2062e-01, 2.0516e+00, 2.0829e+00, 1.6967e-03,\n",
      "        0.0000e+00, 4.8086e-01, 2.1233e+00, 4.4021e-01, 2.1645e+00, 6.0456e-01,\n",
      "        9.1578e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 88.5211, 101.8018, 113.6731, 120.7414,   4.9309,   4.9302,   4.9311,\n",
      "        162.8116, 162.8116, 162.8116,   4.9304,   4.9295, 162.8116, 162.8116,\n",
      "        162.8116, 162.8116, 162.8116,  22.5169,  22.5169,   4.9312, 162.8116,\n",
      "        162.8116, 162.8116, 162.8116, 162.8116,  22.5169,  22.5169, 162.8116,\n",
      "         22.5169,  22.5169,   5.2026, 162.8116, 162.8116, 162.8116, 162.8116,\n",
      "        162.8116,  22.5169,  22.5169, 162.8116,  22.5169,  22.5169,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 162.8116,   5.2026,   5.2025, 162.8116,   5.2026,\n",
      "          5.2025, 162.8116,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        162.8116, 162.8116, 162.8116, 162.8116,  22.5169,  22.5169,  22.5169,\n",
      "         22.5169, 162.8116, 162.8116, 162.8116,  22.5169,  22.5169,  22.5169,\n",
      "         22.5169,   5.2026,  22.5169,  22.5169,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.9985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 114 was 91.6%\n",
      "tensor([0.0000e+00, 1.4989e-03, 1.3969e-03, 1.0319e-03, 3.0152e-04, 2.5106e-05,\n",
      "        0.0000e+00, 1.8059e-05, 3.6858e-04, 1.9518e-03, 1.8794e-03, 1.8245e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7996e-03, 1.7457e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.4937e-01, 5.1873e-01, 2.0439e+00, 2.0751e+00, 1.6707e-03,\n",
      "        0.0000e+00, 4.7918e-01, 2.1154e+00, 4.3850e-01, 2.1566e+00, 6.0217e-01,\n",
      "        9.1609e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 88.7153, 102.0443, 113.9732, 121.0767,   4.9274,   4.9294,   4.9276,\n",
      "        163.3192, 163.3192, 163.3192,   4.9283,   4.9286, 163.3192, 163.3192,\n",
      "        163.3192, 163.3192, 163.3192,  22.5987,  22.5987,   4.9268, 163.3192,\n",
      "        163.3192, 163.3192, 163.3192, 163.3192,  22.5987,  22.5987, 163.3192,\n",
      "         22.5987,  22.5987,   5.2026, 163.3192, 163.3192, 163.3192, 163.3192,\n",
      "        163.3192,  22.5987,  22.5987, 163.3192,  22.5987,  22.5987,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 163.3192,   5.2026,   5.2025, 163.3192,   5.2026,\n",
      "          5.2025, 163.3192,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        163.3192, 163.3192, 163.3192, 163.3192,  22.5987,  22.5987,  22.5987,\n",
      "         22.5987, 163.3192, 163.3192, 163.3192,  22.5987,  22.5987,  22.5987,\n",
      "         22.5987,   5.2026,  22.5987,  22.5987,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.8464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 115 was 91.6%\n",
      "tensor([0.0000e+00, 1.5084e-03, 1.4101e-03, 1.0369e-03, 3.0595e-04, 2.6114e-05,\n",
      "        0.0000e+00, 1.6980e-05, 3.6151e-04, 1.9249e-03, 1.8503e-03, 1.7987e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7734e-03, 1.7184e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.4761e-01, 5.1687e-01, 2.0361e+00, 2.0674e+00, 1.6479e-03,\n",
      "        0.0000e+00, 4.7738e-01, 2.1076e+00, 4.3683e-01, 2.1487e+00, 5.9985e-01,\n",
      "        9.1640e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 88.9095, 102.2865, 114.2727, 121.4102,   4.9258,   4.9246,   4.9255,\n",
      "        163.8258, 163.8258, 163.8258,   4.9256,   4.9253, 163.8258, 163.8258,\n",
      "        163.8258, 163.8258, 163.8258,  22.6804,  22.6804,   4.9258, 163.8258,\n",
      "        163.8258, 163.8258, 163.8258, 163.8258,  22.6804,  22.6804, 163.8258,\n",
      "         22.6804,  22.6804,   5.2026, 163.8258, 163.8258, 163.8258, 163.8258,\n",
      "        163.8258,  22.6804,  22.6804, 163.8258,  22.6804,  22.6804,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 163.8258,   5.2026,   5.2025, 163.8258,   5.2026,\n",
      "          5.2025, 163.8258,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        163.8258, 163.8258, 163.8258, 163.8258,  22.6804,  22.6804,  22.6804,\n",
      "         22.6804, 163.8258, 163.8258, 163.8258,  22.6804,  22.6804,  22.6804,\n",
      "         22.6804,   5.2026,  22.6804,  22.6804,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(81.7012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 116 was 91.6%\n",
      "tensor([0.0000e+00, 1.5181e-03, 1.4237e-03, 1.0422e-03, 3.1017e-04, 2.7038e-05,\n",
      "        0.0000e+00, 1.6033e-05, 3.5448e-04, 1.8962e-03, 1.8261e-03, 1.7724e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7480e-03, 1.6950e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.4564e-01, 5.1508e-01, 2.0284e+00, 2.0596e+00, 1.6228e-03,\n",
      "        0.0000e+00, 4.7558e-01, 2.0998e+00, 4.3519e-01, 2.1407e+00, 5.9744e-01,\n",
      "        9.1672e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 89.1034, 102.5283, 114.5714, 121.7422,   4.9203,   4.9237,   4.9235,\n",
      "        164.3311, 164.3311, 164.3311,   4.9228,   4.9243, 164.3311, 164.3311,\n",
      "        164.3311, 164.3311, 164.3311,  22.7622,  22.7622,   4.9225, 164.3311,\n",
      "        164.3311, 164.3311, 164.3311, 164.3311,  22.7622,  22.7622, 164.3311,\n",
      "         22.7622,  22.7622,   5.2026, 164.3311, 164.3311, 164.3311, 164.3311,\n",
      "        164.3311,  22.7622,  22.7622, 164.3311,  22.7622,  22.7622,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 164.3311,   5.2026,   5.2025, 164.3311,   5.2026,\n",
      "          5.2025, 164.3311,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        164.3311, 164.3311, 164.3311, 164.3311,  22.7622,  22.7622,  22.7622,\n",
      "         22.7622, 164.3311, 164.3311, 164.3311,  22.7622,  22.7622,  22.7622,\n",
      "         22.7622,   5.2026,  22.7622,  22.7622,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.5515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 117 was 91.7%\n",
      "tensor([0.0000e+00, 1.5281e-03, 1.4374e-03, 1.0475e-03, 3.1415e-04, 2.7904e-05,\n",
      "        0.0000e+00, 1.5145e-05, 3.4775e-04, 1.8737e-03, 1.7995e-03, 1.7481e-03,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 1.7246e-03, 1.6704e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.4375e-01, 5.1333e-01, 2.0210e+00, 2.0520e+00, 1.6014e-03,\n",
      "        0.0000e+00, 4.7390e-01, 2.0922e+00, 4.3361e-01, 2.1330e+00, 5.9520e-01,\n",
      "        9.1702e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 89.2974, 102.7698, 114.8696, 122.0723,   4.9187,   4.9203,   4.9208,\n",
      "        164.8354, 164.8354, 164.8354,   4.9208,   4.9197, 164.8354, 164.8354,\n",
      "        164.8354, 164.8354, 164.8354,  22.8438,  22.8438,   4.9215, 164.8354,\n",
      "        164.8354, 164.8354, 164.8354, 164.8354,  22.8438,  22.8438, 164.8354,\n",
      "         22.8438,  22.8438,   5.2026, 164.8354, 164.8354, 164.8354, 164.8354,\n",
      "        164.8354,  22.8438,  22.8438, 164.8354,  22.8438,  22.8438,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 164.8354,   5.2026,   5.2025, 164.8354,   5.2026,\n",
      "          5.2025, 164.8354,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        164.8354, 164.8354, 164.8354, 164.8354,  22.8438,  22.8438,  22.8438,\n",
      "         22.8438, 164.8354, 164.8354, 164.8354,  22.8438,  22.8438,  22.8438,\n",
      "         22.8438,   5.2026,  22.8438,  22.8438,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.4074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 118 was 91.7%\n",
      "tensor([0.0000e+00, 1.5391e-03, 1.4523e-03, 1.0532e-03, 3.1827e-04, 2.8798e-05,\n",
      "        0.0000e+00, 1.4243e-05, 3.4105e-04, 1.8452e-03, 1.7746e-03, 1.7224e-03,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 1.6990e-03, 1.6480e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.4188e-01, 5.1139e-01, 2.0134e+00, 2.0444e+00, 1.5767e-03,\n",
      "        0.0000e+00, 4.7221e-01, 2.0844e+00, 4.3199e-01, 2.1251e+00, 5.9288e-01,\n",
      "        9.1733e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 89.4914, 103.0110, 115.1669, 122.4010,   4.9171,   4.9187,   4.9173,\n",
      "        165.3385, 165.3385, 165.3385,   4.9179,   4.9181, 165.3385, 165.3385,\n",
      "        165.3385, 165.3385, 165.3385,  22.9255,  22.9255,   4.9170, 165.3385,\n",
      "        165.3385, 165.3385, 165.3385, 165.3385,  22.9255,  22.9255, 165.3385,\n",
      "         22.9255,  22.9255,   5.2026, 165.3385, 165.3385, 165.3385, 165.3385,\n",
      "        165.3385,  22.9255,  22.9255, 165.3385,  22.9255,  22.9255,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 165.3385,   5.2026,   5.2025, 165.3385,   5.2026,\n",
      "          5.2025, 165.3385,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        165.3385, 165.3385, 165.3385, 165.3385,  22.9255,  22.9255,  22.9255,\n",
      "         22.9255, 165.3385, 165.3385, 165.3385,  22.9255,  22.9255,  22.9255,\n",
      "         22.9255,   5.2026,  22.9255,  22.9255,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.2618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 119 was 91.7%\n",
      "tensor([0.0000e+00, 1.5511e-03, 1.4679e-03, 1.0596e-03, 3.2276e-04, 2.9672e-05,\n",
      "        0.0000e+00, 1.3401e-05, 3.3453e-04, 1.8179e-03, 1.7477e-03, 1.6983e-03,\n",
      "        3.2526e-19, 0.0000e+00, 0.0000e+00, 1.6748e-03, 1.6227e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.4014e-01, 5.0964e-01, 2.0057e+00, 2.0368e+00, 1.5551e-03,\n",
      "        0.0000e+00, 4.7041e-01, 2.0768e+00, 4.3030e-01, 2.1174e+00, 5.9056e-01,\n",
      "        9.1763e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 89.6853, 103.2519, 115.4635, 122.7282,   4.9155,   4.9139,   4.9152,\n",
      "        165.8406, 165.8406, 165.8406,   4.9152,   4.9147, 165.8406, 165.8406,\n",
      "        165.8406, 165.8406, 165.8406,  23.0071,  23.0071,   4.9160, 165.8406,\n",
      "        165.8406, 165.8406, 165.8406, 165.8406,  23.0071,  23.0071, 165.8406,\n",
      "         23.0071,  23.0071,   5.2026, 165.8406, 165.8406, 165.8406, 165.8406,\n",
      "        165.8406,  23.0071,  23.0071, 165.8406,  23.0071,  23.0071,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 165.8406,   5.2026,   5.2025, 165.8406,   5.2026,\n",
      "          5.2025, 165.8406,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        165.8406, 165.8406, 165.8406, 165.8406,  23.0071,  23.0071,  23.0071,\n",
      "         23.0071, 165.8406, 165.8406, 165.8406,  23.0071,  23.0071,  23.0071,\n",
      "         23.0071,   5.2026,  23.0071,  23.0071,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(81.1201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 120 was 91.7%\n",
      "tensor([0.0000e+00, 1.5627e-03, 1.4832e-03, 1.0660e-03, 3.2666e-04, 3.0423e-05,\n",
      "        0.0000e+00, 1.2656e-05, 3.2820e-04, 1.7916e-03, 1.7257e-03, 1.6744e-03,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 1.6517e-03, 1.6014e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.3821e-01, 5.0790e-01, 1.9984e+00, 2.0293e+00, 1.5321e-03,\n",
      "        0.0000e+00, 4.6871e-01, 2.0693e+00, 4.2874e-01, 2.1097e+00, 5.8828e-01,\n",
      "        9.1793e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 89.8790, 103.4924, 115.7592, 123.0541,   4.9112,   4.9130,   4.9131,\n",
      "        166.3416, 166.3416, 166.3416,   4.9124,   4.9138, 166.3416, 166.3416,\n",
      "        166.3416, 166.3416, 166.3416,  23.0887,  23.0887,   4.9115, 166.3416,\n",
      "        166.3416, 166.3416, 166.3416, 166.3416,  23.0887,  23.0887, 166.3416,\n",
      "         23.0887,  23.0887,   5.2026, 166.3416, 166.3416, 166.3416, 166.3416,\n",
      "        166.3416,  23.0887,  23.0887, 166.3416,  23.0887,  23.0887,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 166.3416,   5.2026,   5.2025, 166.3416,   5.2026,\n",
      "          5.2025, 166.3416,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        166.3416, 166.3416, 166.3416, 166.3416,  23.0887,  23.0887,  23.0887,\n",
      "         23.0887, 166.3416, 166.3416, 166.3416,  23.0887,  23.0887,  23.0887,\n",
      "         23.0887,   5.2026,  23.0887,  23.0887,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(80.9750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 121 was 91.8%\n",
      "tensor([0.0000e+00, 1.5747e-03, 1.4988e-03, 1.0724e-03, 3.3047e-04, 3.1145e-05,\n",
      "        0.0000e+00, 1.1938e-05, 3.2196e-04, 1.7688e-03, 1.6999e-03, 1.6508e-03,\n",
      "        7.5894e-19, 0.0000e+00, 0.0000e+00, 1.6289e-03, 1.5776e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.3638e-01, 5.0622e-01, 1.9910e+00, 2.0218e+00, 1.5124e-03,\n",
      "        0.0000e+00, 4.6699e-01, 2.0618e+00, 4.2715e-01, 2.1022e+00, 5.8606e-01,\n",
      "        9.1823e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 90.0726, 103.7327, 116.0544, 123.3785,   4.9096,   4.9103,   4.9096,\n",
      "        166.8415, 166.8415, 166.8415,   4.9103,   4.9091, 166.8415, 166.8415,\n",
      "        166.8415, 166.8415, 166.8415,  23.1703,  23.1703,   4.9104, 166.8415,\n",
      "        166.8415, 166.8415, 166.8415, 166.8415,  23.1703,  23.1703, 166.8415,\n",
      "         23.1703,  23.1703,   5.2026, 166.8415, 166.8415, 166.8415, 166.8415,\n",
      "        166.8415,  23.1703,  23.1703, 166.8415,  23.1703,  23.1703,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 166.8415,   5.2026,   5.2025, 166.8415,   5.2026,\n",
      "          5.2025, 166.8415,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        166.8415, 166.8415, 166.8415, 166.8415,  23.1703,  23.1703,  23.1703,\n",
      "         23.1703, 166.8415, 166.8415, 166.8415,  23.1703,  23.1703,  23.1703,\n",
      "         23.1703,   5.2026,  23.1703,  23.1703,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.8353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 122 was 91.8%\n",
      "tensor([0.0000e+00, 1.5878e-03, 1.5156e-03, 1.0789e-03, 3.3440e-04, 3.1870e-05,\n",
      "        0.0000e+00, 1.1185e-05, 3.1580e-04, 1.7413e-03, 1.6753e-03, 1.6266e-03,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 1.6045e-03, 1.5558e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.3461e-01, 5.0430e-01, 1.9835e+00, 2.0144e+00, 1.4886e-03,\n",
      "        0.0000e+00, 4.6534e-01, 2.0542e+00, 4.2555e-01, 2.0945e+00, 5.8377e-01,\n",
      "        9.1853e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 90.2660, 103.9726, 116.3488, 123.7016,   4.9074,   4.9080,   4.9075,\n",
      "        167.3404, 167.3404, 167.3404,   4.9068,   4.9081, 167.3404, 167.3404,\n",
      "        167.3404, 167.3404, 167.3404,  23.2519,  23.2519,   4.9059, 167.3404,\n",
      "        167.3404, 167.3404, 167.3404, 167.3404,  23.2519,  23.2519, 167.3404,\n",
      "         23.2519,  23.2519,   5.2026, 167.3404, 167.3404, 167.3404, 167.3404,\n",
      "        167.3404,  23.2519,  23.2519, 167.3404,  23.2519,  23.2519,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 167.3404,   5.2026,   5.2025, 167.3404,   5.2026,\n",
      "          5.2025, 167.3404,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        167.3404, 167.3404, 167.3404, 167.3404,  23.2519,  23.2519,  23.2519,\n",
      "         23.2519, 167.3404, 167.3404, 167.3404,  23.2519,  23.2519,  23.2519,\n",
      "         23.2519,   5.2026,  23.2519,  23.2519,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.6934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 123 was 91.8%\n",
      "tensor([0.0000e+00, 1.6005e-03, 1.5317e-03, 1.0860e-03, 3.3818e-04, 3.2484e-05,\n",
      "        0.0000e+00, 1.0552e-05, 3.0987e-04, 1.7173e-03, 1.6514e-03, 1.6039e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5830e-03, 1.5328e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.3279e-01, 5.0270e-01, 1.9763e+00, 2.0070e+00, 1.4694e-03,\n",
      "        0.0000e+00, 4.6362e-01, 2.0469e+00, 4.2394e-01, 2.0871e+00, 5.8155e-01,\n",
      "        9.1883e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 90.4593, 104.2123, 116.6424, 124.0234,   4.9051,   4.9045,   4.9048,\n",
      "        167.8383, 167.8383, 167.8383,   4.9053,   4.9034, 167.8383, 167.8383,\n",
      "        167.8383, 167.8383, 167.8383,  23.3334,  23.3334,   4.9049, 167.8383,\n",
      "        167.8383, 167.8383, 167.8383, 167.8383,  23.3334,  23.3334, 167.8383,\n",
      "         23.3334,  23.3334,   5.2026, 167.8383, 167.8383, 167.8383, 167.8383,\n",
      "        167.8383,  23.3334,  23.3334, 167.8383,  23.3334,  23.3334,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 167.8383,   5.2026,   5.2025, 167.8383,   5.2026,\n",
      "          5.2025, 167.8383,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        167.8383, 167.8383, 167.8383, 167.8383,  23.3334,  23.3334,  23.3334,\n",
      "         23.3334, 167.8383, 167.8383, 167.8383,  23.3334,  23.3334,  23.3334,\n",
      "         23.3334,   5.2026,  23.3334,  23.3334,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.5554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 124 was 91.9%\n",
      "tensor([0.0000e+00, 1.6137e-03, 1.5486e-03, 1.0927e-03, 3.4174e-04, 3.3070e-05,\n",
      "        0.0000e+00, 9.8975e-06, 3.0405e-04, 1.6919e-03, 1.6285e-03, 1.5805e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5591e-03, 1.5125e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.3102e-01, 5.0089e-01, 1.9690e+00, 1.9998e+00, 1.4466e-03,\n",
      "        0.0000e+00, 4.6196e-01, 2.0395e+00, 4.2241e-01, 2.0795e+00, 5.7933e-01,\n",
      "        9.1912e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 90.6528, 104.4519, 116.9353, 124.3441,   4.9008,   4.9036,   4.9026,\n",
      "        168.3351, 168.3351, 168.3351,   4.9005,   4.9024, 168.3351, 168.3351,\n",
      "        168.3351, 168.3351, 168.3351,  23.4149,  23.4149,   4.9022, 168.3351,\n",
      "        168.3351, 168.3351, 168.3351, 168.3351,  23.4149,  23.4149, 168.3351,\n",
      "         23.4149,  23.4149,   5.2026, 168.3351, 168.3351, 168.3351, 168.3351,\n",
      "        168.3351,  23.4149,  23.4149, 168.3351,  23.4149,  23.4149,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 168.3351,   5.2026,   5.2025, 168.3351,   5.2026,\n",
      "          5.2025, 168.3351,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        168.3351, 168.3351, 168.3351, 168.3351,  23.4149,  23.4149,  23.4149,\n",
      "         23.4149, 168.3351, 168.3351, 168.3351,  23.4149,  23.4149,  23.4149,\n",
      "         23.4149,   5.2026,  23.4149,  23.4149,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.4147, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 125 was 91.9%\n",
      "tensor([0.0000e+00, 1.6263e-03, 1.5646e-03, 1.0995e-03, 3.4478e-04, 3.3551e-05,\n",
      "        0.0000e+00, 9.3158e-06, 2.9844e-04, 1.6701e-03, 1.6041e-03, 1.5585e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5393e-03, 1.4900e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.2916e-01, 4.9919e-01, 1.9619e+00, 1.9926e+00, 1.4268e-03,\n",
      "        0.0000e+00, 4.6045e-01, 2.0321e+00, 4.2083e-01, 2.0722e+00, 5.7719e-01,\n",
      "        9.1941e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 90.8462, 104.6913, 117.2276, 124.6634,   4.8985,   4.8987,   4.8992,\n",
      "        168.8310, 168.8310, 168.8310,   4.8995,   4.8997, 168.8310, 168.8310,\n",
      "        168.8310, 168.8310, 168.8310,  23.4963,  23.4963,   4.9006, 168.8310,\n",
      "        168.8310, 168.8310, 168.8310, 168.8310,  23.4963,  23.4963, 168.8310,\n",
      "         23.4963,  23.4963,   5.2026, 168.8310, 168.8310, 168.8310, 168.8310,\n",
      "        168.8310,  23.4963,  23.4963, 168.8310,  23.4963,  23.4963,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 168.8310,   5.2026,   5.2025, 168.8310,   5.2026,\n",
      "          5.2025, 168.8310,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        168.8310, 168.8310, 168.8310, 168.8310,  23.4963,  23.4963,  23.4963,\n",
      "         23.4963, 168.8310, 168.8310, 168.8310,  23.4963,  23.4963,  23.4963,\n",
      "         23.4963,   5.2026,  23.4963,  23.4963,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(80.2788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 126 was 91.9%\n",
      "tensor([0.0000e+00, 1.6392e-03, 1.5811e-03, 1.1063e-03, 3.4761e-04, 3.3977e-05,\n",
      "        0.0000e+00, 8.7409e-06, 2.9285e-04, 1.6451e-03, 1.5829e-03, 1.5362e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5154e-03, 1.4686e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.2728e-01, 4.9743e-01, 1.9547e+00, 1.9853e+00, 1.4050e-03,\n",
      "        0.0000e+00, 4.5872e-01, 2.0248e+00, 4.1942e-01, 2.0646e+00, 5.7498e-01,\n",
      "        9.1971e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 91.0393, 104.9303, 117.5190, 124.9817,   4.8968,   4.8971,   4.8969,\n",
      "        169.3260, 169.3260, 169.3260,   4.8973,   4.8961, 169.3260, 169.3260,\n",
      "        169.3260, 169.3260, 169.3260,  23.5778,  23.5778,   4.8960, 169.3260,\n",
      "        169.3260, 169.3260, 169.3260, 169.3260,  23.5778,  23.5778, 169.3260,\n",
      "         23.5778,  23.5778,   5.2026, 169.3260, 169.3260, 169.3260, 169.3260,\n",
      "        169.3260,  23.5778,  23.5778, 169.3260,  23.5778,  23.5778,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 169.3260,   5.2026,   5.2025, 169.3260,   5.2026,\n",
      "          5.2025, 169.3260,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        169.3260, 169.3260, 169.3260, 169.3260,  23.5778,  23.5778,  23.5778,\n",
      "         23.5778, 169.3260, 169.3260, 169.3260,  23.5778,  23.5778,  23.5778,\n",
      "         23.5778,   5.2026,  23.5778,  23.5778,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.1404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 127 was 91.9%\n",
      "tensor([0.0000e+00, 1.6530e-03, 1.5985e-03, 1.1137e-03, 3.5123e-04, 3.4416e-05,\n",
      "        0.0000e+00, 8.1580e-06, 2.8739e-04, 1.6194e-03, 1.5579e-03, 1.5122e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4919e-03, 1.4467e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.2564e-01, 4.9575e-01, 1.9475e+00, 1.9780e+00, 1.3848e-03,\n",
      "        0.0000e+00, 4.5704e-01, 2.0175e+00, 4.1778e-01, 2.0573e+00, 5.7276e-01,\n",
      "        9.2000e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 91.2323, 105.1691, 117.8097, 125.2990,   4.8946,   4.8936,   4.8941,\n",
      "        169.8199, 169.8199, 169.8199,   4.8925,   4.8946, 169.8199, 169.8199,\n",
      "        169.8199, 169.8199, 169.8199,  23.6592,  23.6592,   4.8950, 169.8199,\n",
      "        169.8199, 169.8199, 169.8199, 169.8199,  23.6592,  23.6592, 169.8199,\n",
      "         23.6592,  23.6592,   5.2026, 169.8199, 169.8199, 169.8199, 169.8199,\n",
      "        169.8199,  23.6592,  23.6592, 169.8199,  23.6592,  23.6592,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 169.8199,   5.2026,   5.2025, 169.8199,   5.2026,\n",
      "          5.2025, 169.8199,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        169.8199, 169.8199, 169.8199, 169.8199,  23.6592,  23.6592,  23.6592,\n",
      "         23.6592, 169.8199, 169.8199, 169.8199,  23.6592,  23.6592,  23.6592,\n",
      "         23.6592,   5.2026,  23.6592,  23.6592,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(80.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 128 was 92.0%\n",
      "tensor([0.0000e+00, 1.6651e-03, 1.6143e-03, 1.1206e-03, 3.5365e-04, 3.4687e-05,\n",
      "        5.2212e-08, 7.6597e-06, 2.8215e-04, 1.5958e-03, 1.5363e-03, 1.4911e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4726e-03, 1.4255e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.2375e-01, 4.9412e-01, 1.9406e+00, 1.9709e+00, 1.3639e-03,\n",
      "        0.0000e+00, 4.5546e-01, 2.0104e+00, 4.1633e-01, 2.0500e+00, 5.7064e-01,\n",
      "        9.2028e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 91.4249, 105.4075, 118.0995, 125.6154,   4.8908,   4.8921,   4.8926,\n",
      "        170.3129, 170.3129, 170.3129,   4.8915,   4.8911, 170.3129, 170.3129,\n",
      "        170.3129, 170.3129, 170.3129,  23.7406,  23.7406,   4.8904, 170.3129,\n",
      "        170.3129, 170.3129, 170.3129, 170.3129,  23.7406,  23.7406, 170.3129,\n",
      "         23.7406,  23.7406,   5.2026, 170.3129, 170.3129, 170.3129, 170.3129,\n",
      "        170.3129,  23.7406,  23.7406, 170.3129,  23.7406,  23.7406,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 170.3129,   5.2026,   5.2025, 170.3129,   5.2026,\n",
      "          5.2025, 170.3129,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        170.3129, 170.3129, 170.3129, 170.3129,  23.7406,  23.7406,  23.7406,\n",
      "         23.7406, 170.3129, 170.3129, 170.3129,  23.7406,  23.7406,  23.7406,\n",
      "         23.7406,   5.2026,  23.7406,  23.7406,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.8680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 129 was 92.0%\n",
      "tensor([0.0000e+00, 1.6782e-03, 1.6307e-03, 1.1272e-03, 3.5626e-04, 3.4953e-05,\n",
      "        1.7335e-07, 7.1247e-06, 2.7689e-04, 1.5726e-03, 1.5118e-03, 1.4670e-03,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 1.4483e-03, 1.4040e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.2207e-01, 4.9242e-01, 1.9335e+00, 1.9638e+00, 1.3443e-03,\n",
      "        0.0000e+00, 4.5389e-01, 2.0032e+00, 4.1472e-01, 2.0428e+00, 5.6851e-01,\n",
      "        9.2057e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 91.6174, 105.6458, 118.3886, 125.9308,   4.8891,   4.8886,   4.8877,\n",
      "        170.8050, 170.8050, 170.8050,   4.8887,   4.8890, 170.8050, 170.8050,\n",
      "        170.8050, 170.8050, 170.8050,  23.8219,  23.8219,   4.8893, 170.8050,\n",
      "        170.8050, 170.8050, 170.8050, 170.8050,  23.8219,  23.8219, 170.8050,\n",
      "         23.8219,  23.8219,   5.2026, 170.8050, 170.8050, 170.8050, 170.8050,\n",
      "        170.8050,  23.8219,  23.8219, 170.8050,  23.8219,  23.8219,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 170.8050,   5.2026,   5.2025, 170.8050,   5.2026,\n",
      "          5.2025, 170.8050,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        170.8050, 170.8050, 170.8050, 170.8050,  23.8219,  23.8219,  23.8219,\n",
      "         23.8219, 170.8050, 170.8050, 170.8050,  23.8219,  23.8219,  23.8219,\n",
      "         23.8219,   5.2026,  23.8219,  23.8219,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.7358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 130 was 92.0%\n",
      "tensor([0.0000e+00, 1.6905e-03, 1.6469e-03, 1.1339e-03, 3.5844e-04, 3.5124e-05,\n",
      "        3.0068e-07, 6.6165e-06, 2.7175e-04, 1.5467e-03, 1.4887e-03, 1.4458e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4261e-03, 1.3817e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.2030e-01, 4.9070e-01, 1.9264e+00, 1.9567e+00, 1.3219e-03,\n",
      "        0.0000e+00, 4.5221e-01, 1.9961e+00, 4.1333e-01, 2.0354e+00, 5.6634e-01,\n",
      "        9.2085e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 91.8096, 105.8837, 118.6767, 126.2455,   4.8846,   4.8870,   4.8868,\n",
      "        171.2962, 171.2962, 171.2962,   4.8871,   4.8861, 171.2962, 171.2962,\n",
      "        171.2962, 171.2962, 171.2962,  23.9033,  23.9033,   4.8847, 171.2962,\n",
      "        171.2962, 171.2962, 171.2962, 171.2962,  23.9033,  23.9033, 171.2962,\n",
      "         23.9033,  23.9033,   5.2026, 171.2962, 171.2962, 171.2962, 171.2962,\n",
      "        171.2962,  23.9033,  23.9033, 171.2962,  23.9033,  23.9033,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 171.2962,   5.2026,   5.2025, 171.2962,   5.2026,\n",
      "          5.2025, 171.2962,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        171.2962, 171.2962, 171.2962, 171.2962,  23.9033,  23.9033,  23.9033,\n",
      "         23.9033, 171.2962, 171.2962, 171.2962,  23.9033,  23.9033,  23.9033,\n",
      "         23.9033,   5.2026,  23.9033,  23.9033,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(79.5984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 131 was 92.1%\n",
      "tensor([0.0000e+00, 1.7026e-03, 1.6626e-03, 1.1401e-03, 3.6036e-04, 3.5241e-05,\n",
      "        4.3166e-07, 6.1207e-06, 2.6677e-04, 1.5242e-03, 1.4644e-03, 1.4214e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4027e-03, 1.3599e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.1863e-01, 4.8903e-01, 1.9195e+00, 1.9498e+00, 1.3026e-03,\n",
      "        0.0000e+00, 4.5067e-01, 1.9891e+00, 4.1182e-01, 2.0284e+00, 5.6427e-01,\n",
      "        9.2113e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 92.0015, 106.1214, 118.9643, 126.5592,   4.8829,   4.8835,   4.8840,\n",
      "        171.7865, 171.7865, 171.7865,   4.8822,   4.8840, 171.7865, 171.7865,\n",
      "        171.7865, 171.7865, 171.7865,  23.9846,  23.9846,   4.8836, 171.7865,\n",
      "        171.7865, 171.7865, 171.7865, 171.7865,  23.9846,  23.9846, 171.7865,\n",
      "         23.9846,  23.9846,   5.2026, 171.7865, 171.7865, 171.7865, 171.7865,\n",
      "        171.7865,  23.9846,  23.9846, 171.7865,  23.9846,  23.9846,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 171.7865,   5.2026,   5.2025, 171.7865,   5.2026,\n",
      "          5.2025, 171.7865,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        171.7865, 171.7865, 171.7865, 171.7865,  23.9846,  23.9846,  23.9846,\n",
      "         23.9846, 171.7865, 171.7865, 171.7865,  23.9846,  23.9846,  23.9846,\n",
      "         23.9846,   5.2026,  23.9846,  23.9846,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.4680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 132 was 92.1%\n",
      "tensor([1.3742e-05, 1.7131e-03, 1.6773e-03, 1.1464e-03, 3.6160e-04, 3.5234e-05,\n",
      "        5.6363e-07, 5.6723e-06, 2.6180e-04, 1.4985e-03, 1.4411e-03, 1.3987e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3816e-03, 1.3376e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.1673e-01, 4.8743e-01, 1.9127e+00, 1.9427e+00, 1.2803e-03,\n",
      "        0.0000e+00, 4.4909e-01, 1.9819e+00, 4.1034e-01, 2.0211e+00, 5.6213e-01,\n",
      "        9.2142e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 92.1931, 106.3589, 119.2508, 126.8723,   4.8806,   4.8812,   4.8791,\n",
      "        172.2759, 172.2759, 172.2759,   4.8812,   4.8805, 172.2759, 172.2759,\n",
      "        172.2759, 172.2759, 172.2759,  24.0659,  24.0659,   4.8814, 172.2759,\n",
      "        172.2759, 172.2759, 172.2759, 172.2759,  24.0659,  24.0659, 172.2759,\n",
      "         24.0659,  24.0659,   5.2026, 172.2759, 172.2759, 172.2759, 172.2759,\n",
      "        172.2759,  24.0659,  24.0659, 172.2759,  24.0659,  24.0659,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 172.2759,   5.2026,   5.2025, 172.2759,   5.2026,\n",
      "          5.2025, 172.2759,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        172.2759, 172.2759, 172.2759, 172.2759,  24.0659,  24.0659,  24.0659,\n",
      "         24.0659, 172.2759, 172.2759, 172.2759,  24.0659,  24.0659,  24.0659,\n",
      "         24.0659,   5.2026,  24.0659,  24.0659,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.3355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 133 was 92.1%\n",
      "tensor([3.0535e-05, 1.7244e-03, 1.6925e-03, 1.1519e-03, 3.6294e-04, 3.5217e-05,\n",
      "        7.0650e-07, 5.1708e-06, 2.5700e-04, 1.4721e-03, 1.4161e-03, 1.3759e-03,\n",
      "        3.7947e-19, 0.0000e+00, 0.0000e+00, 1.3567e-03, 1.3148e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.1513e-01, 4.8563e-01, 1.9057e+00, 1.9359e+00, 1.2577e-03,\n",
      "        0.0000e+00, 4.4750e-01, 1.9749e+00, 4.0892e-01, 2.0140e+00, 5.6005e-01,\n",
      "        9.2169e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 92.3844, 106.5962, 119.5365, 127.1849,   4.8776,   4.8775,   4.8782,\n",
      "        172.7645, 172.7645, 172.7645,   4.8789,   4.8789, 172.7645, 172.7645,\n",
      "        172.7645, 172.7645, 172.7645,  24.1471,  24.1471,   4.8767, 172.7645,\n",
      "        172.7645, 172.7645, 172.7645, 172.7645,  24.1471,  24.1471, 172.7645,\n",
      "         24.1471,  24.1471,   5.2026, 172.7645, 172.7645, 172.7645, 172.7645,\n",
      "        172.7645,  24.1471,  24.1471, 172.7645,  24.1471,  24.1471,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 172.7645,   5.2026,   5.2025, 172.7645,   5.2026,\n",
      "          5.2025, 172.7645,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        172.7645, 172.7645, 172.7645, 172.7645,  24.1471,  24.1471,  24.1471,\n",
      "         24.1471, 172.7645, 172.7645, 172.7645,  24.1471,  24.1471,  24.1471,\n",
      "         24.1471,   5.2026,  24.1471,  24.1471,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.2029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 134 was 92.1%\n",
      "tensor([4.6378e-05, 1.7337e-03, 1.7061e-03, 1.1577e-03, 3.6364e-04, 3.5076e-05,\n",
      "        8.4759e-07, 4.7366e-06, 2.5228e-04, 1.4476e-03, 1.3924e-03, 1.3510e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3330e-03, 1.2918e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.1338e-01, 4.8412e-01, 1.8989e+00, 1.9289e+00, 1.2375e-03,\n",
      "        0.0000e+00, 4.4584e-01, 1.9681e+00, 4.0747e-01, 2.0069e+00, 5.5799e-01,\n",
      "        9.2197e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 92.5753, 106.8333, 119.8213, 127.4970,   4.8751,   4.8761,   4.8753,\n",
      "        173.2522, 173.2522, 173.2522,   4.8740,   4.8754, 173.2522, 173.2522,\n",
      "        173.2522, 173.2522, 173.2522,  24.2284,  24.2284,   4.8757, 173.2522,\n",
      "        173.2522, 173.2522, 173.2522, 173.2522,  24.2284,  24.2284, 173.2522,\n",
      "         24.2284,  24.2284,   5.2026, 173.2522, 173.2522, 173.2522, 173.2522,\n",
      "        173.2522,  24.2284,  24.2284, 173.2522,  24.2284,  24.2284,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 173.2522,   5.2026,   5.2025, 173.2522,   5.2026,\n",
      "          5.2025, 173.2522,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        173.2522, 173.2522, 173.2522, 173.2522,  24.2284,  24.2284,  24.2284,\n",
      "         24.2284, 173.2522, 173.2522, 173.2522,  24.2284,  24.2284,  24.2284,\n",
      "         24.2284,   5.2026,  24.2284,  24.2284,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.0729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 135 was 92.2%\n",
      "tensor([6.2355e-05, 1.7425e-03, 1.7192e-03, 1.1627e-03, 3.6397e-04, 3.4868e-05,\n",
      "        9.8699e-07, 4.2773e-06, 2.4763e-04, 1.4206e-03, 1.3660e-03, 1.3265e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3103e-03, 1.2684e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.1165e-01, 4.8241e-01, 1.8921e+00, 1.9221e+00, 1.2136e-03,\n",
      "        0.0000e+00, 4.4443e-01, 1.9610e+00, 4.0594e-01, 1.9999e+00, 5.5590e-01,\n",
      "        9.2225e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 92.7659, 107.0702, 120.1051, 127.8087,   4.8727,   4.8711,   4.8737,\n",
      "        173.7390, 173.7390, 173.7390,   4.8730,   4.8725, 173.7390, 173.7390,\n",
      "        173.7390, 173.7390, 173.7390,  24.3096,  24.3096,   4.8723, 173.7390,\n",
      "        173.7390, 173.7390, 173.7390, 173.7390,  24.3096,  24.3096, 173.7390,\n",
      "         24.3096,  24.3096,   5.2026, 173.7390, 173.7390, 173.7390, 173.7390,\n",
      "        173.7390,  24.3096,  24.3096, 173.7390,  24.3096,  24.3096,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 173.7390,   5.2026,   5.2025, 173.7390,   5.2026,\n",
      "          5.2025, 173.7390,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        173.7390, 173.7390, 173.7390, 173.7390,  24.3096,  24.3096,  24.3096,\n",
      "         24.3096, 173.7390, 173.7390, 173.7390,  24.3096,  24.3096,  24.3096,\n",
      "         24.3096,   5.2026,  24.3096,  24.3096,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(78.9416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 136 was 92.2%\n",
      "tensor([7.7737e-05, 1.7502e-03, 1.7313e-03, 1.1675e-03, 3.6368e-04, 3.4578e-05,\n",
      "        1.1282e-06, 3.8465e-06, 2.4310e-04, 1.3939e-03, 1.3423e-03, 1.3007e-03,\n",
      "        5.4210e-20, 0.0000e+00, 0.0000e+00, 1.2843e-03, 1.2451e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.0993e-01, 4.8088e-01, 1.8854e+00, 1.9153e+00, 1.1914e-03,\n",
      "        0.0000e+00, 4.4284e-01, 1.9542e+00, 4.0451e-01, 1.9929e+00, 5.5387e-01,\n",
      "        9.2252e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 92.9560, 107.3069, 120.3879, 128.1202,   4.8690,   4.8702,   4.8687,\n",
      "        174.2250, 174.2250, 174.2250,   4.8695,   4.8710, 174.2250, 174.2250,\n",
      "        174.2250, 174.2250, 174.2250,  24.3908,  24.3908,   4.8706, 174.2250,\n",
      "        174.2250, 174.2250, 174.2250, 174.2250,  24.3908,  24.3908, 174.2250,\n",
      "         24.3908,  24.3908,   5.2026, 174.2250, 174.2250, 174.2250, 174.2250,\n",
      "        174.2250,  24.3908,  24.3908, 174.2250,  24.3908,  24.3908,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 174.2250,   5.2026,   5.2025, 174.2250,   5.2026,\n",
      "          5.2025, 174.2250,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        174.2250, 174.2250, 174.2250, 174.2250,  24.3908,  24.3908,  24.3908,\n",
      "         24.3908, 174.2250, 174.2250, 174.2250,  24.3908,  24.3908,  24.3908,\n",
      "         24.3908,   5.2026,  24.3908,  24.3908,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.8118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 137 was 92.2%\n",
      "tensor([9.2846e-05, 1.7563e-03, 1.7425e-03, 1.1709e-03, 3.6241e-04, 3.4209e-05,\n",
      "        1.2676e-06, 3.3989e-06, 2.3862e-04, 1.3669e-03, 1.3140e-03, 1.2768e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2597e-03, 1.2193e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.0821e-01, 4.7917e-01, 1.8787e+00, 1.9085e+00, 1.1670e-03,\n",
      "        0.0000e+00, 4.4131e-01, 1.9473e+00, 4.0317e-01, 1.9859e+00, 5.5185e-01,\n",
      "        9.2279e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 93.1457, 107.5434, 120.6697, 128.4314,   4.8665,   4.8671,   4.8678,\n",
      "        174.7102, 174.7102, 174.7102,   4.8678,   4.8660, 174.7102, 174.7102,\n",
      "        174.7102, 174.7102, 174.7102,  24.4719,  24.4719,   4.8672, 174.7102,\n",
      "        174.7102, 174.7102, 174.7102, 174.7102,  24.4719,  24.4719, 174.7102,\n",
      "         24.4719,  24.4719,   5.2026, 174.7102, 174.7102, 174.7102, 174.7102,\n",
      "        174.7102,  24.4719,  24.4719, 174.7102,  24.4719,  24.4719,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 174.7102,   5.2026,   5.2025, 174.7102,   5.2026,\n",
      "          5.2025, 174.7102,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        174.7102, 174.7102, 174.7102, 174.7102,  24.4719,  24.4719,  24.4719,\n",
      "         24.4719, 174.7102, 174.7102, 174.7102,  24.4719,  24.4719,  24.4719,\n",
      "         24.4719,   5.2026,  24.4719,  24.4719,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.6818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 138 was 92.3%\n",
      "tensor([1.0830e-04, 1.7616e-03, 1.7529e-03, 1.1743e-03, 3.6136e-04, 3.3773e-05,\n",
      "        1.4089e-06, 2.9418e-06, 2.3421e-04, 1.3372e-03, 1.2861e-03, 1.2474e-03,\n",
      "        1.6263e-19, 0.0000e+00, 0.0000e+00, 1.2315e-03, 1.1945e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.0661e-01, 4.7753e-01, 1.8719e+00, 1.9017e+00, 1.1422e-03,\n",
      "        0.0000e+00, 4.3980e-01, 1.9404e+00, 4.0167e-01, 1.9789e+00, 5.4978e-01,\n",
      "        9.2307e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 93.3349, 107.7798, 120.9505, 128.7426,   4.8641,   4.8655,   4.8642,\n",
      "        175.1946, 175.1946, 175.1946,   4.8629,   4.8650, 175.1946, 175.1946,\n",
      "        175.1946, 175.1946, 175.1946,  24.5531,  24.5531,   4.8643, 175.1946,\n",
      "        175.1946, 175.1946, 175.1946, 175.1946,  24.5531,  24.5531, 175.1946,\n",
      "         24.5531,  24.5531,   5.2026, 175.1946, 175.1946, 175.1946, 175.1946,\n",
      "        175.1946,  24.5531,  24.5531, 175.1946,  24.5531,  24.5531,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 175.1946,   5.2026,   5.2025, 175.1946,   5.2026,\n",
      "          5.2025, 175.1946,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        175.1946, 175.1946, 175.1946, 175.1946,  24.5531,  24.5531,  24.5531,\n",
      "         24.5531, 175.1946, 175.1946, 175.1946,  24.5531,  24.5531,  24.5531,\n",
      "         24.5531,   5.2026,  24.5531,  24.5531,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.5519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 139 was 92.3%\n",
      "tensor([1.2293e-04, 1.7646e-03, 1.7614e-03, 1.1771e-03, 3.5938e-04, 3.3239e-05,\n",
      "        1.5394e-06, 2.5070e-06, 2.2995e-04, 1.3075e-03, 1.2566e-03, 1.2209e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2062e-03, 1.1667e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.0493e-01, 4.7596e-01, 1.8653e+00, 1.8950e+00, 1.1170e-03,\n",
      "        0.0000e+00, 4.3831e-01, 1.9336e+00, 4.0022e-01, 1.9721e+00, 5.4778e-01,\n",
      "        9.2334e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 93.5234, 108.0161, 121.2302, 129.0539,   4.8617,   4.8604,   4.8626,\n",
      "        175.6782, 175.6782, 175.6782,   4.8619,   4.8615, 175.6782, 175.6782,\n",
      "        175.6782, 175.6782, 175.6782,  24.6342,  24.6342,   4.8615, 175.6782,\n",
      "        175.6782, 175.6782, 175.6782, 175.6782,  24.6342,  24.6342, 175.6782,\n",
      "         24.6342,  24.6342,   5.2026, 175.6782, 175.6782, 175.6782, 175.6782,\n",
      "        175.6782,  24.6342,  24.6342, 175.6782,  24.6342,  24.6342,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 175.6782,   5.2026,   5.2025, 175.6782,   5.2026,\n",
      "          5.2025, 175.6782,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        175.6782, 175.6782, 175.6782, 175.6782,  24.6342,  24.6342,  24.6342,\n",
      "         24.6342, 175.6782, 175.6782, 175.6782,  24.6342,  24.6342,  24.6342,\n",
      "         24.6342,   5.2026,  24.6342,  24.6342,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.4235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 140 was 92.3%\n",
      "tensor([1.3742e-04, 1.7657e-03, 1.7685e-03, 1.1789e-03, 3.5629e-04, 3.2615e-05,\n",
      "        1.6653e-06, 2.0698e-06, 2.2570e-04, 1.2760e-03, 1.2286e-03, 1.1907e-03,\n",
      "        1.6263e-19, 0.0000e+00, 0.0000e+00, 1.1758e-03, 1.1397e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.0322e-01, 4.7440e-01, 1.8587e+00, 1.8883e+00, 1.0903e-03,\n",
      "        0.0000e+00, 4.3676e-01, 1.9268e+00, 3.9881e-01, 1.9652e+00, 5.4576e-01,\n",
      "        9.2361e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 93.7114, 108.2522, 121.5086, 129.3655,   4.8579,   4.8595,   4.8575,\n",
      "        176.1610, 176.1610, 176.1610,   4.8583,   4.8605, 176.1610, 176.1610,\n",
      "        176.1610, 176.1610, 176.1610,  24.7153,  24.7153,   4.8593, 176.1610,\n",
      "        176.1610, 176.1610, 176.1610, 176.1610,  24.7153,  24.7153, 176.1610,\n",
      "         24.7153,  24.7153,   5.2026, 176.1610, 176.1610, 176.1610, 176.1610,\n",
      "        176.1610,  24.7153,  24.7153, 176.1610,  24.7153,  24.7153,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 176.1610,   5.2026,   5.2025, 176.1610,   5.2026,\n",
      "          5.2025, 176.1610,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        176.1610, 176.1610, 176.1610, 176.1610,  24.7153,  24.7153,  24.7153,\n",
      "         24.7153, 176.1610, 176.1610, 176.1610,  24.7153,  24.7153,  24.7153,\n",
      "         24.7153,   5.2026,  24.7153,  24.7153,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 141 was 92.1%\n",
      "tensor([1.0588e-22, 4.2889e-06, 3.6803e-06, 3.2803e-06, 3.0342e-06, 2.3511e-08,\n",
      "        1.8023e-08, 0.0000e+00, 1.4942e-08, 6.3149e-06, 6.0620e-06, 5.8829e-06,\n",
      "        3.9377e-04, 2.9906e-04, 2.9277e-04, 5.8079e-06, 5.6198e-06, 2.1279e-04,\n",
      "        2.0722e-04, 5.2469e-01, 4.9463e-01, 1.9063e+00, 1.9364e+00, 5.3791e-06,\n",
      "        2.0068e-04, 4.5545e-01, 1.9759e+00, 4.1607e-01, 2.0158e+00, 5.4176e-01,\n",
      "        9.2164e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 93.9199, 108.5104, 121.8150, 129.6516,   4.8553,   4.8556,   4.8566,\n",
      "        176.6430, 176.6430, 176.6430,   4.8565,   4.8554, 176.6430, 176.6430,\n",
      "        176.6430, 176.6430, 176.6430,  24.7964,  24.7964,   4.8563, 176.6430,\n",
      "        176.6430, 176.6430, 176.6430, 176.6430,  24.7964,  24.7964, 176.6430,\n",
      "         24.7964,  24.7964,   5.2026, 176.6430, 176.6430, 176.6430, 176.6430,\n",
      "        176.6430,  24.7964,  24.7964, 176.6430,  24.7964,  24.7964,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 176.6430,   5.2026,   5.2025, 176.6430,   5.2026,\n",
      "          5.2025, 176.6430,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        176.6430, 176.6430, 176.6430, 176.6430,  24.7964,  24.7964,  24.7964,\n",
      "         24.7964, 176.6430, 176.6430, 176.6430,  24.7964,  24.7964,  24.7964,\n",
      "         24.7964,   5.2026,  24.7964,  24.7964,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 142 was 92.1%\n",
      "tensor([1.7205e-22, 4.2766e-06, 3.6690e-06, 3.2696e-06, 3.0255e-06, 2.3176e-08,\n",
      "        1.7752e-08, 0.0000e+00, 1.4714e-08, 6.2901e-06, 6.0416e-06, 5.8577e-06,\n",
      "        3.8658e-04, 2.9358e-04, 2.8709e-04, 5.7829e-06, 5.6022e-06, 2.0834e-04,\n",
      "        2.0320e-04, 5.2271e-01, 4.9285e-01, 1.8992e+00, 1.9292e+00, 5.3585e-06,\n",
      "        1.9666e-04, 4.5384e-01, 1.9685e+00, 4.1446e-01, 2.0083e+00, 5.3967e-01,\n",
      "        9.2193e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 94.1274, 108.7678, 122.1189, 129.9400,   4.8534,   4.8538,   4.8514,\n",
      "        177.1243, 177.1243, 177.1243,   4.8527,   4.8537, 177.1243, 177.1243,\n",
      "        177.1243, 177.1243, 177.1243,  24.8775,  24.8775,   4.8534, 177.1243,\n",
      "        177.1243, 177.1243, 177.1243, 177.1243,  24.8775,  24.8775, 177.1243,\n",
      "         24.8775,  24.8775,   5.2026, 177.1243, 177.1243, 177.1243, 177.1243,\n",
      "        177.1243,  24.8775,  24.8775, 177.1243,  24.8775,  24.8775,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 177.1243,   5.2026,   5.2025, 177.1243,   5.2026,\n",
      "          5.2025, 177.1243,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        177.1243, 177.1243, 177.1243, 177.1243,  24.8775,  24.8775,  24.8775,\n",
      "         24.8775, 177.1243, 177.1243, 177.1243,  24.8775,  24.8775,  24.8775,\n",
      "         24.8775,   5.2026,  24.8775,  24.8775,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 143 was 92.2%\n",
      "tensor([3.9705e-23, 4.2647e-06, 3.6583e-06, 3.2592e-06, 3.0170e-06, 2.2850e-08,\n",
      "        1.7491e-08, 0.0000e+00, 1.4494e-08, 6.2660e-06, 6.0174e-06, 5.8401e-06,\n",
      "        3.7969e-04, 2.8797e-04, 2.8189e-04, 5.7634e-06, 5.5803e-06, 2.0434e-04,\n",
      "        1.9913e-04, 5.2080e-01, 4.9114e-01, 1.8924e+00, 1.9221e+00, 5.3389e-06,\n",
      "        1.9279e-04, 4.5219e-01, 1.9613e+00, 4.1294e-01, 2.0011e+00, 5.3765e-01,\n",
      "        9.2222e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 94.3342, 109.0245, 122.4204, 130.2300,   4.8494,   4.8485,   4.8504,\n",
      "        177.6048, 177.6048, 177.6048,   4.8516,   4.8500, 177.6048, 177.6048,\n",
      "        177.6048, 177.6048, 177.6048,  24.9585,  24.9585,   4.8511, 177.6048,\n",
      "        177.6048, 177.6048, 177.6048, 177.6048,  24.9585,  24.9585, 177.6048,\n",
      "         24.9585,  24.9585,   5.2026, 177.6048, 177.6048, 177.6048, 177.6048,\n",
      "        177.6048,  24.9585,  24.9585, 177.6048,  24.9585,  24.9585,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 177.6048,   5.2026,   5.2025, 177.6048,   5.2026,\n",
      "          5.2025, 177.6048,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        177.6048, 177.6048, 177.6048, 177.6048,  24.9585,  24.9585,  24.9585,\n",
      "         24.9585, 177.6048, 177.6048, 177.6048,  24.9585,  24.9585,  24.9585,\n",
      "         24.9585,   5.2026,  24.9585,  24.9585,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.5443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 144 was 92.4%\n",
      "tensor([0.0000e+00, 3.2697e-03, 2.6859e-03, 1.9977e-03, 1.4006e-03, 1.4384e-05,\n",
      "        6.1698e-06, 3.8425e-05, 2.1399e-04, 4.3618e-03, 4.1998e-03, 4.0751e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0229e-03, 3.9021e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.9564e-01, 4.6745e-01, 1.8406e+00, 1.8696e+00, 3.7350e-03,\n",
      "        0.0000e+00, 4.3034e-01, 1.9079e+00, 3.9297e-01, 1.9465e+00, 5.3726e-01,\n",
      "        9.2436e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 94.5264, 109.2568, 122.7002, 130.5359,   4.8468,   4.8476,   4.8474,\n",
      "        178.0846, 178.0846, 178.0846,   4.8466,   4.8483, 178.0846, 178.0846,\n",
      "        178.0846, 178.0846, 178.0846,  25.0395,  25.0395,   4.8475, 178.0846,\n",
      "        178.0846, 178.0846, 178.0846, 178.0846,  25.0395,  25.0395, 178.0846,\n",
      "         25.0395,  25.0395,   5.2026, 178.0846, 178.0846, 178.0846, 178.0846,\n",
      "        178.0846,  25.0395,  25.0395, 178.0846,  25.0395,  25.0395,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 178.0846,   5.2026,   5.2025, 178.0846,   5.2026,\n",
      "          5.2025, 178.0846,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        178.0846, 178.0846, 178.0846, 178.0846,  25.0395,  25.0395,  25.0395,\n",
      "         25.0395, 178.0846, 178.0846, 178.0846,  25.0395,  25.0395,  25.0395,\n",
      "         25.0395,   5.2026,  25.0395,  25.0395,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.4189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 145 was 92.4%\n",
      "tensor([0.0000e+00, 3.2719e-03, 2.6847e-03, 1.9922e-03, 1.3939e-03, 1.3878e-05,\n",
      "        6.5691e-06, 3.7129e-05, 2.1003e-04, 4.3219e-03, 4.1579e-03, 4.0392e-03,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 3.9890e-03, 3.8651e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.9393e-01, 4.6598e-01, 1.8341e+00, 1.8628e+00, 3.7014e-03,\n",
      "        0.0000e+00, 4.2884e-01, 1.9011e+00, 3.9152e-01, 1.9397e+00, 5.3526e-01,\n",
      "        9.2462e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 94.7185, 109.4887, 122.9793, 130.8407,   4.8443,   4.8438,   4.8457,\n",
      "        178.5637, 178.5637, 178.5637,   4.8455,   4.8433, 178.5637, 178.5637,\n",
      "        178.5637, 178.5637, 178.5637,  25.1205,  25.1205,   4.8446, 178.5637,\n",
      "        178.5637, 178.5637, 178.5637, 178.5637,  25.1205,  25.1205, 178.5637,\n",
      "         25.1205,  25.1205,   5.2026, 178.5637, 178.5637, 178.5637, 178.5637,\n",
      "        178.5637,  25.1205,  25.1205, 178.5637,  25.1205,  25.1205,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 178.5637,   5.2026,   5.2025, 178.5637,   5.2026,\n",
      "          5.2025, 178.5637,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        178.5637, 178.5637, 178.5637, 178.5637,  25.1205,  25.1205,  25.1205,\n",
      "         25.1205, 178.5637, 178.5637, 178.5637,  25.1205,  25.1205,  25.1205,\n",
      "         25.1205,   5.2026,  25.1205,  25.1205,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(79.2928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 146 was 92.4%\n",
      "tensor([0.0000e+00, 3.2748e-03, 2.6840e-03, 1.9867e-03, 1.3873e-03, 1.3361e-05,\n",
      "        6.9678e-06, 3.5831e-05, 2.0624e-04, 4.2834e-03, 4.1235e-03, 4.0009e-03,\n",
      "        5.4210e-19, 0.0000e+00, 0.0000e+00, 3.9510e-03, 3.8334e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.9238e-01, 4.6439e-01, 1.8276e+00, 1.8564e+00, 3.6688e-03,\n",
      "        0.0000e+00, 4.2742e-01, 1.8946e+00, 3.9014e-01, 1.9331e+00, 5.3334e-01,\n",
      "        9.2488e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 94.9107, 109.7205, 123.2577, 131.1446,   4.8411,   4.8429,   4.8406,\n",
      "        179.0421, 179.0421, 179.0421,   4.8419,   4.8423, 179.0421, 179.0421,\n",
      "        179.0421, 179.0421, 179.0421,  25.2015,  25.2015,   4.8417, 179.0421,\n",
      "        179.0421, 179.0421, 179.0421, 179.0421,  25.2015,  25.2015, 179.0421,\n",
      "         25.2015,  25.2015,   5.2026, 179.0421, 179.0421, 179.0421, 179.0421,\n",
      "        179.0421,  25.2015,  25.2015, 179.0421,  25.2015,  25.2015,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 179.0421,   5.2026,   5.2025, 179.0421,   5.2026,\n",
      "          5.2025, 179.0421,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        179.0421, 179.0421, 179.0421, 179.0421,  25.2015,  25.2015,  25.2015,\n",
      "         25.2015, 179.0421, 179.0421, 179.0421,  25.2015,  25.2015,  25.2015,\n",
      "         25.2015,   5.2026,  25.2015,  25.2015,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.1691, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 147 was 92.5%\n",
      "tensor([0.0000e+00, 3.2777e-03, 2.6832e-03, 1.9810e-03, 1.3805e-03, 1.2811e-05,\n",
      "        7.3652e-06, 3.4553e-05, 2.0247e-04, 4.2450e-03, 4.0834e-03, 3.9679e-03,\n",
      "        2.7105e-19, 0.0000e+00, 0.0000e+00, 3.9176e-03, 3.7956e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.9081e-01, 4.6277e-01, 1.8211e+00, 1.8499e+00, 3.6356e-03,\n",
      "        0.0000e+00, 4.2595e-01, 1.8880e+00, 3.8879e-01, 1.9264e+00, 5.3141e-01,\n",
      "        9.2515e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 95.1028, 109.9520, 123.5355, 131.4475,   4.8385,   4.8377,   4.8397,\n",
      "        179.5197, 179.5197, 179.5197,   4.8389,   4.8386, 179.5197, 179.5197,\n",
      "        179.5197, 179.5197, 179.5197,  25.2824,  25.2824,   4.8400, 179.5197,\n",
      "        179.5197, 179.5197, 179.5197, 179.5197,  25.2824,  25.2824, 179.5197,\n",
      "         25.2824,  25.2824,   5.2026, 179.5197, 179.5197, 179.5197, 179.5197,\n",
      "        179.5197,  25.2824,  25.2824, 179.5197,  25.2824,  25.2824,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 179.5197,   5.2026,   5.2025, 179.5197,   5.2026,\n",
      "          5.2025, 179.5197,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        179.5197, 179.5197, 179.5197, 179.5197,  25.2824,  25.2824,  25.2824,\n",
      "         25.2824, 179.5197, 179.5197, 179.5197,  25.2824,  25.2824,  25.2824,\n",
      "         25.2824,   5.2026,  25.2824,  25.2824,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(79.0475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 148 was 92.5%\n",
      "tensor([0.0000e+00, 3.2804e-03, 2.6827e-03, 1.9759e-03, 1.3739e-03, 1.2263e-05,\n",
      "        7.7274e-06, 3.3428e-05, 1.9878e-04, 4.2066e-03, 4.0503e-03, 3.9312e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8826e-03, 3.7649e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8904e-01, 4.6129e-01, 1.8149e+00, 1.8434e+00, 3.6027e-03,\n",
      "        0.0000e+00, 4.2453e-01, 1.8814e+00, 3.8748e-01, 1.9197e+00, 5.2950e-01,\n",
      "        9.2541e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 95.2948, 110.1833, 123.8127, 131.7494,   4.8359,   4.8368,   4.8358,\n",
      "        179.9967, 179.9967, 179.9967,   4.8359,   4.8369, 179.9967, 179.9967,\n",
      "        179.9967, 179.9967, 179.9967,  25.3634,  25.3634,   4.8351, 179.9967,\n",
      "        179.9967, 179.9967, 179.9967, 179.9967,  25.3634,  25.3634, 179.9967,\n",
      "         25.3634,  25.3634,   5.2026, 179.9967, 179.9967, 179.9967, 179.9967,\n",
      "        179.9967,  25.3634,  25.3634, 179.9967,  25.3634,  25.3634,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 179.9967,   5.2026,   5.2025, 179.9967,   5.2026,\n",
      "          5.2025, 179.9967,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        179.9967, 179.9967, 179.9967, 179.9967,  25.3634,  25.3634,  25.3634,\n",
      "         25.3634, 179.9967, 179.9967, 179.9967,  25.3634,  25.3634,  25.3634,\n",
      "         25.3634,   5.2026,  25.3634,  25.3634,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.9245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 149 was 92.5%\n",
      "tensor([0.0000e+00, 3.2842e-03, 2.6827e-03, 1.9708e-03, 1.3674e-03, 1.1678e-05,\n",
      "        8.1239e-06, 3.2246e-05, 1.9515e-04, 4.1694e-03, 4.0110e-03, 3.8969e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8488e-03, 3.7288e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8754e-01, 4.5978e-01, 1.8084e+00, 1.8370e+00, 3.5721e-03,\n",
      "        0.0000e+00, 4.2300e-01, 1.8750e+00, 3.8611e-01, 1.9131e+00, 5.2756e-01,\n",
      "        9.2567e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 95.4869, 110.4143, 124.0892, 132.0504,   4.8333,   4.8330,   4.8343,\n",
      "        180.4729, 180.4729, 180.4729,   4.8329,   4.8319, 180.4729, 180.4729,\n",
      "        180.4729, 180.4729, 180.4729,  25.4443,  25.4443,   4.8340, 180.4729,\n",
      "        180.4729, 180.4729, 180.4729, 180.4729,  25.4443,  25.4443, 180.4729,\n",
      "         25.4443,  25.4443,   5.2026, 180.4729, 180.4729, 180.4729, 180.4729,\n",
      "        180.4729,  25.4443,  25.4443, 180.4729,  25.4443,  25.4443,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 180.4729,   5.2026,   5.2025, 180.4729,   5.2026,\n",
      "          5.2025, 180.4729,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        180.4729, 180.4729, 180.4729, 180.4729,  25.4443,  25.4443,  25.4443,\n",
      "         25.4443, 180.4729, 180.4729, 180.4729,  25.4443,  25.4443,  25.4443,\n",
      "         25.4443,   5.2026,  25.4443,  25.4443,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.8050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 150 was 92.5%\n",
      "tensor([0.0000e+00, 3.2877e-03, 2.6827e-03, 1.9658e-03, 1.3610e-03, 1.1090e-05,\n",
      "        8.4760e-06, 3.1170e-05, 1.9163e-04, 4.1321e-03, 3.9782e-03, 3.8617e-03,\n",
      "        2.7105e-19, 0.0000e+00, 0.0000e+00, 3.8149e-03, 3.6998e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8587e-01, 4.5825e-01, 1.8022e+00, 1.8306e+00, 3.5395e-03,\n",
      "        0.0000e+00, 4.2167e-01, 1.8685e+00, 3.8476e-01, 1.9066e+00, 5.2570e-01,\n",
      "        9.2592e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 95.6789, 110.6451, 124.3652, 132.3504,   4.8292,   4.8314,   4.8291,\n",
      "        180.9485, 180.9485, 180.9485,   4.8313,   4.8308, 180.9485, 180.9485,\n",
      "        180.9485, 180.9485, 180.9485,  25.5252,  25.5252,   4.8304, 180.9485,\n",
      "        180.9485, 180.9485, 180.9485, 180.9485,  25.5252,  25.5252, 180.9485,\n",
      "         25.5252,  25.5252,   5.2026, 180.9485, 180.9485, 180.9485, 180.9485,\n",
      "        180.9485,  25.5252,  25.5252, 180.9485,  25.5252,  25.5252,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 180.9485,   5.2026,   5.2025, 180.9485,   5.2026,\n",
      "          5.2025, 180.9485,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        180.9485, 180.9485, 180.9485, 180.9485,  25.5252,  25.5252,  25.5252,\n",
      "         25.5252, 180.9485, 180.9485, 180.9485,  25.5252,  25.5252,  25.5252,\n",
      "         25.5252,   5.2026,  25.5252,  25.5252,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(78.6841, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 151 was 92.6%\n",
      "tensor([0.0000e+00, 3.2917e-03, 2.6827e-03, 1.9604e-03, 1.3543e-03, 1.0465e-05,\n",
      "        8.8566e-06, 3.0027e-05, 1.8816e-04, 4.0972e-03, 3.9416e-03, 3.8293e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7811e-03, 3.6639e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8440e-01, 4.5662e-01, 1.7959e+00, 1.8244e+00, 3.5092e-03,\n",
      "        0.0000e+00, 4.2016e-01, 1.8621e+00, 3.8351e-01, 1.9000e+00, 5.2381e-01,\n",
      "        9.2618e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 95.8709, 110.8758, 124.6406, 132.6494,   4.8266,   4.8261,   4.8282,\n",
      "        181.4234, 181.4234, 181.4234,   4.8276,   4.8279, 181.4234, 181.4234,\n",
      "        181.4234, 181.4234, 181.4234,  25.6061,  25.6061,   4.8287, 181.4234,\n",
      "        181.4234, 181.4234, 181.4234, 181.4234,  25.6061,  25.6061, 181.4234,\n",
      "         25.6061,  25.6061,   5.2026, 181.4234, 181.4234, 181.4234, 181.4234,\n",
      "        181.4234,  25.6061,  25.6061, 181.4234,  25.6061,  25.6061,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 181.4234,   5.2026,   5.2025, 181.4234,   5.2026,\n",
      "          5.2025, 181.4234,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        181.4234, 181.4234, 181.4234, 181.4234,  25.6061,  25.6061,  25.6061,\n",
      "         25.6061, 181.4234, 181.4234, 181.4234,  25.6061,  25.6061,  25.6061,\n",
      "         25.6061,   5.2026,  25.6061,  25.6061,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.5670, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 152 was 92.6%\n",
      "tensor([0.0000e+00, 3.2952e-03, 2.6831e-03, 1.9559e-03, 1.3480e-03, 9.8538e-06,\n",
      "        9.1801e-06, 2.9083e-05, 1.8474e-04, 4.0611e-03, 3.9102e-03, 3.7954e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7485e-03, 3.6346e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8262e-01, 4.5521e-01, 1.7898e+00, 1.8180e+00, 3.4783e-03,\n",
      "        0.0000e+00, 4.1879e-01, 1.8557e+00, 3.8222e-01, 1.8935e+00, 5.2195e-01,\n",
      "        9.2643e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 96.0629, 111.1062, 124.9154, 132.9474,   4.8239,   4.8252,   4.8243,\n",
      "        181.8977, 181.8977, 181.8977,   4.8252,   4.8255, 181.8977, 181.8977,\n",
      "        181.8977, 181.8977, 181.8977,  25.6869,  25.6869,   4.8238, 181.8977,\n",
      "        181.8977, 181.8977, 181.8977, 181.8977,  25.6869,  25.6869, 181.8977,\n",
      "         25.6869,  25.6869,   5.2026, 181.8977, 181.8977, 181.8977, 181.8977,\n",
      "        181.8977,  25.6869,  25.6869, 181.8977,  25.6869,  25.6869,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 181.8977,   5.2026,   5.2025, 181.8977,   5.2026,\n",
      "          5.2025, 181.8977,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        181.8977, 181.8977, 181.8977, 181.8977,  25.6869,  25.6869,  25.6869,\n",
      "         25.6869, 181.8977, 181.8977, 181.8977,  25.6869,  25.6869,  25.6869,\n",
      "         25.6869,   5.2026,  25.6869,  25.6869,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.4485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 153 was 92.6%\n",
      "tensor([0.0000e+00, 3.3000e-03, 2.6838e-03, 1.9511e-03, 1.3417e-03, 9.1965e-06,\n",
      "        9.5504e-06, 2.8043e-05, 1.8140e-04, 4.0257e-03, 3.8731e-03, 3.7622e-03,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 3.7159e-03, 3.6010e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8118e-01, 4.5369e-01, 1.7834e+00, 1.8117e+00, 3.4491e-03,\n",
      "        0.0000e+00, 4.1727e-01, 1.8494e+00, 3.8088e-01, 1.8870e+00, 5.2006e-01,\n",
      "        9.2669e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 96.2548, 111.3364, 125.1897, 133.2446,   4.8220,   4.8221,   4.8220,\n",
      "        182.3713, 182.3713, 182.3713,   4.8214,   4.8203, 182.3713, 182.3713,\n",
      "        182.3713, 182.3713, 182.3713,  25.7678,  25.7678,   4.8227, 182.3713,\n",
      "        182.3713, 182.3713, 182.3713, 182.3713,  25.7678,  25.7678, 182.3713,\n",
      "         25.7678,  25.7678,   5.2026, 182.3713, 182.3713, 182.3713, 182.3713,\n",
      "        182.3713,  25.7678,  25.7678, 182.3713,  25.7678,  25.7678,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 182.3713,   5.2026,   5.2025, 182.3713,   5.2026,\n",
      "          5.2025, 182.3713,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        182.3713, 182.3713, 182.3713, 182.3713,  25.7678,  25.7678,  25.7678,\n",
      "         25.7678, 182.3713, 182.3713, 182.3713,  25.7678,  25.7678,  25.7678,\n",
      "         25.7678,   5.2026,  25.7678,  25.7678,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.3338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 154 was 92.6%\n",
      "tensor([0.0000e+00, 3.3044e-03, 2.6846e-03, 1.9466e-03, 1.3355e-03, 8.5430e-06,\n",
      "        9.8759e-06, 2.7093e-05, 1.7814e-04, 3.9891e-03, 3.8407e-03, 3.7294e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6847e-03, 3.5726e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.7957e-01, 4.5215e-01, 1.7773e+00, 1.8055e+00, 3.4176e-03,\n",
      "        0.0000e+00, 4.1596e-01, 1.8430e+00, 3.7955e-01, 1.8806e+00, 5.1820e-01,\n",
      "        9.2694e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 96.4467, 111.5664, 125.4633, 133.5409,   4.8186,   4.8182,   4.8197,\n",
      "        182.8443, 182.8443, 182.8443,   4.8198,   4.8193, 182.8443, 182.8443,\n",
      "        182.8443, 182.8443, 182.8443,  25.8486,  25.8486,   4.8177, 182.8443,\n",
      "        182.8443, 182.8443, 182.8443, 182.8443,  25.8486,  25.8486, 182.8443,\n",
      "         25.8486,  25.8486,   5.2026, 182.8443, 182.8443, 182.8443, 182.8443,\n",
      "        182.8443,  25.8486,  25.8486, 182.8443,  25.8486,  25.8486,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 182.8443,   5.2026,   5.2025, 182.8443,   5.2026,\n",
      "          5.2025, 182.8443,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        182.8443, 182.8443, 182.8443, 182.8443,  25.8486,  25.8486,  25.8486,\n",
      "         25.8486, 182.8443, 182.8443, 182.8443,  25.8486,  25.8486,  25.8486,\n",
      "         25.8486,   5.2026,  25.8486,  25.8486,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(78.2165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 155 was 92.7%\n",
      "tensor([0.0000e+00, 3.3091e-03, 2.6855e-03, 1.9422e-03, 1.3293e-03, 7.8718e-06,\n",
      "        1.0209e-05, 2.6181e-05, 1.7493e-04, 3.9562e-03, 3.8086e-03, 3.6961e-03,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 3.6516e-03, 3.5408e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.7802e-01, 4.5075e-01, 1.7712e+00, 1.7992e+00, 3.3906e-03,\n",
      "        0.0000e+00, 4.1446e-01, 1.8368e+00, 3.7829e-01, 1.8742e+00, 5.1637e-01,\n",
      "        9.2719e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 96.6386, 111.7962, 125.7364, 133.8363,   4.8159,   4.8166,   4.8159,\n",
      "        183.3166, 183.3166, 183.3166,   4.8146,   4.8163, 183.3166, 183.3166,\n",
      "        183.3166, 183.3166, 183.3166,  25.9294,  25.9294,   4.8166, 183.3166,\n",
      "        183.3166, 183.3166, 183.3166, 183.3166,  25.9294,  25.9294, 183.3166,\n",
      "         25.9294,  25.9294,   5.2026, 183.3166, 183.3166, 183.3166, 183.3166,\n",
      "        183.3166,  25.9294,  25.9294, 183.3166,  25.9294,  25.9294,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 183.3166,   5.2026,   5.2025, 183.3166,   5.2026,\n",
      "          5.2025, 183.3166,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        183.3166, 183.3166, 183.3166, 183.3166,  25.9294,  25.9294,  25.9294,\n",
      "         25.9294, 183.3166, 183.3166, 183.3166,  25.9294,  25.9294,  25.9294,\n",
      "         25.9294,   5.2026,  25.9294,  25.9294,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(78.1037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 156 was 92.7%\n",
      "tensor([0.0000e+00, 3.3138e-03, 2.6866e-03, 1.9377e-03, 1.3232e-03, 7.1850e-06,\n",
      "        1.0515e-05, 2.5286e-05, 1.7178e-04, 3.9213e-03, 3.7743e-03, 3.6662e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6233e-03, 3.5101e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.7642e-01, 4.4921e-01, 1.7651e+00, 1.7931e+00, 3.3601e-03,\n",
      "        0.0000e+00, 4.1315e-01, 1.8304e+00, 3.7698e-01, 1.8678e+00, 5.1452e-01,\n",
      "        9.2744e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 96.8304, 112.0258, 126.0089, 134.1308,   4.8126,   4.8113,   4.8149,\n",
      "        183.7884, 183.7884, 183.7884,   4.8135,   4.8132, 183.7884, 183.7884,\n",
      "        183.7884, 183.7884, 183.7884,  26.0102,  26.0102,   4.8129, 183.7884,\n",
      "        183.7884, 183.7884, 183.7884, 183.7884,  26.0102,  26.0102, 183.7884,\n",
      "         26.0102,  26.0102,   5.2026, 183.7884, 183.7884, 183.7884, 183.7884,\n",
      "        183.7884,  26.0102,  26.0102, 183.7884,  26.0102,  26.0102,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 183.7884,   5.2026,   5.2025, 183.7884,   5.2026,\n",
      "          5.2025, 183.7884,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        183.7884, 183.7884, 183.7884, 183.7884,  26.0102,  26.0102,  26.0102,\n",
      "         26.0102, 183.7884, 183.7884, 183.7884,  26.0102,  26.0102,  26.0102,\n",
      "         26.0102,   5.2026,  26.0102,  26.0102,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(77.9891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 157 was 92.7%\n",
      "tensor([0.0000e+00, 3.3185e-03, 2.6876e-03, 1.9336e-03, 1.3171e-03, 6.4990e-06,\n",
      "        1.0807e-05, 2.4482e-05, 1.6871e-04, 3.8900e-03, 3.7461e-03, 3.6338e-03,\n",
      "        3.7947e-19, 0.0000e+00, 0.0000e+00, 3.5904e-03, 3.4825e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.7480e-01, 4.4785e-01, 1.7592e+00, 1.7869e+00, 3.3336e-03,\n",
      "        0.0000e+00, 4.1178e-01, 1.8243e+00, 3.7570e-01, 1.8616e+00, 5.1276e-01,\n",
      "        9.2768e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 97.0223, 112.2553, 126.2810, 134.4243,   4.8098,   4.8103,   4.8096,\n",
      "        184.2595, 184.2595, 184.2595,   4.8098,   4.8102, 184.2595, 184.2595,\n",
      "        184.2595, 184.2595, 184.2595,  26.0909,  26.0909,   4.8112, 184.2595,\n",
      "        184.2595, 184.2595, 184.2595, 184.2595,  26.0909,  26.0909, 184.2595,\n",
      "         26.0909,  26.0909,   5.2026, 184.2595, 184.2595, 184.2595, 184.2595,\n",
      "        184.2595,  26.0909,  26.0909, 184.2595,  26.0909,  26.0909,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 184.2595,   5.2026,   5.2025, 184.2595,   5.2026,\n",
      "          5.2025, 184.2595,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        184.2595, 184.2595, 184.2595, 184.2595,  26.0909,  26.0909,  26.0909,\n",
      "         26.0909, 184.2595, 184.2595, 184.2595,  26.0909,  26.0909,  26.0909,\n",
      "         26.0909,   5.2026,  26.0909,  26.0909,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 158 was 92.6%\n",
      "tensor([0.0000e+00, 4.1043e-06, 3.5176e-06, 3.1015e-06, 2.8960e-06, 1.4151e-08,\n",
      "        1.0742e-08, 9.1738e-09, 8.8509e-09, 5.9442e-06, 5.7071e-06, 5.5359e-06,\n",
      "        2.9200e-04, 2.1846e-04, 2.1395e-04, 5.4658e-06, 5.2922e-06, 1.5276e-04,\n",
      "        1.4903e-04, 4.9465e-01, 4.6640e-01, 1.7950e+00, 1.8233e+00, 5.0590e-06,\n",
      "        1.4457e-04, 4.2902e-01, 1.8610e+00, 3.9156e-01, 1.8989e+00, 5.0944e-01,\n",
      "        9.2621e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 97.2244, 112.5062, 126.5679, 134.7114,   4.8063,   4.8062,   4.8086,\n",
      "        184.7300, 184.7300, 184.7300,   4.8087,   4.8070, 184.7300, 184.7300,\n",
      "        184.7300, 184.7300, 184.7300,  26.1717,  26.1717,   4.8060, 184.7300,\n",
      "        184.7300, 184.7300, 184.7300, 184.7300,  26.1717,  26.1717, 184.7300,\n",
      "         26.1717,  26.1717,   5.2026, 184.7300, 184.7300, 184.7300, 184.7300,\n",
      "        184.7300,  26.1717,  26.1717, 184.7300,  26.1717,  26.1717,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 184.7300,   5.2026,   5.2025, 184.7300,   5.2026,\n",
      "          5.2025, 184.7300,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        184.7300, 184.7300, 184.7300, 184.7300,  26.1717,  26.1717,  26.1717,\n",
      "         26.1717, 184.7300, 184.7300, 184.7300,  26.1717,  26.1717,  26.1717,\n",
      "         26.1717,   5.2026,  26.1717,  26.1717,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 159 was 92.6%\n",
      "tensor([7.9409e-23, 4.0936e-06, 3.5080e-06, 3.0926e-06, 2.8883e-06, 1.3955e-08,\n",
      "        1.0586e-08, 9.0371e-09, 8.7195e-09, 5.9262e-06, 5.6893e-06, 5.5131e-06,\n",
      "        2.8706e-04, 2.1452e-04, 2.0986e-04, 5.4429e-06, 5.2756e-06, 1.4964e-04,\n",
      "        1.4619e-04, 4.9293e-01, 4.6490e-01, 1.7887e+00, 1.8168e+00, 5.0443e-06,\n",
      "        1.4187e-04, 4.2747e-01, 1.8545e+00, 3.9015e-01, 1.8923e+00, 5.0762e-01,\n",
      "        9.2647e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 97.4263, 112.7567, 126.8542, 134.9978,   4.8034,   4.8045,   4.8047,\n",
      "        185.1999, 185.1999, 185.1999,   4.8032,   4.8039, 185.1999, 185.1999,\n",
      "        185.1999, 185.1999, 185.1999,  26.2524,  26.2524,   4.8049, 185.1999,\n",
      "        185.1999, 185.1999, 185.1999, 185.1999,  26.2524,  26.2524, 185.1999,\n",
      "         26.2524,  26.2524,   5.2026, 185.1999, 185.1999, 185.1999, 185.1999,\n",
      "        185.1999,  26.2524,  26.2524, 185.1999,  26.2524,  26.2524,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 185.1999,   5.2026,   5.2025, 185.1999,   5.2026,\n",
      "          5.2025, 185.1999,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        185.1999, 185.1999, 185.1999, 185.1999,  26.2524,  26.2524,  26.2524,\n",
      "         26.2524, 185.1999, 185.1999, 185.1999,  26.2524,  26.2524,  26.2524,\n",
      "         26.2524,   5.2026,  26.2524,  26.2524,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 160 was 92.6%\n",
      "tensor([3.9705e-23, 4.0820e-06, 3.4973e-06, 3.0834e-06, 2.8801e-06, 1.3755e-08,\n",
      "        1.0425e-08, 8.8986e-09, 8.5873e-09, 5.9023e-06, 5.6652e-06, 5.4955e-06,\n",
      "        2.8166e-04, 2.1041e-04, 2.0609e-04, 5.4263e-06, 5.2552e-06, 1.4674e-04,\n",
      "        1.4319e-04, 4.9106e-01, 4.6321e-01, 1.7823e+00, 1.8102e+00, 5.0232e-06,\n",
      "        1.3901e-04, 4.2605e-01, 1.8477e+00, 3.8872e-01, 1.8855e+00, 5.0573e-01,\n",
      "        9.2673e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 97.6281, 113.0067, 127.1397, 135.2834,   4.8006,   4.8020,   4.8006,\n",
      "        185.6693, 185.6693, 185.6693,   4.8021,   4.8014, 185.6693, 185.6693,\n",
      "        185.6693, 185.6693, 185.6693,  26.3331,  26.3331,   4.7997, 185.6693,\n",
      "        185.6693, 185.6693, 185.6693, 185.6693,  26.3331,  26.3331, 185.6693,\n",
      "         26.3331,  26.3331,   5.2026, 185.6693, 185.6693, 185.6693, 185.6693,\n",
      "        185.6693,  26.3331,  26.3331, 185.6693,  26.3331,  26.3331,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 185.6693,   5.2026,   5.2025, 185.6693,   5.2026,\n",
      "          5.2025, 185.6693,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        185.6693, 185.6693, 185.6693, 185.6693,  26.3331,  26.3331,  26.3331,\n",
      "         26.3331, 185.6693, 185.6693, 185.6693,  26.3331,  26.3331,  26.3331,\n",
      "         26.3331,   5.2026,  26.3331,  26.3331,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 161 was 92.6%\n",
      "tensor([0.0000e+00, 4.0709e-06, 3.4876e-06, 3.0747e-06, 2.8720e-06, 1.3565e-08,\n",
      "        1.0276e-08, 8.7658e-09, 8.4604e-09, 5.8818e-06, 5.6450e-06, 5.4767e-06,\n",
      "        2.7684e-04, 2.0648e-04, 2.0228e-04, 5.4057e-06, 5.2354e-06, 1.4388e-04,\n",
      "        1.4042e-04, 4.8946e-01, 4.6157e-01, 1.7759e+00, 1.8039e+00, 5.0079e-06,\n",
      "        1.3636e-04, 4.2447e-01, 1.8413e+00, 3.8737e-01, 1.8788e+00, 5.0392e-01,\n",
      "        9.2699e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 97.8296, 113.2562, 127.4245, 135.5683,   4.7978,   4.7980,   4.7990,\n",
      "        186.1380, 186.1380, 186.1380,   4.7967,   4.7982, 186.1380, 186.1380,\n",
      "        186.1380, 186.1380, 186.1380,  26.4138,  26.4138,   4.7985, 186.1380,\n",
      "        186.1380, 186.1380, 186.1380, 186.1380,  26.4138,  26.4138, 186.1380,\n",
      "         26.4138,  26.4138,   5.2026, 186.1380, 186.1380, 186.1380, 186.1380,\n",
      "        186.1380,  26.4138,  26.4138, 186.1380,  26.4138,  26.4138,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 186.1380,   5.2026,   5.2025, 186.1380,   5.2026,\n",
      "          5.2025, 186.1380,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        186.1380, 186.1380, 186.1380, 186.1380,  26.4138,  26.4138,  26.4138,\n",
      "         26.4138, 186.1380, 186.1380, 186.1380,  26.4138,  26.4138,  26.4138,\n",
      "         26.4138,   5.2026,  26.4138,  26.4138,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 162 was 92.7%\n",
      "tensor([8.1952e-08, 4.0768e-06, 3.4931e-06, 3.0814e-06, 2.8812e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8593e-06, 5.6251e-06, 5.4566e-06,\n",
      "        2.7175e-04, 2.0266e-04, 1.9853e-04, 5.3868e-06, 5.2179e-06, 1.4100e-04,\n",
      "        1.3765e-04, 4.8749e-01, 4.6007e-01, 1.7698e+00, 1.7973e+00, 4.9881e-06,\n",
      "        1.3365e-04, 4.2309e-01, 1.8346e+00, 3.8595e-01, 1.8722e+00, 5.0208e-01,\n",
      "        9.2725e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 98.0309, 113.5054, 127.7086, 135.8526,   4.7950,   4.7954,   4.7935,\n",
      "        186.6062, 186.6062, 186.6062,   4.7956,   4.7957, 186.6062, 186.6062,\n",
      "        186.6062, 186.6062, 186.6062,  26.4945,  26.4945,   4.7947, 186.6062,\n",
      "        186.6062, 186.6062, 186.6062, 186.6062,  26.4945,  26.4945, 186.6062,\n",
      "         26.4945,  26.4945,   5.2026, 186.6062, 186.6062, 186.6062, 186.6062,\n",
      "        186.6062,  26.4945,  26.4945, 186.6062,  26.4945,  26.4945,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 186.6062,   5.2026,   5.2025, 186.6062,   5.2026,\n",
      "          5.2025, 186.6062,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        186.6062, 186.6062, 186.6062, 186.6062,  26.4945,  26.4945,  26.4945,\n",
      "         26.4945, 186.6062, 186.6062, 186.6062,  26.4945,  26.4945,  26.4945,\n",
      "         26.4945,   5.2026,  26.4945,  26.4945,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 163 was 92.7%\n",
      "tensor([8.0561e-08, 4.0654e-06, 3.4833e-06, 3.0724e-06, 2.8729e-06, 2.8124e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8387e-06, 5.6042e-06, 5.4393e-06,\n",
      "        2.6692e-04, 1.9885e-04, 1.9486e-04, 5.3668e-06, 5.1983e-06, 1.3828e-04,\n",
      "        1.3495e-04, 4.8587e-01, 4.5841e-01, 1.7634e+00, 1.7910e+00, 4.9708e-06,\n",
      "        1.3107e-04, 4.2150e-01, 1.8282e+00, 3.8465e-01, 1.8655e+00, 5.0026e-01,\n",
      "        9.2751e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 98.2321, 113.7540, 127.9920, 136.1362,   4.7921,   4.7921,   4.7925,\n",
      "        187.0738, 187.0738, 187.0738,   4.7915,   4.7903, 187.0738, 187.0738,\n",
      "        187.0738, 187.0738, 187.0738,  26.5752,  26.5752,   4.7929, 187.0738,\n",
      "        187.0738, 187.0738, 187.0738, 187.0738,  26.5752,  26.5752, 187.0738,\n",
      "         26.5752,  26.5752,   5.2026, 187.0738, 187.0738, 187.0738, 187.0738,\n",
      "        187.0738,  26.5752,  26.5752, 187.0738,  26.5752,  26.5752,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 187.0738,   5.2026,   5.2025, 187.0738,   5.2026,\n",
      "          5.2025, 187.0738,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        187.0738, 187.0738, 187.0738, 187.0738,  26.5752,  26.5752,  26.5752,\n",
      "         26.5752, 187.0738, 187.0738, 187.0738,  26.5752,  26.5752,  26.5752,\n",
      "         26.5752,   5.2026,  26.5752,  26.5752,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 164 was 92.7%\n",
      "tensor([7.9196e-08, 4.0542e-06, 3.4728e-06, 3.0634e-06, 2.8649e-06, 3.4742e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8166e-06, 5.5852e-06, 5.4185e-06,\n",
      "        2.6209e-04, 1.9528e-04, 1.9128e-04, 5.3478e-06, 5.1825e-06, 1.3552e-04,\n",
      "        1.3234e-04, 4.8406e-01, 4.5682e-01, 1.7573e+00, 1.7846e+00, 4.9520e-06,\n",
      "        1.2850e-04, 4.2017e-01, 1.8216e+00, 3.8323e-01, 1.8590e+00, 4.9847e-01,\n",
      "        9.2776e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 98.4330, 114.0023, 128.2747, 136.4192,   4.7876,   4.7903,   4.7884,\n",
      "        187.5409, 187.5409, 187.5409,   4.7898,   4.7892, 187.5409, 187.5409,\n",
      "        187.5409, 187.5409, 187.5409,  26.6558,  26.6558,   4.7876, 187.5409,\n",
      "        187.5409, 187.5409, 187.5409, 187.5409,  26.6558,  26.6558, 187.5409,\n",
      "         26.6558,  26.6558,   5.2026, 187.5409, 187.5409, 187.5409, 187.5409,\n",
      "        187.5409,  26.6558,  26.6558, 187.5409,  26.6558,  26.6558,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 187.5409,   5.2026,   5.2025, 187.5409,   5.2026,\n",
      "          5.2025, 187.5409,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        187.5409, 187.5409, 187.5409, 187.5409,  26.6558,  26.6558,  26.6558,\n",
      "         26.6558, 187.5409, 187.5409, 187.5409,  26.6558,  26.6558,  26.6558,\n",
      "         26.6558,   5.2026,  26.6558,  26.6558,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 165 was 92.8%\n",
      "tensor([7.7859e-08, 4.0432e-06, 3.4631e-06, 3.0548e-06, 2.8568e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7987e-06, 5.5639e-06, 5.4003e-06,\n",
      "        2.5762e-04, 1.9153e-04, 1.8777e-04, 5.3286e-06, 5.1614e-06, 1.3288e-04,\n",
      "        1.2971e-04, 4.8247e-01, 4.5519e-01, 1.7511e+00, 1.7784e+00, 4.9377e-06,\n",
      "        1.2607e-04, 4.1866e-01, 1.8152e+00, 3.8191e-01, 1.8525e+00, 4.9671e-01,\n",
      "        9.2802e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 98.6338, 114.2502, 128.5569, 136.7013,   4.7855,   4.7847,   4.7859,\n",
      "        188.0074, 188.0074, 188.0074,   4.7858,   4.7859, 188.0074, 188.0074,\n",
      "        188.0074, 188.0074, 188.0074,  26.7365,  26.7365,   4.7864, 188.0074,\n",
      "        188.0074, 188.0074, 188.0074, 188.0074,  26.7365,  26.7365, 188.0074,\n",
      "         26.7365,  26.7365,   5.2026, 188.0074, 188.0074, 188.0074, 188.0074,\n",
      "        188.0074,  26.7365,  26.7365, 188.0074,  26.7365,  26.7365,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 188.0074,   5.2026,   5.2025, 188.0074,   5.2026,\n",
      "          5.2025, 188.0074,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        188.0074, 188.0074, 188.0074, 188.0074,  26.7365,  26.7365,  26.7365,\n",
      "         26.7365, 188.0074, 188.0074, 188.0074,  26.7365,  26.7365,  26.7365,\n",
      "         26.7365,   5.2026,  26.7365,  26.7365,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 166 was 92.8%\n",
      "tensor([7.6510e-08, 4.0314e-06, 3.4526e-06, 3.0453e-06, 2.8489e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7750e-06, 5.5458e-06, 5.3804e-06,\n",
      "        2.5280e-04, 1.8799e-04, 1.8422e-04, 5.3085e-06, 5.1441e-06, 1.3022e-04,\n",
      "        1.2719e-04, 4.8056e-01, 4.5368e-01, 1.7449e+00, 1.7719e+00, 4.9173e-06,\n",
      "        1.2354e-04, 4.1721e-01, 1.8087e+00, 3.8059e-01, 1.8458e+00, 4.9486e-01,\n",
      "        9.2828e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 98.8344, 114.4976, 128.8383, 136.9829,   4.7826,   4.7837,   4.7833,\n",
      "        188.4733, 188.4733, 188.4733,   4.7832,   4.7819, 188.4733, 188.4733,\n",
      "        188.4733, 188.4733, 188.4733,  26.8171,  26.8171,   4.7811, 188.4733,\n",
      "        188.4733, 188.4733, 188.4733, 188.4733,  26.8171,  26.8171, 188.4733,\n",
      "         26.8171,  26.8171,   5.2026, 188.4733, 188.4733, 188.4733, 188.4733,\n",
      "        188.4733,  26.8171,  26.8171, 188.4733,  26.8171,  26.8171,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 188.4733,   5.2026,   5.2025, 188.4733,   5.2026,\n",
      "          5.2025, 188.4733,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        188.4733, 188.4733, 188.4733, 188.4733,  26.8171,  26.8171,  26.8171,\n",
      "         26.8171, 188.4733, 188.4733, 188.4733,  26.8171,  26.8171,  26.8171,\n",
      "         26.8171,   5.2026,  26.8171,  26.8171,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 167 was 92.8%\n",
      "tensor([7.5242e-08, 4.0208e-06, 3.4428e-06, 3.0366e-06, 2.8408e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7560e-06, 5.5249e-06, 5.3612e-06,\n",
      "        2.4849e-04, 1.8456e-04, 1.8087e-04, 5.2893e-06, 5.1266e-06, 1.2767e-04,\n",
      "        1.2470e-04, 4.7899e-01, 4.5212e-01, 1.7388e+00, 1.7658e+00, 4.9024e-06,\n",
      "        1.2121e-04, 4.1579e-01, 1.8024e+00, 3.7915e-01, 1.8395e+00, 4.9311e-01,\n",
      "        9.2853e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 99.0348, 114.7446, 129.1190, 137.2638,   4.7797,   4.7780,   4.7793,\n",
      "        188.9388, 188.9388, 188.9388,   4.7800,   4.7802, 188.9388, 188.9388,\n",
      "        188.9388, 188.9388, 188.9388,  26.8977,  26.8977,   4.7799, 188.9388,\n",
      "        188.9388, 188.9388, 188.9388, 188.9388,  26.8977,  26.8977, 188.9388,\n",
      "         26.8977,  26.8977,   5.2026, 188.9388, 188.9388, 188.9388, 188.9388,\n",
      "        188.9388,  26.8977,  26.8977, 188.9388,  26.8977,  26.8977,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 188.9388,   5.2026,   5.2025, 188.9388,   5.2026,\n",
      "          5.2025, 188.9388,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        188.9388, 188.9388, 188.9388, 188.9388,  26.8977,  26.8977,  26.8977,\n",
      "         26.8977, 188.9388, 188.9388, 188.9388,  26.8977,  26.8977,  26.8977,\n",
      "         26.8977,   5.2026,  26.8977,  26.8977,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 168 was 92.8%\n",
      "tensor([7.3948e-08, 4.0092e-06, 3.4329e-06, 3.0276e-06, 2.8330e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7342e-06, 5.5067e-06, 5.3432e-06,\n",
      "        2.4390e-04, 1.8108e-04, 1.7751e-04, 5.2707e-06, 5.1077e-06, 1.2517e-04,\n",
      "        1.2228e-04, 4.7717e-01, 4.5060e-01, 1.7328e+00, 1.7595e+00, 4.8829e-06,\n",
      "        1.1882e-04, 4.1428e-01, 1.7960e+00, 3.7794e-01, 1.8329e+00, 4.9133e-01,\n",
      "        9.2878e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 99.2351, 114.9912, 129.3991, 137.5441,   4.7759,   4.7770,   4.7776,\n",
      "        189.4037, 189.4037, 189.4037,   4.7759,   4.7747, 189.4037, 189.4037,\n",
      "        189.4037, 189.4037, 189.4037,  26.9783,  26.9783,   4.7775, 189.4037,\n",
      "        189.4037, 189.4037, 189.4037, 189.4037,  26.9783,  26.9783, 189.4037,\n",
      "         26.9783,  26.9783,   5.2026, 189.4037, 189.4037, 189.4037, 189.4037,\n",
      "        189.4037,  26.9783,  26.9783, 189.4037,  26.9783,  26.9783,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 189.4037,   5.2026,   5.2025, 189.4037,   5.2026,\n",
      "          5.2025, 189.4037,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        189.4037, 189.4037, 189.4037, 189.4037,  26.9783,  26.9783,  26.9783,\n",
      "         26.9783, 189.4037, 189.4037, 189.4037,  26.9783,  26.9783,  26.9783,\n",
      "         26.9783,   5.2026,  26.9783,  26.9783,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 169 was 92.9%\n",
      "tensor([7.2708e-08, 3.9985e-06, 3.4228e-06, 3.0190e-06, 2.8253e-06, 6.6174e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7147e-06, 5.4855e-06, 5.3234e-06,\n",
      "        2.3957e-04, 1.7784e-04, 1.7428e-04, 5.2528e-06, 5.0924e-06, 1.2268e-04,\n",
      "        1.1986e-04, 4.7545e-01, 4.4901e-01, 1.7268e+00, 1.7533e+00, 4.8659e-06,\n",
      "        1.1653e-04, 4.1303e-01, 1.7896e+00, 3.7655e-01, 1.8266e+00, 4.8961e-01,\n",
      "        9.2903e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 99.4351, 115.2374, 129.6786, 137.8237,   4.7722,   4.7743,   4.7720,\n",
      "        189.8681, 189.8681, 189.8681,   4.7741,   4.7736, 189.8681, 189.8681,\n",
      "        189.8681, 189.8681, 189.8681,  27.0588,  27.0588,   4.7736, 189.8681,\n",
      "        189.8681, 189.8681, 189.8681, 189.8681,  27.0588,  27.0588, 189.8681,\n",
      "         27.0588,  27.0588,   5.2026, 189.8681, 189.8681, 189.8681, 189.8681,\n",
      "        189.8681,  27.0588,  27.0588, 189.8681,  27.0588,  27.0588,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 189.8681,   5.2026,   5.2025, 189.8681,   5.2026,\n",
      "          5.2025, 189.8681,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        189.8681, 189.8681, 189.8681, 189.8681,  27.0588,  27.0588,  27.0588,\n",
      "         27.0588, 189.8681, 189.8681, 189.8681,  27.0588,  27.0588,  27.0588,\n",
      "         27.0588,   5.2026,  27.0588,  27.0588,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 170 was 92.9%\n",
      "tensor([7.1472e-08, 3.9874e-06, 3.4132e-06, 3.0105e-06, 2.8173e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6950e-06, 5.4658e-06, 5.3069e-06,\n",
      "        2.3535e-04, 1.7438e-04, 1.7105e-04, 5.2336e-06, 5.0709e-06, 1.2032e-04,\n",
      "        1.1751e-04, 4.7387e-01, 4.4738e-01, 1.7207e+00, 1.7472e+00, 4.8500e-06,\n",
      "        1.1428e-04, 4.1152e-01, 1.7834e+00, 3.7530e-01, 1.8201e+00, 4.8786e-01,\n",
      "        9.2928e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 99.6351, 115.4832, 129.9576, 138.1025,   4.7692,   4.7686,   4.7710,\n",
      "        190.3320, 190.3320, 190.3320,   4.7701,   4.7703, 190.3320, 190.3320,\n",
      "        190.3320, 190.3320, 190.3320,  27.1394,  27.1394,   4.7717, 190.3320,\n",
      "        190.3320, 190.3320, 190.3320, 190.3320,  27.1394,  27.1394, 190.3320,\n",
      "         27.1394,  27.1394,   5.2026, 190.3320, 190.3320, 190.3320, 190.3320,\n",
      "        190.3320,  27.1394,  27.1394, 190.3320,  27.1394,  27.1394,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 190.3320,   5.2026,   5.2025, 190.3320,   5.2026,\n",
      "          5.2025, 190.3320,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        190.3320, 190.3320, 190.3320, 190.3320,  27.1394,  27.1394,  27.1394,\n",
      "         27.1394, 190.3320, 190.3320, 190.3320,  27.1394,  27.1394,  27.1394,\n",
      "         27.1394,   5.2026,  27.1394,  27.1394,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 171 was 92.9%\n",
      "tensor([7.0265e-08, 3.9762e-06, 3.4032e-06, 3.0015e-06, 2.8100e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6735e-06, 5.4486e-06, 5.2874e-06,\n",
      "        2.3110e-04, 1.7127e-04, 1.6787e-04, 5.2142e-06, 5.0558e-06, 1.1794e-04,\n",
      "        1.1526e-04, 4.7197e-01, 4.4596e-01, 1.7149e+00, 1.7410e+00, 4.8320e-06,\n",
      "        1.1203e-04, 4.1018e-01, 1.7771e+00, 3.7404e-01, 1.8137e+00, 4.8615e-01,\n",
      "        9.2952e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([ 99.8349, 115.7287, 130.2359, 138.3808,   4.7662,   4.7676,   4.7668,\n",
      "        190.7953, 190.7953, 190.7953,   4.7674,   4.7678, 190.7953, 190.7953,\n",
      "        190.7953, 190.7953, 190.7953,  27.2199,  27.2199,   4.7664, 190.7953,\n",
      "        190.7953, 190.7953, 190.7953, 190.7953,  27.2199,  27.2199, 190.7953,\n",
      "         27.2199,  27.2199,   5.2026, 190.7953, 190.7953, 190.7953, 190.7953,\n",
      "        190.7953,  27.2199,  27.2199, 190.7953,  27.2199,  27.2199,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 190.7953,   5.2026,   5.2025, 190.7953,   5.2026,\n",
      "          5.2025, 190.7953,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        190.7953, 190.7953, 190.7953, 190.7953,  27.2199,  27.2199,  27.2199,\n",
      "         27.2199, 190.7953, 190.7953, 190.7953,  27.2199,  27.2199,  27.2199,\n",
      "         27.2199,   5.2026,  27.2199,  27.2199,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 172 was 92.9%\n",
      "tensor([6.9076e-08, 3.9655e-06, 3.3937e-06, 2.9929e-06, 2.8019e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6545e-06, 5.4265e-06, 5.2691e-06,\n",
      "        2.2705e-04, 1.6799e-04, 1.6480e-04, 5.1963e-06, 5.0359e-06, 1.1562e-04,\n",
      "        1.1294e-04, 4.7045e-01, 4.4442e-01, 1.7087e+00, 1.7349e+00, 4.8165e-06,\n",
      "        1.0989e-04, 4.0866e-01, 1.7709e+00, 3.7268e-01, 1.8074e+00, 4.8437e-01,\n",
      "        9.2977e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([100.0345, 115.9737, 130.5136, 138.6584,   4.7640,   4.7634,   4.7643,\n",
      "        191.2582, 191.2582, 191.2582,   4.7642,   4.7622, 191.2582, 191.2582,\n",
      "        191.2582, 191.2582, 191.2582,  27.3004,  27.3004,   4.7652, 191.2582,\n",
      "        191.2582, 191.2582, 191.2582, 191.2582,  27.3004,  27.3004, 191.2582,\n",
      "         27.3004,  27.3004,   5.2026, 191.2582, 191.2582, 191.2582, 191.2582,\n",
      "        191.2582,  27.3004,  27.3004, 191.2582,  27.3004,  27.3004,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 191.2582,   5.2026,   5.2025, 191.2582,   5.2026,\n",
      "          5.2025, 191.2582,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        191.2582, 191.2582, 191.2582, 191.2582,  27.3004,  27.3004,  27.3004,\n",
      "         27.3004, 191.2582, 191.2582, 191.2582,  27.3004,  27.3004,  27.3004,\n",
      "         27.3004,   5.2026,  27.3004,  27.3004,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 173 was 93.0%\n",
      "tensor([6.7930e-08, 3.9546e-06, 3.3839e-06, 2.9844e-06, 2.7943e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6324e-06, 5.4096e-06, 5.2505e-06,\n",
      "        2.2296e-04, 1.6504e-04, 1.6180e-04, 5.1779e-06, 5.0216e-06, 1.1337e-04,\n",
      "        1.1082e-04, 4.6874e-01, 4.4286e-01, 1.7030e+00, 1.7289e+00, 4.7982e-06,\n",
      "        1.0775e-04, 4.0736e-01, 1.7647e+00, 3.7140e-01, 1.8012e+00, 4.8268e-01,\n",
      "        9.3001e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([100.2339, 116.2184, 130.7905, 138.9355,   4.7602,   4.7624,   4.7601,\n",
      "        191.7206, 191.7206, 191.7206,   4.7607,   4.7611, 191.7206, 191.7206,\n",
      "        191.7206, 191.7206, 191.7206,  27.3809,  27.3809,   4.7598, 191.7206,\n",
      "        191.7206, 191.7206, 191.7206, 191.7206,  27.3809,  27.3809, 191.7206,\n",
      "         27.3809,  27.3809,   5.2026, 191.7206, 191.7206, 191.7206, 191.7206,\n",
      "        191.7206,  27.3809,  27.3809, 191.7206,  27.3809,  27.3809,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 191.7206,   5.2026,   5.2025, 191.7206,   5.2026,\n",
      "          5.2025, 191.7206,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        191.7206, 191.7206, 191.7206, 191.7206,  27.3809,  27.3809,  27.3809,\n",
      "         27.3809, 191.7206, 191.7206, 191.7206,  27.3809,  27.3809,  27.3809,\n",
      "         27.3809,   5.2026,  27.3809,  27.3809,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 174 was 93.0%\n",
      "tensor([6.6790e-08, 3.9440e-06, 3.3743e-06, 2.9759e-06, 2.7864e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6147e-06, 5.3874e-06, 5.2334e-06,\n",
      "        2.1914e-04, 1.6183e-04, 1.5887e-04, 5.1606e-06, 5.0004e-06, 1.1118e-04,\n",
      "        1.0858e-04, 4.6720e-01, 4.4134e-01, 1.6969e+00, 1.7229e+00, 4.7838e-06,\n",
      "        1.0572e-04, 4.0593e-01, 1.7586e+00, 3.7004e-01, 1.7950e+00, 4.8098e-01,\n",
      "        9.3026e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([100.4331, 116.4627, 131.0670, 139.2120,   4.7572,   4.7566,   4.7584,\n",
      "        192.1825, 192.1825, 192.1825,   4.7575,   4.7571, 192.1825, 192.1825,\n",
      "        192.1825, 192.1825, 192.1825,  27.4614,  27.4614,   4.7586, 192.1825,\n",
      "        192.1825, 192.1825, 192.1825, 192.1825,  27.4614,  27.4614, 192.1825,\n",
      "         27.4614,  27.4614,   5.2026, 192.1825, 192.1825, 192.1825, 192.1825,\n",
      "        192.1825,  27.4614,  27.4614, 192.1825,  27.4614,  27.4614,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 192.1825,   5.2026,   5.2025, 192.1825,   5.2026,\n",
      "          5.2025, 192.1825,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        192.1825, 192.1825, 192.1825, 192.1825,  27.4614,  27.4614,  27.4614,\n",
      "         27.4614, 192.1825, 192.1825, 192.1825,  27.4614,  27.4614,  27.4614,\n",
      "         27.4614,   5.2026,  27.4614,  27.4614,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 175 was 93.0%\n",
      "tensor([6.5653e-08, 3.9329e-06, 3.3645e-06, 2.9672e-06, 2.7792e-06, 3.1433e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5930e-06, 5.3711e-06, 5.2135e-06,\n",
      "        2.1509e-04, 1.5894e-04, 1.5586e-04, 5.1407e-06, 4.9858e-06, 1.0894e-04,\n",
      "        1.0652e-04, 4.6536e-01, 4.3989e-01, 1.6912e+00, 1.7168e+00, 4.7652e-06,\n",
      "        1.0362e-04, 4.0459e-01, 1.7524e+00, 3.6882e-01, 1.7886e+00, 4.7926e-01,\n",
      "        9.3050e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([100.6323, 116.7066, 131.3428, 139.4878,   4.7534,   4.7556,   4.7542,\n",
      "        192.6439, 192.6439, 192.6439,   4.7540,   4.7560, 192.6439, 192.6439,\n",
      "        192.6439, 192.6439, 192.6439,  27.5419,  27.5419,   4.7532, 192.6439,\n",
      "        192.6439, 192.6439, 192.6439, 192.6439,  27.5419,  27.5419, 192.6439,\n",
      "         27.5419,  27.5419,   5.2026, 192.6439, 192.6439, 192.6439, 192.6439,\n",
      "        192.6439,  27.5419,  27.5419, 192.6439,  27.5419,  27.5419,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 192.6439,   5.2026,   5.2025, 192.6439,   5.2026,\n",
      "          5.2025, 192.6439,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        192.6439, 192.6439, 192.6439, 192.6439,  27.5419,  27.5419,  27.5419,\n",
      "         27.5419, 192.6439, 192.6439, 192.6439,  27.5419,  27.5419,  27.5419,\n",
      "         27.5419,   5.2026,  27.5419,  27.5419,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 176 was 93.0%\n",
      "tensor([6.4562e-08, 3.9226e-06, 3.3555e-06, 2.9590e-06, 2.7717e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5763e-06, 5.3492e-06, 5.1977e-06,\n",
      "        2.1143e-04, 1.5588e-04, 1.5308e-04, 5.1247e-06, 4.9655e-06, 1.0687e-04,\n",
      "        1.0437e-04, 4.6382e-01, 4.3845e-01, 1.6854e+00, 1.7108e+00, 4.7515e-06,\n",
      "        1.0169e-04, 4.0314e-01, 1.7464e+00, 3.6755e-01, 1.7825e+00, 4.7759e-01,\n",
      "        9.3074e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([100.8313, 116.9501, 131.6182, 139.7630,   4.7512,   4.7513,   4.7509,\n",
      "        193.1048, 193.1048, 193.1048,   4.7515,   4.7504, 193.1048, 193.1048,\n",
      "        193.1048, 193.1048, 193.1048,  27.6224,  27.6224,   4.7520, 193.1048,\n",
      "        193.1048, 193.1048, 193.1048, 193.1048,  27.6224,  27.6224, 193.1048,\n",
      "         27.6224,  27.6224,   5.2026, 193.1048, 193.1048, 193.1048, 193.1048,\n",
      "        193.1048,  27.6224,  27.6224, 193.1048,  27.6224,  27.6224,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 193.1048,   5.2026,   5.2025, 193.1048,   5.2026,\n",
      "          5.2025, 193.1048,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        193.1048, 193.1048, 193.1048, 193.1048,  27.6224,  27.6224,  27.6224,\n",
      "         27.6224, 193.1048, 193.1048, 193.1048,  27.6224,  27.6224,  27.6224,\n",
      "         27.6224,   5.2026,  27.6224,  27.6224,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 177 was 93.0%\n",
      "tensor([0.0000e+00, 3.8974e-06, 3.3326e-06, 2.9373e-06, 2.7500e-06, 1.0845e-08,\n",
      "        8.1267e-09, 6.8972e-09, 6.6686e-09, 5.5530e-06, 5.3325e-06, 5.1781e-06,\n",
      "        2.0815e-04, 1.5353e-04, 1.5061e-04, 5.1048e-06, 4.9507e-06, 1.0501e-04,\n",
      "        1.0266e-04, 4.6216e-01, 4.3683e-01, 1.6798e+00, 1.7052e+00, 4.7321e-06,\n",
      "        9.9873e-05, 4.0180e-01, 1.7404e+00, 3.6628e-01, 1.7763e+00, 4.7584e-01,\n",
      "        9.3097e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([101.0295, 117.1932, 131.8907, 140.0399,   4.7483,   4.7483,   4.7489,\n",
      "        193.5653, 193.5653, 193.5653,   4.7470,   4.7491, 193.5653, 193.5653,\n",
      "        193.5653, 193.5653, 193.5653,  27.7028,  27.7028,   4.7465, 193.5653,\n",
      "        193.5653, 193.5653, 193.5653, 193.5653,  27.7028,  27.7028, 193.5653,\n",
      "         27.7028,  27.7028,   5.2026, 193.5653, 193.5653, 193.5653, 193.5653,\n",
      "        193.5653,  27.7028,  27.7028, 193.5653,  27.7028,  27.7028,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 193.5653,   5.2026,   5.2025, 193.5653,   5.2026,\n",
      "          5.2025, 193.5653,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        193.5653, 193.5653, 193.5653, 193.5653,  27.7028,  27.7028,  27.7028,\n",
      "         27.7028, 193.5653, 193.5653, 193.5653,  27.7028,  27.7028,  27.7028,\n",
      "         27.7028,   5.2026,  27.7028,  27.7028,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 178 was 93.1%\n",
      "tensor([1.3235e-22, 3.8874e-06, 3.3236e-06, 2.9291e-06, 2.7429e-06, 1.0694e-08,\n",
      "        8.0088e-09, 6.7942e-09, 6.5699e-09, 5.5349e-06, 5.3135e-06, 5.1602e-06,\n",
      "        2.0457e-04, 1.5067e-04, 1.4786e-04, 5.0880e-06, 4.9320e-06, 1.0297e-04,\n",
      "        1.0064e-04, 4.6053e-01, 4.3552e-01, 1.6742e+00, 1.6992e+00, 4.7182e-06,\n",
      "        9.7983e-05, 4.0041e-01, 1.7345e+00, 3.6496e-01, 1.7704e+00, 4.7420e-01,\n",
      "        9.3121e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([101.2276, 117.4359, 132.1626, 140.3162,   4.7462,   4.7446,   4.7445,\n",
      "        194.0253, 194.0253, 194.0253,   4.7450,   4.7432, 194.0253, 194.0253,\n",
      "        194.0253, 194.0253, 194.0253,  27.7832,  27.7832,   4.7453, 194.0253,\n",
      "        194.0253, 194.0253, 194.0253, 194.0253,  27.7832,  27.7832, 194.0253,\n",
      "         27.7832,  27.7832,   5.2026, 194.0253, 194.0253, 194.0253, 194.0253,\n",
      "        194.0253,  27.7832,  27.7832, 194.0253,  27.7832,  27.7832,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 194.0253,   5.2026,   5.2025, 194.0253,   5.2026,\n",
      "          5.2025, 194.0253,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        194.0253, 194.0253, 194.0253, 194.0253,  27.7832,  27.7832,  27.7832,\n",
      "         27.7832, 194.0253, 194.0253, 194.0253,  27.7832,  27.7832,  27.7832,\n",
      "         27.7832,   5.2026,  27.7832,  27.7832,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 179 was 93.1%\n",
      "tensor([0.0000e+00, 3.8771e-06, 3.3146e-06, 2.9212e-06, 2.7355e-06, 1.0546e-08,\n",
      "        7.8918e-09, 6.6952e-09, 6.4743e-09, 5.5135e-06, 5.2964e-06, 5.1433e-06,\n",
      "        2.0083e-04, 1.4801e-04, 1.4520e-04, 5.0700e-06, 4.9182e-06, 1.0099e-04,\n",
      "        9.8753e-05, 4.5903e-01, 4.3395e-01, 1.6683e+00, 1.6934e+00, 4.6990e-06,\n",
      "        9.6090e-05, 3.9903e-01, 1.7285e+00, 3.6371e-01, 1.7643e+00, 4.7253e-01,\n",
      "        9.3145e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([101.4256, 117.6784, 132.4340, 140.5919,   4.7400,   4.7426,   4.7425,\n",
      "        194.4849, 194.4849, 194.4849,   4.7414,   4.7419, 194.4849, 194.4849,\n",
      "        194.4849, 194.4849, 194.4849,  27.8637,  27.8637,   4.7413, 194.4849,\n",
      "        194.4849, 194.4849, 194.4849, 194.4849,  27.8637,  27.8637, 194.4849,\n",
      "         27.8637,  27.8637,   5.2026, 194.4849, 194.4849, 194.4849, 194.4849,\n",
      "        194.4849,  27.8637,  27.8637, 194.4849,  27.8637,  27.8637,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 194.4849,   5.2026,   5.2025, 194.4849,   5.2026,\n",
      "          5.2025, 194.4849,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        194.4849, 194.4849, 194.4849, 194.4849,  27.8637,  27.8637,  27.8637,\n",
      "         27.8637, 194.4849, 194.4849, 194.4849,  27.8637,  27.8637,  27.8637,\n",
      "         27.8637,   5.2026,  27.8637,  27.8637,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 180 was 93.1%\n",
      "tensor([0.0000e+00, 3.8668e-06, 3.3052e-06, 2.9132e-06, 2.7284e-06, 1.0397e-08,\n",
      "        7.7755e-09, 6.5939e-09, 6.3771e-09, 5.4981e-06, 5.2759e-06, 5.1244e-06,\n",
      "        1.9734e-04, 1.4519e-04, 1.4249e-04, 5.0517e-06, 4.8986e-06, 9.8990e-05,\n",
      "        9.6780e-05, 4.5733e-01, 4.3246e-01, 1.6627e+00, 1.6876e+00, 4.6847e-06,\n",
      "        9.4273e-05, 3.9777e-01, 1.7224e+00, 3.6246e-01, 1.7582e+00, 4.7087e-01,\n",
      "        9.3168e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([101.6234, 117.9204, 132.7048, 140.8671,   4.7387,   4.7364,   4.7382,\n",
      "        194.9440, 194.9440, 194.9440,   4.7386,   4.7384, 194.9440, 194.9440,\n",
      "        194.9440, 194.9440, 194.9440,  27.9441,  27.9441,   4.7401, 194.9440,\n",
      "        194.9440, 194.9440, 194.9440, 194.9440,  27.9441,  27.9441, 194.9440,\n",
      "         27.9441,  27.9441,   5.2026, 194.9440, 194.9440, 194.9440, 194.9440,\n",
      "        194.9440,  27.9441,  27.9441, 194.9440,  27.9441,  27.9441,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 194.9440,   5.2026,   5.2025, 194.9440,   5.2026,\n",
      "          5.2025, 194.9440,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        194.9440, 194.9440, 194.9440, 194.9440,  27.9441,  27.9441,  27.9441,\n",
      "         27.9441, 194.9440, 194.9440, 194.9440,  27.9441,  27.9441,  27.9441,\n",
      "         27.9441,   5.2026,  27.9441,  27.9441,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 181 was 93.1%\n",
      "tensor([0.0000e+00, 3.8561e-06, 3.2961e-06, 2.9054e-06, 2.7213e-06, 1.0252e-08,\n",
      "        7.6629e-09, 6.4968e-09, 6.2838e-09, 5.4751e-06, 5.2610e-06, 5.1080e-06,\n",
      "        1.9376e-04, 1.4260e-04, 1.3993e-04, 5.0344e-06, 4.8831e-06, 9.7105e-05,\n",
      "        9.4973e-05, 4.5568e-01, 4.3095e-01, 1.6570e+00, 1.6818e+00, 4.6667e-06,\n",
      "        9.2426e-05, 3.9640e-01, 1.7165e+00, 3.6135e-01, 1.7520e+00, 4.6924e-01,\n",
      "        9.3192e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([101.8211, 118.1621, 132.9751, 141.1416,   4.7340,   4.7351,   4.7361,\n",
      "        195.4027, 195.4027, 195.4027,   4.7350,   4.7363, 195.4027, 195.4027,\n",
      "        195.4027, 195.4027, 195.4027,  28.0245,  28.0245,   4.7346, 195.4027,\n",
      "        195.4027, 195.4027, 195.4027, 195.4027,  28.0245,  28.0245, 195.4027,\n",
      "         28.0245,  28.0245,   5.2026, 195.4027, 195.4027, 195.4027, 195.4027,\n",
      "        195.4027,  28.0245,  28.0245, 195.4027,  28.0245,  28.0245,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 195.4027,   5.2026,   5.2025, 195.4027,   5.2026,\n",
      "          5.2025, 195.4027,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        195.4027, 195.4027, 195.4027, 195.4027,  28.0245,  28.0245,  28.0245,\n",
      "         28.0245, 195.4027, 195.4027, 195.4027,  28.0245,  28.0245,  28.0245,\n",
      "         28.0245,   5.2026,  28.0245,  28.0245,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 182 was 93.2%\n",
      "tensor([0.0000e+00, 3.8460e-06, 3.2871e-06, 2.8971e-06, 2.7142e-06, 1.0108e-08,\n",
      "        7.5501e-09, 6.3987e-09, 6.1892e-09, 5.4587e-06, 5.2394e-06, 5.0892e-06,\n",
      "        1.9042e-04, 1.3990e-04, 1.3732e-04, 5.0161e-06, 4.8648e-06, 9.5176e-05,\n",
      "        9.3060e-05, 4.5406e-01, 4.2960e-01, 1.6514e+00, 1.6759e+00, 4.6533e-06,\n",
      "        9.0677e-05, 3.9503e-01, 1.7106e+00, 3.6004e-01, 1.7460e+00, 4.6758e-01,\n",
      "        9.3215e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([102.0187, 118.4034, 133.2449, 141.4156,   4.7327,   4.7314,   4.7316,\n",
      "        195.8609, 195.8609, 195.8609,   4.7322,   4.7304, 195.8609, 195.8609,\n",
      "        195.8609, 195.8609, 195.8609,  28.1048,  28.1048,   4.7333, 195.8609,\n",
      "        195.8609, 195.8609, 195.8609, 195.8609,  28.1048,  28.1048, 195.8609,\n",
      "         28.1048,  28.1048,   5.2026, 195.8609, 195.8609, 195.8609, 195.8609,\n",
      "        195.8609,  28.1048,  28.1048, 195.8609,  28.1048,  28.1048,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 195.8609,   5.2026,   5.2025, 195.8609,   5.2026,\n",
      "          5.2025, 195.8609,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        195.8609, 195.8609, 195.8609, 195.8609,  28.1048,  28.1048,  28.1048,\n",
      "         28.1048, 195.8609, 195.8609, 195.8609,  28.1048,  28.1048,  28.1048,\n",
      "         28.1048,   5.2026,  28.1048,  28.1048,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 183 was 93.2%\n",
      "tensor([0.0000e+00, 3.8359e-06, 3.2781e-06, 2.8896e-06, 2.7070e-06, 9.9681e-09,\n",
      "        7.4405e-09, 6.3055e-09, 6.0998e-09, 5.4366e-06, 5.2233e-06, 5.0730e-06,\n",
      "        1.8695e-04, 1.3743e-04, 1.3487e-04, 4.9995e-06, 4.8508e-06, 9.3363e-05,\n",
      "        9.1329e-05, 4.5258e-01, 4.2802e-01, 1.6457e+00, 1.6702e+00, 4.6347e-06,\n",
      "        8.8922e-05, 3.9373e-01, 1.7047e+00, 3.5883e-01, 1.7400e+00, 4.6596e-01,\n",
      "        9.3239e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([102.2161, 118.6445, 133.5141, 141.6890,   4.7279,   4.7301,   4.7288,\n",
      "        196.3187, 196.3187, 196.3187,   4.7285,   4.7291, 196.3187, 196.3187,\n",
      "        196.3187, 196.3187, 196.3187,  28.1852,  28.1852,   4.7278, 196.3187,\n",
      "        196.3187, 196.3187, 196.3187, 196.3187,  28.1852,  28.1852, 196.3187,\n",
      "         28.1852,  28.1852,   5.2026, 196.3187, 196.3187, 196.3187, 196.3187,\n",
      "        196.3187,  28.1852,  28.1852, 196.3187,  28.1852,  28.1852,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 196.3187,   5.2026,   5.2025, 196.3187,   5.2026,\n",
      "          5.2025, 196.3187,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        196.3187, 196.3187, 196.3187, 196.3187,  28.1852,  28.1852,  28.1852,\n",
      "         28.1852, 196.3187, 196.3187, 196.3187,  28.1852,  28.1852,  28.1852,\n",
      "         28.1852,   5.2026,  28.1852,  28.1852,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 184 was 93.2%\n",
      "tensor([5.9557e-23, 3.8258e-06, 3.2690e-06, 2.8817e-06, 2.6997e-06, 9.8277e-09,\n",
      "        7.3315e-09, 6.2100e-09, 6.0087e-09, 5.4207e-06, 5.2021e-06, 5.0551e-06,\n",
      "        1.8374e-04, 1.3478e-04, 1.3239e-04, 4.9821e-06, 4.8307e-06, 9.1526e-05,\n",
      "        8.9488e-05, 4.5104e-01, 4.2658e-01, 1.6400e+00, 1.6645e+00, 4.6216e-06,\n",
      "        8.7254e-05, 3.9241e-01, 1.6988e+00, 3.5753e-01, 1.7341e+00, 4.6432e-01,\n",
      "        9.3262e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([102.4135, 118.8851, 133.7828, 141.9618,   4.7266,   4.7239,   4.7252,\n",
      "        196.7760, 196.7760, 196.7760,   4.7257,   4.7248, 196.7760, 196.7760,\n",
      "        196.7760, 196.7760, 196.7760,  28.2656,  28.2656,   4.7265, 196.7760,\n",
      "        196.7760, 196.7760, 196.7760, 196.7760,  28.2656,  28.2656, 196.7760,\n",
      "         28.2656,  28.2656,   5.2026, 196.7760, 196.7760, 196.7760, 196.7760,\n",
      "        196.7760,  28.2656,  28.2656, 196.7760,  28.2656,  28.2656,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 196.7760,   5.2026,   5.2025, 196.7760,   5.2026,\n",
      "          5.2025, 196.7760,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        196.7760, 196.7760, 196.7760, 196.7760,  28.2656,  28.2656,  28.2656,\n",
      "         28.2656, 196.7760, 196.7760, 196.7760,  28.2656,  28.2656,  28.2656,\n",
      "         28.2656,   5.2026,  28.2656,  28.2656,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 185 was 93.2%\n",
      "tensor([0.0000e+00, 3.8157e-06, 3.2604e-06, 2.8739e-06, 2.6928e-06, 9.6909e-09,\n",
      "        7.2247e-09, 6.1192e-09, 5.9210e-09, 5.3987e-06, 5.1881e-06, 5.0384e-06,\n",
      "        1.8037e-04, 1.3242e-04, 1.2999e-04, 4.9649e-06, 4.8172e-06, 8.9768e-05,\n",
      "        8.7834e-05, 4.4945e-01, 4.2518e-01, 1.6344e+00, 1.6587e+00, 4.6030e-06,\n",
      "        8.5552e-05, 3.9104e-01, 1.6931e+00, 3.5638e-01, 1.7281e+00, 4.6271e-01,\n",
      "        9.3285e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([102.6104, 119.1255, 134.0512, 142.2342,   4.7203,   4.7226,   4.7223,\n",
      "        197.2330, 197.2330, 197.2330,   4.7220,   4.7234, 197.2330, 197.2330,\n",
      "        197.2330, 197.2330, 197.2330,  28.3459,  28.3459,   4.7225, 197.2330,\n",
      "        197.2330, 197.2330, 197.2330, 197.2330,  28.3459,  28.3459, 197.2330,\n",
      "         28.3459,  28.3459,   5.2026, 197.2330, 197.2330, 197.2330, 197.2330,\n",
      "        197.2330,  28.3459,  28.3459, 197.2330,  28.3459,  28.3459,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 197.2330,   5.2026,   5.2025, 197.2330,   5.2026,\n",
      "          5.2025, 197.2330,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        197.2330, 197.2330, 197.2330, 197.2330,  28.3459,  28.3459,  28.3459,\n",
      "         28.3459, 197.2330, 197.2330, 197.2330,  28.3459,  28.3459,  28.3459,\n",
      "         28.3459,   5.2026,  28.3459,  28.3459,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 186 was 93.3%\n",
      "tensor([3.9705e-23, 3.8054e-06, 3.2514e-06, 2.8659e-06, 2.6858e-06, 9.5542e-09,\n",
      "        7.1185e-09, 6.0271e-09, 5.8323e-09, 5.3837e-06, 5.1663e-06, 5.0205e-06,\n",
      "        1.7725e-04, 1.2989e-04, 1.2758e-04, 4.9473e-06, 4.7980e-06, 8.8003e-05,\n",
      "        8.6058e-05, 4.4779e-01, 4.2375e-01, 1.6289e+00, 1.6530e+00, 4.5891e-06,\n",
      "        8.3940e-05, 3.8974e-01, 1.6872e+00, 3.5520e-01, 1.7221e+00, 4.6109e-01,\n",
      "        9.3308e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([102.8073, 119.3656, 134.3191, 142.5061,   4.7190,   4.7179,   4.7201,\n",
      "        197.6895, 197.6895, 197.6895,   4.7198,   4.7174, 197.6895, 197.6895,\n",
      "        197.6895, 197.6895, 197.6895,  28.4262,  28.4262,   4.7191, 197.6895,\n",
      "        197.6895, 197.6895, 197.6895, 197.6895,  28.4262,  28.4262, 197.6895,\n",
      "         28.4262,  28.4262,   5.2026, 197.6895, 197.6895, 197.6895, 197.6895,\n",
      "        197.6895,  28.4262,  28.4262, 197.6895,  28.4262,  28.4262,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 197.6895,   5.2026,   5.2025, 197.6895,   5.2026,\n",
      "          5.2025, 197.6895,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        197.6895, 197.6895, 197.6895, 197.6895,  28.4262,  28.4262,  28.4262,\n",
      "         28.4262, 197.6895, 197.6895, 197.6895,  28.4262,  28.4262,  28.4262,\n",
      "         28.4262,   5.2026,  28.4262,  28.4262,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 187 was 93.3%\n",
      "tensor([5.2940e-23, 3.7957e-06, 3.2426e-06, 2.8584e-06, 2.6789e-06, 9.4229e-09,\n",
      "        7.0161e-09, 5.9390e-09, 5.7472e-09, 5.3635e-06, 5.1517e-06, 5.0017e-06,\n",
      "        1.7414e-04, 1.2762e-04, 1.2523e-04, 4.9284e-06, 4.7848e-06, 8.6269e-05,\n",
      "        8.4468e-05, 4.4632e-01, 4.2231e-01, 1.6234e+00, 1.6474e+00, 4.5737e-06,\n",
      "        8.2344e-05, 3.8847e-01, 1.6814e+00, 3.5394e-01, 1.7164e+00, 4.5949e-01,\n",
      "        9.3331e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([103.0040, 119.6054, 134.5865, 142.7775,   4.7160,   4.7166,   4.7140,\n",
      "        198.1456, 198.1456, 198.1456,   4.7154,   4.7161, 198.1456, 198.1456,\n",
      "        198.1456, 198.1456, 198.1456,  28.5065,  28.5065,   4.7158, 198.1456,\n",
      "        198.1456, 198.1456, 198.1456, 198.1456,  28.5065,  28.5065, 198.1456,\n",
      "         28.5065,  28.5065,   5.2026, 198.1456, 198.1456, 198.1456, 198.1456,\n",
      "        198.1456,  28.5065,  28.5065, 198.1456,  28.5065,  28.5065,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 198.1456,   5.2026,   5.2025, 198.1456,   5.2026,\n",
      "          5.2025, 198.1456,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        198.1456, 198.1456, 198.1456, 198.1456,  28.5065,  28.5065,  28.5065,\n",
      "         28.5065, 198.1456, 198.1456, 198.1456,  28.5065,  28.5065,  28.5065,\n",
      "         28.5065,   5.2026,  28.5065,  28.5065,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 188 was 93.3%\n",
      "tensor([0.0000e+00, 3.7855e-06, 3.2336e-06, 2.8506e-06, 2.6717e-06, 9.2906e-09,\n",
      "        6.9137e-09, 5.8504e-09, 5.6627e-09, 5.3441e-06, 5.1309e-06, 4.9877e-06,\n",
      "        1.7103e-04, 1.2519e-04, 1.2300e-04, 4.9134e-06, 4.7653e-06, 8.4644e-05,\n",
      "        8.2793e-05, 4.4481e-01, 4.2084e-01, 1.6177e+00, 1.6417e+00, 4.5577e-06,\n",
      "        8.0762e-05, 3.8713e-01, 1.6756e+00, 3.5273e-01, 1.7104e+00, 4.5788e-01,\n",
      "        9.3354e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([103.2002, 119.8446, 134.8534, 143.0488,   4.7122,   4.7103,   4.7126,\n",
      "        198.6013, 198.6013, 198.6013,   4.7140,   4.7117, 198.6013, 198.6013,\n",
      "        198.6013, 198.6013, 198.6013,  28.5868,  28.5868,   4.7132, 198.6013,\n",
      "        198.6013, 198.6013, 198.6013, 198.6013,  28.5868,  28.5868, 198.6013,\n",
      "         28.5868,  28.5868,   5.2026, 198.6013, 198.6013, 198.6013, 198.6013,\n",
      "        198.6013,  28.5868,  28.5868, 198.6013,  28.5868,  28.5868,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 198.6013,   5.2026,   5.2025, 198.6013,   5.2026,\n",
      "          5.2025, 198.6013,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        198.6013, 198.6013, 198.6013, 198.6013,  28.5868,  28.5868,  28.5868,\n",
      "         28.5868, 198.6013, 198.6013, 198.6013,  28.5868,  28.5868,  28.5868,\n",
      "         28.5868,   5.2026,  28.5868,  28.5868,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 189 was 93.3%\n",
      "tensor([9.2644e-23, 3.7755e-06, 3.2250e-06, 2.8432e-06, 2.6649e-06, 9.1631e-09,\n",
      "        6.8148e-09, 5.7651e-09, 5.5806e-09, 5.3262e-06, 5.1173e-06, 4.9680e-06,\n",
      "        1.6805e-04, 1.2299e-04, 1.2074e-04, 4.8945e-06, 4.7514e-06, 8.2980e-05,\n",
      "        8.1270e-05, 4.4325e-01, 4.1940e-01, 1.6123e+00, 1.6362e+00, 4.5423e-06,\n",
      "        7.9241e-05, 3.8581e-01, 1.6700e+00, 3.5164e-01, 1.7046e+00, 4.5633e-01,\n",
      "        9.3376e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([103.3964, 120.0835, 135.1199, 143.3196,   4.7092,   4.7090,   4.7088,\n",
      "        199.0567, 199.0567, 199.0567,   4.7079,   4.7103, 199.0567, 199.0567,\n",
      "        199.0567, 199.0567, 199.0567,  28.6671,  28.6671,   4.7090, 199.0567,\n",
      "        199.0567, 199.0567, 199.0567, 199.0567,  28.6671,  28.6671, 199.0567,\n",
      "         28.6671,  28.6671,   5.2026, 199.0567, 199.0567, 199.0567, 199.0567,\n",
      "        199.0567,  28.6671,  28.6671, 199.0567,  28.6671,  28.6671,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 199.0567,   5.2026,   5.2025, 199.0567,   5.2026,\n",
      "          5.2025, 199.0567,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        199.0567, 199.0567, 199.0567, 199.0567,  28.6671,  28.6671,  28.6671,\n",
      "         28.6671, 199.0567, 199.0567, 199.0567,  28.6671,  28.6671,  28.6671,\n",
      "         28.6671,   5.2026,  28.6671,  28.6671,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 190 was 93.3%\n",
      "tensor([7.9409e-23, 3.7654e-06, 3.2162e-06, 2.8351e-06, 2.6580e-06, 9.0337e-09,\n",
      "        6.7137e-09, 5.6783e-09, 5.4970e-09, 5.3070e-06, 5.0954e-06, 4.9525e-06,\n",
      "        1.6504e-04, 1.2065e-04, 1.1856e-04, 4.8798e-06, 4.7327e-06, 8.1390e-05,\n",
      "        7.9616e-05, 4.4162e-01, 4.1810e-01, 1.6068e+00, 1.6304e+00, 4.5266e-06,\n",
      "        7.7705e-05, 3.8448e-01, 1.6642e+00, 3.5038e-01, 1.6987e+00, 4.5471e-01,\n",
      "        9.3399e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([103.5924, 120.3221, 135.3859, 143.5899,   4.7044,   4.7060,   4.7075,\n",
      "        199.5116, 199.5116, 199.5116,   4.7065,   4.7043, 199.5116, 199.5116,\n",
      "        199.5116, 199.5116, 199.5116,  28.7474,  28.7474,   4.7057, 199.5116,\n",
      "        199.5116, 199.5116, 199.5116, 199.5116,  28.7474,  28.7474, 199.5116,\n",
      "         28.7474,  28.7474,   5.2026, 199.5116, 199.5116, 199.5116, 199.5116,\n",
      "        199.5116,  28.7474,  28.7474, 199.5116,  28.7474,  28.7474,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 199.5116,   5.2026,   5.2025, 199.5116,   5.2026,\n",
      "          5.2025, 199.5116,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        199.5116, 199.5116, 199.5116, 199.5116,  28.7474,  28.7474,  28.7474,\n",
      "         28.7474, 199.5116, 199.5116, 199.5116,  28.7474,  28.7474,  28.7474,\n",
      "         28.7474,   5.2026,  28.7474,  28.7474,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 191 was 93.4%\n",
      "tensor([5.0385e-08, 3.7671e-06, 3.2175e-06, 2.8378e-06, 2.6617e-06, 3.3087e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2910e-06, 5.0800e-06, 4.9327e-06,\n",
      "        1.6223e-04, 1.1857e-04, 1.1638e-04, 4.8605e-06, 4.7197e-06, 7.9783e-05,\n",
      "        7.8161e-05, 4.4015e-01, 4.1662e-01, 1.6014e+00, 1.6250e+00, 4.5126e-06,\n",
      "        7.6270e-05, 3.8335e-01, 1.6584e+00, 3.4914e-01, 1.6931e+00, 4.5317e-01,\n",
      "        9.3421e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([103.7883, 120.5603, 135.6514, 143.8597,   4.7023,   4.7023,   4.7013,\n",
      "        199.9661, 199.9661, 199.9661,   4.7020,   4.7029, 199.9661, 199.9661,\n",
      "        199.9661, 199.9661, 199.9661,  28.8277,  28.8277,   4.7037, 199.9661,\n",
      "        199.9661, 199.9661, 199.9661, 199.9661,  28.8277,  28.8277, 199.9661,\n",
      "         28.8277,  28.8277,   5.2026, 199.9661, 199.9661, 199.9661, 199.9661,\n",
      "        199.9661,  28.8277,  28.8277, 199.9661,  28.8277,  28.8277,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 199.9661,   5.2026,   5.2025, 199.9661,   5.2026,\n",
      "          5.2025, 199.9661,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        199.9661, 199.9661, 199.9661, 199.9661,  28.8277,  28.8277,  28.8277,\n",
      "         28.8277, 199.9661, 199.9661, 199.9661,  28.8277,  28.8277,  28.8277,\n",
      "         28.8277,   5.2026,  28.8277,  28.8277,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 192 was 93.4%\n",
      "tensor([4.9549e-08, 3.7566e-06, 3.2085e-06, 2.8300e-06, 2.6547e-06, 1.9852e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2695e-06, 5.0613e-06, 4.9199e-06,\n",
      "        1.5926e-04, 1.1635e-04, 1.1431e-04, 4.8455e-06, 4.7014e-06, 7.8310e-05,\n",
      "        7.6636e-05, 4.3856e-01, 4.1518e-01, 1.5960e+00, 1.6194e+00, 4.4951e-06,\n",
      "        7.4775e-05, 3.8200e-01, 1.6527e+00, 3.4806e-01, 1.6871e+00, 4.5158e-01,\n",
      "        9.3444e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([103.9840, 120.7983, 135.9164, 144.1290,   4.6992,   4.6983,   4.6999,\n",
      "        200.4202, 200.4202, 200.4202,   4.7006,   4.6983, 200.4202, 200.4202,\n",
      "        200.4202, 200.4202, 200.4202,  28.9079,  28.9079,   4.6981, 200.4202,\n",
      "        200.4202, 200.4202, 200.4202, 200.4202,  28.9079,  28.9079, 200.4202,\n",
      "         28.9079,  28.9079,   5.2026, 200.4202, 200.4202, 200.4202, 200.4202,\n",
      "        200.4202,  28.9079,  28.9079, 200.4202,  28.9079,  28.9079,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 200.4202,   5.2026,   5.2025, 200.4202,   5.2026,\n",
      "          5.2025, 200.4202,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        200.4202, 200.4202, 200.4202, 200.4202,  28.9079,  28.9079,  28.9079,\n",
      "         28.9079, 200.4202, 200.4202, 200.4202,  28.9079,  28.9079,  28.9079,\n",
      "         28.9079,   5.2026,  28.9079,  28.9079,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 193 was 93.4%\n",
      "tensor([4.8746e-08, 3.7470e-06, 3.2001e-06, 2.8224e-06, 2.6475e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2532e-06, 5.0457e-06, 4.8997e-06,\n",
      "        1.5656e-04, 1.1427e-04, 1.1219e-04, 4.8266e-06, 4.6871e-06, 7.6740e-05,\n",
      "        7.5194e-05, 4.3719e-01, 4.1383e-01, 1.5905e+00, 1.6139e+00, 4.4822e-06,\n",
      "        7.3399e-05, 3.8065e-01, 1.6472e+00, 3.4682e-01, 1.6815e+00, 4.5002e-01,\n",
      "        9.3466e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([104.1796, 121.0359, 136.1809, 144.3978,   4.6954,   4.6963,   4.6953,\n",
      "        200.8740, 200.8740, 200.8740,   4.6944,   4.6963, 200.8740, 200.8740,\n",
      "        200.8740, 200.8740, 200.8740,  28.9882,  28.9882,   4.6968, 200.8740,\n",
      "        200.8740, 200.8740, 200.8740, 200.8740,  28.9882,  28.9882, 200.8740,\n",
      "         28.9882,  28.9882,   5.2026, 200.8740, 200.8740, 200.8740, 200.8740,\n",
      "        200.8740,  28.9882,  28.9882, 200.8740,  28.9882,  28.9882,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 200.8740,   5.2026,   5.2025, 200.8740,   5.2026,\n",
      "          5.2025, 200.8740,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        200.8740, 200.8740, 200.8740, 200.8740,  28.9882,  28.9882,  28.9882,\n",
      "         28.9882, 200.8740, 200.8740, 200.8740,  28.9882,  28.9882,  28.9882,\n",
      "         28.9882,   5.2026,  28.9882,  28.9882,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 194 was 93.4%\n",
      "tensor([0.0000e+00, 3.7267e-06, 3.1820e-06, 2.8059e-06, 2.6315e-06, 8.5859e-09,\n",
      "        6.3704e-09, 5.3879e-09, 5.2198e-09, 5.2338e-06, 5.0257e-06, 4.8858e-06,\n",
      "        1.5431e-04, 1.1272e-04, 1.1087e-04, 4.8131e-06, 4.6688e-06, 7.5828e-05,\n",
      "        7.4254e-05, 4.3554e-01, 4.1239e-01, 1.5847e+00, 1.6079e+00, 4.4652e-06,\n",
      "        7.2564e-05, 3.7946e-01, 1.6412e+00, 3.4566e-01, 1.6755e+00, 4.4845e-01,\n",
      "        9.3490e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([104.3758, 121.2735, 136.4479, 144.6630,   4.6913,   4.6926,   4.6942,\n",
      "        201.3274, 201.3274, 201.3274,   4.6932,   4.6919, 201.3274, 201.3274,\n",
      "        201.3274, 201.3274, 201.3274,  29.0684,  29.0684,   4.6911, 201.3274,\n",
      "        201.3274, 201.3274, 201.3274, 201.3274,  29.0684,  29.0684, 201.3274,\n",
      "         29.0684,  29.0684,   5.2026, 201.3274, 201.3274, 201.3274, 201.3274,\n",
      "        201.3274,  29.0684,  29.0684, 201.3274,  29.0684,  29.0684,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 201.3274,   5.2026,   5.2025, 201.3274,   5.2026,\n",
      "          5.2025, 201.3274,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        201.3274, 201.3274, 201.3274, 201.3274,  29.0684,  29.0684,  29.0684,\n",
      "         29.0684, 201.3274, 201.3274, 201.3274,  29.0684,  29.0684,  29.0684,\n",
      "         29.0684,   5.2026,  29.0684,  29.0684,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 195 was 93.5%\n",
      "tensor([0.0000e+00, 3.7175e-06, 3.1736e-06, 2.7984e-06, 2.6250e-06, 8.4693e-09,\n",
      "        6.2804e-09, 5.3099e-09, 5.1441e-09, 5.2182e-06, 5.0102e-06, 4.8665e-06,\n",
      "        1.5174e-04, 1.1074e-04, 1.0879e-04, 4.7933e-06, 4.6552e-06, 7.4319e-05,\n",
      "        7.2873e-05, 4.3408e-01, 4.1109e-01, 1.5794e+00, 1.6025e+00, 4.4527e-06,\n",
      "        7.1237e-05, 3.7821e-01, 1.6356e+00, 3.4443e-01, 1.6699e+00, 4.4693e-01,\n",
      "        9.3512e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([104.5720, 121.5108, 136.7146, 144.9276,   4.6889,   4.6891,   4.6882,\n",
      "        201.7804, 201.7804, 201.7804,   4.6888,   4.6893, 201.7804, 201.7804,\n",
      "        201.7804, 201.7804, 201.7804,  29.1486,  29.1486,   4.6898, 201.7804,\n",
      "        201.7804, 201.7804, 201.7804, 201.7804,  29.1486,  29.1486, 201.7804,\n",
      "         29.1486,  29.1486,   5.2026, 201.7804, 201.7804, 201.7804, 201.7804,\n",
      "        201.7804,  29.1486,  29.1486, 201.7804,  29.1486,  29.1486,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 201.7804,   5.2026,   5.2025, 201.7804,   5.2026,\n",
      "          5.2025, 201.7804,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        201.7804, 201.7804, 201.7804, 201.7804,  29.1486,  29.1486,  29.1486,\n",
      "         29.1486, 201.7804, 201.7804, 201.7804,  29.1486,  29.1486,  29.1486,\n",
      "         29.1486,   5.2026,  29.1486,  29.1486,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 196 was 93.5%\n",
      "tensor([6.6174e-23, 3.7070e-06, 3.1648e-06, 2.7908e-06, 2.6180e-06, 8.3497e-09,\n",
      "        6.1884e-09, 5.2311e-09, 5.0686e-09, 5.1969e-06, 4.9914e-06, 4.8525e-06,\n",
      "        1.4893e-04, 1.0866e-04, 1.0686e-04, 4.7784e-06, 4.6375e-06, 7.2936e-05,\n",
      "        7.1448e-05, 4.3253e-01, 4.0962e-01, 1.5739e+00, 1.5969e+00, 4.4347e-06,\n",
      "        6.9836e-05, 3.7690e-01, 1.6300e+00, 3.4335e-01, 1.6640e+00, 4.4534e-01,\n",
      "        9.3535e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([104.7680, 121.7477, 136.9806, 145.1919,   4.6848,   4.6854,   4.6871,\n",
      "        202.2330, 202.2330, 202.2330,   4.6876,   4.6849, 202.2330, 202.2330,\n",
      "        202.2330, 202.2330, 202.2330,  29.2288,  29.2288,   4.6841, 202.2330,\n",
      "        202.2330, 202.2330, 202.2330, 202.2330,  29.2288,  29.2288, 202.2330,\n",
      "         29.2288,  29.2288,   5.2026, 202.2330, 202.2330, 202.2330, 202.2330,\n",
      "        202.2330,  29.2288,  29.2288, 202.2330,  29.2288,  29.2288,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 202.2330,   5.2026,   5.2025, 202.2330,   5.2026,\n",
      "          5.2025, 202.2330,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        202.2330, 202.2330, 202.2330, 202.2330,  29.2288,  29.2288,  29.2288,\n",
      "         29.2288, 202.2330, 202.2330, 202.2330,  29.2288,  29.2288,  29.2288,\n",
      "         29.2288,   5.2026,  29.2288,  29.2288,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 197 was 93.5%\n",
      "tensor([4.5933e-08, 3.7082e-06, 3.1662e-06, 2.7929e-06, 2.6212e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1827e-06, 4.9769e-06, 4.8329e-06,\n",
      "        1.4651e-04, 1.0679e-04, 1.0489e-04, 4.7596e-06, 4.6245e-06, 7.1492e-05,\n",
      "        7.0151e-05, 4.3116e-01, 4.0830e-01, 1.5687e+00, 1.5917e+00, 4.4234e-06,\n",
      "        6.8595e-05, 3.7564e-01, 1.6246e+00, 3.4219e-01, 1.6586e+00, 4.4386e-01,\n",
      "        9.3556e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([104.9639, 121.9844, 137.2463, 145.4555,   4.6823,   4.6818,   4.6827,\n",
      "        202.6853, 202.6853, 202.6853,   4.6816,   4.6823, 202.6853, 202.6853,\n",
      "        202.6853, 202.6853, 202.6853,  29.3090,  29.3090,   4.6828, 202.6853,\n",
      "        202.6853, 202.6853, 202.6853, 202.6853,  29.3090,  29.3090, 202.6853,\n",
      "         29.3090,  29.3090,   5.2026, 202.6853, 202.6853, 202.6853, 202.6853,\n",
      "        202.6853,  29.3090,  29.3090, 202.6853,  29.3090,  29.3090,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 202.6853,   5.2026,   5.2025, 202.6853,   5.2026,\n",
      "          5.2025, 202.6853,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        202.6853, 202.6853, 202.6853, 202.6853,  29.3090,  29.3090,  29.3090,\n",
      "         29.3090, 202.6853, 202.6853, 202.6853,  29.3090,  29.3090,  29.3090,\n",
      "         29.3090,   5.2026,  29.3090,  29.3090,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 198 was 93.5%\n",
      "tensor([4.5166e-08, 3.6978e-06, 3.1569e-06, 2.7848e-06, 2.6143e-06, 9.9262e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1609e-06, 4.9576e-06, 4.8186e-06,\n",
      "        1.4378e-04, 1.0476e-04, 1.0304e-04, 4.7456e-06, 4.6068e-06, 7.0150e-05,\n",
      "        6.8755e-05, 4.2951e-01, 4.0693e-01, 1.5634e+00, 1.5861e+00, 4.4051e-06,\n",
      "        6.7228e-05, 3.7441e-01, 1.6189e+00, 3.4101e-01, 1.6528e+00, 4.4227e-01,\n",
      "        9.3578e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([105.1597, 122.2207, 137.5114, 145.7188,   4.6773,   4.6799,   4.6782,\n",
      "        203.1373, 203.1373, 203.1373,   4.6804,   4.6803, 203.1373, 203.1373,\n",
      "        203.1373, 203.1373, 203.1373,  29.3892,  29.3892,   4.6771, 203.1373,\n",
      "        203.1373, 203.1373, 203.1373, 203.1373,  29.3892,  29.3892, 203.1373,\n",
      "         29.3892,  29.3892,   5.2026, 203.1373, 203.1373, 203.1373, 203.1373,\n",
      "        203.1373,  29.3892,  29.3892, 203.1373,  29.3892,  29.3892,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 203.1373,   5.2026,   5.2025, 203.1373,   5.2026,\n",
      "          5.2025, 203.1373,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        203.1373, 203.1373, 203.1373, 203.1373,  29.3892,  29.3892,  29.3892,\n",
      "         29.3892, 203.1373, 203.1373, 203.1373,  29.3892,  29.3892,  29.3892,\n",
      "         29.3892,   5.2026,  29.3892,  29.3892,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 199 was 93.5%\n",
      "tensor([4.4453e-08, 3.6885e-06, 3.1492e-06, 2.7779e-06, 2.6077e-06, 2.3161e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1476e-06, 4.9398e-06, 4.8040e-06,\n",
      "        1.4140e-04, 1.0285e-04, 1.0121e-04, 4.7296e-06, 4.5902e-06, 6.8843e-05,\n",
      "        6.7454e-05, 4.2820e-01, 4.0557e-01, 1.5582e+00, 1.5809e+00, 4.3936e-06,\n",
      "        6.6029e-05, 3.7310e-01, 1.6136e+00, 3.3996e-01, 1.6473e+00, 4.4083e-01,\n",
      "        9.3599e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([105.3554, 122.4568, 137.7762, 145.9814,   4.6748,   4.6763,   4.6756,\n",
      "        203.5888, 203.5888, 203.5888,   4.6743,   4.6760, 203.5888, 203.5888,\n",
      "        203.5888, 203.5888, 203.5888,  29.4694,  29.4694,   4.6758, 203.5888,\n",
      "        203.5888, 203.5888, 203.5888, 203.5888,  29.4694,  29.4694, 203.5888,\n",
      "         29.4694,  29.4694,   5.2026, 203.5888, 203.5888, 203.5888, 203.5888,\n",
      "        203.5888,  29.4694,  29.4694, 203.5888,  29.4694,  29.4694,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 203.5888,   5.2026,   5.2025, 203.5888,   5.2026,\n",
      "          5.2025, 203.5888,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        203.5888, 203.5888, 203.5888, 203.5888,  29.4694,  29.4694,  29.4694,\n",
      "         29.4694, 203.5888, 203.5888, 203.5888,  29.4694,  29.4694,  29.4694,\n",
      "         29.4694,   5.2026,  29.4694,  29.4694,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 200 was 93.6%\n",
      "tensor([4.3718e-08, 3.6785e-06, 3.1400e-06, 2.7700e-06, 2.6009e-06, 1.4889e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1271e-06, 4.9221e-06, 4.7870e-06,\n",
      "        1.3881e-04, 1.0097e-04, 9.9377e-05, 4.7142e-06, 4.5749e-06, 6.7501e-05,\n",
      "        6.6138e-05, 4.2658e-01, 4.0422e-01, 1.5529e+00, 1.5754e+00, 4.3763e-06,\n",
      "        6.4738e-05, 3.7195e-01, 1.6079e+00, 3.3873e-01, 1.6416e+00, 4.3925e-01,\n",
      "        9.3622e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([105.5511, 122.6926, 138.0405, 146.2436,   4.6715,   4.6701,   4.6736,\n",
      "        204.0401, 204.0401, 204.0401,   4.6731,   4.6718, 204.0401, 204.0401,\n",
      "        204.0401, 204.0401, 204.0401,  29.5495,  29.5495,   4.6723, 204.0401,\n",
      "        204.0401, 204.0401, 204.0401, 204.0401,  29.5495,  29.5495, 204.0401,\n",
      "         29.5495,  29.5495,   5.2026, 204.0401, 204.0401, 204.0401, 204.0401,\n",
      "        204.0401,  29.5495,  29.5495, 204.0401,  29.5495,  29.5495,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 204.0401,   5.2026,   5.2025, 204.0401,   5.2026,\n",
      "          5.2025, 204.0401,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        204.0401, 204.0401, 204.0401, 204.0401,  29.5495,  29.5495,  29.5495,\n",
      "         29.5495, 204.0401, 204.0401, 204.0401,  29.5495,  29.5495,  29.5495,\n",
      "         29.5495,   5.2026,  29.5495,  29.5495,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 201 was 93.6%\n",
      "tensor([0.0000e+00, 3.6594e-06, 3.1231e-06, 2.7540e-06, 2.5855e-06, 7.7934e-09,\n",
      "        5.7600e-09, 4.8620e-09, 4.7137e-09, 5.1103e-06, 4.9097e-06, 4.7690e-06,\n",
      "        1.3645e-04, 9.9226e-05, 9.7533e-05, 4.6951e-06, 4.5620e-06, 6.6188e-05,\n",
      "        6.4959e-05, 4.2511e-01, 4.0292e-01, 1.5478e+00, 1.5701e+00, 4.3626e-06,\n",
      "        6.3548e-05, 3.7071e-01, 1.6026e+00, 3.3764e-01, 1.6362e+00, 4.3778e-01,\n",
      "        9.3643e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([105.7466, 122.9281, 138.3043, 146.5053,   4.6681,   4.6690,   4.6675,\n",
      "        204.4909, 204.4909, 204.4909,   4.6687,   4.6698, 204.4909, 204.4909,\n",
      "        204.4909, 204.4909, 204.4909,  29.6297,  29.6297,   4.6688, 204.4909,\n",
      "        204.4909, 204.4909, 204.4909, 204.4909,  29.6297,  29.6297, 204.4909,\n",
      "         29.6297,  29.6297,   5.2026, 204.4909, 204.4909, 204.4909, 204.4909,\n",
      "        204.4909,  29.6297,  29.6297, 204.4909,  29.6297,  29.6297,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 204.4909,   5.2026,   5.2025, 204.4909,   5.2026,\n",
      "          5.2025, 204.4909,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        204.4909, 204.4909, 204.4909, 204.4909,  29.6297,  29.6297,  29.6297,\n",
      "         29.6297, 204.4909, 204.4909, 204.4909,  29.6297,  29.6297,  29.6297,\n",
      "         29.6297,   5.2026,  29.6297,  29.6297,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 202 was 93.6%\n",
      "tensor([1.9852e-23, 3.6494e-06, 3.1147e-06, 2.7466e-06, 2.5787e-06, 7.6850e-09,\n",
      "        5.6769e-09, 4.7905e-09, 4.6454e-09, 5.0919e-06, 4.8888e-06, 4.7557e-06,\n",
      "        1.3402e-04, 9.7334e-05, 9.5829e-05, 4.6811e-06, 4.5436e-06, 6.4968e-05,\n",
      "        6.3665e-05, 4.2365e-01, 4.0153e-01, 1.5425e+00, 1.5647e+00, 4.3471e-06,\n",
      "        6.2340e-05, 3.6941e-01, 1.5971e+00, 3.3653e-01, 1.6305e+00, 4.3625e-01,\n",
      "        9.3665e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([105.9421, 123.1633, 138.5677, 146.7665,   4.6648,   4.6644,   4.6664,\n",
      "        204.9415, 204.9415, 204.9415,   4.6667,   4.6637, 204.9415, 204.9415,\n",
      "        204.9415, 204.9415, 204.9415,  29.7098,  29.7098,   4.6653, 204.9415,\n",
      "        204.9415, 204.9415, 204.9415, 204.9415,  29.7098,  29.7098, 204.9415,\n",
      "         29.7098,  29.7098,   5.2026, 204.9415, 204.9415, 204.9415, 204.9415,\n",
      "        204.9415,  29.7098,  29.7098, 204.9415,  29.7098,  29.7098,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 204.9415,   5.2026,   5.2025, 204.9415,   5.2026,\n",
      "          5.2025, 204.9415,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        204.9415, 204.9415, 204.9415, 204.9415,  29.7098,  29.7098,  29.7098,\n",
      "         29.7098, 204.9415, 204.9415, 204.9415,  29.7098,  29.7098,  29.7098,\n",
      "         29.7098,   5.2026,  29.7098,  29.7098,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 203 was 93.6%\n",
      "tensor([0.0000e+00, 3.6403e-06, 3.1065e-06, 2.7396e-06, 2.5724e-06, 7.5822e-09,\n",
      "        5.5972e-09, 4.7226e-09, 4.5794e-09, 5.0752e-06, 4.8752e-06, 4.7367e-06,\n",
      "        1.3173e-04, 9.5689e-05, 9.4068e-05, 4.6630e-06, 4.5322e-06, 6.3688e-05,\n",
      "        6.2519e-05, 4.2224e-01, 4.0018e-01, 1.5374e+00, 1.5595e+00, 4.3334e-06,\n",
      "        6.1195e-05, 3.6825e-01, 1.5918e+00, 3.3539e-01, 1.6251e+00, 4.3478e-01,\n",
      "        9.3686e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([106.1375, 123.3983, 138.8306, 147.0273,   4.6605,   4.6633,   4.6620,\n",
      "        205.3917, 205.3917, 205.3917,   4.6605,   4.6625, 205.3917, 205.3917,\n",
      "        205.3917, 205.3917, 205.3917,  29.7899,  29.7899,   4.6618, 205.3917,\n",
      "        205.3917, 205.3917, 205.3917, 205.3917,  29.7899,  29.7899, 205.3917,\n",
      "         29.7899,  29.7899,   5.2026, 205.3917, 205.3917, 205.3917, 205.3917,\n",
      "        205.3917,  29.7899,  29.7899, 205.3917,  29.7899,  29.7899,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 205.3917,   5.2026,   5.2025, 205.3917,   5.2026,\n",
      "          5.2025, 205.3917,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        205.3917, 205.3917, 205.3917, 205.3917,  29.7899,  29.7899,  29.7899,\n",
      "         29.7899, 205.3917, 205.3917, 205.3917,  29.7899,  29.7899,  29.7899,\n",
      "         29.7899,   5.2026,  29.7899,  29.7899,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 204 was 93.7%\n",
      "tensor([2.6470e-23, 3.6309e-06, 3.0981e-06, 2.7323e-06, 2.5660e-06, 7.4772e-09,\n",
      "        5.5161e-09, 4.6529e-09, 4.5131e-09, 5.0583e-06, 4.8542e-06, 4.7236e-06,\n",
      "        1.2941e-04, 9.3853e-05, 9.2449e-05, 4.6506e-06, 4.5134e-06, 6.2514e-05,\n",
      "        6.1256e-05, 4.2074e-01, 3.9886e-01, 1.5322e+00, 1.5542e+00, 4.3189e-06,\n",
      "        6.0041e-05, 3.6708e-01, 1.5863e+00, 3.3423e-01, 1.6196e+00, 4.3330e-01,\n",
      "        9.3707e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([106.3328, 123.6330, 139.0932, 147.2874,   4.6572,   4.6571,   4.6584,\n",
      "        205.8415, 205.8415, 205.8415,   4.6593,   4.6582, 205.8415, 205.8415,\n",
      "        205.8415, 205.8415, 205.8415,  29.8701,  29.8701,   4.6598, 205.8415,\n",
      "        205.8415, 205.8415, 205.8415, 205.8415,  29.8701,  29.8701, 205.8415,\n",
      "         29.8701,  29.8701,   5.2026, 205.8415, 205.8415, 205.8415, 205.8415,\n",
      "        205.8415,  29.8701,  29.8701, 205.8415,  29.8701,  29.8701,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 205.8415,   5.2026,   5.2025, 205.8415,   5.2026,\n",
      "          5.2025, 205.8415,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        205.8415, 205.8415, 205.8415, 205.8415,  29.8701,  29.8701,  29.8701,\n",
      "         29.8701, 205.8415, 205.8415, 205.8415,  29.8701,  29.8701,  29.8701,\n",
      "         29.8701,   5.2026,  29.8701,  29.8701,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 205 was 93.7%\n",
      "tensor([0.0000e+00, 3.6210e-06, 3.0898e-06, 2.7252e-06, 2.5596e-06, 7.3734e-09,\n",
      "        5.4381e-09, 4.5858e-09, 4.4482e-09, 5.0394e-06, 4.8419e-06, 4.7067e-06,\n",
      "        1.2709e-04, 9.2209e-05, 9.0729e-05, 4.6318e-06, 4.5001e-06, 6.1312e-05,\n",
      "        6.0164e-05, 4.1924e-01, 3.9747e-01, 1.5271e+00, 1.5490e+00, 4.3031e-06,\n",
      "        5.8899e-05, 3.6584e-01, 1.5809e+00, 3.3324e-01, 1.6140e+00, 4.3184e-01,\n",
      "        9.3728e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([106.5281, 123.8674, 139.3554, 147.5470,   4.6537,   4.6560,   4.6547,\n",
      "        206.2911, 206.2911, 206.2911,   4.6547,   4.6562, 206.2911, 206.2911,\n",
      "        206.2911, 206.2911, 206.2911,  29.9502,  29.9502,   4.6540, 206.2911,\n",
      "        206.2911, 206.2911, 206.2911, 206.2911,  29.9502,  29.9502, 206.2911,\n",
      "         29.9502,  29.9502,   5.2026, 206.2911, 206.2911, 206.2911, 206.2911,\n",
      "        206.2911,  29.9502,  29.9502, 206.2911,  29.9502,  29.9502,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 206.2911,   5.2026,   5.2025, 206.2911,   5.2026,\n",
      "          5.2025, 206.2911,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        206.2911, 206.2911, 206.2911, 206.2911,  29.9502,  29.9502,  29.9502,\n",
      "         29.9502, 206.2911, 206.2911, 206.2911,  29.9502,  29.9502,  29.9502,\n",
      "         29.9502,   5.2026,  29.9502,  29.9502,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 206 was 93.7%\n",
      "tensor([0.0000e+00, 3.6120e-06, 3.0820e-06, 2.7179e-06, 2.5532e-06, 7.2742e-09,\n",
      "        5.3614e-09, 4.5196e-09, 4.3850e-09, 5.0238e-06, 4.8216e-06, 4.6920e-06,\n",
      "        1.2495e-04, 9.0486e-05, 8.9152e-05, 4.6181e-06, 4.4828e-06, 6.0163e-05,\n",
      "        5.8975e-05, 4.1786e-01, 3.9624e-01, 1.5220e+00, 1.5437e+00, 4.2908e-06,\n",
      "        5.7829e-05, 3.6459e-01, 1.5756e+00, 3.3205e-01, 1.6087e+00, 4.3033e-01,\n",
      "        9.3750e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([106.7234, 124.1016, 139.6171, 147.8061,   4.6512,   4.6514,   4.6512,\n",
      "        206.7403, 206.7403, 206.7403,   4.6519,   4.6501, 206.7403, 206.7403,\n",
      "        206.7403, 206.7403, 206.7403,  30.0303,  30.0303,   4.6527, 206.7403,\n",
      "        206.7403, 206.7403, 206.7403, 206.7403,  30.0303,  30.0303, 206.7403,\n",
      "         30.0303,  30.0303,   5.2026, 206.7403, 206.7403, 206.7403, 206.7403,\n",
      "        206.7403,  30.0303,  30.0303, 206.7403,  30.0303,  30.0303,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 206.7403,   5.2026,   5.2025, 206.7403,   5.2026,\n",
      "          5.2025, 206.7403,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        206.7403, 206.7403, 206.7403, 206.7403,  30.0303,  30.0303,  30.0303,\n",
      "         30.0303, 206.7403, 206.7403, 206.7403,  30.0303,  30.0303,  30.0303,\n",
      "         30.0303,   5.2026,  30.0303,  30.0303,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 207 was 93.7%\n",
      "tensor([3.8803e-08, 3.6105e-06, 3.0808e-06, 2.7179e-06, 2.5540e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0038e-06, 4.8077e-06, 4.6752e-06,\n",
      "        1.2220e-04, 8.8426e-05, 8.7013e-05, 4.6013e-06, 4.4705e-06, 5.8588e-05,\n",
      "        5.7467e-05, 4.1643e-01, 3.9481e-01, 1.5174e+00, 1.5390e+00, 4.2742e-06,\n",
      "        5.6239e-05, 3.6344e-01, 1.5705e+00, 3.3099e-01, 1.6034e+00, 4.2888e-01,\n",
      "        9.3769e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([106.9176, 124.3353, 139.8754, 148.0683,   4.6489,   4.6481,   4.6481,\n",
      "        207.1892, 207.1892, 207.1892,   4.6471,   4.6487, 207.1892, 207.1892,\n",
      "        207.1892, 207.1892, 207.1892,  30.1104,  30.1104,   4.6467, 207.1892,\n",
      "        207.1892, 207.1892, 207.1892, 207.1892,  30.1104,  30.1104, 207.1892,\n",
      "         30.1104,  30.1104,   5.2026, 207.1892, 207.1892, 207.1892, 207.1892,\n",
      "        207.1892,  30.1104,  30.1104, 207.1892,  30.1104,  30.1104,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 207.1892,   5.2026,   5.2025, 207.1892,   5.2026,\n",
      "          5.2025, 207.1892,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        207.1892, 207.1892, 207.1892, 207.1892,  30.1104,  30.1104,  30.1104,\n",
      "         30.1104, 207.1892, 207.1892, 207.1892,  30.1104,  30.1104,  30.1104,\n",
      "         30.1104,   5.2026,  30.1104,  30.1104,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 208 was 93.7%\n",
      "tensor([0.0000e+00, 3.5928e-06, 3.0651e-06, 2.7028e-06, 2.5394e-06, 7.0412e-09,\n",
      "        5.1797e-09, 4.3603e-09, 4.2303e-09, 4.9869e-06, 4.7905e-06, 4.6598e-06,\n",
      "        1.2009e-04, 8.6809e-05, 8.5469e-05, 4.5869e-06, 4.4538e-06, 5.7479e-05,\n",
      "        5.6367e-05, 4.1504e-01, 3.9368e-01, 1.5123e+00, 1.5337e+00, 4.2611e-06,\n",
      "        5.5206e-05, 3.6214e-01, 1.5654e+00, 3.2979e-01, 1.5981e+00, 4.2740e-01,\n",
      "        9.3790e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([107.1117, 124.5687, 140.1333, 148.3301,   4.6422,   4.6450,   4.6451,\n",
      "        207.6378, 207.6378, 207.6378,   4.6449,   4.6440, 207.6378, 207.6378,\n",
      "        207.6378, 207.6378, 207.6378,  30.1904,  30.1904,   4.6454, 207.6378,\n",
      "        207.6378, 207.6378, 207.6378, 207.6378,  30.1904,  30.1904, 207.6378,\n",
      "         30.1904,  30.1904,   5.2026, 207.6378, 207.6378, 207.6378, 207.6378,\n",
      "        207.6378,  30.1904,  30.1904, 207.6378,  30.1904,  30.1904,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 207.6378,   5.2026,   5.2025, 207.6378,   5.2026,\n",
      "          5.2025, 207.6378,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        207.6378, 207.6378, 207.6378, 207.6378,  30.1904,  30.1904,  30.1904,\n",
      "         30.1904, 207.6378, 207.6378, 207.6378,  30.1904,  30.1904,  30.1904,\n",
      "         30.1904,   5.2026,  30.1904,  30.1904,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 209 was 93.8%\n",
      "tensor([0.0000e+00, 3.5834e-06, 3.0568e-06, 2.6961e-06, 2.5332e-06, 6.9460e-09,\n",
      "        5.1069e-09, 4.2987e-09, 4.1707e-09, 4.9724e-06, 4.7743e-06, 4.6432e-06,\n",
      "        1.1800e-04, 8.5280e-05, 8.3940e-05, 4.5701e-06, 4.4402e-06, 5.6390e-05,\n",
      "        5.5324e-05, 4.1357e-01, 3.9222e-01, 1.5073e+00, 1.5286e+00, 4.2464e-06,\n",
      "        5.4197e-05, 3.6107e-01, 1.5600e+00, 3.2879e-01, 1.5927e+00, 4.2595e-01,\n",
      "        9.3811e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([107.3058, 124.8019, 140.3909, 148.5913,   4.6407,   4.6418,   4.6402,\n",
      "        208.0861, 208.0861, 208.0861,   4.6418,   4.6417, 208.0861, 208.0861,\n",
      "        208.0861, 208.0861, 208.0861,  30.2705,  30.2705,   4.6394, 208.0861,\n",
      "        208.0861, 208.0861, 208.0861, 208.0861,  30.2705,  30.2705, 208.0861,\n",
      "         30.2705,  30.2705,   5.2026, 208.0861, 208.0861, 208.0861, 208.0861,\n",
      "        208.0861,  30.2705,  30.2705, 208.0861,  30.2705,  30.2705,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 208.0861,   5.2026,   5.2025, 208.0861,   5.2026,\n",
      "          5.2025, 208.0861,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        208.0861, 208.0861, 208.0861, 208.0861,  30.2705,  30.2705,  30.2705,\n",
      "         30.2705, 208.0861, 208.0861, 208.0861,  30.2705,  30.2705,  30.2705,\n",
      "         30.2705,   5.2026,  30.2705,  30.2705,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 210 was 93.8%\n",
      "tensor([0.0000e+00, 3.5742e-06, 3.0490e-06, 2.6890e-06, 2.5267e-06, 6.8525e-09,\n",
      "        5.0360e-09, 4.2378e-09, 4.1121e-09, 4.9543e-06, 4.7569e-06, 4.6292e-06,\n",
      "        1.1599e-04, 8.3733e-05, 8.2461e-05, 4.5547e-06, 4.4238e-06, 5.5346e-05,\n",
      "        5.4282e-05, 4.1225e-01, 3.9097e-01, 1.5022e+00, 1.5235e+00, 4.2338e-06,\n",
      "        5.3212e-05, 3.5976e-01, 1.5548e+00, 3.2767e-01, 1.5873e+00, 4.2450e-01,\n",
      "        9.3832e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([107.4999, 125.0348, 140.6481, 148.8520,   4.6384,   4.6351,   4.6380,\n",
      "        208.5340, 208.5340, 208.5340,   4.6371,   4.6379, 208.5340, 208.5340,\n",
      "        208.5340, 208.5340, 208.5340,  30.3506,  30.3506,   4.6381, 208.5340,\n",
      "        208.5340, 208.5340, 208.5340, 208.5340,  30.3506,  30.3506, 208.5340,\n",
      "         30.3506,  30.3506,   5.2026, 208.5340, 208.5340, 208.5340, 208.5340,\n",
      "        208.5340,  30.3506,  30.3506, 208.5340,  30.3506,  30.3506,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 208.5340,   5.2026,   5.2025, 208.5340,   5.2026,\n",
      "          5.2025, 208.5340,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        208.5340, 208.5340, 208.5340, 208.5340,  30.3506,  30.3506,  30.3506,\n",
      "         30.3506, 208.5340, 208.5340, 208.5340,  30.3506,  30.3506,  30.3506,\n",
      "         30.3506,   5.2026,  30.3506,  30.3506,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 211 was 93.8%\n",
      "tensor([0.0000e+00, 3.5650e-06, 3.0409e-06, 2.6820e-06, 2.5205e-06, 6.7594e-09,\n",
      "        4.9651e-09, 4.1777e-09, 4.0543e-09, 4.9352e-06, 4.7444e-06, 4.6130e-06,\n",
      "        1.1392e-04, 8.2269e-05, 8.0999e-05, 4.5398e-06, 4.4103e-06, 5.4310e-05,\n",
      "        5.3297e-05, 4.1074e-01, 3.8974e-01, 1.4973e+00, 1.5183e+00, 4.2177e-06,\n",
      "        5.2216e-05, 3.5861e-01, 1.5496e+00, 3.2659e-01, 1.5820e+00, 4.2306e-01,\n",
      "        9.3852e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([107.6940, 125.2675, 140.9049, 149.1120,   4.6316,   4.6337,   4.6340,\n",
      "        208.9817, 208.9817, 208.9817,   4.6347,   4.6357, 208.9817, 208.9817,\n",
      "        208.9817, 208.9817, 208.9817,  30.4306,  30.4306,   4.6338, 208.9817,\n",
      "        208.9817, 208.9817, 208.9817, 208.9817,  30.4306,  30.4306, 208.9817,\n",
      "         30.4306,  30.4306,   5.2026, 208.9817, 208.9817, 208.9817, 208.9817,\n",
      "        208.9817,  30.4306,  30.4306, 208.9817,  30.4306,  30.4306,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 208.9817,   5.2026,   5.2025, 208.9817,   5.2026,\n",
      "          5.2025, 208.9817,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        208.9817, 208.9817, 208.9817, 208.9817,  30.4306,  30.4306,  30.4306,\n",
      "         30.4306, 208.9817, 208.9817, 208.9817,  30.4306,  30.4306,  30.4306,\n",
      "         30.4306,   5.2026,  30.4306,  30.4306,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 212 was 93.8%\n",
      "tensor([0.0000e+00, 3.5560e-06, 3.0336e-06, 2.6757e-06, 2.5150e-06, 6.6450e-09,\n",
      "        4.8792e-09, 4.1058e-09, 3.9854e-09, 4.9228e-06, 4.7255e-06, 4.5976e-06,\n",
      "        1.1158e-04, 8.0488e-05, 7.9297e-05, 4.5236e-06, 4.3944e-06, 5.3117e-05,\n",
      "        5.2119e-05, 4.0932e-01, 3.8842e-01, 1.4919e+00, 1.5129e+00, 4.2051e-06,\n",
      "        5.1153e-05, 3.5739e-01, 1.5442e+00, 3.2560e-01, 1.5765e+00, 4.2168e-01,\n",
      "        9.3874e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([107.8892, 125.5000, 141.1636, 149.3682,   4.6290,   4.6316,   4.6303,\n",
      "        209.4290, 209.4290, 209.4290,   4.6302,   4.6295, 209.4290, 209.4290,\n",
      "        209.4290, 209.4290, 209.4290,  30.5106,  30.5106,   4.6317, 209.4290,\n",
      "        209.4290, 209.4290, 209.4290, 209.4290,  30.5106,  30.5106, 209.4290,\n",
      "         30.5106,  30.5106,   5.2026, 209.4290, 209.4290, 209.4290, 209.4290,\n",
      "        209.4290,  30.5106,  30.5106, 209.4290,  30.5106,  30.5106,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 209.4290,   5.2026,   5.2025, 209.4290,   5.2026,\n",
      "          5.2025, 209.4290,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        209.4290, 209.4290, 209.4290, 209.4290,  30.5106,  30.5106,  30.5106,\n",
      "         30.5106, 209.4290, 209.4290, 209.4290,  30.5106,  30.5106,  30.5106,\n",
      "         30.5106,   5.2026,  30.5106,  30.5106,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 213 was 93.8%\n",
      "tensor([0.0000e+00, 3.5468e-06, 3.0250e-06, 2.6690e-06, 2.5085e-06, 6.5576e-09,\n",
      "        4.8116e-09, 4.0486e-09, 3.9309e-09, 4.9035e-06, 4.7093e-06, 4.5817e-06,\n",
      "        1.0963e-04, 7.9098e-05, 7.7941e-05, 4.5096e-06, 4.3808e-06, 5.2126e-05,\n",
      "        5.1174e-05, 4.0797e-01, 3.8696e-01, 1.4869e+00, 1.5079e+00, 4.1899e-06,\n",
      "        5.0210e-05, 3.5638e-01, 1.5388e+00, 3.2444e-01, 1.5712e+00, 4.2025e-01,\n",
      "        9.3895e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.0844, 125.7321, 141.4219, 149.6238,   4.6264,   4.6268,   4.6275,\n",
      "        209.8761, 209.8761, 209.8761,   4.6272,   4.6274, 209.8761, 209.8761,\n",
      "        209.8761, 209.8761, 209.8761,  30.5907,  30.5907,   4.6257, 209.8761,\n",
      "        209.8761, 209.8761, 209.8761, 209.8761,  30.5907,  30.5907, 209.8761,\n",
      "         30.5907,  30.5907,   5.2026, 209.8761, 209.8761, 209.8761, 209.8761,\n",
      "        209.8761,  30.5907,  30.5907, 209.8761,  30.5907,  30.5907,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 209.8761,   5.2026,   5.2025, 209.8761,   5.2026,\n",
      "          5.2025, 209.8761,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        209.8761, 209.8761, 209.8761, 209.8761,  30.5907,  30.5907,  30.5907,\n",
      "         30.5907, 209.8761, 209.8761, 209.8761,  30.5907,  30.5907,  30.5907,\n",
      "         30.5907,   5.2026,  30.5907,  30.5907,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 214 was 93.9%\n",
      "tensor([1.3235e-23, 3.5376e-06, 3.0173e-06, 2.6615e-06, 2.5023e-06, 6.4692e-09,\n",
      "        4.7455e-09, 3.9917e-09, 3.8759e-09, 4.8865e-06, 4.6935e-06, 4.5659e-06,\n",
      "        1.0777e-04, 7.7676e-05, 7.6528e-05, 4.4923e-06, 4.3655e-06, 5.1150e-05,\n",
      "        5.0230e-05, 4.0654e-01, 3.8583e-01, 1.4819e+00, 1.5027e+00, 4.1773e-06,\n",
      "        4.9303e-05, 3.5507e-01, 1.5337e+00, 3.2334e-01, 1.5659e+00, 4.1878e-01,\n",
      "        9.3915e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.2796, 125.9639, 141.6795, 149.8789,   4.6238,   4.6240,   4.6211,\n",
      "        210.3228, 210.3228, 210.3228,   4.6235,   4.6230, 210.3228, 210.3228,\n",
      "        210.3228, 210.3228, 210.3228,  30.6707,  30.6707,   4.6244, 210.3228,\n",
      "        210.3228, 210.3228, 210.3228, 210.3228,  30.6707,  30.6707, 210.3228,\n",
      "         30.6707,  30.6707,   5.2026, 210.3228, 210.3228, 210.3228, 210.3228,\n",
      "        210.3228,  30.6707,  30.6707, 210.3228,  30.6707,  30.6707,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 210.3228,   5.2026,   5.2025, 210.3228,   5.2026,\n",
      "          5.2025, 210.3228,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        210.3228, 210.3228, 210.3228, 210.3228,  30.6707,  30.6707,  30.6707,\n",
      "         30.6707, 210.3228, 210.3228, 210.3228,  30.6707,  30.6707,  30.6707,\n",
      "         30.6707,   5.2026,  30.6707,  30.6707,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 215 was 93.9%\n",
      "tensor([3.4093e-08, 3.5362e-06, 3.0163e-06, 2.6618e-06, 2.5033e-06, 1.4062e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8682e-06, 4.6778e-06, 4.5536e-06,\n",
      "        1.0589e-04, 7.6332e-05, 7.5232e-05, 4.4785e-06, 4.3517e-06, 5.0248e-05,\n",
      "        4.9327e-05, 4.0520e-01, 3.8445e-01, 1.4771e+00, 1.4979e+00, 4.1619e-06,\n",
      "        4.8410e-05, 3.5395e-01, 1.5286e+00, 3.2232e-01, 1.5607e+00, 4.1739e-01,\n",
      "        9.3935e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.4742, 126.1949, 141.9375, 150.1346,   4.6185,   4.6191,   4.6200,\n",
      "        210.7693, 210.7693, 210.7693,   4.6215,   4.6209, 210.7693, 210.7693,\n",
      "        210.7693, 210.7693, 210.7693,  30.7507,  30.7507,   4.6184, 210.7693,\n",
      "        210.7693, 210.7693, 210.7693, 210.7693,  30.7507,  30.7507, 210.7693,\n",
      "         30.7507,  30.7507,   5.2026, 210.7693, 210.7693, 210.7693, 210.7693,\n",
      "        210.7693,  30.7507,  30.7507, 210.7693,  30.7507,  30.7507,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 210.7693,   5.2026,   5.2025, 210.7693,   5.2026,\n",
      "          5.2025, 210.7693,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        210.7693, 210.7693, 210.7693, 210.7693,  30.7507,  30.7507,  30.7507,\n",
      "         30.7507, 210.7693, 210.7693, 210.7693,  30.7507,  30.7507,  30.7507,\n",
      "         30.7507,   5.2026,  30.7507,  30.7507,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 216 was 93.9%\n",
      "tensor([3.3553e-08, 3.5270e-06, 3.0088e-06, 2.6547e-06, 2.4971e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8554e-06, 4.6627e-06, 4.5355e-06,\n",
      "        1.0411e-04, 7.4946e-05, 7.3844e-05, 4.4615e-06, 4.3369e-06, 4.9260e-05,\n",
      "        4.8404e-05, 4.0380e-01, 3.8327e-01, 1.4722e+00, 1.4928e+00, 4.1505e-06,\n",
      "        4.7547e-05, 3.5267e-01, 1.5236e+00, 3.2132e-01, 1.5555e+00, 4.1602e-01,\n",
      "        9.3956e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.6689, 126.4256, 142.1954, 150.3894,   4.6159,   4.6163,   4.6163,\n",
      "        211.2155, 211.2155, 211.2155,   4.6151,   4.6164, 211.2155, 211.2155,\n",
      "        211.2155, 211.2155, 211.2155,  30.8307,  30.8307,   4.6170, 211.2155,\n",
      "        211.2155, 211.2155, 211.2155, 211.2155,  30.8307,  30.8307, 211.2155,\n",
      "         30.8307,  30.8307,   5.2026, 211.2155, 211.2155, 211.2155, 211.2155,\n",
      "        211.2155,  30.8307,  30.8307, 211.2155,  30.8307,  30.8307,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 211.2155,   5.2026,   5.2025, 211.2155,   5.2026,\n",
      "          5.2025, 211.2155,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        211.2155, 211.2155, 211.2155, 211.2155,  30.8307,  30.8307,  30.8307,\n",
      "         30.8307, 211.2155, 211.2155, 211.2155,  30.8307,  30.8307,  30.8307,\n",
      "         30.8307,   5.2026,  30.8307,  30.8307,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 217 was 93.9%\n",
      "tensor([3.3016e-08, 3.5176e-06, 3.0002e-06, 2.6475e-06, 2.4908e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8355e-06, 4.6454e-06, 4.5212e-06,\n",
      "        1.0220e-04, 7.3584e-05, 7.2553e-05, 4.4482e-06, 4.3221e-06, 4.8339e-05,\n",
      "        4.7479e-05, 4.0231e-01, 3.8195e-01, 1.4672e+00, 1.4877e+00, 4.1343e-06,\n",
      "        4.6634e-05, 3.5163e-01, 1.5183e+00, 3.2018e-01, 1.5502e+00, 4.1455e-01,\n",
      "        9.3976e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.8637, 126.6560, 142.4528, 150.6437,   4.6124,   4.6124,   4.6142,\n",
      "        211.6614, 211.6614, 211.6614,   4.6139,   4.6118, 211.6614, 211.6614,\n",
      "        211.6614, 211.6614, 211.6614,  30.9107,  30.9107,   4.6110, 211.6614,\n",
      "        211.6614, 211.6614, 211.6614, 211.6614,  30.9107,  30.9107, 211.6614,\n",
      "         30.9107,  30.9107,   5.2026, 211.6614, 211.6614, 211.6614, 211.6614,\n",
      "        211.6614,  30.9107,  30.9107, 211.6614,  30.9107,  30.9107,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 211.6614,   5.2026,   5.2025, 211.6614,   5.2026,\n",
      "          5.2025, 211.6614,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        211.6614, 211.6614, 211.6614, 211.6614,  30.9107,  30.9107,  30.9107,\n",
      "         30.9107, 211.6614, 211.6614, 211.6614,  30.9107,  30.9107,  30.9107,\n",
      "         30.9107,   5.2026,  30.9107,  30.9107,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 218 was 93.9%\n",
      "tensor([0.0000e+00, 3.5015e-06, 2.9860e-06, 2.6342e-06, 2.4778e-06, 6.1296e-09,\n",
      "        4.4883e-09, 3.7725e-09, 3.6648e-09, 4.8213e-06, 4.6317e-06, 4.5042e-06,\n",
      "        1.0056e-04, 7.2334e-05, 7.1237e-05, 4.4304e-06, 4.3098e-06, 4.7420e-05,\n",
      "        4.6641e-05, 4.0104e-01, 3.8075e-01, 1.4625e+00, 1.4828e+00, 4.1236e-06,\n",
      "        4.5830e-05, 3.5045e-01, 1.5134e+00, 3.1908e-01, 1.5451e+00, 4.1319e-01,\n",
      "        9.3996e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.0585, 126.8860, 142.7097, 150.8975,   4.6071,   4.6105,   4.6078,\n",
      "        212.1070, 212.1070, 212.1070,   4.6092,   4.6098, 212.1070, 212.1070,\n",
      "        212.1070, 212.1070, 212.1070,  30.9907,  30.9907,   4.6096, 212.1070,\n",
      "        212.1070, 212.1070, 212.1070, 212.1070,  30.9907,  30.9907, 212.1070,\n",
      "         30.9907,  30.9907,   5.2026, 212.1070, 212.1070, 212.1070, 212.1070,\n",
      "        212.1070,  30.9907,  30.9907, 212.1070,  30.9907,  30.9907,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 212.1070,   5.2026,   5.2025, 212.1070,   5.2026,\n",
      "          5.2025, 212.1070,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        212.1070, 212.1070, 212.1070, 212.1070,  30.9907,  30.9907,  30.9907,\n",
      "         30.9907, 212.1070, 212.1070, 212.1070,  30.9907,  30.9907,  30.9907,\n",
      "         30.9907,   5.2026,  30.9907,  30.9907,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 219 was 94.0%\n",
      "tensor([0.0000e+00, 3.4923e-06, 2.9781e-06, 2.6277e-06, 2.4717e-06, 6.0434e-09,\n",
      "        4.4237e-09, 3.7174e-09, 3.6128e-09, 4.8055e-06, 4.6136e-06, 4.4927e-06,\n",
      "        9.8730e-05, 7.0936e-05, 7.0010e-05, 4.4184e-06, 4.2919e-06, 4.6562e-05,\n",
      "        4.5729e-05, 3.9967e-01, 3.7936e-01, 1.4576e+00, 1.4779e+00, 4.1083e-06,\n",
      "        4.4977e-05, 3.4935e-01, 1.5082e+00, 3.1810e-01, 1.5399e+00, 4.1181e-01,\n",
      "        9.4016e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.2536, 127.1157, 142.9664, 151.1501,   4.6045,   4.6039,   4.6057,\n",
      "        212.5524, 212.5524, 212.5524,   4.6071,   4.6053, 212.5524, 212.5524,\n",
      "        212.5524, 212.5524, 212.5524,  31.0706,  31.0706,   4.6059, 212.5524,\n",
      "        212.5524, 212.5524, 212.5524, 212.5524,  31.0706,  31.0706, 212.5524,\n",
      "         31.0706,  31.0706,   5.2026, 212.5524, 212.5524, 212.5524, 212.5524,\n",
      "        212.5524,  31.0706,  31.0706, 212.5524,  31.0706,  31.0706,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 212.5524,   5.2026,   5.2025, 212.5524,   5.2026,\n",
      "          5.2025, 212.5524,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        212.5524, 212.5524, 212.5524, 212.5524,  31.0706,  31.0706,  31.0706,\n",
      "         31.0706, 212.5524, 212.5524, 212.5524,  31.0706,  31.0706,  31.0706,\n",
      "         31.0706,   5.2026,  31.0706,  31.0706,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 220 was 94.0%\n",
      "tensor([0.0000e+00, 3.4828e-06, 2.9704e-06, 2.6207e-06, 2.4655e-06, 5.9620e-09,\n",
      "        4.3623e-09, 3.6655e-09, 3.5624e-09, 4.7880e-06, 4.6009e-06, 4.4750e-06,\n",
      "        9.7012e-05, 6.9725e-05, 6.8720e-05, 4.4008e-06, 4.2803e-06, 4.5662e-05,\n",
      "        4.4920e-05, 3.9827e-01, 3.7814e-01, 1.4528e+00, 1.4730e+00, 4.0945e-06,\n",
      "        4.4157e-05, 3.4811e-01, 1.5032e+00, 3.1710e-01, 1.5347e+00, 4.1043e-01,\n",
      "        9.4036e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.4487, 127.3450, 143.2225, 151.4023,   4.6009,   4.6027,   4.6019,\n",
      "        212.9974, 212.9974, 212.9974,   4.6006,   4.6032, 212.9974, 212.9974,\n",
      "        212.9974, 212.9974, 212.9974,  31.1506,  31.1506,   4.6015, 212.9974,\n",
      "        212.9974, 212.9974, 212.9974, 212.9974,  31.1506,  31.1506, 212.9974,\n",
      "         31.1506,  31.1506,   5.2026, 212.9974, 212.9974, 212.9974, 212.9974,\n",
      "        212.9974,  31.1506,  31.1506, 212.9974,  31.1506,  31.1506,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 212.9974,   5.2026,   5.2025, 212.9974,   5.2026,\n",
      "          5.2025, 212.9974,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        212.9974, 212.9974, 212.9974, 212.9974,  31.1506,  31.1506,  31.1506,\n",
      "         31.1506, 212.9974, 212.9974, 212.9974,  31.1506,  31.1506,  31.1506,\n",
      "         31.1506,   5.2026,  31.1506,  31.1506,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 221 was 94.0%\n",
      "tensor([0.0000e+00, 3.4741e-06, 2.9626e-06, 2.6137e-06, 2.4597e-06, 5.8808e-09,\n",
      "        4.3002e-09, 3.6127e-09, 3.5121e-09, 4.7721e-06, 4.5811e-06, 4.4621e-06,\n",
      "        9.5318e-05, 6.8408e-05, 6.7546e-05, 4.3891e-06, 4.2638e-06, 4.4823e-05,\n",
      "        4.4027e-05, 3.9684e-01, 3.7699e-01, 1.4480e+00, 1.4680e+00, 4.0816e-06,\n",
      "        4.3347e-05, 3.4700e-01, 1.4982e+00, 3.1599e-01, 1.5296e+00, 4.0904e-01,\n",
      "        9.4056e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.6442, 127.5739, 143.4781, 151.6536,   4.5974,   4.5980,   4.5982,\n",
      "        213.4422, 213.4422, 213.4422,   4.5994,   4.5969, 213.4422, 213.4422,\n",
      "        213.4422, 213.4422, 213.4422,  31.2306,  31.2306,   4.5994, 213.4422,\n",
      "        213.4422, 213.4422, 213.4422, 213.4422,  31.2306,  31.2306, 213.4422,\n",
      "         31.2306,  31.2306,   5.2026, 213.4422, 213.4422, 213.4422, 213.4422,\n",
      "        213.4422,  31.2306,  31.2306, 213.4422,  31.2306,  31.2306,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 213.4422,   5.2026,   5.2025, 213.4422,   5.2026,\n",
      "          5.2025, 213.4422,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        213.4422, 213.4422, 213.4422, 213.4422,  31.2306,  31.2306,  31.2306,\n",
      "         31.2306, 213.4422, 213.4422, 213.4422,  31.2306,  31.2306,  31.2306,\n",
      "         31.2306,   5.2026,  31.2306,  31.2306,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 222 was 94.0%\n",
      "tensor([3.0506e-08, 3.4718e-06, 2.9610e-06, 2.6133e-06, 2.4598e-06, 1.6544e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7545e-06, 4.5688e-06, 4.4455e-06,\n",
      "        9.3596e-05, 6.7218e-05, 6.6301e-05, 4.3721e-06, 4.2521e-06, 4.3954e-05,\n",
      "        4.3247e-05, 3.9555e-01, 3.7558e-01, 1.4432e+00, 1.4632e+00, 4.0667e-06,\n",
      "        4.2543e-05, 3.4588e-01, 1.4932e+00, 3.1501e-01, 1.5244e+00, 4.0768e-01,\n",
      "        9.4076e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.8399, 127.8023, 143.7331, 151.9039,   4.5939,   4.5958,   4.5943,\n",
      "        213.8868, 213.8868, 213.8868,   4.5945,   4.5956, 213.8868, 213.8868,\n",
      "        213.8868, 213.8868, 213.8868,  31.3105,  31.3105,   4.5932, 213.8868,\n",
      "        213.8868, 213.8868, 213.8868, 213.8868,  31.3105,  31.3105, 213.8868,\n",
      "         31.3105,  31.3105,   5.2026, 213.8868, 213.8868, 213.8868, 213.8868,\n",
      "        213.8868,  31.3105,  31.3105, 213.8868,  31.3105,  31.3105,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 213.8868,   5.2026,   5.2025, 213.8868,   5.2026,\n",
      "          5.2025, 213.8868,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        213.8868, 213.8868, 213.8868, 213.8868,  31.3105,  31.3105,  31.3105,\n",
      "         31.3105, 213.8868, 213.8868, 213.8868,  31.3105,  31.3105,  31.3105,\n",
      "         31.3105,   5.2026,  31.3105,  31.3105,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 223 was 94.0%\n",
      "tensor([3.0038e-08, 3.4631e-06, 2.9534e-06, 2.6064e-06, 2.4538e-06, 4.1359e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7396e-06, 4.5505e-06, 4.4324e-06,\n",
      "        9.2038e-05, 6.5974e-05, 6.5161e-05, 4.3588e-06, 4.2356e-06, 4.3160e-05,\n",
      "        4.2420e-05, 3.9421e-01, 3.7446e-01, 1.4384e+00, 1.4583e+00, 4.0554e-06,\n",
      "        4.1793e-05, 3.4471e-01, 1.4882e+00, 3.1390e-01, 1.5194e+00, 4.0630e-01,\n",
      "        9.4095e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.0343, 128.0313, 143.9882, 152.1557,   4.5913,   4.5892,   4.5914,\n",
      "        214.3310, 214.3310, 214.3310,   4.5907,   4.5910, 214.3310, 214.3310,\n",
      "        214.3310, 214.3310, 214.3310,  31.3904,  31.3904,   4.5918, 214.3310,\n",
      "        214.3310, 214.3310, 214.3310, 214.3310,  31.3904,  31.3904, 214.3310,\n",
      "         31.3904,  31.3904,   5.2026, 214.3310, 214.3310, 214.3310, 214.3310,\n",
      "        214.3310,  31.3904,  31.3904, 214.3310,  31.3904,  31.3904,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 214.3310,   5.2026,   5.2025, 214.3310,   5.2026,\n",
      "          5.2025, 214.3310,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        214.3310, 214.3310, 214.3310, 214.3310,  31.3904,  31.3904,  31.3904,\n",
      "         31.3904, 214.3310, 214.3310, 214.3310,  31.3904,  31.3904,  31.3904,\n",
      "         31.3904,   5.2026,  31.3904,  31.3904,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 224 was 94.1%\n",
      "tensor([3.3087e-24, 3.4469e-06, 2.9393e-06, 2.5934e-06, 2.4415e-06, 5.6463e-09,\n",
      "        4.1241e-09, 3.4634e-09, 3.3688e-09, 4.7209e-06, 4.5383e-06, 4.4166e-06,\n",
      "        9.0393e-05, 6.4853e-05, 6.4010e-05, 4.3433e-06, 4.2234e-06, 4.2357e-05,\n",
      "        4.1684e-05, 3.9276e-01, 3.7323e-01, 1.4338e+00, 1.4534e+00, 4.0396e-06,\n",
      "        4.1023e-05, 3.4360e-01, 1.4832e+00, 3.1290e-01, 1.5143e+00, 4.0493e-01,\n",
      "        9.4115e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.2289, 128.2599, 144.2426, 152.4069,   4.5859,   4.5880,   4.5866,\n",
      "        214.7751, 214.7751, 214.7751,   4.5886,   4.5889, 214.7751, 214.7751,\n",
      "        214.7751, 214.7751, 214.7751,  31.4704,  31.4704,   4.5856, 214.7751,\n",
      "        214.7751, 214.7751, 214.7751, 214.7751,  31.4704,  31.4704, 214.7751,\n",
      "         31.4704,  31.4704,   5.2026, 214.7751, 214.7751, 214.7751, 214.7751,\n",
      "        214.7751,  31.4704,  31.4704, 214.7751,  31.4704,  31.4704,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 214.7751,   5.2026,   5.2025, 214.7751,   5.2026,\n",
      "          5.2025, 214.7751,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        214.7751, 214.7751, 214.7751, 214.7751,  31.4704,  31.4704,  31.4704,\n",
      "         31.4704, 214.7751, 214.7751, 214.7751,  31.4704,  31.4704,  31.4704,\n",
      "         31.4704,   5.2026,  31.4704,  31.4704,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 225 was 94.1%\n",
      "tensor([2.3161e-23, 3.4382e-06, 2.9323e-06, 2.5870e-06, 2.4356e-06, 5.5731e-09,\n",
      "        4.0695e-09, 3.4167e-09, 3.3238e-09, 4.7087e-06, 4.5204e-06, 4.4030e-06,\n",
      "        8.8931e-05, 6.3691e-05, 6.2909e-05, 4.3288e-06, 4.2078e-06, 4.1599e-05,\n",
      "        4.0912e-05, 3.9153e-01, 3.7199e-01, 1.4290e+00, 1.4486e+00, 4.0291e-06,\n",
      "        4.0335e-05, 3.4238e-01, 1.4784e+00, 3.1194e-01, 1.5093e+00, 4.0362e-01,\n",
      "        9.4134e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.4220, 128.4893, 144.4990, 152.6580,   4.5833,   4.5841,   4.5837,\n",
      "        215.2188, 215.2188, 215.2188,   4.5838,   4.5825, 215.2188, 215.2188,\n",
      "        215.2188, 215.2188, 215.2188,  31.5503,  31.5503,   4.5842, 215.2188,\n",
      "        215.2188, 215.2188, 215.2188, 215.2188,  31.5503,  31.5503, 215.2188,\n",
      "         31.5503,  31.5503,   5.2026, 215.2188, 215.2188, 215.2188, 215.2188,\n",
      "        215.2188,  31.5503,  31.5503, 215.2188,  31.5503,  31.5503,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 215.2188,   5.2026,   5.2025, 215.2188,   5.2026,\n",
      "          5.2025, 215.2188,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        215.2188, 215.2188, 215.2188, 215.2188,  31.5503,  31.5503,  31.5503,\n",
      "         31.5503, 215.2188, 215.2188, 215.2188,  31.5503,  31.5503,  31.5503,\n",
      "         31.5503,   5.2026,  31.5503,  31.5503,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 226 was 94.1%\n",
      "tensor([0.0000e+00, 3.4290e-06, 2.9238e-06, 2.5800e-06, 2.4292e-06, 5.4942e-09,\n",
      "        4.0098e-09, 3.3676e-09, 3.2767e-09, 4.6893e-06, 4.5055e-06, 4.3866e-06,\n",
      "        8.7249e-05, 6.2543e-05, 6.1759e-05, 4.3136e-06, 4.1954e-06, 4.0789e-05,\n",
      "        4.0154e-05, 3.9012e-01, 3.7067e-01, 1.4242e+00, 1.4437e+00, 4.0130e-06,\n",
      "        3.9580e-05, 3.4135e-01, 1.4733e+00, 3.1081e-01, 1.5041e+00, 4.0222e-01,\n",
      "        9.4154e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.6158, 128.7180, 144.7555, 152.9079,   4.5799,   4.5791,   4.5807,\n",
      "        215.6623, 215.6623, 215.6623,   4.5807,   4.5812, 215.6623, 215.6623,\n",
      "        215.6623, 215.6623, 215.6623,  31.6302,  31.6302,   4.5780, 215.6623,\n",
      "        215.6623, 215.6623, 215.6623, 215.6623,  31.6302,  31.6302, 215.6623,\n",
      "         31.6302,  31.6302,   5.2026, 215.6623, 215.6623, 215.6623, 215.6623,\n",
      "        215.6623,  31.6302,  31.6302, 215.6623,  31.6302,  31.6302,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 215.6623,   5.2026,   5.2025, 215.6623,   5.2026,\n",
      "          5.2025, 215.6623,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        215.6623, 215.6623, 215.6623, 215.6623,  31.6302,  31.6302,  31.6302,\n",
      "         31.6302, 215.6623, 215.6623, 215.6623,  31.6302,  31.6302,  31.6302,\n",
      "         31.6302,   5.2026,  31.6302,  31.6302,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 227 was 94.1%\n",
      "tensor([1.6544e-23, 3.4212e-06, 2.9175e-06, 2.5739e-06, 2.4243e-06, 5.5257e-09,\n",
      "        4.0358e-09, 3.3887e-09, 3.2969e-09, 4.6752e-06, 4.4916e-06, 4.3722e-06,\n",
      "        8.7450e-05, 6.2665e-05, 6.1864e-05, 4.2989e-06, 4.1812e-06, 4.0921e-05,\n",
      "        4.0276e-05, 3.8879e-01, 3.6962e-01, 1.4194e+00, 1.4386e+00, 4.0025e-06,\n",
      "        3.9684e-05, 3.4014e-01, 1.4683e+00, 3.0984e-01, 1.4990e+00, 4.0070e-01,\n",
      "        9.4174e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.8083, 128.9468, 145.0109, 153.1597,   4.5762,   4.5771,   4.5760,\n",
      "        216.1055, 216.1055, 216.1055,   4.5768,   4.5747, 216.1055, 216.1055,\n",
      "        216.1055, 216.1055, 216.1055,  31.7101,  31.7101,   4.5766, 216.1055,\n",
      "        216.1055, 216.1055, 216.1055, 216.1055,  31.7101,  31.7101, 216.1055,\n",
      "         31.7101,  31.7101,   5.2026, 216.1055, 216.1055, 216.1055, 216.1055,\n",
      "        216.1055,  31.7101,  31.7101, 216.1055,  31.7101,  31.7101,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 216.1055,   5.2026,   5.2025, 216.1055,   5.2026,\n",
      "          5.2025, 216.1055,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        216.1055, 216.1055, 216.1055, 216.1055,  31.7101,  31.7101,  31.7101,\n",
      "         31.7101, 216.1055, 216.1055, 216.1055,  31.7101,  31.7101,  31.7101,\n",
      "         31.7101,   5.2026,  31.7101,  31.7101,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 228 was 94.1%\n",
      "tensor([3.9705e-23, 3.4124e-06, 2.9095e-06, 2.5675e-06, 2.4180e-06, 5.4596e-09,\n",
      "        3.9859e-09, 3.3474e-09, 3.2570e-09, 4.6578e-06, 4.4753e-06, 4.3583e-06,\n",
      "        8.6014e-05, 6.1657e-05, 6.0880e-05, 4.2848e-06, 4.1680e-06, 4.0241e-05,\n",
      "        3.9605e-05, 3.8751e-01, 3.6821e-01, 1.4146e+00, 1.4339e+00, 3.9873e-06,\n",
      "        3.9032e-05, 3.3912e-01, 1.4632e+00, 3.0877e-01, 1.4939e+00, 3.9932e-01,\n",
      "        9.4194e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.0040, 129.1743, 145.2638, 153.4063,   4.5717,   4.5704,   4.5739,\n",
      "        216.5485, 216.5485, 216.5485,   4.5721,   4.5734, 216.5485, 216.5485,\n",
      "        216.5485, 216.5485, 216.5485,  31.7900,  31.7900,   4.5736, 216.5485,\n",
      "        216.5485, 216.5485, 216.5485, 216.5485,  31.7900,  31.7900, 216.5485,\n",
      "         31.7900,  31.7900,   5.2026, 216.5485, 216.5485, 216.5485, 216.5485,\n",
      "        216.5485,  31.7900,  31.7900, 216.5485,  31.7900,  31.7900,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 216.5485,   5.2026,   5.2025, 216.5485,   5.2026,\n",
      "          5.2025, 216.5485,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        216.5485, 216.5485, 216.5485, 216.5485,  31.7900,  31.7900,  31.7900,\n",
      "         31.7900, 216.5485, 216.5485, 216.5485,  31.7900,  31.7900,  31.7900,\n",
      "         31.7900,   5.2026,  31.7900,  31.7900,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 229 was 94.2%\n",
      "tensor([2.7930e-08, 3.4100e-06, 2.9077e-06, 2.5662e-06, 2.4187e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6426e-06, 4.4619e-06, 4.3440e-06,\n",
      "        8.4454e-05, 6.0511e-05, 5.9737e-05, 4.2697e-06, 4.1545e-06, 3.9459e-05,\n",
      "        3.8854e-05, 3.8596e-01, 3.6717e-01, 1.4102e+00, 1.4291e+00, 3.9746e-06,\n",
      "        3.8302e-05, 3.3804e-01, 1.4584e+00, 3.0783e-01, 1.4890e+00, 3.9805e-01,\n",
      "        9.4213e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.2028, 129.4002, 145.5144, 153.6478,   4.5682,   4.5692,   4.5673,\n",
      "        216.9913, 216.9913, 216.9913,   4.5690,   4.5704, 216.9913, 216.9913,\n",
      "        216.9913, 216.9913, 216.9913,  31.8699,  31.8699,   4.5691, 216.9913,\n",
      "        216.9913, 216.9913, 216.9913, 216.9913,  31.8699,  31.8699, 216.9913,\n",
      "         31.8699,  31.8699,   5.2026, 216.9913, 216.9913, 216.9913, 216.9913,\n",
      "        216.9913,  31.8699,  31.8699, 216.9913,  31.8699,  31.8699,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 216.9913,   5.2026,   5.2025, 216.9913,   5.2026,\n",
      "          5.2025, 216.9913,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        216.9913, 216.9913, 216.9913, 216.9913,  31.8699,  31.8699,  31.8699,\n",
      "         31.8699, 216.9913, 216.9913, 216.9913,  31.8699,  31.8699,  31.8699,\n",
      "         31.8699,   5.2026,  31.8699,  31.8699,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 230 was 94.2%\n",
      "tensor([1.5063e-06, 3.0641e-06, 2.3547e-06, 5.9292e-21, 1.4674e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6272e-06, 4.4440e-06, 4.3309e-06,\n",
      "        8.4756e-05, 6.0772e-05, 6.0084e-05, 4.2561e-06, 4.1380e-06, 3.9743e-05,\n",
      "        3.9110e-05, 3.8472e-01, 3.6584e-01, 1.4058e+00, 1.4246e+00, 3.9612e-06,\n",
      "        3.8603e-05, 3.3678e-01, 1.4538e+00, 3.0682e-01, 1.4838e+00, 3.9653e-01,\n",
      "        9.4232e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.6681, 131.2108, 147.2973, 157.0333,   4.5436,   4.5279,   4.5453,\n",
      "        217.4338, 217.4338, 217.4338,   4.5347,   4.5294, 217.4338, 217.4338,\n",
      "        217.4338, 217.4338, 217.4338,  31.9498,  31.9498,   4.5373, 217.4338,\n",
      "        217.4338, 217.4338, 217.4338, 217.4338,  31.9498,  31.9498, 217.4338,\n",
      "         31.9498,  31.9498,   5.2026, 217.4338, 217.4338, 217.4338, 217.4338,\n",
      "        217.4338,  31.9498,  31.9498, 217.4338,  31.9498,  31.9498,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 217.4338,   5.2026,   5.2025, 217.4338,   5.2026,\n",
      "          5.2025, 217.4338,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        217.4338, 217.4338, 217.4338, 217.4338,  31.9498,  31.9498,  31.9498,\n",
      "         31.9498, 217.4338, 217.4338, 217.4338,  31.9498,  31.9498,  31.9498,\n",
      "         31.9498,   5.2026,  31.9498,  31.9498,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 231 was 94.3%\n",
      "tensor([0.0000e+00, 3.4647e-06, 2.8409e-06, 2.5109e-06, 2.3418e-06, 5.0822e-09,\n",
      "        3.4366e-09, 2.8730e-09, 2.7788e-09, 4.5621e-06, 4.4054e-06, 4.2540e-06,\n",
      "        7.8293e-05, 5.6280e-05, 5.5242e-05, 4.1622e-06, 4.0363e-06, 3.2896e-05,\n",
      "        3.2252e-05, 3.8117e-01, 3.5977e-01, 1.3713e+00, 1.3927e+00, 3.8538e-06,\n",
      "        3.1620e-05, 3.3152e-01, 1.4211e+00, 2.9446e-01, 1.4587e+00, 3.8630e-01,\n",
      "        9.4356e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.8226, 131.4108, 147.5179, 157.1790,   4.5383,   4.5264,   4.5384,\n",
      "        217.8760, 217.8760, 217.8760,   4.5315,   4.5278, 217.8760, 217.8760,\n",
      "        217.8760, 217.8760, 217.8760,  32.0297,  32.0297,   4.5336, 217.8760,\n",
      "        217.8760, 217.8760, 217.8760, 217.8760,  32.0297,  32.0297, 217.8760,\n",
      "         32.0297,  32.0297,   5.2026, 217.8760, 217.8760, 217.8760, 217.8760,\n",
      "        217.8760,  32.0297,  32.0297, 217.8760,  32.0297,  32.0297,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 217.8760,   5.2026,   5.2025, 217.8760,   5.2026,\n",
      "          5.2025, 217.8760,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        217.8760, 217.8760, 217.8760, 217.8760,  32.0297,  32.0297,  32.0297,\n",
      "         32.0297, 217.8760, 217.8760, 217.8760,  32.0297,  32.0297,  32.0297,\n",
      "         32.0297,   5.2026,  32.0297,  32.0297,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 232 was 94.3%\n",
      "tensor([6.3382e-07, 6.2636e-06, 2.5061e-06, 0.0000e+00, 2.2472e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5469e-06, 4.3899e-06, 4.2422e-06,\n",
      "        7.7353e-05, 5.5646e-05, 5.4711e-05, 4.1487e-06, 4.0208e-06, 3.2556e-05,\n",
      "        3.1934e-05, 3.7992e-01, 3.5856e-01, 1.3668e+00, 1.3882e+00, 3.8415e-06,\n",
      "        3.1338e-05, 3.3048e-01, 1.4166e+00, 2.9375e-01, 1.4538e+00, 3.8502e-01,\n",
      "        9.4374e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([108.9813, 131.6123, 147.7358, 157.3236,   4.5351,   4.5219,   4.5318,\n",
      "        218.3181, 218.3181, 218.3181,   4.5285,   4.5266, 218.3181, 218.3181,\n",
      "        218.3181, 218.3181, 218.3181,  32.1095,  32.1095,   4.5299, 218.3181,\n",
      "        218.3181, 218.3181, 218.3181, 218.3181,  32.1095,  32.1095, 218.3181,\n",
      "         32.1095,  32.1095,   5.2026, 218.3181, 218.3181, 218.3181, 218.3181,\n",
      "        218.3181,  32.1095,  32.1095, 218.3181,  32.1095,  32.1095,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 218.3181,   5.2026,   5.2025, 218.3181,   5.2026,\n",
      "          5.2025, 218.3181,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        218.3181, 218.3181, 218.3181, 218.3181,  32.1095,  32.1095,  32.1095,\n",
      "         32.1095, 218.3181, 218.3181, 218.3181,  32.1095,  32.1095,  32.1095,\n",
      "         32.1095,   5.2026,  32.1095,  32.1095,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 233 was 94.3%\n",
      "tensor([1.9852e-23, 3.4471e-06, 2.8274e-06, 2.4990e-06, 2.3329e-06, 4.9982e-09,\n",
      "        3.3773e-09, 2.8246e-09, 2.7350e-09, 4.5324e-06, 4.3729e-06, 4.2326e-06,\n",
      "        7.6315e-05, 5.4878e-05, 5.3981e-05, 4.1371e-06, 4.0085e-06, 3.2083e-05,\n",
      "        3.1443e-05, 3.7878e-01, 3.5758e-01, 1.3631e+00, 1.3843e+00, 3.8297e-06,\n",
      "        3.0853e-05, 3.2941e-01, 1.4127e+00, 2.9304e-01, 1.4496e+00, 3.8389e-01,\n",
      "        9.4390e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.1360, 131.8125, 147.9568, 157.4692,   4.5279,   4.5203,   4.5267,\n",
      "        218.7599, 218.7599, 218.7599,   4.5252,   4.5250, 218.7599, 218.7599,\n",
      "        218.7599, 218.7599, 218.7599,  32.1894,  32.1894,   4.5262, 218.7599,\n",
      "        218.7599, 218.7599, 218.7599, 218.7599,  32.1894,  32.1894, 218.7599,\n",
      "         32.1894,  32.1894,   5.2026, 218.7599, 218.7599, 218.7599, 218.7599,\n",
      "        218.7599,  32.1894,  32.1894, 218.7599,  32.1894,  32.1894,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 218.7599,   5.2026,   5.2025, 218.7599,   5.2026,\n",
      "          5.2025, 218.7599,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        218.7599, 218.7599, 218.7599, 218.7599,  32.1894,  32.1894,  32.1894,\n",
      "         32.1894, 218.7599, 218.7599, 218.7599,  32.1894,  32.1894,  32.1894,\n",
      "         32.1894,   5.2026,  32.1894,  32.1894,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 234 was 94.4%\n",
      "tensor([2.4938e-08, 3.4438e-06, 2.8249e-06, 2.4978e-06, 2.3337e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5195e-06, 4.3543e-06, 4.2193e-06,\n",
      "        7.5035e-05, 5.3846e-05, 5.2993e-05, 4.1221e-06, 3.9933e-06, 3.1440e-05,\n",
      "        3.0804e-05, 3.7740e-01, 3.5638e-01, 1.3590e+00, 1.3801e+00, 3.8195e-06,\n",
      "        3.0251e-05, 3.2853e-01, 1.4081e+00, 2.9235e-01, 1.4449e+00, 3.8262e-01,\n",
      "        9.4408e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.2907, 132.0126, 148.1777, 157.6149,   4.5206,   4.5188,   4.5216,\n",
      "        219.2014, 219.2014, 219.2014,   4.5219,   4.5234, 219.2014, 219.2014,\n",
      "        219.2014, 219.2014, 219.2014,  32.2692,  32.2692,   4.5226, 219.2014,\n",
      "        219.2014, 219.2014, 219.2014, 219.2014,  32.2692,  32.2692, 219.2014,\n",
      "         32.2692,  32.2692,   5.2026, 219.2014, 219.2014, 219.2014, 219.2014,\n",
      "        219.2014,  32.2692,  32.2692, 219.2014,  32.2692,  32.2692,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 219.2014,   5.2026,   5.2025, 219.2014,   5.2026,\n",
      "          5.2025, 219.2014,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        219.2014, 219.2014, 219.2014, 219.2014,  32.2692,  32.2692,  32.2692,\n",
      "         32.2692, 219.2014, 219.2014, 219.2014,  32.2692,  32.2692,  32.2692,\n",
      "         32.2692,   5.2026,  32.2692,  32.2692,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 235 was 94.4%\n",
      "tensor([2.6915e-08, 3.4366e-06, 2.8184e-06, 2.4921e-06, 2.3302e-06, 1.6544e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5073e-06, 4.3359e-06, 4.2071e-06,\n",
      "        7.9640e-05, 5.7703e-05, 5.7013e-05, 4.1064e-06, 3.9784e-06, 3.4268e-05,\n",
      "        3.3708e-05, 3.7587e-01, 3.5516e-01, 1.3550e+00, 1.3757e+00, 3.8089e-06,\n",
      "        3.3306e-05, 3.2749e-01, 1.4035e+00, 2.9155e-01, 1.4397e+00, 3.8133e-01,\n",
      "        9.4426e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.4464, 132.2134, 148.4019, 157.7591,   4.5172,   4.5175,   4.5184,\n",
      "        219.6427, 219.6427, 219.6427,   4.5187,   4.5168, 219.6427, 219.6427,\n",
      "        219.6427, 219.6427, 219.6427,  32.3491,  32.3491,   4.5178, 219.6427,\n",
      "        219.6427, 219.6427, 219.6427, 219.6427,  32.3491,  32.3491, 219.6427,\n",
      "         32.3491,  32.3491,   5.2026, 219.6427, 219.6427, 219.6427, 219.6427,\n",
      "        219.6427,  32.3491,  32.3491, 219.6427,  32.3491,  32.3491,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 219.6427,   5.2026,   5.2025, 219.6427,   5.2026,\n",
      "          5.2025, 219.6427,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        219.6427, 219.6427, 219.6427, 219.6427,  32.3491,  32.3491,  32.3491,\n",
      "         32.3491, 219.6427, 219.6427, 219.6427,  32.3491,  32.3491,  32.3491,\n",
      "         32.3491,   5.2026,  32.3491,  32.3491,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 236 was 94.4%\n",
      "tensor([0.0000e+00, 3.4225e-06, 2.8060e-06, 2.4810e-06, 2.3201e-06, 5.2253e-09,\n",
      "        3.5540e-09, 2.9925e-09, 2.9071e-09, 4.4932e-06, 4.3215e-06, 4.1931e-06,\n",
      "        7.8535e-05, 5.6897e-05, 5.6193e-05, 4.0933e-06, 3.9689e-06, 3.3711e-05,\n",
      "        3.3193e-05, 3.7478e-01, 3.5409e-01, 1.3510e+00, 1.3717e+00, 3.7988e-06,\n",
      "        3.2801e-05, 3.2664e-01, 1.3993e+00, 2.9065e-01, 1.4355e+00, 3.8018e-01,\n",
      "        9.4442e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.6023, 132.4142, 148.6261, 157.9033,   4.5140,   4.5151,   4.5134,\n",
      "        220.0838, 220.0838, 220.0838,   4.5119,   4.5153, 220.0838, 220.0838,\n",
      "        220.0838, 220.0838, 220.0838,  32.4289,  32.4289,   4.5139, 220.0838,\n",
      "        220.0838, 220.0838, 220.0838, 220.0838,  32.4289,  32.4289, 220.0838,\n",
      "         32.4289,  32.4289,   5.2026, 220.0838, 220.0838, 220.0838, 220.0838,\n",
      "        220.0838,  32.4289,  32.4289, 220.0838,  32.4289,  32.4289,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 220.0838,   5.2026,   5.2025, 220.0838,   5.2026,\n",
      "          5.2025, 220.0838,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        220.0838, 220.0838, 220.0838, 220.0838,  32.4289,  32.4289,  32.4289,\n",
      "         32.4289, 220.0838, 220.0838, 220.0838,  32.4289,  32.4289,  32.4289,\n",
      "         32.4289,   5.2026,  32.4289,  32.4289,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 237 was 94.4%\n",
      "tensor([0.0000e+00, 3.4150e-06, 2.7996e-06, 2.4752e-06, 2.3164e-06, 5.1738e-09,\n",
      "        3.5170e-09, 2.9602e-09, 2.8774e-09, 4.4801e-06, 4.3065e-06, 4.1850e-06,\n",
      "        7.7488e-05, 5.6060e-05, 5.5472e-05, 4.0847e-06, 3.9559e-06, 3.3236e-05,\n",
      "        3.2680e-05, 3.7355e-01, 3.5323e-01, 1.3474e+00, 1.3678e+00, 3.7892e-06,\n",
      "        3.2323e-05, 3.2580e-01, 1.3953e+00, 2.8986e-01, 1.4315e+00, 3.7911e-01,\n",
      "        9.4458e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.7582, 132.6149, 148.8501, 158.0477,   4.5087,   4.5100,   4.5121,\n",
      "        220.5247, 220.5247, 220.5247,   4.5105,   4.5087, 220.5247, 220.5247,\n",
      "        220.5247, 220.5247, 220.5247,  32.5087,  32.5087,   4.5109, 220.5247,\n",
      "        220.5247, 220.5247, 220.5247, 220.5247,  32.5087,  32.5087, 220.5247,\n",
      "         32.5087,  32.5087,   5.2026, 220.5247, 220.5247, 220.5247, 220.5247,\n",
      "        220.5247,  32.5087,  32.5087, 220.5247,  32.5087,  32.5087,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 220.5247,   5.2026,   5.2025, 220.5247,   5.2026,\n",
      "          5.2025, 220.5247,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        220.5247, 220.5247, 220.5247, 220.5247,  32.5087,  32.5087,  32.5087,\n",
      "         32.5087, 220.5247, 220.5247, 220.5247,  32.5087,  32.5087,  32.5087,\n",
      "         32.5087,   5.2026,  32.5087,  32.5087,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 238 was 94.4%\n",
      "tensor([0.0000e+00, 3.4073e-06, 2.7926e-06, 2.4694e-06, 2.3126e-06, 5.1207e-09,\n",
      "        3.4787e-09, 2.9279e-09, 2.8460e-09, 4.4674e-06, 4.2961e-06, 4.1702e-06,\n",
      "        7.6411e-05, 5.5317e-05, 5.4636e-05, 4.0689e-06, 3.9485e-06, 3.2692e-05,\n",
      "        3.2210e-05, 3.7229e-01, 3.5224e-01, 1.3438e+00, 1.3639e+00, 3.7787e-06,\n",
      "        3.1838e-05, 3.2503e-01, 1.3912e+00, 2.8906e-01, 1.4274e+00, 3.7806e-01,\n",
      "        9.4473e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([109.9142, 132.8157, 149.0742, 158.1922,   4.5054,   4.5077,   4.5053,\n",
      "        220.9654, 220.9654, 220.9654,   4.5063,   4.5073, 220.9654, 220.9654,\n",
      "        220.9654, 220.9654, 220.9654,  32.5886,  32.5886,   4.5062, 220.9654,\n",
      "        220.9654, 220.9654, 220.9654, 220.9654,  32.5886,  32.5886, 220.9654,\n",
      "         32.5886,  32.5886,   5.2026, 220.9654, 220.9654, 220.9654, 220.9654,\n",
      "        220.9654,  32.5886,  32.5886, 220.9654,  32.5886,  32.5886,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 220.9654,   5.2026,   5.2025, 220.9654,   5.2026,\n",
      "          5.2025, 220.9654,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        220.9654, 220.9654, 220.9654, 220.9654,  32.5886,  32.5886,  32.5886,\n",
      "         32.5886, 220.9654, 220.9654, 220.9654,  32.5886,  32.5886,  32.5886,\n",
      "         32.5886,   5.2026,  32.5886,  32.5886,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 239 was 94.4%\n",
      "tensor([0.0000e+00, 3.3994e-06, 2.7862e-06, 2.4637e-06, 2.3084e-06, 5.0665e-09,\n",
      "        3.4409e-09, 2.8944e-09, 2.8152e-09, 4.4538e-06, 4.2807e-06, 4.1622e-06,\n",
      "        7.5341e-05, 5.4445e-05, 5.3884e-05, 4.0585e-06, 3.9339e-06, 3.2214e-05,\n",
      "        3.1693e-05, 3.7118e-01, 3.5125e-01, 1.3399e+00, 1.3599e+00, 3.7687e-06,\n",
      "        3.1353e-05, 3.2406e-01, 1.3872e+00, 2.8830e-01, 1.4232e+00, 3.7693e-01,\n",
      "        9.4489e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.0703, 133.0165, 149.2982, 158.3368,   4.5020,   4.5007,   4.5040,\n",
      "        221.4058, 221.4058, 221.4058,   4.5023,   4.5024, 221.4058, 221.4058,\n",
      "        221.4058, 221.4058, 221.4058,  32.6684,  32.6684,   4.5039, 221.4058,\n",
      "        221.4058, 221.4058, 221.4058, 221.4058,  32.6684,  32.6684, 221.4058,\n",
      "         32.6684,  32.6684,   5.2026, 221.4058, 221.4058, 221.4058, 221.4058,\n",
      "        221.4058,  32.6684,  32.6684, 221.4058,  32.6684,  32.6684,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 221.4058,   5.2026,   5.2025, 221.4058,   5.2026,\n",
      "          5.2025, 221.4058,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        221.4058, 221.4058, 221.4058, 221.4058,  32.6684,  32.6684,  32.6684,\n",
      "         32.6684, 221.4058, 221.4058, 221.4058,  32.6684,  32.6684,  32.6684,\n",
      "         32.6684,   5.2026,  32.6684,  32.6684,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 240 was 94.5%\n",
      "tensor([0.0000e+00, 3.3914e-06, 2.7793e-06, 2.4575e-06, 2.3047e-06, 5.0068e-09,\n",
      "        3.3978e-09, 2.8581e-09, 2.7801e-09, 4.4390e-06, 4.2708e-06, 4.1490e-06,\n",
      "        7.4156e-05, 5.3631e-05, 5.3010e-05, 4.0447e-06, 3.9264e-06, 3.1647e-05,\n",
      "        3.1179e-05, 3.6981e-01, 3.5038e-01, 1.3365e+00, 1.3560e+00, 3.7574e-06,\n",
      "        3.0819e-05, 3.2325e-01, 1.3832e+00, 2.8753e-01, 1.4192e+00, 3.7589e-01,\n",
      "        9.4505e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.2268, 133.2170, 149.5219, 158.4811,   4.4985,   4.4994,   4.4971,\n",
      "        221.8460, 221.8460, 221.8460,   4.4990,   4.4993, 221.8460, 221.8460,\n",
      "        221.8460, 221.8460, 221.8460,  32.7482,  32.7482,   4.4991, 221.8460,\n",
      "        221.8460, 221.8460, 221.8460, 221.8460,  32.7482,  32.7482, 221.8460,\n",
      "         32.7482,  32.7482,   5.2026, 221.8460, 221.8460, 221.8460, 221.8460,\n",
      "        221.8460,  32.7482,  32.7482, 221.8460,  32.7482,  32.7482,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 221.8460,   5.2026,   5.2025, 221.8460,   5.2026,\n",
      "          5.2025, 221.8460,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        221.8460, 221.8460, 221.8460, 221.8460,  32.7482,  32.7482,  32.7482,\n",
      "         32.7482, 221.8460, 221.8460, 221.8460,  32.7482,  32.7482,  32.7482,\n",
      "         32.7482,   5.2026,  32.7482,  32.7482,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 241 was 94.5%\n",
      "tensor([1.3235e-23, 3.3836e-06, 2.7729e-06, 2.4519e-06, 2.3004e-06, 4.9524e-09,\n",
      "        3.3594e-09, 2.8246e-09, 2.7489e-09, 4.4258e-06, 4.2558e-06, 4.1395e-06,\n",
      "        7.3088e-05, 5.2794e-05, 5.2242e-05, 4.0331e-06, 3.9134e-06, 3.1153e-05,\n",
      "        3.0675e-05, 3.6875e-01, 3.4936e-01, 1.3326e+00, 1.3520e+00, 3.7473e-06,\n",
      "        3.0340e-05, 3.2229e-01, 1.3792e+00, 2.8674e-01, 1.4150e+00, 3.7476e-01,\n",
      "        9.4521e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.3834, 133.4176, 149.7455, 158.6254,   4.4950,   4.4923,   4.4958,\n",
      "        222.2860, 222.2860, 222.2860,   4.4966,   4.4944, 222.2860, 222.2860,\n",
      "        222.2860, 222.2860, 222.2860,  32.8280,  32.8280,   4.4952, 222.2860,\n",
      "        222.2860, 222.2860, 222.2860, 222.2860,  32.8280,  32.8280, 222.2860,\n",
      "         32.8280,  32.8280,   5.2026, 222.2860, 222.2860, 222.2860, 222.2860,\n",
      "        222.2860,  32.8280,  32.8280, 222.2860,  32.8280,  32.8280,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 222.2860,   5.2026,   5.2025, 222.2860,   5.2026,\n",
      "          5.2025, 222.2860,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        222.2860, 222.2860, 222.2860, 222.2860,  32.8280,  32.8280,  32.8280,\n",
      "         32.8280, 222.2860, 222.2860, 222.2860,  32.8280,  32.8280,  32.8280,\n",
      "         32.8280,   5.2026,  32.8280,  32.8280,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 242 was 94.5%\n",
      "tensor([2.6470e-23, 3.3761e-06, 2.7667e-06, 2.4463e-06, 2.2966e-06, 4.9017e-09,\n",
      "        3.3233e-09, 2.7935e-09, 2.7193e-09, 4.4133e-06, 4.2470e-06, 4.1257e-06,\n",
      "        7.2091e-05, 5.2073e-05, 5.1474e-05, 4.0196e-06, 3.9053e-06, 3.0650e-05,\n",
      "        3.0235e-05, 3.6757e-01, 3.4847e-01, 1.3290e+00, 1.3482e+00, 3.7380e-06,\n",
      "        2.9888e-05, 3.2141e-01, 1.3753e+00, 2.8601e-01, 1.4111e+00, 3.7373e-01,\n",
      "        9.4536e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.5400, 133.6182, 149.9691, 158.7699,   4.4905,   4.4910,   4.4908,\n",
      "        222.7258, 222.7258, 222.7258,   4.4897,   4.4930, 222.7258, 222.7258,\n",
      "        222.7258, 222.7258, 222.7258,  32.9078,  32.9078,   4.4912, 222.7258,\n",
      "        222.7258, 222.7258, 222.7258, 222.7258,  32.9078,  32.9078, 222.7258,\n",
      "         32.9078,  32.9078,   5.2026, 222.7258, 222.7258, 222.7258, 222.7258,\n",
      "        222.7258,  32.9078,  32.9078, 222.7258,  32.9078,  32.9078,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 222.7258,   5.2026,   5.2025, 222.7258,   5.2026,\n",
      "          5.2025, 222.7258,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        222.7258, 222.7258, 222.7258, 222.7258,  32.9078,  32.9078,  32.9078,\n",
      "         32.9078, 222.7258, 222.7258, 222.7258,  32.9078,  32.9078,  32.9078,\n",
      "         32.9078,   5.2026,  32.9078,  32.9078,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 243 was 94.5%\n",
      "tensor([2.4308e-08, 3.3737e-06, 2.7649e-06, 2.4449e-06, 2.2979e-06, 1.1581e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3998e-06, 4.2294e-06, 4.1167e-06,\n",
      "        7.1054e-05, 5.1253e-05, 5.0758e-05, 4.0099e-06, 3.8919e-06, 3.0187e-05,\n",
      "        2.9722e-05, 3.6624e-01, 3.4760e-01, 1.3254e+00, 1.3441e+00, 3.7275e-06,\n",
      "        2.9421e-05, 3.2053e-01, 1.3713e+00, 2.8524e-01, 1.4069e+00, 3.7266e-01,\n",
      "        9.4552e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.6967, 133.8189, 150.1927, 158.9144,   4.4871,   4.4867,   4.4885,\n",
      "        223.1654, 223.1654, 223.1654,   4.4882,   4.4862, 223.1654, 223.1654,\n",
      "        223.1654, 223.1654, 223.1654,  32.9876,  32.9876,   4.4863, 223.1654,\n",
      "        223.1654, 223.1654, 223.1654, 223.1654,  32.9876,  32.9876, 223.1654,\n",
      "         32.9876,  32.9876,   5.2026, 223.1654, 223.1654, 223.1654, 223.1654,\n",
      "        223.1654,  32.9876,  32.9876, 223.1654,  32.9876,  32.9876,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 223.1654,   5.2026,   5.2025, 223.1654,   5.2026,\n",
      "          5.2025, 223.1654,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        223.1654, 223.1654, 223.1654, 223.1654,  32.9876,  32.9876,  32.9876,\n",
      "         32.9876, 223.1654, 223.1654, 223.1654,  32.9876,  32.9876,  32.9876,\n",
      "         32.9876,   5.2026,  32.9876,  32.9876,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 244 was 94.5%\n",
      "tensor([2.4002e-08, 3.3664e-06, 2.7583e-06, 2.4394e-06, 2.2937e-06, 9.9262e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3868e-06, 4.2194e-06, 4.1028e-06,\n",
      "        7.0056e-05, 5.0545e-05, 4.9975e-05, 3.9947e-06, 3.8839e-06, 2.9682e-05,\n",
      "        2.9285e-05, 3.6517e-01, 3.4660e-01, 1.3216e+00, 1.3402e+00, 3.7182e-06,\n",
      "        2.8968e-05, 3.1971e-01, 1.3673e+00, 2.8437e-01, 1.4029e+00, 3.7155e-01,\n",
      "        9.4568e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([110.8533, 134.0197, 150.4167, 159.0595,   4.4817,   4.4846,   4.4815,\n",
      "        223.6048, 223.6048, 223.6048,   4.4832,   4.4848, 223.6048, 223.6048,\n",
      "        223.6048, 223.6048, 223.6048,  33.0673,  33.0673,   4.4841, 223.6048,\n",
      "        223.6048, 223.6048, 223.6048, 223.6048,  33.0673,  33.0673, 223.6048,\n",
      "         33.0673,  33.0673,   5.2026, 223.6048, 223.6048, 223.6048, 223.6048,\n",
      "        223.6048,  33.0673,  33.0673, 223.6048,  33.0673,  33.0673,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 223.6048,   5.2026,   5.2025, 223.6048,   5.2026,\n",
      "          5.2025, 223.6048,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        223.6048, 223.6048, 223.6048, 223.6048,  33.0673,  33.0673,  33.0673,\n",
      "         33.0673, 223.6048, 223.6048, 223.6048,  33.0673,  33.0673,  33.0673,\n",
      "         33.0673,   5.2026,  33.0673,  33.0673,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 245 was 94.5%\n",
      "tensor([0.0000e+00, 3.3529e-06, 2.7470e-06, 2.4292e-06, 2.2849e-06, 4.7465e-09,\n",
      "        3.2130e-09, 2.6982e-09, 2.6296e-09, 4.3748e-06, 4.2044e-06, 4.0956e-06,\n",
      "        6.9050e-05, 4.9746e-05, 4.9292e-05, 3.9857e-06, 3.8698e-06, 2.9247e-05,\n",
      "        2.8810e-05, 3.6397e-01, 3.4558e-01, 1.3180e+00, 1.3364e+00, 3.7077e-06,\n",
      "        2.8522e-05, 3.1888e-01, 1.3633e+00, 2.8369e-01, 1.3988e+00, 3.7050e-01,\n",
      "        9.4583e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.0100, 134.2206, 150.6409, 159.2047,   4.4781,   4.4794,   4.4802,\n",
      "        224.0440, 224.0440, 224.0440,   4.4808,   4.4780, 224.0440, 224.0440,\n",
      "        224.0440, 224.0440, 224.0440,  33.1471,  33.1471,   4.4800, 224.0440,\n",
      "        224.0440, 224.0440, 224.0440, 224.0440,  33.1471,  33.1471, 224.0440,\n",
      "         33.1471,  33.1471,   5.2026, 224.0440, 224.0440, 224.0440, 224.0440,\n",
      "        224.0440,  33.1471,  33.1471, 224.0440,  33.1471,  33.1471,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 224.0440,   5.2026,   5.2025, 224.0440,   5.2026,\n",
      "          5.2025, 224.0440,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        224.0440, 224.0440, 224.0440, 224.0440,  33.1471,  33.1471,  33.1471,\n",
      "         33.1471, 224.0440, 224.0440, 224.0440,  33.1471,  33.1471,  33.1471,\n",
      "         33.1471,   5.2026,  33.1471,  33.1471,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 246 was 94.5%\n",
      "tensor([0.0000e+00, 3.3451e-06, 2.7403e-06, 2.4234e-06, 2.2808e-06, 4.6962e-09,\n",
      "        3.1762e-09, 2.6672e-09, 2.5997e-09, 4.3610e-06, 4.1938e-06, 4.0802e-06,\n",
      "        6.8053e-05, 4.9059e-05, 4.8535e-05, 3.9712e-06, 3.8628e-06, 2.8747e-05,\n",
      "        2.8372e-05, 3.6281e-01, 3.4461e-01, 1.3143e+00, 1.3325e+00, 3.6972e-06,\n",
      "        2.8071e-05, 3.1802e-01, 1.3592e+00, 2.8288e-01, 1.3947e+00, 3.6941e-01,\n",
      "        9.4599e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.1668, 134.4215, 150.8649, 159.3499,   4.4746,   4.4770,   4.4751,\n",
      "        224.4829, 224.4829, 224.4829,   4.4738,   4.4765, 224.4829, 224.4829,\n",
      "        224.4829, 224.4829, 224.4829,  33.2269,  33.2269,   4.4760, 224.4829,\n",
      "        224.4829, 224.4829, 224.4829, 224.4829,  33.2269,  33.2269, 224.4829,\n",
      "         33.2269,  33.2269,   5.2026, 224.4829, 224.4829, 224.4829, 224.4829,\n",
      "        224.4829,  33.2269,  33.2269, 224.4829,  33.2269,  33.2269,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 224.4829,   5.2026,   5.2025, 224.4829,   5.2026,\n",
      "          5.2025, 224.4829,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        224.4829, 224.4829, 224.4829, 224.4829,  33.2269,  33.2269,  33.2269,\n",
      "         33.2269, 224.4829, 224.4829, 224.4829,  33.2269,  33.2269,  33.2269,\n",
      "         33.2269,   5.2026,  33.2269,  33.2269,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 247 was 94.6%\n",
      "tensor([0.0000e+00, 3.3376e-06, 2.7337e-06, 2.4175e-06, 2.2769e-06, 4.6427e-09,\n",
      "        3.1383e-09, 2.6343e-09, 2.5689e-09, 4.3476e-06, 4.1782e-06, 4.0722e-06,\n",
      "        6.7033e-05, 4.8253e-05, 4.7827e-05, 3.9622e-06, 3.8493e-06, 2.8293e-05,\n",
      "        2.7881e-05, 3.6157e-01, 3.4374e-01, 1.3107e+00, 1.3286e+00, 3.6873e-06,\n",
      "        2.7613e-05, 3.1719e-01, 1.3553e+00, 2.8207e-01, 1.3907e+00, 3.6836e-01,\n",
      "        9.4614e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.3239, 134.6223, 151.0884, 159.4949,   4.4710,   4.4698,   4.4728,\n",
      "        224.9217, 224.9217, 224.9217,   4.4723,   4.4716, 224.9217, 224.9217,\n",
      "        224.9217, 224.9217, 224.9217,  33.3066,  33.3066,   4.4720, 224.9217,\n",
      "        224.9217, 224.9217, 224.9217, 224.9217,  33.3066,  33.3066, 224.9217,\n",
      "         33.3066,  33.3066,   5.2026, 224.9217, 224.9217, 224.9217, 224.9217,\n",
      "        224.9217,  33.3066,  33.3066, 224.9217,  33.3066,  33.3066,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 224.9217,   5.2026,   5.2025, 224.9217,   5.2026,\n",
      "          5.2025, 224.9217,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        224.9217, 224.9217, 224.9217, 224.9217,  33.3066,  33.3066,  33.3066,\n",
      "         33.3066, 224.9217, 224.9217, 224.9217,  33.3066,  33.3066,  33.3066,\n",
      "         33.3066,   5.2026,  33.3066,  33.3066,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 248 was 94.6%\n",
      "tensor([2.6470e-23, 3.3297e-06, 2.7272e-06, 2.4116e-06, 2.2730e-06, 4.5912e-09,\n",
      "        3.1023e-09, 2.6034e-09, 2.5390e-09, 4.3339e-06, 4.1693e-06, 4.0586e-06,\n",
      "        6.6046e-05, 4.7554e-05, 4.7063e-05, 3.9465e-06, 3.8408e-06, 2.7814e-05,\n",
      "        2.7459e-05, 3.6036e-01, 3.4285e-01, 1.3071e+00, 1.3246e+00, 3.6768e-06,\n",
      "        2.7171e-05, 3.1628e-01, 1.3513e+00, 2.8131e-01, 1.3866e+00, 3.6727e-01,\n",
      "        9.4630e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.4810, 134.8230, 151.3119, 159.6399,   4.4673,   4.4685,   4.4657,\n",
      "        225.3603, 225.3603, 225.3603,   4.4673,   4.4693, 225.3603, 225.3603,\n",
      "        225.3603, 225.3603, 225.3603,  33.3864,  33.3864,   4.4679, 225.3603,\n",
      "        225.3603, 225.3603, 225.3603, 225.3603,  33.3864,  33.3864, 225.3603,\n",
      "         33.3864,  33.3864,   5.2026, 225.3603, 225.3603, 225.3603, 225.3603,\n",
      "        225.3603,  33.3864,  33.3864, 225.3603,  33.3864,  33.3864,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 225.3603,   5.2026,   5.2025, 225.3603,   5.2026,\n",
      "          5.2025, 225.3603,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        225.3603, 225.3603, 225.3603, 225.3603,  33.3864,  33.3864,  33.3864,\n",
      "         33.3864, 225.3603, 225.3603, 225.3603,  33.3864,  33.3864,  33.3864,\n",
      "         33.3864,   5.2026,  33.3864,  33.3864,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 249 was 94.6%\n",
      "tensor([0.0000e+00, 3.3220e-06, 2.7209e-06, 2.4060e-06, 2.2690e-06, 4.5413e-09,\n",
      "        3.0668e-09, 2.5727e-09, 2.5101e-09, 4.3209e-06, 4.1532e-06, 4.0509e-06,\n",
      "        6.5089e-05, 4.6801e-05, 4.6398e-05, 3.9371e-06, 3.8281e-06, 2.7390e-05,\n",
      "        2.6997e-05, 3.5922e-01, 3.4189e-01, 1.3034e+00, 1.3208e+00, 3.6670e-06,\n",
      "        2.6742e-05, 3.1538e-01, 1.3474e+00, 2.8057e-01, 1.3826e+00, 3.6622e-01,\n",
      "        9.4646e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.6382, 135.0238, 151.5353, 159.7852,   4.4627,   4.4632,   4.4644,\n",
      "        225.7987, 225.7987, 225.7987,   4.4658,   4.4624, 225.7987, 225.7987,\n",
      "        225.7987, 225.7987, 225.7987,  33.4661,  33.4661,   4.4639, 225.7987,\n",
      "        225.7987, 225.7987, 225.7987, 225.7987,  33.4661,  33.4661, 225.7987,\n",
      "         33.4661,  33.4661,   5.2026, 225.7987, 225.7987, 225.7987, 225.7987,\n",
      "        225.7987,  33.4661,  33.4661, 225.7987,  33.4661,  33.4661,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 225.7987,   5.2026,   5.2025, 225.7987,   5.2026,\n",
      "          5.2025, 225.7987,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        225.7987, 225.7987, 225.7987, 225.7987,  33.4661,  33.4661,  33.4661,\n",
      "         33.4661, 225.7987, 225.7987, 225.7987,  33.4661,  33.4661,  33.4661,\n",
      "         33.4661,   5.2026,  33.4661,  33.4661,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 250 was 94.6%\n",
      "tensor([3.9705e-23, 3.3143e-06, 2.7144e-06, 2.4006e-06, 2.2649e-06, 4.4914e-09,\n",
      "        3.0310e-09, 2.5422e-09, 2.4808e-09, 4.3085e-06, 4.1438e-06, 4.0353e-06,\n",
      "        6.4139e-05, 4.6136e-05, 4.5657e-05, 3.9222e-06, 3.8207e-06, 2.6905e-05,\n",
      "        2.6586e-05, 3.5812e-01, 3.4086e-01, 1.2997e+00, 1.3170e+00, 3.6572e-06,\n",
      "        2.6316e-05, 3.1453e-01, 1.3435e+00, 2.7981e-01, 1.3785e+00, 3.6517e-01,\n",
      "        9.4661e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.7955, 135.2247, 151.7588, 159.9305,   4.4591,   4.4608,   4.4593,\n",
      "        226.2368, 226.2368, 226.2368,   4.4587,   4.4609, 226.2368, 226.2368,\n",
      "        226.2368, 226.2368, 226.2368,  33.5459,  33.5459,   4.4598, 226.2368,\n",
      "        226.2368, 226.2368, 226.2368, 226.2368,  33.5459,  33.5459, 226.2368,\n",
      "         33.5459,  33.5459,   5.2026, 226.2368, 226.2368, 226.2368, 226.2368,\n",
      "        226.2368,  33.5459,  33.5459, 226.2368,  33.5459,  33.5459,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 226.2368,   5.2026,   5.2025, 226.2368,   5.2026,\n",
      "          5.2025, 226.2368,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        226.2368, 226.2368, 226.2368, 226.2368,  33.5459,  33.5459,  33.5459,\n",
      "         33.5459, 226.2368, 226.2368, 226.2368,  33.5459,  33.5459,  33.5459,\n",
      "         33.5459,   5.2026,  33.5459,  33.5459,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 251 was 94.6%\n",
      "tensor([2.1896e-08, 3.3120e-06, 2.7124e-06, 2.3991e-06, 2.2657e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2947e-06, 4.1277e-06, 4.0273e-06,\n",
      "        6.3181e-05, 4.5380e-05, 4.5004e-05, 3.9133e-06, 3.8069e-06, 2.6489e-05,\n",
      "        2.6125e-05, 3.5686e-01, 3.4001e-01, 1.2961e+00, 1.3130e+00, 3.6468e-06,\n",
      "        2.5885e-05, 3.1370e-01, 1.3394e+00, 2.7898e-01, 1.3745e+00, 3.6406e-01,\n",
      "        9.4677e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([111.9528, 135.4256, 151.9828, 160.0762,   4.4554,   4.4555,   4.4570,\n",
      "        226.6748, 226.6748, 226.6748,   4.4572,   4.4540, 226.6748, 226.6748,\n",
      "        226.6748, 226.6748, 226.6748,  33.6256,  33.6256,   4.4557, 226.6748,\n",
      "        226.6748, 226.6748, 226.6748, 226.6748,  33.6256,  33.6256, 226.6748,\n",
      "         33.6256,  33.6256,   5.2026, 226.6748, 226.6748, 226.6748, 226.6748,\n",
      "        226.6748,  33.6256,  33.6256, 226.6748,  33.6256,  33.6256,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 226.6748,   5.2026,   5.2025, 226.6748,   5.2026,\n",
      "          5.2025, 226.6748,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        226.6748, 226.6748, 226.6748, 226.6748,  33.6256,  33.6256,  33.6256,\n",
      "         33.6256, 226.6748, 226.6748, 226.6748,  33.6256,  33.6256,  33.6256,\n",
      "         33.6256,   5.2026,  33.6256,  33.6256,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 252 was 94.6%\n",
      "tensor([2.1601e-08, 3.3045e-06, 2.7061e-06, 2.3936e-06, 2.2618e-06, 2.4815e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2819e-06, 4.1184e-06, 4.0134e-06,\n",
      "        6.2253e-05, 4.4724e-05, 4.4267e-05, 3.8984e-06, 3.8000e-06, 2.6017e-05,\n",
      "        2.5707e-05, 3.5576e-01, 3.3905e-01, 1.2924e+00, 1.3091e+00, 3.6371e-06,\n",
      "        2.5444e-05, 3.1285e-01, 1.3355e+00, 2.7822e-01, 1.3705e+00, 3.6299e-01,\n",
      "        9.4692e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([112.1100, 135.6265, 152.2063, 160.2223,   4.4517,   4.4531,   4.4518,\n",
      "        227.1126, 227.1126, 227.1126,   4.4501,   4.4525, 227.1126, 227.1126,\n",
      "        227.1126, 227.1126, 227.1126,  33.7053,  33.7053,   4.4516, 227.1126,\n",
      "        227.1126, 227.1126, 227.1126, 227.1126,  33.7053,  33.7053, 227.1126,\n",
      "         33.7053,  33.7053,   5.2026, 227.1126, 227.1126, 227.1126, 227.1126,\n",
      "        227.1126,  33.7053,  33.7053, 227.1126,  33.7053,  33.7053,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 227.1126,   5.2026,   5.2025, 227.1126,   5.2026,\n",
      "          5.2025, 227.1126,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        227.1126, 227.1126, 227.1126, 227.1126,  33.7053,  33.7053,  33.7053,\n",
      "         33.7053, 227.1126, 227.1126, 227.1126,  33.7053,  33.7053,  33.7053,\n",
      "         33.7053,   5.2026,  33.7053,  33.7053,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 253 was 94.7%\n",
      "tensor([2.1307e-08, 3.2968e-06, 2.6994e-06, 2.3877e-06, 2.2576e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2682e-06, 4.1030e-06, 4.0046e-06,\n",
      "        6.1295e-05, 4.3971e-05, 4.3617e-05, 3.8898e-06, 3.7860e-06, 2.5597e-05,\n",
      "        2.5256e-05, 3.5456e-01, 3.3814e-01, 1.2888e+00, 1.3052e+00, 3.6267e-06,\n",
      "        2.5022e-05, 3.1200e-01, 1.3315e+00, 2.7740e-01, 1.3665e+00, 3.6192e-01,\n",
      "        9.4708e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([112.2674, 135.8272, 152.4298, 160.3683,   4.4479,   4.4458,   4.4477,\n",
      "        227.5503, 227.5503, 227.5503,   4.4486,   4.4475, 227.5503, 227.5503,\n",
      "        227.5503, 227.5503, 227.5503,  33.7850,  33.7850,   4.4493, 227.5503,\n",
      "        227.5503, 227.5503, 227.5503, 227.5503,  33.7850,  33.7850, 227.5503,\n",
      "         33.7850,  33.7850,   5.2026, 227.5503, 227.5503, 227.5503, 227.5503,\n",
      "        227.5503,  33.7850,  33.7850, 227.5503,  33.7850,  33.7850,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 227.5503,   5.2026,   5.2025, 227.5503,   5.2026,\n",
      "          5.2025, 227.5503,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        227.5503, 227.5503, 227.5503, 227.5503,  33.7850,  33.7850,  33.7850,\n",
      "         33.7850, 227.5503, 227.5503, 227.5503,  33.7850,  33.7850,  33.7850,\n",
      "         33.7850,   5.2026,  33.7850,  33.7850,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 254 was 94.7%\n",
      "tensor([1.9852e-23, 3.2836e-06, 2.6886e-06, 2.3779e-06, 2.2492e-06, 4.2905e-09,\n",
      "        2.8886e-09, 2.4192e-09, 2.3638e-09, 4.2538e-06, 4.0943e-06, 3.9930e-06,\n",
      "        6.0342e-05, 4.3311e-05, 4.2921e-05, 3.8759e-06, 3.7774e-06, 2.5163e-05,\n",
      "        2.4860e-05, 3.5337e-01, 3.3715e-01, 1.2852e+00, 1.3014e+00, 3.6153e-06,\n",
      "        2.4597e-05, 3.1112e-01, 1.3276e+00, 2.7674e-01, 1.3624e+00, 3.6089e-01,\n",
      "        9.4723e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([112.4248, 136.0280, 152.6532, 160.5145,   4.4420,   4.4445,   4.4445,\n",
      "        227.9877, 227.9877, 227.9877,   4.4433,   4.4460, 227.9877, 227.9877,\n",
      "        227.9877, 227.9877, 227.9877,  33.8648,  33.8648,   4.4425, 227.9877,\n",
      "        227.9877, 227.9877, 227.9877, 227.9877,  33.8648,  33.8648, 227.9877,\n",
      "         33.8648,  33.8648,   5.2026, 227.9877, 227.9877, 227.9877, 227.9877,\n",
      "        227.9877,  33.8648,  33.8648, 227.9877,  33.8648,  33.8648,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 227.9877,   5.2026,   5.2025, 227.9877,   5.2026,\n",
      "          5.2025, 227.9877,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        227.9877, 227.9877, 227.9877, 227.9877,  33.8648,  33.8648,  33.8648,\n",
      "         33.8648, 227.9877, 227.9877, 227.9877,  33.8648,  33.8648,  33.8648,\n",
      "         33.8648,   5.2026,  33.8648,  33.8648,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 255 was 94.7%\n",
      "tensor([1.3235e-23, 3.2765e-06, 2.6825e-06, 2.3721e-06, 2.2457e-06, 4.2410e-09,\n",
      "        2.8533e-09, 2.3884e-09, 2.3343e-09, 4.2444e-06, 4.0779e-06, 3.9826e-06,\n",
      "        5.9469e-05, 4.2592e-05, 4.2253e-05, 3.8652e-06, 3.7650e-06, 2.4735e-05,\n",
      "        2.4408e-05, 3.5216e-01, 3.3638e-01, 1.2816e+00, 1.2975e+00, 3.6080e-06,\n",
      "        2.4196e-05, 3.1024e-01, 1.3238e+00, 2.7595e-01, 1.3584e+00, 3.5985e-01,\n",
      "        9.4738e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([112.5824, 136.2288, 152.8768, 160.6606,   4.4392,   4.4402,   4.4392,\n",
      "        228.4249, 228.4249, 228.4249,   4.4401,   4.4390, 228.4249, 228.4249,\n",
      "        228.4249, 228.4249, 228.4249,  33.9445,  33.9445,   4.4409, 228.4249,\n",
      "        228.4249, 228.4249, 228.4249, 228.4249,  33.9445,  33.9445, 228.4249,\n",
      "         33.9445,  33.9445,   5.2026, 228.4249, 228.4249, 228.4249, 228.4249,\n",
      "        228.4249,  33.9445,  33.9445, 228.4249,  33.9445,  33.9445,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 228.4249,   5.2026,   5.2025, 228.4249,   5.2026,\n",
      "          5.2025, 228.4249,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        228.4249, 228.4249, 228.4249, 228.4249,  33.9445,  33.9445,  33.9445,\n",
      "         33.9445, 228.4249, 228.4249, 228.4249,  33.9445,  33.9445,  33.9445,\n",
      "         33.9445,   5.2026,  33.9445,  33.9445,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 256 was 94.7%\n",
      "tensor([0.0000e+00, 3.2683e-06, 2.6755e-06, 2.3666e-06, 2.2412e-06, 4.1905e-09,\n",
      "        2.8174e-09, 2.3578e-09, 2.3051e-09, 4.2278e-06, 4.0669e-06, 3.9704e-06,\n",
      "        5.8499e-05, 4.1924e-05, 4.1570e-05, 3.8524e-06, 3.7556e-06, 2.4297e-05,\n",
      "        2.4005e-05, 3.5106e-01, 3.3522e-01, 1.2778e+00, 1.2937e+00, 3.5954e-06,\n",
      "        2.3762e-05, 3.0945e-01, 1.3196e+00, 2.7516e-01, 1.3543e+00, 3.5874e-01,\n",
      "        9.4754e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([112.7400, 136.4296, 153.1002, 160.8070,   4.4354,   4.4347,   4.4360,\n",
      "        228.8620, 228.8620, 228.8620,   4.4367,   4.4375, 228.8620, 228.8620,\n",
      "        228.8620, 228.8620, 228.8620,  34.0242,  34.0242,   4.4341, 228.8620,\n",
      "        228.8620, 228.8620, 228.8620, 228.8620,  34.0242,  34.0242, 228.8620,\n",
      "         34.0242,  34.0242,   5.2026, 228.8620, 228.8620, 228.8620, 228.8620,\n",
      "        228.8620,  34.0242,  34.0242, 228.8620,  34.0242,  34.0242,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 228.8620,   5.2026,   5.2025, 228.8620,   5.2026,\n",
      "          5.2025, 228.8620,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        228.8620, 228.8620, 228.8620, 228.8620,  34.0242,  34.0242,  34.0242,\n",
      "         34.0242, 228.8620, 228.8620, 228.8620,  34.0242,  34.0242,  34.0242,\n",
      "         34.0242,   5.2026,  34.0242,  34.0242,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 257 was 94.7%\n",
      "tensor([9.9262e-24, 3.2609e-06, 2.6698e-06, 2.3608e-06, 2.2375e-06, 4.1422e-09,\n",
      "        2.7834e-09, 2.3282e-09, 2.2767e-09, 4.2171e-06, 4.0547e-06, 3.9591e-06,\n",
      "        5.7644e-05, 4.1250e-05, 4.0906e-05, 3.8400e-06, 3.7448e-06, 2.3880e-05,\n",
      "        2.3591e-05, 3.4989e-01, 3.3449e-01, 1.2743e+00, 1.2898e+00, 3.5875e-06,\n",
      "        2.3375e-05, 3.0844e-01, 1.3160e+00, 2.7444e-01, 1.3504e+00, 3.5772e-01,\n",
      "        9.4769e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([112.8976, 136.6304, 153.3235, 160.9535,   4.4314,   4.4325,   4.4317,\n",
      "        229.2989, 229.2989, 229.2989,   4.4314,   4.4305, 229.2989, 229.2989,\n",
      "        229.2989, 229.2989, 229.2989,  34.1039,  34.1039,   4.4325, 229.2989,\n",
      "        229.2989, 229.2989, 229.2989, 229.2989,  34.1039,  34.1039, 229.2989,\n",
      "         34.1039,  34.1039,   5.2026, 229.2989, 229.2989, 229.2989, 229.2989,\n",
      "        229.2989,  34.1039,  34.1039, 229.2989,  34.1039,  34.1039,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 229.2989,   5.2026,   5.2025, 229.2989,   5.2026,\n",
      "          5.2025, 229.2989,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        229.2989, 229.2989, 229.2989, 229.2989,  34.1039,  34.1039,  34.1039,\n",
      "         34.1039, 229.2989, 229.2989, 229.2989,  34.1039,  34.1039,  34.1039,\n",
      "         34.1039,   5.2026,  34.1039,  34.1039,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 258 was 94.7%\n",
      "tensor([0.0000e+00, 3.2534e-06, 2.6628e-06, 2.3554e-06, 2.2333e-06, 4.0921e-09,\n",
      "        2.7473e-09, 2.2976e-09, 2.2474e-09, 4.2024e-06, 4.0414e-06, 3.9480e-06,\n",
      "        5.6700e-05, 4.0582e-05, 4.0247e-05, 3.8290e-06, 3.7351e-06, 2.3454e-05,\n",
      "        2.3176e-05, 3.4876e-01, 3.3340e-01, 1.2706e+00, 1.2860e+00, 3.5754e-06,\n",
      "        2.2953e-05, 3.0775e-01, 1.3118e+00, 2.7358e-01, 1.3464e+00, 3.5662e-01,\n",
      "        9.4785e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([113.0553, 136.8311, 153.5468, 161.1002,   4.4275,   4.4270,   4.4284,\n",
      "        229.7356, 229.7356, 229.7356,   4.4280,   4.4290, 229.7356, 229.7356,\n",
      "        229.7356, 229.7356, 229.7356,  34.1836,  34.1836,   4.4257, 229.7356,\n",
      "        229.7356, 229.7356, 229.7356, 229.7356,  34.1836,  34.1836, 229.7356,\n",
      "         34.1836,  34.1836,   5.2026, 229.7356, 229.7356, 229.7356, 229.7356,\n",
      "        229.7356,  34.1836,  34.1836, 229.7356,  34.1836,  34.1836,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 229.7356,   5.2026,   5.2025, 229.7356,   5.2026,\n",
      "          5.2025, 229.7356,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        229.7356, 229.7356, 229.7356, 229.7356,  34.1836,  34.1836,  34.1836,\n",
      "         34.1836, 229.7356, 229.7356, 229.7356,  34.1836,  34.1836,  34.1836,\n",
      "         34.1836,   5.2026,  34.1836,  34.1836,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 259 was 94.8%\n",
      "tensor([1.9599e-08, 3.2507e-06, 2.6610e-06, 2.3535e-06, 2.2337e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1906e-06, 4.0297e-06, 3.9368e-06,\n",
      "        5.5857e-05, 3.9918e-05, 3.9591e-05, 3.8163e-06, 3.7239e-06, 2.3043e-05,\n",
      "        2.2772e-05, 3.4758e-01, 3.3264e-01, 1.2671e+00, 1.2821e+00, 3.5678e-06,\n",
      "        2.2562e-05, 3.0678e-01, 1.3081e+00, 2.7286e-01, 1.3424e+00, 3.5559e-01,\n",
      "        9.4800e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([113.2131, 137.0319, 153.7700, 161.2470,   4.4234,   4.4248,   4.4232,\n",
      "        230.1722, 230.1722, 230.1722,   4.4237,   4.4219, 230.1722, 230.1722,\n",
      "        230.1722, 230.1722, 230.1722,  34.2632,  34.2632,   4.4241, 230.1722,\n",
      "        230.1722, 230.1722, 230.1722, 230.1722,  34.2632,  34.2632, 230.1722,\n",
      "         34.2632,  34.2632,   5.2026, 230.1722, 230.1722, 230.1722, 230.1722,\n",
      "        230.1722,  34.2632,  34.2632, 230.1722,  34.2632,  34.2632,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 230.1722,   5.2026,   5.2025, 230.1722,   5.2026,\n",
      "          5.2025, 230.1722,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        230.1722, 230.1722, 230.1722, 230.1722,  34.2632,  34.2632,  34.2632,\n",
      "         34.2632, 230.1722, 230.1722, 230.1722,  34.2632,  34.2632,  34.2632,\n",
      "         34.2632,   5.2026,  34.2632,  34.2632,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 260 was 94.8%\n",
      "tensor([1.9319e-08, 3.2431e-06, 2.6542e-06, 2.3483e-06, 2.2294e-06, 4.1359e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1766e-06, 4.0167e-06, 3.9264e-06,\n",
      "        5.4948e-05, 3.9262e-05, 3.8953e-05, 3.8053e-06, 3.7141e-06, 2.2635e-05,\n",
      "        2.2369e-05, 3.4652e-01, 3.3151e-01, 1.2633e+00, 1.2784e+00, 3.5560e-06,\n",
      "        2.2158e-05, 3.0605e-01, 1.3040e+00, 2.7205e-01, 1.3384e+00, 3.5452e-01,\n",
      "        9.4816e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([113.3709, 137.2327, 153.9931, 161.3940,   4.4184,   4.4174,   4.4209,\n",
      "        230.6085, 230.6085, 230.6085,   4.4203,   4.4204, 230.6085, 230.6085,\n",
      "        230.6085, 230.6085, 230.6085,  34.3429,  34.3429,   4.4191, 230.6085,\n",
      "        230.6085, 230.6085, 230.6085, 230.6085,  34.3429,  34.3429, 230.6085,\n",
      "         34.3429,  34.3429,   5.2026, 230.6085, 230.6085, 230.6085, 230.6085,\n",
      "        230.6085,  34.3429,  34.3429, 230.6085,  34.3429,  34.3429,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 230.6085,   5.2026,   5.2025, 230.6085,   5.2026,\n",
      "          5.2025, 230.6085,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        230.6085, 230.6085, 230.6085, 230.6085,  34.3429,  34.3429,  34.3429,\n",
      "         34.3429, 230.6085, 230.6085, 230.6085,  34.3429,  34.3429,  34.3429,\n",
      "         34.3429,   5.2026,  34.3429,  34.3429,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 261 was 94.8%\n",
      "tensor([9.9262e-24, 3.2309e-06, 2.6442e-06, 2.3386e-06, 2.2219e-06, 3.9443e-09,\n",
      "        2.6434e-09, 2.2075e-09, 2.1606e-09, 4.1656e-06, 4.0069e-06, 3.9143e-06,\n",
      "        5.4073e-05, 3.8606e-05, 3.8270e-05, 3.7916e-06, 3.7039e-06, 2.2213e-05,\n",
      "        2.1970e-05, 3.4525e-01, 3.3077e-01, 1.2599e+00, 1.2744e+00, 3.5472e-06,\n",
      "        2.1760e-05, 3.0514e-01, 1.3002e+00, 2.7135e-01, 1.3345e+00, 3.5349e-01,\n",
      "        9.4831e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([113.5288, 137.4335, 154.2163, 161.5410,   4.4143,   4.4160,   4.4136,\n",
      "        231.0447, 231.0447, 231.0447,   4.4160,   4.4153, 231.0447, 231.0447,\n",
      "        231.0447, 231.0447, 231.0447,  34.4226,  34.4226,   4.4167, 231.0447,\n",
      "        231.0447, 231.0447, 231.0447, 231.0447,  34.4226,  34.4226, 231.0447,\n",
      "         34.4226,  34.4226,   5.2026, 231.0447, 231.0447, 231.0447, 231.0447,\n",
      "        231.0447,  34.4226,  34.4226, 231.0447,  34.4226,  34.4226,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 231.0447,   5.2026,   5.2025, 231.0447,   5.2026,\n",
      "          5.2025, 231.0447,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        231.0447, 231.0447, 231.0447, 231.0447,  34.4226,  34.4226,  34.4226,\n",
      "         34.4226, 231.0447, 231.0447, 231.0447,  34.4226,  34.4226,  34.4226,\n",
      "         34.4226,   5.2026,  34.4226,  34.4226,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 262 was 94.8%\n",
      "tensor([0.0000e+00, 3.2231e-06, 2.6376e-06, 2.3334e-06, 2.2176e-06, 3.8952e-09,\n",
      "        2.6085e-09, 2.1774e-09, 2.1322e-09, 4.1513e-06, 3.9927e-06, 3.9054e-06,\n",
      "        5.3177e-05, 3.7939e-05, 3.7654e-05, 3.7817e-06, 3.6922e-06, 2.1818e-05,\n",
      "        2.1568e-05, 3.4420e-01, 3.2964e-01, 1.2561e+00, 1.2707e+00, 3.5358e-06,\n",
      "        2.1358e-05, 3.0433e-01, 1.2962e+00, 2.7061e-01, 1.3304e+00, 3.5243e-01,\n",
      "        9.4846e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([113.6868, 137.6343, 154.4395, 161.6881,   4.4101,   4.4104,   4.4123,\n",
      "        231.4808, 231.4808, 231.4808,   4.4126,   4.4120, 231.4808, 231.4808,\n",
      "        231.4808, 231.4808, 231.4808,  34.5023,  34.5023,   4.4097, 231.4808,\n",
      "        231.4808, 231.4808, 231.4808, 231.4808,  34.5023,  34.5023, 231.4808,\n",
      "         34.5023,  34.5023,   5.2026, 231.4808, 231.4808, 231.4808, 231.4808,\n",
      "        231.4808,  34.5023,  34.5023, 231.4808,  34.5023,  34.5023,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 231.4808,   5.2026,   5.2025, 231.4808,   5.2026,\n",
      "          5.2025, 231.4808,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        231.4808, 231.4808, 231.4808, 231.4808,  34.5023,  34.5023,  34.5023,\n",
      "         34.5023, 231.4808, 231.4808, 231.4808,  34.5023,  34.5023,  34.5023,\n",
      "         34.5023,   5.2026,  34.5023,  34.5023,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 263 was 94.8%\n",
      "tensor([0.0000e+00, 3.2158e-06, 2.6317e-06, 2.3276e-06, 2.2138e-06, 3.8466e-09,\n",
      "        2.5741e-09, 2.1476e-09, 2.1031e-09, 4.1402e-06, 3.9813e-06, 3.8918e-06,\n",
      "        5.2342e-05, 3.7308e-05, 3.6994e-05, 3.7682e-06, 3.6830e-06, 2.1401e-05,\n",
      "        2.1173e-05, 3.4304e-01, 3.2888e-01, 1.2526e+00, 1.2668e+00, 3.5279e-06,\n",
      "        2.0975e-05, 3.0340e-01, 1.2925e+00, 2.6983e-01, 1.3265e+00, 3.5138e-01,\n",
      "        9.4861e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([113.8448, 137.8351, 154.6626, 161.8354,   4.4070,   4.4071,   4.4070,\n",
      "        231.9166, 231.9166, 231.9166,   4.4053,   4.4078, 231.9166, 231.9166,\n",
      "        231.9166, 231.9166, 231.9166,  34.5819,  34.5819,   4.4081, 231.9166,\n",
      "        231.9166, 231.9166, 231.9166, 231.9166,  34.5819,  34.5819, 231.9166,\n",
      "         34.5819,  34.5819,   5.2026, 231.9166, 231.9166, 231.9166, 231.9166,\n",
      "        231.9166,  34.5819,  34.5819, 231.9166,  34.5819,  34.5819,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 231.9166,   5.2026,   5.2025, 231.9166,   5.2026,\n",
      "          5.2025, 231.9166,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        231.9166, 231.9166, 231.9166, 231.9166,  34.5819,  34.5819,  34.5819,\n",
      "         34.5819, 231.9166, 231.9166, 231.9166,  34.5819,  34.5819,  34.5819,\n",
      "         34.5819,   5.2026,  34.5819,  34.5819,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 264 was 94.8%\n",
      "tensor([0.0000e+00, 3.2080e-06, 2.6249e-06, 2.3220e-06, 2.2098e-06, 3.7968e-09,\n",
      "        2.5385e-09, 2.1171e-09, 2.0740e-09, 4.1249e-06, 3.9675e-06, 3.8828e-06,\n",
      "        5.1439e-05, 3.6650e-05, 3.6378e-05, 3.7591e-06, 3.6716e-06, 2.1009e-05,\n",
      "        2.0768e-05, 3.4182e-01, 3.2791e-01, 1.2490e+00, 1.2630e+00, 3.5155e-06,\n",
      "        2.0568e-05, 3.0262e-01, 1.2885e+00, 2.6905e-01, 1.3225e+00, 3.5031e-01,\n",
      "        9.4877e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.0028, 138.0360, 154.8855, 161.9830,   4.4018,   4.4026,   4.4056,\n",
      "        232.3523, 232.3523, 232.3523,   4.4038,   4.4024, 232.3523, 232.3523,\n",
      "        232.3523, 232.3523, 232.3523,  34.6616,  34.6616,   4.4011, 232.3523,\n",
      "        232.3523, 232.3523, 232.3523, 232.3523,  34.6616,  34.6616, 232.3523,\n",
      "         34.6616,  34.6616,   5.2026, 232.3523, 232.3523, 232.3523, 232.3523,\n",
      "        232.3523,  34.6616,  34.6616, 232.3523,  34.6616,  34.6616,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 232.3523,   5.2026,   5.2025, 232.3523,   5.2026,\n",
      "          5.2025, 232.3523,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        232.3523, 232.3523, 232.3523, 232.3523,  34.6616,  34.6616,  34.6616,\n",
      "         34.6616, 232.3523, 232.3523, 232.3523,  34.6616,  34.6616,  34.6616,\n",
      "         34.6616,   5.2026,  34.6616,  34.6616,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 265 was 94.8%\n",
      "tensor([1.3235e-23, 3.2013e-06, 2.6189e-06, 2.3166e-06, 2.2061e-06, 3.7492e-09,\n",
      "        2.5049e-09, 2.0878e-09, 2.0452e-09, 4.1153e-06, 3.9572e-06, 3.8690e-06,\n",
      "        5.0647e-05, 3.6045e-05, 3.5717e-05, 3.7442e-06, 3.6635e-06, 2.0594e-05,\n",
      "        2.0391e-05, 3.4074e-01, 3.2708e-01, 1.2455e+00, 1.2592e+00, 3.5088e-06,\n",
      "        2.0199e-05, 3.0182e-01, 1.2847e+00, 2.6821e-01, 1.3187e+00, 3.4932e-01,\n",
      "        9.4892e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.1609, 138.2369, 155.1086, 162.1307,   4.3987,   4.3983,   4.3982,\n",
      "        232.7879, 232.7879, 232.7879,   4.3985,   4.3991, 232.7879, 232.7879,\n",
      "        232.7879, 232.7879, 232.7879,  34.7412,  34.7412,   4.3996, 232.7879,\n",
      "        232.7879, 232.7879, 232.7879, 232.7879,  34.7412,  34.7412, 232.7879,\n",
      "         34.7412,  34.7412,   5.2026, 232.7879, 232.7879, 232.7879, 232.7879,\n",
      "        232.7879,  34.7412,  34.7412, 232.7879,  34.7412,  34.7412,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 232.7879,   5.2026,   5.2025, 232.7879,   5.2026,\n",
      "          5.2025, 232.7879,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        232.7879, 232.7879, 232.7879, 232.7879,  34.7412,  34.7412,  34.7412,\n",
      "         34.7412, 232.7879, 232.7879, 232.7879,  34.7412,  34.7412,  34.7412,\n",
      "         34.7412,   5.2026,  34.7412,  34.7412,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 266 was 94.9%\n",
      "tensor([1.7646e-08, 3.1972e-06, 2.6160e-06, 2.3144e-06, 2.2054e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0990e-06, 3.9431e-06, 3.8605e-06,\n",
      "        4.9719e-05, 3.5369e-05, 3.5103e-05, 3.7344e-06, 3.6508e-06, 2.0207e-05,\n",
      "        1.9982e-05, 3.3958e-01, 3.2604e-01, 1.2417e+00, 1.2553e+00, 3.4953e-06,\n",
      "        1.9788e-05, 3.0088e-01, 1.2807e+00, 2.6754e-01, 1.3145e+00, 3.4820e-01,\n",
      "        9.4908e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.3190, 138.4377, 155.3313, 162.2786,   4.3922,   4.3959,   4.3969,\n",
      "        233.2232, 233.2232, 233.2232,   4.3960,   4.3938, 233.2232, 233.2232,\n",
      "        233.2232, 233.2232, 233.2232,  34.8209,  34.8209,   4.3925, 233.2232,\n",
      "        233.2232, 233.2232, 233.2232, 233.2232,  34.8209,  34.8209, 233.2232,\n",
      "         34.8209,  34.8209,   5.2026, 233.2232, 233.2232, 233.2232, 233.2232,\n",
      "        233.2232,  34.8209,  34.8209, 233.2232,  34.8209,  34.8209,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 233.2232,   5.2026,   5.2025, 233.2232,   5.2026,\n",
      "          5.2025, 233.2232,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        233.2232, 233.2232, 233.2232, 233.2232,  34.8209,  34.8209,  34.8209,\n",
      "         34.8209, 233.2232, 233.2232, 233.2232,  34.8209,  34.8209,  34.8209,\n",
      "         34.8209,   5.2026,  34.8209,  34.8209,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 267 was 94.9%\n",
      "tensor([1.7382e-08, 3.1909e-06, 2.6102e-06, 2.3096e-06, 2.2019e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0912e-06, 3.9321e-06, 3.8477e-06,\n",
      "        4.8944e-05, 3.4767e-05, 3.4478e-05, 3.7218e-06, 3.6426e-06, 1.9806e-05,\n",
      "        1.9606e-05, 3.3858e-01, 3.2516e-01, 1.2382e+00, 1.2517e+00, 3.4895e-06,\n",
      "        1.9425e-05, 3.0015e-01, 1.2770e+00, 2.6672e-01, 1.3109e+00, 3.4724e-01,\n",
      "        9.4922e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.4772, 138.6386, 155.5544, 162.4264,   4.3890,   4.3916,   4.3894,\n",
      "        233.6584, 233.6584, 233.6584,   4.3907,   4.3905, 233.6584, 233.6584,\n",
      "        233.6584, 233.6584, 233.6584,  34.9005,  34.9005,   4.3909, 233.6584,\n",
      "        233.6584, 233.6584, 233.6584, 233.6584,  34.9005,  34.9005, 233.6584,\n",
      "         34.9005,  34.9005,   5.2026, 233.6584, 233.6584, 233.6584, 233.6584,\n",
      "        233.6584,  34.9005,  34.9005, 233.6584,  34.9005,  34.9005,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 233.6584,   5.2026,   5.2025, 233.6584,   5.2026,\n",
      "          5.2025, 233.6584,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        233.6584, 233.6584, 233.6584, 233.6584,  34.9005,  34.9005,  34.9005,\n",
      "         34.9005, 233.6584, 233.6584, 233.6584,  34.9005,  34.9005,  34.9005,\n",
      "         34.9005,   5.2026,  34.9005,  34.9005,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 268 was 94.9%\n",
      "tensor([9.9262e-24, 3.1782e-06, 2.5999e-06, 2.3003e-06, 2.1938e-06, 3.5990e-09,\n",
      "        2.3988e-09, 1.9958e-09, 1.9573e-09, 4.0755e-06, 3.9182e-06, 3.8388e-06,\n",
      "        4.8043e-05, 3.4090e-05, 3.3857e-05, 3.7116e-06, 3.6292e-06, 1.9416e-05,\n",
      "        1.9202e-05, 3.3742e-01, 3.2411e-01, 1.2345e+00, 1.2478e+00, 3.4766e-06,\n",
      "        1.9020e-05, 2.9925e-01, 1.2729e+00, 2.6600e-01, 1.3067e+00, 3.4613e-01,\n",
      "        9.4938e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.6355, 138.8394, 155.7772, 162.5745,   4.3857,   4.3840,   4.3870,\n",
      "        234.0935, 234.0935, 234.0935,   4.3872,   4.3871, 234.0935, 234.0935,\n",
      "        234.0935, 234.0935, 234.0935,  34.9801,  34.9801,   4.3858, 234.0935,\n",
      "        234.0935, 234.0935, 234.0935, 234.0935,  34.9801,  34.9801, 234.0935,\n",
      "         34.9801,  34.9801,   5.2026, 234.0935, 234.0935, 234.0935, 234.0935,\n",
      "        234.0935,  34.9801,  34.9801, 234.0935,  34.9801,  34.9801,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 234.0935,   5.2026,   5.2025, 234.0935,   5.2026,\n",
      "          5.2025, 234.0935,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        234.0935, 234.0935, 234.0935, 234.0935,  34.9801,  34.9801,  34.9801,\n",
      "         34.9801, 234.0935, 234.0935, 234.0935,  34.9801,  34.9801,  34.9801,\n",
      "         34.9801,   5.2026,  34.9801,  34.9801,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 269 was 94.9%\n",
      "tensor([9.9262e-24, 3.1707e-06, 2.5940e-06, 2.2946e-06, 2.1901e-06, 3.5496e-09,\n",
      "        2.3638e-09, 1.9657e-09, 1.9277e-09, 4.0628e-06, 3.9086e-06, 3.8264e-06,\n",
      "        4.7209e-05, 3.3480e-05, 3.3220e-05, 3.6986e-06, 3.6203e-06, 1.9019e-05,\n",
      "        1.8822e-05, 3.3623e-01, 3.2334e-01, 1.2310e+00, 1.2440e+00, 3.4673e-06,\n",
      "        1.8637e-05, 2.9832e-01, 1.2692e+00, 2.6529e-01, 1.3028e+00, 3.4509e-01,\n",
      "        9.4953e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.7937, 139.0402, 155.9997, 162.7229,   4.3812,   4.3826,   4.3826,\n",
      "        234.5284, 234.5284, 234.5284,   4.3798,   4.3818, 234.5284, 234.5284,\n",
      "        234.5284, 234.5284, 234.5284,  35.0598,  35.0598,   4.3834, 234.5284,\n",
      "        234.5284, 234.5284, 234.5284, 234.5284,  35.0598,  35.0598, 234.5284,\n",
      "         35.0598,  35.0598,   5.2026, 234.5284, 234.5284, 234.5284, 234.5284,\n",
      "        234.5284,  35.0598,  35.0598, 234.5284,  35.0598,  35.0598,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 234.5284,   5.2026,   5.2025, 234.5284,   5.2026,\n",
      "          5.2025, 234.5284,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        234.5284, 234.5284, 234.5284, 234.5284,  35.0598,  35.0598,  35.0598,\n",
      "         35.0598, 234.5284, 234.5284, 234.5284,  35.0598,  35.0598,  35.0598,\n",
      "         35.0598,   5.2026,  35.0598,  35.0598,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 270 was 94.9%\n",
      "tensor([0.0000e+00, 3.1633e-06, 2.5874e-06, 2.2892e-06, 2.1861e-06, 3.4999e-09,\n",
      "        2.3278e-09, 1.9349e-09, 1.8980e-09, 4.0493e-06, 3.8938e-06, 3.8162e-06,\n",
      "        4.6349e-05, 3.2854e-05, 3.2619e-05, 3.6899e-06, 3.6102e-06, 1.8630e-05,\n",
      "        1.8427e-05, 3.3507e-01, 3.2235e-01, 1.2274e+00, 1.2402e+00, 3.4560e-06,\n",
      "        1.8245e-05, 2.9761e-01, 1.2652e+00, 2.6449e-01, 1.2989e+00, 3.4406e-01,\n",
      "        9.4968e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([114.9520, 139.2410, 156.2222, 162.8714,   4.3769,   4.3769,   4.3792,\n",
      "        234.9631, 234.9631, 234.9631,   4.3783,   4.3784, 234.9631, 234.9631,\n",
      "        234.9631, 234.9631, 234.9631,  35.1394,  35.1394,   4.3762, 234.9631,\n",
      "        234.9631, 234.9631, 234.9631, 234.9631,  35.1394,  35.1394, 234.9631,\n",
      "         35.1394,  35.1394,   5.2026, 234.9631, 234.9631, 234.9631, 234.9631,\n",
      "        234.9631,  35.1394,  35.1394, 234.9631,  35.1394,  35.1394,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 234.9631,   5.2026,   5.2025, 234.9631,   5.2026,\n",
      "          5.2025, 234.9631,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        234.9631, 234.9631, 234.9631, 234.9631,  35.1394,  35.1394,  35.1394,\n",
      "         35.1394, 234.9631, 234.9631, 234.9631,  35.1394,  35.1394,  35.1394,\n",
      "         35.1394,   5.2026,  35.1394,  35.1394,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 271 was 94.9%\n",
      "tensor([0.0000e+00, 3.1559e-06, 2.5814e-06, 2.2836e-06, 2.1822e-06, 3.4506e-09,\n",
      "        2.2936e-09, 1.9047e-09, 1.8685e-09, 4.0379e-06, 3.8831e-06, 3.8040e-06,\n",
      "        4.5554e-05, 3.2237e-05, 3.1980e-05, 3.6752e-06, 3.5997e-06, 1.8238e-05,\n",
      "        1.8052e-05, 3.3397e-01, 3.2153e-01, 1.2239e+00, 1.2364e+00, 3.4484e-06,\n",
      "        1.7875e-05, 2.9667e-01, 1.2615e+00, 2.6372e-01, 1.2950e+00, 3.4303e-01,\n",
      "        9.4983e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([115.1103, 139.4418, 156.4445, 163.0200,   4.3735,   4.3736,   4.3717,\n",
      "        235.3977, 235.3977, 235.3977,   4.3738,   4.3732, 235.3977, 235.3977,\n",
      "        235.3977, 235.3977, 235.3977,  35.2190,  35.2190,   4.3747, 235.3977,\n",
      "        235.3977, 235.3977, 235.3977, 235.3977,  35.2190,  35.2190, 235.3977,\n",
      "         35.2190,  35.2190,   5.2026, 235.3977, 235.3977, 235.3977, 235.3977,\n",
      "        235.3977,  35.2190,  35.2190, 235.3977,  35.2190,  35.2190,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 235.3977,   5.2026,   5.2025, 235.3977,   5.2026,\n",
      "          5.2025, 235.3977,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        235.3977, 235.3977, 235.3977, 235.3977,  35.2190,  35.2190,  35.2190,\n",
      "         35.2190, 235.3977, 235.3977, 235.3977,  35.2190,  35.2190,  35.2190,\n",
      "         35.2190,   5.2026,  35.2190,  35.2190,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 272 was 94.9%\n",
      "tensor([1.6005e-08, 3.1521e-06, 2.5783e-06, 2.2816e-06, 2.1813e-06, 4.1359e-25,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0228e-06, 3.8704e-06, 3.7955e-06,\n",
      "        4.4708e-05, 3.1624e-05, 3.1396e-05, 3.6650e-06, 3.5891e-06, 1.7869e-05,\n",
      "        1.7679e-05, 3.3291e-01, 3.2045e-01, 1.2202e+00, 1.2327e+00, 3.4362e-06,\n",
      "        1.7494e-05, 2.9584e-01, 1.2576e+00, 2.6302e-01, 1.2910e+00, 3.4197e-01,\n",
      "        9.4998e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([115.2687, 139.6425, 156.6666, 163.1689,   4.3680,   4.3700,   4.3704,\n",
      "        235.8322, 235.8322, 235.8322,   4.3683,   4.3707, 235.8322, 235.8322,\n",
      "        235.8322, 235.8322, 235.8322,  35.2986,  35.2986,   4.3675, 235.8322,\n",
      "        235.8322, 235.8322, 235.8322, 235.8322,  35.2986,  35.2986, 235.8322,\n",
      "         35.2986,  35.2986,   5.2026, 235.8322, 235.8322, 235.8322, 235.8322,\n",
      "        235.8322,  35.2986,  35.2986, 235.8322,  35.2986,  35.2986,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 235.8322,   5.2026,   5.2025, 235.8322,   5.2026,\n",
      "          5.2025, 235.8322,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        235.8322, 235.8322, 235.8322, 235.8322,  35.2986,  35.2986,  35.2986,\n",
      "         35.2986, 235.8322, 235.8322, 235.8322,  35.2986,  35.2986,  35.2986,\n",
      "         35.2986,   5.2026,  35.2986,  35.2986,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 273 was 95.0%\n",
      "tensor([9.9262e-24, 3.1408e-06, 2.5686e-06, 2.2722e-06, 2.1736e-06, 3.3660e-09,\n",
      "        2.2330e-09, 1.8514e-09, 1.8169e-09, 4.0132e-06, 3.8568e-06, 3.7837e-06,\n",
      "        4.4113e-05, 3.1136e-05, 3.0912e-05, 3.6543e-06, 3.5777e-06, 1.7560e-05,\n",
      "        1.7361e-05, 3.3175e-01, 3.1970e-01, 1.2171e+00, 1.2292e+00, 3.4291e-06,\n",
      "        1.7188e-05, 2.9501e-01, 1.2540e+00, 2.6221e-01, 1.2874e+00, 3.4095e-01,\n",
      "        9.5012e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([115.4267, 139.8431, 156.8850, 163.3202,   4.3662,   4.3651,   4.3644,\n",
      "        236.2665, 236.2665, 236.2665,   4.3646,   4.3629, 236.2665, 236.2665,\n",
      "        236.2665, 236.2665, 236.2665,  35.3782,  35.3782,   4.3659, 236.2665,\n",
      "        236.2665, 236.2665, 236.2665, 236.2665,  35.3782,  35.3782, 236.2665,\n",
      "         35.3782,  35.3782,   5.2026, 236.2665, 236.2665, 236.2665, 236.2665,\n",
      "        236.2665,  35.3782,  35.3782, 236.2665,  35.3782,  35.3782,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 236.2665,   5.2026,   5.2025, 236.2665,   5.2026,\n",
      "          5.2025, 236.2665,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        236.2665, 236.2665, 236.2665, 236.2665,  35.3782,  35.3782,  35.3782,\n",
      "         35.3782, 236.2665, 236.2665, 236.2665,  35.3782,  35.3782,  35.3782,\n",
      "         35.3782,   5.2026,  35.3782,  35.3782,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 274 was 95.0%\n",
      "tensor([3.3087e-24, 3.1333e-06, 2.5624e-06, 2.2670e-06, 2.1694e-06, 3.3255e-09,\n",
      "        2.2046e-09, 1.8279e-09, 1.7945e-09, 3.9970e-06, 3.8468e-06, 3.7734e-06,\n",
      "        4.3373e-05, 3.0638e-05, 3.0416e-05, 3.6430e-06, 3.5702e-06, 1.7250e-05,\n",
      "        1.7071e-05, 3.3074e-01, 3.1866e-01, 1.2134e+00, 1.2255e+00, 3.4159e-06,\n",
      "        1.6885e-05, 2.9416e-01, 1.2502e+00, 2.6144e-01, 1.2834e+00, 3.3990e-01,\n",
      "        9.5027e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([115.5848, 140.0437, 157.1035, 163.4713,   4.3578,   4.3601,   4.3616,\n",
      "        236.7006, 236.7006, 236.7006,   4.3618,   4.3611, 236.7006, 236.7006,\n",
      "        236.7006, 236.7006, 236.7006,  35.4579,  35.4579,   4.3608, 236.7006,\n",
      "        236.7006, 236.7006, 236.7006, 236.7006,  35.4579,  35.4579, 236.7006,\n",
      "         35.4579,  35.4579,   5.2026, 236.7006, 236.7006, 236.7006, 236.7006,\n",
      "        236.7006,  35.4579,  35.4579, 236.7006,  35.4579,  35.4579,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 236.7006,   5.2026,   5.2025, 236.7006,   5.2026,\n",
      "          5.2025, 236.7006,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        236.7006, 236.7006, 236.7006, 236.7006,  35.4579,  35.4579,  35.4579,\n",
      "         35.4579, 236.7006, 236.7006, 236.7006,  35.4579,  35.4579,  35.4579,\n",
      "         35.4579,   5.2026,  35.4579,  35.4579,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 275 was 95.0%\n",
      "tensor([3.3087e-24, 3.1258e-06, 2.5562e-06, 2.2617e-06, 2.1655e-06, 3.2761e-09,\n",
      "        2.1700e-09, 1.7975e-09, 1.7647e-09, 3.9890e-06, 3.8349e-06, 3.7606e-06,\n",
      "        4.2593e-05, 3.0031e-05, 2.9798e-05, 3.6292e-06, 3.5584e-06, 1.6868e-05,\n",
      "        1.6696e-05, 3.2956e-01, 3.1776e-01, 1.2100e+00, 1.2218e+00, 3.4081e-06,\n",
      "        1.6521e-05, 2.9332e-01, 1.2464e+00, 2.6077e-01, 1.2795e+00, 3.3887e-01,\n",
      "        9.5042e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([115.7429, 140.2442, 157.3218, 163.6227,   4.3560,   4.3571,   4.3557,\n",
      "        237.1346, 237.1346, 237.1346,   4.3539,   4.3564, 237.1346, 237.1346,\n",
      "        237.1346, 237.1346, 237.1346,  35.5375,  35.5375,   4.3584, 237.1346,\n",
      "        237.1346, 237.1346, 237.1346, 237.1346,  35.5375,  35.5375, 237.1346,\n",
      "         35.5375,  35.5375,   5.2026, 237.1346, 237.1346, 237.1346, 237.1346,\n",
      "        237.1346,  35.5375,  35.5375, 237.1346,  35.5375,  35.5375,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 237.1346,   5.2026,   5.2025, 237.1346,   5.2026,\n",
      "          5.2025, 237.1346,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        237.1346, 237.1346, 237.1346, 237.1346,  35.5375,  35.5375,  35.5375,\n",
      "         35.5375, 237.1346, 237.1346, 237.1346,  35.5375,  35.5375,  35.5375,\n",
      "         35.5375,   5.2026,  35.5375,  35.5375,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 276 was 95.0%\n",
      "tensor([6.6174e-24, 3.1184e-06, 2.5498e-06, 2.2566e-06, 2.1616e-06, 3.2692e-09,\n",
      "        2.1662e-09, 1.7958e-09, 1.7640e-09, 3.9729e-06, 3.8217e-06, 3.7517e-06,\n",
      "        4.2297e-05, 2.9857e-05, 2.9663e-05, 3.6216e-06, 3.5475e-06, 1.6799e-05,\n",
      "        1.6627e-05, 3.2842e-01, 3.1676e-01, 1.2063e+00, 1.2180e+00, 3.3967e-06,\n",
      "        1.6456e-05, 2.9256e-01, 1.2424e+00, 2.5999e-01, 1.2756e+00, 3.3786e-01,\n",
      "        9.5058e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([115.9011, 140.4450, 157.5409, 163.7736,   4.3520,   4.3509,   4.3539,\n",
      "        237.5685, 237.5685, 237.5685,   4.3520,   4.3516, 237.5685, 237.5685,\n",
      "        237.5685, 237.5685, 237.5685,  35.6170,  35.6170,   4.3511, 237.5685,\n",
      "        237.5685, 237.5685, 237.5685, 237.5685,  35.6170,  35.6170, 237.5685,\n",
      "         35.6170,  35.6170,   5.2026, 237.5685, 237.5685, 237.5685, 237.5685,\n",
      "        237.5685,  35.6170,  35.6170, 237.5685,  35.6170,  35.6170,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 237.5685,   5.2026,   5.2025, 237.5685,   5.2026,\n",
      "          5.2025, 237.5685,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        237.5685, 237.5685, 237.5685, 237.5685,  35.6170,  35.6170,  35.6170,\n",
      "         35.6170, 237.5685, 237.5685, 237.5685,  35.6170,  35.6170,  35.6170,\n",
      "         35.6170,   5.2026,  35.6170,  35.6170,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 277 was 95.0%\n",
      "tensor([0.0000e+00, 3.1112e-06, 2.5437e-06, 2.2507e-06, 2.1574e-06, 3.2215e-09,\n",
      "        2.1327e-09, 1.7670e-09, 1.7355e-09, 3.9614e-06, 3.8110e-06, 3.7378e-06,\n",
      "        4.1534e-05, 2.9286e-05, 2.9060e-05, 3.6063e-06, 3.5380e-06, 1.6429e-05,\n",
      "        1.6272e-05, 3.2732e-01, 3.1599e-01, 1.2027e+00, 1.2141e+00, 3.3884e-06,\n",
      "        1.6113e-05, 2.9163e-01, 1.2386e+00, 2.5913e-01, 1.2717e+00, 3.3680e-01,\n",
      "        9.5073e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([116.0594, 140.6457, 157.7597, 163.9248,   4.3459,   4.3490,   4.3457,\n",
      "        238.0022, 238.0022, 238.0022,   4.3473,   4.3489, 238.0022, 238.0022,\n",
      "        238.0022, 238.0022, 238.0022,  35.6966,  35.6966,   4.3486, 238.0022,\n",
      "        238.0022, 238.0022, 238.0022, 238.0022,  35.6966,  35.6966, 238.0022,\n",
      "         35.6966,  35.6966,   5.2026, 238.0022, 238.0022, 238.0022, 238.0022,\n",
      "        238.0022,  35.6966,  35.6966, 238.0022,  35.6966,  35.6966,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 238.0022,   5.2026,   5.2025, 238.0022,   5.2026,\n",
      "          5.2025, 238.0022,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        238.0022, 238.0022, 238.0022, 238.0022,  35.6966,  35.6966,  35.6966,\n",
      "         35.6966, 238.0022, 238.0022, 238.0022,  35.6966,  35.6966,  35.6966,\n",
      "         35.6966,   5.2026,  35.6966,  35.6966,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 278 was 95.0%\n",
      "tensor([0.0000e+00, 3.1047e-06, 2.5377e-06, 2.2457e-06, 2.1533e-06, 3.5272e-09,\n",
      "        2.3599e-09, 1.9758e-09, 1.9452e-09, 3.9491e-06, 3.7956e-06, 3.7297e-06,\n",
      "        4.5096e-05, 3.2228e-05, 3.2127e-05, 3.5961e-06, 3.5236e-06, 1.8521e-05,\n",
      "        1.8381e-05, 3.2613e-01, 3.1475e-01, 1.1989e+00, 1.2103e+00, 3.3770e-06,\n",
      "        1.8333e-05, 2.9067e-01, 1.2345e+00, 2.5837e-01, 1.2670e+00, 3.3562e-01,\n",
      "        9.5089e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([116.2193, 140.8468, 157.9843, 164.0718,   4.3418,   4.3410,   4.3442,\n",
      "        238.4357, 238.4357, 238.4357,   4.3446,   4.3434, 238.4357, 238.4357,\n",
      "        238.4357, 238.4357, 238.4357,  35.7762,  35.7762,   4.3441, 238.4357,\n",
      "        238.4357, 238.4357, 238.4357, 238.4357,  35.7762,  35.7762, 238.4357,\n",
      "         35.7762,  35.7762,   5.2026, 238.4357, 238.4357, 238.4357, 238.4357,\n",
      "        238.4357,  35.7762,  35.7762, 238.4357,  35.7762,  35.7762,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 238.4357,   5.2026,   5.2025, 238.4357,   5.2026,\n",
      "          5.2025, 238.4357,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        238.4357, 238.4357, 238.4357, 238.4357,  35.7762,  35.7762,  35.7762,\n",
      "         35.7762, 238.4357, 238.4357, 238.4357,  35.7762,  35.7762,  35.7762,\n",
      "         35.7762,   5.2026,  35.7762,  35.7762,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 279 was 95.1%\n",
      "tensor([0.0000e+00, 3.0972e-06, 2.5315e-06, 2.2401e-06, 2.1494e-06, 3.4879e-09,\n",
      "        2.3325e-09, 1.9525e-09, 1.9222e-09, 3.9362e-06, 3.7868e-06, 3.7159e-06,\n",
      "        4.4414e-05, 3.1754e-05, 3.1600e-05, 3.5816e-06, 3.5160e-06, 1.8200e-05,\n",
      "        1.8093e-05, 3.2496e-01, 3.1391e-01, 1.1954e+00, 1.2065e+00, 3.3670e-06,\n",
      "        1.8033e-05, 2.8979e-01, 1.2307e+00, 2.5763e-01, 1.2631e+00, 3.3458e-01,\n",
      "        9.5104e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([116.3792, 141.0479, 158.2087, 164.2189,   4.3378,   4.3395,   4.3385,\n",
      "        238.8692, 238.8692, 238.8692,   4.3368,   4.3408, 238.8692, 238.8692,\n",
      "        238.8692, 238.8692, 238.8692,  35.8558,  35.8558,   4.3396, 238.8692,\n",
      "        238.8692, 238.8692, 238.8692, 238.8692,  35.8558,  35.8558, 238.8692,\n",
      "         35.8558,  35.8558,   5.2026, 238.8692, 238.8692, 238.8692, 238.8692,\n",
      "        238.8692,  35.8558,  35.8558, 238.8692,  35.8558,  35.8558,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 238.8692,   5.2026,   5.2025, 238.8692,   5.2026,\n",
      "          5.2025, 238.8692,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        238.8692, 238.8692, 238.8692, 238.8692,  35.8558,  35.8558,  35.8558,\n",
      "         35.8558, 238.8692, 238.8692, 238.8692,  35.8558,  35.8558,  35.8558,\n",
      "         35.8558,   5.2026,  35.8558,  35.8558,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 280 was 95.1%\n",
      "tensor([1.6186e-08, 3.0939e-06, 2.5288e-06, 2.2378e-06, 2.1490e-06, 4.1359e-25,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9236e-06, 3.7709e-06, 3.7072e-06,\n",
      "        4.3757e-05, 3.1243e-05, 3.1150e-05, 3.5740e-06, 3.5038e-06, 1.7912e-05,\n",
      "        1.7777e-05, 3.2382e-01, 3.1304e-01, 1.1919e+00, 1.2027e+00, 3.3573e-06,\n",
      "        1.7740e-05, 2.8896e-01, 1.2269e+00, 2.5687e-01, 1.2593e+00, 3.3357e-01,\n",
      "        9.5119e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([116.5391, 141.2491, 158.4333, 164.3664,   4.3338,   4.3347,   4.3359,\n",
      "        239.3025, 239.3025, 239.3025,   4.3351,   4.3331, 239.3025, 239.3025,\n",
      "        239.3025, 239.3025, 239.3025,  35.9354,  35.9354,   4.3341, 239.3025,\n",
      "        239.3025, 239.3025, 239.3025, 239.3025,  35.9354,  35.9354, 239.3025,\n",
      "         35.9354,  35.9354,   5.2026, 239.3025, 239.3025, 239.3025, 239.3025,\n",
      "        239.3025,  35.9354,  35.9354, 239.3025,  35.9354,  35.9354,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 239.3025,   5.2026,   5.2025, 239.3025,   5.2026,\n",
      "          5.2025, 239.3025,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        239.3025, 239.3025, 239.3025, 239.3025,  35.9354,  35.9354,  35.9354,\n",
      "         35.9354, 239.3025, 239.3025, 239.3025,  35.9354,  35.9354,  35.9354,\n",
      "         35.9354,   5.2026,  35.9354,  35.9354,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 281 was 95.1%\n",
      "tensor([1.5972e-08, 3.0866e-06, 2.5224e-06, 2.2324e-06, 2.1447e-06, 8.2718e-25,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9107e-06, 3.7611e-06, 3.6932e-06,\n",
      "        4.3091e-05, 3.0774e-05, 3.0630e-05, 3.5592e-06, 3.4959e-06, 1.7591e-05,\n",
      "        1.7493e-05, 3.2280e-01, 3.1208e-01, 1.1882e+00, 1.1990e+00, 3.3478e-06,\n",
      "        1.7444e-05, 2.8814e-01, 1.2230e+00, 2.5602e-01, 1.2554e+00, 3.3250e-01,\n",
      "        9.5134e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([116.6990, 141.4502, 158.6578, 164.5140,   4.3298,   4.3300,   4.3280,\n",
      "        239.7356, 239.7356, 239.7356,   4.3295,   4.3314, 239.7356, 239.7356,\n",
      "        239.7356, 239.7356, 239.7356,  36.0149,  36.0149,   4.3315, 239.7356,\n",
      "        239.7356, 239.7356, 239.7356, 239.7356,  36.0149,  36.0149, 239.7356,\n",
      "         36.0149,  36.0149,   5.2026, 239.7356, 239.7356, 239.7356, 239.7356,\n",
      "        239.7356,  36.0149,  36.0149, 239.7356,  36.0149,  36.0149,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 239.7356,   5.2026,   5.2025, 239.7356,   5.2026,\n",
      "          5.2025, 239.7356,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        239.7356, 239.7356, 239.7356, 239.7356,  36.0149,  36.0149,  36.0149,\n",
      "         36.0149, 239.7356, 239.7356, 239.7356,  36.0149,  36.0149,  36.0149,\n",
      "         36.0149,   5.2026,  36.0149,  36.0149,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 282 was 95.1%\n",
      "tensor([0.0000e+00, 3.0749e-06, 2.5130e-06, 2.2237e-06, 2.1375e-06, 3.3721e-09,\n",
      "        2.2515e-09, 1.8830e-09, 1.8552e-09, 3.8971e-06, 3.7482e-06, 3.6866e-06,\n",
      "        4.2418e-05, 3.0271e-05, 3.0167e-05, 3.5497e-06, 3.4838e-06, 1.7317e-05,\n",
      "        1.7196e-05, 3.2163e-01, 3.1116e-01, 1.1848e+00, 1.1953e+00, 3.3368e-06,\n",
      "        1.7149e-05, 2.8726e-01, 1.2193e+00, 2.5540e-01, 1.2515e+00, 3.3150e-01,\n",
      "        9.5149e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([116.8589, 141.6512, 158.8821, 164.6618,   4.3245,   4.3251,   4.3265,\n",
      "        240.1686, 240.1686, 240.1686,   4.3278,   4.3257, 240.1686, 240.1686,\n",
      "        240.1686, 240.1686, 240.1686,  36.0945,  36.0945,   4.3240, 240.1686,\n",
      "        240.1686, 240.1686, 240.1686, 240.1686,  36.0945,  36.0945, 240.1686,\n",
      "         36.0945,  36.0945,   5.2026, 240.1686, 240.1686, 240.1686, 240.1686,\n",
      "        240.1686,  36.0945,  36.0945, 240.1686,  36.0945,  36.0945,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 240.1686,   5.2026,   5.2025, 240.1686,   5.2026,\n",
      "          5.2025, 240.1686,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        240.1686, 240.1686, 240.1686, 240.1686,  36.0945,  36.0945,  36.0945,\n",
      "         36.0945, 240.1686, 240.1686, 240.1686,  36.0945,  36.0945,  36.0945,\n",
      "         36.0945,   5.2026,  36.0945,  36.0945,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 283 was 95.1%\n",
      "tensor([0.0000e+00, 3.0678e-06, 2.5073e-06, 2.2186e-06, 2.1334e-06, 3.3339e-09,\n",
      "        2.2247e-09, 1.8596e-09, 1.8327e-09, 3.8870e-06, 3.7380e-06, 3.6714e-06,\n",
      "        4.1795e-05, 2.9801e-05, 2.9662e-05, 3.5360e-06, 3.4751e-06, 1.6997e-05,\n",
      "        1.6912e-05, 3.2067e-01, 3.1025e-01, 1.1811e+00, 1.1916e+00, 3.3294e-06,\n",
      "        1.6869e-05, 2.8637e-01, 1.2156e+00, 2.5461e-01, 1.2476e+00, 3.3047e-01,\n",
      "        9.5164e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.0190, 141.8523, 159.1066, 164.8095,   4.3215,   4.3215,   4.3208,\n",
      "        240.6015, 240.6015, 240.6015,   4.3199,   4.3211, 240.6015, 240.6015,\n",
      "        240.6015, 240.6015, 240.6015,  36.1741,  36.1741,   4.3223, 240.6015,\n",
      "        240.6015, 240.6015, 240.6015, 240.6015,  36.1741,  36.1741, 240.6015,\n",
      "         36.1741,  36.1741,   5.2026, 240.6015, 240.6015, 240.6015, 240.6015,\n",
      "        240.6015,  36.1741,  36.1741, 240.6015,  36.1741,  36.1741,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 240.6015,   5.2026,   5.2025, 240.6015,   5.2026,\n",
      "          5.2025, 240.6015,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        240.6015, 240.6015, 240.6015, 240.6015,  36.1741,  36.1741,  36.1741,\n",
      "         36.1741, 240.6015, 240.6015, 240.6015,  36.1741,  36.1741,  36.1741,\n",
      "         36.1741,   5.2026,  36.1741,  36.1741,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 284 was 95.1%\n",
      "tensor([3.3087e-24, 3.0602e-06, 2.5006e-06, 2.2130e-06, 2.1294e-06, 3.2943e-09,\n",
      "        2.1966e-09, 1.8359e-09, 1.8099e-09, 3.8713e-06, 3.7244e-06, 3.6628e-06,\n",
      "        4.1096e-05, 2.9304e-05, 2.9205e-05, 3.5273e-06, 3.4639e-06, 1.6713e-05,\n",
      "        1.6610e-05, 3.1948e-01, 3.0931e-01, 1.1776e+00, 1.1878e+00, 3.3167e-06,\n",
      "        1.6562e-05, 2.8561e-01, 1.2116e+00, 2.5382e-01, 1.2437e+00, 3.2940e-01,\n",
      "        9.5179e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.1790, 142.0533, 159.3305, 164.9577,   4.3151,   4.3154,   4.3193,\n",
      "        241.0343, 241.0343, 241.0343,   4.3182,   4.3176, 241.0343, 241.0343,\n",
      "        241.0343, 241.0343, 241.0343,  36.2536,  36.2536,   4.3147, 241.0343,\n",
      "        241.0343, 241.0343, 241.0343, 241.0343,  36.2536,  36.2536, 241.0343,\n",
      "         36.2536,  36.2536,   5.2026, 241.0343, 241.0343, 241.0343, 241.0343,\n",
      "        241.0343,  36.2536,  36.2536, 241.0343,  36.2536,  36.2536,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 241.0343,   5.2026,   5.2025, 241.0343,   5.2026,\n",
      "          5.2025, 241.0343,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        241.0343, 241.0343, 241.0343, 241.0343,  36.2536,  36.2536,  36.2536,\n",
      "         36.2536, 241.0343, 241.0343, 241.0343,  36.2536,  36.2536,  36.2536,\n",
      "         36.2536,   5.2026,  36.2536,  36.2536,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 285 was 95.1%\n",
      "tensor([9.9262e-24, 3.0535e-06, 2.4951e-06, 2.2077e-06, 2.1259e-06, 3.2564e-09,\n",
      "        2.1706e-09, 1.8130e-09, 1.7874e-09, 3.8632e-06, 3.7149e-06, 3.6496e-06,\n",
      "        4.0506e-05, 2.8843e-05, 2.8705e-05, 3.5130e-06, 3.4551e-06, 1.6409e-05,\n",
      "        1.6331e-05, 3.1838e-01, 3.0856e-01, 1.1742e+00, 1.1841e+00, 3.3108e-06,\n",
      "        1.6294e-05, 2.8476e-01, 1.2080e+00, 2.5309e-01, 1.2400e+00, 3.2845e-01,\n",
      "        9.5194e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.3391, 142.2544, 159.5550, 165.1056,   4.3119,   4.3118,   4.3113,\n",
      "        241.4669, 241.4669, 241.4669,   4.3125,   4.3130, 241.4669, 241.4669,\n",
      "        241.4669, 241.4669, 241.4669,  36.3332,  36.3332,   4.3130, 241.4669,\n",
      "        241.4669, 241.4669, 241.4669, 241.4669,  36.3332,  36.3332, 241.4669,\n",
      "         36.3332,  36.3332,   5.2026, 241.4669, 241.4669, 241.4669, 241.4669,\n",
      "        241.4669,  36.3332,  36.3332, 241.4669,  36.3332,  36.3332,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 241.4669,   5.2026,   5.2025, 241.4669,   5.2026,\n",
      "          5.2025, 241.4669,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        241.4669, 241.4669, 241.4669, 241.4669,  36.3332,  36.3332,  36.3332,\n",
      "         36.3332, 241.4669, 241.4669, 241.4669,  36.3332,  36.3332,  36.3332,\n",
      "         36.3332,   5.2026,  36.3332,  36.3332,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 286 was 95.2%\n",
      "tensor([0.0000e+00, 3.0454e-06, 2.4885e-06, 2.2022e-06, 2.1214e-06, 3.2153e-09,\n",
      "        2.1420e-09, 1.7887e-09, 1.7641e-09, 3.8473e-06, 3.7006e-06, 3.6413e-06,\n",
      "        3.9797e-05, 2.8331e-05, 2.8236e-05, 3.5031e-06, 3.4427e-06, 1.6124e-05,\n",
      "        1.6027e-05, 3.1729e-01, 3.0750e-01, 1.1705e+00, 1.1803e+00, 3.2973e-06,\n",
      "        1.5988e-05, 2.8388e-01, 1.2040e+00, 2.5236e-01, 1.2359e+00, 3.2734e-01,\n",
      "        9.5209e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.4992, 142.4554, 159.7789, 165.2539,   4.3063,   4.3092,   4.3098,\n",
      "        241.8994, 241.8994, 241.8994,   4.3087,   4.3072, 241.8994, 241.8994,\n",
      "        241.8994, 241.8994, 241.8994,  36.4127,  36.4127,   4.3054, 241.8994,\n",
      "        241.8994, 241.8994, 241.8994, 241.8994,  36.4127,  36.4127, 241.8994,\n",
      "         36.4127,  36.4127,   5.2026, 241.8994, 241.8994, 241.8994, 241.8994,\n",
      "        241.8994,  36.4127,  36.4127, 241.8994,  36.4127,  36.4127,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 241.8994,   5.2026,   5.2025, 241.8994,   5.2026,\n",
      "          5.2025, 241.8994,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        241.8994, 241.8994, 241.8994, 241.8994,  36.4127,  36.4127,  36.4127,\n",
      "         36.4127, 241.8994, 241.8994, 241.8994,  36.4127,  36.4127,  36.4127,\n",
      "         36.4127,   5.2026,  36.4127,  36.4127,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 287 was 95.2%\n",
      "tensor([1.4712e-08, 3.0428e-06, 2.4859e-06, 2.2003e-06, 2.1208e-06, 9.0990e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8381e-06, 3.6893e-06, 3.6287e-06,\n",
      "        3.9215e-05, 2.7886e-05, 2.7776e-05, 3.4916e-06, 3.4344e-06, 1.5832e-05,\n",
      "        1.5750e-05, 3.1631e-01, 3.0665e-01, 1.1670e+00, 1.1767e+00, 3.2911e-06,\n",
      "        1.5720e-05, 2.8315e-01, 1.2004e+00, 2.5152e-01, 1.2323e+00, 3.2638e-01,\n",
      "        9.5223e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.6594, 142.6564, 160.0032, 165.4020,   4.3031,   4.3034,   4.3018,\n",
      "        242.3318, 242.3318, 242.3318,   4.3041,   4.3036, 242.3318, 242.3318,\n",
      "        242.3318, 242.3318, 242.3318,  36.4923,  36.4923,   4.3037, 242.3318,\n",
      "        242.3318, 242.3318, 242.3318, 242.3318,  36.4923,  36.4923, 242.3318,\n",
      "         36.4923,  36.4923,   5.2026, 242.3318, 242.3318, 242.3318, 242.3318,\n",
      "        242.3318,  36.4923,  36.4923, 242.3318,  36.4923,  36.4923,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 242.3318,   5.2026,   5.2025, 242.3318,   5.2026,\n",
      "          5.2025, 242.3318,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        242.3318, 242.3318, 242.3318, 242.3318,  36.4923,  36.4923,  36.4923,\n",
      "         36.4923, 242.3318, 242.3318, 242.3318,  36.4923,  36.4923,  36.4923,\n",
      "         36.4923,   5.2026,  36.4923,  36.4923,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 288 was 95.2%\n",
      "tensor([1.6544e-23, 3.0308e-06, 2.4765e-06, 2.1916e-06, 2.1134e-06, 3.1378e-09,\n",
      "        2.0878e-09, 1.7420e-09, 1.7188e-09, 3.8228e-06, 3.6768e-06, 3.6196e-06,\n",
      "        3.8529e-05, 2.7388e-05, 2.7298e-05, 3.4805e-06, 3.4225e-06, 1.5545e-05,\n",
      "        1.5457e-05, 3.1518e-01, 3.0565e-01, 1.1634e+00, 1.1729e+00, 3.2782e-06,\n",
      "        1.5421e-05, 2.8220e-01, 1.1965e+00, 2.5087e-01, 1.2282e+00, 3.2529e-01,\n",
      "        9.5239e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.8195, 142.8573, 160.2269, 165.5506,   4.2987,   4.2995,   4.3003,\n",
      "        242.7640, 242.7640, 242.7640,   4.2961,   4.3000, 242.7640, 242.7640,\n",
      "        242.7640, 242.7640, 242.7640,  36.5718,  36.5718,   4.2980, 242.7640,\n",
      "        242.7640, 242.7640, 242.7640, 242.7640,  36.5718,  36.5718, 242.7640,\n",
      "         36.5718,  36.5718,   5.2026, 242.7640, 242.7640, 242.7640, 242.7640,\n",
      "        242.7640,  36.5718,  36.5718, 242.7640,  36.5718,  36.5718,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 242.7640,   5.2026,   5.2025, 242.7640,   5.2026,\n",
      "          5.2025, 242.7640,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        242.7640, 242.7640, 242.7640, 242.7640,  36.5718,  36.5718,  36.5718,\n",
      "         36.5718, 242.7640, 242.7640, 242.7640,  36.5718,  36.5718,  36.5718,\n",
      "         36.5718,   5.2026,  36.5718,  36.5718,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 289 was 95.2%\n",
      "tensor([2.1507e-23, 3.0241e-06, 2.4705e-06, 2.1862e-06, 2.1099e-06, 3.0998e-09,\n",
      "        2.0607e-09, 1.7184e-09, 1.6961e-09, 3.8114e-06, 3.6646e-06, 3.6084e-06,\n",
      "        3.7917e-05, 2.6922e-05, 2.6847e-05, 3.4716e-06, 3.4123e-06, 1.5258e-05,\n",
      "        1.5170e-05, 3.1402e-01, 3.0491e-01, 1.1600e+00, 1.1692e+00, 3.2701e-06,\n",
      "        1.5140e-05, 2.8146e-01, 1.1928e+00, 2.5005e-01, 1.2246e+00, 3.2431e-01,\n",
      "        9.5253e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([117.9797, 143.0582, 160.4505, 165.6993,   4.2943,   4.2947,   4.2922,\n",
      "        243.1961, 243.1961, 243.1961,   4.2944,   4.2943, 243.1961, 243.1961,\n",
      "        243.1961, 243.1961, 243.1961,  36.6514,  36.6514,   4.2954, 243.1961,\n",
      "        243.1961, 243.1961, 243.1961, 243.1961,  36.6514,  36.6514, 243.1961,\n",
      "         36.6514,  36.6514,   5.2026, 243.1961, 243.1961, 243.1961, 243.1961,\n",
      "        243.1961,  36.6514,  36.6514, 243.1961,  36.6514,  36.6514,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 243.1961,   5.2026,   5.2025, 243.1961,   5.2026,\n",
      "          5.2025, 243.1961,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        243.1961, 243.1961, 243.1961, 243.1961,  36.6514,  36.6514,  36.6514,\n",
      "         36.6514, 243.1961, 243.1961, 243.1961,  36.6514,  36.6514,  36.6514,\n",
      "         36.6514,   5.2026,  36.6514,  36.6514,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 290 was 95.2%\n",
      "tensor([0.0000e+00, 3.0162e-06, 2.4643e-06, 2.1811e-06, 2.1055e-06, 3.0597e-09,\n",
      "        2.0331e-09, 1.6949e-09, 1.6730e-09, 3.7975e-06, 3.6531e-06, 3.5990e-06,\n",
      "        3.7257e-05, 2.6453e-05, 2.6374e-05, 3.4589e-06, 3.4025e-06, 1.4975e-05,\n",
      "        1.4889e-05, 3.1300e-01, 3.0382e-01, 1.1564e+00, 1.1656e+00, 3.2585e-06,\n",
      "        1.4852e-05, 2.8059e-01, 1.1890e+00, 2.4939e-01, 1.2206e+00, 3.2327e-01,\n",
      "        9.5268e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([118.1399, 143.2591, 160.6740, 165.8482,   4.2888,   4.2886,   4.2907,\n",
      "        243.6281, 243.6281, 243.6281,   4.2907,   4.2917, 243.6281, 243.6281,\n",
      "        243.6281, 243.6281, 243.6281,  36.7309,  36.7309,   4.2877, 243.6281,\n",
      "        243.6281, 243.6281, 243.6281, 243.6281,  36.7309,  36.7309, 243.6281,\n",
      "         36.7309,  36.7309,   5.2026, 243.6281, 243.6281, 243.6281, 243.6281,\n",
      "        243.6281,  36.7309,  36.7309, 243.6281,  36.7309,  36.7309,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 243.6281,   5.2026,   5.2025, 243.6281,   5.2026,\n",
      "          5.2025, 243.6281,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        243.6281, 243.6281, 243.6281, 243.6281,  36.7309,  36.7309,  36.7309,\n",
      "         36.7309, 243.6281, 243.6281, 243.6281,  36.7309,  36.7309,  36.7309,\n",
      "         36.7309,   5.2026,  36.7309,  36.7309,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 291 was 95.2%\n",
      "tensor([3.9705e-23, 3.0092e-06, 2.4588e-06, 2.1756e-06, 2.1019e-06, 3.0205e-09,\n",
      "        2.0058e-09, 1.6709e-09, 1.6496e-09, 3.7879e-06, 3.6421e-06, 3.5861e-06,\n",
      "        3.6659e-05, 2.5983e-05, 2.5898e-05, 3.4466e-06, 3.3924e-06, 1.4682e-05,\n",
      "        1.4603e-05, 3.1188e-01, 3.0310e-01, 1.1530e+00, 1.1618e+00, 3.2516e-06,\n",
      "        1.4578e-05, 2.7967e-01, 1.1854e+00, 2.4868e-01, 1.2168e+00, 3.2229e-01,\n",
      "        9.5283e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([118.3002, 143.4600, 160.8976, 165.9970,   4.2842,   4.2861,   4.2848,\n",
      "        244.0600, 244.0600, 244.0600,   4.2859,   4.2837, 244.0600, 244.0600,\n",
      "        244.0600, 244.0600, 244.0600,  36.8104,  36.8104,   4.2860, 244.0600,\n",
      "        244.0600, 244.0600, 244.0600, 244.0600,  36.8104,  36.8104, 244.0600,\n",
      "         36.8104,  36.8104,   5.2026, 244.0600, 244.0600, 244.0600, 244.0600,\n",
      "        244.0600,  36.8104,  36.8104, 244.0600,  36.8104,  36.8104,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 244.0600,   5.2026,   5.2025, 244.0600,   5.2026,\n",
      "          5.2025, 244.0600,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        244.0600, 244.0600, 244.0600, 244.0600,  36.8104,  36.8104,  36.8104,\n",
      "         36.8104, 244.0600, 244.0600, 244.0600,  36.8104,  36.8104,  36.8104,\n",
      "         36.8104,   5.2026,  36.8104,  36.8104,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 292 was 95.2%\n",
      "tensor([0.0000e+00, 3.0017e-06, 2.4522e-06, 2.1707e-06, 2.0975e-06, 2.9806e-09,\n",
      "        1.9775e-09, 1.6467e-09, 1.6264e-09, 3.7738e-06, 3.6296e-06, 3.5753e-06,\n",
      "        3.6004e-05, 2.5515e-05, 2.5440e-05, 3.4362e-06, 3.3825e-06, 1.4393e-05,\n",
      "        1.4322e-05, 3.1089e-01, 3.0195e-01, 1.1493e+00, 1.1582e+00, 3.2398e-06,\n",
      "        1.4288e-05, 2.7896e-01, 1.1814e+00, 2.4788e-01, 1.2129e+00, 3.2124e-01,\n",
      "        9.5298e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([118.4604, 143.6608, 161.1212, 166.1459,   4.2797,   4.2778,   4.2812,\n",
      "        244.4917, 244.4917, 244.4917,   4.2821,   4.2821, 244.4917, 244.4917,\n",
      "        244.4917, 244.4917, 244.4917,  36.8899,  36.8899,   4.2804, 244.4917,\n",
      "        244.4917, 244.4917, 244.4917, 244.4917,  36.8899,  36.8899, 244.4917,\n",
      "         36.8899,  36.8899,   5.2026, 244.4917, 244.4917, 244.4917, 244.4917,\n",
      "        244.4917,  36.8899,  36.8899, 244.4917,  36.8899,  36.8899,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 244.4917,   5.2026,   5.2025, 244.4917,   5.2026,\n",
      "          5.2025, 244.4917,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        244.4917, 244.4917, 244.4917, 244.4917,  36.8899,  36.8899,  36.8899,\n",
      "         36.8899, 244.4917, 244.4917, 244.4917,  36.8899,  36.8899,  36.8899,\n",
      "         36.8899,   5.2026,  36.8899,  36.8899,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 293 was 95.3%\n",
      "tensor([1.3443e-08, 2.9980e-06, 2.4497e-06, 2.1679e-06, 2.0968e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7632e-06, 3.6201e-06, 3.5649e-06,\n",
      "        3.5386e-05, 2.5053e-05, 2.4967e-05, 3.4239e-06, 3.3724e-06, 1.4111e-05,\n",
      "        1.4043e-05, 3.0975e-01, 3.0124e-01, 1.1459e+00, 1.1545e+00, 3.2308e-06,\n",
      "        1.4012e-05, 2.7802e-01, 1.1779e+00, 2.4723e-01, 1.2091e+00, 3.2025e-01,\n",
      "        9.5312e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([118.6208, 143.8616, 161.3446, 166.2951,   4.2750,   4.2764,   4.2763,\n",
      "        244.9234, 244.9234, 244.9234,   4.2740,   4.2763, 244.9234, 244.9234,\n",
      "        244.9234, 244.9234, 244.9234,  36.9695,  36.9695,   4.2777, 244.9234,\n",
      "        244.9234, 244.9234, 244.9234, 244.9234,  36.9695,  36.9695, 244.9234,\n",
      "         36.9695,  36.9695,   5.2026, 244.9234, 244.9234, 244.9234, 244.9234,\n",
      "        244.9234,  36.9695,  36.9695, 244.9234,  36.9695,  36.9695,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 244.9234,   5.2026,   5.2025, 244.9234,   5.2026,\n",
      "          5.2025, 244.9234,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        244.9234, 244.9234, 244.9234, 244.9234,  36.9695,  36.9695,  36.9695,\n",
      "         36.9695, 244.9234, 244.9234, 244.9234,  36.9695,  36.9695,  36.9695,\n",
      "         36.9695,   5.2026,  36.9695,  36.9695,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 294 was 95.3%\n",
      "tensor([9.9262e-24, 2.9872e-06, 2.4402e-06, 2.1600e-06, 2.0900e-06, 2.9004e-09,\n",
      "        1.9212e-09, 1.5984e-09, 1.5790e-09, 3.7491e-06, 3.6056e-06, 3.5550e-06,\n",
      "        3.4737e-05, 2.4587e-05, 2.4518e-05, 3.4154e-06, 3.3623e-06, 1.3828e-05,\n",
      "        1.3752e-05, 3.0861e-01, 3.0025e-01, 1.1424e+00, 1.1508e+00, 3.2197e-06,\n",
      "        1.3718e-05, 2.7733e-01, 1.1739e+00, 2.4643e-01, 1.2053e+00, 3.1922e-01,\n",
      "        9.5327e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([118.7811, 144.0624, 161.5678, 166.4443,   4.2704,   4.2701,   4.2727,\n",
      "        245.3549, 245.3549, 245.3549,   4.2723,   4.2726, 245.3549, 245.3549,\n",
      "        245.3549, 245.3549, 245.3549,  37.0490,  37.0490,   4.2700, 245.3549,\n",
      "        245.3549, 245.3549, 245.3549, 245.3549,  37.0490,  37.0490, 245.3549,\n",
      "         37.0490,  37.0490,   5.2026, 245.3549, 245.3549, 245.3549, 245.3549,\n",
      "        245.3549,  37.0490,  37.0490, 245.3549,  37.0490,  37.0490,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 245.3549,   5.2026,   5.2025, 245.3549,   5.2026,\n",
      "          5.2025, 245.3549,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        245.3549, 245.3549, 245.3549, 245.3549,  37.0490,  37.0490,  37.0490,\n",
      "         37.0490, 245.3549, 245.3549, 245.3549,  37.0490,  37.0490,  37.0490,\n",
      "         37.0490,   5.2026,  37.0490,  37.0490,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 295 was 95.3%\n",
      "tensor([0.0000e+00, 2.9801e-06, 2.4346e-06, 2.1545e-06, 2.0860e-06, 2.8607e-09,\n",
      "        1.8939e-09, 1.5744e-09, 1.5555e-09, 3.7386e-06, 3.5955e-06, 3.5425e-06,\n",
      "        3.4146e-05, 2.4127e-05, 2.4044e-05, 3.4015e-06, 3.3522e-06, 1.3541e-05,\n",
      "        1.3477e-05, 3.0760e-01, 2.9945e-01, 1.1389e+00, 1.1471e+00, 3.2123e-06,\n",
      "        1.3448e-05, 2.7638e-01, 1.1703e+00, 2.4569e-01, 1.2015e+00, 3.1821e-01,\n",
      "        9.5342e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([118.9414, 144.2632, 161.7910, 166.5937,   4.2656,   4.2677,   4.2644,\n",
      "        245.7863, 245.7863, 245.7863,   4.2675,   4.2669, 245.7863, 245.7863,\n",
      "        245.7863, 245.7863, 245.7863,  37.1285,  37.1285,   4.2682, 245.7863,\n",
      "        245.7863, 245.7863, 245.7863, 245.7863,  37.1285,  37.1285, 245.7863,\n",
      "         37.1285,  37.1285,   5.2026, 245.7863, 245.7863, 245.7863, 245.7863,\n",
      "        245.7863,  37.1285,  37.1285, 245.7863,  37.1285,  37.1285,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 245.7863,   5.2026,   5.2025, 245.7863,   5.2026,\n",
      "          5.2025, 245.7863,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        245.7863, 245.7863, 245.7863, 245.7863,  37.1285,  37.1285,  37.1285,\n",
      "         37.1285, 245.7863, 245.7863, 245.7863,  37.1285,  37.1285,  37.1285,\n",
      "         37.1285,   5.2026,  37.1285,  37.1285,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 296 was 95.3%\n",
      "tensor([1.3235e-23, 2.9727e-06, 2.4284e-06, 2.1498e-06, 2.0818e-06, 2.8206e-09,\n",
      "        1.8660e-09, 1.5502e-09, 1.5323e-09, 3.7252e-06, 3.5829e-06, 3.5347e-06,\n",
      "        3.3515e-05, 2.3661e-05, 2.3604e-05, 3.3921e-06, 3.3410e-06, 1.3270e-05,\n",
      "        1.3202e-05, 3.0662e-01, 2.9835e-01, 1.1353e+00, 1.1436e+00, 3.2009e-06,\n",
      "        1.3167e-05, 2.7564e-01, 1.1665e+00, 2.4499e-01, 1.1977e+00, 3.1720e-01,\n",
      "        9.5357e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([119.1017, 144.4639, 162.0141, 166.7432,   4.2608,   4.2615,   4.2630,\n",
      "        246.2175, 246.2175, 246.2175,   4.2637,   4.2631, 246.2175, 246.2175,\n",
      "        246.2175, 246.2175, 246.2175,  37.2080,  37.2080,   4.2604, 246.2175,\n",
      "        246.2175, 246.2175, 246.2175, 246.2175,  37.2080,  37.2080, 246.2175,\n",
      "         37.2080,  37.2080,   5.2026, 246.2175, 246.2175, 246.2175, 246.2175,\n",
      "        246.2175,  37.2080,  37.2080, 246.2175,  37.2080,  37.2080,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 246.2175,   5.2026,   5.2025, 246.2175,   5.2026,\n",
      "          5.2025, 246.2175,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        246.2175, 246.2175, 246.2175, 246.2175,  37.2080,  37.2080,  37.2080,\n",
      "         37.2080, 246.2175, 246.2175, 246.2175,  37.2080,  37.2080,  37.2080,\n",
      "         37.2080,   5.2026,  37.2080,  37.2080,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 297 was 95.3%\n",
      "tensor([1.1581e-23, 2.9656e-06, 2.4228e-06, 2.1442e-06, 2.0779e-06, 2.7802e-09,\n",
      "        1.8376e-09, 1.5257e-09, 1.5079e-09, 3.7147e-06, 3.5720e-06, 3.5212e-06,\n",
      "        3.2912e-05, 2.3209e-05, 2.3130e-05, 3.3793e-06, 3.3320e-06, 1.2979e-05,\n",
      "        1.2920e-05, 3.0553e-01, 2.9760e-01, 1.1319e+00, 1.1398e+00, 3.1932e-06,\n",
      "        1.2892e-05, 2.7471e-01, 1.1629e+00, 2.4424e-01, 1.1939e+00, 3.1620e-01,\n",
      "        9.5371e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([119.2621, 144.6646, 162.2371, 166.8928,   4.2572,   4.2578,   4.2581,\n",
      "        246.6487, 246.6487, 246.6487,   4.2556,   4.2573, 246.6487, 246.6487,\n",
      "        246.6487, 246.6487, 246.6487,  37.2875,  37.2875,   4.2587, 246.6487,\n",
      "        246.6487, 246.6487, 246.6487, 246.6487,  37.2875,  37.2875, 246.6487,\n",
      "         37.2875,  37.2875,   5.2026, 246.6487, 246.6487, 246.6487, 246.6487,\n",
      "        246.6487,  37.2875,  37.2875, 246.6487,  37.2875,  37.2875,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 246.6487,   5.2026,   5.2025, 246.6487,   5.2026,\n",
      "          5.2025, 246.6487,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        246.6487, 246.6487, 246.6487, 246.6487,  37.2875,  37.2875,  37.2875,\n",
      "         37.2875, 246.6487, 246.6487, 246.6487,  37.2875,  37.2875,  37.2875,\n",
      "         37.2875,   5.2026,  37.2875,  37.2875,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 298 was 95.3%\n",
      "tensor([1.2383e-08, 2.9614e-06, 2.4189e-06, 2.1414e-06, 2.0765e-06, 6.6174e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7002e-06, 3.5590e-06, 3.5114e-06,\n",
      "        3.2267e-05, 2.2747e-05, 2.2683e-05, 3.3707e-06, 3.3220e-06, 1.2700e-05,\n",
      "        1.2635e-05, 3.0439e-01, 2.9666e-01, 1.1284e+00, 1.1361e+00, 3.1811e-06,\n",
      "        1.2602e-05, 2.7401e-01, 1.1590e+00, 2.4344e-01, 1.1901e+00, 3.1516e-01,\n",
      "        9.5386e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([119.4224, 144.8652, 162.4595, 167.0429,   4.2524,   4.2540,   4.2520,\n",
      "        247.0797, 247.0797, 247.0797,   4.2539,   4.2536, 247.0797, 247.0797,\n",
      "        247.0797, 247.0797, 247.0797,  37.3670,  37.3670,   4.2508, 247.0797,\n",
      "        247.0797, 247.0797, 247.0797, 247.0797,  37.3670,  37.3670, 247.0797,\n",
      "         37.3670,  37.3670,   5.2026, 247.0797, 247.0797, 247.0797, 247.0797,\n",
      "        247.0797,  37.3670,  37.3670, 247.0797,  37.3670,  37.3670,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 247.0797,   5.2026,   5.2025, 247.0797,   5.2026,\n",
      "          5.2025, 247.0797,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        247.0797, 247.0797, 247.0797, 247.0797,  37.3670,  37.3670,  37.3670,\n",
      "         37.3670, 247.0797, 247.0797, 247.0797,  37.3670,  37.3670,  37.3670,\n",
      "         37.3670,   5.2026,  37.3670,  37.3670,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 299 was 95.4%\n",
      "tensor([4.9631e-24, 2.9512e-06, 2.4107e-06, 2.1338e-06, 2.0697e-06, 2.7003e-09,\n",
      "        1.7816e-09, 1.4770e-09, 1.4606e-09, 3.6895e-06, 3.5467e-06, 3.5016e-06,\n",
      "        3.1696e-05, 2.2297e-05, 2.2242e-05, 3.3585e-06, 3.3107e-06, 1.2432e-05,\n",
      "        1.2367e-05, 3.0349e-01, 2.9575e-01, 1.1248e+00, 1.1326e+00, 3.1739e-06,\n",
      "        1.2341e-05, 2.7307e-01, 1.1554e+00, 2.4273e-01, 1.1863e+00, 3.1416e-01,\n",
      "        9.5401e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([119.5828, 145.0658, 162.6819, 167.1930,   4.2474,   4.2456,   4.2496,\n",
      "        247.5107, 247.5107, 247.5107,   4.2480,   4.2488, 247.5107, 247.5107,\n",
      "        247.5107, 247.5107, 247.5107,  37.4465,  37.4465,   4.2491, 247.5107,\n",
      "        247.5107, 247.5107, 247.5107, 247.5107,  37.4465,  37.4465, 247.5107,\n",
      "         37.4465,  37.4465,   5.2026, 247.5107, 247.5107, 247.5107, 247.5107,\n",
      "        247.5107,  37.4465,  37.4465, 247.5107,  37.4465,  37.4465,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 247.5107,   5.2026,   5.2025, 247.5107,   5.2026,\n",
      "          5.2025, 247.5107,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        247.5107, 247.5107, 247.5107, 247.5107,  37.4465,  37.4465,  37.4465,\n",
      "         37.4465, 247.5107, 247.5107, 247.5107,  37.4465,  37.4465,  37.4465,\n",
      "         37.4465,   5.2026,  37.4465,  37.4465,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 300 was 95.4%\n",
      "tensor([4.9631e-24, 2.9439e-06, 2.4045e-06, 2.1284e-06, 2.0662e-06, 2.6565e-09,\n",
      "        1.7509e-09, 1.4505e-09, 1.4342e-09, 3.6767e-06, 3.5378e-06, 3.4900e-06,\n",
      "        3.1045e-05, 2.1830e-05, 2.1753e-05, 3.3466e-06, 3.3021e-06, 1.2136e-05,\n",
      "        1.2077e-05, 3.0223e-01, 2.9494e-01, 1.1215e+00, 1.1288e+00, 3.1627e-06,\n",
      "        1.2041e-05, 2.7233e-01, 1.1516e+00, 2.4202e-01, 1.1825e+00, 3.1317e-01,\n",
      "        9.5415e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([119.7431, 145.2664, 162.9041, 167.3433,   4.2424,   4.2441,   4.2412,\n",
      "        247.9415, 247.9415, 247.9415,   4.2442,   4.2451, 247.9415, 247.9415,\n",
      "        247.9415, 247.9415, 247.9415,  37.5260,  37.5260,   4.2434, 247.9415,\n",
      "        247.9415, 247.9415, 247.9415, 247.9415,  37.5260,  37.5260, 247.9415,\n",
      "         37.5260,  37.5260,   5.2026, 247.9415, 247.9415, 247.9415, 247.9415,\n",
      "        247.9415,  37.5260,  37.5260, 247.9415,  37.5260,  37.5260,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 247.9415,   5.2026,   5.2025, 247.9415,   5.2026,\n",
      "          5.2025, 247.9415,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        247.9415, 247.9415, 247.9415, 247.9415,  37.5260,  37.5260,  37.5260,\n",
      "         37.5260, 247.9415, 247.9415, 247.9415,  37.5260,  37.5260,  37.5260,\n",
      "         37.5260,   5.2026,  37.5260,  37.5260,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 301 was 95.4%\n",
      "tensor([3.9705e-23, 2.9366e-06, 2.3989e-06, 2.1234e-06, 2.0619e-06, 2.6165e-09,\n",
      "        1.7230e-09, 1.4262e-09, 1.4109e-09, 3.6657e-06, 3.5236e-06, 3.4816e-06,\n",
      "        3.0453e-05, 2.1371e-05, 2.1325e-05, 3.3368e-06, 3.2899e-06, 1.1870e-05,\n",
      "        1.1804e-05, 3.0132e-01, 2.9396e-01, 1.1179e+00, 1.1253e+00, 3.1536e-06,\n",
      "        1.1776e-05, 2.7142e-01, 1.1480e+00, 2.4133e-01, 1.1787e+00, 3.1217e-01,\n",
      "        9.5430e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([119.9035, 145.4669, 163.1263, 167.4937,   4.2373,   4.2391,   4.2397,\n",
      "        248.3722, 248.3722, 248.3722,   4.2382,   4.2369, 248.3722, 248.3722,\n",
      "        248.3722, 248.3722, 248.3722,  37.6055,  37.6055,   4.2407, 248.3722,\n",
      "        248.3722, 248.3722, 248.3722, 248.3722,  37.6055,  37.6055, 248.3722,\n",
      "         37.6055,  37.6055,   5.2026, 248.3722, 248.3722, 248.3722, 248.3722,\n",
      "        248.3722,  37.6055,  37.6055, 248.3722,  37.6055,  37.6055,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 248.3722,   5.2026,   5.2025, 248.3722,   5.2026,\n",
      "          5.2025, 248.3722,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        248.3722, 248.3722, 248.3722, 248.3722,  37.6055,  37.6055,  37.6055,\n",
      "         37.6055, 248.3722, 248.3722, 248.3722,  37.6055,  37.6055,  37.6055,\n",
      "         37.6055,   5.2026,  37.6055,  37.6055,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 302 was 95.4%\n",
      "tensor([1.1529e-08, 2.9325e-06, 2.3949e-06, 2.1207e-06, 2.0605e-06, 4.1359e-25,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6527e-06, 3.5131e-06, 3.4682e-06,\n",
      "        2.9822e-05, 2.0931e-05, 2.0865e-05, 3.3260e-06, 3.2832e-06, 1.1581e-05,\n",
      "        1.1526e-05, 3.0019e-01, 2.9301e-01, 1.1144e+00, 1.1216e+00, 3.1426e-06,\n",
      "        1.1487e-05, 2.7077e-01, 1.1442e+00, 2.4054e-01, 1.1750e+00, 3.1118e-01,\n",
      "        9.5445e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([120.0639, 145.6675, 163.3485, 167.6442,   4.2324,   4.2353,   4.2335,\n",
      "        248.8028, 248.8028, 248.8028,   4.2343,   4.2353, 248.8028, 248.8028,\n",
      "        248.8028, 248.8028, 248.8028,  37.6850,  37.6850,   4.2327, 248.8028,\n",
      "        248.8028, 248.8028, 248.8028, 248.8028,  37.6850,  37.6850, 248.8028,\n",
      "         37.6850,  37.6850,   5.2026, 248.8028, 248.8028, 248.8028, 248.8028,\n",
      "        248.8028,  37.6850,  37.6850, 248.8028,  37.6850,  37.6850,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 248.8028,   5.2026,   5.2025, 248.8028,   5.2026,\n",
      "          5.2025, 248.8028,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        248.8028, 248.8028, 248.8028, 248.8028,  37.6850,  37.6850,  37.6850,\n",
      "         37.6850, 248.8028, 248.8028, 248.8028,  37.6850,  37.6850,  37.6850,\n",
      "         37.6850,   5.2026,  37.6850,  37.6850,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 303 was 95.4%\n",
      "tensor([0.0000e+00, 2.9225e-06, 2.3871e-06, 2.1132e-06, 2.0540e-06, 2.5333e-09,\n",
      "        1.6644e-09, 1.3753e-09, 1.3609e-09, 3.6423e-06, 3.5000e-06, 3.4592e-06,\n",
      "        2.9236e-05, 2.0460e-05, 2.0417e-05, 3.3151e-06, 3.2699e-06, 1.1309e-05,\n",
      "        1.1246e-05, 2.9924e-01, 2.9218e-01, 1.1109e+00, 1.1180e+00, 3.1353e-06,\n",
      "        1.1218e-05, 2.6982e-01, 1.1406e+00, 2.3981e-01, 1.1712e+00, 3.1015e-01,\n",
      "        9.5459e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([120.2243, 145.8679, 163.5706, 167.7948,   4.2284,   4.2268,   4.2299,\n",
      "        249.2333, 249.2333, 249.2333,   4.2295,   4.2295, 249.2333, 249.2333,\n",
      "        249.2333, 249.2333, 249.2333,  37.7644,  37.7644,   4.2310, 249.2333,\n",
      "        249.2333, 249.2333, 249.2333, 249.2333,  37.7644,  37.7644, 249.2333,\n",
      "         37.7644,  37.7644,   5.2026, 249.2333, 249.2333, 249.2333, 249.2333,\n",
      "        249.2333,  37.7644,  37.7644, 249.2333,  37.7644,  37.7644,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 249.2333,   5.2026,   5.2025, 249.2333,   5.2026,\n",
      "          5.2025, 249.2333,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        249.2333, 249.2333, 249.2333, 249.2333,  37.7644,  37.7644,  37.7644,\n",
      "         37.7644, 249.2333, 249.2333, 249.2333,  37.7644,  37.7644,  37.7644,\n",
      "         37.7644,   5.2026,  37.7644,  37.7644,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 304 was 95.4%\n",
      "tensor([4.9631e-24, 2.9149e-06, 2.3808e-06, 2.1078e-06, 2.0502e-06, 2.4898e-09,\n",
      "        1.6339e-09, 1.3489e-09, 1.3347e-09, 3.6280e-06, 3.4919e-06, 3.4478e-06,\n",
      "        2.8597e-05, 2.0011e-05, 1.9945e-05, 3.3030e-06, 3.2620e-06, 1.1023e-05,\n",
      "        1.0969e-05, 2.9806e-01, 2.9128e-01, 1.1075e+00, 1.1144e+00, 3.1236e-06,\n",
      "        1.0923e-05, 2.6905e-01, 1.1368e+00, 2.3913e-01, 1.1674e+00, 3.0917e-01,\n",
      "        9.5474e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([120.3846, 146.0683, 163.7921, 167.9458,   4.2232,   4.2253,   4.2236,\n",
      "        249.6637, 249.6637, 249.6637,   4.2245,   4.2267, 249.6637, 249.6637,\n",
      "        249.6637, 249.6637, 249.6637,  37.8439,  37.8439,   4.2230, 249.6637,\n",
      "        249.6637, 249.6637, 249.6637, 249.6637,  37.8439,  37.8439, 249.6637,\n",
      "         37.8439,  37.8439,   5.2026, 249.6637, 249.6637, 249.6637, 249.6637,\n",
      "        249.6637,  37.8439,  37.8439, 249.6637,  37.8439,  37.8439,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 249.6637,   5.2026,   5.2025, 249.6637,   5.2026,\n",
      "          5.2025, 249.6637,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        249.6637, 249.6637, 249.6637, 249.6637,  37.8439,  37.8439,  37.8439,\n",
      "         37.8439, 249.6637, 249.6637, 249.6637,  37.8439,  37.8439,  37.8439,\n",
      "         37.8439,   5.2026,  37.8439,  37.8439,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 305 was 95.4%\n",
      "tensor([4.9631e-24, 2.9079e-06, 2.3754e-06, 2.1026e-06, 2.0461e-06, 2.4491e-09,\n",
      "        1.6053e-09, 1.3238e-09, 1.3103e-09, 3.6183e-06, 3.4765e-06, 3.4385e-06,\n",
      "        2.8026e-05, 1.9551e-05, 1.9515e-05, 3.2936e-06, 3.2494e-06, 1.0754e-05,\n",
      "        1.0689e-05, 2.9712e-01, 2.9044e-01, 1.1040e+00, 1.1107e+00, 3.1164e-06,\n",
      "        1.0661e-05, 2.6812e-01, 1.1333e+00, 2.3839e-01, 1.1637e+00, 3.0818e-01,\n",
      "        9.5488e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([120.5450, 146.2687, 164.0136, 168.0968,   4.2191,   4.2192,   4.2200,\n",
      "        250.0940, 250.0940, 250.0940,   4.2197,   4.2185, 250.0940, 250.0940,\n",
      "        250.0940, 250.0940, 250.0940,  37.9234,  37.9234,   4.2213, 250.0940,\n",
      "        250.0940, 250.0940, 250.0940, 250.0940,  37.9234,  37.9234, 250.0940,\n",
      "         37.9234,  37.9234,   5.2026, 250.0940, 250.0940, 250.0940, 250.0940,\n",
      "        250.0940,  37.9234,  37.9234, 250.0940,  37.9234,  37.9234,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 250.0940,   5.2026,   5.2025, 250.0940,   5.2026,\n",
      "          5.2025, 250.0940,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        250.0940, 250.0940, 250.0940, 250.0940,  37.9234,  37.9234,  37.9234,\n",
      "         37.9234, 250.0940, 250.0940, 250.0940,  37.9234,  37.9234,  37.9234,\n",
      "         37.9234,   5.2026,  37.9234,  37.9234,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 306 was 95.5%\n",
      "tensor([3.3087e-24, 2.8880e-06, 2.3613e-06, 2.0929e-06, 2.0378e-06, 2.4190e-09,\n",
      "        1.5837e-09, 1.3047e-09, 1.2913e-09, 3.5806e-06, 3.4510e-06, 3.4117e-06,\n",
      "        2.7554e-05, 1.9222e-05, 1.9161e-05, 3.2732e-06, 3.2347e-06, 1.0534e-05,\n",
      "        1.0482e-05, 2.9601e-01, 2.8943e-01, 1.1008e+00, 1.1074e+00, 3.1043e-06,\n",
      "        1.0430e-05, 2.6742e-01, 1.1296e+00, 2.3763e-01, 1.1600e+00, 3.0714e-01,\n",
      "        9.5502e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([120.7018, 146.4688, 164.2404, 168.2452,   4.2167,   4.2156,   4.2116,\n",
      "        250.5242, 250.5242, 250.5242,   4.2140,   4.2146, 250.5242, 250.5242,\n",
      "        250.5242, 250.5242, 250.5242,  38.0029,  38.0029,   4.2165, 250.5242,\n",
      "        250.5242, 250.5242, 250.5242, 250.5242,  38.0029,  38.0029, 250.5242,\n",
      "         38.0029,  38.0029,   5.2026, 250.5242, 250.5242, 250.5242, 250.5242,\n",
      "        250.5242,  38.0029,  38.0029, 250.5242,  38.0029,  38.0029,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 250.5242,   5.2026,   5.2025, 250.5242,   5.2026,\n",
      "          5.2025, 250.5242,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        250.5242, 250.5242, 250.5242, 250.5242,  38.0029,  38.0029,  38.0029,\n",
      "         38.0029, 250.5242, 250.5242, 250.5242,  38.0029,  38.0029,  38.0029,\n",
      "         38.0029,   5.2026,  38.0029,  38.0029,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 307 was 95.5%\n",
      "tensor([0.0000e+00, 2.8940e-06, 2.3635e-06, 2.0925e-06, 2.0380e-06, 2.4008e-09,\n",
      "        1.5721e-09, 1.2963e-09, 1.2836e-09, 3.5907e-06, 3.4562e-06, 3.4195e-06,\n",
      "        2.7207e-05, 1.9001e-05, 1.8954e-05, 3.2729e-06, 3.2324e-06, 1.0425e-05,\n",
      "        1.0374e-05, 2.9511e-01, 2.8860e-01, 1.0971e+00, 1.1036e+00, 3.0942e-06,\n",
      "        1.0331e-05, 2.6655e-01, 1.1259e+00, 2.3687e-01, 1.1564e+00, 3.0617e-01,\n",
      "        9.5517e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([120.8621, 146.6692, 164.4612, 168.3969,   4.2054,   4.2106,   4.2102,\n",
      "        250.9543, 250.9543, 250.9543,   4.2123,   4.2109, 250.9543, 250.9543,\n",
      "        250.9543, 250.9543, 250.9543,  38.0823,  38.0823,   4.2108, 250.9543,\n",
      "        250.9543, 250.9543, 250.9543, 250.9543,  38.0823,  38.0823, 250.9543,\n",
      "         38.0823,  38.0823,   5.2026, 250.9543, 250.9543, 250.9543, 250.9543,\n",
      "        250.9543,  38.0823,  38.0823, 250.9543,  38.0823,  38.0823,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 250.9543,   5.2026,   5.2025, 250.9543,   5.2026,\n",
      "          5.2025, 250.9543,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        250.9543, 250.9543, 250.9543, 250.9543,  38.0823,  38.0823,  38.0823,\n",
      "         38.0823, 250.9543, 250.9543, 250.9543,  38.0823,  38.0823,  38.0823,\n",
      "         38.0823,   5.2026,  38.0823,  38.0823,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 308 was 95.5%\n",
      "tensor([7.1786e-06, 3.2911e-05, 1.1548e-05, 9.9493e-07, 1.1858e-19, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4260e-05, 3.6248e-05, 3.3404e-05,\n",
      "        2.6678e-05, 1.8580e-05, 1.8524e-05, 1.6678e-05, 1.5691e-05, 1.0164e-05,\n",
      "        1.0121e-05, 2.9401e-01, 2.8761e-01, 1.0938e+00, 1.1003e+00, 2.6442e-06,\n",
      "        1.0074e-05, 2.6570e-01, 1.1224e+00, 2.3622e-01, 1.1526e+00, 3.0517e-01,\n",
      "        9.5531e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([121.0182, 146.8678, 164.6791, 168.5495,   4.2046,   4.2062,   4.2038,\n",
      "        251.3842, 251.3842, 251.3842,   4.2037,   4.2006, 251.3842, 251.3842,\n",
      "        251.3842, 251.3842, 251.3842,  38.1618,  38.1618,   4.2125, 251.3842,\n",
      "        251.3842, 251.3842, 251.3842, 251.3842,  38.1618,  38.1618, 251.3842,\n",
      "         38.1618,  38.1618,   5.2026, 251.3842, 251.3842, 251.3842, 251.3842,\n",
      "        251.3842,  38.1618,  38.1618, 251.3842,  38.1618,  38.1618,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 251.3842,   5.2026,   5.2025, 251.3842,   5.2026,\n",
      "          5.2025, 251.3842,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        251.3842, 251.3842, 251.3842, 251.3842,  38.1618,  38.1618,  38.1618,\n",
      "         38.1618, 251.3842, 251.3842, 251.3842,  38.1618,  38.1618,  38.1618,\n",
      "         38.1618,   5.2026,  38.1618,  38.1618,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 309 was 95.5%\n",
      "tensor([8.2718e-24, 2.8801e-06, 2.3505e-06, 2.0824e-06, 2.0298e-06, 2.6504e-09,\n",
      "        1.7557e-09, 1.4657e-09, 1.4534e-09, 3.5648e-06, 3.4344e-06, 3.3974e-06,\n",
      "        2.9700e-05, 2.1126e-05, 2.1105e-05, 3.2519e-06, 3.2147e-06, 1.1887e-05,\n",
      "        1.1857e-05, 2.9274e-01, 2.8639e-01, 1.0907e+00, 1.0970e+00, 3.0727e-06,\n",
      "        1.1870e-05, 2.6513e-01, 1.1185e+00, 2.3547e-01, 1.1484e+00, 3.0423e-01,\n",
      "        9.5545e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([121.1798, 147.0685, 164.9039, 168.6982,   4.1976,   4.1996,   4.2011,\n",
      "        251.8141, 251.8141, 251.8141,   4.2009,   8.3121, 251.8141, 251.8141,\n",
      "        251.8141, 251.8141, 251.8141,  38.2412,  38.2412,   4.2043, 251.8141,\n",
      "        251.8141, 251.8141, 251.8141, 251.8141,  38.2412,  38.2412, 251.8141,\n",
      "         38.2412,  38.2412,   5.2026, 251.8141, 251.8141, 251.8141, 251.8141,\n",
      "        251.8141,  38.2412,  38.2412, 251.8141,  38.2412,  38.2412,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 251.8141,   5.2026,   5.2025, 251.8141,   5.2026,\n",
      "          5.2025, 251.8141,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        251.8141, 251.8141, 251.8141, 251.8141,  38.2412,  38.2412,  38.2412,\n",
      "         38.2412, 251.8141, 251.8141, 251.8141,  38.2412,  38.2412,  38.2412,\n",
      "         38.2412,   5.2026,  38.2412,  38.2412,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 310 was 94.0%\n",
      "tensor([4.3512e-06, 2.7620e-05, 0.0000e+00, 3.7185e-06, 1.3450e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5305e-06, 2.6799e-06, 7.3847e-06,\n",
      "        1.7234e-04, 4.5473e-05, 1.1203e-04, 6.4688e-06, 9.4655e-06, 8.3255e-05,\n",
      "        1.8980e-05, 2.5950e-01, 4.9669e-01, 1.5765e+00, 1.3445e+00, 6.3239e-06,\n",
      "        7.0501e-05, 2.3173e-01, 1.6061e+00, 4.1030e-01, 1.4323e+00, 4.4456e-01,\n",
      "        9.4040e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([121.0566, 147.4238, 163.7565, 169.9356,   8.3100,   8.3121,   8.3134,\n",
      "        252.2439, 252.2439, 252.2439,   8.3133,   8.3107, 252.2439, 252.2439,\n",
      "        252.2439, 252.2439, 252.2439,  38.3207,  38.3207,   4.1967, 252.2439,\n",
      "        252.2439, 252.2439, 252.2439, 252.2439,  38.3207,  38.3207, 252.2439,\n",
      "         38.3207,  38.3207,   5.2026, 252.2439, 252.2439, 252.2439, 252.2439,\n",
      "        252.2439,  38.3207,  38.3207, 252.2439,  38.3207,  38.3207,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 252.2439,   5.2026,   5.2025, 252.2439,   5.2026,\n",
      "          5.2025, 252.2439,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        252.2439, 252.2439, 252.2439, 252.2439,  38.3207,  38.3207,  38.3207,\n",
      "         38.3207, 252.2439, 252.2439, 252.2439,  38.3207,  38.3207,  38.3207,\n",
      "         38.3207,   5.2026,  38.3207,  38.3207,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 311 was 89.8%\n",
      "tensor([2.8609e-07, 5.8891e-06, 4.8011e-06, 4.1726e-06, 4.0083e-06, 3.0888e-08,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9833e-06, 7.9166e-06, 7.7623e-06,\n",
      "        2.3050e-03, 1.0150e-03, 1.0037e-03, 7.5079e-06, 7.3593e-06, 6.4096e-04,\n",
      "        6.3343e-04, 7.2426e-01, 6.9921e-01, 2.4252e+00, 2.4499e+00, 1.2587e-05,\n",
      "        6.8669e-04, 5.4660e-01, 2.6027e+00, 4.8924e-01, 2.6586e+00, 6.9829e-01,\n",
      "        8.9858e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([121.3720, 147.8020, 164.3039, 170.1641,   8.3097,   8.3108,   8.3115,\n",
      "        252.6736, 252.6736, 252.6736,   8.3118,   8.3097, 252.6736, 252.6736,\n",
      "        252.6736, 252.6736, 252.6736,  38.4002,  38.4002,   8.3099, 252.6736,\n",
      "        252.6736, 252.6736, 252.6736, 252.6736,  38.4002,  38.4002, 252.6736,\n",
      "         38.4002,  38.4002,   5.2026, 252.6736, 252.6736, 252.6736, 252.6736,\n",
      "        252.6736,  38.4002,  38.4002, 252.6736,  38.4002,  38.4002,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 252.6736,   5.2026,   5.2025, 252.6736,   5.2026,\n",
      "          5.2025, 252.6736,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        252.6736, 252.6736, 252.6736, 252.6736,  38.4002,  38.4002,  38.4002,\n",
      "         38.4002, 252.6736, 252.6736, 252.6736,  38.4002,  38.4002,  38.4002,\n",
      "         38.4002,   5.2026,  38.4002,  38.4002,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(50.3487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 312 was 89.7%\n",
      "tensor([0.0000e+00, 2.5748e-05, 4.1518e-04, 9.9553e-04, 0.0000e+00, 9.5012e-08,\n",
      "        9.3181e-09, 4.7631e-06, 8.6452e-04, 1.3855e-05, 1.3307e-05, 1.3057e-05,\n",
      "        1.5036e-04, 2.9990e-05, 0.0000e+00, 1.2436e-05, 1.2209e-05, 0.0000e+00,\n",
      "        0.0000e+00, 6.6635e-01, 6.4401e-01, 2.5076e+00, 2.5302e+00, 1.1653e-05,\n",
      "        0.0000e+00, 5.9652e-01, 2.5775e+00, 5.2519e-01, 2.6491e+00, 7.4286e-01,\n",
      "        8.9735e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([121.6679, 148.1868, 164.7227, 170.4419,   8.3091,   8.3097,   8.3102,\n",
      "        253.1032, 253.1032, 253.1032,   8.3100,   8.3091, 253.1032, 253.1032,\n",
      "        253.1032, 253.1032, 253.1032,  38.4796,  38.4796,   8.3093, 253.1032,\n",
      "        253.1032, 253.1032, 253.1032, 253.1032,  38.4796,  38.4796, 253.1032,\n",
      "         38.4796,  38.4796,   5.2026, 253.1032, 253.1032, 253.1032, 253.1032,\n",
      "        253.1032,  38.4796,  38.4796, 253.1032,  38.4796,  38.4796,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 253.1032,   5.2026,   5.2025, 253.1032,   5.2026,\n",
      "          5.2025, 253.1032,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        253.1032, 253.1032, 253.1032, 253.1032,  38.4796,  38.4796,  38.4796,\n",
      "         38.4796, 253.1032, 253.1032, 253.1032,  38.4796,  38.4796,  38.4796,\n",
      "         38.4796,   5.2026,  38.4796,  38.4796,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 313 was 89.4%\n",
      "tensor([0.0000e+00, 4.3392e-06, 1.2967e-06, 1.8221e-05, 2.0329e-20, 2.6498e-07,\n",
      "        1.9232e-07, 0.0000e+00, 0.0000e+00, 8.6145e-06, 8.2872e-06, 8.1493e-06,\n",
      "        1.7097e-03, 1.3852e-03, 1.3628e-03, 7.7631e-06, 7.6264e-06, 9.3380e-04,\n",
      "        9.1655e-04, 6.9874e-01, 6.7616e-01, 2.5871e+00, 2.6098e+00, 7.3084e-06,\n",
      "        8.6896e-04, 6.2647e-01, 2.6599e+00, 5.5183e-01, 2.7359e+00, 7.3710e-01,\n",
      "        8.9400e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([121.9863, 148.5827, 165.1440, 170.7584,   8.3087,   8.3086,   8.3082,\n",
      "        253.5326, 253.5326, 253.5326,   8.3086,   8.3084, 253.5326, 253.5326,\n",
      "        253.5326, 253.5326, 253.5326,  38.5591,  38.5591,   8.3087, 253.5326,\n",
      "        253.5326, 253.5326, 253.5326, 253.5326,  38.5591,  38.5591, 253.5326,\n",
      "         38.5591,  38.5591,   5.2026, 253.5326, 253.5326, 253.5326, 253.5326,\n",
      "        253.5326,  38.5591,  38.5591, 253.5326,  38.5591,  38.5591,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 253.5326,   5.2026,   5.2025, 253.5326,   5.2026,\n",
      "          5.2025, 253.5326,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        253.5326, 253.5326, 253.5326, 253.5326,  38.5591,  38.5591,  38.5591,\n",
      "         38.5591, 253.5326, 253.5326, 253.5326,  38.5591,  38.5591,  38.5591,\n",
      "         38.5591,   5.2026,  38.5591,  38.5591,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 314 was 89.4%\n",
      "tensor([1.1626e-05, 5.8997e-06, 4.8930e-06, 1.6602e-19, 5.4396e-07, 0.0000e+00,\n",
      "        0.0000e+00, 1.5151e-06, 1.4817e-06, 8.5841e-06, 8.2590e-06, 8.1259e-06,\n",
      "        1.6824e-03, 1.3627e-03, 1.3413e-03, 7.7380e-06, 7.6033e-06, 9.1784e-04,\n",
      "        9.0101e-04, 6.9627e-01, 6.7422e-01, 2.5798e+00, 2.6018e+00, 7.2865e-06,\n",
      "        8.5424e-04, 6.2471e-01, 2.6518e+00, 5.5031e-01, 2.7276e+00, 7.3490e-01,\n",
      "        8.9432e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([122.2895, 148.9786, 165.5569, 171.0953,   8.3067,   8.3078,   8.3078,\n",
      "        253.9620, 253.9620, 253.9620,   8.3074,   8.3078, 253.9620, 253.9620,\n",
      "        253.9620, 253.9620, 253.9620,  38.6385,  38.6385,   8.3072, 253.9620,\n",
      "        253.9620, 253.9620, 253.9620, 253.9620,  38.6385,  38.6385, 253.9620,\n",
      "         38.6385,  38.6385,   5.2026, 253.9620, 253.9620, 253.9620, 253.9620,\n",
      "        253.9620,  38.6385,  38.6385, 253.9620,  38.6385,  38.6385,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 253.9620,   5.2026,   5.2025, 253.9620,   5.2026,\n",
      "          5.2025, 253.9620,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        253.9620, 253.9620, 253.9620, 253.9620,  38.6385,  38.6385,  38.6385,\n",
      "         38.6385, 253.9620, 253.9620, 253.9620,  38.6385,  38.6385,  38.6385,\n",
      "         38.6385,   5.2026,  38.6385,  38.6385,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 315 was 89.4%\n",
      "tensor([1.1266e-05, 5.8929e-06, 4.9018e-06, 1.6178e-19, 6.6681e-07, 0.0000e+00,\n",
      "        0.0000e+00, 1.4639e-06, 1.4322e-06, 8.5579e-06, 8.2327e-06, 8.1022e-06,\n",
      "        1.6587e-03, 1.3431e-03, 1.3224e-03, 7.7137e-06, 7.5811e-06, 9.0358e-04,\n",
      "        8.8726e-04, 6.9394e-01, 6.7235e-01, 2.5726e+00, 2.5942e+00, 7.2668e-06,\n",
      "        8.4149e-04, 6.2306e-01, 2.6440e+00, 5.4879e-01, 2.7196e+00, 7.3273e-01,\n",
      "        8.9463e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([122.5919, 149.3730, 165.9666, 171.4296,   8.3063,   8.3064,   8.3058,\n",
      "        254.3913, 254.3913, 254.3913,   8.3065,   8.3067, 254.3913, 254.3913,\n",
      "        254.3913, 254.3913, 254.3913,  38.7179,  38.7179,   8.3067, 254.3913,\n",
      "        254.3913, 254.3913, 254.3913, 254.3913,  38.7179,  38.7179, 254.3913,\n",
      "         38.7179,  38.7179,   5.2026, 254.3913, 254.3913, 254.3913, 254.3913,\n",
      "        254.3913,  38.7179,  38.7179, 254.3913,  38.7179,  38.7179,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 254.3913,   5.2026,   5.2025, 254.3913,   5.2026,\n",
      "          5.2025, 254.3913,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        254.3913, 254.3913, 254.3913, 254.3913,  38.7179,  38.7179,  38.7179,\n",
      "         38.7179, 254.3913, 254.3913, 254.3913,  38.7179,  38.7179,  38.7179,\n",
      "         38.7179,   5.2026,  38.7179,  38.7179,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 316 was 89.4%\n",
      "tensor([2.8708e-06, 6.3385e-06, 5.0379e-06, 0.0000e+00, 4.7204e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.8643e-07, 0.0000e+00, 8.5307e-06, 8.2085e-06, 8.0810e-06,\n",
      "        1.6581e-03, 1.3459e-03, 1.3263e-03, 7.6901e-06, 7.5603e-06, 9.0824e-04,\n",
      "        8.9268e-04, 6.9158e-01, 6.7037e-01, 2.5649e+00, 2.5861e+00, 7.2470e-06,\n",
      "        8.4810e-04, 6.2131e-01, 2.6357e+00, 5.4725e-01, 2.7110e+00, 7.3046e-01,\n",
      "        8.9495e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([122.9080, 149.7636, 166.3814, 171.7418,   8.3054,   8.3054,   8.3054,\n",
      "        254.8205, 254.8205, 254.8205,   8.3056,   8.3053, 254.8205, 254.8205,\n",
      "        254.8205, 254.8205, 254.8205,  38.7974,  38.7974,   8.3049, 254.8205,\n",
      "        254.8205, 254.8205, 254.8205, 254.8205,  38.7974,  38.7974, 254.8205,\n",
      "         38.7974,  38.7974,   5.2026, 254.8205, 254.8205, 254.8205, 254.8205,\n",
      "        254.8205,  38.7974,  38.7974, 254.8205,  38.7974,  38.7974,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 254.8205,   5.2026,   5.2025, 254.8205,   5.2026,\n",
      "          5.2025, 254.8205,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        254.8205, 254.8205, 254.8205, 254.8205,  38.7974,  38.7974,  38.7974,\n",
      "         38.7974, 254.8205, 254.8205, 254.8205,  38.7974,  38.7974,  38.7974,\n",
      "         38.7974,   5.2026,  38.7974,  38.7974,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 317 was 89.5%\n",
      "tensor([2.8487e-06, 6.3708e-06, 5.0223e-06, 0.0000e+00, 4.7067e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.8344e-07, 0.0000e+00, 8.5032e-06, 8.1824e-06, 8.0571e-06,\n",
      "        1.6353e-03, 1.3271e-03, 1.3081e-03, 7.6656e-06, 7.5395e-06, 8.9461e-04,\n",
      "        8.7975e-04, 6.8925e-01, 6.6855e-01, 2.5578e+00, 2.5786e+00, 7.2278e-06,\n",
      "        8.3595e-04, 6.1966e-01, 2.6280e+00, 5.4577e-01, 2.7031e+00, 7.2832e-01,\n",
      "        8.9526e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([123.2232, 150.1525, 166.7943, 172.0532,   8.3046,   8.3043,   8.3040,\n",
      "        255.2496, 255.2496, 255.2496,   8.3037,   8.3047, 255.2496, 255.2496,\n",
      "        255.2496, 255.2496, 255.2496,  38.8768,  38.8768,   8.3045, 255.2496,\n",
      "        255.2496, 255.2496, 255.2496, 255.2496,  38.8768,  38.8768, 255.2496,\n",
      "         38.8768,  38.8768,   5.2026, 255.2496, 255.2496, 255.2496, 255.2496,\n",
      "        255.2496,  38.8768,  38.8768, 255.2496,  38.8768,  38.8768,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 255.2496,   5.2026,   5.2025, 255.2496,   5.2026,\n",
      "          5.2025, 255.2496,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        255.2496, 255.2496, 255.2496, 255.2496,  38.8768,  38.8768,  38.8768,\n",
      "         38.8768, 255.2496, 255.2496, 255.2496,  38.8768,  38.8768,  38.8768,\n",
      "         38.8768,   5.2026,  38.8768,  38.8768,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 318 was 89.5%\n",
      "tensor([2.8272e-06, 6.4144e-06, 5.0070e-06, 0.0000e+00, 4.6937e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.8053e-07, 0.0000e+00, 8.4759e-06, 8.1566e-06, 8.0351e-06,\n",
      "        1.6131e-03, 1.3089e-03, 1.2908e-03, 7.6427e-06, 7.5185e-06, 8.8173e-04,\n",
      "        8.6730e-04, 6.8691e-01, 6.6675e-01, 2.5509e+00, 2.5711e+00, 7.2078e-06,\n",
      "        8.2424e-04, 6.1803e-01, 2.6204e+00, 5.4435e-01, 2.6953e+00, 7.2622e-01,\n",
      "        8.9556e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([123.5385, 150.5406, 167.2062, 172.3652,   8.3029,   8.3034,   8.3036,\n",
      "        255.6786, 255.6786, 255.6786,   8.3032,   8.3027, 255.6786, 255.6786,\n",
      "        255.6786, 255.6786, 255.6786,  38.9562,  38.9562,   8.3033, 255.6786,\n",
      "        255.6786, 255.6786, 255.6786, 255.6786,  38.9562,  38.9562, 255.6786,\n",
      "         38.9562,  38.9562,   5.2026, 255.6786, 255.6786, 255.6786, 255.6786,\n",
      "        255.6786,  38.9562,  38.9562, 255.6786,  38.9562,  38.9562,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 255.6786,   5.2026,   5.2025, 255.6786,   5.2026,\n",
      "          5.2025, 255.6786,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        255.6786, 255.6786, 255.6786, 255.6786,  38.9562,  38.9562,  38.9562,\n",
      "         38.9562, 255.6786, 255.6786, 255.6786,  38.9562,  38.9562,  38.9562,\n",
      "         38.9562,   5.2026,  38.9562,  38.9562,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 319 was 89.5%\n",
      "tensor([2.8061e-06, 6.4507e-06, 4.9918e-06, 0.0000e+00, 4.6807e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.7769e-07, 0.0000e+00, 8.4496e-06, 8.1311e-06, 8.0115e-06,\n",
      "        1.5917e-03, 1.2914e-03, 1.2737e-03, 7.6181e-06, 7.4983e-06, 8.6914e-04,\n",
      "        8.5540e-04, 6.8461e-01, 6.6490e-01, 2.5439e+00, 2.5637e+00, 7.1886e-06,\n",
      "        8.1311e-04, 6.1644e-01, 2.6127e+00, 5.4291e-01, 2.6875e+00, 7.2411e-01,\n",
      "        8.9586e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([123.8529, 150.9271, 167.6164, 172.6763,   8.3020,   8.3020,   8.3017,\n",
      "        256.1076, 256.1076, 256.1076,   8.3023,   8.3023, 256.1076, 256.1076,\n",
      "        256.1076, 256.1076, 256.1076,  39.0357,  39.0357,   8.3025, 256.1076,\n",
      "        256.1076, 256.1076, 256.1076, 256.1076,  39.0357,  39.0357, 256.1076,\n",
      "         39.0357,  39.0357,   5.2026, 256.1076, 256.1076, 256.1076, 256.1076,\n",
      "        256.1076,  39.0357,  39.0357, 256.1076,  39.0357,  39.0357,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 256.1076,   5.2026,   5.2025, 256.1076,   5.2026,\n",
      "          5.2025, 256.1076,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        256.1076, 256.1076, 256.1076, 256.1076,  39.0357,  39.0357,  39.0357,\n",
      "         39.0357, 256.1076, 256.1076, 256.1076,  39.0357,  39.0357,  39.0357,\n",
      "         39.0357,   5.2026,  39.0357,  39.0357,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 320 was 89.6%\n",
      "tensor([2.7853e-06, 6.4883e-06, 4.9770e-06, 3.8116e-20, 4.6678e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.7488e-07, 0.0000e+00, 8.4224e-06, 8.1058e-06, 7.9899e-06,\n",
      "        1.5705e-03, 1.2740e-03, 1.2571e-03, 7.5945e-06, 7.4770e-06, 8.5696e-04,\n",
      "        8.4363e-04, 6.8231e-01, 6.6309e-01, 2.5370e+00, 2.5563e+00, 7.1689e-06,\n",
      "        8.0199e-04, 6.1479e-01, 2.6052e+00, 5.4153e-01, 2.6796e+00, 7.2202e-01,\n",
      "        8.9615e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([124.1665, 151.3120, 168.0247, 172.9864,   8.3008,   8.3013,   8.3013,\n",
      "        256.5364, 256.5364, 256.5364,   8.3014,   8.3009, 256.5364, 256.5364,\n",
      "        256.5364, 256.5364, 256.5364,  39.1151,  39.1151,   8.3006, 256.5364,\n",
      "        256.5364, 256.5364, 256.5364, 256.5364,  39.1151,  39.1151, 256.5364,\n",
      "         39.1151,  39.1151,   5.2026, 256.5364, 256.5364, 256.5364, 256.5364,\n",
      "        256.5364,  39.1151,  39.1151, 256.5364,  39.1151,  39.1151,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 256.5364,   5.2026,   5.2025, 256.5364,   5.2026,\n",
      "          5.2025, 256.5364,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        256.5364, 256.5364, 256.5364, 256.5364,  39.1151,  39.1151,  39.1151,\n",
      "         39.1151, 256.5364, 256.5364, 256.5364,  39.1151,  39.1151,  39.1151,\n",
      "         39.1151,   5.2026,  39.1151,  39.1151,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 321 was 89.6%\n",
      "tensor([2.7648e-06, 6.5085e-06, 4.9621e-06, 0.0000e+00, 4.6549e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.7212e-07, 0.0000e+00, 8.3963e-06, 8.0804e-06, 7.9668e-06,\n",
      "        1.5498e-03, 1.2569e-03, 1.2405e-03, 7.5710e-06, 7.4569e-06, 8.4468e-04,\n",
      "        8.3193e-04, 6.8008e-01, 6.6130e-01, 2.5302e+00, 2.5490e+00, 7.1505e-06,\n",
      "        7.9106e-04, 6.1319e-01, 2.5977e+00, 5.4009e-01, 2.6720e+00, 7.1995e-01,\n",
      "        8.9645e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([124.4793, 151.6954, 168.4314, 173.2958,   8.3002,   8.2999,   8.3001,\n",
      "        256.9652, 256.9652, 256.9652,   8.2994,   8.3000, 256.9652, 256.9652,\n",
      "        256.9652, 256.9652, 256.9652,  39.1945,  39.1945,   8.3002, 256.9652,\n",
      "        256.9652, 256.9652, 256.9652, 256.9652,  39.1945,  39.1945, 256.9652,\n",
      "         39.1945,  39.1945,   5.2026, 256.9652, 256.9652, 256.9652, 256.9652,\n",
      "        256.9652,  39.1945,  39.1945, 256.9652,  39.1945,  39.1945,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 256.9652,   5.2026,   5.2025, 256.9652,   5.2026,\n",
      "          5.2025, 256.9652,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        256.9652, 256.9652, 256.9652, 256.9652,  39.1945,  39.1945,  39.1945,\n",
      "         39.1945, 256.9652, 256.9652, 256.9652,  39.1945,  39.1945,  39.1945,\n",
      "         39.1945,   5.2026,  39.1945,  39.1945,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 322 was 89.6%\n",
      "tensor([2.7444e-06, 6.5076e-06, 4.9473e-06, 3.1340e-20, 4.6422e-06, 0.0000e+00,\n",
      "        0.0000e+00, 2.6938e-07, 0.0000e+00, 8.3692e-06, 8.0555e-06, 7.9449e-06,\n",
      "        1.5289e-03, 1.2399e-03, 1.2242e-03, 7.5485e-06, 7.4365e-06, 8.3270e-04,\n",
      "        8.2037e-04, 6.7780e-01, 6.5954e-01, 2.5234e+00, 2.5417e+00, 7.1307e-06,\n",
      "        7.8011e-04, 6.1159e-01, 2.5902e+00, 5.3869e-01, 2.6643e+00, 7.1789e-01,\n",
      "        8.9674e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([124.7914, 152.0773, 168.8363, 173.6043,   8.2979,   8.2993,   8.2990,\n",
      "        257.3938, 257.3938, 257.3938,   8.2990,   8.2994, 257.3938, 257.3938,\n",
      "        257.3938, 257.3938, 257.3938,  39.2739,  39.2739,   8.2988, 257.3938,\n",
      "        257.3938, 257.3938, 257.3938, 257.3938,  39.2739,  39.2739, 257.3938,\n",
      "         39.2739,  39.2739,   5.2026, 257.3938, 257.3938, 257.3938, 257.3938,\n",
      "        257.3938,  39.2739,  39.2739, 257.3938,  39.2739,  39.2739,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 257.3938,   5.2026,   5.2025, 257.3938,   5.2026,\n",
      "          5.2025, 257.3938,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        257.3938, 257.3938, 257.3938, 257.3938,  39.2739,  39.2739,  39.2739,\n",
      "         39.2739, 257.3938, 257.3938, 257.3938,  39.2739,  39.2739,  39.2739,\n",
      "         39.2739,   5.2026,  39.2739,  39.2739,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 323 was 89.7%\n",
      "tensor([8.6363e-07, 6.0243e-06, 3.5698e-06, 8.3384e-06, 0.0000e+00, 0.0000e+00,\n",
      "        8.1116e-08, 0.0000e+00, 7.0077e-08, 8.3469e-06, 8.0325e-06, 7.9253e-06,\n",
      "        1.5090e-03, 1.2233e-03, 1.2083e-03, 7.5275e-06, 7.4181e-06, 8.2103e-04,\n",
      "        8.0908e-04, 6.7560e-01, 6.5778e-01, 2.5167e+00, 2.5346e+00, 7.1147e-06,\n",
      "        7.6970e-04, 6.1003e-01, 2.5829e+00, 5.3735e-01, 2.6568e+00, 7.1587e-01,\n",
      "        8.9703e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([125.1019, 152.4585, 169.2411, 173.9149,   8.2973,   8.2978,   8.2981,\n",
      "        257.8224, 257.8224, 257.8224,   8.2979,   8.2974, 257.8224, 257.8224,\n",
      "        257.8224, 257.8224, 257.8224,  39.3533,  39.3533,   8.2983, 257.8224,\n",
      "        257.8224, 257.8224, 257.8224, 257.8224,  39.3533,  39.3533, 257.8224,\n",
      "         39.3533,  39.3533,   5.2026, 257.8224, 257.8224, 257.8224, 257.8224,\n",
      "        257.8224,  39.3533,  39.3533, 257.8224,  39.3533,  39.3533,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 257.8224,   5.2026,   5.2025, 257.8224,   5.2026,\n",
      "          5.2025, 257.8224,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        257.8224, 257.8224, 257.8224, 257.8224,  39.3533,  39.3533,  39.3533,\n",
      "         39.3533, 257.8224, 257.8224, 257.8224,  39.3533,  39.3533,  39.3533,\n",
      "         39.3533,   5.2026,  39.3533,  39.3533,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 324 was 89.7%\n",
      "tensor([0.0000e+00, 5.3685e-06, 5.6714e-06, 3.3881e-21, 7.2610e-06, 9.6896e-08,\n",
      "        0.0000e+00, 6.1663e-08, 0.0000e+00, 8.3076e-06, 7.9966e-06, 7.8912e-06,\n",
      "        1.4885e-03, 1.2068e-03, 1.1921e-03, 7.4937e-06, 7.3882e-06, 8.0913e-04,\n",
      "        7.9777e-04, 6.7337e-01, 6.5599e-01, 2.5100e+00, 2.5274e+00, 7.0854e-06,\n",
      "        7.5886e-04, 6.0847e-01, 2.5755e+00, 5.3596e-01, 2.6492e+00, 7.1384e-01,\n",
      "        8.9732e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([125.4111, 152.8384, 169.6441, 174.2259,   8.2967,   8.2971,   8.2966,\n",
      "        258.2509, 258.2509, 258.2509,   8.2967,   8.2967, 258.2509, 258.2509,\n",
      "        258.2509, 258.2509, 258.2509,  39.4328,  39.4328,   8.2964, 258.2509,\n",
      "        258.2509, 258.2509, 258.2509, 258.2509,  39.4328,  39.4328, 258.2509,\n",
      "         39.4328,  39.4328,   5.2026, 258.2509, 258.2509, 258.2509, 258.2509,\n",
      "        258.2509,  39.4328,  39.4328, 258.2509,  39.4328,  39.4328,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 258.2509,   5.2026,   5.2025, 258.2509,   5.2026,\n",
      "          5.2025, 258.2509,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        258.2509, 258.2509, 258.2509, 258.2509,  39.4328,  39.4328,  39.4328,\n",
      "         39.4328, 258.2509, 258.2509, 258.2509,  39.4328,  39.4328,  39.4328,\n",
      "         39.4328,   5.2026,  39.4328,  39.4328,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 325 was 89.7%\n",
      "tensor([9.7761e-07, 5.9604e-06, 1.7740e-06, 1.1533e-05, 8.4703e-22, 0.0000e+00,\n",
      "        1.1257e-07, 0.0000e+00, 9.7320e-08, 8.1957e-06, 7.8892e-06, 7.7885e-06,\n",
      "        1.4687e-03, 1.1902e-03, 1.1763e-03, 7.3955e-06, 7.2929e-06, 7.9756e-04,\n",
      "        7.8649e-04, 6.7123e-01, 6.5425e-01, 2.5032e+00, 2.5203e+00, 6.9966e-06,\n",
      "        7.4834e-04, 6.0687e-01, 2.5682e+00, 5.3455e-01, 2.6417e+00, 7.1181e-01,\n",
      "        8.9760e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([125.7187, 153.2168, 170.0450, 174.5379,   8.2953,   8.2951,   8.2960,\n",
      "        258.6793, 258.6793, 258.6793,   8.2961,   8.2953, 258.6793, 258.6793,\n",
      "        258.6793, 258.6793, 258.6793,  39.5122,  39.5122,   8.2960, 258.6793,\n",
      "        258.6793, 258.6793, 258.6793, 258.6793,  39.5122,  39.5122, 258.6793,\n",
      "         39.5122,  39.5122,   5.2026, 258.6793, 258.6793, 258.6793, 258.6793,\n",
      "        258.6793,  39.5122,  39.5122, 258.6793,  39.5122,  39.5122,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 258.6793,   5.2026,   5.2025, 258.6793,   5.2026,\n",
      "          5.2025, 258.6793,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        258.6793, 258.6793, 258.6793, 258.6793,  39.5122,  39.5122,  39.5122,\n",
      "         39.5122, 258.6793, 258.6793, 258.6793,  39.5122,  39.5122,  39.5122,\n",
      "         39.5122,   5.2026,  39.5122,  39.5122,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 326 was 89.7%\n",
      "tensor([1.1866e-06, 7.0951e-06, 0.0000e+00, 1.1621e-05, 1.4535e-06, 0.0000e+00,\n",
      "        1.1888e-07, 0.0000e+00, 1.0282e-07, 7.6780e-06, 7.3933e-06, 7.3006e-06,\n",
      "        1.4489e-03, 1.1742e-03, 1.1605e-03, 6.9365e-06, 6.8438e-06, 7.8597e-04,\n",
      "        7.7553e-04, 6.6904e-01, 6.5251e-01, 2.4966e+00, 2.5132e+00, 6.5702e-06,\n",
      "        7.3789e-04, 6.0531e-01, 2.5609e+00, 5.3322e-01, 2.6343e+00, 7.0982e-01,\n",
      "        8.9789e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([126.0250, 153.5940, 170.4447, 174.8500,   8.2943,   8.2947,   8.2948,\n",
      "        259.1076, 259.1076, 259.1076,   8.2941,   8.2946, 259.1076, 259.1076,\n",
      "        259.1076, 259.1076, 259.1076,  39.5916,  39.5916,   8.2946, 259.1076,\n",
      "        259.1076, 259.1076, 259.1076, 259.1076,  39.5916,  39.5916, 259.1076,\n",
      "         39.5916,  39.5916,   5.2026, 259.1076, 259.1076, 259.1076, 259.1076,\n",
      "        259.1076,  39.5916,  39.5916, 259.1076,  39.5916,  39.5916,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 259.1076,   5.2026,   5.2025, 259.1076,   5.2026,\n",
      "          5.2025, 259.1076,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        259.1076, 259.1076, 259.1076, 259.1076,  39.5916,  39.5916,  39.5916,\n",
      "         39.5916, 259.1076, 259.1076, 259.1076,  39.5916,  39.5916,  39.5916,\n",
      "         39.5916,   5.2026,  39.5916,  39.5916,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(54.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 327 was 90.1%\n",
      "tensor([0.0000e+00, 8.2362e-04, 1.2364e-03, 2.5497e-04, 0.0000e+00, 7.7606e-06,\n",
      "        0.0000e+00, 1.2946e-05, 7.8627e-04, 1.1826e-03, 1.1371e-03, 1.1229e-03,\n",
      "        8.6736e-19, 0.0000e+00, 0.0000e+00, 1.0602e-03, 1.0452e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.3149e-01, 6.1611e-01, 2.4043e+00, 2.4198e+00, 9.9820e-04,\n",
      "        0.0000e+00, 5.7145e-01, 2.4658e+00, 5.0307e-01, 2.5344e+00, 7.1124e-01,\n",
      "        9.0176e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([126.3046, 153.9223, 170.7689, 175.1761,   8.2935,   8.2934,   8.2928,\n",
      "        259.5358, 259.5358, 259.5358,   8.2937,   8.2937, 259.5358, 259.5358,\n",
      "        259.5358, 259.5358, 259.5358,  39.6710,  39.6710,   8.2938, 259.5358,\n",
      "        259.5358, 259.5358, 259.5358, 259.5358,  39.6710,  39.6710, 259.5358,\n",
      "         39.6710,  39.6710,   5.2026, 259.5358, 259.5358, 259.5358, 259.5358,\n",
      "        259.5358,  39.6710,  39.6710, 259.5358,  39.6710,  39.6710,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 259.5358,   5.2026,   5.2025, 259.5358,   5.2026,\n",
      "          5.2025, 259.5358,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        259.5358, 259.5358, 259.5358, 259.5358,  39.6710,  39.6710,  39.6710,\n",
      "         39.6710, 259.5358, 259.5358, 259.5358,  39.6710,  39.6710,  39.6710,\n",
      "         39.6710,   5.2026,  39.6710,  39.6710,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(53.9374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 328 was 90.1%\n",
      "tensor([0.0000e+00, 8.4252e-04, 1.3107e-03, 2.8768e-04, 0.0000e+00, 8.7073e-06,\n",
      "        0.0000e+00, 1.2779e-05, 7.7669e-04, 1.1802e-03, 1.1354e-03, 1.1217e-03,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 1.0581e-03, 1.0435e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.2991e-01, 6.1457e-01, 2.3985e+00, 2.4140e+00, 9.9666e-04,\n",
      "        0.0000e+00, 5.7012e-01, 2.4598e+00, 5.0199e-01, 2.5282e+00, 7.0941e-01,\n",
      "        9.0200e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([126.5838, 154.2502, 171.0925, 175.5014,   8.2923,   8.2929,   8.2925,\n",
      "        259.9640, 259.9640, 259.9640,   8.2924,   8.2928, 259.9640, 259.9640,\n",
      "        259.9640, 259.9640, 259.9640,  39.7504,  39.7504,   8.2920, 259.9640,\n",
      "        259.9640, 259.9640, 259.9640, 259.9640,  39.7504,  39.7504, 259.9640,\n",
      "         39.7504,  39.7504,   5.2026, 259.9640, 259.9640, 259.9640, 259.9640,\n",
      "        259.9640,  39.7504,  39.7504, 259.9640,  39.7504,  39.7504,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 259.9640,   5.2026,   5.2025, 259.9640,   5.2026,\n",
      "          5.2025, 259.9640,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        259.9640, 259.9640, 259.9640, 259.9640,  39.7504,  39.7504,  39.7504,\n",
      "         39.7504, 259.9640, 259.9640, 259.9640,  39.7504,  39.7504,  39.7504,\n",
      "         39.7504,   5.2026,  39.7504,  39.7504,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(53.8491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 329 was 90.2%\n",
      "tensor([0.0000e+00, 8.6189e-04, 1.3886e-03, 3.2253e-04, 0.0000e+00, 9.7226e-06,\n",
      "        0.0000e+00, 1.2606e-05, 7.6720e-04, 1.1777e-03, 1.1327e-03, 1.1189e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0563e-03, 1.0414e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.2833e-01, 6.1307e-01, 2.3928e+00, 2.4082e+00, 9.9550e-04,\n",
      "        0.0000e+00, 5.6882e-01, 2.4539e+00, 5.0085e-01, 2.5220e+00, 7.0760e-01,\n",
      "        9.0223e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([126.8627, 154.5775, 171.4153, 175.8261,   8.2917,   8.2910,   8.2914,\n",
      "        260.3921, 260.3921, 260.3921,   8.2915,   8.2914, 260.3921, 260.3921,\n",
      "        260.3921, 260.3921, 260.3921,  39.8298,  39.8298,   8.2916, 260.3921,\n",
      "        260.3921, 260.3921, 260.3921, 260.3921,  39.8298,  39.8298, 260.3921,\n",
      "         39.8298,  39.8298,   5.2026, 260.3921, 260.3921, 260.3921, 260.3921,\n",
      "        260.3921,  39.8298,  39.8298, 260.3921,  39.8298,  39.8298,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 260.3921,   5.2026,   5.2025, 260.3921,   5.2026,\n",
      "          5.2025, 260.3921,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        260.3921, 260.3921, 260.3921, 260.3921,  39.8298,  39.8298,  39.8298,\n",
      "         39.8298, 260.3921, 260.3921, 260.3921,  39.8298,  39.8298,  39.8298,\n",
      "         39.8298,   5.2026,  39.8298,  39.8298,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(53.7617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 330 was 90.2%\n",
      "tensor([0.0000e+00, 8.8185e-04, 1.4711e-03, 3.6029e-04, 0.0000e+00, 1.0808e-05,\n",
      "        0.0000e+00, 1.2435e-05, 7.5784e-04, 1.1733e-03, 1.1297e-03, 1.1153e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0528e-03, 1.0385e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.2676e-01, 6.1156e-01, 2.3871e+00, 2.4024e+00, 9.9207e-04,\n",
      "        0.0000e+00, 5.6751e-01, 2.4479e+00, 4.9976e-01, 2.5158e+00, 7.0579e-01,\n",
      "        9.0247e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([127.1411, 154.9044, 171.7372, 176.1506,   8.2895,   8.2907,   8.2908,\n",
      "        260.8200, 260.8200, 260.8200,   8.2905,   8.2908, 260.8200, 260.8200,\n",
      "        260.8200, 260.8200, 260.8200,  39.9092,  39.9092,   8.2903, 260.8200,\n",
      "        260.8200, 260.8200, 260.8200, 260.8200,  39.9092,  39.9092, 260.8200,\n",
      "         39.9092,  39.9092,   5.2026, 260.8200, 260.8200, 260.8200, 260.8200,\n",
      "        260.8200,  39.9092,  39.9092, 260.8200,  39.9092,  39.9092,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 260.8200,   5.2026,   5.2025, 260.8200,   5.2026,\n",
      "          5.2025, 260.8200,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        260.8200, 260.8200, 260.8200, 260.8200,  39.9092,  39.9092,  39.9092,\n",
      "         39.9092, 260.8200, 260.8200, 260.8200,  39.9092,  39.9092,  39.9092,\n",
      "         39.9092,   5.2026,  39.9092,  39.9092,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(53.6738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 331 was 90.2%\n",
      "tensor([0.0000e+00, 9.0216e-04, 1.5574e-03, 4.0050e-04, 0.0000e+00, 1.1958e-05,\n",
      "        0.0000e+00, 1.2264e-05, 7.4857e-04, 1.1693e-03, 1.1244e-03, 1.1104e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0487e-03, 1.0341e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.2518e-01, 6.1006e-01, 2.3814e+00, 2.3967e+00, 9.8857e-04,\n",
      "        0.0000e+00, 5.6624e-01, 2.4420e+00, 4.9866e-01, 2.5096e+00, 7.0400e-01,\n",
      "        9.0270e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([127.4191, 155.2307, 172.0578, 176.4752,   8.2889,   8.2896,   8.2889,\n",
      "        261.2480, 261.2480, 261.2480,   8.2896,   8.2894, 261.2480, 261.2480,\n",
      "        261.2480, 261.2480, 261.2480,  39.9886,  39.9886,   8.2899, 261.2480,\n",
      "        261.2480, 261.2480, 261.2480, 261.2480,  39.9886,  39.9886, 261.2480,\n",
      "         39.9886,  39.9886,   5.2026, 261.2480, 261.2480, 261.2480, 261.2480,\n",
      "        261.2480,  39.9886,  39.9886, 261.2480,  39.9886,  39.9886,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 261.2480,   5.2026,   5.2025, 261.2480,   5.2026,\n",
      "          5.2025, 261.2480,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        261.2480, 261.2480, 261.2480, 261.2480,  39.9886,  39.9886,  39.9886,\n",
      "         39.9886, 261.2480, 261.2480, 261.2480,  39.9886,  39.9886,  39.9886,\n",
      "         39.9886,   5.2026,  39.9886,  39.9886,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(53.5860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 332 was 90.2%\n",
      "tensor([0.0000e+00, 9.2278e-04, 1.6512e-03, 4.4582e-04, 0.0000e+00, 1.3247e-05,\n",
      "        0.0000e+00, 1.2104e-05, 7.3942e-04, 1.1599e-03, 1.1161e-03, 1.1028e-03,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 1.0408e-03, 1.0266e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.2364e-01, 6.0851e-01, 2.3757e+00, 2.3910e+00, 9.8097e-04,\n",
      "        0.0000e+00, 5.6495e-01, 2.4361e+00, 4.9759e-01, 2.5034e+00, 7.0222e-01,\n",
      "        9.0294e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([127.6966, 155.5566, 172.3769, 176.8000,   8.2881,   8.2887,   8.2885,\n",
      "        261.6758, 261.6758, 261.6758,   8.2883,   8.2885, 261.6758, 261.6758,\n",
      "        261.6758, 261.6758, 261.6758,  40.0679,  40.0679,   8.2881, 261.6758,\n",
      "        261.6758, 261.6758, 261.6758, 261.6758,  40.0679,  40.0679, 261.6758,\n",
      "         40.0679,  40.0679,   5.2026, 261.6758, 261.6758, 261.6758, 261.6758,\n",
      "        261.6758,  40.0679,  40.0679, 261.6758,  40.0679,  40.0679,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 261.6758,   5.2026,   5.2025, 261.6758,   5.2026,\n",
      "          5.2025, 261.6758,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        261.6758, 261.6758, 261.6758, 261.6758,  40.0679,  40.0679,  40.0679,\n",
      "         40.0679, 261.6758, 261.6758, 261.6758,  40.0679,  40.0679,  40.0679,\n",
      "         40.0679,   5.2026,  40.0679,  40.0679,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(53.4982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 333 was 90.3%\n",
      "tensor([0.0000e+00, 9.4335e-04, 1.7480e-03, 4.9343e-04, 0.0000e+00, 1.4610e-05,\n",
      "        0.0000e+00, 1.1939e-05, 7.3036e-04, 1.1497e-03, 1.1063e-03, 1.0928e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0322e-03, 1.0179e-03, 0.0000e+00,\n",
      "        0.0000e+00, 6.2209e-01, 6.0706e-01, 2.3701e+00, 2.3853e+00, 9.7339e-04,\n",
      "        0.0000e+00, 5.6366e-01, 2.4303e+00, 4.9647e-01, 2.4973e+00, 7.0043e-01,\n",
      "        9.0317e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([127.9736, 155.8819, 172.6939, 177.1257,   8.2874,   8.2868,   8.2871,\n",
      "        262.1035, 262.1035, 262.1035,   8.2874,   8.2874, 262.1035, 262.1035,\n",
      "        262.1035, 262.1035, 262.1035,  40.1473,  40.1473,   8.2877, 262.1035,\n",
      "        262.1035, 262.1035, 262.1035, 262.1035,  40.1473,  40.1473, 262.1035,\n",
      "         40.1473,  40.1473,   5.2026, 262.1035, 262.1035, 262.1035, 262.1035,\n",
      "        262.1035,  40.1473,  40.1473, 262.1035,  40.1473,  40.1473,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 262.1035,   5.2026,   5.2025, 262.1035,   5.2026,\n",
      "          5.2025, 262.1035,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        262.1035, 262.1035, 262.1035, 262.1035,  40.1473,  40.1473,  40.1473,\n",
      "         40.1473, 262.1035, 262.1035, 262.1035,  40.1473,  40.1473,  40.1473,\n",
      "         40.1473,   5.2026,  40.1473,  40.1473,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 334 was 89.9%\n",
      "tensor([8.3820e-07, 4.9698e-06, 5.1780e-06, 6.7763e-21, 9.9561e-06, 1.2453e-07,\n",
      "        0.0000e+00, 7.9076e-08, 0.0000e+00, 8.0847e-06, 7.7888e-06, 7.6936e-06,\n",
      "        1.3096e-03, 1.0620e-03, 1.0503e-03, 7.3028e-06, 7.2069e-06, 7.0788e-04,\n",
      "        6.9878e-04, 6.5477e-01, 6.3908e-01, 2.4474e+00, 2.4631e+00, 6.9180e-06,\n",
      "        6.6599e-04, 5.9363e-01, 2.5091e+00, 5.2324e-01, 2.5807e+00, 6.9533e-01,\n",
      "        8.9994e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([128.2814, 156.2531, 173.1030, 177.4130,   8.2856,   8.2864,   8.2865,\n",
      "        262.5312, 262.5312, 262.5312,   8.2862,   8.2867, 262.5312, 262.5312,\n",
      "        262.5312, 262.5312, 262.5312,  40.2267,  40.2267,   8.2857, 262.5312,\n",
      "        262.5312, 262.5312, 262.5312, 262.5312,  40.2267,  40.2267, 262.5312,\n",
      "         40.2267,  40.2267,   5.2026, 262.5312, 262.5312, 262.5312, 262.5312,\n",
      "        262.5312,  40.2267,  40.2267, 262.5312,  40.2267,  40.2267,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 262.5312,   5.2026,   5.2025, 262.5312,   5.2026,\n",
      "          5.2025, 262.5312,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        262.5312, 262.5312, 262.5312, 262.5312,  40.2267,  40.2267,  40.2267,\n",
      "         40.2267, 262.5312, 262.5312, 262.5312,  40.2267,  40.2267,  40.2267,\n",
      "         40.2267,   5.2026,  40.2267,  40.2267,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 335 was 90.0%\n",
      "tensor([0.0000e+00, 5.8426e-06, 3.9985e-06, 6.5286e-06, 0.0000e+00, 0.0000e+00,\n",
      "        5.6979e-08, 0.0000e+00, 4.9386e-08, 8.0617e-06, 7.7648e-06, 7.6733e-06,\n",
      "        1.2932e-03, 1.0480e-03, 1.0369e-03, 7.2814e-06, 7.1882e-06, 6.9811e-04,\n",
      "        6.8933e-04, 6.5266e-01, 6.3750e-01, 2.4412e+00, 2.4564e+00, 6.9014e-06,\n",
      "        6.5723e-04, 5.9215e-01, 2.5022e+00, 5.2195e-01, 2.5736e+00, 6.9344e-01,\n",
      "        9.0021e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([128.5883, 156.6231, 173.4987, 177.7077,   8.2849,   8.2852,   8.2850,\n",
      "        262.9588, 262.9588, 262.9588,   8.2853,   8.2847, 262.9588, 262.9588,\n",
      "        262.9588, 262.9588, 262.9588,  40.3061,  40.3061,   8.2853, 262.9588,\n",
      "        262.9588, 262.9588, 262.9588, 262.9588,  40.3061,  40.3061, 262.9588,\n",
      "         40.3061,  40.3061,   5.2026, 262.9588, 262.9588, 262.9588, 262.9588,\n",
      "        262.9588,  40.3061,  40.3061, 262.9588,  40.3061,  40.3061,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 262.9588,   5.2026,   5.2025, 262.9588,   5.2026,\n",
      "          5.2025, 262.9588,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        262.9588, 262.9588, 262.9588, 262.9588,  40.3061,  40.3061,  40.3061,\n",
      "         40.3061, 262.9588, 262.9588, 262.9588,  40.3061,  40.3061,  40.3061,\n",
      "         40.3061,   5.2026,  40.3061,  40.3061,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 336 was 90.0%\n",
      "tensor([0.0000e+00, 5.8262e-06, 3.9971e-06, 6.4845e-06, 0.0000e+00, 0.0000e+00,\n",
      "        5.6116e-08, 0.0000e+00, 4.8655e-08, 8.0368e-06, 7.7422e-06, 7.6526e-06,\n",
      "        1.2764e-03, 1.0343e-03, 1.0236e-03, 7.2599e-06, 7.1699e-06, 6.8845e-04,\n",
      "        6.8010e-04, 6.5062e-01, 6.3582e-01, 2.4349e+00, 2.4497e+00, 6.8832e-06,\n",
      "        6.4837e-04, 5.9068e-01, 2.4953e+00, 5.2066e-01, 2.5666e+00, 6.9155e-01,\n",
      "        9.0048e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([128.8947, 156.9919, 173.8990, 177.9977,   8.2840,   8.2842,   8.2840,\n",
      "        263.3863, 263.3863, 263.3863,   8.2833,   8.2843, 263.3863, 263.3863,\n",
      "        263.3863, 263.3863, 263.3863,  40.3855,  40.3855,   8.2839, 263.3863,\n",
      "        263.3863, 263.3863, 263.3863, 263.3863,  40.3855,  40.3855, 263.3863,\n",
      "         40.3855,  40.3855,   5.2026, 263.3863, 263.3863, 263.3863, 263.3863,\n",
      "        263.3863,  40.3855,  40.3855, 263.3863,  40.3855,  40.3855,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 263.3863,   5.2026,   5.2025, 263.3863,   5.2026,\n",
      "          5.2025, 263.3863,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        263.3863, 263.3863, 263.3863, 263.3863,  40.3855,  40.3855,  40.3855,\n",
      "         40.3855, 263.3863, 263.3863, 263.3863,  40.3855,  40.3855,  40.3855,\n",
      "         40.3855,   5.2026,  40.3855,  40.3855,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 337 was 90.0%\n",
      "tensor([1.8509e-06, 2.0530e-06, 6.3192e-06, 0.0000e+00, 7.1083e-06, 6.1260e-07,\n",
      "        0.0000e+00, 1.8555e-06, 0.0000e+00, 8.0130e-06, 7.7189e-06, 7.6329e-06,\n",
      "        1.2593e-03, 1.0201e-03, 1.0100e-03, 7.2394e-06, 7.1511e-06, 6.7856e-04,\n",
      "        6.7047e-04, 6.4852e-01, 6.3425e-01, 2.4287e+00, 2.4430e+00, 6.8661e-06,\n",
      "        6.3931e-04, 5.8920e-01, 2.4885e+00, 5.1937e-01, 2.5596e+00, 6.8969e-01,\n",
      "        9.0075e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([129.1755, 157.3610, 173.6945, 178.6940,   8.2831,   8.2829,   8.2826,\n",
      "        263.8138, 263.8138, 263.8138,   8.2829,   8.2819, 263.8138, 263.8138,\n",
      "        263.8138, 263.8138, 263.8138,  40.4649,  40.4649,   8.2831, 263.8138,\n",
      "        263.8138, 263.8138, 263.8138, 263.8138,  40.4649,  40.4649, 263.8138,\n",
      "         40.4649,  40.4649,   5.2026, 263.8138, 263.8138, 263.8138, 263.8138,\n",
      "        263.8138,  40.4649,  40.4649, 263.8138,  40.4649,  40.4649,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 263.8138,   5.2026,   5.2025, 263.8138,   5.2026,\n",
      "          5.2025, 263.8138,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        263.8138, 263.8138, 263.8138, 263.8138,  40.4649,  40.4649,  40.4649,\n",
      "         40.4649, 263.8138, 263.8138, 263.8138,  40.4649,  40.4649,  40.4649,\n",
      "         40.4649,   5.2026,  40.4649,  40.4649,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 338 was 90.0%\n",
      "tensor([8.3927e-07, 4.8669e-06, 5.1081e-06, 3.3881e-21, 1.0473e-05, 1.2732e-07,\n",
      "        0.0000e+00, 8.1047e-08, 0.0000e+00, 7.9913e-06, 7.7097e-06, 7.6046e-06,\n",
      "        1.2410e-03, 1.0128e-03, 1.0004e-03, 7.2305e-06, 7.1250e-06, 6.7329e-04,\n",
      "        6.6370e-04, 6.4851e-01, 6.3111e-01, 2.4213e+00, 2.4388e+00, 6.8493e-06,\n",
      "        6.3409e-04, 5.8782e-01, 2.4825e+00, 5.1814e-01, 2.5533e+00, 6.8794e-01,\n",
      "        9.0099e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([129.4808, 157.7274, 174.0937, 178.9800,   8.2812,   8.2822,   8.2820,\n",
      "        264.2412, 264.2412, 264.2412,   8.2817,   8.2815, 264.2412, 264.2412,\n",
      "        264.2412, 264.2412, 264.2412,  40.5442,  40.5442,   8.2812, 264.2412,\n",
      "        264.2412, 264.2412, 264.2412, 264.2412,  40.5442,  40.5442, 264.2412,\n",
      "         40.5442,  40.5442,   5.2026, 264.2412, 264.2412, 264.2412, 264.2412,\n",
      "        264.2412,  40.5442,  40.5442, 264.2412,  40.5442,  40.5442,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 264.2412,   5.2026,   5.2025, 264.2412,   5.2026,\n",
      "          5.2025, 264.2412,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        264.2412, 264.2412, 264.2412, 264.2412,  40.5442,  40.5442,  40.5442,\n",
      "         40.5442, 264.2412, 264.2412, 264.2412,  40.5442,  40.5442,  40.5442,\n",
      "         40.5442,   5.2026,  40.5442,  40.5442,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 339 was 90.1%\n",
      "tensor([0.0000e+00, 5.7774e-06, 4.0024e-06, 6.2618e-06, 0.0000e+00, 0.0000e+00,\n",
      "        5.2764e-08, 0.0000e+00, 4.5846e-08, 7.9691e-06, 7.6866e-06, 7.5844e-06,\n",
      "        1.2253e-03, 9.9938e-04, 9.8759e-04, 7.2094e-06, 7.1062e-06, 6.6399e-04,\n",
      "        6.5476e-04, 6.4647e-01, 6.2955e-01, 2.4152e+00, 2.4322e+00, 6.8330e-06,\n",
      "        6.2577e-04, 5.8639e-01, 2.4758e+00, 5.1686e-01, 2.5465e+00, 6.8611e-01,\n",
      "        9.0125e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([129.7849, 158.0927, 174.4828, 179.2721,   8.2805,   8.2801,   8.2805,\n",
      "        264.6685, 264.6685, 264.6685,   8.2805,   8.2806, 264.6685, 264.6685,\n",
      "        264.6685, 264.6685, 264.6685,  40.6236,  40.6236,   8.2807, 264.6685,\n",
      "        264.6685, 264.6685, 264.6685, 264.6685,  40.6236,  40.6236, 264.6685,\n",
      "         40.6236,  40.6236,   5.2026, 264.6685, 264.6685, 264.6685, 264.6685,\n",
      "        264.6685,  40.6236,  40.6236, 264.6685,  40.6236,  40.6236,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 264.6685,   5.2026,   5.2025, 264.6685,   5.2026,\n",
      "          5.2025, 264.6685,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        264.6685, 264.6685, 264.6685, 264.6685,  40.6236,  40.6236,  40.6236,\n",
      "         40.6236, 264.6685, 264.6685, 264.6685,  40.6236,  40.6236,  40.6236,\n",
      "         40.6236,   5.2026,  40.6236,  40.6236,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 340 was 90.1%\n",
      "tensor([0.0000e+00, 4.8405e-06, 5.0722e-06, 1.6941e-21, 1.0455e-05, 1.2508e-07,\n",
      "        0.0000e+00, 7.9554e-08, 0.0000e+00, 7.9445e-06, 7.6646e-06, 7.5646e-06,\n",
      "        1.2093e-03, 9.8622e-04, 9.7483e-04, 7.1886e-06, 7.0880e-06, 6.5481e-04,\n",
      "        6.4595e-04, 6.4442e-01, 6.2795e-01, 2.4091e+00, 2.4256e+00, 6.8151e-06,\n",
      "        6.1727e-04, 5.8491e-01, 2.4691e+00, 5.1564e-01, 2.5396e+00, 6.8426e-01,\n",
      "        9.0152e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([130.0931, 158.4579, 175.0126, 179.4648,   8.2789,   8.2797,   8.2799,\n",
      "        265.0957, 265.0957, 265.0957,   8.2798,   8.2791, 265.0957, 265.0957,\n",
      "        265.0957, 265.0957, 265.0957,  40.7030,  40.7030,   8.2788, 265.0957,\n",
      "        265.0957, 265.0957, 265.0957, 265.0957,  40.7030,  40.7030, 265.0957,\n",
      "         40.7030,  40.7030,   5.2026, 265.0957, 265.0957, 265.0957, 265.0957,\n",
      "        265.0957,  40.7030,  40.7030, 265.0957,  40.7030,  40.7030,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 265.0957,   5.2026,   5.2025, 265.0957,   5.2026,\n",
      "          5.2025, 265.0957,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        265.0957, 265.0957, 265.0957, 265.0957,  40.7030,  40.7030,  40.7030,\n",
      "         40.7030, 265.0957, 265.0957, 265.0957,  40.7030,  40.7030,  40.7030,\n",
      "         40.7030,   5.2026,  40.7030,  40.7030,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 341 was 90.1%\n",
      "tensor([8.0799e-07, 4.8519e-06, 5.0619e-06, 0.0000e+00, 1.0179e-05, 1.2071e-07,\n",
      "        0.0000e+00, 7.6655e-08, 0.0000e+00, 7.9221e-06, 7.6396e-06, 7.5467e-06,\n",
      "        1.1947e-03, 9.7231e-04, 9.6178e-04, 7.1651e-06, 7.0728e-06, 6.4496e-04,\n",
      "        6.3691e-04, 6.4201e-01, 6.2675e-01, 2.4034e+00, 2.4187e+00, 6.7991e-06,\n",
      "        6.0850e-04, 5.8350e-01, 2.4624e+00, 5.1440e-01, 2.5327e+00, 6.8245e-01,\n",
      "        9.0178e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([130.3976, 158.8219, 175.4405, 179.7258,   8.2782,   8.2785,   8.2778,\n",
      "        265.5229, 265.5229, 265.5229,   8.2783,   8.2782, 265.5229, 265.5229,\n",
      "        265.5229, 265.5229, 265.5229,  40.7823,  40.7823,   8.2784, 265.5229,\n",
      "        265.5229, 265.5229, 265.5229, 265.5229,  40.7823,  40.7823, 265.5229,\n",
      "         40.7823,  40.7823,   5.2026, 265.5229, 265.5229, 265.5229, 265.5229,\n",
      "        265.5229,  40.7823,  40.7823, 265.5229,  40.7823,  40.7823,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 265.5229,   5.2026,   5.2025, 265.5229,   5.2026,\n",
      "          5.2025, 265.5229,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        265.5229, 265.5229, 265.5229, 265.5229,  40.7823,  40.7823,  40.7823,\n",
      "         40.7823, 265.5229, 265.5229, 265.5229,  40.7823,  40.7823,  40.7823,\n",
      "         40.7823,   5.2026,  40.7823,  40.7823,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 342 was 90.2%\n",
      "tensor([7.9829e-07, 4.8478e-06, 5.0481e-06, 1.3553e-20, 1.0063e-05, 1.1858e-07,\n",
      "        0.0000e+00, 7.5213e-08, 0.0000e+00, 7.8982e-06, 7.6165e-06, 7.5287e-06,\n",
      "        1.1821e-03, 9.6108e-04, 9.5119e-04, 7.1445e-06, 7.0550e-06, 6.3691e-04,\n",
      "        6.2912e-04, 6.3989e-01, 6.2526e-01, 2.3979e+00, 2.4126e+00, 6.7814e-06,\n",
      "        6.0085e-04, 5.8207e-01, 2.4561e+00, 5.1317e-01, 2.5260e+00, 6.8060e-01,\n",
      "        9.0202e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([130.6998, 159.1837, 175.8249, 180.0160,   8.2772,   8.2763,   8.2774,\n",
      "        265.9500, 265.9500, 265.9500,   8.2772,   8.2775, 265.9500, 265.9500,\n",
      "        265.9500, 265.9500, 265.9500,  40.8617,  40.8617,   8.2769, 265.9500,\n",
      "        265.9500, 265.9500, 265.9500, 265.9500,  40.8617,  40.8617, 265.9500,\n",
      "         40.8617,  40.8617,   5.2026, 265.9500, 265.9500, 265.9500, 265.9500,\n",
      "        265.9500,  40.8617,  40.8617, 265.9500,  40.8617,  40.8617,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 265.9500,   5.2026,   5.2025, 265.9500,   5.2026,\n",
      "          5.2025, 265.9500,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        265.9500, 265.9500, 265.9500, 265.9500,  40.8617,  40.8617,  40.8617,\n",
      "         40.8617, 265.9500, 265.9500, 265.9500,  40.8617,  40.8617,  40.8617,\n",
      "         40.8617,   5.2026,  40.8617,  40.8617,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 343 was 90.2%\n",
      "tensor([7.8975e-07, 4.8406e-06, 5.0346e-06, 3.3881e-21, 9.9960e-06, 1.1682e-07,\n",
      "        0.0000e+00, 7.4066e-08, 0.0000e+00, 7.8755e-06, 7.5955e-06, 7.5087e-06,\n",
      "        1.1670e-03, 9.4855e-04, 9.3895e-04, 7.1242e-06, 7.0374e-06, 6.2809e-04,\n",
      "        6.2068e-04, 6.3791e-01, 6.2375e-01, 2.3920e+00, 2.4062e+00, 6.7649e-06,\n",
      "        5.9281e-04, 5.8063e-01, 2.4496e+00, 5.1197e-01, 2.5194e+00, 6.7881e-01,\n",
      "        9.0228e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([131.0013, 159.5444, 176.2085, 180.3057,   8.2764,   8.2759,   8.2758,\n",
      "        266.3770, 266.3770, 266.3770,   8.2759,   8.2753, 266.3770, 266.3770,\n",
      "        266.3770, 266.3770, 266.3770,  40.9411,  40.9411,   8.2762, 266.3770,\n",
      "        266.3770, 266.3770, 266.3770, 266.3770,  40.9411,  40.9411, 266.3770,\n",
      "         40.9411,  40.9411,   5.2026, 266.3770, 266.3770, 266.3770, 266.3770,\n",
      "        266.3770,  40.9411,  40.9411, 266.3770,  40.9411,  40.9411,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 266.3770,   5.2026,   5.2025, 266.3770,   5.2026,\n",
      "          5.2025, 266.3770,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        266.3770, 266.3770, 266.3770, 266.3770,  40.9411,  40.9411,  40.9411,\n",
      "         40.9411, 266.3770, 266.3770, 266.3770,  40.9411,  40.9411,  40.9411,\n",
      "         40.9411,   5.2026,  40.9411,  40.9411,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 344 was 90.2%\n",
      "tensor([7.8094e-07, 4.8341e-06, 5.0210e-06, 4.2352e-21, 9.9205e-06, 1.1499e-07,\n",
      "        0.0000e+00, 7.2875e-08, 0.0000e+00, 7.8521e-06, 7.5737e-06, 7.4900e-06,\n",
      "        1.1518e-03, 9.3620e-04, 9.2695e-04, 7.1045e-06, 7.0204e-06, 6.1946e-04,\n",
      "        6.1230e-04, 6.3600e-01, 6.2217e-01, 2.3861e+00, 2.3999e+00, 6.7476e-06,\n",
      "        5.8479e-04, 5.7924e-01, 2.4432e+00, 5.1073e-01, 2.5127e+00, 6.7704e-01,\n",
      "        9.0253e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([131.3023, 159.9041, 176.5917, 180.5944,   8.2742,   8.2751,   8.2751,\n",
      "        266.8039, 266.8039, 266.8039,   8.2746,   8.2749, 266.8039, 266.8039,\n",
      "        266.8039, 266.8039, 266.8039,  41.0204,  41.0204,   8.2748, 266.8039,\n",
      "        266.8039, 266.8039, 266.8039, 266.8039,  41.0204,  41.0204, 266.8039,\n",
      "         41.0204,  41.0204,   5.2026, 266.8039, 266.8039, 266.8039, 266.8039,\n",
      "        266.8039,  41.0204,  41.0204, 266.8039,  41.0204,  41.0204,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 266.8039,   5.2026,   5.2025, 266.8039,   5.2026,\n",
      "          5.2025, 266.8039,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        266.8039, 266.8039, 266.8039, 266.8039,  41.0204,  41.0204,  41.0204,\n",
      "         41.0204, 266.8039, 266.8039, 266.8039,  41.0204,  41.0204,  41.0204,\n",
      "         41.0204,   5.2026,  41.0204,  41.0204,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(51.6546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 345 was 90.6%\n",
      "tensor([0.0000e+00, 6.7316e-05, 2.8422e-04, 4.4104e-04, 0.0000e+00, 2.2939e-07,\n",
      "        5.8011e-09, 6.2606e-05, 6.3353e-04, 8.9689e-05, 8.6464e-05, 8.5534e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0875e-05, 7.9897e-05, 0.0000e+00,\n",
      "        0.0000e+00, 6.0207e-01, 5.8923e-01, 2.2991e+00, 2.3122e+00, 7.6585e-05,\n",
      "        0.0000e+00, 5.4850e-01, 2.3530e+00, 4.8338e-01, 2.4185e+00, 6.7849e-01,\n",
      "        9.0618e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([131.5790, 160.2204, 176.9689, 180.8666,   8.2735,   8.2731,   8.2737,\n",
      "        267.2308, 267.2308, 267.2308,   8.2739,   8.2737, 267.2308, 267.2308,\n",
      "        267.2308, 267.2308, 267.2308,  41.0998,  41.0998,   8.2741, 267.2308,\n",
      "        267.2308, 267.2308, 267.2308, 267.2308,  41.0998,  41.0998, 267.2308,\n",
      "         41.0998,  41.0998,   5.2026, 267.2308, 267.2308, 267.2308, 267.2308,\n",
      "        267.2308,  41.0998,  41.0998, 267.2308,  41.0998,  41.0998,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 267.2308,   5.2026,   5.2025, 267.2308,   5.2026,\n",
      "          5.2025, 267.2308,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        267.2308, 267.2308, 267.2308, 267.2308,  41.0998,  41.0998,  41.0998,\n",
      "         41.0998, 267.2308, 267.2308, 267.2308,  41.0998,  41.0998,  41.0998,\n",
      "         41.0998,   5.2026,  41.0998,  41.0998,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(51.5775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 346 was 90.6%\n",
      "tensor([5.8019e-05, 1.9503e-05, 2.2710e-04, 5.1304e-04, 0.0000e+00, 8.6325e-08,\n",
      "        6.1171e-09, 3.6031e-05, 6.2550e-04, 1.9064e-05, 1.8384e-05, 1.8174e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7176e-05, 1.6975e-05, 0.0000e+00,\n",
      "        0.0000e+00, 6.0052e-01, 5.8806e-01, 2.2937e+00, 2.3064e+00, 1.6246e-05,\n",
      "        0.0000e+00, 5.4735e-01, 2.3471e+00, 4.8246e-01, 2.4123e+00, 6.7695e-01,\n",
      "        9.0640e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([131.8528, 160.5348, 177.3198, 181.1600,   8.2726,   8.2728,   8.2727,\n",
      "        267.6576, 267.6576, 267.6576,   8.2725,   8.2728, 267.6576, 267.6576,\n",
      "        267.6576, 267.6576, 267.6576,  41.1791,  41.1791,   8.2722, 267.6576,\n",
      "        267.6576, 267.6576, 267.6576, 267.6576,  41.1791,  41.1791, 267.6576,\n",
      "         41.1791,  41.1791,   5.2026, 267.6576, 267.6576, 267.6576, 267.6576,\n",
      "        267.6576,  41.1791,  41.1791, 267.6576,  41.1791,  41.1791,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 267.6576,   5.2026,   5.2025, 267.6576,   5.2026,\n",
      "          5.2025, 267.6576,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        267.6576, 267.6576, 267.6576, 267.6576,  41.1791,  41.1791,  41.1791,\n",
      "         41.1791, 267.6576, 267.6576, 267.6576,  41.1791,  41.1791,  41.1791,\n",
      "         41.1791,   5.2026,  41.1791,  41.1791,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(51.6023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 347 was 90.6%\n",
      "tensor([1.4815e-04, 0.0000e+00, 8.9184e-04, 1.3828e-03, 3.4694e-04, 1.5546e-06,\n",
      "        1.0865e-08, 0.0000e+00, 6.1785e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.9891e-01, 5.8669e-01, 2.2889e+00, 2.3014e+00, 1.3191e-05,\n",
      "        0.0000e+00, 5.4605e-01, 2.3416e+00, 4.8133e-01, 2.4055e+00, 6.7525e-01,\n",
      "        9.0662e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([132.1330, 160.8520, 177.7558, 181.3812,   8.2720,   8.2711,   8.2715,\n",
      "        268.0844, 268.0844, 268.0844,   8.2717,   8.2708, 268.0844, 268.0844,\n",
      "        268.0844, 268.0844, 268.0844,  41.2585,  41.2585,   8.2720, 268.0844,\n",
      "        268.0844, 268.0844, 268.0844, 268.0844,  41.2585,  41.2585, 268.0844,\n",
      "         41.2585,  41.2585,   5.2026, 268.0844, 268.0844, 268.0844, 268.0844,\n",
      "        268.0844,  41.2585,  41.2585, 268.0844,  41.2585,  41.2585,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 268.0844,   5.2026,   5.2025, 268.0844,   5.2026,\n",
      "          5.2025, 268.0844,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        268.0844, 268.0844, 268.0844, 268.0844,  41.2585,  41.2585,  41.2585,\n",
      "         41.2585, 268.0844, 268.0844, 268.0844,  41.2585,  41.2585,  41.2585,\n",
      "         41.2585,   5.2026,  41.2585,  41.2585,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 348 was 90.3%\n",
      "tensor([3.0113e-06, 3.4436e-06, 1.6588e-05, 2.5048e-05, 9.1593e-06, 4.1600e-08,\n",
      "        1.2509e-08, 0.0000e+00, 9.2612e-06, 0.0000e+00, 1.7094e-06, 2.1371e-06,\n",
      "        1.1013e-03, 8.9311e-04, 8.8540e-04, 4.5337e-06, 4.8053e-06, 5.9027e-04,\n",
      "        5.8437e-04, 6.2855e-01, 6.1653e-01, 2.3637e+00, 2.3757e+00, 6.8073e-06,\n",
      "        5.5825e-04, 5.7377e-01, 2.4188e+00, 5.0611e-01, 2.4875e+00, 6.7032e-01,\n",
      "        9.0350e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([132.4252, 161.2046, 178.0235, 181.7569,   8.2697,   8.2707,   8.2705,\n",
      "        268.5110, 268.5110, 268.5110,   8.2704,   8.2703, 268.5110, 268.5110,\n",
      "        268.5110, 268.5110, 268.5110,  41.3378,  41.3378,   8.2704, 268.5110,\n",
      "        268.5110, 268.5110, 268.5110, 268.5110,  41.3378,  41.3378, 268.5110,\n",
      "         41.3378,  41.3378,   5.2026, 268.5110, 268.5110, 268.5110, 268.5110,\n",
      "        268.5110,  41.3378,  41.3378, 268.5110,  41.3378,  41.3378,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 268.5110,   5.2026,   5.2025, 268.5110,   5.2026,\n",
      "          5.2025, 268.5110,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        268.5110, 268.5110, 268.5110, 268.5110,  41.3378,  41.3378,  41.3378,\n",
      "         41.3378, 268.5110, 268.5110, 268.5110,  41.3378,  41.3378,  41.3378,\n",
      "         41.3378,   5.2026,  41.3378,  41.3378,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(51.4317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 349 was 90.7%\n",
      "tensor([1.6958e-04, 0.0000e+00, 8.9865e-04, 1.4127e-03, 4.0000e-04, 1.5710e-06,\n",
      "        1.0682e-08, 0.0000e+00, 6.0335e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.9575e-01, 5.8394e-01, 2.2783e+00, 2.2903e+00, 1.3032e-05,\n",
      "        0.0000e+00, 5.4362e-01, 2.3302e+00, 4.7925e-01, 2.3937e+00, 6.7186e-01,\n",
      "        9.0707e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([132.7054, 161.5212, 178.4613, 181.9755,   8.2693,   8.2685,   8.2690,\n",
      "        268.9376, 268.9376, 268.9376,   8.2693,   8.2696, 268.9376, 268.9376,\n",
      "        268.9376, 268.9376, 268.9376,  41.4172,  41.4172,   8.2697, 268.9376,\n",
      "        268.9376, 268.9376, 268.9376, 268.9376,  41.4172,  41.4172, 268.9376,\n",
      "         41.4172,  41.4172,   5.2026, 268.9376, 268.9376, 268.9376, 268.9376,\n",
      "        268.9376,  41.4172,  41.4172, 268.9376,  41.4172,  41.4172,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 268.9376,   5.2026,   5.2025, 268.9376,   5.2026,\n",
      "          5.2025, 268.9376,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        268.9376, 268.9376, 268.9376, 268.9376,  41.4172,  41.4172,  41.4172,\n",
      "         41.4172, 268.9376, 268.9376, 268.9376,  41.4172,  41.4172,  41.4172,\n",
      "         41.4172,   5.2026,  41.4172,  41.4172,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 350 was 90.3%\n",
      "tensor([0.0000e+00, 5.6175e-06, 3.8284e-06, 6.4520e-06, 0.0000e+00, 0.0000e+00,\n",
      "        5.1419e-08, 0.0000e+00, 4.4866e-08, 7.7269e-06, 7.4518e-06, 7.3818e-06,\n",
      "        1.0938e-03, 8.8899e-04, 8.8201e-04, 6.9919e-06, 6.9215e-06, 5.8983e-04,\n",
      "        5.8439e-04, 6.2496e-01, 6.1346e-01, 2.3519e+00, 2.3634e+00, 6.6527e-06,\n",
      "        5.5941e-04, 5.7098e-01, 2.4063e+00, 5.0375e-01, 2.4745e+00, 6.6684e-01,\n",
      "        9.0399e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([133.0052, 161.8769, 178.8184, 182.2762,   8.2677,   8.2681,   8.2683,\n",
      "        269.3642, 269.3642, 269.3642,   8.2686,   8.2680, 269.3642, 269.3642,\n",
      "        269.3642, 269.3642, 269.3642,  41.4965,  41.4965,   8.2677, 269.3642,\n",
      "        269.3642, 269.3642, 269.3642, 269.3642,  41.4965,  41.4965, 269.3642,\n",
      "         41.4965,  41.4965,   5.2026, 269.3642, 269.3642, 269.3642, 269.3642,\n",
      "        269.3642,  41.4965,  41.4965, 269.3642,  41.4965,  41.4965,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 269.3642,   5.2026,   5.2025, 269.3642,   5.2026,\n",
      "          5.2025, 269.3642,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        269.3642, 269.3642, 269.3642, 269.3642,  41.4965,  41.4965,  41.4965,\n",
      "         41.4965, 269.3642, 269.3642, 269.3642,  41.4965,  41.4965,  41.4965,\n",
      "         41.4965,   5.2026,  41.4965,  41.4965,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 351 was 90.4%\n",
      "tensor([7.4190e-07, 4.7935e-06, 4.9518e-06, 1.1858e-20, 9.3448e-06, 1.0486e-07,\n",
      "        0.0000e+00, 6.6619e-08, 0.0000e+00, 7.7059e-06, 7.4310e-06, 7.3620e-06,\n",
      "        1.0807e-03, 8.7831e-04, 8.7144e-04, 6.9726e-06, 6.9043e-06, 5.8234e-04,\n",
      "        5.7713e-04, 6.2320e-01, 6.1189e-01, 2.3461e+00, 2.3574e+00, 6.6375e-06,\n",
      "        5.5266e-04, 5.6961e-01, 2.4001e+00, 5.0256e-01, 2.4681e+00, 6.6512e-01,\n",
      "        9.0424e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([133.3045, 162.2317, 179.1777, 182.5743,   8.2671,   8.2669,   8.2667,\n",
      "        269.7907, 269.7907, 269.7907,   8.2665,   8.2670, 269.7907, 269.7907,\n",
      "        269.7907, 269.7907, 269.7907,  41.5759,  41.5759,   8.2672, 269.7907,\n",
      "        269.7907, 269.7907, 269.7907, 269.7907,  41.5759,  41.5759, 269.7907,\n",
      "         41.5759,  41.5759,   5.2026, 269.7907, 269.7907, 269.7907, 269.7907,\n",
      "        269.7907,  41.5759,  41.5759, 269.7907,  41.5759,  41.5759,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 269.7907,   5.2026,   5.2025, 269.7907,   5.2026,\n",
      "          5.2025, 269.7907,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        269.7907, 269.7907, 269.7907, 269.7907,  41.5759,  41.5759,  41.5759,\n",
      "         41.5759, 269.7907, 269.7907, 269.7907,  41.5759,  41.5759,  41.5759,\n",
      "         41.5759,   5.2026,  41.5759,  41.5759,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 352 was 90.4%\n",
      "tensor([0.0000e+00, 5.5875e-06, 3.8122e-06, 6.4208e-06, 8.4703e-21, 0.0000e+00,\n",
      "        5.0411e-08, 0.0000e+00, 4.4018e-08, 7.6834e-06, 7.4104e-06, 7.3439e-06,\n",
      "        1.0674e-03, 8.6761e-04, 8.6114e-04, 6.9546e-06, 6.8869e-06, 5.7506e-04,\n",
      "        5.6993e-04, 6.2138e-01, 6.1035e-01, 2.3403e+00, 2.3514e+00, 6.6207e-06,\n",
      "        5.4581e-04, 5.6826e-01, 2.3938e+00, 5.0139e-01, 2.4617e+00, 6.6340e-01,\n",
      "        9.0448e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([133.6032, 162.5854, 179.5325, 182.8744,   8.2651,   8.2659,   8.2663,\n",
      "        270.2171, 270.2171, 270.2171,   8.2660,   8.2657, 270.2171, 270.2171,\n",
      "        270.2171, 270.2171, 270.2171,  41.6552,  41.6552,   8.2652, 270.2171,\n",
      "        270.2171, 270.2171, 270.2171, 270.2171,  41.6552,  41.6552, 270.2171,\n",
      "         41.6552,  41.6552,   5.2026, 270.2171, 270.2171, 270.2171, 270.2171,\n",
      "        270.2171,  41.6552,  41.6552, 270.2171,  41.6552,  41.6552,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 270.2171,   5.2026,   5.2025, 270.2171,   5.2026,\n",
      "          5.2025, 270.2171,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        270.2171, 270.2171, 270.2171, 270.2171,  41.6552,  41.6552,  41.6552,\n",
      "         41.6552, 270.2171, 270.2171, 270.2171,  41.6552,  41.6552,  41.6552,\n",
      "         41.6552,   5.2026,  41.6552,  41.6552,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 353 was 90.4%\n",
      "tensor([2.2364e-05, 1.3891e-19, 3.1004e-06, 5.6699e-05, 3.3011e-05, 0.0000e+00,\n",
      "        3.3406e-06, 0.0000e+00, 2.9182e-06, 7.3709e-06, 7.1086e-06, 7.0451e-06,\n",
      "        1.0537e-03, 8.5635e-04, 8.4993e-04, 6.6712e-06, 6.6084e-06, 5.6716e-04,\n",
      "        5.6229e-04, 6.1960e-01, 6.0880e-01, 2.3346e+00, 2.3454e+00, 6.3545e-06,\n",
      "        5.3866e-04, 5.6691e-01, 2.3876e+00, 5.0020e-01, 2.4553e+00, 6.6173e-01,\n",
      "        9.0473e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([133.8414, 162.8839, 177.7171, 184.6217,   8.2645,   8.2653,   8.2626,\n",
      "        270.6435, 270.6435, 270.6435,   8.2656,   8.2638, 270.6435, 270.6435,\n",
      "        270.6435, 270.6435, 270.6435,  41.7346,  41.7346,   8.2645, 270.6435,\n",
      "        270.6435, 270.6435, 270.6435, 270.6435,  41.7346,  41.7346, 270.6435,\n",
      "         41.7346,  41.7346,   5.2026, 270.6435, 270.6435, 270.6435, 270.6435,\n",
      "        270.6435,  41.7346,  41.7346, 270.6435,  41.7346,  41.7346,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 270.6435,   5.2026,   5.2025, 270.6435,   5.2026,\n",
      "          5.2025, 270.6435,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        270.6435, 270.6435, 270.6435, 270.6435,  41.7346,  41.7346,  41.7346,\n",
      "         41.7346, 270.6435, 270.6435, 270.6435,  41.7346,  41.7346,  41.7346,\n",
      "         41.7346,   5.2026,  41.7346,  41.7346,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 354 was 90.4%\n",
      "tensor([7.4358e-07, 5.5466e-06, 3.9468e-06, 5.6489e-06, 2.5411e-20, 0.0000e+00,\n",
      "        4.2079e-08, 0.0000e+00, 3.6828e-08, 7.6499e-06, 7.4126e-06, 7.2787e-06,\n",
      "        1.0102e-03, 8.4041e-04, 8.2736e-04, 6.9603e-06, 6.8245e-06, 5.5474e-04,\n",
      "        5.4456e-04, 6.2483e-01, 6.0236e-01, 2.3252e+00, 2.3477e+00, 6.5937e-06,\n",
      "        5.2429e-04, 5.6584e-01, 2.3846e+00, 4.9941e-01, 2.4521e+00, 6.6070e-01,\n",
      "        9.0486e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([134.1412, 163.2361, 178.0361, 184.8958,   8.2632,   8.2637,   8.2622,\n",
      "        271.0697, 271.0697, 271.0697,   8.2635,   8.2631, 271.0697, 271.0697,\n",
      "        271.0697, 271.0697, 271.0697,  41.8139,  41.8139,   8.2635, 271.0697,\n",
      "        271.0697, 271.0697, 271.0697, 271.0697,  41.8139,  41.8139, 271.0697,\n",
      "         41.8139,  41.8139,   5.2026, 271.0697, 271.0697, 271.0697, 271.0697,\n",
      "        271.0697,  41.8139,  41.8139, 271.0697,  41.8139,  41.8139,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 271.0697,   5.2026,   5.2025, 271.0697,   5.2026,\n",
      "          5.2025, 271.0697,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        271.0697, 271.0697, 271.0697, 271.0697,  41.8139,  41.8139,  41.8139,\n",
      "         41.8139, 271.0697, 271.0697, 271.0697,  41.8139,  41.8139,  41.8139,\n",
      "         41.8139,   5.2026,  41.8139,  41.8139,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 355 was 90.5%\n",
      "tensor([0.0000e+00, 4.5487e-06, 4.8715e-06, 0.0000e+00, 1.1714e-05, 1.2594e-07,\n",
      "        0.0000e+00, 8.0871e-08, 0.0000e+00, 7.6288e-06, 7.3929e-06, 7.2602e-06,\n",
      "        9.9762e-04, 8.3031e-04, 8.1766e-04, 6.9426e-06, 6.8076e-06, 5.4781e-04,\n",
      "        5.3785e-04, 6.2302e-01, 6.0090e-01, 2.3198e+00, 2.3420e+00, 6.5783e-06,\n",
      "        5.1798e-04, 5.6460e-01, 2.3787e+00, 4.9832e-01, 2.4460e+00, 6.5907e-01,\n",
      "        9.0509e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([134.4399, 163.5874, 178.3569, 185.1688,   8.2619,   8.2615,   8.2619,\n",
      "        271.4960, 271.4960, 271.4960,   8.2625,   8.2623, 271.4960, 271.4960,\n",
      "        271.4960, 271.4960, 271.4960,  41.8932,  41.8932,   8.2620, 271.4960,\n",
      "        271.4960, 271.4960, 271.4960, 271.4960,  41.8932,  41.8932, 271.4960,\n",
      "         41.8932,  41.8932,   5.2026, 271.4960, 271.4960, 271.4960, 271.4960,\n",
      "        271.4960,  41.8932,  41.8932, 271.4960,  41.8932,  41.8932,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 271.4960,   5.2026,   5.2025, 271.4960,   5.2026,\n",
      "          5.2025, 271.4960,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        271.4960, 271.4960, 271.4960, 271.4960,  41.8932,  41.8932,  41.8932,\n",
      "         41.8932, 271.4960, 271.4960, 271.4960,  41.8932,  41.8932,  41.8932,\n",
      "         41.8932,   5.2026,  41.8932,  41.8932,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 356 was 90.5%\n",
      "tensor([0.0000e+00, 4.5395e-06, 4.8602e-06, 2.7105e-20, 1.1676e-05, 1.2460e-07,\n",
      "        0.0000e+00, 8.0017e-08, 0.0000e+00, 7.6085e-06, 7.3742e-06, 7.2418e-06,\n",
      "        9.8551e-04, 8.2060e-04, 8.0815e-04, 6.9246e-06, 6.7915e-06, 5.4106e-04,\n",
      "        5.3142e-04, 6.2127e-01, 5.9947e-01, 2.3145e+00, 2.3364e+00, 6.5637e-06,\n",
      "        5.1190e-04, 5.6332e-01, 2.3729e+00, 4.9728e-01, 2.4399e+00, 6.5749e-01,\n",
      "        9.0532e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([134.7376, 163.9379, 178.6797, 185.4402,   8.2605,   8.2611,   8.2612,\n",
      "        271.9221, 271.9221, 271.9221,   8.2603,   8.2608, 271.9221, 271.9221,\n",
      "        271.9221, 271.9221, 271.9221,  41.9726,  41.9726,   8.2610, 271.9221,\n",
      "        271.9221, 271.9221, 271.9221, 271.9221,  41.9726,  41.9726, 271.9221,\n",
      "         41.9726,  41.9726,   5.2026, 271.9221, 271.9221, 271.9221, 271.9221,\n",
      "        271.9221,  41.9726,  41.9726, 271.9221,  41.9726,  41.9726,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 271.9221,   5.2026,   5.2025, 271.9221,   5.2026,\n",
      "          5.2025, 271.9221,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        271.9221, 271.9221, 271.9221, 271.9221,  41.9726,  41.9726,  41.9726,\n",
      "         41.9726, 271.9221, 271.9221, 271.9221,  41.9726,  41.9726,  41.9726,\n",
      "         41.9726,   5.2026,  41.9726,  41.9726,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 357 was 90.5%\n",
      "tensor([2.0625e-07, 5.1696e-06, 4.1651e-06, 3.8325e-06, 3.6473e-06, 1.0588e-22,\n",
      "        1.7727e-08, 0.0000e+00, 1.5542e-08, 7.5882e-06, 7.3547e-06, 7.2245e-06,\n",
      "        9.7365e-04, 8.1108e-04, 7.9898e-04, 6.9078e-06, 6.7760e-06, 5.3447e-04,\n",
      "        5.2501e-04, 6.1955e-01, 5.9803e-01, 2.3092e+00, 2.3308e+00, 6.5494e-06,\n",
      "        5.0588e-04, 5.6215e-01, 2.3670e+00, 4.9621e-01, 2.4340e+00, 6.5592e-01,\n",
      "        9.0555e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([135.0333, 164.2880, 179.0169, 185.7020,   8.2594,   8.2595,   8.2590,\n",
      "        272.3483, 272.3483, 272.3483,   8.2599,   8.2597, 272.3483, 272.3483,\n",
      "        272.3483, 272.3483, 272.3483,  42.0519,  42.0519,   8.2601, 272.3483,\n",
      "        272.3483, 272.3483, 272.3483, 272.3483,  42.0519,  42.0519, 272.3483,\n",
      "         42.0519,  42.0519,   5.2026, 272.3483, 272.3483, 272.3483, 272.3483,\n",
      "        272.3483,  42.0519,  42.0519, 272.3483,  42.0519,  42.0519,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 272.3483,   5.2026,   5.2025, 272.3483,   5.2026,\n",
      "          5.2025, 272.3483,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        272.3483, 272.3483, 272.3483, 272.3483,  42.0519,  42.0519,  42.0519,\n",
      "         42.0519, 272.3483, 272.3483, 272.3483,  42.0519,  42.0519,  42.0519,\n",
      "         42.0519,   5.2026,  42.0519,  42.0519,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 358 was 90.5%\n",
      "tensor([0.0000e+00, 4.5243e-06, 4.8374e-06, 4.2352e-21, 1.1570e-05, 1.2163e-07,\n",
      "        0.0000e+00, 7.8104e-08, 0.0000e+00, 7.5671e-06, 7.3359e-06, 7.2078e-06,\n",
      "        9.6185e-04, 8.0142e-04, 7.8961e-04, 6.8895e-06, 6.7599e-06, 5.2788e-04,\n",
      "        5.1866e-04, 6.1780e-01, 5.9657e-01, 2.3039e+00, 2.3252e+00, 6.5345e-06,\n",
      "        4.9977e-04, 5.6088e-01, 2.3613e+00, 4.9518e-01, 2.4280e+00, 6.5434e-01,\n",
      "        9.0578e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([135.3292, 164.6369, 179.3439, 185.9700,   8.2584,   8.2585,   8.2586,\n",
      "        272.7743, 272.7743, 272.7743,   8.2582,   8.2587, 272.7743, 272.7743,\n",
      "        272.7743, 272.7743, 272.7743,  42.1312,  42.1312,   8.2580, 272.7743,\n",
      "        272.7743, 272.7743, 272.7743, 272.7743,  42.1312,  42.1312, 272.7743,\n",
      "         42.1312,  42.1312,   5.2026, 272.7743, 272.7743, 272.7743, 272.7743,\n",
      "        272.7743,  42.1312,  42.1312, 272.7743,  42.1312,  42.1312,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 272.7743,   5.2026,   5.2025, 272.7743,   5.2026,\n",
      "          5.2025, 272.7743,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        272.7743, 272.7743, 272.7743, 272.7743,  42.1312,  42.1312,  42.1312,\n",
      "         42.1312, 272.7743, 272.7743, 272.7743,  42.1312,  42.1312,  42.1312,\n",
      "         42.1312,   5.2026,  42.1312,  42.1312,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 359 was 90.6%\n",
      "tensor([0.0000e+00, 5.0403e-06, 4.1781e-06, 3.7124e-06, 3.6707e-06, 7.3102e-08,\n",
      "        0.0000e+00, 4.6937e-08, 0.0000e+00, 7.5471e-06, 7.3167e-06, 7.1901e-06,\n",
      "        9.5036e-04, 7.9198e-04, 7.8051e-04, 6.8724e-06, 6.7441e-06, 5.2134e-04,\n",
      "        5.1235e-04, 6.1609e-01, 5.9519e-01, 2.2987e+00, 2.3196e+00, 6.5209e-06,\n",
      "        4.9385e-04, 5.5966e-01, 2.3555e+00, 4.9411e-01, 2.4221e+00, 6.5279e-01,\n",
      "        9.0600e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([135.6239, 164.9852, 179.6798, 186.2317,   8.2574,   8.2571,   8.2569,\n",
      "        273.2003, 273.2003, 273.2003,   8.2575,   8.2565, 273.2003, 273.2003,\n",
      "        273.2003, 273.2003, 273.2003,  42.2105,  42.2105,   8.2575, 273.2003,\n",
      "        273.2003, 273.2003, 273.2003, 273.2003,  42.2105,  42.2105, 273.2003,\n",
      "         42.2105,  42.2105,   5.2026, 273.2003, 273.2003, 273.2003, 273.2003,\n",
      "        273.2003,  42.2105,  42.2105, 273.2003,  42.2105,  42.2105,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 273.2003,   5.2026,   5.2025, 273.2003,   5.2026,\n",
      "          5.2025, 273.2003,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        273.2003, 273.2003, 273.2003, 273.2003,  42.2105,  42.2105,  42.2105,\n",
      "         42.2105, 273.2003, 273.2003, 273.2003,  42.2105,  42.2105,  42.2105,\n",
      "         42.2105,   5.2026,  42.2105,  42.2105,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 360 was 90.6%\n",
      "tensor([0.0000e+00, 4.5098e-06, 4.8150e-06, 5.0822e-21, 1.1458e-05, 1.1866e-07,\n",
      "        0.0000e+00, 7.6183e-08, 0.0000e+00, 7.5263e-06, 7.2981e-06, 7.1731e-06,\n",
      "        9.3879e-04, 7.8267e-04, 7.7137e-04, 6.8545e-06, 6.7292e-06, 5.1485e-04,\n",
      "        5.0613e-04, 6.1438e-01, 5.9373e-01, 2.2935e+00, 2.3142e+00, 6.5059e-06,\n",
      "        4.8786e-04, 5.5844e-01, 2.3498e+00, 4.9307e-01, 2.4162e+00, 6.5123e-01,\n",
      "        9.0622e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([135.9181, 165.3327, 180.0107, 186.4964,   8.2556,   8.2564,   8.2563,\n",
      "        273.6262, 273.6262, 273.6262,   8.2554,   8.2561, 273.6262, 273.6262,\n",
      "        273.6262, 273.6262, 273.6262,  42.2899,  42.2899,   8.2559, 273.6262,\n",
      "        273.6262, 273.6262, 273.6262, 273.6262,  42.2899,  42.2899, 273.6262,\n",
      "         42.2899,  42.2899,   5.2026, 273.6262, 273.6262, 273.6262, 273.6262,\n",
      "        273.6262,  42.2899,  42.2899, 273.6262,  42.2899,  42.2899,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 273.6262,   5.2026,   5.2025, 273.6262,   5.2026,\n",
      "          5.2025, 273.6262,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        273.6262, 273.6262, 273.6262, 273.6262,  42.2899,  42.2899,  42.2899,\n",
      "         42.2899, 273.6262, 273.6262, 273.6262,  42.2899,  42.2899,  42.2899,\n",
      "         42.2899,   5.2026,  42.2899,  42.2899,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 361 was 90.6%\n",
      "tensor([0.0000e+00, 4.5023e-06, 4.8037e-06, 1.3553e-20, 1.1407e-05, 1.1724e-07,\n",
      "        0.0000e+00, 7.5260e-08, 0.0000e+00, 7.5069e-06, 7.2785e-06, 7.1560e-06,\n",
      "        9.2747e-04, 7.7327e-04, 7.6241e-04, 6.8377e-06, 6.7130e-06, 5.0843e-04,\n",
      "        4.9986e-04, 6.1264e-01, 5.9236e-01, 2.2883e+00, 2.3086e+00, 6.4920e-06,\n",
      "        4.8201e-04, 5.5725e-01, 2.3441e+00, 4.9200e-01, 2.4104e+00, 6.4968e-01,\n",
      "        9.0645e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([136.2114, 165.6794, 180.3432, 186.7597,   8.2546,   8.2542,   8.2547,\n",
      "        274.0521, 274.0521, 274.0521,   8.2549,   8.2548, 274.0521, 274.0521,\n",
      "        274.0521, 274.0521, 274.0521,  42.3692,  42.3692,   8.2552, 274.0521,\n",
      "        274.0521, 274.0521, 274.0521, 274.0521,  42.3692,  42.3692, 274.0521,\n",
      "         42.3692,  42.3692,   5.2026, 274.0521, 274.0521, 274.0521, 274.0521,\n",
      "        274.0521,  42.3692,  42.3692, 274.0521,  42.3692,  42.3692,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 274.0521,   5.2026,   5.2025, 274.0521,   5.2026,\n",
      "          5.2025, 274.0521,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        274.0521, 274.0521, 274.0521, 274.0521,  42.3692,  42.3692,  42.3692,\n",
      "         42.3692, 274.0521, 274.0521, 274.0521,  42.3692,  42.3692,  42.3692,\n",
      "         42.3692,   5.2026,  42.3692,  42.3692,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 362 was 90.6%\n",
      "tensor([6.9884e-07, 5.4310e-06, 3.8592e-06, 5.6068e-06, 1.6941e-21, 0.0000e+00,\n",
      "        3.9372e-08, 0.0000e+00, 3.4604e-08, 7.4864e-06, 7.2608e-06, 7.1392e-06,\n",
      "        9.1629e-04, 7.6423e-04, 7.5355e-04, 6.8198e-06, 6.6978e-06, 5.0217e-04,\n",
      "        4.9392e-04, 6.1093e-01, 5.9094e-01, 2.2831e+00, 2.3032e+00, 6.4773e-06,\n",
      "        4.7623e-04, 5.5602e-01, 2.3385e+00, 4.9101e-01, 2.4045e+00, 6.4814e-01,\n",
      "        9.0667e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([136.5045, 166.0253, 180.6745, 187.0232,   8.2535,   8.2538,   8.2536,\n",
      "        274.4779, 274.4779, 274.4779,   8.2533,   8.2538, 274.4779, 274.4779,\n",
      "        274.4779, 274.4779, 274.4779,  42.4485,  42.4485,   8.2531, 274.4779,\n",
      "        274.4779, 274.4779, 274.4779, 274.4779,  42.4485,  42.4485, 274.4779,\n",
      "         42.4485,  42.4485,   5.2026, 274.4779, 274.4779, 274.4779, 274.4779,\n",
      "        274.4779,  42.4485,  42.4485, 274.4779,  42.4485,  42.4485,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 274.4779,   5.2026,   5.2025, 274.4779,   5.2026,\n",
      "          5.2025, 274.4779,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        274.4779, 274.4779, 274.4779, 274.4779,  42.4485,  42.4485,  42.4485,\n",
      "         42.4485, 274.4779, 274.4779, 274.4779,  42.4485,  42.4485,  42.4485,\n",
      "         42.4485,   5.2026,  42.4485,  42.4485,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 363 was 90.6%\n",
      "tensor([0.0000e+00, 4.9922e-06, 4.1368e-06, 3.6827e-06, 3.6445e-06, 7.0737e-08,\n",
      "        0.0000e+00, 4.5377e-08, 0.0000e+00, 7.4671e-06, 7.2415e-06, 7.1226e-06,\n",
      "        9.0744e-04, 7.5666e-04, 7.4624e-04, 6.8032e-06, 6.6822e-06, 4.9674e-04,\n",
      "        4.8855e-04, 6.0928e-01, 5.8959e-01, 2.2784e+00, 2.2981e+00, 6.4639e-06,\n",
      "        4.7113e-04, 5.5481e-01, 2.3331e+00, 4.8995e-01, 2.3989e+00, 6.4659e-01,\n",
      "        9.0688e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([136.7966, 166.3699, 181.0033, 187.2886,   8.2527,   8.2514,   8.2523,\n",
      "        274.9037, 274.9037, 274.9037,   8.2525,   8.2521, 274.9037, 274.9037,\n",
      "        274.9037, 274.9037, 274.9037,  42.5278,  42.5278,   8.2526, 274.9037,\n",
      "        274.9037, 274.9037, 274.9037, 274.9037,  42.5278,  42.5278, 274.9037,\n",
      "         42.5278,  42.5278,   5.2026, 274.9037, 274.9037, 274.9037, 274.9037,\n",
      "        274.9037,  42.5278,  42.5278, 274.9037,  42.5278,  42.5278,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 274.9037,   5.2026,   5.2025, 274.9037,   5.2026,\n",
      "          5.2025, 274.9037,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        274.9037, 274.9037, 274.9037, 274.9037,  42.5278,  42.5278,  42.5278,\n",
      "         42.5278, 274.9037, 274.9037, 274.9037,  42.5278,  42.5278,  42.5278,\n",
      "         42.5278,   5.2026,  42.5278,  42.5278,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 364 was 90.7%\n",
      "tensor([1.9216e-07, 5.0786e-06, 4.0962e-06, 3.7733e-06, 3.6055e-06, 3.9705e-23,\n",
      "        1.6174e-08, 0.0000e+00, 1.4224e-08, 7.4469e-06, 7.2244e-06, 7.1060e-06,\n",
      "        8.9647e-04, 7.4787e-04, 7.3760e-04, 6.7860e-06, 6.6677e-06, 4.9062e-04,\n",
      "        4.8272e-04, 6.0761e-01, 5.8820e-01, 2.2733e+00, 2.2927e+00, 6.4491e-06,\n",
      "        4.6546e-04, 5.5360e-01, 2.3275e+00, 4.8894e-01, 2.3931e+00, 6.4507e-01,\n",
      "        9.0710e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([137.0884, 166.7137, 181.3313, 187.5540,   8.2503,   8.2510,   8.2512,\n",
      "        275.3294, 275.3294, 275.3294,   8.2511,   8.2516, 275.3294, 275.3294,\n",
      "        275.3294, 275.3294, 275.3294,  42.6071,  42.6071,   8.2511, 275.3294,\n",
      "        275.3294, 275.3294, 275.3294, 275.3294,  42.6071,  42.6071, 275.3294,\n",
      "         42.6071,  42.6071,   5.2026, 275.3294, 275.3294, 275.3294, 275.3294,\n",
      "        275.3294,  42.6071,  42.6071, 275.3294,  42.6071,  42.6071,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 275.3294,   5.2026,   5.2025, 275.3294,   5.2026,\n",
      "          5.2025, 275.3294,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        275.3294, 275.3294, 275.3294, 275.3294,  42.6071,  42.6071,  42.6071,\n",
      "         42.6071, 275.3294, 275.3294, 275.3294,  42.6071,  42.6071,  42.6071,\n",
      "         42.6071,   5.2026,  42.6071,  42.6071,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 365 was 90.7%\n",
      "tensor([7.9409e-23, 4.9686e-06, 4.1168e-06, 3.6684e-06, 3.6318e-06, 6.9516e-08,\n",
      "        0.0000e+00, 4.4585e-08, 0.0000e+00, 7.4282e-06, 7.2048e-06, 7.0890e-06,\n",
      "        8.8573e-04, 7.3890e-04, 7.2896e-04, 6.7688e-06, 6.6517e-06, 4.8450e-04,\n",
      "        4.7672e-04, 6.0592e-01, 5.8682e-01, 2.2682e+00, 2.2873e+00, 6.4355e-06,\n",
      "        4.5989e-04, 5.5240e-01, 2.3219e+00, 4.8793e-01, 2.3873e+00, 6.4356e-01,\n",
      "        9.0731e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([137.3797, 167.0568, 181.6586, 187.8194,   8.2499,   8.2502,   8.2494,\n",
      "        275.7550, 275.7550, 275.7550,   8.2497,   8.2493, 275.7550, 275.7550,\n",
      "        275.7550, 275.7550, 275.7550,  42.6865,  42.6865,   8.2504, 275.7550,\n",
      "        275.7550, 275.7550, 275.7550, 275.7550,  42.6865,  42.6865, 275.7550,\n",
      "         42.6865,  42.6865,   5.2026, 275.7550, 275.7550, 275.7550, 275.7550,\n",
      "        275.7550,  42.6865,  42.6865, 275.7550,  42.6865,  42.6865,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 275.7550,   5.2026,   5.2025, 275.7550,   5.2026,\n",
      "          5.2025, 275.7550,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        275.7550, 275.7550, 275.7550, 275.7550,  42.6865,  42.6865,  42.6865,\n",
      "         42.6865, 275.7550, 275.7550, 275.7550,  42.6865,  42.6865,  42.6865,\n",
      "         42.6865,   5.2026,  42.6865,  42.6865,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 366 was 90.7%\n",
      "tensor([0.0000e+00, 4.9350e-06, 4.7516e-06, 5.5993e-06, 0.0000e+00, 5.3733e-08,\n",
      "        0.0000e+00, 0.0000e+00, 3.3815e-08, 7.4074e-06, 7.1865e-06, 7.0726e-06,\n",
      "        8.7720e-04, 7.3268e-04, 7.2310e-04, 6.7522e-06, 6.6369e-06, 4.8086e-04,\n",
      "        4.7338e-04, 6.0426e-01, 5.8535e-01, 2.2625e+00, 2.2815e+00, 6.4210e-06,\n",
      "        4.5689e-04, 5.5121e-01, 2.3160e+00, 4.8686e-01, 2.3814e+00, 6.4203e-01,\n",
      "        9.0755e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([137.6679, 167.3971, 181.9664, 188.1012,   8.2481,   8.2485,   8.2487,\n",
      "        276.1806, 276.1806, 276.1806,   8.2490,   8.2488, 276.1806, 276.1806,\n",
      "        276.1806, 276.1806, 276.1806,  42.7658,  42.7658,   8.2482, 276.1806,\n",
      "        276.1806, 276.1806, 276.1806, 276.1806,  42.7658,  42.7658, 276.1806,\n",
      "         42.7658,  42.7658,   5.2026, 276.1806, 276.1806, 276.1806, 276.1806,\n",
      "        276.1806,  42.7658,  42.7658, 276.1806,  42.7658,  42.7658,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 276.1806,   5.2026,   5.2025, 276.1806,   5.2026,\n",
      "          5.2025, 276.1806,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        276.1806, 276.1806, 276.1806, 276.1806,  42.7658,  42.7658,  42.7658,\n",
      "         42.7658, 276.1806, 276.1806, 276.1806,  42.7658,  42.7658,  42.7658,\n",
      "         42.7658,   5.2026,  42.7658,  42.7658,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 367 was 90.7%\n",
      "tensor([7.7230e-07, 5.3642e-06, 2.8180e-06, 0.0000e+00, 1.1089e-05, 0.0000e+00,\n",
      "        7.8207e-08, 7.0330e-08, 0.0000e+00, 7.3890e-06, 7.1688e-06, 7.0550e-06,\n",
      "        8.6698e-04, 7.2434e-04, 7.1489e-04, 6.7351e-06, 6.6211e-06, 4.7512e-04,\n",
      "        4.6784e-04, 6.0268e-01, 5.8398e-01, 2.2574e+00, 2.2762e+00, 6.4076e-06,\n",
      "        4.5170e-04, 5.4997e-01, 2.3105e+00, 4.8585e-01, 2.3757e+00, 6.4052e-01,\n",
      "        9.0777e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([137.9560, 167.7370, 182.2733, 188.3840,   8.2474,   8.2474,   8.2474,\n",
      "        276.6062, 276.6062, 276.6062,   8.2468,   8.2472, 276.6062, 276.6062,\n",
      "        276.6062, 276.6062, 276.6062,  42.8451,  42.8451,   8.2477, 276.6062,\n",
      "        276.6062, 276.6062, 276.6062, 276.6062,  42.8451,  42.8451, 276.6062,\n",
      "         42.8451,  42.8451,   5.2026, 276.6062, 276.6062, 276.6062, 276.6062,\n",
      "        276.6062,  42.8451,  42.8451, 276.6062,  42.8451,  42.8451,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 276.6062,   5.2026,   5.2025, 276.6062,   5.2026,\n",
      "          5.2025, 276.6062,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        276.6062, 276.6062, 276.6062, 276.6062,  42.8451,  42.8451,  42.8451,\n",
      "         42.8451, 276.6062, 276.6062, 276.6062,  42.8451,  42.8451,  42.8451,\n",
      "         42.8451,   5.2026,  42.8451,  42.8451,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 368 was 90.7%\n",
      "tensor([7.6682e-07, 5.3507e-06, 2.8121e-06, 1.1011e-20, 1.1065e-05, 0.0000e+00,\n",
      "        7.7454e-08, 6.9677e-08, 0.0000e+00, 7.3689e-06, 7.1509e-06, 7.0386e-06,\n",
      "        8.5664e-04, 7.1613e-04, 7.0695e-04, 6.7195e-06, 6.6058e-06, 4.6952e-04,\n",
      "        4.6234e-04, 6.0110e-01, 5.8255e-01, 2.2523e+00, 2.2709e+00, 6.3929e-06,\n",
      "        4.4644e-04, 5.4881e-01, 2.3050e+00, 4.8481e-01, 2.3700e+00, 6.3901e-01,\n",
      "        9.0798e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([138.2436, 168.0761, 182.5786, 188.6676,   8.2456,   8.2457,   8.2466,\n",
      "        277.0316, 277.0316, 277.0316,   8.2463,   8.2464, 277.0316, 277.0316,\n",
      "        277.0316, 277.0316, 277.0316,  42.9244,  42.9244,   8.2455, 277.0316,\n",
      "        277.0316, 277.0316, 277.0316, 277.0316,  42.9244,  42.9244, 277.0316,\n",
      "         42.9244,  42.9244,   5.2026, 277.0316, 277.0316, 277.0316, 277.0316,\n",
      "        277.0316,  42.9244,  42.9244, 277.0316,  42.9244,  42.9244,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 277.0316,   5.2026,   5.2025, 277.0316,   5.2026,\n",
      "          5.2025, 277.0316,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        277.0316, 277.0316, 277.0316, 277.0316,  42.9244,  42.9244,  42.9244,\n",
      "         42.9244, 277.0316, 277.0316, 277.0316,  42.9244,  42.9244,  42.9244,\n",
      "         42.9244,   5.2026,  42.9244,  42.9244,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 369 was 90.8%\n",
      "tensor([1.0358e-06, 5.3376e-06, 4.7194e-06, 0.0000e+00, 1.1050e-05, 0.0000e+00,\n",
      "        0.0000e+00, 6.9208e-08, 0.0000e+00, 7.3510e-06, 7.1337e-06, 7.0214e-06,\n",
      "        8.4873e-04, 7.0955e-04, 7.0032e-04, 6.7024e-06, 6.5905e-06, 4.6474e-04,\n",
      "        4.5768e-04, 5.9953e-01, 5.8118e-01, 2.2477e+00, 2.2660e+00, 6.3799e-06,\n",
      "        4.4198e-04, 5.4759e-01, 2.2998e+00, 4.8379e-01, 2.3646e+00, 6.3749e-01,\n",
      "        9.0818e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([138.5355, 168.4180, 182.9065, 188.9284,   8.2451,   8.2446,   8.2443,\n",
      "        277.4571, 277.4571, 277.4571,   8.2449,   8.2447, 277.4571, 277.4571,\n",
      "        277.4571, 277.4571, 277.4571,  43.0037,  43.0037,   8.2451, 277.4571,\n",
      "        277.4571, 277.4571, 277.4571, 277.4571,  43.0037,  43.0037, 277.4571,\n",
      "         43.0037,  43.0037,   5.2026, 277.4571, 277.4571, 277.4571, 277.4571,\n",
      "        277.4571,  43.0037,  43.0037, 277.4571,  43.0037,  43.0037,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 277.4571,   5.2026,   5.2025, 277.4571,   5.2026,\n",
      "          5.2025, 277.4571,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        277.4571, 277.4571, 277.4571, 277.4571,  43.0037,  43.0037,  43.0037,\n",
      "         43.0037, 277.4571, 277.4571, 277.4571,  43.0037,  43.0037,  43.0037,\n",
      "         43.0037,   5.2026,  43.0037,  43.0037,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 370 was 90.8%\n",
      "tensor([1.0266e-06, 5.3241e-06, 4.7090e-06, 0.0000e+00, 1.0989e-05, 0.0000e+00,\n",
      "        0.0000e+00, 6.8324e-08, 0.0000e+00, 7.3307e-06, 7.1156e-06, 7.0060e-06,\n",
      "        8.3864e-04, 7.0139e-04, 6.9247e-04, 6.6863e-06, 6.5756e-06, 4.5921e-04,\n",
      "        4.5228e-04, 5.9793e-01, 5.7979e-01, 2.2426e+00, 2.2608e+00, 6.3651e-06,\n",
      "        4.3677e-04, 5.4641e-01, 2.2944e+00, 4.8279e-01, 2.3589e+00, 6.3599e-01,\n",
      "        9.0840e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([138.8270, 168.7592, 183.2340, 189.1888,   8.2427,   8.2438,   8.2438,\n",
      "        277.8824, 277.8824, 277.8824,   8.2435,   8.2439, 277.8824, 277.8824,\n",
      "        277.8824, 277.8824, 277.8824,  43.0830,  43.0830,   8.2435, 277.8824,\n",
      "        277.8824, 277.8824, 277.8824, 277.8824,  43.0830,  43.0830, 277.8824,\n",
      "         43.0830,  43.0830,   5.2026, 277.8824, 277.8824, 277.8824, 277.8824,\n",
      "        277.8824,  43.0830,  43.0830, 277.8824,  43.0830,  43.0830,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 277.8824,   5.2026,   5.2025, 277.8824,   5.2026,\n",
      "          5.2025, 277.8824,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        277.8824, 277.8824, 277.8824, 277.8824,  43.0830,  43.0830,  43.0830,\n",
      "         43.0830, 277.8824, 277.8824, 277.8824,  43.0830,  43.0830,  43.0830,\n",
      "         43.0830,   5.2026,  43.0830,  43.0830,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 371 was 90.8%\n",
      "tensor([1.0178e-06, 5.3107e-06, 4.6984e-06, 0.0000e+00, 1.0937e-05, 0.0000e+00,\n",
      "        0.0000e+00, 6.7496e-08, 0.0000e+00, 7.3128e-06, 7.0971e-06, 6.9893e-06,\n",
      "        8.2897e-04, 6.9330e-04, 6.8465e-04, 6.6698e-06, 6.5603e-06, 4.5369e-04,\n",
      "        4.4692e-04, 5.9629e-01, 5.7846e-01, 2.2377e+00, 2.2555e+00, 6.3520e-06,\n",
      "        4.3176e-04, 5.4526e-01, 2.2889e+00, 4.8179e-01, 2.3533e+00, 6.3451e-01,\n",
      "        9.0861e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([139.1181, 169.0997, 183.5609, 189.4493,   8.2422,   8.2420,   8.2423,\n",
      "        278.3078, 278.3078, 278.3078,   8.2424,   8.2416, 278.3078, 278.3078,\n",
      "        278.3078, 278.3078, 278.3078,  43.1623,  43.1623,   8.2430, 278.3078,\n",
      "        278.3078, 278.3078, 278.3078, 278.3078,  43.1623,  43.1623, 278.3078,\n",
      "         43.1623,  43.1623,   5.2026, 278.3078, 278.3078, 278.3078, 278.3078,\n",
      "        278.3078,  43.1623,  43.1623, 278.3078,  43.1623,  43.1623,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 278.3078,   5.2026,   5.2025, 278.3078,   5.2026,\n",
      "          5.2025, 278.3078,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        278.3078, 278.3078, 278.3078, 278.3078,  43.1623,  43.1623,  43.1623,\n",
      "         43.1623, 278.3078, 278.3078, 278.3078,  43.1623,  43.1623,  43.1623,\n",
      "         43.1623,   5.2026,  43.1623,  43.1623,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 372 was 90.8%\n",
      "tensor([0.0000e+00, 4.8897e-06, 4.0518e-06, 3.6208e-06, 3.5906e-06, 6.7408e-08,\n",
      "        0.0000e+00, 4.3475e-08, 0.0000e+00, 7.2931e-06, 7.0806e-06, 6.9738e-06,\n",
      "        8.3578e-04, 7.0110e-04, 6.9282e-04, 6.6534e-06, 6.5467e-06, 4.6096e-04,\n",
      "        4.5459e-04, 5.9456e-01, 5.7698e-01, 2.2321e+00, 2.2498e+00, 6.3381e-06,\n",
      "        4.3980e-04, 5.4401e-01, 2.2830e+00, 4.8072e-01, 2.3471e+00, 6.3295e-01,\n",
      "        9.0884e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([139.4090, 169.4396, 183.8916, 189.7085,   8.2409,   8.2416,   8.2409,\n",
      "        278.7330, 278.7330, 278.7330,   8.2407,   8.2411, 278.7330, 278.7330,\n",
      "        278.7330, 278.7330, 278.7330,  43.2416,  43.2416,   8.2408, 278.7330,\n",
      "        278.7330, 278.7330, 278.7330, 278.7330,  43.2416,  43.2416, 278.7330,\n",
      "         43.2416,  43.2416,   5.2026, 278.7330, 278.7330, 278.7330, 278.7330,\n",
      "        278.7330,  43.2416,  43.2416, 278.7330,  43.2416,  43.2416,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 278.7330,   5.2026,   5.2025, 278.7330,   5.2026,\n",
      "          5.2025, 278.7330,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        278.7330, 278.7330, 278.7330, 278.7330,  43.2416,  43.2416,  43.2416,\n",
      "         43.2416, 278.7330, 278.7330, 278.7330,  43.2416,  43.2416,  43.2416,\n",
      "         43.2416,   5.2026,  43.2416,  43.2416,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 373 was 90.9%\n",
      "tensor([0.0000e+00, 4.8785e-06, 4.0423e-06, 3.6138e-06, 3.5844e-06, 6.6838e-08,\n",
      "        0.0000e+00, 4.3105e-08, 0.0000e+00, 7.2748e-06, 7.0617e-06, 6.9578e-06,\n",
      "        8.2653e-04, 6.9321e-04, 6.8536e-04, 6.6373e-06, 6.5308e-06, 4.5571e-04,\n",
      "        4.4941e-04, 5.9298e-01, 5.7567e-01, 2.2271e+00, 2.2445e+00, 6.3250e-06,\n",
      "        4.3499e-04, 5.4283e-01, 2.2776e+00, 4.7968e-01, 2.3415e+00, 6.3146e-01,\n",
      "        9.0906e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([139.6996, 169.7788, 184.2216, 189.9676,   8.2398,   8.2393,   8.2396,\n",
      "        279.1583, 279.1583, 279.1583,   8.2402,   8.2394, 279.1583, 279.1583,\n",
      "        279.1583, 279.1583, 279.1583,  43.3209,  43.3209,   8.2401, 279.1583,\n",
      "        279.1583, 279.1583, 279.1583, 279.1583,  43.3209,  43.3209, 279.1583,\n",
      "         43.3209,  43.3209,   5.2026, 279.1583, 279.1583, 279.1583, 279.1583,\n",
      "        279.1583,  43.3209,  43.3209, 279.1583,  43.3209,  43.3209,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 279.1583,   5.2026,   5.2025, 279.1583,   5.2026,\n",
      "          5.2025, 279.1583,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        279.1583, 279.1583, 279.1583, 279.1583,  43.3209,  43.3209,  43.3209,\n",
      "         43.3209, 279.1583, 279.1583, 279.1583,  43.3209,  43.3209,  43.3209,\n",
      "         43.3209,   5.2026,  43.3209,  43.3209,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 374 was 90.9%\n",
      "tensor([1.7935e-07, 4.9592e-06, 4.0056e-06, 3.6979e-06, 3.5494e-06, 0.0000e+00,\n",
      "        1.4658e-08, 0.0000e+00, 1.2983e-08, 7.2556e-06, 7.0452e-06, 6.9415e-06,\n",
      "        8.1719e-04, 6.8569e-04, 6.7786e-04, 6.6204e-06, 6.5171e-06, 4.5048e-04,\n",
      "        4.4447e-04, 5.9137e-01, 5.7434e-01, 2.2222e+00, 2.2393e+00, 6.3110e-06,\n",
      "        4.3017e-04, 5.4164e-01, 2.2723e+00, 4.7873e-01, 2.3360e+00, 6.3000e-01,\n",
      "        9.0927e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([139.9897, 170.1173, 184.5510, 190.2267,   8.2381,   8.2388,   8.2385,\n",
      "        279.5834, 279.5834, 279.5834,   8.2379,   8.2389, 279.5834, 279.5834,\n",
      "        279.5834, 279.5834, 279.5834,  43.4002,  43.4002,   8.2384, 279.5834,\n",
      "        279.5834, 279.5834, 279.5834, 279.5834,  43.4002,  43.4002, 279.5834,\n",
      "         43.4002,  43.4002,   5.2026, 279.5834, 279.5834, 279.5834, 279.5834,\n",
      "        279.5834,  43.4002,  43.4002, 279.5834,  43.4002,  43.4002,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 279.5834,   5.2026,   5.2025, 279.5834,   5.2026,\n",
      "          5.2025, 279.5834,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        279.5834, 279.5834, 279.5834, 279.5834,  43.4002,  43.4002,  43.4002,\n",
      "         43.4002, 279.5834, 279.5834, 279.5834,  43.4002,  43.4002,  43.4002,\n",
      "         43.4002,   5.2026,  43.4002,  43.4002,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(49.6599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 375 was 91.2%\n",
      "tensor([1.5476e-05, 4.2486e-04, 4.0127e-04, 6.7479e-04, 5.3235e-04, 1.6077e-04,\n",
      "        0.0000e+00, 4.7079e-04, 0.0000e+00, 4.9693e-04, 4.8210e-04, 4.7524e-04,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 4.5190e-04, 4.4442e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.6150e-01, 5.4564e-01, 2.1468e+00, 2.1636e+00, 4.2970e-04,\n",
      "        0.0000e+00, 5.1451e-01, 2.1942e+00, 4.5457e-01, 2.2547e+00, 6.3130e-01,\n",
      "        9.1241e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([140.2607, 170.4032, 184.6476, 190.6451,   8.2371,   8.2373,   8.2371,\n",
      "        280.0085, 280.0085, 280.0085,   8.2375,   8.2365, 280.0085, 280.0085,\n",
      "        280.0085, 280.0085, 280.0085,  43.4795,  43.4795,   8.2377, 280.0085,\n",
      "        280.0085, 280.0085, 280.0085, 280.0085,  43.4795,  43.4795, 280.0085,\n",
      "         43.4795,  43.4795,   5.2026, 280.0085, 280.0085, 280.0085, 280.0085,\n",
      "        280.0085,  43.4795,  43.4795, 280.0085,  43.4795,  43.4795,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 280.0085,   5.2026,   5.2025, 280.0085,   5.2026,\n",
      "          5.2025, 280.0085,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        280.0085, 280.0085, 280.0085, 280.0085,  43.4795,  43.4795,  43.4795,\n",
      "         43.4795, 280.0085, 280.0085, 280.0085,  43.4795,  43.4795,  43.4795,\n",
      "         43.4795,   5.2026,  43.4795,  43.4795,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 376 was 90.9%\n",
      "tensor([0.0000e+00, 4.8458e-06, 4.0154e-06, 3.5981e-06, 3.5633e-06, 6.5217e-08,\n",
      "        0.0000e+00, 4.2123e-08, 0.0000e+00, 7.2203e-06, 7.0142e-06, 6.9073e-06,\n",
      "        7.9845e-04, 6.7164e-04, 6.6374e-04, 6.5930e-06, 6.4860e-06, 4.4113e-04,\n",
      "        4.3502e-04, 5.8894e-01, 5.7130e-01, 2.2122e+00, 2.2299e+00, 6.2843e-06,\n",
      "        4.2138e-04, 5.3934e-01, 2.2621e+00, 4.7680e-01, 2.3254e+00, 6.2718e-01,\n",
      "        9.0967e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([140.5501, 170.7409, 184.9771, 190.9033,   8.2361,   8.2361,   8.2361,\n",
      "        280.4336, 280.4336, 280.4336,   8.2358,   8.2361, 280.4336, 280.4336,\n",
      "        280.4336, 280.4336, 280.4336,  43.5588,  43.5588,   8.2354, 280.4336,\n",
      "        280.4336, 280.4336, 280.4336, 280.4336,  43.5588,  43.5588, 280.4336,\n",
      "         43.5588,  43.5588,   5.2026, 280.4336, 280.4336, 280.4336, 280.4336,\n",
      "        280.4336,  43.5588,  43.5588, 280.4336,  43.5588,  43.5588,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 280.4336,   5.2026,   5.2025, 280.4336,   5.2026,\n",
      "          5.2025, 280.4336,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        280.4336, 280.4336, 280.4336, 280.4336,  43.5588,  43.5588,  43.5588,\n",
      "         43.5588, 280.4336, 280.4336, 280.4336,  43.5588,  43.5588,  43.5588,\n",
      "         43.5588,   5.2026,  43.5588,  43.5588,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 377 was 90.9%\n",
      "tensor([0.0000e+00, 4.8346e-06, 4.0063e-06, 3.5910e-06, 3.5575e-06, 6.4799e-08,\n",
      "        0.0000e+00, 4.1850e-08, 0.0000e+00, 7.2019e-06, 6.9962e-06, 6.8914e-06,\n",
      "        7.8958e-04, 6.6416e-04, 6.5655e-04, 6.5770e-06, 6.4709e-06, 4.3608e-04,\n",
      "        4.3011e-04, 5.8736e-01, 5.7004e-01, 2.2073e+00, 2.2247e+00, 6.2713e-06,\n",
      "        4.1673e-04, 5.3817e-01, 2.2568e+00, 4.7579e-01, 2.3200e+00, 6.2572e-01,\n",
      "        9.0988e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([140.8392, 171.0779, 185.3061, 191.1616,   8.2341,   8.2338,   8.2350,\n",
      "        280.8586, 280.8586, 280.8586,   8.2350,   8.2350, 280.8586, 280.8586,\n",
      "        280.8586, 280.8586, 280.8586,  43.6381,  43.6381,   8.2349, 280.8586,\n",
      "        280.8586, 280.8586, 280.8586, 280.8586,  43.6381,  43.6381, 280.8586,\n",
      "         43.6381,  43.6381,   5.2026, 280.8586, 280.8586, 280.8586, 280.8586,\n",
      "        280.8586,  43.6381,  43.6381, 280.8586,  43.6381,  43.6381,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 280.8586,   5.2026,   5.2025, 280.8586,   5.2026,\n",
      "          5.2025, 280.8586,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        280.8586, 280.8586, 280.8586, 280.8586,  43.6381,  43.6381,  43.6381,\n",
      "         43.6381, 280.8586, 280.8586, 280.8586,  43.6381,  43.6381,  43.6381,\n",
      "         43.6381,   5.2026,  43.6381,  43.6381,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 378 was 91.0%\n",
      "tensor([1.7256e-07, 4.9125e-06, 3.9711e-06, 3.6717e-06, 3.5241e-06, 0.0000e+00,\n",
      "        1.3968e-08, 0.0000e+00, 1.2394e-08, 7.1841e-06, 6.9798e-06, 6.8757e-06,\n",
      "        7.8071e-04, 6.5687e-04, 6.4935e-04, 6.5603e-06, 6.4569e-06, 4.3109e-04,\n",
      "        4.2534e-04, 5.8575e-01, 5.6875e-01, 2.2025e+00, 2.2196e+00, 6.2578e-06,\n",
      "        4.1214e-04, 5.3703e-01, 2.2515e+00, 4.7486e-01, 2.3145e+00, 6.2430e-01,\n",
      "        9.1009e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([141.1279, 171.4142, 185.6345, 191.4198,   8.2330,   8.2333,   8.2336,\n",
      "        281.2836, 281.2836, 281.2836,   8.2333,   8.2327, 281.2836, 281.2836,\n",
      "        281.2836, 281.2836, 281.2836,  43.7174,  43.7174,   8.2341, 281.2836,\n",
      "        281.2836, 281.2836, 281.2836, 281.2836,  43.7174,  43.7174, 281.2836,\n",
      "         43.7174,  43.7174,   5.2026, 281.2836, 281.2836, 281.2836, 281.2836,\n",
      "        281.2836,  43.7174,  43.7174, 281.2836,  43.7174,  43.7174,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 281.2836,   5.2026,   5.2025, 281.2836,   5.2026,\n",
      "          5.2025, 281.2836,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        281.2836, 281.2836, 281.2836, 281.2836,  43.7174,  43.7174,  43.7174,\n",
      "         43.7174, 281.2836, 281.2836, 281.2836,  43.7174,  43.7174,  43.7174,\n",
      "         43.7174,   5.2026,  43.7174,  43.7174,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 379 was 91.0%\n",
      "tensor([3.9705e-22, 4.8128e-06, 3.9877e-06, 3.5776e-06, 3.5456e-06, 6.3612e-08,\n",
      "        0.0000e+00, 4.1081e-08, 0.0000e+00, 7.1651e-06, 6.9619e-06, 6.8600e-06,\n",
      "        7.7184e-04, 6.4965e-04, 6.4234e-04, 6.5449e-06, 6.4431e-06, 4.2612e-04,\n",
      "        4.2050e-04, 5.8418e-01, 5.6741e-01, 2.1977e+00, 2.2145e+00, 6.2440e-06,\n",
      "        4.0749e-04, 5.3593e-01, 2.2462e+00, 4.7387e-01, 2.3091e+00, 6.2287e-01,\n",
      "        9.1029e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([141.4162, 171.7499, 185.9624, 191.6780,   8.2319,   8.2322,   8.2318,\n",
      "        281.7085, 281.7085, 281.7085,   8.2322,   8.2322, 281.7085, 281.7085,\n",
      "        281.7085, 281.7085, 281.7085,  43.7967,  43.7967,   8.2319, 281.7085,\n",
      "        281.7085, 281.7085, 281.7085, 281.7085,  43.7967,  43.7967, 281.7085,\n",
      "         43.7967,  43.7967,   5.2026, 281.7085, 281.7085, 281.7085, 281.7085,\n",
      "        281.7085,  43.7967,  43.7967, 281.7085,  43.7967,  43.7967,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 281.7085,   5.2026,   5.2025, 281.7085,   5.2026,\n",
      "          5.2025, 281.7085,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        281.7085, 281.7085, 281.7085, 281.7085,  43.7967,  43.7967,  43.7967,\n",
      "         43.7967, 281.7085, 281.7085, 281.7085,  43.7967,  43.7967,  43.7967,\n",
      "         43.7967,   5.2026,  43.7967,  43.7967,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 380 was 91.0%\n",
      "tensor([0.0000e+00, 4.8017e-06, 3.9789e-06, 3.5704e-06, 3.5400e-06, 6.3310e-08,\n",
      "        0.0000e+00, 4.0883e-08, 0.0000e+00, 7.1469e-06, 6.9440e-06, 6.8445e-06,\n",
      "        7.6322e-04, 6.4231e-04, 6.3530e-04, 6.5288e-06, 6.4279e-06, 4.2122e-04,\n",
      "        4.1570e-04, 5.8265e-01, 5.6615e-01, 2.1928e+00, 2.2094e+00, 6.2310e-06,\n",
      "        4.0296e-04, 5.3473e-01, 2.2410e+00, 4.7289e-01, 2.3037e+00, 6.2142e-01,\n",
      "        9.1050e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([141.7042, 172.0850, 186.2897, 191.9361,   8.2308,   8.2298,   8.2314,\n",
      "        282.1334, 282.1334, 282.1334,   8.2308,   8.2305, 282.1334, 282.1334,\n",
      "        282.1334, 282.1334, 282.1334,  43.8759,  43.8759,   8.2311, 282.1334,\n",
      "        282.1334, 282.1334, 282.1334, 282.1334,  43.8759,  43.8759, 282.1334,\n",
      "         43.8759,  43.8759,   5.2026, 282.1334, 282.1334, 282.1334, 282.1334,\n",
      "        282.1334,  43.8759,  43.8759, 282.1334,  43.8759,  43.8759,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 282.1334,   5.2026,   5.2025, 282.1334,   5.2026,\n",
      "          5.2025, 282.1334,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        282.1334, 282.1334, 282.1334, 282.1334,  43.8759,  43.8759,  43.8759,\n",
      "         43.8759, 282.1334, 282.1334, 282.1334,  43.8759,  43.8759,  43.8759,\n",
      "         43.8759,   5.2026,  43.8759,  43.8759,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 381 was 91.0%\n",
      "tensor([0.0000e+00, 4.7913e-06, 3.9695e-06, 3.5640e-06, 3.5339e-06, 6.2531e-08,\n",
      "        0.0000e+00, 4.0378e-08, 0.0000e+00, 7.1288e-06, 6.9281e-06, 6.8286e-06,\n",
      "        7.5471e-04, 6.3537e-04, 6.2842e-04, 6.5129e-06, 6.4146e-06, 4.1639e-04,\n",
      "        4.1113e-04, 5.8107e-01, 5.6490e-01, 2.1881e+00, 2.2043e+00, 6.2178e-06,\n",
      "        3.9851e-04, 5.3363e-01, 2.2358e+00, 4.7192e-01, 2.2983e+00, 6.2001e-01,\n",
      "        9.1070e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([141.9918, 172.4194, 186.6165, 192.1943,   8.2294,   8.2294,   8.2290,\n",
      "        282.5582, 282.5582, 282.5582,   8.2294,   8.2300, 282.5582, 282.5582,\n",
      "        282.5582, 282.5582, 282.5582,  43.9552,  43.9552,   8.2294, 282.5582,\n",
      "        282.5582, 282.5582, 282.5582, 282.5582,  43.9552,  43.9552, 282.5582,\n",
      "         43.9552,  43.9552,   5.2026, 282.5582, 282.5582, 282.5582, 282.5582,\n",
      "        282.5582,  43.9552,  43.9552, 282.5582,  43.9552,  43.9552,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 282.5582,   5.2026,   5.2025, 282.5582,   5.2026,\n",
      "          5.2025, 282.5582,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        282.5582, 282.5582, 282.5582, 282.5582,  43.9552,  43.9552,  43.9552,\n",
      "         43.9552, 282.5582, 282.5582, 282.5582,  43.9552,  43.9552,  43.9552,\n",
      "         43.9552,   5.2026,  43.9552,  43.9552,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 382 was 91.0%\n",
      "tensor([0.0000e+00, 4.7799e-06, 3.9610e-06, 3.5567e-06, 3.5285e-06, 6.2377e-08,\n",
      "        0.0000e+00, 4.0277e-08, 0.0000e+00, 7.1107e-06, 6.9096e-06, 6.8137e-06,\n",
      "        7.4622e-04, 6.2817e-04, 6.2159e-04, 6.4974e-06, 6.3994e-06, 4.1165e-04,\n",
      "        4.0638e-04, 5.7954e-01, 5.6361e-01, 2.1833e+00, 2.1992e+00, 6.2045e-06,\n",
      "        3.9406e-04, 5.3245e-01, 2.2306e+00, 4.7098e-01, 2.2929e+00, 6.1859e-01,\n",
      "        9.1091e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([142.2791, 172.7533, 186.9427, 192.4524,   8.2282,   8.2282,   8.2286,\n",
      "        282.9830, 282.9830, 282.9830,   8.2283,   8.2277, 282.9830, 282.9830,\n",
      "        282.9830, 282.9830, 282.9830,  44.0345,  44.0345,   8.2277, 282.9830,\n",
      "        282.9830, 282.9830, 282.9830, 282.9830,  44.0345,  44.0345, 282.9830,\n",
      "         44.0345,  44.0345,   5.2026, 282.9830, 282.9830, 282.9830, 282.9830,\n",
      "        282.9830,  44.0345,  44.0345, 282.9830,  44.0345,  44.0345,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 282.9830,   5.2026,   5.2025, 282.9830,   5.2026,\n",
      "          5.2025, 282.9830,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        282.9830, 282.9830, 282.9830, 282.9830,  44.0345,  44.0345,  44.0345,\n",
      "         44.0345, 282.9830, 282.9830, 282.9830,  44.0345,  44.0345,  44.0345,\n",
      "         44.0345,   5.2026,  44.0345,  44.0345,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 383 was 91.1%\n",
      "tensor([1.8529e-22, 4.7700e-06, 3.9514e-06, 3.5507e-06, 3.5220e-06, 6.1424e-08,\n",
      "        0.0000e+00, 3.9658e-08, 0.0000e+00, 7.0927e-06, 6.8931e-06, 6.7976e-06,\n",
      "        7.3789e-04, 6.2134e-04, 6.1476e-04, 6.4811e-06, 6.3861e-06, 4.0687e-04,\n",
      "        4.0185e-04, 5.7803e-01, 5.6234e-01, 2.1785e+00, 2.1942e+00, 6.1916e-06,\n",
      "        3.8967e-04, 5.3136e-01, 2.2255e+00, 4.6997e-01, 2.2876e+00, 6.1717e-01,\n",
      "        9.1111e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([142.5663, 173.0867, 187.2686, 192.7109,   8.2265,   8.2275,   8.2262,\n",
      "        283.4078, 283.4078, 283.4078,   8.2265,   8.2272, 283.4078, 283.4078,\n",
      "        283.4078, 283.4078, 283.4078,  44.1138,  44.1138,   8.2270, 283.4078,\n",
      "        283.4078, 283.4078, 283.4078, 283.4078,  44.1138,  44.1138, 283.4078,\n",
      "         44.1138,  44.1138,   5.2026, 283.4078, 283.4078, 283.4078, 283.4078,\n",
      "        283.4078,  44.1138,  44.1138, 283.4078,  44.1138,  44.1138,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 283.4078,   5.2026,   5.2025, 283.4078,   5.2026,\n",
      "          5.2025, 283.4078,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        283.4078, 283.4078, 283.4078, 283.4078,  44.1138,  44.1138,  44.1138,\n",
      "         44.1138, 283.4078, 283.4078, 283.4078,  44.1138,  44.1138,  44.1138,\n",
      "         44.1138,   5.2026,  44.1138,  44.1138,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 384 was 91.1%\n",
      "tensor([5.2940e-23, 4.7585e-06, 3.9433e-06, 3.5434e-06, 3.5171e-06, 6.1515e-08,\n",
      "        0.0000e+00, 3.9716e-08, 0.0000e+00, 7.0752e-06, 6.8755e-06, 6.7833e-06,\n",
      "        7.2975e-04, 6.1446e-04, 6.0830e-04, 6.4666e-06, 6.3711e-06, 4.0237e-04,\n",
      "        3.9735e-04, 5.7651e-01, 5.6104e-01, 2.1738e+00, 2.1893e+00, 6.1785e-06,\n",
      "        3.8543e-04, 5.3025e-01, 2.2203e+00, 4.6904e-01, 2.2823e+00, 6.1578e-01,\n",
      "        9.1131e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([142.8532, 173.4195, 187.5940, 192.9693,   8.2254,   8.2251,   8.2257,\n",
      "        283.8325, 283.8325, 283.8325,   8.2257,   8.2254, 283.8325, 283.8325,\n",
      "        283.8325, 283.8325, 283.8325,  44.1931,  44.1931,   8.2256, 283.8325,\n",
      "        283.8325, 283.8325, 283.8325, 283.8325,  44.1931,  44.1931, 283.8325,\n",
      "         44.1931,  44.1931,   5.2026, 283.8325, 283.8325, 283.8325, 283.8325,\n",
      "        283.8325,  44.1931,  44.1931, 283.8325,  44.1931,  44.1931,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 283.8325,   5.2026,   5.2025, 283.8325,   5.2026,\n",
      "          5.2025, 283.8325,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        283.8325, 283.8325, 283.8325, 283.8325,  44.1931,  44.1931,  44.1931,\n",
      "         44.1931, 283.8325, 283.8325, 283.8325,  44.1931,  44.1931,  44.1931,\n",
      "         44.1931,   5.2026,  44.1931,  44.1931,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(48.4087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 385 was 91.4%\n",
      "tensor([0.0000e+00, 2.4757e-04, 3.0303e-04, 1.7865e-04, 0.0000e+00, 2.5715e-06,\n",
      "        3.2911e-09, 4.7146e-05, 4.1932e-04, 3.6227e-04, 3.5231e-04, 3.4748e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3069e-04, 3.2597e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4823e-01, 5.3369e-01, 2.1013e+00, 2.1161e+00, 3.1572e-04,\n",
      "        0.0000e+00, 5.0435e-01, 2.1457e+00, 4.4601e-01, 2.2044e+00, 6.1694e-01,\n",
      "        9.1432e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([143.1190, 173.7156, 187.8988, 193.2258,   8.2243,   8.2246,   8.2234,\n",
      "        284.2571, 284.2571, 284.2571,   8.2241,   8.2247, 284.2571, 284.2571,\n",
      "        284.2571, 284.2571, 284.2571,  44.2724,  44.2724,   8.2243, 284.2571,\n",
      "        284.2571, 284.2571, 284.2571, 284.2571,  44.2724,  44.2724, 284.2571,\n",
      "         44.2724,  44.2724,   5.2026, 284.2571, 284.2571, 284.2571, 284.2571,\n",
      "        284.2571,  44.2724,  44.2724, 284.2571,  44.2724,  44.2724,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 284.2571,   5.2026,   5.2025, 284.2571,   5.2026,\n",
      "          5.2025, 284.2571,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        284.2571, 284.2571, 284.2571, 284.2571,  44.2724,  44.2724,  44.2724,\n",
      "         44.2724, 284.2571, 284.2571, 284.2571,  44.2724,  44.2724,  44.2724,\n",
      "         44.2724,   5.2026,  44.2724,  44.2724,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(48.3420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 386 was 91.4%\n",
      "tensor([0.0000e+00, 2.4735e-04, 3.0259e-04, 1.7729e-04, 0.0000e+00, 2.5400e-06,\n",
      "        3.2375e-09, 4.7764e-05, 4.1517e-04, 3.6196e-04, 3.5188e-04, 3.4750e-04,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 3.3060e-04, 3.2574e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4698e-01, 5.3261e-01, 2.0971e+00, 2.1117e+00, 3.1563e-04,\n",
      "        0.0000e+00, 5.0336e-01, 2.1412e+00, 4.4519e-01, 2.1998e+00, 6.1562e-01,\n",
      "        9.1450e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([143.3847, 174.0115, 188.2032, 193.4825,   8.2229,   8.2229,   8.2230,\n",
      "        284.6817, 284.6817, 284.6817,   8.2236,   8.2224, 284.6817, 284.6817,\n",
      "        284.6817, 284.6817, 284.6817,  44.3516,  44.3516,   8.2230, 284.6817,\n",
      "        284.6817, 284.6817, 284.6817, 284.6817,  44.3516,  44.3516, 284.6817,\n",
      "         44.3516,  44.3516,   5.2026, 284.6817, 284.6817, 284.6817, 284.6817,\n",
      "        284.6817,  44.3516,  44.3516, 284.6817,  44.3516,  44.3516,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 284.6817,   5.2026,   5.2025, 284.6817,   5.2026,\n",
      "          5.2025, 284.6817,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        284.6817, 284.6817, 284.6817, 284.6817,  44.3516,  44.3516,  44.3516,\n",
      "         44.3516, 284.6817, 284.6817, 284.6817,  44.3516,  44.3516,  44.3516,\n",
      "         44.3516,   5.2026,  44.3516,  44.3516,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(48.2757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 387 was 91.4%\n",
      "tensor([0.0000e+00, 2.4709e-04, 3.0221e-04, 1.7599e-04, 0.0000e+00, 2.5116e-06,\n",
      "        3.1828e-09, 4.8341e-05, 4.1102e-04, 3.6156e-04, 3.5160e-04, 3.4698e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3014e-04, 3.2568e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4574e-01, 5.3151e-01, 2.0929e+00, 2.1074e+00, 3.1542e-04,\n",
      "        0.0000e+00, 5.0237e-01, 2.1368e+00, 4.4438e-01, 2.1951e+00, 6.1430e-01,\n",
      "        9.1468e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([143.6503, 174.3073, 188.5071, 193.7394,   8.2218,   8.2222,   8.2216,\n",
      "        285.1063, 285.1063, 285.1063,   8.2213,   8.2219, 285.1063, 285.1063,\n",
      "        285.1063, 285.1063, 285.1063,  44.4309,  44.4309,   8.2214, 285.1063,\n",
      "        285.1063, 285.1063, 285.1063, 285.1063,  44.4309,  44.4309, 285.1063,\n",
      "         44.4309,  44.4309,   5.2026, 285.1063, 285.1063, 285.1063, 285.1063,\n",
      "        285.1063,  44.4309,  44.4309, 285.1063,  44.4309,  44.4309,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 285.1063,   5.2026,   5.2025, 285.1063,   5.2026,\n",
      "          5.2025, 285.1063,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        285.1063, 285.1063, 285.1063, 285.1063,  44.4309,  44.4309,  44.4309,\n",
      "         44.4309, 285.1063, 285.1063, 285.1063,  44.4309,  44.4309,  44.4309,\n",
      "         44.4309,   5.2026,  44.4309,  44.4309,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(48.2096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 388 was 91.4%\n",
      "tensor([0.0000e+00, 2.4685e-04, 3.0169e-04, 1.7461e-04, 0.0000e+00, 2.4796e-06,\n",
      "        3.1273e-09, 4.8980e-05, 4.0692e-04, 3.6129e-04, 3.5129e-04, 3.4690e-04,\n",
      "        6.5052e-19, 0.0000e+00, 0.0000e+00, 3.3019e-04, 3.2544e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4448e-01, 5.3046e-01, 2.0887e+00, 2.1029e+00, 3.1542e-04,\n",
      "        0.0000e+00, 5.0140e-01, 2.1323e+00, 4.4353e-01, 2.1905e+00, 6.1298e-01,\n",
      "        9.1486e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([143.9158, 174.6028, 188.8106, 193.9964,   8.2201,   8.2199,   8.2209,\n",
      "        285.5308, 285.5308, 285.5308,   8.2209,   8.2203, 285.5308, 285.5308,\n",
      "        285.5308, 285.5308, 285.5308,  44.5102,  44.5102,   8.2206, 285.5308,\n",
      "        285.5308, 285.5308, 285.5308, 285.5308,  44.5102,  44.5102, 285.5308,\n",
      "         44.5102,  44.5102,   5.2026, 285.5308, 285.5308, 285.5308, 285.5308,\n",
      "        285.5308,  44.5102,  44.5102, 285.5308,  44.5102,  44.5102,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 285.5308,   5.2026,   5.2025, 285.5308,   5.2026,\n",
      "          5.2025, 285.5308,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        285.5308, 285.5308, 285.5308, 285.5308,  44.5102,  44.5102,  44.5102,\n",
      "         44.5102, 285.5308, 285.5308, 285.5308,  44.5102,  44.5102,  44.5102,\n",
      "         44.5102,   5.2026,  44.5102,  44.5102,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(48.1438, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 389 was 91.5%\n",
      "tensor([0.0000e+00, 2.4662e-04, 3.0117e-04, 1.7321e-04, 0.0000e+00, 2.4465e-06,\n",
      "        3.0713e-09, 4.9599e-05, 4.0284e-04, 3.6113e-04, 3.5130e-04, 3.4661e-04,\n",
      "        1.0842e-19, 0.0000e+00, 0.0000e+00, 3.2987e-04, 3.2544e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4320e-01, 5.2939e-01, 2.0845e+00, 2.0986e+00, 3.1527e-04,\n",
      "        0.0000e+00, 5.0043e-01, 2.1278e+00, 4.4275e-01, 2.1859e+00, 6.1166e-01,\n",
      "        9.1503e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([144.1812, 174.8982, 189.1137, 194.2535,   8.2190,   8.2194,   8.2186,\n",
      "        285.9552, 285.9552, 285.9552,   8.2192,   8.2195, 285.9552, 285.9552,\n",
      "        285.9552, 285.9552, 285.9552,  44.5895,  44.5895,   8.2193, 285.9552,\n",
      "        285.9552, 285.9552, 285.9552, 285.9552,  44.5895,  44.5895, 285.9552,\n",
      "         44.5895,  44.5895,   5.2026, 285.9552, 285.9552, 285.9552, 285.9552,\n",
      "        285.9552,  44.5895,  44.5895, 285.9552,  44.5895,  44.5895,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 285.9552,   5.2026,   5.2025, 285.9552,   5.2026,\n",
      "          5.2025, 285.9552,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        285.9552, 285.9552, 285.9552, 285.9552,  44.5895,  44.5895,  44.5895,\n",
      "         44.5895, 285.9552, 285.9552, 285.9552,  44.5895,  44.5895,  44.5895,\n",
      "         44.5895,   5.2026,  44.5895,  44.5895,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(48.0785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 390 was 91.5%\n",
      "tensor([0.0000e+00, 2.4636e-04, 3.0076e-04, 1.7194e-04, 0.0000e+00, 2.4192e-06,\n",
      "        3.0145e-09, 5.0159e-05, 3.9879e-04, 3.6066e-04, 3.5073e-04, 3.4649e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2965e-04, 3.2507e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4197e-01, 5.2831e-01, 2.0803e+00, 2.0942e+00, 3.1505e-04,\n",
      "        0.0000e+00, 4.9944e-01, 2.1234e+00, 4.4194e-01, 2.1813e+00, 6.1035e-01,\n",
      "        9.1521e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([144.4465, 175.1934, 189.4164, 194.5108,   8.2179,   8.2177,   8.2181,\n",
      "        286.3797, 286.3797, 286.3797,   8.2184,   8.2172, 286.3797, 286.3797,\n",
      "        286.3797, 286.3797, 286.3797,  44.6687,  44.6687,   8.2180, 286.3797,\n",
      "        286.3797, 286.3797, 286.3797, 286.3797,  44.6687,  44.6687, 286.3797,\n",
      "         44.6687,  44.6687,   5.2026, 286.3797, 286.3797, 286.3797, 286.3797,\n",
      "        286.3797,  44.6687,  44.6687, 286.3797,  44.6687,  44.6687,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 286.3797,   5.2026,   5.2025, 286.3797,   5.2026,\n",
      "          5.2025, 286.3797,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        286.3797, 286.3797, 286.3797, 286.3797,  44.6687,  44.6687,  44.6687,\n",
      "         44.6687, 286.3797, 286.3797, 286.3797,  44.6687,  44.6687,  44.6687,\n",
      "         44.6687,   5.2026,  44.6687,  44.6687,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(48.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 391 was 91.5%\n",
      "tensor([0.0000e+00, 2.4608e-04, 3.0035e-04, 1.7068e-04, 0.0000e+00, 2.3920e-06,\n",
      "        2.9571e-09, 5.0716e-05, 3.9480e-04, 3.6021e-04, 3.5045e-04, 3.4599e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2924e-04, 3.2502e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4075e-01, 5.2724e-01, 2.0762e+00, 2.0899e+00, 3.1484e-04,\n",
      "        0.0000e+00, 4.9847e-01, 2.1189e+00, 4.4112e-01, 2.1767e+00, 6.0905e-01,\n",
      "        9.1538e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([144.7117, 175.4885, 189.7186, 194.7682,   8.2165,   8.2173,   8.2164,\n",
      "        286.8041, 286.8041, 286.8041,   8.2161,   8.2167, 286.8041, 286.8041,\n",
      "        286.8041, 286.8041, 286.8041,  44.7480,  44.7480,   8.2167, 286.8041,\n",
      "        286.8041, 286.8041, 286.8041, 286.8041,  44.7480,  44.7480, 286.8041,\n",
      "         44.7480,  44.7480,   5.2026, 286.8041, 286.8041, 286.8041, 286.8041,\n",
      "        286.8041,  44.7480,  44.7480, 286.8041,  44.7480,  44.7480,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 286.8041,   5.2026,   5.2025, 286.8041,   5.2026,\n",
      "          5.2025, 286.8041,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        286.8041, 286.8041, 286.8041, 286.8041,  44.7480,  44.7480,  44.7480,\n",
      "         44.7480, 286.8041, 286.8041, 286.8041,  44.7480,  44.7480,  44.7480,\n",
      "         44.7480,   5.2026,  44.7480,  44.7480,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.9482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 392 was 91.5%\n",
      "tensor([0.0000e+00, 2.4581e-04, 2.9989e-04, 1.6942e-04, 0.0000e+00, 2.3645e-06,\n",
      "        2.8986e-09, 5.1272e-05, 3.9084e-04, 3.5985e-04, 3.4992e-04, 3.4579e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2916e-04, 3.2462e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3952e-01, 5.2617e-01, 2.0720e+00, 2.0856e+00, 3.1465e-04,\n",
      "        0.0000e+00, 4.9752e-01, 2.1145e+00, 4.4029e-01, 2.1722e+00, 6.0775e-01,\n",
      "        9.1556e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([144.9768, 175.7834, 190.0205, 195.0258,   8.2150,   8.2149,   8.2160,\n",
      "        287.2284, 287.2284, 287.2284,   8.2156,   8.2150, 287.2284, 287.2284,\n",
      "        287.2284, 287.2284, 287.2284,  44.8273,  44.8273,   8.2153, 287.2284,\n",
      "        287.2284, 287.2284, 287.2284, 287.2284,  44.8273,  44.8273, 287.2284,\n",
      "         44.8273,  44.8273,   5.2026, 287.2284, 287.2284, 287.2284, 287.2284,\n",
      "        287.2284,  44.8273,  44.8273, 287.2284,  44.8273,  44.8273,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 287.2284,   5.2026,   5.2025, 287.2284,   5.2026,\n",
      "          5.2025, 287.2284,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        287.2284, 287.2284, 287.2284, 287.2284,  44.8273,  44.8273,  44.8273,\n",
      "         44.8273, 287.2284, 287.2284, 287.2284,  44.8273,  44.8273,  44.8273,\n",
      "         44.8273,   5.2026,  44.8273,  44.8273,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.8835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 393 was 91.5%\n",
      "tensor([0.0000e+00, 2.4555e-04, 2.9936e-04, 1.6808e-04, 0.0000e+00, 2.3341e-06,\n",
      "        2.8406e-09, 5.1870e-05, 3.8689e-04, 3.5958e-04, 3.4987e-04, 3.4541e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2879e-04, 3.2459e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3826e-01, 5.2514e-01, 2.0679e+00, 2.0812e+00, 3.1456e-04,\n",
      "        0.0000e+00, 4.9654e-01, 2.1101e+00, 4.3950e-01, 2.1676e+00, 6.0645e-01,\n",
      "        9.1573e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([145.2418, 176.0781, 190.3219, 195.2836,   8.2136,   8.2145,   8.2136,\n",
      "        287.6527, 287.6527, 287.6527,   8.2140,   8.2145, 287.6527, 287.6527,\n",
      "        287.6527, 287.6527, 287.6527,  44.9065,  44.9065,   8.2140, 287.6527,\n",
      "        287.6527, 287.6527, 287.6527, 287.6527,  44.9065,  44.9065, 287.6527,\n",
      "         44.9065,  44.9065,   5.2026, 287.6527, 287.6527, 287.6527, 287.6527,\n",
      "        287.6527,  44.9065,  44.9065, 287.6527,  44.9065,  44.9065,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 287.6527,   5.2026,   5.2025, 287.6527,   5.2026,\n",
      "          5.2025, 287.6527,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        287.6527, 287.6527, 287.6527, 287.6527,  44.9065,  44.9065,  44.9065,\n",
      "         44.9065, 287.6527, 287.6527, 287.6527,  44.9065,  44.9065,  44.9065,\n",
      "         44.9065,   5.2026,  44.9065,  44.9065,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.8191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 394 was 91.5%\n",
      "tensor([0.0000e+00, 2.4526e-04, 2.9896e-04, 1.6690e-04, 0.0000e+00, 2.3092e-06,\n",
      "        2.7812e-09, 5.2371e-05, 3.8299e-04, 3.5909e-04, 3.4921e-04, 3.4521e-04,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 3.2850e-04, 3.2407e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3706e-01, 5.2406e-01, 2.0637e+00, 2.0770e+00, 3.1426e-04,\n",
      "        0.0000e+00, 4.9556e-01, 2.1057e+00, 4.3871e-01, 2.1630e+00, 6.0515e-01,\n",
      "        9.1591e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([145.5068, 176.3726, 190.6229, 195.5415,   8.2128,   8.2128,   8.2128,\n",
      "        288.0770, 288.0770, 288.0770,   8.2132,   8.2122, 288.0770, 288.0770,\n",
      "        288.0770, 288.0770, 288.0770,  44.9858,  44.9858,   8.2127, 288.0770,\n",
      "        288.0770, 288.0770, 288.0770, 288.0770,  44.9858,  44.9858, 288.0770,\n",
      "         44.9858,  44.9858,   5.2026, 288.0770, 288.0770, 288.0770, 288.0770,\n",
      "        288.0770,  44.9858,  44.9858, 288.0770,  44.9858,  44.9858,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 288.0770,   5.2026,   5.2025, 288.0770,   5.2026,\n",
      "          5.2025, 288.0770,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        288.0770, 288.0770, 288.0770, 288.0770,  44.9858,  44.9858,  44.9858,\n",
      "         44.9858, 288.0770, 288.0770, 288.0770,  44.9858,  44.9858,  44.9858,\n",
      "         44.9858,   5.2026,  44.9858,  44.9858,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.7552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 395 was 91.6%\n",
      "tensor([0.0000e+00, 2.4494e-04, 2.9858e-04, 1.6576e-04, 0.0000e+00, 2.2857e-06,\n",
      "        2.7206e-09, 5.2871e-05, 3.7911e-04, 3.5843e-04, 3.4879e-04, 3.4462e-04,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 3.2796e-04, 3.2390e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3585e-01, 5.2300e-01, 2.0596e+00, 2.0727e+00, 3.1391e-04,\n",
      "        0.0000e+00, 4.9459e-01, 2.1014e+00, 4.3790e-01, 2.1585e+00, 6.0386e-01,\n",
      "        9.1608e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([145.7716, 176.6670, 190.9235, 195.7995,   8.2110,   8.2121,   8.2111,\n",
      "        288.5012, 288.5012, 288.5012,   8.2109,   8.2117, 288.5012, 288.5012,\n",
      "        288.5012, 288.5012, 288.5012,  45.0651,  45.0651,   8.2119, 288.5012,\n",
      "        288.5012, 288.5012, 288.5012, 288.5012,  45.0651,  45.0651, 288.5012,\n",
      "         45.0651,  45.0651,   5.2026, 288.5012, 288.5012, 288.5012, 288.5012,\n",
      "        288.5012,  45.0651,  45.0651, 288.5012,  45.0651,  45.0651,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 288.5012,   5.2026,   5.2025, 288.5012,   5.2026,\n",
      "          5.2025, 288.5012,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        288.5012, 288.5012, 288.5012, 288.5012,  45.0651,  45.0651,  45.0651,\n",
      "         45.0651, 288.5012, 288.5012, 288.5012,  45.0651,  45.0651,  45.0651,\n",
      "         45.0651,   5.2026,  45.0651,  45.0651,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(47.6912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 396 was 91.6%\n",
      "tensor([0.0000e+00, 2.4466e-04, 2.9807e-04, 1.6451e-04, 0.0000e+00, 2.2577e-06,\n",
      "        2.6601e-09, 5.3400e-05, 3.7531e-04, 3.5814e-04, 3.4834e-04, 3.4445e-04,\n",
      "        4.3368e-19, 0.0000e+00, 0.0000e+00, 3.2790e-04, 3.2353e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3462e-01, 5.2194e-01, 2.0555e+00, 2.0684e+00, 3.1366e-04,\n",
      "        0.0000e+00, 4.9367e-01, 2.0970e+00, 4.3711e-01, 2.1540e+00, 6.0259e-01,\n",
      "        9.1625e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([146.0363, 176.9612, 191.2237, 196.0578,   8.2099,   8.2097,   8.2103,\n",
      "        288.9253, 288.9253, 288.9253,   8.2104,   8.2103, 288.9253, 288.9253,\n",
      "        288.9253, 288.9253, 288.9253,  45.1443,  45.1443,   8.2103, 288.9253,\n",
      "        288.9253, 288.9253, 288.9253, 288.9253,  45.1443,  45.1443, 288.9253,\n",
      "         45.1443,  45.1443,   5.2026, 288.9253, 288.9253, 288.9253, 288.9253,\n",
      "        288.9253,  45.1443,  45.1443, 288.9253,  45.1443,  45.1443,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 288.9253,   5.2026,   5.2025, 288.9253,   5.2026,\n",
      "          5.2025, 288.9253,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        288.9253, 288.9253, 288.9253, 288.9253,  45.1443,  45.1443,  45.1443,\n",
      "         45.1443, 288.9253, 288.9253, 288.9253,  45.1443,  45.1443,  45.1443,\n",
      "         45.1443,   5.2026,  45.1443,  45.1443,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.6279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 397 was 91.6%\n",
      "tensor([0.0000e+00, 2.4436e-04, 2.9761e-04, 1.6334e-04, 0.0000e+00, 2.2327e-06,\n",
      "        2.5993e-09, 5.3917e-05, 3.7147e-04, 3.5760e-04, 3.4808e-04, 3.4392e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2735e-04, 3.2324e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3340e-01, 5.2091e-01, 2.0514e+00, 2.0641e+00, 3.1341e-04,\n",
      "        0.0000e+00, 4.9267e-01, 2.0926e+00, 4.3631e-01, 2.1494e+00, 6.0129e-01,\n",
      "        9.1642e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([146.3010, 177.2552, 191.5235, 196.3161,   8.2087,   8.2092,   8.2086,\n",
      "        289.3495, 289.3495, 289.3495,   8.2080,   8.2089, 289.3495, 289.3495,\n",
      "        289.3495, 289.3495, 289.3495,  45.2236,  45.2236,   8.2095, 289.3495,\n",
      "        289.3495, 289.3495, 289.3495, 289.3495,  45.2236,  45.2236, 289.3495,\n",
      "         45.2236,  45.2236,   5.2026, 289.3495, 289.3495, 289.3495, 289.3495,\n",
      "        289.3495,  45.2236,  45.2236, 289.3495,  45.2236,  45.2236,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 289.3495,   5.2026,   5.2025, 289.3495,   5.2026,\n",
      "          5.2025, 289.3495,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        289.3495, 289.3495, 289.3495, 289.3495,  45.2236,  45.2236,  45.2236,\n",
      "         45.2236, 289.3495, 289.3495, 289.3495,  45.2236,  45.2236,  45.2236,\n",
      "         45.2236,   5.2026,  45.2236,  45.2236,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.5645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 398 was 91.6%\n",
      "tensor([0.0000e+00, 2.4403e-04, 2.9721e-04, 1.6222e-04, 0.0000e+00, 2.2089e-06,\n",
      "        2.5367e-09, 5.4382e-05, 3.6775e-04, 3.5703e-04, 3.4743e-04, 3.4358e-04,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 3.2715e-04, 3.2289e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3220e-01, 5.1985e-01, 2.0474e+00, 2.0599e+00, 3.1301e-04,\n",
      "        0.0000e+00, 4.9175e-01, 2.0883e+00, 4.3552e-01, 2.1450e+00, 6.0003e-01,\n",
      "        9.1659e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([146.5655, 177.5491, 191.8229, 196.5747,   8.2072,   8.2075,   8.2082,\n",
      "        289.7736, 289.7736, 289.7736,   8.2075,   8.2075, 289.7736, 289.7736,\n",
      "        289.7736, 289.7736, 289.7736,  45.3028,  45.3028,   8.2072, 289.7736,\n",
      "        289.7736, 289.7736, 289.7736, 289.7736,  45.3028,  45.3028, 289.7736,\n",
      "         45.3028,  45.3028,   5.2026, 289.7736, 289.7736, 289.7736, 289.7736,\n",
      "        289.7736,  45.3028,  45.3028, 289.7736,  45.3028,  45.3028,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 289.7736,   5.2026,   5.2025, 289.7736,   5.2026,\n",
      "          5.2025, 289.7736,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        289.7736, 289.7736, 289.7736, 289.7736,  45.3028,  45.3028,  45.3028,\n",
      "         45.3028, 289.7736, 289.7736, 289.7736,  45.3028,  45.3028,  45.3028,\n",
      "         45.3028,   5.2026,  45.3028,  45.3028,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.5013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 399 was 91.6%\n",
      "tensor([0.0000e+00, 2.4371e-04, 2.9673e-04, 1.6108e-04, 0.0000e+00, 2.1853e-06,\n",
      "        2.4747e-09, 5.4886e-05, 3.6398e-04, 3.5655e-04, 3.4704e-04, 3.4298e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2657e-04, 3.2257e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.3100e-01, 5.1884e-01, 2.0433e+00, 2.0556e+00, 3.1286e-04,\n",
      "        0.0000e+00, 4.9078e-01, 2.0840e+00, 4.3470e-01, 2.1405e+00, 5.9875e-01,\n",
      "        9.1677e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([146.8300, 177.8428, 192.1219, 196.8334,   8.2064,   8.2064,   8.2057,\n",
      "        290.1976, 290.1976, 290.1976,   8.2058,   8.2061, 290.1976, 290.1976,\n",
      "        290.1976, 290.1976, 290.1976,  45.3821,  45.3821,   8.2067, 290.1976,\n",
      "        290.1976, 290.1976, 290.1976, 290.1976,  45.3821,  45.3821, 290.1976,\n",
      "         45.3821,  45.3821,   5.2026, 290.1976, 290.1976, 290.1976, 290.1976,\n",
      "        290.1976,  45.3821,  45.3821, 290.1976,  45.3821,  45.3821,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 290.1976,   5.2026,   5.2025, 290.1976,   5.2026,\n",
      "          5.2025, 290.1976,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        290.1976, 290.1976, 290.1976, 290.1976,  45.3821,  45.3821,  45.3821,\n",
      "         45.3821, 290.1976, 290.1976, 290.1976,  45.3821,  45.3821,  45.3821,\n",
      "         45.3821,   5.2026,  45.3821,  45.3821,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.4388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 400 was 91.6%\n",
      "tensor([0.0000e+00, 2.4337e-04, 2.9639e-04, 1.6007e-04, 0.0000e+00, 2.1643e-06,\n",
      "        2.4100e-09, 5.5289e-05, 3.6030e-04, 3.5575e-04, 3.4635e-04, 3.4260e-04,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 3.2612e-04, 3.2208e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.2982e-01, 5.1776e-01, 2.0392e+00, 2.0515e+00, 3.1226e-04,\n",
      "        0.0000e+00, 4.8983e-01, 2.0797e+00, 4.3393e-01, 2.1361e+00, 5.9749e-01,\n",
      "        9.1694e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([147.0944, 178.1364, 192.4205, 197.0923,   8.2046,   8.2046,   8.2053,\n",
      "        290.6217, 290.6217, 290.6217,   8.2053,   8.2051, 290.6217, 290.6217,\n",
      "        290.6217, 290.6217, 290.6217,  45.4614,  45.4614,   8.2044, 290.6217,\n",
      "        290.6217, 290.6217, 290.6217, 290.6217,  45.4614,  45.4614, 290.6217,\n",
      "         45.4614,  45.4614,   5.2026, 290.6217, 290.6217, 290.6217, 290.6217,\n",
      "        290.6217,  45.4614,  45.4614, 290.6217,  45.4614,  45.4614,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 290.6217,   5.2026,   5.2025, 290.6217,   5.2026,\n",
      "          5.2025, 290.6217,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        290.6217, 290.6217, 290.6217, 290.6217,  45.4614,  45.4614,  45.4614,\n",
      "         45.4614, 290.6217, 290.6217, 290.6217,  45.4614,  45.4614,  45.4614,\n",
      "         45.4614,   5.2026,  45.4614,  45.4614,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(47.3759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 401 was 91.7%\n",
      "tensor([0.0000e+00, 2.4303e-04, 2.9594e-04, 1.5901e-04, 0.0000e+00, 2.1418e-06,\n",
      "        2.3468e-09, 5.5743e-05, 3.5662e-04, 3.5528e-04, 3.4589e-04, 3.4192e-04,\n",
      "        5.4210e-19, 0.0000e+00, 0.0000e+00, 3.2549e-04, 3.2164e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.2863e-01, 5.1674e-01, 2.0351e+00, 2.0472e+00, 3.1207e-04,\n",
      "        0.0000e+00, 4.8886e-01, 2.0754e+00, 4.3314e-01, 2.1316e+00, 5.9622e-01,\n",
      "        9.1711e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([147.3587, 178.4298, 192.7188, 197.3514,   8.2037,   8.2036,   8.2035,\n",
      "        291.0456, 291.0456, 291.0456,   8.2030,   8.2037, 291.0456, 291.0456,\n",
      "        291.0456, 291.0456, 291.0456,  45.5406,  45.5406,   8.2039, 291.0456,\n",
      "        291.0456, 291.0456, 291.0456, 291.0456,  45.5406,  45.5406, 291.0456,\n",
      "         45.5406,  45.5406,   5.2026, 291.0456, 291.0456, 291.0456, 291.0456,\n",
      "        291.0456,  45.5406,  45.5406, 291.0456,  45.5406,  45.5406,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 291.0456,   5.2026,   5.2025, 291.0456,   5.2026,\n",
      "          5.2025, 291.0456,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        291.0456, 291.0456, 291.0456, 291.0456,  45.5406,  45.5406,  45.5406,\n",
      "         45.5406, 291.0456, 291.0456, 291.0456,  45.5406,  45.5406,  45.5406,\n",
      "         45.5406,   5.2026,  45.5406,  45.5406,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.3141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 402 was 91.7%\n",
      "tensor([0.0000e+00, 2.4266e-04, 2.9554e-04, 1.5799e-04, 0.0000e+00, 2.1203e-06,\n",
      "        2.2807e-09, 5.6163e-05, 3.5299e-04, 3.5451e-04, 3.4523e-04, 3.4146e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2518e-04, 3.2118e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.2744e-01, 5.1569e-01, 2.0311e+00, 2.0430e+00, 3.1150e-04,\n",
      "        0.0000e+00, 4.8792e-01, 2.0711e+00, 4.3234e-01, 2.1272e+00, 5.9495e-01,\n",
      "        9.1728e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([147.6230, 178.7230, 193.0166, 197.6107,   8.2015,   8.2025,   8.2031,\n",
      "        291.4696, 291.4696, 291.4696,   8.2025,   8.2022, 291.4696, 291.4696,\n",
      "        291.4696, 291.4696, 291.4696,  45.6199,  45.6199,   8.2016, 291.4696,\n",
      "        291.4696, 291.4696, 291.4696, 291.4696,  45.6199,  45.6199, 291.4696,\n",
      "         45.6199,  45.6199,   5.2026, 291.4696, 291.4696, 291.4696, 291.4696,\n",
      "        291.4696,  45.6199,  45.6199, 291.4696,  45.6199,  45.6199,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 291.4696,   5.2026,   5.2025, 291.4696,   5.2026,\n",
      "          5.2025, 291.4696,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        291.4696, 291.4696, 291.4696, 291.4696,  45.6199,  45.6199,  45.6199,\n",
      "         45.6199, 291.4696, 291.4696, 291.4696,  45.6199,  45.6199,  45.6199,\n",
      "         45.6199,   5.2026,  45.6199,  45.6199,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(47.2514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 403 was 91.7%\n",
      "tensor([0.0000e+00, 2.4232e-04, 2.9510e-04, 1.5696e-04, 0.0000e+00, 2.0989e-06,\n",
      "        2.2157e-09, 5.6584e-05, 3.4940e-04, 3.5411e-04, 3.4464e-04, 3.4079e-04,\n",
      "        3.2526e-19, 0.0000e+00, 0.0000e+00, 3.2455e-04, 3.2078e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.2627e-01, 5.1468e-01, 2.0271e+00, 2.0389e+00, 3.1130e-04,\n",
      "        0.0000e+00, 4.8700e-01, 2.0668e+00, 4.3154e-01, 2.1228e+00, 5.9372e-01,\n",
      "        9.1744e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([147.8871, 179.0161, 193.3141, 197.8700,   8.2006,   8.2008,   8.2006,\n",
      "        291.8935, 291.8935, 291.8935,   8.2011,   8.2011, 291.8935, 291.8935,\n",
      "        291.8935, 291.8935, 291.8935,  45.6991,  45.6991,   8.2011, 291.8935,\n",
      "        291.8935, 291.8935, 291.8935, 291.8935,  45.6991,  45.6991, 291.8935,\n",
      "         45.6991,  45.6991,   5.2026, 291.8935, 291.8935, 291.8935, 291.8935,\n",
      "        291.8935,  45.6991,  45.6991, 291.8935,  45.6991,  45.6991,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 291.8935,   5.2026,   5.2025, 291.8935,   5.2026,\n",
      "          5.2025, 291.8935,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        291.8935, 291.8935, 291.8935, 291.8935,  45.6991,  45.6991,  45.6991,\n",
      "         45.6991, 291.8935, 291.8935, 291.8935,  45.6991,  45.6991,  45.6991,\n",
      "         45.6991,   5.2026,  45.6991,  45.6991,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 404 was 91.5%\n",
      "tensor([3.1764e-22, 4.6029e-06, 3.7548e-06, 3.4565e-06, 3.3695e-06, 2.7133e-08,\n",
      "        1.9340e-08, 1.7504e-08, 1.7272e-08, 6.7556e-06, 6.5705e-06, 6.4980e-06,\n",
      "        5.9122e-04, 4.9758e-04, 4.9360e-04, 6.1869e-06, 6.1137e-06, 3.2414e-04,\n",
      "        3.2102e-04, 5.4985e-01, 5.3788e-01, 2.0862e+00, 2.0982e+00, 5.9335e-06,\n",
      "        3.1197e-04, 5.0905e-01, 2.1273e+00, 4.5137e-01, 2.1858e+00, 5.9006e-01,\n",
      "        9.1500e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([148.1713, 179.3433, 193.6315, 198.1285,   8.1997,   8.1995,   8.1998,\n",
      "        292.3174, 292.3174, 292.3174,   8.1999,   8.1986, 292.3174, 292.3174,\n",
      "        292.3174, 292.3174, 292.3174,  45.7784,  45.7784,   8.1993, 292.3174,\n",
      "        292.3174, 292.3174, 292.3174, 292.3174,  45.7784,  45.7784, 292.3174,\n",
      "         45.7784,  45.7784,   5.2026, 292.3174, 292.3174, 292.3174, 292.3174,\n",
      "        292.3174,  45.7784,  45.7784, 292.3174,  45.7784,  45.7784,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 292.3174,   5.2026,   5.2025, 292.3174,   5.2026,\n",
      "          5.2025, 292.3174,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        292.3174, 292.3174, 292.3174, 292.3174,  45.7784,  45.7784,  45.7784,\n",
      "         45.7784, 292.3174, 292.3174, 292.3174,  45.7784,  45.7784,  45.7784,\n",
      "         45.7784,   5.2026,  45.7784,  45.7784,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 405 was 91.5%\n",
      "tensor([1.8135e-07, 4.6293e-06, 3.7815e-06, 3.4852e-06, 3.4003e-06, 1.0257e-22,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7390e-06, 6.5551e-06, 6.4832e-06,\n",
      "        5.8463e-04, 4.9215e-04, 4.8818e-04, 6.1724e-06, 6.1015e-06, 3.2037e-04,\n",
      "        3.1738e-04, 5.4849e-01, 5.3670e-01, 2.0817e+00, 2.0936e+00, 5.9216e-06,\n",
      "        3.0846e-04, 5.0801e-01, 2.1225e+00, 4.5044e-01, 2.1809e+00, 5.8876e-01,\n",
      "        9.1519e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([148.4554, 179.6699, 193.9484, 198.3870,   8.1977,   8.1988,   8.1979,\n",
      "        292.7412, 292.7412, 292.7412,   8.1974,   8.1981, 292.7412, 292.7412,\n",
      "        292.7412, 292.7412, 292.7412,  45.8576,  45.8576,   8.1985, 292.7412,\n",
      "        292.7412, 292.7412, 292.7412, 292.7412,  45.8576,  45.8576, 292.7412,\n",
      "         45.8576,  45.8576,   5.2026, 292.7412, 292.7412, 292.7412, 292.7412,\n",
      "        292.7412,  45.8576,  45.8576, 292.7412,  45.8576,  45.8576,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 292.7412,   5.2026,   5.2025, 292.7412,   5.2026,\n",
      "          5.2025, 292.7412,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        292.7412, 292.7412, 292.7412, 292.7412,  45.8576,  45.8576,  45.8576,\n",
      "         45.8576, 292.7412, 292.7412, 292.7412,  45.8576,  45.8576,  45.8576,\n",
      "         45.8576,   5.2026,  45.8576,  45.8576,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 406 was 91.5%\n",
      "tensor([1.7937e-07, 4.6189e-06, 3.7733e-06, 3.4785e-06, 3.3949e-06, 3.9705e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7228e-06, 6.5389e-06, 6.4695e-06,\n",
      "        5.7803e-04, 4.8659e-04, 4.8292e-04, 6.1592e-06, 6.0875e-06, 3.1671e-04,\n",
      "        3.1372e-04, 5.4708e-01, 5.3549e-01, 2.0773e+00, 2.0890e+00, 5.9092e-06,\n",
      "        3.0497e-04, 5.0699e-01, 2.1177e+00, 4.4956e-01, 2.1760e+00, 5.8747e-01,\n",
      "        9.1538e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([148.7392, 179.9961, 194.2648, 198.6455,   8.1965,   8.1961,   8.1971,\n",
      "        293.1650, 293.1650, 293.1650,   8.1968,   8.1966, 293.1650, 293.1650,\n",
      "        293.1650, 293.1650, 293.1650,  45.9369,  45.9369,   8.1967, 293.1650,\n",
      "        293.1650, 293.1650, 293.1650, 293.1650,  45.9369,  45.9369, 293.1650,\n",
      "         45.9369,  45.9369,   5.2026, 293.1650, 293.1650, 293.1650, 293.1650,\n",
      "        293.1650,  45.9369,  45.9369, 293.1650,  45.9369,  45.9369,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 293.1650,   5.2026,   5.2025, 293.1650,   5.2026,\n",
      "          5.2025, 293.1650,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        293.1650, 293.1650, 293.1650, 293.1650,  45.9369,  45.9369,  45.9369,\n",
      "         45.9369, 293.1650, 293.1650, 293.1650,  45.9369,  45.9369,  45.9369,\n",
      "         45.9369,   5.2026,  45.9369,  45.9369,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 407 was 91.5%\n",
      "tensor([2.6470e-22, 4.5727e-06, 3.7312e-06, 3.4367e-06, 3.3538e-06, 2.6527e-08,\n",
      "        1.8891e-08, 1.7101e-08, 1.6883e-08, 6.7065e-06, 6.5244e-06, 6.4546e-06,\n",
      "        5.7275e-04, 4.8214e-04, 4.7836e-04, 6.1437e-06, 6.0749e-06, 3.1347e-04,\n",
      "        3.1061e-04, 5.4569e-01, 5.3434e-01, 2.0733e+00, 2.0846e+00, 5.8970e-06,\n",
      "        3.0188e-04, 5.0591e-01, 2.1132e+00, 4.4866e-01, 2.1712e+00, 5.8614e-01,\n",
      "        9.1555e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([149.0226, 180.3215, 194.5785, 198.9057,   8.1955,   8.1956,   8.1944,\n",
      "        293.5888, 293.5888, 293.5888,   8.1949,   8.1956, 293.5888, 293.5888,\n",
      "        293.5888, 293.5888, 293.5888,  46.0161,  46.0161,   8.1952, 293.5888,\n",
      "        293.5888, 293.5888, 293.5888, 293.5888,  46.0161,  46.0161, 293.5888,\n",
      "         46.0161,  46.0161,   5.2026, 293.5888, 293.5888, 293.5888, 293.5888,\n",
      "        293.5888,  46.0161,  46.0161, 293.5888,  46.0161,  46.0161,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 293.5888,   5.2026,   5.2025, 293.5888,   5.2026,\n",
      "          5.2025, 293.5888,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        293.5888, 293.5888, 293.5888, 293.5888,  46.0161,  46.0161,  46.0161,\n",
      "         46.0161, 293.5888, 293.5888, 293.5888,  46.0161,  46.0161,  46.0161,\n",
      "         46.0161,   5.2026,  46.0161,  46.0161,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 408 was 91.5%\n",
      "tensor([1.7578e-07, 4.5983e-06, 3.7571e-06, 3.4645e-06, 3.3836e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6901e-06, 6.5083e-06, 6.4416e-06,\n",
      "        5.6631e-04, 4.7675e-04, 4.7319e-04, 6.1305e-06, 6.0614e-06, 3.0991e-04,\n",
      "        3.0704e-04, 5.4435e-01, 5.3316e-01, 2.0689e+00, 2.0801e+00, 5.8849e-06,\n",
      "        2.9847e-04, 5.0485e-01, 2.1085e+00, 4.4778e-01, 2.1663e+00, 5.8485e-01,\n",
      "        9.1574e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([149.3058, 180.6465, 194.8916, 199.1659,   8.1939,   8.1936,   8.1938,\n",
      "        294.0125, 294.0125, 294.0125,   8.1943,   8.1930, 294.0125, 294.0125,\n",
      "        294.0125, 294.0125, 294.0125,  46.0954,  46.0954,   8.1941, 294.0125,\n",
      "        294.0125, 294.0125, 294.0125, 294.0125,  46.0954,  46.0954, 294.0125,\n",
      "         46.0954,  46.0954,   5.2026, 294.0125, 294.0125, 294.0125, 294.0125,\n",
      "        294.0125,  46.0954,  46.0954, 294.0125,  46.0954,  46.0954,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 294.0125,   5.2026,   5.2025, 294.0125,   5.2026,\n",
      "          5.2025, 294.0125,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        294.0125, 294.0125, 294.0125, 294.0125,  46.0954,  46.0954,  46.0954,\n",
      "         46.0954, 294.0125, 294.0125, 294.0125,  46.0954,  46.0954,  46.0954,\n",
      "         46.0954,   5.2026,  46.0954,  46.0954,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 409 was 91.5%\n",
      "tensor([1.7388e-07, 4.5880e-06, 3.7491e-06, 3.4579e-06, 3.3781e-06, 6.2866e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6738e-06, 6.4938e-06, 6.4264e-06,\n",
      "        5.5996e-04, 4.7156e-04, 4.6798e-04, 6.1157e-06, 6.0493e-06, 3.0630e-04,\n",
      "        3.0360e-04, 5.4300e-01, 5.3196e-01, 2.0645e+00, 2.0755e+00, 5.8725e-06,\n",
      "        2.9512e-04, 5.0381e-01, 2.1038e+00, 4.4690e-01, 2.1615e+00, 5.8356e-01,\n",
      "        9.1592e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([149.5891, 180.9711, 195.2044, 199.4262,   8.1922,   8.1930,   8.1925,\n",
      "        294.4362, 294.4362, 294.4362,   8.1916,   8.1924, 294.4362, 294.4362,\n",
      "        294.4362, 294.4362, 294.4362,  46.1746,  46.1746,   8.1922, 294.4362,\n",
      "        294.4362, 294.4362, 294.4362, 294.4362,  46.1746,  46.1746, 294.4362,\n",
      "         46.1746,  46.1746,   5.2026, 294.4362, 294.4362, 294.4362, 294.4362,\n",
      "        294.4362,  46.1746,  46.1746, 294.4362,  46.1746,  46.1746,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 294.4362,   5.2026,   5.2025, 294.4362,   5.2026,\n",
      "          5.2025, 294.4362,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        294.4362, 294.4362, 294.4362, 294.4362,  46.1746,  46.1746,  46.1746,\n",
      "         46.1746, 294.4362, 294.4362, 294.4362,  46.1746,  46.1746,  46.1746,\n",
      "         46.1746,   5.2026,  46.1746,  46.1746,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 410 was 91.6%\n",
      "tensor([7.7749e-07, 4.8615e-06, 4.3463e-06, 1.6094e-20, 9.3162e-06, 0.0000e+00,\n",
      "        0.0000e+00, 4.5554e-08, 0.0000e+00, 6.6578e-06, 6.4774e-06, 6.4123e-06,\n",
      "        5.5565e-04, 4.6826e-04, 4.6497e-04, 6.1022e-06, 6.0352e-06, 3.0462e-04,\n",
      "        3.0195e-04, 5.4160e-01, 5.3076e-01, 2.0596e+00, 2.0705e+00, 5.8606e-06,\n",
      "        2.9376e-04, 5.0276e-01, 2.0988e+00, 4.4595e-01, 2.1564e+00, 5.8225e-01,\n",
      "        9.1612e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([149.8700, 181.2920, 195.4926, 199.7097,   8.1909,   8.1903,   8.1906,\n",
      "        294.8598, 294.8598, 294.8598,   8.1911,   8.1909, 294.8598, 294.8598,\n",
      "        294.8598, 294.8598, 294.8598,  46.2539,  46.2539,   8.1914, 294.8598,\n",
      "        294.8598, 294.8598, 294.8598, 294.8598,  46.2539,  46.2539, 294.8598,\n",
      "         46.2539,  46.2539,   5.2026, 294.8598, 294.8598, 294.8598, 294.8598,\n",
      "        294.8598,  46.2539,  46.2539, 294.8598,  46.2539,  46.2539,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 294.8598,   5.2026,   5.2025, 294.8598,   5.2026,\n",
      "          5.2025, 294.8598,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        294.8598, 294.8598, 294.8598, 294.8598,  46.2539,  46.2539,  46.2539,\n",
      "         46.2539, 294.8598, 294.8598, 294.8598,  46.2539,  46.2539,  46.2539,\n",
      "         46.2539,   5.2026,  46.2539,  46.2539,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 411 was 91.6%\n",
      "tensor([7.7273e-07, 4.8501e-06, 4.3372e-06, 0.0000e+00, 9.3055e-06, 0.0000e+00,\n",
      "        0.0000e+00, 4.5197e-08, 0.0000e+00, 6.6413e-06, 6.4635e-06, 6.3978e-06,\n",
      "        5.4939e-04, 4.6329e-04, 4.5996e-04, 6.0880e-06, 6.0223e-06, 3.0125e-04,\n",
      "        2.9868e-04, 5.4031e-01, 5.2953e-01, 2.0552e+00, 2.0660e+00, 5.8478e-06,\n",
      "        2.9055e-04, 5.0168e-01, 2.0941e+00, 4.4510e-01, 2.1516e+00, 5.8097e-01,\n",
      "        9.1631e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([150.1502, 181.6120, 195.7773, 199.9961,   8.1888,   8.1899,   8.1898,\n",
      "        295.2834, 295.2834, 295.2834,   8.1892,   8.1900, 295.2834, 295.2834,\n",
      "        295.2834, 295.2834, 295.2834,  46.3331,  46.3331,   8.1889, 295.2834,\n",
      "        295.2834, 295.2834, 295.2834, 295.2834,  46.3331,  46.3331, 295.2834,\n",
      "         46.3331,  46.3331,   5.2026, 295.2834, 295.2834, 295.2834, 295.2834,\n",
      "        295.2834,  46.3331,  46.3331, 295.2834,  46.3331,  46.3331,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 295.2834,   5.2026,   5.2025, 295.2834,   5.2026,\n",
      "          5.2025, 295.2834,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        295.2834, 295.2834, 295.2834, 295.2834,  46.3331,  46.3331,  46.3331,\n",
      "         46.3331, 295.2834, 295.2834, 295.2834,  46.3331,  46.3331,  46.3331,\n",
      "         46.3331,   5.2026,  46.3331,  46.3331,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 412 was 91.6%\n",
      "tensor([7.6830e-07, 4.8392e-06, 4.3281e-06, 1.3553e-20, 9.3023e-06, 0.0000e+00,\n",
      "        0.0000e+00, 4.4876e-08, 0.0000e+00, 6.6264e-06, 6.4478e-06, 6.3833e-06,\n",
      "        5.4335e-04, 4.5826e-04, 4.5505e-04, 6.0749e-06, 6.0086e-06, 2.9790e-04,\n",
      "        2.9531e-04, 5.3905e-01, 5.2834e-01, 2.0508e+00, 2.0615e+00, 5.8367e-06,\n",
      "        2.8743e-04, 5.0065e-01, 2.0895e+00, 4.4419e-01, 2.1468e+00, 5.7969e-01,\n",
      "        9.1649e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([150.4296, 181.9309, 196.0578, 200.2864,   8.1879,   8.1879,   8.1882,\n",
      "        295.7070, 295.7070, 295.7070,   8.1880,   8.1873, 295.7070, 295.7070,\n",
      "        295.7070, 295.7070, 295.7070,  46.4124,  46.4124,   8.1883, 295.7070,\n",
      "        295.7070, 295.7070, 295.7070, 295.7070,  46.4124,  46.4124, 295.7070,\n",
      "         46.4124,  46.4124,   5.2026, 295.7070, 295.7070, 295.7070, 295.7070,\n",
      "        295.7070,  46.4124,  46.4124, 295.7070,  46.4124,  46.4124,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 295.7070,   5.2026,   5.2025, 295.7070,   5.2026,\n",
      "          5.2025, 295.7070,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        295.7070, 295.7070, 295.7070, 295.7070,  46.4124,  46.4124,  46.4124,\n",
      "         46.4124, 295.7070, 295.7070, 295.7070,  46.4124,  46.4124,  46.4124,\n",
      "         46.4124,   5.2026,  46.4124,  46.4124,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(46.7164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 413 was 91.9%\n",
      "tensor([0.0000e+00, 8.4175e-04, 1.0710e-04, 0.0000e+00, 5.3451e-04, 0.0000e+00,\n",
      "        2.5909e-04, 3.1935e-04, 0.0000e+00, 2.0417e-03, 1.5815e-03, 1.4153e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0913e-04, 4.9567e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.1385e-01, 5.0364e-01, 1.9867e+00, 1.9972e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.7734e-01, 2.0247e+00, 4.2338e-01, 2.0812e+00, 5.8055e-01,\n",
      "        9.1910e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([150.6944, 182.2288, 196.3575, 200.5352,   8.1857,   8.1872,   8.1873,\n",
      "        296.1306, 296.1306, 296.1306,   8.1871,   8.1883, 296.1306, 296.1306,\n",
      "        296.1306, 296.1306, 296.1306,  46.4916,  46.4916,   8.1839, 296.1306,\n",
      "        296.1306, 296.1306, 296.1306, 296.1306,  46.4916,  46.4916, 296.1306,\n",
      "         46.4916,  46.4916,   5.2026, 296.1306, 296.1306, 296.1306, 296.1306,\n",
      "        296.1306,  46.4916,  46.4916, 296.1306,  46.4916,  46.4916,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 296.1306,   5.2026,   5.2025, 296.1306,   5.2026,\n",
      "          5.2025, 296.1306,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        296.1306, 296.1306, 296.1306, 296.1306,  46.4916,  46.4916,  46.4916,\n",
      "         46.4916, 296.1306, 296.1306, 296.1306,  46.4916,  46.4916,  46.4916,\n",
      "         46.4916,   5.2026,  46.4916,  46.4916,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 414 was 91.6%\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.1793e-05, 1.2815e-05, 2.4604e-06, 3.1641e-06,\n",
      "        0.0000e+00, 0.0000e+00, 2.0183e-06, 1.2264e-05, 1.0642e-05, 1.0121e-05,\n",
      "        5.3149e-04, 4.4816e-04, 4.4504e-04, 7.4508e-06, 6.8831e-06, 2.9101e-04,\n",
      "        2.8845e-04, 5.3650e-01, 5.2603e-01, 2.0426e+00, 2.0531e+00, 5.7079e-06,\n",
      "        2.8082e-04, 4.9852e-01, 2.0808e+00, 4.4245e-01, 2.1375e+00, 5.7725e-01,\n",
      "        9.1684e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([150.9682, 182.5511, 196.6806, 200.7943,   8.1856,   8.1854,   8.1847,\n",
      "        296.5541, 296.5541, 296.5541,   8.1860,   8.1853, 296.5541, 296.5541,\n",
      "        296.5541, 296.5541, 296.5541,  46.5708,  46.5708,   8.1837, 296.5541,\n",
      "        296.5541, 296.5541, 296.5541, 296.5541,  46.5708,  46.5708, 296.5541,\n",
      "         46.5708,  46.5708,   5.2026, 296.5541, 296.5541, 296.5541, 296.5541,\n",
      "        296.5541,  46.5708,  46.5708, 296.5541,  46.5708,  46.5708,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 296.5541,   5.2026,   5.2025, 296.5541,   5.2026,\n",
      "          5.2025, 296.5541,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        296.5541, 296.5541, 296.5541, 296.5541,  46.5708,  46.5708,  46.5708,\n",
      "         46.5708, 296.5541, 296.5541, 296.5541,  46.5708,  46.5708,  46.5708,\n",
      "         46.5708,   5.2026,  46.5708,  46.5708,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(46.5842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 415 was 91.9%\n",
      "tensor([0.0000e+00, 8.2097e-04, 8.9750e-05, 0.0000e+00, 5.4288e-04, 0.0000e+00,\n",
      "        2.5387e-04, 3.1262e-04, 0.0000e+00, 1.9740e-03, 1.5216e-03, 1.3917e-03,\n",
      "        2.1684e-19, 0.0000e+00, 0.0000e+00, 5.2406e-04, 4.1498e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.1154e-01, 5.0162e-01, 1.9786e+00, 1.9888e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.7544e-01, 2.0161e+00, 4.2182e-01, 2.0724e+00, 5.7809e-01,\n",
      "        9.1944e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([151.2333, 182.8489, 196.9792, 201.0428,   8.1823,   8.1844,   8.1848,\n",
      "        296.9776, 296.9776, 296.9776,   8.1841,   8.1857, 296.9776, 296.9776,\n",
      "        296.9776, 296.9776, 296.9776,  46.6501,  46.6501,   8.1811, 296.9776,\n",
      "        296.9776, 296.9776, 296.9776, 296.9776,  46.6501,  46.6501, 296.9776,\n",
      "         46.6501,  46.6501,   5.2026, 296.9776, 296.9776, 296.9776, 296.9776,\n",
      "        296.9776,  46.6501,  46.6501, 296.9776,  46.6501,  46.6501,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 296.9776,   5.2026,   5.2025, 296.9776,   5.2026,\n",
      "          5.2025, 296.9776,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        296.9776, 296.9776, 296.9776, 296.9776,  46.6501,  46.6501,  46.6501,\n",
      "         46.6501, 296.9776, 296.9776, 296.9776,  46.6501,  46.6501,  46.6501,\n",
      "         46.6501,   5.2026,  46.6501,  46.6501,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 416 was 91.7%\n",
      "tensor([2.6470e-23, 4.4889e-06, 3.6668e-06, 3.3841e-06, 3.3096e-06, 2.5499e-08,\n",
      "        1.8205e-08, 1.6538e-08, 1.6353e-08, 6.5675e-06, 6.3906e-06, 6.3297e-06,\n",
      "        5.3481e-04, 4.5215e-04, 4.4935e-04, 6.0219e-06, 5.9589e-06, 2.9517e-04,\n",
      "        2.9284e-04, 5.3388e-01, 5.2381e-01, 2.0339e+00, 2.0440e+00, 5.7922e-06,\n",
      "        2.8562e-04, 4.9650e-01, 2.0715e+00, 4.4071e-01, 2.1279e+00, 5.7469e-01,\n",
      "        9.1720e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([151.5164, 183.1720, 197.2946, 201.2993,   8.1814,   8.1828,   8.1829,\n",
      "        297.4010, 297.4010, 297.4010,   8.1829,   8.1831, 297.4010, 297.4010,\n",
      "        297.4010, 297.4010, 297.4010,  46.7293,  46.7293,   8.1805, 297.4010,\n",
      "        297.4010, 297.4010, 297.4010, 297.4010,  46.7293,  46.7293, 297.4010,\n",
      "         46.7293,  46.7293,   5.2026, 297.4010, 297.4010, 297.4010, 297.4010,\n",
      "        297.4010,  46.7293,  46.7293, 297.4010,  46.7293,  46.7293,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 297.4010,   5.2026,   5.2025, 297.4010,   5.2026,\n",
      "          5.2025, 297.4010,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        297.4010, 297.4010, 297.4010, 297.4010,  46.7293,  46.7293,  46.7293,\n",
      "         46.7293, 297.4010, 297.4010, 297.4010,  46.7293,  46.7293,  46.7293,\n",
      "         46.7293,   5.2026,  46.7293,  46.7293,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 417 was 91.7%\n",
      "tensor([1.6587e-07, 4.5131e-06, 3.6911e-06, 3.4103e-06, 3.3375e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5505e-06, 6.3758e-06, 6.3152e-06,\n",
      "        5.2893e-04, 4.4740e-04, 4.4460e-04, 6.0074e-06, 5.9464e-06, 2.9193e-04,\n",
      "        2.8972e-04, 5.3257e-01, 5.2260e-01, 2.0295e+00, 2.0395e+00, 5.7789e-06,\n",
      "        2.8253e-04, 4.9548e-01, 2.0668e+00, 4.3981e-01, 2.1231e+00, 5.7338e-01,\n",
      "        9.1739e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([151.7993, 183.4945, 197.6095, 201.5560,   8.1806,   8.1815,   8.1809,\n",
      "        297.8244, 297.8244, 297.8244,   8.1813,   8.1804, 297.8244, 297.8244,\n",
      "        297.8244, 297.8244, 297.8244,  46.8085,  46.8085,   8.1799, 297.8244,\n",
      "        297.8244, 297.8244, 297.8244, 297.8244,  46.8085,  46.8085, 297.8244,\n",
      "         46.8085,  46.8085,   5.2026, 297.8244, 297.8244, 297.8244, 297.8244,\n",
      "        297.8244,  46.8085,  46.8085, 297.8244,  46.8085,  46.8085,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 297.8244,   5.2026,   5.2025, 297.8244,   5.2026,\n",
      "          5.2025, 297.8244,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        297.8244, 297.8244, 297.8244, 297.8244,  46.8085,  46.8085,  46.8085,\n",
      "         46.8085, 297.8244, 297.8244, 297.8244,  46.8085,  46.8085,  46.8085,\n",
      "         46.8085,   5.2026,  46.8085,  46.8085,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 418 was 91.7%\n",
      "tensor([1.6419e-07, 4.5031e-06, 3.6833e-06, 3.4039e-06, 3.3321e-06, 2.3161e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5340e-06, 6.3608e-06, 6.3013e-06,\n",
      "        5.2327e-04, 4.4275e-04, 4.4001e-04, 5.9935e-06, 5.9338e-06, 2.8880e-04,\n",
      "        2.8665e-04, 5.3128e-01, 5.2140e-01, 2.0252e+00, 2.0351e+00, 5.7663e-06,\n",
      "        2.7954e-04, 4.9448e-01, 2.0622e+00, 4.3891e-01, 2.1184e+00, 5.7212e-01,\n",
      "        9.1757e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([152.0818, 183.8166, 197.9239, 201.8127,   8.1793,   8.1788,   8.1793,\n",
      "        298.2478, 298.2478, 298.2478,   8.1793,   8.1795, 298.2478, 298.2478,\n",
      "        298.2478, 298.2478, 298.2478,  46.8878,  46.8878,   8.1793, 298.2478,\n",
      "        298.2478, 298.2478, 298.2478, 298.2478,  46.8878,  46.8878, 298.2478,\n",
      "         46.8878,  46.8878,   5.2026, 298.2478, 298.2478, 298.2478, 298.2478,\n",
      "        298.2478,  46.8878,  46.8878, 298.2478,  46.8878,  46.8878,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 298.2478,   5.2026,   5.2025, 298.2478,   5.2026,\n",
      "          5.2025, 298.2478,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        298.2478, 298.2478, 298.2478, 298.2478,  46.8878,  46.8878,  46.8878,\n",
      "         46.8878, 298.2478, 298.2478, 298.2478,  46.8878,  46.8878,  46.8878,\n",
      "         46.8878,   5.2026,  46.8878,  46.8878,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 419 was 91.7%\n",
      "tensor([5.2940e-23, 4.4597e-06, 3.6443e-06, 3.3654e-06, 3.2945e-06, 2.4915e-08,\n",
      "        1.7782e-08, 1.6161e-08, 1.5989e-08, 6.5177e-06, 6.3462e-06, 6.2876e-06,\n",
      "        5.1757e-04, 4.3805e-04, 4.3541e-04, 5.9798e-06, 5.9210e-06, 2.8567e-04,\n",
      "        2.8359e-04, 5.2990e-01, 5.2029e-01, 2.0209e+00, 2.0305e+00, 5.7535e-06,\n",
      "        2.7655e-04, 4.9343e-01, 2.0576e+00, 4.3807e-01, 2.1136e+00, 5.7085e-01,\n",
      "        9.1775e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([152.3642, 184.1382, 198.2378, 202.0695,   8.1776,   8.1783,   8.1784,\n",
      "        298.6712, 298.6712, 298.6712,   8.1774,   8.1769, 298.6712, 298.6712,\n",
      "        298.6712, 298.6712, 298.6712,  46.9670,  46.9670,   8.1781, 298.6712,\n",
      "        298.6712, 298.6712, 298.6712, 298.6712,  46.9670,  46.9670, 298.6712,\n",
      "         46.9670,  46.9670,   5.2026, 298.6712, 298.6712, 298.6712, 298.6712,\n",
      "        298.6712,  46.9670,  46.9670, 298.6712,  46.9670,  46.9670,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 298.6712,   5.2026,   5.2025, 298.6712,   5.2026,\n",
      "          5.2025, 298.6712,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        298.6712, 298.6712, 298.6712, 298.6712,  46.9670,  46.9670,  46.9670,\n",
      "         46.9670, 298.6712, 298.6712, 298.6712,  46.9670,  46.9670,  46.9670,\n",
      "         46.9670,   5.2026,  46.9670,  46.9670,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 420 was 91.7%\n",
      "tensor([0.0000e+00, 4.4505e-06, 3.6370e-06, 3.3594e-06, 3.2897e-06, 2.4730e-08,\n",
      "        1.7645e-08, 1.6040e-08, 1.5872e-08, 6.5027e-06, 6.3313e-06, 6.2738e-06,\n",
      "        5.1212e-04, 4.3358e-04, 4.3098e-04, 5.9667e-06, 5.9094e-06, 2.8260e-04,\n",
      "        2.8060e-04, 5.2861e-01, 5.1916e-01, 2.0167e+00, 2.0262e+00, 5.7418e-06,\n",
      "        2.7369e-04, 4.9248e-01, 2.0531e+00, 4.3718e-01, 2.1090e+00, 5.6963e-01,\n",
      "        9.1793e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([152.6463, 184.4594, 198.5514, 202.3264,   8.1760,   8.1763,   8.1757,\n",
      "        299.0945, 299.0945, 299.0945,   8.1765,   8.1763, 299.0945, 299.0945,\n",
      "        299.0945, 299.0945, 299.0945,  47.0462,  47.0462,   8.1769, 299.0945,\n",
      "        299.0945, 299.0945, 299.0945, 299.0945,  47.0462,  47.0462, 299.0945,\n",
      "         47.0462,  47.0462,   5.2026, 299.0945, 299.0945, 299.0945, 299.0945,\n",
      "        299.0945,  47.0462,  47.0462, 299.0945,  47.0462,  47.0462,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 299.0945,   5.2026,   5.2025, 299.0945,   5.2026,\n",
      "          5.2025, 299.0945,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        299.0945, 299.0945, 299.0945, 299.0945,  47.0462,  47.0462,  47.0462,\n",
      "         47.0462, 299.0945, 299.0945, 299.0945,  47.0462,  47.0462,  47.0462,\n",
      "         47.0462,   5.2026,  47.0462,  47.0462,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 421 was 91.8%\n",
      "tensor([0.0000e+00, 4.4408e-06, 3.6298e-06, 3.3533e-06, 3.2849e-06, 2.4539e-08,\n",
      "        1.7509e-08, 1.5918e-08, 1.5754e-08, 6.4868e-06, 6.3168e-06, 6.2608e-06,\n",
      "        5.0666e-04, 4.2897e-04, 4.2650e-04, 5.9529e-06, 5.8961e-06, 2.7960e-04,\n",
      "        2.7763e-04, 5.2730e-01, 5.1800e-01, 2.0125e+00, 2.0218e+00, 5.7300e-06,\n",
      "        2.7078e-04, 4.9144e-01, 2.0485e+00, 4.3638e-01, 2.1042e+00, 5.6838e-01,\n",
      "        9.1811e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([152.9281, 184.7801, 198.8645, 202.5833,   8.1747,   8.1750,   8.1752,\n",
      "        299.5178, 299.5178, 299.5178,   8.1745,   8.1750, 299.5178, 299.5178,\n",
      "        299.5178, 299.5178, 299.5178,  47.1255,  47.1255,   8.1743, 299.5178,\n",
      "        299.5178, 299.5178, 299.5178, 299.5178,  47.1255,  47.1255, 299.5178,\n",
      "         47.1255,  47.1255,   5.2026, 299.5178, 299.5178, 299.5178, 299.5178,\n",
      "        299.5178,  47.1255,  47.1255, 299.5178,  47.1255,  47.1255,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 299.5178,   5.2026,   5.2025, 299.5178,   5.2026,\n",
      "          5.2025, 299.5178,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        299.5178, 299.5178, 299.5178, 299.5178,  47.1255,  47.1255,  47.1255,\n",
      "         47.1255, 299.5178, 299.5178, 299.5178,  47.1255,  47.1255,  47.1255,\n",
      "         47.1255,   5.2026,  47.1255,  47.1255,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 422 was 91.8%\n",
      "tensor([1.0588e-22, 4.4315e-06, 3.6226e-06, 3.3472e-06, 3.2801e-06, 2.4354e-08,\n",
      "        1.7374e-08, 1.5796e-08, 1.5637e-08, 6.4717e-06, 6.3018e-06, 6.2467e-06,\n",
      "        5.0136e-04, 4.2448e-04, 4.2208e-04, 5.9394e-06, 5.8836e-06, 2.7655e-04,\n",
      "        2.7465e-04, 5.2600e-01, 5.1693e-01, 2.0082e+00, 2.0173e+00, 5.7189e-06,\n",
      "        2.6795e-04, 4.9043e-01, 2.0440e+00, 4.3548e-01, 2.0996e+00, 5.6714e-01,\n",
      "        9.1829e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([153.2097, 185.1004, 199.1773, 202.8402,   8.1734,   8.1734,   8.1725,\n",
      "        299.9411, 299.9411, 299.9411,   8.1736,   8.1731, 299.9411, 299.9411,\n",
      "        299.9411, 299.9411, 299.9411,  47.2047,  47.2047,   8.1737, 299.9411,\n",
      "        299.9411, 299.9411, 299.9411, 299.9411,  47.2047,  47.2047, 299.9411,\n",
      "         47.2047,  47.2047,   5.2026, 299.9411, 299.9411, 299.9411, 299.9411,\n",
      "        299.9411,  47.2047,  47.2047, 299.9411,  47.2047,  47.2047,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 299.9411,   5.2026,   5.2025, 299.9411,   5.2026,\n",
      "          5.2025, 299.9411,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        299.9411, 299.9411, 299.9411, 299.9411,  47.2047,  47.2047,  47.2047,\n",
      "         47.2047, 299.9411, 299.9411, 299.9411,  47.2047,  47.2047,  47.2047,\n",
      "         47.2047,   5.2026,  47.2047,  47.2047,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 423 was 91.8%\n",
      "tensor([1.5609e-07, 4.4544e-06, 3.6457e-06, 3.3720e-06, 3.3065e-06, 2.3161e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4558e-06, 6.2876e-06, 6.2338e-06,\n",
      "        4.9598e-04, 4.2005e-04, 4.1770e-04, 5.9259e-06, 5.8715e-06, 2.7360e-04,\n",
      "        2.7174e-04, 5.2473e-01, 5.1576e-01, 2.0040e+00, 2.0130e+00, 5.7067e-06,\n",
      "        2.6510e-04, 4.8942e-01, 2.0396e+00, 4.3466e-01, 2.0950e+00, 5.6591e-01,\n",
      "        9.1846e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([153.4911, 185.4203, 199.4896, 203.0973,   8.1713,   8.1725,   8.1720,\n",
      "        300.3643, 300.3643, 300.3643,   8.1716,   8.1722, 300.3643, 300.3643,\n",
      "        300.3643, 300.3643, 300.3643,  47.2839,  47.2839,   8.1711, 300.3643,\n",
      "        300.3643, 300.3643, 300.3643, 300.3643,  47.2839,  47.2839, 300.3643,\n",
      "         47.2839,  47.2839,   5.2026, 300.3643, 300.3643, 300.3643, 300.3643,\n",
      "        300.3643,  47.2839,  47.2839, 300.3643,  47.2839,  47.2839,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 300.3643,   5.2026,   5.2025, 300.3643,   5.2026,\n",
      "          5.2025, 300.3643,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        300.3643, 300.3643, 300.3643, 300.3643,  47.2839,  47.2839,  47.2839,\n",
      "         47.2839, 300.3643, 300.3643, 300.3643,  47.2839,  47.2839,  47.2839,\n",
      "         47.2839,   5.2026,  47.2839,  47.2839,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 424 was 91.8%\n",
      "tensor([1.5453e-07, 4.4450e-06, 3.6384e-06, 3.3657e-06, 3.3015e-06, 3.6396e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4417e-06, 6.2724e-06, 6.2201e-06,\n",
      "        4.9081e-04, 4.1560e-04, 4.1340e-04, 5.9130e-06, 5.8586e-06, 2.7064e-04,\n",
      "        2.6880e-04, 5.2345e-01, 5.1468e-01, 1.9999e+00, 2.0087e+00, 5.6961e-06,\n",
      "        2.6236e-04, 4.8843e-01, 2.0351e+00, 4.3379e-01, 2.0904e+00, 5.6469e-01,\n",
      "        9.1864e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([153.7723, 185.7398, 199.8015, 203.3544,   8.1704,   8.1697,   8.1704,\n",
      "        300.7875, 300.7875, 300.7875,   8.1704,   8.1702, 300.7875, 300.7875,\n",
      "        300.7875, 300.7875, 300.7875,  47.3632,  47.3632,   8.1705, 300.7875,\n",
      "        300.7875, 300.7875, 300.7875, 300.7875,  47.3632,  47.3632, 300.7875,\n",
      "         47.3632,  47.3632,   5.2026, 300.7875, 300.7875, 300.7875, 300.7875,\n",
      "        300.7875,  47.3632,  47.3632, 300.7875,  47.3632,  47.3632,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 300.7875,   5.2026,   5.2025, 300.7875,   5.2026,\n",
      "          5.2025, 300.7875,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        300.7875, 300.7875, 300.7875, 300.7875,  47.3632,  47.3632,  47.3632,\n",
      "         47.3632, 300.7875, 300.7875, 300.7875,  47.3632,  47.3632,  47.3632,\n",
      "         47.3632,   5.2026,  47.3632,  47.3632,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 425 was 91.8%\n",
      "tensor([0.0000e+00, 4.4035e-06, 3.6012e-06, 3.3292e-06, 3.2656e-06, 2.3796e-08,\n",
      "        1.6970e-08, 1.5435e-08, 1.5287e-08, 6.4254e-06, 6.2588e-06, 6.2062e-06,\n",
      "        4.8546e-04, 4.1125e-04, 4.0903e-04, 5.8991e-06, 5.8468e-06, 2.6768e-04,\n",
      "        2.6596e-04, 5.2215e-01, 5.1356e-01, 1.9957e+00, 2.0043e+00, 5.6835e-06,\n",
      "        2.5952e-04, 4.8742e-01, 2.0306e+00, 4.3295e-01, 2.0857e+00, 5.6345e-01,\n",
      "        9.1882e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([154.0532, 186.0588, 200.1130, 203.6115,   8.1687,   8.1692,   8.1687,\n",
      "        301.2107, 301.2107, 301.2107,   8.1684,   8.1696, 301.2107, 301.2107,\n",
      "        301.2107, 301.2107, 301.2107,  47.4424,  47.4424,   8.1679, 301.2107,\n",
      "        301.2107, 301.2107, 301.2107, 301.2107,  47.4424,  47.4424, 301.2107,\n",
      "         47.4424,  47.4424,   5.2026, 301.2107, 301.2107, 301.2107, 301.2107,\n",
      "        301.2107,  47.4424,  47.4424, 301.2107,  47.4424,  47.4424,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 301.2107,   5.2026,   5.2025, 301.2107,   5.2026,\n",
      "          5.2025, 301.2107,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        301.2107, 301.2107, 301.2107, 301.2107,  47.4424,  47.4424,  47.4424,\n",
      "         47.4424, 301.2107, 301.2107, 301.2107,  47.4424,  47.4424,  47.4424,\n",
      "         47.4424,   5.2026,  47.4424,  47.4424,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 426 was 91.8%\n",
      "tensor([0.0000e+00, 4.3944e-06, 3.5943e-06, 3.3233e-06, 3.2609e-06, 2.3616e-08,\n",
      "        1.6839e-08, 1.5317e-08, 1.5174e-08, 6.4111e-06, 6.2435e-06, 6.1935e-06,\n",
      "        4.8044e-04, 4.0689e-04, 4.0486e-04, 5.8866e-06, 5.8338e-06, 2.6483e-04,\n",
      "        2.6307e-04, 5.2089e-01, 5.1249e-01, 1.9916e+00, 2.0000e+00, 5.6731e-06,\n",
      "        2.5683e-04, 4.8641e-01, 2.0262e+00, 4.3211e-01, 2.0812e+00, 5.6226e-01,\n",
      "        9.1899e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([154.3339, 186.3774, 200.4242, 203.8688,   8.1674,   8.1672,   8.1671,\n",
      "        301.6338, 301.6338, 301.6338,   8.1675,   8.1669, 301.6338, 301.6338,\n",
      "        301.6338, 301.6338, 301.6338,  47.5216,  47.5216,   8.1673, 301.6338,\n",
      "        301.6338, 301.6338, 301.6338, 301.6338,  47.5216,  47.5216, 301.6338,\n",
      "         47.5216,  47.5216,   5.2026, 301.6338, 301.6338, 301.6338, 301.6338,\n",
      "        301.6338,  47.5216,  47.5216, 301.6338,  47.5216,  47.5216,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 301.6338,   5.2026,   5.2025, 301.6338,   5.2026,\n",
      "          5.2025, 301.6338,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        301.6338, 301.6338, 301.6338, 301.6338,  47.5216,  47.5216,  47.5216,\n",
      "         47.5216, 301.6338, 301.6338, 301.6338,  47.5216,  47.5216,  47.5216,\n",
      "         47.5216,   5.2026,  47.5216,  47.5216,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 427 was 91.9%\n",
      "tensor([0.0000e+00, 4.3851e-06, 3.5872e-06, 3.3173e-06, 3.2560e-06, 2.3432e-08,\n",
      "        1.6706e-08, 1.5198e-08, 1.5058e-08, 6.3952e-06, 6.2298e-06, 6.1795e-06,\n",
      "        4.7520e-04, 4.0267e-04, 4.0056e-04, 5.8726e-06, 5.8224e-06, 2.6192e-04,\n",
      "        2.6029e-04, 5.1963e-01, 5.1134e-01, 1.9873e+00, 1.9956e+00, 5.6605e-06,\n",
      "        2.5405e-04, 4.8542e-01, 2.0218e+00, 4.3126e-01, 2.0766e+00, 5.6102e-01,\n",
      "        9.1917e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([154.6144, 186.6957, 200.7349, 204.1261,   8.1649,   8.1663,   8.1662,\n",
      "        302.0569, 302.0569, 302.0569,   8.1647,   8.1663, 302.0569, 302.0569,\n",
      "        302.0569, 302.0569, 302.0569,  47.6008,  47.6008,   8.1657, 302.0569,\n",
      "        302.0569, 302.0569, 302.0569, 302.0569,  47.6008,  47.6008, 302.0569,\n",
      "         47.6008,  47.6008,   5.2026, 302.0569, 302.0569, 302.0569, 302.0569,\n",
      "        302.0569,  47.6008,  47.6008, 302.0569,  47.6008,  47.6008,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 302.0569,   5.2026,   5.2025, 302.0569,   5.2026,\n",
      "          5.2025, 302.0569,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        302.0569, 302.0569, 302.0569, 302.0569,  47.6008,  47.6008,  47.6008,\n",
      "         47.6008, 302.0569, 302.0569, 302.0569,  47.6008,  47.6008,  47.6008,\n",
      "         47.6008,   5.2026,  47.6008,  47.6008,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 428 was 91.9%\n",
      "tensor([5.2940e-23, 4.3761e-06, 3.5802e-06, 3.3115e-06, 3.2515e-06, 2.3253e-08,\n",
      "        1.6575e-08, 1.5081e-08, 1.4945e-08, 6.3814e-06, 6.2148e-06, 6.1666e-06,\n",
      "        4.7021e-04, 3.9841e-04, 3.9646e-04, 5.8604e-06, 5.8099e-06, 2.5910e-04,\n",
      "        2.5746e-04, 5.1833e-01, 5.1028e-01, 1.9833e+00, 1.9914e+00, 5.6497e-06,\n",
      "        2.5140e-04, 4.8448e-01, 2.0174e+00, 4.3043e-01, 2.0721e+00, 5.5983e-01,\n",
      "        9.1934e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([154.8947, 187.0135, 201.0453, 204.3834,   8.1635,   8.1642,   8.1646,\n",
      "        302.4800, 302.4800, 302.4800,   8.1642,   8.1636, 302.4800, 302.4800,\n",
      "        302.4800, 302.4800, 302.4800,  47.6801,  47.6801,   8.1648, 302.4800,\n",
      "        302.4800, 302.4800, 302.4800, 302.4800,  47.6801,  47.6801, 302.4800,\n",
      "         47.6801,  47.6801,   5.2026, 302.4800, 302.4800, 302.4800, 302.4800,\n",
      "        302.4800,  47.6801,  47.6801, 302.4800,  47.6801,  47.6801,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 302.4800,   5.2026,   5.2025, 302.4800,   5.2026,\n",
      "          5.2025, 302.4800,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        302.4800, 302.4800, 302.4800, 302.4800,  47.6801,  47.6801,  47.6801,\n",
      "         47.6801, 302.4800, 302.4800, 302.4800,  47.6801,  47.6801,  47.6801,\n",
      "         47.6801,   5.2026,  47.6801,  47.6801,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 429 was 91.9%\n",
      "tensor([1.4690e-07, 4.3976e-06, 3.6018e-06, 3.3347e-06, 3.2762e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3657e-06, 6.2015e-06, 6.1527e-06,\n",
      "        4.6512e-04, 3.9426e-04, 3.9226e-04, 5.8465e-06, 5.7986e-06, 2.5625e-04,\n",
      "        2.5473e-04, 5.1708e-01, 5.0914e-01, 1.9791e+00, 1.9871e+00, 5.6377e-06,\n",
      "        2.4869e-04, 4.8350e-01, 2.0130e+00, 4.2960e-01, 2.0675e+00, 5.5862e-01,\n",
      "        9.1951e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([155.1747, 187.3309, 201.3554, 204.6408,   8.1626,   8.1629,   8.1625,\n",
      "        302.9031, 302.9031, 302.9031,   8.1629,   8.1627, 302.9031, 302.9031,\n",
      "        302.9031, 302.9031, 302.9031,  47.7593,  47.7593,   8.1621, 302.9031,\n",
      "        302.9031, 302.9031, 302.9031, 302.9031,  47.7593,  47.7593, 302.9031,\n",
      "         47.7593,  47.7593,   5.2026, 302.9031, 302.9031, 302.9031, 302.9031,\n",
      "        302.9031,  47.7593,  47.7593, 302.9031,  47.7593,  47.7593,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 302.9031,   5.2026,   5.2025, 302.9031,   5.2026,\n",
      "          5.2025, 302.9031,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        302.9031, 302.9031, 302.9031, 302.9031,  47.7593,  47.7593,  47.7593,\n",
      "         47.7593, 302.9031, 302.9031, 302.9031,  47.7593,  47.7593,  47.7593,\n",
      "         47.7593,   5.2026,  47.7593,  47.7593,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 430 was 91.9%\n",
      "tensor([1.4542e-07, 4.3882e-06, 3.5947e-06, 3.3285e-06, 3.2710e-06, 2.3161e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3505e-06, 6.1868e-06, 6.1397e-06,\n",
      "        4.6020e-04, 3.9004e-04, 3.8814e-04, 5.8333e-06, 5.7856e-06, 2.5347e-04,\n",
      "        2.5197e-04, 5.1587e-01, 5.0805e-01, 1.9750e+00, 1.9828e+00, 5.6267e-06,\n",
      "        2.4604e-04, 4.8247e-01, 2.0086e+00, 4.2875e-01, 2.0630e+00, 5.5740e-01,\n",
      "        9.1969e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([155.4546, 187.6480, 201.6650, 204.8984,   8.1612,   8.1601,   8.1617,\n",
      "        303.3261, 303.3261, 303.3261,   8.1609,   8.1610, 303.3261, 303.3261,\n",
      "        303.3261, 303.3261, 303.3261,  47.8385,  47.8385,   8.1615, 303.3261,\n",
      "        303.3261, 303.3261, 303.3261, 303.3261,  47.8385,  47.8385, 303.3261,\n",
      "         47.8385,  47.8385,   5.2026, 303.3261, 303.3261, 303.3261, 303.3261,\n",
      "        303.3261,  47.8385,  47.8385, 303.3261,  47.8385,  47.8385,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 303.3261,   5.2026,   5.2025, 303.3261,   5.2026,\n",
      "          5.2025, 303.3261,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        303.3261, 303.3261, 303.3261, 303.3261,  47.8385,  47.8385,  47.8385,\n",
      "         47.8385, 303.3261, 303.3261, 303.3261,  47.8385,  47.8385,  47.8385,\n",
      "         47.8385,   5.2026,  47.8385,  47.8385,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 431 was 91.9%\n",
      "tensor([0.0000e+00, 4.3488e-06, 3.5593e-06, 3.2939e-06, 3.2372e-06, 2.2715e-08,\n",
      "        1.6186e-08, 1.4732e-08, 1.4605e-08, 6.3355e-06, 6.1738e-06, 6.1265e-06,\n",
      "        4.5525e-04, 3.8597e-04, 3.8409e-04, 5.8205e-06, 5.7742e-06, 2.5071e-04,\n",
      "        2.4930e-04, 5.1458e-01, 5.0700e-01, 1.9710e+00, 1.9786e+00, 5.6149e-06,\n",
      "        2.4341e-04, 4.8152e-01, 2.0042e+00, 4.2792e-01, 2.0585e+00, 5.5622e-01,\n",
      "        9.1986e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([155.7342, 187.9646, 201.9742, 205.1560,   8.1590,   8.1595,   8.1589,\n",
      "        303.7491, 303.7491, 303.7491,   8.1599,   8.1601, 303.7491, 303.7491,\n",
      "        303.7491, 303.7491, 303.7491,  47.9177,  47.9177,   8.1596, 303.7491,\n",
      "        303.7491, 303.7491, 303.7491, 303.7491,  47.9177,  47.9177, 303.7491,\n",
      "         47.9177,  47.9177,   5.2026, 303.7491, 303.7491, 303.7491, 303.7491,\n",
      "        303.7491,  47.9177,  47.9177, 303.7491,  47.9177,  47.9177,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 303.7491,   5.2026,   5.2025, 303.7491,   5.2026,\n",
      "          5.2025, 303.7491,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        303.7491, 303.7491, 303.7491, 303.7491,  47.9177,  47.9177,  47.9177,\n",
      "         47.9177, 303.7491, 303.7491, 303.7491,  47.9177,  47.9177,  47.9177,\n",
      "         47.9177,   5.2026,  47.9177,  47.9177,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 432 was 92.0%\n",
      "tensor([2.6470e-23, 4.3397e-06, 3.5526e-06, 3.2881e-06, 3.2324e-06, 2.2536e-08,\n",
      "        1.6057e-08, 1.4616e-08, 1.4493e-08, 6.3215e-06, 6.1588e-06, 6.1139e-06,\n",
      "        4.5038e-04, 3.8180e-04, 3.8005e-04, 5.8075e-06, 5.7613e-06, 2.4800e-04,\n",
      "        2.4657e-04, 5.1338e-01, 5.0588e-01, 1.9668e+00, 1.9743e+00, 5.6037e-06,\n",
      "        2.4083e-04, 4.8050e-01, 1.9999e+00, 4.2712e-01, 2.0540e+00, 5.5503e-01,\n",
      "        9.2003e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([156.0137, 188.2809, 202.2831, 205.4136,   8.1576,   8.1582,   8.1584,\n",
      "        304.1721, 304.1721, 304.1721,   8.1579,   8.1573, 304.1721, 304.1721,\n",
      "        304.1721, 304.1721, 304.1721,  47.9970,  47.9970,   8.1583, 304.1721,\n",
      "        304.1721, 304.1721, 304.1721, 304.1721,  47.9970,  47.9970, 304.1721,\n",
      "         47.9970,  47.9970,   5.2026, 304.1721, 304.1721, 304.1721, 304.1721,\n",
      "        304.1721,  47.9970,  47.9970, 304.1721,  47.9970,  47.9970,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 304.1721,   5.2026,   5.2025, 304.1721,   5.2026,\n",
      "          5.2025, 304.1721,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        304.1721, 304.1721, 304.1721, 304.1721,  47.9970,  47.9970,  47.9970,\n",
      "         47.9970, 304.1721, 304.1721, 304.1721,  47.9970,  47.9970,  47.9970,\n",
      "         47.9970,   5.2026,  47.9970,  47.9970,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 433 was 92.0%\n",
      "tensor([0.0000e+00, 4.3308e-06, 3.5456e-06, 3.2823e-06, 3.2277e-06, 2.2362e-08,\n",
      "        1.5929e-08, 1.4502e-08, 1.4382e-08, 6.3064e-06, 6.1448e-06, 6.1000e-06,\n",
      "        4.4555e-04, 3.7784e-04, 3.7607e-04, 5.7946e-06, 5.7502e-06, 2.4526e-04,\n",
      "        2.4390e-04, 5.1214e-01, 5.0479e-01, 1.9627e+00, 1.9701e+00, 5.5922e-06,\n",
      "        2.3824e-04, 4.7957e-01, 1.9955e+00, 4.2626e-01, 2.0495e+00, 5.5383e-01,\n",
      "        9.2020e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([156.2931, 188.5968, 202.5916, 205.6714,   8.1563,   8.1569,   8.1555,\n",
      "        304.5950, 304.5950, 304.5950,   8.1566,   8.1567, 304.5950, 304.5950,\n",
      "        304.5950, 304.5950, 304.5950,  48.0762,  48.0762,   8.1563, 304.5950,\n",
      "        304.5950, 304.5950, 304.5950, 304.5950,  48.0762,  48.0762, 304.5950,\n",
      "         48.0762,  48.0762,   5.2026, 304.5950, 304.5950, 304.5950, 304.5950,\n",
      "        304.5950,  48.0762,  48.0762, 304.5950,  48.0762,  48.0762,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 304.5950,   5.2026,   5.2025, 304.5950,   5.2026,\n",
      "          5.2025, 304.5950,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        304.5950, 304.5950, 304.5950, 304.5950,  48.0762,  48.0762,  48.0762,\n",
      "         48.0762, 304.5950, 304.5950, 304.5950,  48.0762,  48.0762,  48.0762,\n",
      "         48.0762,   5.2026,  48.0762,  48.0762,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 434 was 92.0%\n",
      "tensor([0.0000e+00, 4.3219e-06, 3.5389e-06, 3.2766e-06, 3.2229e-06, 2.2188e-08,\n",
      "        1.5805e-08, 1.4389e-08, 1.4272e-08, 6.2918e-06, 6.1306e-06, 6.0880e-06,\n",
      "        4.4084e-04, 3.7380e-04, 3.7217e-04, 5.7819e-06, 5.7374e-06, 2.4265e-04,\n",
      "        2.4128e-04, 5.1094e-01, 5.0371e-01, 1.9587e+00, 1.9659e+00, 5.5813e-06,\n",
      "        2.3571e-04, 4.7857e-01, 1.9913e+00, 4.2544e-01, 2.0451e+00, 5.5265e-01,\n",
      "        9.2037e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([156.5723, 188.9123, 202.8997, 205.9294,   8.1549,   8.1540,   8.1550,\n",
      "        305.0179, 305.0179, 305.0179,   8.1549,   8.1547, 305.0179, 305.0179,\n",
      "        305.0179, 305.0179, 305.0179,  48.1554,  48.1554,   8.1554, 305.0179,\n",
      "        305.0179, 305.0179, 305.0179, 305.0179,  48.1554,  48.1554, 305.0179,\n",
      "         48.1554,  48.1554,   5.2026, 305.0179, 305.0179, 305.0179, 305.0179,\n",
      "        305.0179,  48.1554,  48.1554, 305.0179,  48.1554,  48.1554,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 305.0179,   5.2026,   5.2025, 305.0179,   5.2026,\n",
      "          5.2025, 305.0179,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        305.0179, 305.0179, 305.0179, 305.0179,  48.1554,  48.1554,  48.1554,\n",
      "         48.1554, 305.0179, 305.0179, 305.0179,  48.1554,  48.1554,  48.1554,\n",
      "         48.1554,   5.2026,  48.1554,  48.1554,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 435 was 92.0%\n",
      "tensor([1.3825e-07, 4.3421e-06, 3.5592e-06, 3.2984e-06, 3.2462e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2766e-06, 6.1177e-06, 6.0742e-06,\n",
      "        4.3607e-04, 3.6990e-04, 3.6824e-04, 5.7689e-06, 5.7261e-06, 2.3997e-04,\n",
      "        2.3872e-04, 5.0968e-01, 5.0264e-01, 1.9546e+00, 1.9617e+00, 5.5696e-06,\n",
      "        2.3316e-04, 4.7761e-01, 1.9869e+00, 4.2463e-01, 2.0406e+00, 5.5146e-01,\n",
      "        9.2054e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([156.8513, 189.2274, 203.2075, 206.1874,   8.1531,   8.1535,   8.1529,\n",
      "        305.4408, 305.4408, 305.4408,   8.1533,   8.1541, 305.4408, 305.4408,\n",
      "        305.4408, 305.4408, 305.4408,  48.2346,  48.2346,   8.1527, 305.4408,\n",
      "        305.4408, 305.4408, 305.4408, 305.4408,  48.2346,  48.2346, 305.4408,\n",
      "         48.2346,  48.2346,   5.2026, 305.4408, 305.4408, 305.4408, 305.4408,\n",
      "        305.4408,  48.2346,  48.2346, 305.4408,  48.2346,  48.2346,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 305.4408,   5.2026,   5.2025, 305.4408,   5.2026,\n",
      "          5.2025, 305.4408,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        305.4408, 305.4408, 305.4408, 305.4408,  48.2346,  48.2346,  48.2346,\n",
      "         48.2346, 305.4408, 305.4408, 305.4408,  48.2346,  48.2346,  48.2346,\n",
      "         48.2346,   5.2026,  48.2346,  48.2346,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 436 was 92.0%\n",
      "tensor([1.3687e-07, 4.3330e-06, 3.5523e-06, 3.2923e-06, 3.2412e-06, 3.3087e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2628e-06, 6.1025e-06, 6.0618e-06,\n",
      "        4.3151e-04, 3.6592e-04, 3.6442e-04, 5.7565e-06, 5.7134e-06, 2.3739e-04,\n",
      "        2.3608e-04, 5.0847e-01, 5.0159e-01, 1.9506e+00, 1.9575e+00, 5.5592e-06,\n",
      "        2.3071e-04, 4.7660e-01, 1.9827e+00, 4.2381e-01, 2.0362e+00, 5.5029e-01,\n",
      "        9.2071e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([157.1301, 189.5422, 203.5149, 206.4454,   8.1516,   8.1514,   8.1520,\n",
      "        305.8637, 305.8637, 305.8637,   8.1516,   8.1513, 305.8637, 305.8637,\n",
      "        305.8637, 305.8637, 305.8637,  48.3138,  48.3138,   8.1521, 305.8637,\n",
      "        305.8637, 305.8637, 305.8637, 305.8637,  48.3138,  48.3138, 305.8637,\n",
      "         48.3138,  48.3138,   5.2026, 305.8637, 305.8637, 305.8637, 305.8637,\n",
      "        305.8637,  48.3138,  48.3138, 305.8637,  48.3138,  48.3138,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 305.8637,   5.2026,   5.2025, 305.8637,   5.2026,\n",
      "          5.2025, 305.8637,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        305.8637, 305.8637, 305.8637, 305.8637,  48.3138,  48.3138,  48.3138,\n",
      "         48.3138, 305.8637, 305.8637, 305.8637,  48.3138,  48.3138,  48.3138,\n",
      "         48.3138,   5.2026,  48.3138,  48.3138,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 437 was 92.0%\n",
      "tensor([1.3549e-07, 4.3240e-06, 3.5452e-06, 3.2864e-06, 3.2363e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2476e-06, 6.0896e-06, 6.0481e-06,\n",
      "        4.2681e-04, 3.6211e-04, 3.6055e-04, 5.7433e-06, 5.7025e-06, 2.3476e-04,\n",
      "        2.3356e-04, 5.0725e-01, 5.0050e-01, 1.9466e+00, 1.9533e+00, 5.5472e-06,\n",
      "        2.2820e-04, 4.7568e-01, 1.9784e+00, 4.2297e-01, 2.0318e+00, 5.4911e-01,\n",
      "        9.2088e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([157.4087, 189.8567, 203.8220, 206.7036,   8.1494,   8.1509,   8.1499,\n",
      "        306.2865, 306.2865, 306.2865,   8.1503,   8.1507, 306.2865, 306.2865,\n",
      "        306.2865, 306.2865, 306.2865,  48.3931,  48.3931,   8.1493, 306.2865,\n",
      "        306.2865, 306.2865, 306.2865, 306.2865,  48.3931,  48.3931, 306.2865,\n",
      "         48.3931,  48.3931,   5.2026, 306.2865, 306.2865, 306.2865, 306.2865,\n",
      "        306.2865,  48.3931,  48.3931, 306.2865,  48.3931,  48.3931,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 306.2865,   5.2026,   5.2025, 306.2865,   5.2026,\n",
      "          5.2025, 306.2865,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        306.2865, 306.2865, 306.2865, 306.2865,  48.3931,  48.3931,  48.3931,\n",
      "         48.3931, 306.2865, 306.2865, 306.2865,  48.3931,  48.3931,  48.3931,\n",
      "         48.3931,   5.2026,  48.3931,  48.3931,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 438 was 92.1%\n",
      "tensor([0.0000e+00, 4.2867e-06, 3.5120e-06, 3.2539e-06, 3.2043e-06, 2.1502e-08,\n",
      "        1.5307e-08, 1.3942e-08, 1.3837e-08, 6.2344e-06, 6.0751e-06, 6.0359e-06,\n",
      "        4.2233e-04, 3.5820e-04, 3.5679e-04, 5.7312e-06, 5.6897e-06, 2.3221e-04,\n",
      "        2.3099e-04, 5.0609e-01, 4.9943e-01, 1.9426e+00, 1.9492e+00, 5.5372e-06,\n",
      "        2.2580e-04, 4.7471e-01, 1.9742e+00, 4.2217e-01, 2.0274e+00, 5.4795e-01,\n",
      "        9.2105e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([157.6871, 190.1707, 204.1287, 206.9617,   8.1484,   8.1479,   8.1486,\n",
      "        306.7093, 306.7093, 306.7093,   8.1486,   8.1487, 306.7093, 306.7093,\n",
      "        306.7093, 306.7093, 306.7093,  48.4723,  48.4723,   8.1487, 306.7093,\n",
      "        306.7093, 306.7093, 306.7093, 306.7093,  48.4723,  48.4723, 306.7093,\n",
      "         48.4723,  48.4723,   5.2026, 306.7093, 306.7093, 306.7093, 306.7093,\n",
      "        306.7093,  48.4723,  48.4723, 306.7093,  48.4723,  48.4723,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 306.7093,   5.2026,   5.2025, 306.7093,   5.2026,\n",
      "          5.2025, 306.7093,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        306.7093, 306.7093, 306.7093, 306.7093,  48.4723,  48.4723,  48.4723,\n",
      "         48.4723, 306.7093, 306.7093, 306.7093,  48.4723,  48.4723,  48.4723,\n",
      "         48.4723,   5.2026,  48.4723,  48.4723,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 439 was 92.1%\n",
      "tensor([0.0000e+00, 4.2778e-06, 3.5051e-06, 3.2481e-06, 3.1995e-06, 2.1331e-08,\n",
      "        1.5184e-08, 1.3831e-08, 1.3729e-08, 6.2189e-06, 6.0622e-06, 6.0224e-06,\n",
      "        4.1769e-04, 3.5442e-04, 3.5297e-04, 5.7179e-06, 5.6784e-06, 2.2964e-04,\n",
      "        2.2852e-04, 5.0485e-01, 4.9837e-01, 1.9385e+00, 1.9450e+00, 5.5250e-06,\n",
      "        2.2332e-04, 4.7374e-01, 1.9699e+00, 4.2135e-01, 2.0230e+00, 5.4676e-01,\n",
      "        9.2122e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([157.9653, 190.4845, 204.4351, 207.2200,   8.1469,   8.1474,   8.1472,\n",
      "        307.1321, 307.1321, 307.1321,   8.1473,   8.1465, 307.1321, 307.1321,\n",
      "        307.1321, 307.1321, 307.1321,  48.5515,  48.5515,   8.1460, 307.1321,\n",
      "        307.1321, 307.1321, 307.1321, 307.1321,  48.5515,  48.5515, 307.1321,\n",
      "         48.5515,  48.5515,   5.2026, 307.1321, 307.1321, 307.1321, 307.1321,\n",
      "        307.1321,  48.5515,  48.5515, 307.1321,  48.5515,  48.5515,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 307.1321,   5.2026,   5.2025, 307.1321,   5.2026,\n",
      "          5.2025, 307.1321,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        307.1321, 307.1321, 307.1321, 307.1321,  48.5515,  48.5515,  48.5515,\n",
      "         48.5515, 307.1321, 307.1321, 307.1321,  48.5515,  48.5515,  48.5515,\n",
      "         48.5515,   5.2026,  48.5515,  48.5515,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 440 was 92.1%\n",
      "tensor([0.0000e+00, 4.2692e-06, 3.4985e-06, 3.2425e-06, 3.1949e-06, 2.1166e-08,\n",
      "        1.5063e-08, 1.3723e-08, 1.3623e-08, 6.2049e-06, 6.0482e-06, 6.0095e-06,\n",
      "        4.1331e-04, 3.5070e-04, 3.4928e-04, 5.7053e-06, 5.6669e-06, 2.2713e-04,\n",
      "        2.2604e-04, 5.0370e-01, 4.9730e-01, 1.9345e+00, 1.9409e+00, 5.5148e-06,\n",
      "        2.2095e-04, 4.7279e-01, 1.9657e+00, 4.2051e-01, 2.0187e+00, 5.4561e-01,\n",
      "        9.2138e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([158.2434, 190.7978, 204.7411, 207.4784,   8.1455,   8.1445,   8.1455,\n",
      "        307.5548, 307.5548, 307.5548,   8.1453,   8.1456, 307.5548, 307.5548,\n",
      "        307.5548, 307.5548, 307.5548,  48.6307,  48.6307,   8.1454, 307.5548,\n",
      "        307.5548, 307.5548, 307.5548, 307.5548,  48.6307,  48.6307, 307.5548,\n",
      "         48.6307,  48.6307,   5.2026, 307.5548, 307.5548, 307.5548, 307.5548,\n",
      "        307.5548,  48.6307,  48.6307, 307.5548,  48.6307,  48.6307,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 307.5548,   5.2026,   5.2025, 307.5548,   5.2026,\n",
      "          5.2025, 307.5548,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        307.5548, 307.5548, 307.5548, 307.5548,  48.6307,  48.6307,  48.6307,\n",
      "         48.6307, 307.5548, 307.5548, 307.5548,  48.6307,  48.6307,  48.6307,\n",
      "         48.6307,   5.2026,  48.6307,  48.6307,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 441 was 92.1%\n",
      "tensor([1.3235e-22, 4.2604e-06, 3.4919e-06, 3.2368e-06, 3.1902e-06, 2.0997e-08,\n",
      "        1.4942e-08, 1.3613e-08, 1.3517e-08, 6.1901e-06, 6.0351e-06, 5.9968e-06,\n",
      "        4.0880e-04, 3.4693e-04, 3.4559e-04, 5.6931e-06, 5.6549e-06, 2.2464e-04,\n",
      "        2.2359e-04, 5.0246e-01, 4.9627e-01, 1.9306e+00, 1.9368e+00, 5.5030e-06,\n",
      "        2.1854e-04, 4.7182e-01, 1.9614e+00, 4.1973e-01, 2.0143e+00, 5.4444e-01,\n",
      "        9.2155e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([158.5213, 191.1108, 205.0468, 207.7369,   8.1436,   8.1440,   8.1434,\n",
      "        307.9776, 307.9776, 307.9776,   8.1443,   8.1428, 307.9776, 307.9776,\n",
      "        307.9776, 307.9776, 307.9776,  48.7099,  48.7099,   8.1440, 307.9776,\n",
      "        307.9776, 307.9776, 307.9776, 307.9776,  48.7099,  48.7099, 307.9776,\n",
      "         48.7099,  48.7099,   5.2026, 307.9776, 307.9776, 307.9776, 307.9776,\n",
      "        307.9776,  48.7099,  48.7099, 307.9776,  48.7099,  48.7099,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 307.9776,   5.2026,   5.2025, 307.9776,   5.2026,\n",
      "          5.2025, 307.9776,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        307.9776, 307.9776, 307.9776, 307.9776,  48.7099,  48.7099,  48.7099,\n",
      "         48.7099, 307.9776, 307.9776, 307.9776,  48.7099,  48.7099,  48.7099,\n",
      "         48.7099,   5.2026,  48.7099,  48.7099,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 442 was 92.1%\n",
      "tensor([0.0000e+00, 4.2518e-06, 3.4853e-06, 3.2314e-06, 3.1855e-06, 2.0832e-08,\n",
      "        1.4822e-08, 1.3505e-08, 1.3411e-08, 6.1760e-06, 6.0214e-06, 5.9841e-06,\n",
      "        4.0443e-04, 3.4329e-04, 3.4194e-04, 5.6805e-06, 5.6438e-06, 2.2217e-04,\n",
      "        2.2116e-04, 5.0132e-01, 4.9515e-01, 1.9266e+00, 1.9328e+00, 5.4920e-06,\n",
      "        2.1619e-04, 4.7089e-01, 1.9572e+00, 4.1893e-01, 2.0099e+00, 5.4330e-01,\n",
      "        9.2172e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([158.7990, 191.4235, 205.3521, 207.9955,   8.1418,   8.1426,   8.1425,\n",
      "        308.4003, 308.4003, 308.4003,   8.1414,   8.1422, 308.4003, 308.4003,\n",
      "        308.4003, 308.4003, 308.4003,  48.7891,  48.7891,   8.1420, 308.4003,\n",
      "        308.4003, 308.4003, 308.4003, 308.4003,  48.7891,  48.7891, 308.4003,\n",
      "         48.7891,  48.7891,   5.2026, 308.4003, 308.4003, 308.4003, 308.4003,\n",
      "        308.4003,  48.7891,  48.7891, 308.4003,  48.7891,  48.7891,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 308.4003,   5.2026,   5.2025, 308.4003,   5.2026,\n",
      "          5.2025, 308.4003,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        308.4003, 308.4003, 308.4003, 308.4003,  48.7891,  48.7891,  48.7891,\n",
      "         48.7891, 308.4003, 308.4003, 308.4003,  48.7891,  48.7891,  48.7891,\n",
      "         48.7891,   5.2026,  48.7891,  48.7891,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 443 was 92.1%\n",
      "tensor([1.2749e-07, 4.2705e-06, 3.5040e-06, 3.2513e-06, 3.2068e-06, 3.9705e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1623e-06, 6.0073e-06, 5.9714e-06,\n",
      "        4.0006e-04, 3.3957e-04, 3.3833e-04, 5.6685e-06, 5.6315e-06, 2.1971e-04,\n",
      "        2.1870e-04, 5.0010e-01, 4.9415e-01, 1.9226e+00, 1.9286e+00, 5.4811e-06,\n",
      "        2.1385e-04, 4.6996e-01, 1.9530e+00, 4.1809e-01, 2.0056e+00, 5.4214e-01,\n",
      "        9.2188e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([159.0765, 191.7358, 205.6572, 208.2541,   8.1403,   8.1396,   8.1404,\n",
      "        308.8230, 308.8230, 308.8230,   8.1408,   8.1405, 308.8230, 308.8230,\n",
      "        308.8230, 308.8230, 308.8230,  48.8683,  48.8683,   8.1411, 308.8230,\n",
      "        308.8230, 308.8230, 308.8230, 308.8230,  48.8683,  48.8683, 308.8230,\n",
      "         48.8683,  48.8683,   5.2026, 308.8230, 308.8230, 308.8230, 308.8230,\n",
      "        308.8230,  48.8683,  48.8683, 308.8230,  48.8683,  48.8683,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 308.8230,   5.2026,   5.2025, 308.8230,   5.2026,\n",
      "          5.2025, 308.8230,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        308.8230, 308.8230, 308.8230, 308.8230,  48.8683,  48.8683,  48.8683,\n",
      "         48.8683, 308.8230, 308.8230, 308.8230,  48.8683,  48.8683,  48.8683,\n",
      "         48.8683,   5.2026,  48.8683,  48.8683,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 444 was 92.2%\n",
      "tensor([1.2621e-07, 4.2615e-06, 3.4972e-06, 3.2455e-06, 3.2019e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1477e-06, 5.9950e-06, 5.9587e-06,\n",
      "        3.9571e-04, 3.3596e-04, 3.3472e-04, 5.6556e-06, 5.6201e-06, 2.1730e-04,\n",
      "        2.1636e-04, 4.9892e-01, 4.9308e-01, 1.9187e+00, 1.9246e+00, 5.4698e-06,\n",
      "        2.1151e-04, 4.6899e-01, 1.9489e+00, 4.1733e-01, 2.0013e+00, 5.4100e-01,\n",
      "        9.2205e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([159.3539, 192.0478, 205.9619, 208.5128,   8.1388,   8.1391,   8.1390,\n",
      "        309.2456, 309.2456, 309.2456,   8.1387,   8.1391, 309.2456, 309.2456,\n",
      "        309.2456, 309.2456, 309.2456,  48.9475,  48.9475,   8.1383, 309.2456,\n",
      "        309.2456, 309.2456, 309.2456, 309.2456,  48.9475,  48.9475, 309.2456,\n",
      "         48.9475,  48.9475,   5.2026, 309.2456, 309.2456, 309.2456, 309.2456,\n",
      "        309.2456,  48.9475,  48.9475, 309.2456,  48.9475,  48.9475,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 309.2456,   5.2026,   5.2025, 309.2456,   5.2026,\n",
      "          5.2025, 309.2456,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        309.2456, 309.2456, 309.2456, 309.2456,  48.9475,  48.9475,  48.9475,\n",
      "         48.9475, 309.2456, 309.2456, 309.2456,  48.9475,  48.9475,  48.9475,\n",
      "         48.9475,   5.2026,  48.9475,  48.9475,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 445 was 92.2%\n",
      "tensor([1.2493e-07, 4.2528e-06, 3.4905e-06, 3.2397e-06, 3.1970e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1338e-06, 5.9805e-06, 5.9460e-06,\n",
      "        3.9149e-04, 3.3233e-04, 3.3117e-04, 5.6435e-06, 5.6081e-06, 2.1489e-04,\n",
      "        2.1394e-04, 4.9776e-01, 4.9206e-01, 1.9147e+00, 1.9205e+00, 5.4594e-06,\n",
      "        2.0922e-04, 4.6804e-01, 1.9447e+00, 4.1649e-01, 1.9970e+00, 5.3984e-01,\n",
      "        9.2221e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([159.6310, 192.3595, 206.2662, 208.7716,   8.1373,   8.1369,   8.1373,\n",
      "        309.6682, 309.6682, 309.6682,   8.1378,   8.1362, 309.6682, 309.6682,\n",
      "        309.6682, 309.6682, 309.6682,  49.0267,  49.0267,   8.1376, 309.6682,\n",
      "        309.6682, 309.6682, 309.6682, 309.6682,  49.0267,  49.0267, 309.6682,\n",
      "         49.0267,  49.0267,   5.2026, 309.6682, 309.6682, 309.6682, 309.6682,\n",
      "        309.6682,  49.0267,  49.0267, 309.6682,  49.0267,  49.0267,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 309.6682,   5.2026,   5.2025, 309.6682,   5.2026,\n",
      "          5.2025, 309.6682,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        309.6682, 309.6682, 309.6682, 309.6682,  49.0267,  49.0267,  49.0267,\n",
      "         49.0267, 309.6682, 309.6682, 309.6682,  49.0267,  49.0267,  49.0267,\n",
      "         49.0267,   5.2026,  49.0267,  49.0267,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 446 was 92.2%\n",
      "tensor([0.0000e+00, 4.2175e-06, 3.4589e-06, 3.2088e-06, 3.1666e-06, 2.0215e-08,\n",
      "        1.4371e-08, 1.3097e-08, 1.3013e-08, 6.1197e-06, 5.9681e-06, 5.9334e-06,\n",
      "        3.8806e-04, 3.2946e-04, 3.2825e-04, 5.6310e-06, 5.5976e-06, 2.1283e-04,\n",
      "        2.1194e-04, 4.9661e-01, 4.9098e-01, 1.9111e+00, 1.9168e+00, 5.4481e-06,\n",
      "        2.0721e-04, 4.6710e-01, 1.9408e+00, 4.1571e-01, 1.9928e+00, 5.3870e-01,\n",
      "        9.2237e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([159.9080, 192.6706, 206.5678, 209.0322,   8.1354,   8.1363,   8.1359,\n",
      "        310.0908, 310.0908, 310.0908,   8.1348,   8.1355, 310.0908, 310.0908,\n",
      "        310.0908, 310.0908, 310.0908,  49.1060,  49.1060,   8.1356, 310.0908,\n",
      "        310.0908, 310.0908, 310.0908, 310.0908,  49.1060,  49.1060, 310.0908,\n",
      "         49.1060,  49.1060,   5.2026, 310.0908, 310.0908, 310.0908, 310.0908,\n",
      "        310.0908,  49.1060,  49.1060, 310.0908,  49.1060,  49.1060,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 310.0908,   5.2026,   5.2025, 310.0908,   5.2026,\n",
      "          5.2025, 310.0908,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        310.0908, 310.0908, 310.0908, 310.0908,  49.1060,  49.1060,  49.1060,\n",
      "         49.1060, 310.0908, 310.0908, 310.0908,  49.1060,  49.1060,  49.1060,\n",
      "         49.1060,   5.2026,  49.1060,  49.1060,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 447 was 92.2%\n",
      "tensor([0.0000e+00, 4.2091e-06, 3.4524e-06, 3.2033e-06, 3.1620e-06, 2.0054e-08,\n",
      "        1.4254e-08, 1.2992e-08, 1.2910e-08, 6.1062e-06, 5.9538e-06, 5.9210e-06,\n",
      "        3.8389e-04, 3.2589e-04, 3.2480e-04, 5.6194e-06, 5.5852e-06, 2.1050e-04,\n",
      "        2.0959e-04, 4.9545e-01, 4.8996e-01, 1.9072e+00, 1.9127e+00, 5.4374e-06,\n",
      "        2.0497e-04, 4.6619e-01, 1.9366e+00, 4.1487e-01, 1.9886e+00, 5.3756e-01,\n",
      "        9.2253e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([160.1847, 192.9814, 206.8690, 209.2929,   8.1344,   8.1332,   8.1336,\n",
      "        310.5134, 310.5134, 310.5134,   8.1341,   8.1341, 310.5134, 310.5134,\n",
      "        310.5134, 310.5134, 310.5134,  49.1852,  49.1852,   8.1343, 310.5134,\n",
      "        310.5134, 310.5134, 310.5134, 310.5134,  49.1852,  49.1852, 310.5134,\n",
      "         49.1852,  49.1852,   5.2026, 310.5134, 310.5134, 310.5134, 310.5134,\n",
      "        310.5134,  49.1852,  49.1852, 310.5134,  49.1852,  49.1852,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 310.5134,   5.2026,   5.2025, 310.5134,   5.2026,\n",
      "          5.2025, 310.5134,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        310.5134, 310.5134, 310.5134, 310.5134,  49.1852,  49.1852,  49.1852,\n",
      "         49.1852, 310.5134, 310.5134, 310.5134,  49.1852,  49.1852,  49.1852,\n",
      "         49.1852,   5.2026,  49.1852,  49.1852,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 448 was 92.2%\n",
      "tensor([0.0000e+00, 4.2006e-06, 3.4460e-06, 3.1978e-06, 3.1574e-06, 1.9893e-08,\n",
      "        1.4138e-08, 1.2888e-08, 1.2808e-08, 6.0916e-06, 5.9416e-06, 5.9087e-06,\n",
      "        3.7969e-04, 3.2244e-04, 3.2134e-04, 5.6068e-06, 5.5740e-06, 2.0818e-04,\n",
      "        2.0732e-04, 4.9429e-01, 4.8893e-01, 1.9033e+00, 1.9087e+00, 5.4259e-06,\n",
      "        2.0272e-04, 4.6520e-01, 1.9325e+00, 4.1412e-01, 1.9843e+00, 5.3642e-01,\n",
      "        9.2270e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([160.4613, 193.2919, 207.1699, 209.5537,   8.1312,   8.1325,   8.1325,\n",
      "        310.9360, 310.9360, 310.9360,   8.1322,   8.1330, 310.9360, 310.9360,\n",
      "        310.9360, 310.9360, 310.9360,  49.2644,  49.2644,   8.1322, 310.9360,\n",
      "        310.9360, 310.9360, 310.9360, 310.9360,  49.2644,  49.2644, 310.9360,\n",
      "         49.2644,  49.2644,   5.2026, 310.9360, 310.9360, 310.9360, 310.9360,\n",
      "        310.9360,  49.2644,  49.2644, 310.9360,  49.2644,  49.2644,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 310.9360,   5.2026,   5.2025, 310.9360,   5.2026,\n",
      "          5.2025, 310.9360,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        310.9360, 310.9360, 310.9360, 310.9360,  49.2644,  49.2644,  49.2644,\n",
      "         49.2644, 310.9360, 310.9360, 310.9360,  49.2644,  49.2644,  49.2644,\n",
      "         49.2644,   5.2026,  49.2644,  49.2644,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 449 was 92.2%\n",
      "tensor([0.0000e+00, 4.1926e-06, 3.4402e-06, 3.1931e-06, 3.1535e-06, 1.9830e-08,\n",
      "        1.4105e-08, 1.2866e-08, 1.2788e-08, 6.0789e-06, 5.9274e-06, 5.8959e-06,\n",
      "        3.7729e-04, 3.2059e-04, 3.1958e-04, 5.5947e-06, 5.5620e-06, 2.0731e-04,\n",
      "        2.0646e-04, 4.9310e-01, 4.8788e-01, 1.8990e+00, 1.9043e+00, 5.4159e-06,\n",
      "        2.0207e-04, 4.6426e-01, 1.9281e+00, 4.1331e-01, 1.9798e+00, 5.3528e-01,\n",
      "        9.2287e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([160.7380, 193.6026, 207.4739, 209.8121,   8.1301,   8.1307,   8.1304,\n",
      "        311.3585, 311.3585, 311.3585,   8.1309,   8.1300, 311.3585, 311.3585,\n",
      "        311.3585, 311.3585, 311.3585,  49.3436,  49.3436,   8.1316, 311.3585,\n",
      "        311.3585, 311.3585, 311.3585, 311.3585,  49.3436,  49.3436, 311.3585,\n",
      "         49.3436,  49.3436,   5.2026, 311.3585, 311.3585, 311.3585, 311.3585,\n",
      "        311.3585,  49.3436,  49.3436, 311.3585,  49.3436,  49.3436,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 311.3585,   5.2026,   5.2025, 311.3585,   5.2026,\n",
      "          5.2025, 311.3585,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        311.3585, 311.3585, 311.3585, 311.3585,  49.3436,  49.3436,  49.3436,\n",
      "         49.3436, 311.3585, 311.3585, 311.3585,  49.3436,  49.3436,  49.3436,\n",
      "         49.3436,   5.2026,  49.3436,  49.3436,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 450 was 92.3%\n",
      "tensor([0.0000e+00, 4.1841e-06, 3.4337e-06, 3.1878e-06, 3.1489e-06, 1.9674e-08,\n",
      "        1.3992e-08, 1.2764e-08, 1.2689e-08, 6.0640e-06, 5.9149e-06, 5.8834e-06,\n",
      "        3.7321e-04, 3.1725e-04, 3.1623e-04, 5.5825e-06, 5.5512e-06, 2.0504e-04,\n",
      "        2.0426e-04, 4.9197e-01, 4.8677e-01, 1.8952e+00, 1.9004e+00, 5.4045e-06,\n",
      "        1.9985e-04, 4.6336e-01, 1.9240e+00, 4.1253e-01, 1.9756e+00, 5.3416e-01,\n",
      "        9.2303e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([161.0145, 193.9130, 207.7776, 210.0705,   8.1286,   8.1293,   8.1290,\n",
      "        311.7810, 311.7810, 311.7810,   8.1287,   8.1294, 311.7810, 311.7810,\n",
      "        311.7810, 311.7810, 311.7810,  49.4228,  49.4228,   8.1287, 311.7810,\n",
      "        311.7810, 311.7810, 311.7810, 311.7810,  49.4228,  49.4228, 311.7810,\n",
      "         49.4228,  49.4228,   5.2026, 311.7810, 311.7810, 311.7810, 311.7810,\n",
      "        311.7810,  49.4228,  49.4228, 311.7810,  49.4228,  49.4228,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 311.7810,   5.2026,   5.2025, 311.7810,   5.2026,\n",
      "          5.2025, 311.7810,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        311.7810, 311.7810, 311.7810, 311.7810,  49.4228,  49.4228,  49.4228,\n",
      "         49.4228, 311.7810, 311.7810, 311.7810,  49.4228,  49.4228,  49.4228,\n",
      "         49.4228,   5.2026,  49.4228,  49.4228,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 451 was 92.3%\n",
      "tensor([1.1846e-07, 4.2014e-06, 3.4510e-06, 3.2061e-06, 3.1684e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0508e-06, 5.9009e-06, 5.8711e-06,\n",
      "        3.6923e-04, 3.1379e-04, 3.1286e-04, 5.5705e-06, 5.5390e-06, 2.0278e-04,\n",
      "        2.0197e-04, 4.9082e-01, 4.8581e-01, 1.8913e+00, 1.8963e+00, 5.3943e-06,\n",
      "        1.9770e-04, 4.6240e-01, 1.9199e+00, 4.1171e-01, 1.9714e+00, 5.3302e-01,\n",
      "        9.2320e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([161.2909, 194.2230, 208.0809, 210.3291,   8.1275,   8.1271,   8.1273,\n",
      "        312.2035, 312.2035, 312.2035,   8.1274,   8.1265, 312.2035, 312.2035,\n",
      "        312.2035, 312.2035, 312.2035,  49.5020,  49.5020,   8.1281, 312.2035,\n",
      "        312.2035, 312.2035, 312.2035, 312.2035,  49.5020,  49.5020, 312.2035,\n",
      "         49.5020,  49.5020,   5.2026, 312.2035, 312.2035, 312.2035, 312.2035,\n",
      "        312.2035,  49.5020,  49.5020, 312.2035,  49.5020,  49.5020,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 312.2035,   5.2026,   5.2025, 312.2035,   5.2026,\n",
      "          5.2025, 312.2035,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        312.2035, 312.2035, 312.2035, 312.2035,  49.5020,  49.5020,  49.5020,\n",
      "         49.5020, 312.2035, 312.2035, 312.2035,  49.5020,  49.5020,  49.5020,\n",
      "         49.5020,   5.2026,  49.5020,  49.5020,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 452 was 92.3%\n",
      "tensor([1.1749e-07, 4.1928e-06, 3.4441e-06, 3.2001e-06, 3.1632e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0362e-06, 5.8888e-06, 5.8588e-06,\n",
      "        3.6601e-04, 3.1113e-04, 3.1015e-04, 5.5583e-06, 5.5289e-06, 2.0087e-04,\n",
      "        2.0012e-04, 4.8968e-01, 4.8475e-01, 1.8877e+00, 1.8927e+00, 5.3828e-06,\n",
      "        1.9580e-04, 4.6149e-01, 1.9161e+00, 4.1094e-01, 1.9673e+00, 5.3189e-01,\n",
      "        9.2335e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([161.5670, 194.5326, 208.3816, 210.5894,   8.1251,   8.1264,   8.1258,\n",
      "        312.6260, 312.6260, 312.6260,   8.1255,   8.1258, 312.6260, 312.6260,\n",
      "        312.6260, 312.6260, 312.6260,  49.5812,  49.5812,   8.1252, 312.6260,\n",
      "        312.6260, 312.6260, 312.6260, 312.6260,  49.5812,  49.5812, 312.6260,\n",
      "         49.5812,  49.5812,   5.2026, 312.6260, 312.6260, 312.6260, 312.6260,\n",
      "        312.6260,  49.5812,  49.5812, 312.6260,  49.5812,  49.5812,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 312.6260,   5.2026,   5.2025, 312.6260,   5.2026,\n",
      "          5.2025, 312.6260,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        312.6260, 312.6260, 312.6260, 312.6260,  49.5812,  49.5812,  49.5812,\n",
      "         49.5812, 312.6260, 312.6260, 312.6260,  49.5812,  49.5812,  49.5812,\n",
      "         49.5812,   5.2026,  49.5812,  49.5812,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 453 was 92.3%\n",
      "tensor([7.9409e-23, 4.1592e-06, 3.4143e-06, 3.1711e-06, 3.1347e-06, 1.9246e-08,\n",
      "        1.3679e-08, 1.2479e-08, 1.2410e-08, 6.0237e-06, 5.8749e-06, 5.8463e-06,\n",
      "        3.6214e-04, 3.0774e-04, 3.0686e-04, 5.5464e-06, 5.5164e-06, 1.9865e-04,\n",
      "        1.9790e-04, 4.8857e-01, 4.8374e-01, 1.8839e+00, 1.8887e+00, 5.3730e-06,\n",
      "        1.9371e-04, 4.6057e-01, 1.9120e+00, 4.1012e-01, 1.9631e+00, 5.3078e-01,\n",
      "        9.2351e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([161.8430, 194.8418, 208.6819, 210.8499,   8.1244,   8.1232,   8.1235,\n",
      "        313.0484, 313.0484, 313.0484,   8.1241,   8.1239, 313.0484, 313.0484,\n",
      "        313.0484, 313.0484, 313.0484,  49.6604,  49.6604,   8.1245, 313.0484,\n",
      "        313.0484, 313.0484, 313.0484, 313.0484,  49.6604,  49.6604, 313.0484,\n",
      "         49.6604,  49.6604,   5.2026, 313.0484, 313.0484, 313.0484, 313.0484,\n",
      "        313.0484,  49.6604,  49.6604, 313.0484,  49.6604,  49.6604,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 313.0484,   5.2026,   5.2025, 313.0484,   5.2026,\n",
      "          5.2025, 313.0484,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        313.0484, 313.0484, 313.0484, 313.0484,  49.6604,  49.6604,  49.6604,\n",
      "         49.6604, 313.0484, 313.0484, 313.0484,  49.6604,  49.6604,  49.6604,\n",
      "         49.6604,   5.2026,  49.6604,  49.6604,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 454 was 92.3%\n",
      "tensor([0.0000e+00, 4.1509e-06, 3.4081e-06, 3.1657e-06, 3.1301e-06, 1.9092e-08,\n",
      "        1.3568e-08, 1.2380e-08, 1.2312e-08, 6.0090e-06, 5.8631e-06, 5.8343e-06,\n",
      "        3.5817e-04, 3.0453e-04, 3.0362e-04, 5.5345e-06, 5.5059e-06, 1.9648e-04,\n",
      "        1.9578e-04, 4.8743e-01, 4.8273e-01, 1.8800e+00, 1.8847e+00, 5.3612e-06,\n",
      "        1.9158e-04, 4.5961e-01, 1.9080e+00, 4.0937e-01, 1.9589e+00, 5.2966e-01,\n",
      "        9.2367e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([162.1188, 195.1508, 208.9819, 211.1104,   8.1220,   8.1226,   8.1224,\n",
      "        313.4709, 313.4709, 313.4709,   8.1222,   8.1228, 313.4709, 313.4709,\n",
      "        313.4709, 313.4709, 313.4709,  49.7396,  49.7396,   8.1216, 313.4709,\n",
      "        313.4709, 313.4709, 313.4709, 313.4709,  49.7396,  49.7396, 313.4709,\n",
      "         49.7396,  49.7396,   5.2026, 313.4709, 313.4709, 313.4709, 313.4709,\n",
      "        313.4709,  49.7396,  49.7396, 313.4709,  49.7396,  49.7396,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 313.4709,   5.2026,   5.2025, 313.4709,   5.2026,\n",
      "          5.2025, 313.4709,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        313.4709, 313.4709, 313.4709, 313.4709,  49.7396,  49.7396,  49.7396,\n",
      "         49.7396, 313.4709, 313.4709, 313.4709,  49.7396,  49.7396,  49.7396,\n",
      "         49.7396,   5.2026,  49.7396,  49.7396,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 455 was 92.3%\n",
      "tensor([0.0000e+00, 4.1442e-06, 3.4028e-06, 3.1612e-06, 3.1265e-06, 1.9515e-08,\n",
      "        1.3918e-08, 1.2722e-08, 1.2656e-08, 5.9962e-06, 5.8490e-06, 5.8216e-06,\n",
      "        3.6450e-04, 3.1065e-04, 3.0987e-04, 5.5221e-06, 5.4935e-06, 2.0172e-04,\n",
      "        2.0104e-04, 4.8618e-01, 4.8161e-01, 1.8757e+00, 1.8803e+00, 5.3514e-06,\n",
      "        1.9711e-04, 4.5858e-01, 1.9035e+00, 4.0847e-01, 1.9542e+00, 5.2843e-01,\n",
      "        9.2385e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([162.3954, 195.4603, 209.2858, 211.3676,   8.1210,   8.1203,   8.1206,\n",
      "        313.8933, 313.8933, 313.8933,   8.1208,   8.1198, 313.8933, 313.8933,\n",
      "        313.8933, 313.8933, 313.8933,  49.8188,  49.8188,   8.1210, 313.8933,\n",
      "        313.8933, 313.8933, 313.8933, 313.8933,  49.8188,  49.8188, 313.8933,\n",
      "         49.8188,  49.8188,   5.2026, 313.8933, 313.8933, 313.8933, 313.8933,\n",
      "        313.8933,  49.8188,  49.8188, 313.8933,  49.8188,  49.8188,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 313.8933,   5.2026,   5.2025, 313.8933,   5.2026,\n",
      "          5.2025, 313.8933,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        313.8933, 313.8933, 313.8933, 313.8933,  49.8188,  49.8188,  49.8188,\n",
      "         49.8188, 313.8933, 313.8933, 313.8933,  49.8188,  49.8188,  49.8188,\n",
      "         49.8188,   5.2026,  49.8188,  49.8188,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 456 was 92.4%\n",
      "tensor([1.1674e-07, 4.1613e-06, 3.4199e-06, 3.1796e-06, 3.1458e-06, 5.2940e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9819e-06, 5.8369e-06, 5.8093e-06,\n",
      "        3.6070e-04, 3.0757e-04, 3.0674e-04, 5.5100e-06, 5.4833e-06, 1.9962e-04,\n",
      "        1.9901e-04, 4.8507e-01, 4.8058e-01, 1.8719e+00, 1.8764e+00, 5.3400e-06,\n",
      "        1.9507e-04, 4.5768e-01, 1.8995e+00, 4.0769e-01, 1.9500e+00, 5.2732e-01,\n",
      "        9.2401e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([162.6719, 195.7695, 209.5893, 211.6250,   8.1181,   8.1197,   8.1192,\n",
      "        314.3156, 314.3156, 314.3156,   8.1190,   8.1192, 314.3156, 314.3156,\n",
      "        314.3156, 314.3156, 314.3156,  49.8980,  49.8980,   8.1180, 314.3156,\n",
      "        314.3156, 314.3156, 314.3156, 314.3156,  49.8980,  49.8980, 314.3156,\n",
      "         49.8980,  49.8980,   5.2026, 314.3156, 314.3156, 314.3156, 314.3156,\n",
      "        314.3156,  49.8980,  49.8980, 314.3156,  49.8980,  49.8980,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 314.3156,   5.2026,   5.2025, 314.3156,   5.2026,\n",
      "          5.2025, 314.3156,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        314.3156, 314.3156, 314.3156, 314.3156,  49.8980,  49.8980,  49.8980,\n",
      "         49.8980, 314.3156, 314.3156, 314.3156,  49.8980,  49.8980,  49.8980,\n",
      "         49.8980,   5.2026,  49.8980,  49.8980,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 457 was 92.4%\n",
      "tensor([1.1565e-07, 4.1530e-06, 3.4135e-06, 3.1741e-06, 3.1412e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9696e-06, 5.8232e-06, 5.7972e-06,\n",
      "        3.5710e-04, 3.0439e-04, 3.0367e-04, 5.4983e-06, 5.4712e-06, 1.9755e-04,\n",
      "        1.9692e-04, 4.8396e-01, 4.7958e-01, 1.8681e+00, 1.8725e+00, 5.3305e-06,\n",
      "        1.9313e-04, 4.5678e-01, 1.8955e+00, 4.0690e-01, 1.9459e+00, 5.2622e-01,\n",
      "        9.2416e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([162.9482, 196.0785, 209.8926, 211.8824,   8.1171,   8.1166,   8.1170,\n",
      "        314.7380, 314.7380, 314.7380,   8.1176,   8.1174, 314.7380, 314.7380,\n",
      "        314.7380, 314.7380, 314.7380,  49.9772,  49.9772,   8.1174, 314.7380,\n",
      "        314.7380, 314.7380, 314.7380, 314.7380,  49.9772,  49.9772, 314.7380,\n",
      "         49.9772,  49.9772,   5.2026, 314.7380, 314.7380, 314.7380, 314.7380,\n",
      "        314.7380,  49.9772,  49.9772, 314.7380,  49.9772,  49.9772,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 314.7380,   5.2026,   5.2025, 314.7380,   5.2026,\n",
      "          5.2025, 314.7380,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        314.7380, 314.7380, 314.7380, 314.7380,  49.9772,  49.9772,  49.9772,\n",
      "         49.9772, 314.7380, 314.7380, 314.7380,  49.9772,  49.9772,  49.9772,\n",
      "         49.9772,   5.2026,  49.9772,  49.9772,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 458 was 92.4%\n",
      "tensor([1.1454e-07, 4.1444e-06, 3.4071e-06, 3.1685e-06, 3.1364e-06, 1.3235e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9553e-06, 5.8111e-06, 5.7848e-06,\n",
      "        3.5334e-04, 3.0131e-04, 3.0056e-04, 5.4860e-06, 5.4602e-06, 1.9549e-04,\n",
      "        1.9492e-04, 4.8281e-01, 4.7856e-01, 1.8643e+00, 1.8686e+00, 5.3189e-06,\n",
      "        1.9112e-04, 4.5582e-01, 1.8915e+00, 4.0615e-01, 1.9417e+00, 5.2510e-01,\n",
      "        9.2432e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([163.2244, 196.3871, 210.1955, 212.1399,   8.1151,   8.1160,   8.1160,\n",
      "        315.1603, 315.1603, 315.1603,   8.1146,   8.1159, 315.1603, 315.1603,\n",
      "        315.1603, 315.1603, 315.1603,  50.0564,  50.0564,   8.1152, 315.1603,\n",
      "        315.1603, 315.1603, 315.1603, 315.1603,  50.0564,  50.0564, 315.1603,\n",
      "         50.0564,  50.0564,   5.2026, 315.1603, 315.1603, 315.1603, 315.1603,\n",
      "        315.1603,  50.0564,  50.0564, 315.1603,  50.0564,  50.0564,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 315.1603,   5.2026,   5.2025, 315.1603,   5.2026,\n",
      "          5.2025, 315.1603,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        315.1603, 315.1603, 315.1603, 315.1603,  50.0564,  50.0564,  50.0564,\n",
      "         50.0564, 315.1603, 315.1603, 315.1603,  50.0564,  50.0564,  50.0564,\n",
      "         50.0564,   5.2026,  50.0564,  50.0564,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 459 was 92.4%\n",
      "tensor([1.1347e-07, 4.1363e-06, 3.4007e-06, 3.1630e-06, 3.1319e-06, 1.3235e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9424e-06, 5.7974e-06, 5.7729e-06,\n",
      "        3.4977e-04, 2.9824e-04, 2.9759e-04, 5.4751e-06, 5.4489e-06, 1.9347e-04,\n",
      "        1.9288e-04, 4.8169e-01, 4.7759e-01, 1.8606e+00, 1.8647e+00, 5.3090e-06,\n",
      "        1.8919e-04, 4.5495e-01, 1.8875e+00, 4.0535e-01, 1.9376e+00, 5.2402e-01,\n",
      "        9.2448e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([163.5004, 196.6955, 210.4982, 212.3975,   8.1136,   8.1129,   8.1138,\n",
      "        315.5827, 315.5827, 315.5827,   8.1139,   8.1141, 315.5827, 315.5827,\n",
      "        315.5827, 315.5827, 315.5827,  50.1356,  50.1356,   8.1142, 315.5827,\n",
      "        315.5827, 315.5827, 315.5827, 315.5827,  50.1356,  50.1356, 315.5827,\n",
      "         50.1356,  50.1356,   5.2026, 315.5827, 315.5827, 315.5827, 315.5827,\n",
      "        315.5827,  50.1356,  50.1356, 315.5827,  50.1356,  50.1356,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 315.5827,   5.2026,   5.2025, 315.5827,   5.2026,\n",
      "          5.2025, 315.5827,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        315.5827, 315.5827, 315.5827, 315.5827,  50.1356,  50.1356,  50.1356,\n",
      "         50.1356, 315.5827, 315.5827, 315.5827,  50.1356,  50.1356,  50.1356,\n",
      "         50.1356,   5.2026,  50.1356,  50.1356,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 460 was 92.4%\n",
      "tensor([0.0000e+00, 4.1034e-06, 3.3717e-06, 3.1347e-06, 3.1042e-06, 1.8793e-08,\n",
      "        1.3398e-08, 1.2253e-08, 1.2197e-08, 5.9284e-06, 5.7856e-06, 5.7608e-06,\n",
      "        3.4610e-04, 2.9520e-04, 2.9451e-04, 5.4625e-06, 5.4380e-06, 1.9144e-04,\n",
      "        1.9091e-04, 4.8056e-01, 4.7657e-01, 1.8568e+00, 1.8608e+00, 5.2978e-06,\n",
      "        1.8722e-04, 4.5401e-01, 1.8835e+00, 4.0461e-01, 1.9335e+00, 5.2291e-01,\n",
      "        9.2464e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([163.7763, 197.0036, 210.8006, 212.6553,   8.1121,   8.1123,   8.1123,\n",
      "        316.0049, 316.0049, 316.0049,   8.1125,   8.1119, 316.0049, 316.0049,\n",
      "        316.0049, 316.0049, 316.0049,  50.2148,  50.2148,   8.1112, 316.0049,\n",
      "        316.0049, 316.0049, 316.0049, 316.0049,  50.2148,  50.2148, 316.0049,\n",
      "         50.2148,  50.2148,   5.2026, 316.0049, 316.0049, 316.0049, 316.0049,\n",
      "        316.0049,  50.2148,  50.2148, 316.0049,  50.2148,  50.2148,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 316.0049,   5.2026,   5.2025, 316.0049,   5.2026,\n",
      "          5.2025, 316.0049,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        316.0049, 316.0049, 316.0049, 316.0049,  50.2148,  50.2148,  50.2148,\n",
      "         50.2148, 316.0049, 316.0049, 316.0049,  50.2148,  50.2148,  50.2148,\n",
      "         50.2148,   5.2026,  50.2148,  50.2148,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 461 was 92.4%\n",
      "tensor([1.5882e-22, 4.0954e-06, 3.3656e-06, 3.1295e-06, 3.0996e-06, 1.8653e-08,\n",
      "        1.3297e-08, 1.2161e-08, 1.2107e-08, 5.9152e-06, 5.7723e-06, 5.7483e-06,\n",
      "        3.4260e-04, 2.9221e-04, 2.9153e-04, 5.4506e-06, 5.4271e-06, 1.8943e-04,\n",
      "        1.8892e-04, 4.7950e-01, 4.7556e-01, 1.8530e+00, 1.8569e+00, 5.2880e-06,\n",
      "        1.8531e-04, 4.5310e-01, 1.8795e+00, 4.0381e-01, 1.9294e+00, 5.2182e-01,\n",
      "        9.2480e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([164.0520, 197.3114, 211.1026, 212.9131,   8.1106,   8.1100,   8.1105,\n",
      "        316.4272, 316.4272, 316.4272,   8.1094,   8.1109, 316.4272, 316.4272,\n",
      "        316.4272, 316.4272, 316.4272,  50.2940,  50.2940,   8.1105, 316.4272,\n",
      "        316.4272, 316.4272, 316.4272, 316.4272,  50.2940,  50.2940, 316.4272,\n",
      "         50.2940,  50.2940,   5.2026, 316.4272, 316.4272, 316.4272, 316.4272,\n",
      "        316.4272,  50.2940,  50.2940, 316.4272,  50.2940,  50.2940,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 316.4272,   5.2026,   5.2025, 316.4272,   5.2026,\n",
      "          5.2025, 316.4272,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        316.4272, 316.4272, 316.4272, 316.4272,  50.2940,  50.2940,  50.2940,\n",
      "         50.2940, 316.4272, 316.4272, 316.4272,  50.2940,  50.2940,  50.2940,\n",
      "         50.2940,   5.2026,  50.2940,  50.2940,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 462 was 92.4%\n",
      "tensor([0.0000e+00, 4.0873e-06, 3.3595e-06, 3.1242e-06, 3.0953e-06, 1.8512e-08,\n",
      "        1.3195e-08, 1.2069e-08, 1.2018e-08, 5.9015e-06, 5.7597e-06, 5.7367e-06,\n",
      "        3.3904e-04, 2.8922e-04, 2.8863e-04, 5.4399e-06, 5.4159e-06, 1.8747e-04,\n",
      "        1.8696e-04, 4.7835e-01, 4.7460e-01, 1.8492e+00, 1.8530e+00, 5.2770e-06,\n",
      "        1.8339e-04, 4.5220e-01, 1.8756e+00, 4.0306e-01, 1.9253e+00, 5.2073e-01,\n",
      "        9.2495e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([164.3276, 197.6189, 211.4044, 213.1711,   8.1077,   8.1090,   8.1094,\n",
      "        316.8495, 316.8495, 316.8495,   8.1088,   8.1078, 316.8495, 316.8495,\n",
      "        316.8495, 316.8495, 316.8495,  50.3732,  50.3732,   8.1087, 316.8495,\n",
      "        316.8495, 316.8495, 316.8495, 316.8495,  50.3732,  50.3732, 316.8495,\n",
      "         50.3732,  50.3732,   5.2026, 316.8495, 316.8495, 316.8495, 316.8495,\n",
      "        316.8495,  50.3732,  50.3732, 316.8495,  50.3732,  50.3732,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 316.8495,   5.2026,   5.2025, 316.8495,   5.2026,\n",
      "          5.2025, 316.8495,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        316.8495, 316.8495, 316.8495, 316.8495,  50.3732,  50.3732,  50.3732,\n",
      "         50.3732, 316.8495, 316.8495, 316.8495,  50.3732,  50.3732,  50.3732,\n",
      "         50.3732,   5.2026,  50.3732,  50.3732,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 463 was 92.5%\n",
      "tensor([1.0588e-22, 4.0795e-06, 3.3534e-06, 3.1191e-06, 3.0909e-06, 1.8373e-08,\n",
      "        1.3094e-08, 1.1979e-08, 1.1928e-08, 5.8894e-06, 5.7472e-06, 5.7239e-06,\n",
      "        3.3557e-04, 2.8631e-04, 2.8566e-04, 5.4275e-06, 5.4056e-06, 1.8547e-04,\n",
      "        1.8503e-04, 4.7728e-01, 4.7357e-01, 1.8455e+00, 1.8492e+00, 5.2669e-06,\n",
      "        1.8154e-04, 4.5135e-01, 1.8716e+00, 4.0227e-01, 1.9212e+00, 5.1966e-01,\n",
      "        9.2511e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([164.6031, 197.9262, 211.7060, 213.4290,   8.1066,   8.1068,   8.1063,\n",
      "        317.2717, 317.2717, 317.2717,   8.1069,   8.1067, 317.2717, 317.2717,\n",
      "        317.2717, 317.2717, 317.2717,  50.4524,  50.4524,   8.1077, 317.2717,\n",
      "        317.2717, 317.2717, 317.2717, 317.2717,  50.4524,  50.4524, 317.2717,\n",
      "         50.4524,  50.4524,   5.2026, 317.2717, 317.2717, 317.2717, 317.2717,\n",
      "        317.2717,  50.4524,  50.4524, 317.2717,  50.4524,  50.4524,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 317.2717,   5.2026,   5.2025, 317.2717,   5.2026,\n",
      "          5.2025, 317.2717,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        317.2717, 317.2717, 317.2717, 317.2717,  50.4524,  50.4524,  50.4524,\n",
      "         50.4524, 317.2717, 317.2717, 317.2717,  50.4524,  50.4524,  50.4524,\n",
      "         50.4524,   5.2026,  50.4524,  50.4524,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 464 was 92.5%\n",
      "tensor([3.9705e-23, 4.0713e-06, 3.3473e-06, 3.1139e-06, 3.0864e-06, 1.8233e-08,\n",
      "        1.2994e-08, 1.1888e-08, 1.1839e-08, 5.8750e-06, 5.7347e-06, 5.7130e-06,\n",
      "        3.3205e-04, 2.8336e-04, 2.8278e-04, 5.4161e-06, 5.3941e-06, 1.8358e-04,\n",
      "        1.8311e-04, 4.7617e-01, 4.7255e-01, 1.8417e+00, 1.8454e+00, 5.2558e-06,\n",
      "        1.7963e-04, 4.5042e-01, 1.8677e+00, 4.0155e-01, 1.9171e+00, 5.1857e-01,\n",
      "        9.2527e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([164.8784, 198.2332, 212.0072, 213.6871,   8.1051,   8.1053,   8.1057,\n",
      "        317.6939, 317.6939, 317.6939,   8.1046,   8.1053, 317.6939, 317.6939,\n",
      "        317.6939, 317.6939, 317.6939,  50.5316,  50.5316,   8.1047, 317.6939,\n",
      "        317.6939, 317.6939, 317.6939, 317.6939,  50.5316,  50.5316, 317.6939,\n",
      "         50.5316,  50.5316,   5.2026, 317.6939, 317.6939, 317.6939, 317.6939,\n",
      "        317.6939,  50.5316,  50.5316, 317.6939,  50.5316,  50.5316,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 317.6939,   5.2026,   5.2025, 317.6939,   5.2026,\n",
      "          5.2025, 317.6939,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        317.6939, 317.6939, 317.6939, 317.6939,  50.5316,  50.5316,  50.5316,\n",
      "         50.5316, 317.6939, 317.6939, 317.6939,  50.5316,  50.5316,  50.5316,\n",
      "         50.5316,   5.2026,  50.5316,  50.5316,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 465 was 92.5%\n",
      "tensor([1.3235e-23, 4.0635e-06, 3.3413e-06, 3.1086e-06, 3.0820e-06, 1.8095e-08,\n",
      "        1.2894e-08, 1.1797e-08, 1.1751e-08, 5.8624e-06, 5.7218e-06, 5.7004e-06,\n",
      "        3.2869e-04, 2.8045e-04, 2.7989e-04, 5.4044e-06, 5.3829e-06, 1.8163e-04,\n",
      "        1.8119e-04, 4.7508e-01, 4.7162e-01, 1.8380e+00, 1.8415e+00, 5.2461e-06,\n",
      "        1.7780e-04, 4.4952e-01, 1.8637e+00, 4.0073e-01, 1.9131e+00, 5.1748e-01,\n",
      "        9.2542e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([165.1536, 198.5399, 212.3082, 213.9454,   8.1035,   8.1034,   8.1025,\n",
      "        318.1161, 318.1161, 318.1161,   8.1040,   8.1030, 318.1161, 318.1161,\n",
      "        318.1161, 318.1161, 318.1161,  50.6108,  50.6108,   8.1037, 318.1161,\n",
      "        318.1161, 318.1161, 318.1161, 318.1161,  50.6108,  50.6108, 318.1161,\n",
      "         50.6108,  50.6108,   5.2026, 318.1161, 318.1161, 318.1161, 318.1161,\n",
      "        318.1161,  50.6108,  50.6108, 318.1161,  50.6108,  50.6108,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 318.1161,   5.2026,   5.2025, 318.1161,   5.2026,\n",
      "          5.2025, 318.1161,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        318.1161, 318.1161, 318.1161, 318.1161,  50.6108,  50.6108,  50.6108,\n",
      "         50.6108, 318.1161, 318.1161, 318.1161,  50.6108,  50.6108,  50.6108,\n",
      "         50.6108,   5.2026,  50.6108,  50.6108,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 466 was 92.5%\n",
      "tensor([0.0000e+00, 4.0555e-06, 3.3353e-06, 3.1036e-06, 3.0775e-06, 1.7958e-08,\n",
      "        1.2796e-08, 1.1709e-08, 1.1663e-08, 5.8489e-06, 5.7096e-06, 5.6891e-06,\n",
      "        3.2528e-04, 2.7761e-04, 2.7705e-04, 5.3928e-06, 5.3724e-06, 1.7975e-04,\n",
      "        1.7933e-04, 4.7404e-01, 4.7059e-01, 1.8343e+00, 1.8377e+00, 5.2354e-06,\n",
      "        1.7596e-04, 4.4860e-01, 1.8599e+00, 4.0001e-01, 1.9091e+00, 5.1640e-01,\n",
      "        9.2558e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([165.4287, 198.8463, 212.6088, 214.2037,   8.1010,   8.1024,   8.1019,\n",
      "        318.5383, 318.5383, 318.5383,   8.1009,   8.1020, 318.5383, 318.5383,\n",
      "        318.5383, 318.5383, 318.5383,  50.6899,  50.6899,   8.1014, 318.5383,\n",
      "        318.5383, 318.5383, 318.5383, 318.5383,  50.6899,  50.6899, 318.5383,\n",
      "         50.6899,  50.6899,   5.2026, 318.5383, 318.5383, 318.5383, 318.5383,\n",
      "        318.5383,  50.6899,  50.6899, 318.5383,  50.6899,  50.6899,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 318.5383,   5.2026,   5.2025, 318.5383,   5.2026,\n",
      "          5.2025, 318.5383,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        318.5383, 318.5383, 318.5383, 318.5383,  50.6899,  50.6899,  50.6899,\n",
      "         50.6899, 318.5383, 318.5383, 318.5383,  50.6899,  50.6899,  50.6899,\n",
      "         50.6899,   5.2026,  50.6899,  50.6899,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 467 was 92.5%\n",
      "tensor([1.0515e-07, 4.0709e-06, 3.3506e-06, 3.1198e-06, 3.0948e-06, 3.9705e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8367e-06, 5.6962e-06, 5.6771e-06,\n",
      "        3.2193e-04, 2.7471e-04, 2.7425e-04, 5.3820e-06, 5.3609e-06, 1.7785e-04,\n",
      "        1.7740e-04, 4.7292e-01, 4.6964e-01, 1.8306e+00, 1.8339e+00, 5.2255e-06,\n",
      "        1.7415e-04, 4.4774e-01, 1.8559e+00, 3.9922e-01, 1.9051e+00, 5.1533e-01,\n",
      "        9.2573e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([165.7037, 199.1525, 212.9093, 214.4621,   8.0995,   8.0991,   8.1001,\n",
      "        318.9604, 318.9604, 318.9604,   8.1002,   8.0997, 318.9604, 318.9604,\n",
      "        318.9604, 318.9604, 318.9604,  50.7691,  50.7691,   8.1004, 318.9604,\n",
      "        318.9604, 318.9604, 318.9604, 318.9604,  50.7691,  50.7691, 318.9604,\n",
      "         50.7691,  50.7691,   5.2026, 318.9604, 318.9604, 318.9604, 318.9604,\n",
      "        318.9604,  50.7691,  50.7691, 318.9604,  50.7691,  50.7691,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 318.9604,   5.2026,   5.2025, 318.9604,   5.2026,\n",
      "          5.2025, 318.9604,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        318.9604, 318.9604, 318.9604, 318.9604,  50.7691,  50.7691,  50.7691,\n",
      "         50.7691, 318.9604, 318.9604, 318.9604,  50.7691,  50.7691,  50.7691,\n",
      "         50.7691,   5.2026,  50.7691,  50.7691,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 468 was 92.5%\n",
      "tensor([1.0415e-07, 4.0627e-06, 3.3444e-06, 3.1145e-06, 3.0902e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8232e-06, 5.6850e-06, 5.6648e-06,\n",
      "        3.1855e-04, 2.7192e-04, 2.7140e-04, 5.3696e-06, 5.3507e-06, 1.7596e-04,\n",
      "        1.7560e-04, 4.7183e-01, 4.6864e-01, 1.8269e+00, 1.8301e+00, 5.2147e-06,\n",
      "        1.7233e-04, 4.4683e-01, 1.8521e+00, 3.9850e-01, 1.9010e+00, 5.1426e-01,\n",
      "        9.2589e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([165.9785, 199.4585, 213.2094, 214.7206,   8.0979,   8.0986,   8.0981,\n",
      "        319.3826, 319.3826, 319.3826,   8.0979,   8.0986, 319.3826, 319.3826,\n",
      "        319.3826, 319.3826, 319.3826,  50.8483,  50.8483,   8.0974, 319.3826,\n",
      "        319.3826, 319.3826, 319.3826, 319.3826,  50.8483,  50.8483, 319.3826,\n",
      "         50.8483,  50.8483,   5.2026, 319.3826, 319.3826, 319.3826, 319.3826,\n",
      "        319.3826,  50.8483,  50.8483, 319.3826,  50.8483,  50.8483,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 319.3826,   5.2026,   5.2025, 319.3826,   5.2026,\n",
      "          5.2025, 319.3826,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        319.3826, 319.3826, 319.3826, 319.3826,  50.8483,  50.8483,  50.8483,\n",
      "         50.8483, 319.3826, 319.3826, 319.3826,  50.8483,  50.8483,  50.8483,\n",
      "         50.8483,   5.2026,  50.8483,  50.8483,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 469 was 92.6%\n",
      "tensor([1.0316e-07, 4.0548e-06, 3.3383e-06, 3.1092e-06, 3.0856e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8105e-06, 5.6715e-06, 5.6534e-06,\n",
      "        3.1531e-04, 2.6909e-04, 2.6866e-04, 5.3588e-06, 5.3390e-06, 1.7413e-04,\n",
      "        1.7372e-04, 4.7078e-01, 4.6769e-01, 1.8232e+00, 1.8263e+00, 5.2051e-06,\n",
      "        1.7055e-04, 4.4593e-01, 1.8482e+00, 3.9771e-01, 1.8970e+00, 5.1318e-01,\n",
      "        9.2604e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([166.2532, 199.7641, 213.5093, 214.9792,   8.0963,   8.0962,   8.0963,\n",
      "        319.8047, 319.8047, 319.8047,   8.0969,   8.0954, 319.8047, 319.8047,\n",
      "        319.8047, 319.8047, 319.8047,  50.9275,  50.9275,   8.0967, 319.8047,\n",
      "        319.8047, 319.8047, 319.8047, 319.8047,  50.9275,  50.9275, 319.8047,\n",
      "         50.9275,  50.9275,   5.2026, 319.8047, 319.8047, 319.8047, 319.8047,\n",
      "        319.8047,  50.9275,  50.9275, 319.8047,  50.9275,  50.9275,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 319.8047,   5.2026,   5.2025, 319.8047,   5.2026,\n",
      "          5.2025, 319.8047,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        319.8047, 319.8047, 319.8047, 319.8047,  50.9275,  50.9275,  50.9275,\n",
      "         50.9275, 319.8047, 319.8047, 319.8047,  50.9275,  50.9275,  50.9275,\n",
      "         50.9275,   5.2026,  50.9275,  50.9275,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 470 was 92.6%\n",
      "tensor([1.0218e-07, 4.0467e-06, 3.3321e-06, 3.1039e-06, 3.0810e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7971e-06, 5.6600e-06, 5.6412e-06,\n",
      "        3.1200e-04, 2.6638e-04, 2.6589e-04, 5.3468e-06, 5.3292e-06, 1.7228e-04,\n",
      "        1.7194e-04, 4.6972e-01, 4.6667e-01, 1.8195e+00, 1.8225e+00, 5.1941e-06,\n",
      "        1.6877e-04, 4.4504e-01, 1.8443e+00, 3.9698e-01, 1.8930e+00, 5.1212e-01,\n",
      "        9.2619e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([166.5278, 200.0696, 213.8089, 215.2379,   8.0938,   8.0956,   8.0948,\n",
      "        320.2268, 320.2268, 320.2268,   8.0937,   8.0948, 320.2268, 320.2268,\n",
      "        320.2268, 320.2268, 320.2268,  51.0067,  51.0067,   8.0944, 320.2268,\n",
      "        320.2268, 320.2268, 320.2268, 320.2268,  51.0067,  51.0067, 320.2268,\n",
      "         51.0067,  51.0067,   5.2026, 320.2268, 320.2268, 320.2268, 320.2268,\n",
      "        320.2268,  51.0067,  51.0067, 320.2268,  51.0067,  51.0067,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 320.2268,   5.2026,   5.2025, 320.2268,   5.2026,\n",
      "          5.2025, 320.2268,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        320.2268, 320.2268, 320.2268, 320.2268,  51.0067,  51.0067,  51.0067,\n",
      "         51.0067, 320.2268, 320.2268, 320.2268,  51.0067,  51.0067,  51.0067,\n",
      "         51.0067,   5.2026,  51.0067,  51.0067,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 471 was 92.6%\n",
      "tensor([1.0122e-07, 4.0390e-06, 3.3260e-06, 3.0987e-06, 3.0765e-06, 9.9262e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7851e-06, 5.6466e-06, 5.6300e-06,\n",
      "        3.0881e-04, 2.6359e-04, 2.6323e-04, 5.3365e-06, 5.3176e-06, 1.7048e-04,\n",
      "        1.7009e-04, 4.6864e-01, 4.6573e-01, 1.8158e+00, 1.8188e+00, 5.1845e-06,\n",
      "        1.6704e-04, 4.4420e-01, 1.8405e+00, 3.9619e-01, 1.8891e+00, 5.1107e-01,\n",
      "        9.2634e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([166.8023, 200.3747, 214.1083, 215.4967,   8.0922,   8.0923,   8.0925,\n",
      "        320.6489, 320.6489, 320.6489,   8.0930,   8.0929, 320.6489, 320.6489,\n",
      "        320.6489, 320.6489, 320.6489,  51.0859,  51.0859,   8.0934, 320.6489,\n",
      "        320.6489, 320.6489, 320.6489, 320.6489,  51.0859,  51.0859, 320.6489,\n",
      "         51.0859,  51.0859,   5.2026, 320.6489, 320.6489, 320.6489, 320.6489,\n",
      "        320.6489,  51.0859,  51.0859, 320.6489,  51.0859,  51.0859,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 320.6489,   5.2026,   5.2025, 320.6489,   5.2026,\n",
      "          5.2025, 320.6489,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        320.6489, 320.6489, 320.6489, 320.6489,  51.0859,  51.0859,  51.0859,\n",
      "         51.0859, 320.6489, 320.6489, 320.6489,  51.0859,  51.0859,  51.0859,\n",
      "         51.0859,   5.2026,  51.0859,  51.0859,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 472 was 92.6%\n",
      "tensor([0.0000e+00, 4.0086e-06, 3.2996e-06, 3.0729e-06, 3.0513e-06, 1.7146e-08,\n",
      "        1.2211e-08, 1.1179e-08, 1.1143e-08, 5.7715e-06, 5.6354e-06, 5.6181e-06,\n",
      "        3.0550e-04, 2.6087e-04, 2.6044e-04, 5.3241e-06, 5.3071e-06, 1.6865e-04,\n",
      "        1.6833e-04, 4.6755e-01, 4.6474e-01, 1.8122e+00, 1.8150e+00, 5.1735e-06,\n",
      "        1.6526e-04, 4.4328e-01, 1.8366e+00, 3.9549e-01, 1.8850e+00, 5.1000e-01,\n",
      "        9.2650e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([167.0766, 200.6797, 214.4074, 215.7556,   8.0910,   8.0913,   8.0910,\n",
      "        321.0709, 321.0709, 321.0709,   8.0907,   8.0914, 321.0709, 321.0709,\n",
      "        321.0709, 321.0709, 321.0709,  51.1651,  51.1651,   8.0903, 321.0709,\n",
      "        321.0709, 321.0709, 321.0709, 321.0709,  51.1651,  51.1651, 321.0709,\n",
      "         51.1651,  51.1651,   5.2026, 321.0709, 321.0709, 321.0709, 321.0709,\n",
      "        321.0709,  51.1651,  51.1651, 321.0709,  51.1651,  51.1651,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 321.0709,   5.2026,   5.2025, 321.0709,   5.2026,\n",
      "          5.2025, 321.0709,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        321.0709, 321.0709, 321.0709, 321.0709,  51.1651,  51.1651,  51.1651,\n",
      "         51.1651, 321.0709, 321.0709, 321.0709,  51.1651,  51.1651,  51.1651,\n",
      "         51.1651,   5.2026,  51.1651,  51.1651,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 473 was 92.6%\n",
      "tensor([6.6174e-23, 4.0010e-06, 3.2938e-06, 3.0678e-06, 3.0469e-06, 1.7015e-08,\n",
      "        1.2116e-08, 1.1093e-08, 1.1058e-08, 5.7588e-06, 5.6224e-06, 5.6064e-06,\n",
      "        3.0239e-04, 2.5816e-04, 2.5780e-04, 5.3133e-06, 5.2960e-06, 1.6687e-04,\n",
      "        1.6653e-04, 4.6652e-01, 4.6381e-01, 1.8085e+00, 1.8112e+00, 5.1640e-06,\n",
      "        1.6354e-04, 4.4238e-01, 1.8328e+00, 3.9471e-01, 1.8811e+00, 5.0893e-01,\n",
      "        9.2665e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([167.3508, 200.9843, 214.7062, 216.0147,   8.0885,   8.0889,   8.0900,\n",
      "        321.4930, 321.4930, 321.4930,   8.0896,   8.0882, 321.4930, 321.4930,\n",
      "        321.4930, 321.4930, 321.4930,  51.2443,  51.2443,   8.0896, 321.4930,\n",
      "        321.4930, 321.4930, 321.4930, 321.4930,  51.2443,  51.2443, 321.4930,\n",
      "         51.2443,  51.2443,   5.2026, 321.4930, 321.4930, 321.4930, 321.4930,\n",
      "        321.4930,  51.2443,  51.2443, 321.4930,  51.2443,  51.2443,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 321.4930,   5.2026,   5.2025, 321.4930,   5.2026,\n",
      "          5.2025, 321.4930,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        321.4930, 321.4930, 321.4930, 321.4930,  51.2443,  51.2443,  51.2443,\n",
      "         51.2443, 321.4930, 321.4930, 321.4930,  51.2443,  51.2443,  51.2443,\n",
      "         51.2443,   5.2026,  51.2443,  51.2443,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 474 was 92.6%\n",
      "tensor([1.3235e-22, 3.9934e-06, 3.2879e-06, 3.0629e-06, 3.0427e-06, 1.6884e-08,\n",
      "        1.2021e-08, 1.1008e-08, 1.0974e-08, 5.7465e-06, 5.6113e-06, 5.5939e-06,\n",
      "        2.9923e-04, 2.5557e-04, 2.5512e-04, 5.3014e-06, 5.2867e-06, 1.6507e-04,\n",
      "        1.6482e-04, 4.6545e-01, 4.6282e-01, 1.8049e+00, 1.8075e+00, 5.1537e-06,\n",
      "        1.6185e-04, 4.4155e-01, 1.8290e+00, 3.9397e-01, 1.8772e+00, 5.0790e-01,\n",
      "        9.2680e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([167.6249, 201.2887, 215.0048, 216.2738,   8.0869,   8.0878,   8.0867,\n",
      "        321.9150, 321.9150, 321.9150,   8.0873,   8.0875, 321.9150, 321.9150,\n",
      "        321.9150, 321.9150, 321.9150,  51.3235,  51.3235,   8.0877, 321.9150,\n",
      "        321.9150, 321.9150, 321.9150, 321.9150,  51.3235,  51.3235, 321.9150,\n",
      "         51.3235,  51.3235,   5.2026, 321.9150, 321.9150, 321.9150, 321.9150,\n",
      "        321.9150,  51.3235,  51.3235, 321.9150,  51.3235,  51.3235,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 321.9150,   5.2026,   5.2025, 321.9150,   5.2026,\n",
      "          5.2025, 321.9150,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        321.9150, 321.9150, 321.9150, 321.9150,  51.3235,  51.3235,  51.3235,\n",
      "         51.3235, 321.9150, 321.9150, 321.9150,  51.3235,  51.3235,  51.3235,\n",
      "         51.3235,   5.2026,  51.3235,  51.3235,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 475 was 92.6%\n",
      "tensor([2.6470e-23, 3.9856e-06, 3.2820e-06, 3.0579e-06, 3.0382e-06, 1.6752e-08,\n",
      "        1.1927e-08, 1.0921e-08, 1.0889e-08, 5.7334e-06, 5.5982e-06, 5.5834e-06,\n",
      "        2.9608e-04, 2.5285e-04, 2.5252e-04, 5.2909e-06, 5.2746e-06, 1.6335e-04,\n",
      "        1.6304e-04, 4.6442e-01, 4.6184e-01, 1.8012e+00, 1.8038e+00, 5.1433e-06,\n",
      "        1.6013e-04, 4.4065e-01, 1.8252e+00, 3.9323e-01, 1.8732e+00, 5.0683e-01,\n",
      "        9.2695e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([167.8989, 201.5929, 215.3032, 216.5330,   8.0852,   8.0845,   8.0861,\n",
      "        322.3370, 322.3370, 322.3370,   8.0862,   8.0856, 322.3370, 322.3370,\n",
      "        322.3370, 322.3370, 322.3370,  51.4026,  51.4026,   8.0854, 322.3370,\n",
      "        322.3370, 322.3370, 322.3370, 322.3370,  51.4026,  51.4026, 322.3370,\n",
      "         51.4026,  51.4026,   5.2026, 322.3370, 322.3370, 322.3370, 322.3370,\n",
      "        322.3370,  51.4026,  51.4026, 322.3370,  51.4026,  51.4026,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 322.3370,   5.2026,   5.2025, 322.3370,   5.2026,\n",
      "          5.2025, 322.3370,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        322.3370, 322.3370, 322.3370, 322.3370,  51.4026,  51.4026,  51.4026,\n",
      "         51.4026, 322.3370, 322.3370, 322.3370,  51.4026,  51.4026,  51.4026,\n",
      "         51.4026,   5.2026,  51.4026,  51.4026,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 476 was 92.7%\n",
      "tensor([0.0000e+00, 3.9780e-06, 3.2763e-06, 3.0528e-06, 3.0340e-06, 1.6623e-08,\n",
      "        1.1834e-08, 1.0837e-08, 1.0806e-08, 5.7210e-06, 5.5872e-06, 5.5709e-06,\n",
      "        2.9303e-04, 2.5028e-04, 2.4987e-04, 5.2788e-06, 5.2648e-06, 1.6159e-04,\n",
      "        1.6136e-04, 4.6336e-01, 4.6092e-01, 1.7976e+00, 1.8001e+00, 5.1336e-06,\n",
      "        1.5847e-04, 4.3976e-01, 1.8214e+00, 3.9249e-01, 1.8693e+00, 5.0579e-01,\n",
      "        9.2710e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([168.1728, 201.8969, 215.6012, 216.7924,   8.0835,   8.0839,   8.0837,\n",
      "        322.7590, 322.7590, 322.7590,   8.0830,   8.0837, 322.7590, 322.7590,\n",
      "        322.7590, 322.7590, 322.7590,  51.4818,  51.4818,   8.0844, 322.7590,\n",
      "        322.7590, 322.7590, 322.7590, 322.7590,  51.4818,  51.4818, 322.7590,\n",
      "         51.4818,  51.4818,   5.2026, 322.7590, 322.7590, 322.7590, 322.7590,\n",
      "        322.7590,  51.4818,  51.4818, 322.7590,  51.4818,  51.4818,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 322.7590,   5.2026,   5.2025, 322.7590,   5.2026,\n",
      "          5.2025, 322.7590,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        322.7590, 322.7590, 322.7590, 322.7590,  51.4818,  51.4818,  51.4818,\n",
      "         51.4818, 322.7590, 322.7590, 322.7590,  51.4818,  51.4818,  51.4818,\n",
      "         51.4818,   5.2026,  51.4818,  51.4818,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 477 was 92.7%\n",
      "tensor([0.0000e+00, 3.9703e-06, 3.2704e-06, 3.0479e-06, 3.0296e-06, 1.6494e-08,\n",
      "        1.1740e-08, 1.0752e-08, 1.0723e-08, 5.7076e-06, 5.5741e-06, 5.5599e-06,\n",
      "        2.8992e-04, 2.4766e-04, 2.4736e-04, 5.2688e-06, 5.2538e-06, 1.5989e-04,\n",
      "        1.5962e-04, 4.6230e-01, 4.5993e-01, 1.7940e+00, 1.7964e+00, 5.1228e-06,\n",
      "        1.5678e-04, 4.3891e-01, 1.8176e+00, 3.9174e-01, 1.8654e+00, 5.0474e-01,\n",
      "        9.2725e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([168.4466, 202.2006, 215.8991, 217.0518,   8.0819,   8.0814,   8.0826,\n",
      "        323.1809, 323.1809, 323.1809,   8.0823,   8.0818, 323.1809, 323.1809,\n",
      "        323.1809, 323.1809, 323.1809,  51.5610,  51.5610,   8.0812, 323.1809,\n",
      "        323.1809, 323.1809, 323.1809, 323.1809,  51.5610,  51.5610, 323.1809,\n",
      "         51.5610,  51.5610,   5.2026, 323.1809, 323.1809, 323.1809, 323.1809,\n",
      "        323.1809,  51.5610,  51.5610, 323.1809,  51.5610,  51.5610,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 323.1809,   5.2026,   5.2025, 323.1809,   5.2026,\n",
      "          5.2025, 323.1809,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        323.1809, 323.1809, 323.1809, 323.1809,  51.5610,  51.5610,  51.5610,\n",
      "         51.5610, 323.1809, 323.1809, 323.1809,  51.5610,  51.5610,  51.5610,\n",
      "         51.5610,   5.2026,  51.5610,  51.5610,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 478 was 92.7%\n",
      "tensor([2.6470e-23, 3.9628e-06, 3.2647e-06, 3.0428e-06, 3.0253e-06, 1.6366e-08,\n",
      "        1.1648e-08, 1.0668e-08, 1.0640e-08, 5.6956e-06, 5.5627e-06, 5.5476e-06,\n",
      "        2.8695e-04, 2.4512e-04, 2.4475e-04, 5.2567e-06, 5.2436e-06, 1.5816e-04,\n",
      "        1.5795e-04, 4.6128e-01, 4.5902e-01, 1.7904e+00, 1.7927e+00, 5.1136e-06,\n",
      "        1.5515e-04, 4.3801e-01, 1.8138e+00, 3.9099e-01, 1.8615e+00, 5.0370e-01,\n",
      "        9.2740e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([168.7202, 202.5040, 216.1966, 217.3114,   8.0793,   8.0804,   8.0793,\n",
      "        323.6029, 323.6029, 323.6029,   8.0800,   8.0807, 323.6029, 323.6029,\n",
      "        323.6029, 323.6029, 323.6029,  51.6402,  51.6402,   8.0805, 323.6029,\n",
      "        323.6029, 323.6029, 323.6029, 323.6029,  51.6402,  51.6402, 323.6029,\n",
      "         51.6402,  51.6402,   5.2026, 323.6029, 323.6029, 323.6029, 323.6029,\n",
      "        323.6029,  51.6402,  51.6402, 323.6029,  51.6402,  51.6402,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 323.6029,   5.2026,   5.2025, 323.6029,   5.2026,\n",
      "          5.2025, 323.6029,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        323.6029, 323.6029, 323.6029, 323.6029,  51.6402,  51.6402,  51.6402,\n",
      "         51.6402, 323.6029, 323.6029, 323.6029,  51.6402,  51.6402,  51.6402,\n",
      "         51.6402,   5.2026,  51.6402,  51.6402,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 479 was 92.7%\n",
      "tensor([0.0000e+00, 3.9552e-06, 3.2590e-06, 3.0380e-06, 3.0210e-06, 1.6237e-08,\n",
      "        1.1555e-08, 1.0584e-08, 1.0558e-08, 5.6832e-06, 5.5498e-06, 5.5375e-06,\n",
      "        2.8391e-04, 2.4250e-04, 2.4226e-04, 5.2465e-06, 5.2320e-06, 1.5651e-04,\n",
      "        1.5624e-04, 4.6024e-01, 4.5803e-01, 1.7868e+00, 1.7890e+00, 5.1031e-06,\n",
      "        1.5351e-04, 4.3716e-01, 1.8100e+00, 3.9029e-01, 1.8576e+00, 5.0266e-01,\n",
      "        9.2755e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([168.9938, 202.8073, 216.4940, 217.5711,   8.0780,   8.0784,   8.0782,\n",
      "        324.0248, 324.0248, 324.0248,   8.0789,   8.0774, 324.0248, 324.0248,\n",
      "        324.0248, 324.0248, 324.0248,  51.7194,  51.7194,   8.0782, 324.0248,\n",
      "        324.0248, 324.0248, 324.0248, 324.0248,  51.7194,  51.7194, 324.0248,\n",
      "         51.7194,  51.7194,   5.2026, 324.0248, 324.0248, 324.0248, 324.0248,\n",
      "        324.0248,  51.7194,  51.7194, 324.0248,  51.7194,  51.7194,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 324.0248,   5.2026,   5.2025, 324.0248,   5.2026,\n",
      "          5.2025, 324.0248,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        324.0248, 324.0248, 324.0248, 324.0248,  51.7194,  51.7194,  51.7194,\n",
      "         51.7194, 324.0248, 324.0248, 324.0248,  51.7194,  51.7194,  51.7194,\n",
      "         51.7194,   5.2026,  51.7194,  51.7194,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 480 was 92.7%\n",
      "tensor([1.3235e-23, 3.9477e-06, 3.2532e-06, 3.0330e-06, 3.0165e-06, 1.6112e-08,\n",
      "        1.1464e-08, 1.0502e-08, 1.0476e-08, 5.6703e-06, 5.5382e-06, 5.5249e-06,\n",
      "        2.8094e-04, 2.4004e-04, 2.3972e-04, 5.2348e-06, 5.2225e-06, 1.5481e-04,\n",
      "        1.5459e-04, 4.5924e-01, 4.5706e-01, 1.7831e+00, 1.7853e+00, 5.0931e-06,\n",
      "        1.5189e-04, 4.3627e-01, 1.8063e+00, 3.8953e-01, 1.8537e+00, 5.0162e-01,\n",
      "        9.2770e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([169.2672, 203.1103, 216.7911, 217.8308,   8.0764,   8.0760,   8.0763,\n",
      "        324.4467, 324.4467, 324.4467,   8.0756,   8.0768, 324.4467, 324.4467,\n",
      "        324.4467, 324.4467, 324.4467,  51.7986,  51.7986,   8.0771, 324.4467,\n",
      "        324.4467, 324.4467, 324.4467, 324.4467,  51.7986,  51.7986, 324.4467,\n",
      "         51.7986,  51.7986,   5.2026, 324.4467, 324.4467, 324.4467, 324.4467,\n",
      "        324.4467,  51.7986,  51.7986, 324.4467,  51.7986,  51.7986,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 324.4467,   5.2026,   5.2025, 324.4467,   5.2026,\n",
      "          5.2025, 324.4467,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        324.4467, 324.4467, 324.4467, 324.4467,  51.7986,  51.7986,  51.7986,\n",
      "         51.7986, 324.4467, 324.4467, 324.4467,  51.7986,  51.7986,  51.7986,\n",
      "         51.7986,   5.2026,  51.7986,  51.7986,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 481 was 92.7%\n",
      "tensor([0.0000e+00, 3.9401e-06, 3.2475e-06, 3.0281e-06, 3.0124e-06, 1.5985e-08,\n",
      "        1.1373e-08, 1.0419e-08, 1.0394e-08, 5.6573e-06, 5.5264e-06, 5.5142e-06,\n",
      "        2.7796e-04, 2.3752e-04, 2.3727e-04, 5.2246e-06, 5.2116e-06, 1.5317e-04,\n",
      "        1.5295e-04, 4.5815e-01, 4.5615e-01, 1.7796e+00, 1.7816e+00, 5.0827e-06,\n",
      "        1.5026e-04, 4.3543e-01, 1.8025e+00, 3.8881e-01, 1.8498e+00, 5.0059e-01,\n",
      "        9.2785e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([169.5405, 203.4130, 217.0879, 218.0908,   8.0737,   8.0750,   8.0752,\n",
      "        324.8686, 324.8686, 324.8686,   8.0749,   8.0743, 324.8686, 324.8686,\n",
      "        324.8686, 324.8686, 324.8686,  51.8778,  51.8778,   8.0739, 324.8686,\n",
      "        324.8686, 324.8686, 324.8686, 324.8686,  51.8778,  51.8778, 324.8686,\n",
      "         51.8778,  51.8778,   5.2026, 324.8686, 324.8686, 324.8686, 324.8686,\n",
      "        324.8686,  51.8778,  51.8778, 324.8686,  51.8778,  51.8778,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 324.8686,   5.2026,   5.2025, 324.8686,   5.2026,\n",
      "          5.2025, 324.8686,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        324.8686, 324.8686, 324.8686, 324.8686,  51.8778,  51.8778,  51.8778,\n",
      "         51.8778, 324.8686, 324.8686, 324.8686,  51.8778,  51.8778,  51.8778,\n",
      "         51.8778,   5.2026,  51.8778,  51.8778,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 482 was 92.7%\n",
      "tensor([0.0000e+00, 3.9328e-06, 3.2419e-06, 3.0232e-06, 3.0081e-06, 1.5860e-08,\n",
      "        1.1282e-08, 1.0337e-08, 1.0313e-08, 5.6461e-06, 5.5144e-06, 5.5020e-06,\n",
      "        2.7509e-04, 2.3505e-04, 2.3476e-04, 5.2128e-06, 5.2014e-06, 1.5150e-04,\n",
      "        1.5131e-04, 4.5717e-01, 4.5521e-01, 1.7760e+00, 1.7780e+00, 5.0737e-06,\n",
      "        1.4870e-04, 4.3457e-01, 1.7988e+00, 3.8804e-01, 1.8460e+00, 4.9956e-01,\n",
      "        9.2800e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([169.8137, 203.7156, 217.3845, 218.3507,   8.0724,   8.0726,   8.0718,\n",
      "        325.2905, 325.2905, 325.2905,   8.0730,   8.0728, 325.2905, 325.2905,\n",
      "        325.2905, 325.2905, 325.2905,  51.9569,  51.9569,   8.0732, 325.2905,\n",
      "        325.2905, 325.2905, 325.2905, 325.2905,  51.9569,  51.9569, 325.2905,\n",
      "         51.9569,  51.9569,   5.2026, 325.2905, 325.2905, 325.2905, 325.2905,\n",
      "        325.2905,  51.9569,  51.9569, 325.2905,  51.9569,  51.9569,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 325.2905,   5.2026,   5.2025, 325.2905,   5.2026,\n",
      "          5.2025, 325.2905,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        325.2905, 325.2905, 325.2905, 325.2905,  51.9569,  51.9569,  51.9569,\n",
      "         51.9569, 325.2905, 325.2905, 325.2905,  51.9569,  51.9569,  51.9569,\n",
      "         51.9569,   5.2026,  51.9569,  51.9569,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 483 was 92.8%\n",
      "tensor([0.0000e+00, 3.9252e-06, 3.2361e-06, 3.0183e-06, 3.0037e-06, 1.5734e-08,\n",
      "        1.1192e-08, 1.0255e-08, 1.0232e-08, 5.6328e-06, 5.5026e-06, 5.4915e-06,\n",
      "        2.7214e-04, 2.3257e-04, 2.3233e-04, 5.2021e-06, 5.1905e-06, 1.4990e-04,\n",
      "        1.4969e-04, 4.5614e-01, 4.5424e-01, 1.7724e+00, 1.7744e+00, 5.0628e-06,\n",
      "        1.4710e-04, 4.3369e-01, 1.7951e+00, 3.8735e-01, 1.8421e+00, 4.9852e-01,\n",
      "        9.2815e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([170.0869, 204.0179, 217.6809, 218.6108,   8.0706,   8.0710,   8.0712,\n",
      "        325.7124, 325.7124, 325.7124,   8.0705,   8.0713, 325.7124, 325.7124,\n",
      "        325.7124, 325.7124, 325.7124,  52.0361,  52.0361,   8.0700, 325.7124,\n",
      "        325.7124, 325.7124, 325.7124, 325.7124,  52.0361,  52.0361, 325.7124,\n",
      "         52.0361,  52.0361,   5.2026, 325.7124, 325.7124, 325.7124, 325.7124,\n",
      "        325.7124,  52.0361,  52.0361, 325.7124,  52.0361,  52.0361,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 325.7124,   5.2026,   5.2025, 325.7124,   5.2026,\n",
      "          5.2025, 325.7124,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        325.7124, 325.7124, 325.7124, 325.7124,  52.0361,  52.0361,  52.0361,\n",
      "         52.0361, 325.7124, 325.7124, 325.7124,  52.0361,  52.0361,  52.0361,\n",
      "         52.0361,   5.2026,  52.0361,  52.0361,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 484 was 92.8%\n",
      "tensor([8.9314e-08, 3.9379e-06, 3.2488e-06, 3.0317e-06, 3.0179e-06, 1.3235e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6207e-06, 5.4903e-06, 5.4796e-06,\n",
      "        2.6932e-04, 2.3012e-04, 2.2991e-04, 5.1913e-06, 5.1799e-06, 1.4826e-04,\n",
      "        1.4807e-04, 4.5511e-01, 4.5335e-01, 1.7689e+00, 1.7707e+00, 5.0537e-06,\n",
      "        1.4554e-04, 4.3283e-01, 1.7914e+00, 3.8658e-01, 1.8383e+00, 4.9750e-01,\n",
      "        9.2830e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([170.3599, 204.3200, 217.9770, 218.8711,   8.0689,   8.0690,   8.0688,\n",
      "        326.1342, 326.1342, 326.1342,   8.0695,   8.0680, 326.1342, 326.1342,\n",
      "        326.1342, 326.1342, 326.1342,  52.1153,  52.1153,   8.0693, 326.1342,\n",
      "        326.1342, 326.1342, 326.1342, 326.1342,  52.1153,  52.1153, 326.1342,\n",
      "         52.1153,  52.1153,   5.2026, 326.1342, 326.1342, 326.1342, 326.1342,\n",
      "        326.1342,  52.1153,  52.1153, 326.1342,  52.1153,  52.1153,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 326.1342,   5.2026,   5.2025, 326.1342,   5.2026,\n",
      "          5.2025, 326.1342,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        326.1342, 326.1342, 326.1342, 326.1342,  52.1153,  52.1153,  52.1153,\n",
      "         52.1153, 326.1342, 326.1342, 326.1342,  52.1153,  52.1153,  52.1153,\n",
      "         52.1153,   5.2026,  52.1153,  52.1153,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 485 was 92.8%\n",
      "tensor([8.8455e-08, 3.9302e-06, 3.2430e-06, 3.0268e-06, 3.0134e-06, 3.3087e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6080e-06, 5.4791e-06, 5.4682e-06,\n",
      "        2.6645e-04, 2.2775e-04, 2.2750e-04, 5.1802e-06, 5.1703e-06, 1.4667e-04,\n",
      "        1.4650e-04, 4.5413e-01, 4.5235e-01, 1.7653e+00, 1.7671e+00, 5.0431e-06,\n",
      "        1.4398e-04, 4.3198e-01, 1.7877e+00, 3.8587e-01, 1.8344e+00, 4.9647e-01,\n",
      "        9.2844e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([170.6328, 204.6219, 218.2729, 219.1314,   8.0667,   8.0674,   8.0677,\n",
      "        326.5561, 326.5561, 326.5561,   8.0661,   8.0673, 326.5561, 326.5561,\n",
      "        326.5561, 326.5561, 326.5561,  52.1945,  52.1945,   8.0669, 326.5561,\n",
      "        326.5561, 326.5561, 326.5561, 326.5561,  52.1945,  52.1945, 326.5561,\n",
      "         52.1945,  52.1945,   5.2026, 326.5561, 326.5561, 326.5561, 326.5561,\n",
      "        326.5561,  52.1945,  52.1945, 326.5561,  52.1945,  52.1945,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 326.5561,   5.2026,   5.2025, 326.5561,   5.2026,\n",
      "          5.2025, 326.5561,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        326.5561, 326.5561, 326.5561, 326.5561,  52.1945,  52.1945,  52.1945,\n",
      "         52.1945, 326.5561, 326.5561, 326.5561,  52.1945,  52.1945,  52.1945,\n",
      "         52.1945,   5.2026,  52.1945,  52.1945,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 486 was 92.8%\n",
      "tensor([8.7600e-08, 3.9228e-06, 3.2372e-06, 3.0217e-06, 3.0090e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5962e-06, 5.4668e-06, 5.4569e-06,\n",
      "        2.6365e-04, 2.2533e-04, 2.2513e-04, 5.1699e-06, 5.1593e-06, 1.4508e-04,\n",
      "        1.4490e-04, 4.5308e-01, 4.5147e-01, 1.7618e+00, 1.7634e+00, 5.0336e-06,\n",
      "        1.4245e-04, 4.3114e-01, 1.7840e+00, 3.8511e-01, 1.8307e+00, 4.9546e-01,\n",
      "        9.2859e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([170.9056, 204.9236, 218.5686, 219.3919,   8.0650,   8.0649,   8.0643,\n",
      "        326.9779, 326.9779, 326.9779,   8.0655,   8.0653, 326.9779, 326.9779,\n",
      "        326.9779, 326.9779, 326.9779,  52.2737,  52.2737,   8.0659, 326.9779,\n",
      "        326.9779, 326.9779, 326.9779, 326.9779,  52.2737,  52.2737, 326.9779,\n",
      "         52.2737,  52.2737,   5.2026, 326.9779, 326.9779, 326.9779, 326.9779,\n",
      "        326.9779,  52.2737,  52.2737, 326.9779,  52.2737,  52.2737,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 326.9779,   5.2026,   5.2025, 326.9779,   5.2026,\n",
      "          5.2025, 326.9779,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        326.9779, 326.9779, 326.9779, 326.9779,  52.2737,  52.2737,  52.2737,\n",
      "         52.2737, 326.9779, 326.9779, 326.9779,  52.2737,  52.2737,  52.2737,\n",
      "         52.2737,   5.2026,  52.2737,  52.2737,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 487 was 92.8%\n",
      "tensor([8.6903e-08, 3.9151e-06, 3.2311e-06, 3.0164e-06, 3.0041e-06, 6.6174e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5836e-06, 5.4557e-06, 5.4463e-06,\n",
      "        2.6137e-04, 2.2338e-04, 2.2318e-04, 5.1586e-06, 5.1490e-06, 1.4374e-04,\n",
      "        1.4358e-04, 4.5208e-01, 4.5049e-01, 1.7585e+00, 1.7601e+00, 5.0231e-06,\n",
      "        1.4110e-04, 4.3026e-01, 1.7805e+00, 3.8443e-01, 1.8269e+00, 4.9443e-01,\n",
      "        9.2873e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([171.1783, 205.2248, 218.8614, 219.6543,   8.0632,   8.0637,   8.0635,\n",
      "        327.3997, 327.3997, 327.3997,   8.0629,   8.0636, 327.3997, 327.3997,\n",
      "        327.3997, 327.3997, 327.3997,  52.3528,  52.3528,   8.0626, 327.3997,\n",
      "        327.3997, 327.3997, 327.3997, 327.3997,  52.3528,  52.3528, 327.3997,\n",
      "         52.3528,  52.3528,   5.2026, 327.3997, 327.3997, 327.3997, 327.3997,\n",
      "        327.3997,  52.3528,  52.3528, 327.3997,  52.3528,  52.3528,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 327.3997,   5.2026,   5.2025, 327.3997,   5.2026,\n",
      "          5.2025, 327.3997,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        327.3997, 327.3997, 327.3997, 327.3997,  52.3528,  52.3528,  52.3528,\n",
      "         52.3528, 327.3997, 327.3997, 327.3997,  52.3528,  52.3528,  52.3528,\n",
      "         52.3528,   5.2026,  52.3528,  52.3528,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 488 was 92.8%\n",
      "tensor([8.6066e-08, 3.9077e-06, 3.2254e-06, 3.0114e-06, 2.9997e-06, 3.3087e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5717e-06, 5.4433e-06, 5.4345e-06,\n",
      "        2.5865e-04, 2.2102e-04, 2.2086e-04, 5.1482e-06, 5.1383e-06, 1.4218e-04,\n",
      "        1.4201e-04, 4.5109e-01, 4.4959e-01, 1.7550e+00, 1.7565e+00, 5.0141e-06,\n",
      "        1.3960e-04, 4.2941e-01, 1.7768e+00, 3.8366e-01, 1.8231e+00, 4.9340e-01,\n",
      "        9.2887e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([171.4508, 205.5258, 219.1539, 219.9169,   8.0620,   8.0601,   8.0614,\n",
      "        327.8215, 327.8215, 327.8215,   8.0617,   8.0611, 327.8215, 327.8215,\n",
      "        327.8215, 327.8215, 327.8215,  52.4320,  52.4320,   8.0619, 327.8215,\n",
      "        327.8215, 327.8215, 327.8215, 327.8215,  52.4320,  52.4320, 327.8215,\n",
      "         52.4320,  52.4320,   5.2026, 327.8215, 327.8215, 327.8215, 327.8215,\n",
      "        327.8215,  52.4320,  52.4320, 327.8215,  52.4320,  52.4320,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 327.8215,   5.2026,   5.2025, 327.8215,   5.2026,\n",
      "          5.2025, 327.8215,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        327.8215, 327.8215, 327.8215, 327.8215,  52.4320,  52.4320,  52.4320,\n",
      "         52.4320, 327.8215, 327.8215, 327.8215,  52.4320,  52.4320,  52.4320,\n",
      "         52.4320,   5.2026,  52.4320,  52.4320,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 489 was 92.9%\n",
      "tensor([8.5245e-08, 3.9002e-06, 3.2198e-06, 3.0065e-06, 2.9953e-06, 5.2940e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5589e-06, 5.4332e-06, 5.4234e-06,\n",
      "        2.5589e-04, 2.1876e-04, 2.1856e-04, 5.1374e-06, 5.1289e-06, 1.4066e-04,\n",
      "        1.4053e-04, 4.5011e-01, 4.4866e-01, 1.7515e+00, 1.7530e+00, 5.0035e-06,\n",
      "        1.3811e-04, 4.2855e-01, 1.7732e+00, 3.8297e-01, 1.8193e+00, 4.9240e-01,\n",
      "        9.2902e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([171.7233, 205.8266, 219.4463, 220.1795,   8.0583,   8.0593,   8.0597,\n",
      "        328.2433, 328.2433, 328.2433,   8.0596,   8.0603, 328.2433, 328.2433,\n",
      "        328.2433, 328.2433, 328.2433,  52.5112,  52.5112,   8.0595, 328.2433,\n",
      "        328.2433, 328.2433, 328.2433, 328.2433,  52.5112,  52.5112, 328.2433,\n",
      "         52.5112,  52.5112,   5.2026, 328.2433, 328.2433, 328.2433, 328.2433,\n",
      "        328.2433,  52.5112,  52.5112, 328.2433,  52.5112,  52.5112,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 328.2433,   5.2026,   5.2025, 328.2433,   5.2026,\n",
      "          5.2025, 328.2433,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        328.2433, 328.2433, 328.2433, 328.2433,  52.5112,  52.5112,  52.5112,\n",
      "         52.5112, 328.2433, 328.2433, 328.2433,  52.5112,  52.5112,  52.5112,\n",
      "         52.5112,   5.2026,  52.5112,  52.5112,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 490 was 92.9%\n",
      "tensor([8.4420e-08, 3.8927e-06, 3.2141e-06, 3.0015e-06, 2.9908e-06, 4.9631e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5480e-06, 5.4203e-06, 5.4121e-06,\n",
      "        2.5322e-04, 2.1643e-04, 2.1627e-04, 5.1265e-06, 5.1178e-06, 1.3914e-04,\n",
      "        1.3898e-04, 4.4908e-01, 4.4774e-01, 1.7480e+00, 1.7494e+00, 4.9944e-06,\n",
      "        1.3666e-04, 4.2771e-01, 1.7695e+00, 3.8226e-01, 1.8155e+00, 4.9139e-01,\n",
      "        9.2916e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([171.9957, 206.1272, 219.7384, 220.4423,   8.0575,   8.0581,   8.0571,\n",
      "        328.6650, 328.6650, 328.6650,   8.0574,   8.0568, 328.6650, 328.6650,\n",
      "        328.6650, 328.6650, 328.6650,  52.5904,  52.5904,   8.0583, 328.6650,\n",
      "        328.6650, 328.6650, 328.6650, 328.6650,  52.5904,  52.5904, 328.6650,\n",
      "         52.5904,  52.5904,   5.2026, 328.6650, 328.6650, 328.6650, 328.6650,\n",
      "        328.6650,  52.5904,  52.5904, 328.6650,  52.5904,  52.5904,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 328.6650,   5.2026,   5.2025, 328.6650,   5.2026,\n",
      "          5.2025, 328.6650,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        328.6650, 328.6650, 328.6650, 328.6650,  52.5904,  52.5904,  52.5904,\n",
      "         52.5904, 328.6650, 328.6650, 328.6650,  52.5904,  52.5904,  52.5904,\n",
      "         52.5904,   5.2026,  52.5904,  52.5904,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 491 was 92.9%\n",
      "tensor([8.3613e-08, 3.8853e-06, 3.2083e-06, 2.9968e-06, 2.9863e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5347e-06, 5.4090e-06, 5.4012e-06,\n",
      "        2.5052e-04, 2.1419e-04, 2.1404e-04, 5.1163e-06, 5.1081e-06, 1.3765e-04,\n",
      "        1.3751e-04, 4.4813e-01, 4.4674e-01, 1.7445e+00, 1.7459e+00, 4.9840e-06,\n",
      "        1.3518e-04, 4.2690e-01, 1.7658e+00, 3.8152e-01, 1.8118e+00, 4.9039e-01,\n",
      "        9.2931e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([172.2680, 206.4276, 220.0303, 220.7052,   8.0553,   8.0554,   8.0558,\n",
      "        329.0867, 329.0867, 329.0867,   8.0562,   8.0559, 329.0867, 329.0867,\n",
      "        329.0867, 329.0867, 329.0867,  52.6696,  52.6696,   8.0550, 329.0867,\n",
      "        329.0867, 329.0867, 329.0867, 329.0867,  52.6696,  52.6696, 329.0867,\n",
      "         52.6696,  52.6696,   5.2026, 329.0867, 329.0867, 329.0867, 329.0867,\n",
      "        329.0867,  52.6696,  52.6696, 329.0867,  52.6696,  52.6696,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 329.0867,   5.2026,   5.2025, 329.0867,   5.2026,\n",
      "          5.2025, 329.0867,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        329.0867, 329.0867, 329.0867, 329.0867,  52.6696,  52.6696,  52.6696,\n",
      "         52.6696, 329.0867, 329.0867, 329.0867,  52.6696,  52.6696,  52.6696,\n",
      "         52.6696,   5.2026,  52.6696,  52.6696,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 492 was 92.9%\n",
      "tensor([0.0000e+00, 3.8594e-06, 3.1861e-06, 2.9753e-06, 2.9653e-06, 1.4763e-08,\n",
      "        1.0500e-08, 9.6304e-09, 9.6159e-09, 5.5233e-06, 5.3975e-06, 5.3892e-06,\n",
      "        2.4924e-04, 2.1325e-04, 2.1308e-04, 5.1047e-06, 5.0974e-06, 1.3726e-04,\n",
      "        1.3715e-04, 4.4711e-01, 4.4584e-01, 1.7406e+00, 1.7419e+00, 4.9749e-06,\n",
      "        1.3492e-04, 4.2598e-01, 1.7620e+00, 3.8079e-01, 1.8078e+00, 4.8936e-01,\n",
      "        9.2947e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([172.5404, 206.7283, 220.3257, 220.9654,   8.0540,   8.0538,   8.0538,\n",
      "        329.5085, 329.5085, 329.5085,   8.0528,   8.0535, 329.5085, 329.5085,\n",
      "        329.5085, 329.5085, 329.5085,  52.7487,  52.7487,   8.0543, 329.5085,\n",
      "        329.5085, 329.5085, 329.5085, 329.5085,  52.7487,  52.7487, 329.5085,\n",
      "         52.7487,  52.7487,   5.2026, 329.5085, 329.5085, 329.5085, 329.5085,\n",
      "        329.5085,  52.7487,  52.7487, 329.5085,  52.7487,  52.7487,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 329.5085,   5.2026,   5.2025, 329.5085,   5.2026,\n",
      "          5.2025, 329.5085,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        329.5085, 329.5085, 329.5085, 329.5085,  52.7487,  52.7487,  52.7487,\n",
      "         52.7487, 329.5085, 329.5085, 329.5085,  52.7487,  52.7487,  52.7487,\n",
      "         52.7487,   5.2026,  52.7487,  52.7487,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 493 was 92.9%\n",
      "tensor([6.6174e-23, 3.8522e-06, 3.1805e-06, 2.9705e-06, 2.9611e-06, 1.4647e-08,\n",
      "        1.0415e-08, 9.5540e-09, 9.5407e-09, 5.5104e-06, 5.3859e-06, 5.3787e-06,\n",
      "        2.4657e-04, 2.1103e-04, 2.1090e-04, 5.0951e-06, 5.0874e-06, 1.3580e-04,\n",
      "        1.3568e-04, 4.4611e-01, 4.4492e-01, 1.7372e+00, 1.7384e+00, 4.9642e-06,\n",
      "        1.3346e-04, 4.2518e-01, 1.7583e+00, 3.8006e-01, 1.8041e+00, 4.8835e-01,\n",
      "        9.2961e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([172.8127, 207.0288, 220.6207, 221.2258,   8.0507,   8.0518,   8.0527,\n",
      "        329.9302, 329.9302, 329.9302,   8.0521,   8.0523, 329.9302, 329.9302,\n",
      "        329.9302, 329.9302, 329.9302,  52.8279,  52.8279,   8.0509, 329.9302,\n",
      "        329.9302, 329.9302, 329.9302, 329.9302,  52.8279,  52.8279, 329.9302,\n",
      "         52.8279,  52.8279,   5.2026, 329.9302, 329.9302, 329.9302, 329.9302,\n",
      "        329.9302,  52.8279,  52.8279, 329.9302,  52.8279,  52.8279,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 329.9302,   5.2026,   5.2025, 329.9302,   5.2026,\n",
      "          5.2025, 329.9302,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        329.9302, 329.9302, 329.9302, 329.9302,  52.8279,  52.8279,  52.8279,\n",
      "         52.8279, 329.9302, 329.9302, 329.9302,  52.8279,  52.8279,  52.8279,\n",
      "         52.8279,   5.2026,  52.8279,  52.8279,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 494 was 92.9%\n",
      "tensor([1.0588e-22, 3.8450e-06, 3.1749e-06, 2.9653e-06, 2.9566e-06, 1.4560e-08,\n",
      "        1.0350e-08, 9.4932e-09, 9.4802e-09, 5.5000e-06, 5.3746e-06, 5.3671e-06,\n",
      "        2.4456e-04, 2.0921e-04, 2.0905e-04, 5.0836e-06, 5.0771e-06, 1.3452e-04,\n",
      "        1.3443e-04, 4.4512e-01, 4.4403e-01, 1.7340e+00, 1.7351e+00, 4.9559e-06,\n",
      "        1.3224e-04, 4.2433e-01, 1.7549e+00, 3.7935e-01, 1.8005e+00, 4.8736e-01,\n",
      "        9.2974e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([173.0849, 207.3289, 220.9130, 221.4881,   8.0499,   8.0501,   8.0490,\n",
      "        330.3519, 330.3519, 330.3519,   8.0500,   8.0497, 330.3519, 330.3519,\n",
      "        330.3519, 330.3519, 330.3519,  52.9071,  52.9071,   8.0502, 330.3519,\n",
      "        330.3519, 330.3519, 330.3519, 330.3519,  52.9071,  52.9071, 330.3519,\n",
      "         52.9071,  52.9071,   5.2026, 330.3519, 330.3519, 330.3519, 330.3519,\n",
      "        330.3519,  52.9071,  52.9071, 330.3519,  52.9071,  52.9071,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 330.3519,   5.2026,   5.2025, 330.3519,   5.2026,\n",
      "          5.2025, 330.3519,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        330.3519, 330.3519, 330.3519, 330.3519,  52.9071,  52.9071,  52.9071,\n",
      "         52.9071, 330.3519, 330.3519, 330.3519,  52.9071,  52.9071,  52.9071,\n",
      "         52.9071,   5.2026,  52.9071,  52.9071,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 495 was 92.9%\n",
      "tensor([0.0000e+00, 3.8377e-06, 3.1693e-06, 2.9606e-06, 2.9522e-06, 1.4444e-08,\n",
      "        1.0267e-08, 9.4173e-09, 9.4053e-09, 5.4866e-06, 5.3628e-06, 5.3567e-06,\n",
      "        2.4192e-04, 2.0700e-04, 2.0689e-04, 5.0734e-06, 5.0667e-06, 1.3309e-04,\n",
      "        1.3298e-04, 4.4416e-01, 4.4306e-01, 1.7305e+00, 1.7316e+00, 4.9451e-06,\n",
      "        1.3081e-04, 4.2348e-01, 1.7513e+00, 3.7864e-01, 1.7967e+00, 4.8634e-01,\n",
      "        9.2989e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([173.3570, 207.6288, 221.2052, 221.7505,   8.0481,   8.0473,   8.0482,\n",
      "        330.7736, 330.7736, 330.7736,   8.0482,   8.0485, 330.7736, 330.7736,\n",
      "        330.7736, 330.7736, 330.7736,  52.9863,  52.9863,   8.0468, 330.7736,\n",
      "        330.7736, 330.7736, 330.7736, 330.7736,  52.9863,  52.9863, 330.7736,\n",
      "         52.9863,  52.9863,   5.2026, 330.7736, 330.7736, 330.7736, 330.7736,\n",
      "        330.7736,  52.9863,  52.9863, 330.7736,  52.9863,  52.9863,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 330.7736,   5.2026,   5.2025, 330.7736,   5.2026,\n",
      "          5.2025, 330.7736,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        330.7736, 330.7736, 330.7736, 330.7736,  52.9863,  52.9863,  52.9863,\n",
      "         52.9863, 330.7736, 330.7736, 330.7736,  52.9863,  52.9863,  52.9863,\n",
      "         52.9863,   5.2026,  52.9863,  52.9863,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 496 was 93.0%\n",
      "tensor([5.2940e-23, 3.8306e-06, 3.1640e-06, 2.9559e-06, 2.9480e-06, 1.4330e-08,\n",
      "        1.0184e-08, 9.3423e-09, 9.3312e-09, 5.4752e-06, 5.3518e-06, 5.3449e-06,\n",
      "        2.3941e-04, 2.0484e-04, 2.0473e-04, 5.0628e-06, 5.0566e-06, 1.3164e-04,\n",
      "        1.3156e-04, 4.4318e-01, 4.4219e-01, 1.7270e+00, 1.7280e+00, 4.9363e-06,\n",
      "        1.2943e-04, 4.2261e-01, 1.7477e+00, 3.7792e-01, 1.7930e+00, 4.8535e-01,\n",
      "        9.3003e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([173.6290, 207.9285, 221.4971, 222.0130,   8.0468,   8.0461,   8.0455,\n",
      "        331.1952, 331.1952, 331.1952,   8.0461,   8.0449, 331.1952, 331.1952,\n",
      "        331.1952, 331.1952, 331.1952,  53.0654,  53.0654,   8.0461, 331.1952,\n",
      "        331.1952, 331.1952, 331.1952, 331.1952,  53.0654,  53.0654, 331.1952,\n",
      "         53.0654,  53.0654,   5.2026, 331.1952, 331.1952, 331.1952, 331.1952,\n",
      "        331.1952,  53.0654,  53.0654, 331.1952,  53.0654,  53.0654,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 331.1952,   5.2026,   5.2025, 331.1952,   5.2026,\n",
      "          5.2025, 331.1952,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        331.1952, 331.1952, 331.1952, 331.1952,  53.0654,  53.0654,  53.0654,\n",
      "         53.0654, 331.1952, 331.1952, 331.1952,  53.0654,  53.0654,  53.0654,\n",
      "         53.0654,   5.2026,  53.0654,  53.0654,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 497 was 93.0%\n",
      "tensor([3.9705e-23, 3.8235e-06, 3.1585e-06, 2.9513e-06, 2.9437e-06, 1.4217e-08,\n",
      "        1.0103e-08, 9.2689e-09, 9.2582e-09, 5.4625e-06, 5.3404e-06, 5.3347e-06,\n",
      "        2.3685e-04, 2.0274e-04, 2.0262e-04, 5.0526e-06, 5.0473e-06, 1.3025e-04,\n",
      "        1.3017e-04, 4.4225e-01, 4.4125e-01, 1.7236e+00, 1.7245e+00, 4.9257e-06,\n",
      "        1.2804e-04, 4.2179e-01, 1.7441e+00, 3.7719e-01, 1.7893e+00, 4.8436e-01,\n",
      "        9.3017e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([173.9010, 208.2280, 221.7888, 222.2756,   8.0431,   8.0439,   8.0443,\n",
      "        331.6169, 331.6169, 331.6169,   8.0448,   8.0440, 331.6169, 331.6169,\n",
      "        331.6169, 331.6169, 331.6169,  53.1446,  53.1446,   8.0436, 331.6169,\n",
      "        331.6169, 331.6169, 331.6169, 331.6169,  53.1446,  53.1446, 331.6169,\n",
      "         53.1446,  53.1446,   5.2026, 331.6169, 331.6169, 331.6169, 331.6169,\n",
      "        331.6169,  53.1446,  53.1446, 331.6169,  53.1446,  53.1446,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 331.6169,   5.2026,   5.2025, 331.6169,   5.2026,\n",
      "          5.2025, 331.6169,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        331.6169, 331.6169, 331.6169, 331.6169,  53.1446,  53.1446,  53.1446,\n",
      "         53.1446, 331.6169, 331.6169, 331.6169,  53.1446,  53.1446,  53.1446,\n",
      "         53.1446,   5.2026,  53.1446,  53.1446,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 498 was 93.0%\n",
      "tensor([8.1877e-08, 3.8362e-06, 3.1708e-06, 2.9644e-06, 2.9573e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4519e-06, 5.3289e-06, 5.3226e-06,\n",
      "        2.4212e-04, 2.0779e-04, 2.0766e-04, 5.0409e-06, 5.0361e-06, 1.3441e-04,\n",
      "        1.3436e-04, 4.4115e-01, 4.4022e-01, 1.7197e+00, 1.7206e+00, 4.9164e-06,\n",
      "        1.3240e-04, 4.2086e-01, 1.7401e+00, 3.7642e-01, 1.7851e+00, 4.8326e-01,\n",
      "        9.3033e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([174.1737, 208.5283, 222.0848, 222.5345,   8.0418,   8.0423,   8.0416,\n",
      "        332.0385, 332.0385, 332.0385,   8.0413,   8.0420, 332.0385, 332.0385,\n",
      "        332.0385, 332.0385, 332.0385,  53.2238,  53.2238,   8.0429, 332.0385,\n",
      "        332.0385, 332.0385, 332.0385, 332.0385,  53.2238,  53.2238, 332.0385,\n",
      "         53.2238,  53.2238,   5.2026, 332.0385, 332.0385, 332.0385, 332.0385,\n",
      "        332.0385,  53.2238,  53.2238, 332.0385,  53.2238,  53.2238,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 332.0385,   5.2026,   5.2025, 332.0385,   5.2026,\n",
      "          5.2025, 332.0385,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        332.0385, 332.0385, 332.0385, 332.0385,  53.2238,  53.2238,  53.2238,\n",
      "         53.2238, 332.0385, 332.0385, 332.0385,  53.2238,  53.2238,  53.2238,\n",
      "         53.2238,   5.2026,  53.2238,  53.2238,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 499 was 93.0%\n",
      "tensor([8.1139e-08, 3.8288e-06, 3.1651e-06, 2.9595e-06, 2.9531e-06, 1.3235e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4389e-06, 5.3172e-06, 5.3125e-06,\n",
      "        2.3964e-04, 2.0571e-04, 2.0565e-04, 5.0315e-06, 5.0259e-06, 1.3307e-04,\n",
      "        1.3299e-04, 4.4014e-01, 4.3930e-01, 1.7163e+00, 1.7171e+00, 4.9060e-06,\n",
      "        1.3104e-04, 4.2007e-01, 1.7365e+00, 3.7571e-01, 1.7814e+00, 4.8227e-01,\n",
      "        9.3048e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([174.4463, 208.8284, 222.3806, 222.7935,   8.0396,   8.0396,   8.0410,\n",
      "        332.4601, 332.4601, 332.4601,   8.0406,   8.0399, 332.4601, 332.4601,\n",
      "        332.4601, 332.4601, 332.4601,  53.3030,  53.3030,   8.0395, 332.4601,\n",
      "        332.4601, 332.4601, 332.4601, 332.4601,  53.3030,  53.3030, 332.4601,\n",
      "         53.3030,  53.3030,   5.2026, 332.4601, 332.4601, 332.4601, 332.4601,\n",
      "        332.4601,  53.3030,  53.3030, 332.4601,  53.3030,  53.3030,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 332.4601,   5.2026,   5.2025, 332.4601,   5.2026,\n",
      "          5.2025, 332.4601,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        332.4601, 332.4601, 332.4601, 332.4601,  53.3030,  53.3030,  53.3030,\n",
      "         53.3030, 332.4601, 332.4601, 332.4601,  53.3030,  53.3030,  53.3030,\n",
      "         53.3030,   5.2026,  53.3030,  53.3030,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 500 was 93.0%\n",
      "tensor([8.0407e-08, 3.8218e-06, 3.1597e-06, 2.9547e-06, 2.9488e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4281e-06, 5.3065e-06, 5.3004e-06,\n",
      "        2.3729e-04, 2.0368e-04, 2.0353e-04, 5.0197e-06, 5.0164e-06, 1.3167e-04,\n",
      "        1.3166e-04, 4.3917e-01, 4.3845e-01, 1.7129e+00, 1.7136e+00, 4.8975e-06,\n",
      "        1.2975e-04, 4.1921e-01, 1.7330e+00, 3.7498e-01, 1.7777e+00, 4.8129e-01,\n",
      "        9.3062e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([174.7189, 209.1283, 222.6761, 223.0527,   8.0383,   8.0380,   8.0374,\n",
      "        332.8817, 332.8817, 332.8817,   8.0380,   8.0378, 332.8817, 332.8817,\n",
      "        332.8817, 332.8817, 332.8817,  53.3821,  53.3821,   8.0387, 332.8817,\n",
      "        332.8817, 332.8817, 332.8817, 332.8817,  53.3821,  53.3821, 332.8817,\n",
      "         53.3821,  53.3821,   5.2026, 332.8817, 332.8817, 332.8817, 332.8817,\n",
      "        332.8817,  53.3821,  53.3821, 332.8817,  53.3821,  53.3821,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 332.8817,   5.2026,   5.2025, 332.8817,   5.2026,\n",
      "          5.2025, 332.8817,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        332.8817, 332.8817, 332.8817, 332.8817,  53.3821,  53.3821,  53.3821,\n",
      "         53.3821, 332.8817, 332.8817, 332.8817,  53.3821,  53.3821,  53.3821,\n",
      "         53.3821,   5.2026,  53.3821,  53.3821,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 501 was 93.0%\n",
      "tensor([7.9677e-08, 3.8144e-06, 3.1541e-06, 2.9499e-06, 2.9444e-06, 1.9852e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4150e-06, 5.2947e-06, 5.2909e-06,\n",
      "        2.3482e-04, 2.0162e-04, 2.0155e-04, 5.0102e-06, 5.0061e-06, 1.3037e-04,\n",
      "        1.3031e-04, 4.3821e-01, 4.3750e-01, 1.7094e+00, 1.7101e+00, 4.8868e-06,\n",
      "        1.2840e-04, 4.1839e-01, 1.7294e+00, 3.7429e-01, 1.7740e+00, 4.8029e-01,\n",
      "        9.3076e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([174.9913, 209.4279, 222.9713, 223.3121,   8.0350,   8.0368,   8.0367,\n",
      "        333.3033, 333.3033, 333.3033,   8.0359,   8.0366, 333.3033, 333.3033,\n",
      "        333.3033, 333.3033, 333.3033,  53.4613,  53.4613,   8.0353, 333.3033,\n",
      "        333.3033, 333.3033, 333.3033, 333.3033,  53.4613,  53.4613, 333.3033,\n",
      "         53.4613,  53.4613,   5.2026, 333.3033, 333.3033, 333.3033, 333.3033,\n",
      "        333.3033,  53.4613,  53.4613, 333.3033,  53.4613,  53.4613,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 333.3033,   5.2026,   5.2025, 333.3033,   5.2026,\n",
      "          5.2025, 333.3033,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        333.3033, 333.3033, 333.3033, 333.3033,  53.4613,  53.4613,  53.4613,\n",
      "         53.4613, 333.3033, 333.3033, 333.3033,  53.4613,  53.4613,  53.4613,\n",
      "         53.4613,   5.2026,  53.4613,  53.4613,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 502 was 93.0%\n",
      "tensor([7.8958e-08, 3.8075e-06, 3.1487e-06, 2.9451e-06, 2.9403e-06, 2.9779e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4050e-06, 5.2829e-06, 5.2796e-06,\n",
      "        2.3252e-04, 1.9957e-04, 1.9954e-04, 4.9999e-06, 4.9956e-06, 1.2902e-04,\n",
      "        1.2896e-04, 4.3725e-01, 4.3664e-01, 1.7060e+00, 1.7066e+00, 4.8785e-06,\n",
      "        1.2715e-04, 4.1758e-01, 1.7258e+00, 3.7357e-01, 1.7704e+00, 4.7932e-01,\n",
      "        9.3090e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([175.2637, 209.7275, 223.2666, 223.5714,   8.0337,   8.0332,   8.0341,\n",
      "        333.7249, 333.7249, 333.7249,   8.0343,   8.0345, 333.7249, 333.7249,\n",
      "        333.7249, 333.7249, 333.7249,  53.5405,  53.5405,   8.0345, 333.7249,\n",
      "        333.7249, 333.7249, 333.7249, 333.7249,  53.5405,  53.5405, 333.7249,\n",
      "         53.5405,  53.5405,   5.2026, 333.7249, 333.7249, 333.7249, 333.7249,\n",
      "        333.7249,  53.5405,  53.5405, 333.7249,  53.5405,  53.5405,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 333.7249,   5.2026,   5.2025, 333.7249,   5.2026,\n",
      "          5.2025, 333.7249,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        333.7249, 333.7249, 333.7249, 333.7249,  53.5405,  53.5405,  53.5405,\n",
      "         53.5405, 333.7249, 333.7249, 333.7249,  53.5405,  53.5405,  53.5405,\n",
      "         53.5405,   5.2026,  53.5405,  53.5405,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 503 was 93.1%\n",
      "tensor([1.3235e-23, 3.7822e-06, 3.1269e-06, 2.9239e-06, 2.9197e-06, 1.4054e-08,\n",
      "        1.0024e-08, 9.2170e-09, 9.2111e-09, 5.3923e-06, 5.2725e-06, 5.2687e-06,\n",
      "        2.3010e-04, 1.9756e-04, 1.9749e-04, 4.9889e-06, 4.9857e-06, 1.2769e-04,\n",
      "        1.2765e-04, 4.3626e-01, 4.3573e-01, 1.7026e+00, 1.7031e+00, 4.8680e-06,\n",
      "        1.2582e-04, 4.1672e-01, 1.7223e+00, 3.7290e-01, 1.7666e+00, 4.7833e-01,\n",
      "        9.3104e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([175.5360, 210.0268, 223.5615, 223.8310,   8.0318,   8.0325,   8.0324,\n",
      "        334.1465, 334.1465, 334.1465,   8.0326,   8.0318, 334.1465, 334.1465,\n",
      "        334.1465, 334.1465, 334.1465,  53.6196,  53.6196,   8.0310, 334.1465,\n",
      "        334.1465, 334.1465, 334.1465, 334.1465,  53.6196,  53.6196, 334.1465,\n",
      "         53.6196,  53.6196,   5.2026, 334.1465, 334.1465, 334.1465, 334.1465,\n",
      "        334.1465,  53.6196,  53.6196, 334.1465,  53.6196,  53.6196,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 334.1465,   5.2026,   5.2025, 334.1465,   5.2026,\n",
      "          5.2025, 334.1465,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        334.1465, 334.1465, 334.1465, 334.1465,  53.6196,  53.6196,  53.6196,\n",
      "         53.6196, 334.1465, 334.1465, 334.1465,  53.6196,  53.6196,  53.6196,\n",
      "         53.6196,   5.2026,  53.6196,  53.6196,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 504 was 93.1%\n",
      "tensor([3.9705e-23, 3.7753e-06, 3.1216e-06, 2.9194e-06, 2.9155e-06, 1.3950e-08,\n",
      "        9.9488e-09, 9.1482e-09, 9.1430e-09, 5.3809e-06, 5.2608e-06, 5.2575e-06,\n",
      "        2.2782e-04, 1.9559e-04, 1.9553e-04, 4.9786e-06, 4.9760e-06, 1.2637e-04,\n",
      "        1.2634e-04, 4.3535e-01, 4.3483e-01, 1.6992e+00, 1.6997e+00, 4.8594e-06,\n",
      "        1.2456e-04, 4.1590e-01, 1.7188e+00, 3.7217e-01, 1.7630e+00, 4.7736e-01,\n",
      "        9.3118e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([175.8083, 210.3259, 223.8561, 224.0906,   8.0305,   8.0299,   8.0303,\n",
      "        334.5680, 334.5680, 334.5680,   8.0290,   8.0302, 334.5680, 334.5680,\n",
      "        334.5680, 334.5680, 334.5680,  53.6988,  53.6988,   8.0303, 334.5680,\n",
      "        334.5680, 334.5680, 334.5680, 334.5680,  53.6988,  53.6988, 334.5680,\n",
      "         53.6988,  53.6988,   5.2026, 334.5680, 334.5680, 334.5680, 334.5680,\n",
      "        334.5680,  53.6988,  53.6988, 334.5680,  53.6988,  53.6988,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 334.5680,   5.2026,   5.2025, 334.5680,   5.2026,\n",
      "          5.2025, 334.5680,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        334.5680, 334.5680, 334.5680, 334.5680,  53.6988,  53.6988,  53.6988,\n",
      "         53.6988, 334.5680, 334.5680, 334.5680,  53.6988,  53.6988,  53.6988,\n",
      "         53.6988,   5.2026,  53.6988,  53.6988,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 505 was 93.1%\n",
      "tensor([0.0000e+00, 3.7683e-06, 3.1163e-06, 2.9146e-06, 2.9114e-06, 1.3845e-08,\n",
      "        9.8729e-09, 9.0792e-09, 9.0752e-09, 5.3684e-06, 5.2498e-06, 5.2471e-06,\n",
      "        2.2547e-04, 1.9362e-04, 1.9360e-04, 4.9691e-06, 4.9660e-06, 1.2509e-04,\n",
      "        1.2505e-04, 4.3435e-01, 4.3396e-01, 1.6958e+00, 1.6962e+00, 4.8490e-06,\n",
      "        1.2328e-04, 4.1508e-01, 1.7152e+00, 3.7146e-01, 1.7594e+00, 4.7637e-01,\n",
      "        9.3132e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([176.0804, 210.6248, 224.1505, 224.3505,   8.0261,   8.0287,   8.0276,\n",
      "        334.9896, 334.9896, 334.9896,   8.0283,   8.0290, 334.9896, 334.9896,\n",
      "        334.9896, 334.9896, 334.9896,  53.7780,  53.7780,   8.0282, 334.9896,\n",
      "        334.9896, 334.9896, 334.9896, 334.9896,  53.7780,  53.7780, 334.9896,\n",
      "         53.7780,  53.7780,   5.2026, 334.9896, 334.9896, 334.9896, 334.9896,\n",
      "        334.9896,  53.7780,  53.7780, 334.9896,  53.7780,  53.7780,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 334.9896,   5.2026,   5.2025, 334.9896,   5.2026,\n",
      "          5.2025, 334.9896,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        334.9896, 334.9896, 334.9896, 334.9896,  53.7780,  53.7780,  53.7780,\n",
      "         53.7780, 334.9896, 334.9896, 334.9896,  53.7780,  53.7780,  53.7780,\n",
      "         53.7780,   5.2026,  53.7780,  53.7780,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 506 was 93.1%\n",
      "tensor([0.0000e+00, 3.7615e-06, 3.1112e-06, 2.9103e-06, 2.9074e-06, 1.3739e-08,\n",
      "        9.7975e-09, 9.0107e-09, 9.0072e-09, 5.3588e-06, 5.2381e-06, 5.2370e-06,\n",
      "        2.2321e-04, 1.9162e-04, 1.9164e-04, 4.9587e-06, 4.9554e-06, 1.2381e-04,\n",
      "        1.2375e-04, 4.3341e-01, 4.3305e-01, 1.6925e+00, 1.6928e+00, 4.8403e-06,\n",
      "        1.2206e-04, 4.1428e-01, 1.7117e+00, 3.7081e-01, 1.7557e+00, 4.7542e-01,\n",
      "        9.3146e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([176.3525, 210.9237, 224.4450, 224.6102,   8.0248,   8.0260,   8.0265,\n",
      "        335.4111, 335.4111, 335.4111,   8.0262,   8.0254, 335.4111, 335.4111,\n",
      "        335.4111, 335.4111, 335.4111,  53.8572,  53.8572,   8.0270, 335.4111,\n",
      "        335.4111, 335.4111, 335.4111, 335.4111,  53.8572,  53.8572, 335.4111,\n",
      "         53.8572,  53.8572,   5.2026, 335.4111, 335.4111, 335.4111, 335.4111,\n",
      "        335.4111,  53.8572,  53.8572, 335.4111,  53.8572,  53.8572,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 335.4111,   5.2026,   5.2025, 335.4111,   5.2026,\n",
      "          5.2025, 335.4111,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        335.4111, 335.4111, 335.4111, 335.4111,  53.8572,  53.8572,  53.8572,\n",
      "         53.8572, 335.4111, 335.4111, 335.4111,  53.8572,  53.8572,  53.8572,\n",
      "         53.8572,   5.2026,  53.8572,  53.8572,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 507 was 93.1%\n",
      "tensor([0.0000e+00, 3.7544e-06, 3.1057e-06, 2.9056e-06, 2.9033e-06, 1.3636e-08,\n",
      "        9.7225e-09, 8.9429e-09, 8.9397e-09, 5.3461e-06, 5.2277e-06, 5.2253e-06,\n",
      "        2.2091e-04, 1.8975e-04, 1.8970e-04, 4.9480e-06, 4.9468e-06, 1.2251e-04,\n",
      "        1.2250e-04, 4.3244e-01, 4.3213e-01, 1.6891e+00, 1.6894e+00, 4.8302e-06,\n",
      "        1.2079e-04, 4.1349e-01, 1.7082e+00, 3.7011e-01, 1.7521e+00, 4.7445e-01,\n",
      "        9.3160e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([176.6245, 211.2223, 224.7392, 224.8701,   8.0235,   8.0248,   8.0237,\n",
      "        335.8326, 335.8326, 335.8326,   8.0240,   8.0242, 335.8326, 335.8326,\n",
      "        335.8326, 335.8326, 335.8326,  53.9363,  53.9363,   8.0235, 335.8326,\n",
      "        335.8326, 335.8326, 335.8326, 335.8326,  53.9363,  53.9363, 335.8326,\n",
      "         53.9363,  53.9363,   5.2026, 335.8326, 335.8326, 335.8326, 335.8326,\n",
      "        335.8326,  53.9363,  53.9363, 335.8326,  53.9363,  53.9363,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 335.8326,   5.2026,   5.2025, 335.8326,   5.2026,\n",
      "          5.2025, 335.8326,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        335.8326, 335.8326, 335.8326, 335.8326,  53.9363,  53.9363,  53.9363,\n",
      "         53.9363, 335.8326, 335.8326, 335.8326,  53.9363,  53.9363,  53.9363,\n",
      "         53.9363,   5.2026,  53.9363,  53.9363,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 508 was 93.1%\n",
      "tensor([7.9409e-23, 3.7476e-06, 3.1005e-06, 2.9010e-06, 2.8990e-06, 1.3533e-08,\n",
      "        9.6490e-09, 8.8750e-09, 8.8728e-09, 5.3346e-06, 5.2157e-06, 5.2152e-06,\n",
      "        2.1870e-04, 1.8779e-04, 1.8781e-04, 4.9380e-06, 4.9358e-06, 1.2126e-04,\n",
      "        1.2122e-04, 4.3153e-01, 4.3126e-01, 1.6857e+00, 1.6859e+00, 4.8214e-06,\n",
      "        1.1957e-04, 4.1264e-01, 1.7047e+00, 3.6938e-01, 1.7485e+00, 4.7347e-01,\n",
      "        9.3174e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([176.8964, 211.5207, 225.0331, 225.1302,   8.0221,   8.0211,   8.0221,\n",
      "        336.2541, 336.2541, 336.2541,   8.0219,   8.0216, 336.2541, 336.2541,\n",
      "        336.2541, 336.2541, 336.2541,  54.0155,  54.0155,   8.0227, 336.2541,\n",
      "        336.2541, 336.2541, 336.2541, 336.2541,  54.0155,  54.0155, 336.2541,\n",
      "         54.0155,  54.0155,   5.2026, 336.2541, 336.2541, 336.2541, 336.2541,\n",
      "        336.2541,  54.0155,  54.0155, 336.2541,  54.0155,  54.0155,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 336.2541,   5.2026,   5.2025, 336.2541,   5.2026,\n",
      "          5.2025, 336.2541,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        336.2541, 336.2541, 336.2541, 336.2541,  54.0155,  54.0155,  54.0155,\n",
      "         54.0155, 336.2541, 336.2541, 336.2541,  54.0155,  54.0155,  54.0155,\n",
      "         54.0155,   5.2026,  54.0155,  54.0155,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 509 was 93.1%\n",
      "tensor([0.0000e+00, 3.7406e-06, 3.0952e-06, 2.8964e-06, 2.8950e-06, 1.3430e-08,\n",
      "        9.5752e-09, 8.8080e-09, 8.8063e-09, 5.3221e-06, 5.2059e-06, 5.2043e-06,\n",
      "        2.1643e-04, 1.8593e-04, 1.8591e-04, 4.9277e-06, 4.9269e-06, 1.2001e-04,\n",
      "        1.2001e-04, 4.3055e-01, 4.3038e-01, 1.6824e+00, 1.6825e+00, 4.8111e-06,\n",
      "        1.1832e-04, 4.1183e-01, 1.7012e+00, 3.6871e-01, 1.7449e+00, 4.7250e-01,\n",
      "        9.3188e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([177.1683, 211.8189, 225.3267, 225.3905,   8.0186,   8.0204,   8.0199,\n",
      "        336.6756, 336.6756, 336.6756,   8.0202,   8.0208, 336.6756, 336.6756,\n",
      "        336.6756, 336.6756, 336.6756,  54.0947,  54.0947,   8.0192, 336.6756,\n",
      "        336.6756, 336.6756, 336.6756, 336.6756,  54.0947,  54.0947, 336.6756,\n",
      "         54.0947,  54.0947,   5.2026, 336.6756, 336.6756, 336.6756, 336.6756,\n",
      "        336.6756,  54.0947,  54.0947, 336.6756,  54.0947,  54.0947,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 336.6756,   5.2026,   5.2025, 336.6756,   5.2026,\n",
      "          5.2025, 336.6756,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        336.6756, 336.6756, 336.6756, 336.6756,  54.0947,  54.0947,  54.0947,\n",
      "         54.0947, 336.6756, 336.6756, 336.6756,  54.0947,  54.0947,  54.0947,\n",
      "         54.0947,   5.2026,  54.0947,  54.0947,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 510 was 93.2%\n",
      "tensor([6.6174e-23, 3.7339e-06, 3.0902e-06, 2.8919e-06, 2.8910e-06, 1.3328e-08,\n",
      "        9.5017e-09, 8.7408e-09, 8.7398e-09, 5.3123e-06, 5.1938e-06, 5.1939e-06,\n",
      "        2.1428e-04, 1.8401e-04, 1.8403e-04, 4.9176e-06, 4.9163e-06, 1.1877e-04,\n",
      "        1.1874e-04, 4.2963e-01, 4.2952e-01, 1.6790e+00, 1.6791e+00, 4.8030e-06,\n",
      "        1.1715e-04, 4.1100e-01, 1.6978e+00, 3.6802e-01, 1.7413e+00, 4.7155e-01,\n",
      "        9.3202e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([177.4401, 212.1170, 225.6203, 225.6508,   8.0173,   8.0177,   8.0182,\n",
      "        337.0971, 337.0971, 337.0971,   8.0181,   8.0172, 337.0971, 337.0971,\n",
      "        337.0971, 337.0971, 337.0971,  54.1738,  54.1738,   8.0184, 337.0971,\n",
      "        337.0971, 337.0971, 337.0971, 337.0971,  54.1738,  54.1738, 337.0971,\n",
      "         54.1738,  54.1738,   5.2026, 337.0971, 337.0971, 337.0971, 337.0971,\n",
      "        337.0971,  54.1738,  54.1738, 337.0971,  54.1738,  54.1738,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 337.0971,   5.2026,   5.2025, 337.0971,   5.2026,\n",
      "          5.2025, 337.0971,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        337.0971, 337.0971, 337.0971, 337.0971,  54.1738,  54.1738,  54.1738,\n",
      "         54.1738, 337.0971, 337.0971, 337.0971,  54.1738,  54.1738,  54.1738,\n",
      "         54.1738,   5.2026,  54.1738,  54.1738,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 511 was 93.2%\n",
      "tensor([1.3235e-23, 3.7269e-06, 3.0847e-06, 2.8873e-06, 2.8868e-06, 1.3226e-08,\n",
      "        9.4280e-09, 8.6741e-09, 8.6734e-09, 5.2998e-06, 5.1834e-06, 5.1824e-06,\n",
      "        2.1205e-04, 1.8218e-04, 1.8215e-04, 4.9070e-06, 4.9074e-06, 1.1752e-04,\n",
      "        1.1753e-04, 4.2867e-01, 4.2861e-01, 1.6756e+00, 1.6757e+00, 4.7927e-06,\n",
      "        1.1592e-04, 4.1022e-01, 1.6942e+00, 3.6732e-01, 1.7377e+00, 4.7058e-01,\n",
      "        9.3216e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([177.7118, 212.4149, 225.9136, 225.9112,   8.0154,   8.0165,   8.0155,\n",
      "        337.5186, 337.5186, 337.5186,   8.0159,   8.0164, 337.5186, 337.5186,\n",
      "        337.5186, 337.5186, 337.5186,  54.2530,  54.2530,   8.0148, 337.5186,\n",
      "        337.5186, 337.5186, 337.5186, 337.5186,  54.2530,  54.2530, 337.5186,\n",
      "         54.2530,  54.2530,   5.2026, 337.5186, 337.5186, 337.5186, 337.5186,\n",
      "        337.5186,  54.2530,  54.2530, 337.5186,  54.2530,  54.2530,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 337.5186,   5.2026,   5.2025, 337.5186,   5.2026,\n",
      "          5.2025, 337.5186,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        337.5186, 337.5186, 337.5186, 337.5186,  54.2530,  54.2530,  54.2530,\n",
      "         54.2530, 337.5186, 337.5186, 337.5186,  54.2530,  54.2530,  54.2530,\n",
      "         54.2530,   5.2026,  54.2530,  54.2530,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 512 was 93.2%\n",
      "tensor([0.0000e+00, 3.7201e-06, 3.0797e-06, 2.8828e-06, 2.8828e-06, 1.3126e-08,\n",
      "        9.3565e-09, 8.6082e-09, 8.6084e-09, 5.2889e-06, 5.1716e-06, 5.1727e-06,\n",
      "        2.0993e-04, 1.8029e-04, 1.8034e-04, 4.8974e-06, 4.8965e-06, 1.1633e-04,\n",
      "        1.1630e-04, 4.2777e-01, 4.2775e-01, 1.6723e+00, 1.6723e+00, 4.7842e-06,\n",
      "        1.1475e-04, 4.0938e-01, 1.6908e+00, 3.6662e-01, 1.7341e+00, 4.6962e-01,\n",
      "        9.3230e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([177.9834, 212.7127, 226.2743, 226.1229,   8.0140,   8.0127,   8.0138,\n",
      "        337.9400, 337.9400, 337.9400,   8.0137,   8.0137, 337.9400, 337.9400,\n",
      "        337.9400, 337.9400, 337.9400,  54.3322,  54.3322,   8.0140, 337.9400,\n",
      "        337.9400, 337.9400, 337.9400, 337.9400,  54.3322,  54.3322, 337.9400,\n",
      "         54.3322,  54.3322,   5.2026, 337.9400, 337.9400, 337.9400, 337.9400,\n",
      "        337.9400,  54.3322,  54.3322, 337.9400,  54.3322,  54.3322,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 337.9400,   5.2026,   5.2025, 337.9400,   5.2026,\n",
      "          5.2025, 337.9400,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        337.9400, 337.9400, 337.9400, 337.9400,  54.3322,  54.3322,  54.3322,\n",
      "         54.3322, 337.9400, 337.9400, 337.9400,  54.3322,  54.3322,  54.3322,\n",
      "         54.3322,   5.2026,  54.3322,  54.3322,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 513 was 93.2%\n",
      "tensor([1.3235e-23, 3.7133e-06, 3.0744e-06, 2.8772e-06, 2.8793e-06, 1.3032e-08,\n",
      "        9.2895e-09, 8.5498e-09, 8.5526e-09, 5.2764e-06, 5.1609e-06, 5.1619e-06,\n",
      "        2.0776e-04, 1.7867e-04, 1.7869e-04, 4.8860e-06, 4.8878e-06, 1.1525e-04,\n",
      "        1.1528e-04, 4.2670e-01, 4.2698e-01, 1.6689e+00, 1.6687e+00, 4.7732e-06,\n",
      "        1.1370e-04, 4.0851e-01, 1.6873e+00, 3.6589e-01, 1.7304e+00, 4.6861e-01,\n",
      "        9.3244e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([178.2550, 213.0102, 226.6341, 226.3348,   8.0105,   8.0120,   8.0116,\n",
      "        338.3615, 338.3615, 338.3615,   8.0121,   8.0130, 338.3615, 338.3615,\n",
      "        338.3615, 338.3615, 338.3615,  54.4113,  54.4113,   8.0104, 338.3615,\n",
      "        338.3615, 338.3615, 338.3615, 338.3615,  54.4113,  54.4113, 338.3615,\n",
      "         54.4113,  54.4113,   5.2026, 338.3615, 338.3615, 338.3615, 338.3615,\n",
      "        338.3615,  54.4113,  54.4113, 338.3615,  54.4113,  54.4113,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 338.3615,   5.2026,   5.2025, 338.3615,   5.2026,\n",
      "          5.2025, 338.3615,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        338.3615, 338.3615, 338.3615, 338.3615,  54.4113,  54.4113,  54.4113,\n",
      "         54.4113, 338.3615, 338.3615, 338.3615,  54.4113,  54.4113,  54.4113,\n",
      "         54.4113,   5.2026,  54.4113,  54.4113,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 514 was 93.2%\n",
      "tensor([3.9705e-23, 3.7067e-06, 3.0695e-06, 2.8719e-06, 2.8761e-06, 1.2940e-08,\n",
      "        9.2242e-09, 8.4923e-09, 8.4976e-09, 5.2667e-06, 5.1481e-06, 5.1522e-06,\n",
      "        2.0574e-04, 1.7700e-04, 1.7709e-04, 4.8754e-06, 4.8779e-06, 1.1421e-04,\n",
      "        1.1422e-04, 4.2567e-01, 4.2622e-01, 1.6657e+00, 1.6651e+00, 4.7648e-06,\n",
      "        1.1273e-04, 4.0764e-01, 1.6838e+00, 3.6519e-01, 1.7268e+00, 4.6765e-01,\n",
      "        9.3258e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([178.5266, 213.3077, 226.9929, 226.5471,   8.0091,   8.0098,   8.0099,\n",
      "        338.7829, 338.7829, 338.7829,   8.0094,   8.0092, 338.7829, 338.7829,\n",
      "        338.7829, 338.7829, 338.7829,  54.4905,  54.4905,   8.0097, 338.7829,\n",
      "        338.7829, 338.7829, 338.7829, 338.7829,  54.4905,  54.4905, 338.7829,\n",
      "         54.4905,  54.4905,   5.2026, 338.7829, 338.7829, 338.7829, 338.7829,\n",
      "        338.7829,  54.4905,  54.4905, 338.7829,  54.4905,  54.4905,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 338.7829,   5.2026,   5.2025, 338.7829,   5.2026,\n",
      "          5.2025, 338.7829,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        338.7829, 338.7829, 338.7829, 338.7829,  54.4905,  54.4905,  54.4905,\n",
      "         54.4905, 338.7829, 338.7829, 338.7829,  54.4905,  54.4905,  54.4905,\n",
      "         54.4905,   5.2026,  54.4905,  54.4905,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 515 was 93.2%\n",
      "tensor([9.2644e-23, 3.6999e-06, 3.0641e-06, 2.8664e-06, 2.8725e-06, 1.2845e-08,\n",
      "        9.1563e-09, 8.4334e-09, 8.4410e-09, 5.2541e-06, 5.1364e-06, 5.1410e-06,\n",
      "        2.0357e-04, 1.7538e-04, 1.7544e-04, 4.8640e-06, 4.8689e-06, 1.1312e-04,\n",
      "        1.1318e-04, 4.2462e-01, 4.2540e-01, 1.6622e+00, 1.6615e+00, 4.7537e-06,\n",
      "        1.1168e-04, 4.0682e-01, 1.6802e+00, 3.6441e-01, 1.7231e+00, 4.6663e-01,\n",
      "        9.3272e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([178.7981, 213.6051, 227.3509, 226.7597,   8.0077,   8.0071,   8.0061,\n",
      "        339.2043, 339.2043, 339.2043,   8.0076,   8.0080, 339.2043, 339.2043,\n",
      "        339.2043, 339.2043, 339.2043,  54.5697,  54.5697,   8.0080, 339.2043,\n",
      "        339.2043, 339.2043, 339.2043, 339.2043,  54.5697,  54.5697, 339.2043,\n",
      "         54.5697,  54.5697,   5.2026, 339.2043, 339.2043, 339.2043, 339.2043,\n",
      "        339.2043,  54.5697,  54.5697, 339.2043,  54.5697,  54.5697,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 339.2043,   5.2026,   5.2025, 339.2043,   5.2026,\n",
      "          5.2025, 339.2043,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        339.2043, 339.2043, 339.2043, 339.2043,  54.5697,  54.5697,  54.5697,\n",
      "         54.5697, 339.2043, 339.2043, 339.2043,  54.5697,  54.5697,  54.5697,\n",
      "         54.5697,   5.2026,  54.5697,  54.5697,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 516 was 93.2%\n",
      "tensor([6.9697e-08, 3.7092e-06, 3.0736e-06, 2.8757e-06, 2.8838e-06, 3.3087e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2425e-06, 5.1251e-06, 5.1321e-06,\n",
      "        2.0153e-04, 1.7378e-04, 1.7388e-04, 4.8534e-06, 4.8595e-06, 1.1213e-04,\n",
      "        1.1218e-04, 4.2361e-01, 4.2463e-01, 1.6590e+00, 1.6579e+00, 4.7437e-06,\n",
      "        1.1069e-04, 4.0594e-01, 1.6767e+00, 3.6372e-01, 1.7195e+00, 4.6565e-01,\n",
      "        9.3286e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([179.0697, 213.9023, 227.7081, 226.9724,   8.0047,   8.0059,   8.0054,\n",
      "        339.6257, 339.6257, 339.6257,   8.0064,   8.0052, 339.6257, 339.6257,\n",
      "        339.6257, 339.6257, 339.6257,  54.6488,  54.6488,   8.0044, 339.6257,\n",
      "        339.6257, 339.6257, 339.6257, 339.6257,  54.6488,  54.6488, 339.6257,\n",
      "         54.6488,  54.6488,   5.2026, 339.6257, 339.6257, 339.6257, 339.6257,\n",
      "        339.6257,  54.6488,  54.6488, 339.6257,  54.6488,  54.6488,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 339.6257,   5.2026,   5.2025, 339.6257,   5.2026,\n",
      "          5.2025, 339.6257,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        339.6257, 339.6257, 339.6257, 339.6257,  54.6488,  54.6488,  54.6488,\n",
      "         54.6488, 339.6257, 339.6257, 339.6257,  54.6488,  54.6488,  54.6488,\n",
      "         54.6488,   5.2026,  54.6488,  54.6488,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 517 was 93.3%\n",
      "tensor([6.9117e-08, 3.7025e-06, 3.0685e-06, 2.8703e-06, 2.8802e-06, 2.4815e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2320e-06, 5.1133e-06, 5.1207e-06,\n",
      "        1.9954e-04, 1.7218e-04, 1.7226e-04, 4.8421e-06, 4.8503e-06, 1.1106e-04,\n",
      "        1.1116e-04, 4.2263e-01, 4.2383e-01, 1.6556e+00, 1.6544e+00, 4.7352e-06,\n",
      "        1.0970e-04, 4.0510e-01, 1.6733e+00, 3.6298e-01, 1.7159e+00, 4.6468e-01,\n",
      "        9.3300e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([179.3412, 214.1994, 228.0644, 227.1856,   8.0033,   8.0031,   8.0032,\n",
      "        340.0471, 340.0471, 340.0471,   8.0026,   8.0035, 340.0471, 340.0471,\n",
      "        340.0471, 340.0471, 340.0471,  54.7280,  54.7280,   8.0036, 340.0471,\n",
      "        340.0471, 340.0471, 340.0471, 340.0471,  54.7280,  54.7280, 340.0471,\n",
      "         54.7280,  54.7280,   5.2026, 340.0471, 340.0471, 340.0471, 340.0471,\n",
      "        340.0471,  54.7280,  54.7280, 340.0471,  54.7280,  54.7280,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 340.0471,   5.2026,   5.2025, 340.0471,   5.2026,\n",
      "          5.2025, 340.0471,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        340.0471, 340.0471, 340.0471, 340.0471,  54.7280,  54.7280,  54.7280,\n",
      "         54.7280, 340.0471, 340.0471, 340.0471,  54.7280,  54.7280,  54.7280,\n",
      "         54.7280,   5.2026,  54.7280,  54.7280,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 518 was 93.3%\n",
      "tensor([6.8535e-08, 3.6956e-06, 3.0631e-06, 2.8647e-06, 2.8767e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2196e-06, 5.1015e-06, 5.1108e-06,\n",
      "        1.9745e-04, 1.7057e-04, 1.7070e-04, 4.8318e-06, 4.8407e-06, 1.1004e-04,\n",
      "        1.1013e-04, 4.2154e-01, 4.2308e-01, 1.6523e+00, 1.6508e+00, 4.7243e-06,\n",
      "        1.0868e-04, 4.0426e-01, 1.6697e+00, 3.6225e-01, 1.7122e+00, 4.6368e-01,\n",
      "        9.3314e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([179.6126, 214.4963, 228.4199, 227.3990,   8.0002,   8.0019,   8.0019,\n",
      "        340.4685, 340.4685, 340.4685,   8.0019,   8.0007, 340.4685, 340.4685,\n",
      "        340.4685, 340.4685, 340.4685,  54.8072,  54.8072,   7.9999, 340.4685,\n",
      "        340.4685, 340.4685, 340.4685, 340.4685,  54.8072,  54.8072, 340.4685,\n",
      "         54.8072,  54.8072,   5.2026, 340.4685, 340.4685, 340.4685, 340.4685,\n",
      "        340.4685,  54.8072,  54.8072, 340.4685,  54.8072,  54.8072,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 340.4685,   5.2026,   5.2025, 340.4685,   5.2026,\n",
      "          5.2025, 340.4685,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        340.4685, 340.4685, 340.4685, 340.4685,  54.8072,  54.8072,  54.8072,\n",
      "         54.8072, 340.4685, 340.4685, 340.4685,  54.8072,  54.8072,  54.8072,\n",
      "         54.8072,   5.2026,  54.8072,  54.8072,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 519 was 93.3%\n",
      "tensor([6.7970e-08, 3.6891e-06, 3.0580e-06, 2.8595e-06, 2.8733e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2098e-06, 5.0901e-06, 5.1001e-06,\n",
      "        1.9551e-04, 1.6902e-04, 1.6913e-04, 4.8205e-06, 4.8320e-06, 1.0901e-04,\n",
      "        1.0914e-04, 4.2058e-01, 4.2230e-01, 1.6490e+00, 1.6473e+00, 4.7159e-06,\n",
      "        1.0773e-04, 4.0344e-01, 1.6663e+00, 3.6152e-01, 1.7087e+00, 4.6273e-01,\n",
      "        9.3328e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([179.8841, 214.7932, 228.7744, 227.6129,   7.9988,   7.9992,   7.9981,\n",
      "        340.8899, 340.8899, 340.8899,   7.9997,   7.9990, 340.8899, 340.8899,\n",
      "        340.8899, 340.8899, 340.8899,  54.8863,  54.8863,   7.9991, 340.8899,\n",
      "        340.8899, 340.8899, 340.8899, 340.8899,  54.8863,  54.8863, 340.8899,\n",
      "         54.8863,  54.8863,   5.2026, 340.8899, 340.8899, 340.8899, 340.8899,\n",
      "        340.8899,  54.8863,  54.8863, 340.8899,  54.8863,  54.8863,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 340.8899,   5.2026,   5.2025, 340.8899,   5.2026,\n",
      "          5.2025, 340.8899,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        340.8899, 340.8899, 340.8899, 340.8899,  54.8863,  54.8863,  54.8863,\n",
      "         54.8863, 340.8899, 340.8899, 340.8899,  54.8863,  54.8863,  54.8863,\n",
      "         54.8863,   5.2026,  54.8863,  54.8863,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 520 was 93.3%\n",
      "tensor([6.7394e-08, 3.6821e-06, 3.0528e-06, 2.8540e-06, 2.8696e-06, 1.4889e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1975e-06, 5.0784e-06, 5.0906e-06,\n",
      "        1.9347e-04, 1.6742e-04, 1.6757e-04, 4.8099e-06, 4.8221e-06, 1.0800e-04,\n",
      "        1.0813e-04, 4.1956e-01, 4.2149e-01, 1.6457e+00, 1.6437e+00, 4.7052e-06,\n",
      "        1.0673e-04, 4.0256e-01, 1.6628e+00, 3.6083e-01, 1.7050e+00, 4.6174e-01,\n",
      "        9.3342e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([180.1555, 215.0899, 229.1282, 227.8269,   7.9969,   7.9963,   7.9974,\n",
      "        341.3112, 341.3112, 341.3112,   7.9959,   7.9972, 341.3112, 341.3112,\n",
      "        341.3112, 341.3112, 341.3112,  54.9655,  54.9655,   7.9974, 341.3112,\n",
      "        341.3112, 341.3112, 341.3112, 341.3112,  54.9655,  54.9655, 341.3112,\n",
      "         54.9655,  54.9655,   5.2026, 341.3112, 341.3112, 341.3112, 341.3112,\n",
      "        341.3112,  54.9655,  54.9655, 341.3112,  54.9655,  54.9655,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 341.3112,   5.2026,   5.2025, 341.3112,   5.2026,\n",
      "          5.2025, 341.3112,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        341.3112, 341.3112, 341.3112, 341.3112,  54.9655,  54.9655,  54.9655,\n",
      "         54.9655, 341.3112, 341.3112, 341.3112,  54.9655,  54.9655,  54.9655,\n",
      "         54.9655,   5.2026,  54.9655,  54.9655,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 521 was 93.3%\n",
      "tensor([6.6833e-08, 3.6754e-06, 3.0476e-06, 2.8486e-06, 2.8663e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1859e-06, 5.0670e-06, 5.0803e-06,\n",
      "        1.9150e-04, 1.6588e-04, 1.6605e-04, 4.7997e-06, 4.8130e-06, 1.0700e-04,\n",
      "        1.0714e-04, 4.1849e-01, 4.2077e-01, 1.6425e+00, 1.6402e+00, 4.6954e-06,\n",
      "        1.0575e-04, 4.0175e-01, 1.6593e+00, 3.6010e-01, 1.7014e+00, 4.6077e-01,\n",
      "        9.3356e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([180.4269, 215.3865, 229.4812, 228.0412,   7.9944,   7.9951,   7.9945,\n",
      "        341.7326, 341.7326, 341.7326,   7.9951,   7.9954, 341.7326, 341.7326,\n",
      "        341.7326, 341.7326, 341.7326,  55.0447,  55.0447,   7.9937, 341.7326,\n",
      "        341.7326, 341.7326, 341.7326, 341.7326,  55.0447,  55.0447, 341.7326,\n",
      "         55.0447,  55.0447,   5.2026, 341.7326, 341.7326, 341.7326, 341.7326,\n",
      "        341.7326,  55.0447,  55.0447, 341.7326,  55.0447,  55.0447,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 341.7326,   5.2026,   5.2025, 341.7326,   5.2026,\n",
      "          5.2025, 341.7326,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        341.7326, 341.7326, 341.7326, 341.7326,  55.0447,  55.0447,  55.0447,\n",
      "         55.0447, 341.7326, 341.7326, 341.7326,  55.0447,  55.0447,  55.0447,\n",
      "         55.0447,   5.2026,  55.0447,  55.0447,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 522 was 93.3%\n",
      "tensor([6.6272e-08, 3.6687e-06, 3.0425e-06, 2.8433e-06, 2.8627e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1755e-06, 5.0549e-06, 5.0705e-06,\n",
      "        1.8958e-04, 1.6431e-04, 1.6451e-04, 4.7888e-06, 4.8032e-06, 1.0600e-04,\n",
      "        1.0614e-04, 4.1754e-01, 4.1998e-01, 1.6391e+00, 1.6367e+00, 4.6866e-06,\n",
      "        1.0480e-04, 4.0088e-01, 1.6559e+00, 3.5939e-01, 1.6979e+00, 4.5980e-01,\n",
      "        9.3370e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([180.6983, 215.6830, 229.8334, 228.2559,   7.9930,   7.9923,   7.9927,\n",
      "        342.1539, 342.1539, 342.1539,   7.9929,   7.9916, 342.1539, 342.1539,\n",
      "        342.1539, 342.1539, 342.1539,  55.1238,  55.1238,   7.9929, 342.1539,\n",
      "        342.1539, 342.1539, 342.1539, 342.1539,  55.1238,  55.1238, 342.1539,\n",
      "         55.1238,  55.1238,   5.2026, 342.1539, 342.1539, 342.1539, 342.1539,\n",
      "        342.1539,  55.1238,  55.1238, 342.1539,  55.1238,  55.1238,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 342.1539,   5.2026,   5.2025, 342.1539,   5.2026,\n",
      "          5.2025, 342.1539,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        342.1539, 342.1539, 342.1539, 342.1539,  55.1238,  55.1238,  55.1238,\n",
      "         55.1238, 342.1539, 342.1539, 342.1539,  55.1238,  55.1238,  55.1238,\n",
      "         55.1238,   5.2026,  55.1238,  55.1238,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 523 was 93.3%\n",
      "tensor([0.0000e+00, 3.6468e-06, 3.0236e-06, 2.8241e-06, 2.8454e-06, 1.2123e-08,\n",
      "        8.6420e-09, 7.9811e-09, 8.0055e-09, 5.1636e-06, 5.0442e-06, 5.0601e-06,\n",
      "        1.8761e-04, 1.6282e-04, 1.6299e-04, 4.7781e-06, 4.7951e-06, 1.0501e-04,\n",
      "        1.0518e-04, 4.1654e-01, 4.1920e-01, 1.6359e+00, 1.6332e+00, 4.6760e-06,\n",
      "        1.0383e-04, 4.0006e-01, 1.6524e+00, 3.5866e-01, 1.6943e+00, 4.5883e-01,\n",
      "        9.3383e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([180.9696, 215.9793, 230.1848, 228.4707,   7.9884,   7.9916,   7.9910,\n",
      "        342.5752, 342.5752, 342.5752,   7.9906,   7.9908, 342.5752, 342.5752,\n",
      "        342.5752, 342.5752, 342.5752,  55.2030,  55.2030,   7.9902, 342.5752,\n",
      "        342.5752, 342.5752, 342.5752, 342.5752,  55.2030,  55.2030, 342.5752,\n",
      "         55.2030,  55.2030,   5.2026, 342.5752, 342.5752, 342.5752, 342.5752,\n",
      "        342.5752,  55.2030,  55.2030, 342.5752,  55.2030,  55.2030,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 342.5752,   5.2026,   5.2025, 342.5752,   5.2026,\n",
      "          5.2025, 342.5752,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        342.5752, 342.5752, 342.5752, 342.5752,  55.2030,  55.2030,  55.2030,\n",
      "         55.2030, 342.5752, 342.5752, 342.5752,  55.2030,  55.2030,  55.2030,\n",
      "         55.2030,   5.2026,  55.2030,  55.2030,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 524 was 93.3%\n",
      "tensor([0.0000e+00, 3.6392e-06, 3.0179e-06, 2.8185e-06, 2.8415e-06, 1.1553e-08,\n",
      "        8.1976e-09, 7.5575e-09, 7.5841e-09, 5.1548e-06, 5.0324e-06, 5.0505e-06,\n",
      "        1.7860e-04, 1.5458e-04, 1.5484e-04, 4.7684e-06, 4.7856e-06, 9.8889e-05,\n",
      "        9.9069e-05, 4.1566e-01, 4.1853e-01, 1.6331e+00, 1.6302e+00, 4.6680e-06,\n",
      "        9.7678e-05, 3.9939e-01, 1.6494e+00, 3.5806e-01, 1.6913e+00, 4.5801e-01,\n",
      "        9.3395e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([181.2399, 216.2743, 230.5415, 228.6824,   7.9875,   7.9875,   7.9880,\n",
      "        342.9965, 342.9965, 342.9965,   7.9887,   7.9884, 342.9965, 342.9965,\n",
      "        342.9965, 342.9965, 342.9965,  55.2821,  55.2821,   7.9893, 342.9965,\n",
      "        342.9965, 342.9965, 342.9965, 342.9965,  55.2821,  55.2821, 342.9965,\n",
      "         55.2821,  55.2821,   5.2026, 342.9965, 342.9965, 342.9965, 342.9965,\n",
      "        342.9965,  55.2821,  55.2821, 342.9965,  55.2821,  55.2821,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 342.9965,   5.2026,   5.2025, 342.9965,   5.2026,\n",
      "          5.2025, 342.9965,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        342.9965, 342.9965, 342.9965, 342.9965,  55.2821,  55.2821,  55.2821,\n",
      "         55.2821, 342.9965, 342.9965, 342.9965,  55.2821,  55.2821,  55.2821,\n",
      "         55.2821,   5.2026,  55.2821,  55.2821,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 525 was 93.4%\n",
      "tensor([5.2940e-23, 3.6324e-06, 3.0129e-06, 2.8132e-06, 2.8381e-06, 1.1471e-08,\n",
      "        8.1399e-09, 7.5070e-09, 7.5353e-09, 5.1422e-06, 5.0220e-06, 5.0406e-06,\n",
      "        1.7677e-04, 1.5319e-04, 1.5343e-04, 4.7573e-06, 4.7767e-06, 9.7996e-05,\n",
      "        9.8206e-05, 4.1462e-01, 4.1774e-01, 1.6298e+00, 1.6267e+00, 4.6573e-06,\n",
      "        9.6792e-05, 3.9852e-01, 1.6460e+00, 3.5740e-01, 1.6877e+00, 4.5704e-01,\n",
      "        9.3409e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([181.5101, 216.5692, 230.8972, 228.8944,   7.9861,   7.9866,   7.9860,\n",
      "        343.4178, 343.4178, 343.4178,   7.9858,   7.9865, 343.4178, 343.4178,\n",
      "        343.4178, 343.4178, 343.4178,  55.3613,  55.3613,   7.9856, 343.4178,\n",
      "        343.4178, 343.4178, 343.4178, 343.4178,  55.3613,  55.3613, 343.4178,\n",
      "         55.3613,  55.3613,   5.2026, 343.4178, 343.4178, 343.4178, 343.4178,\n",
      "        343.4178,  55.3613,  55.3613, 343.4178,  55.3613,  55.3613,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 343.4178,   5.2026,   5.2025, 343.4178,   5.2026,\n",
      "          5.2025, 343.4178,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        343.4178, 343.4178, 343.4178, 343.4178,  55.3613,  55.3613,  55.3613,\n",
      "         55.3613, 343.4178, 343.4178, 343.4178,  55.3613,  55.3613,  55.3613,\n",
      "         55.3613,   5.2026,  55.3613,  55.3613,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 526 was 93.4%\n",
      "tensor([6.1287e-08, 3.6403e-06, 3.0208e-06, 2.8208e-06, 2.8475e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1312e-06, 5.0094e-06, 5.0306e-06,\n",
      "        1.7501e-04, 1.5177e-04, 1.5205e-04, 4.7472e-06, 4.7669e-06, 9.7103e-05,\n",
      "        9.7303e-05, 4.1366e-01, 4.1701e-01, 1.6265e+00, 1.6231e+00, 4.6485e-06,\n",
      "        9.5943e-05, 3.9768e-01, 1.6426e+00, 3.5663e-01, 1.6841e+00, 4.5606e-01,\n",
      "        9.3423e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([181.7803, 216.8639, 231.2522, 229.1067,   7.9836,   7.9825,   7.9846,\n",
      "        343.8391, 343.8391, 343.8391,   7.9844,   7.9836, 343.8391, 343.8391,\n",
      "        343.8391, 343.8391, 343.8391,  55.4405,  55.4405,   7.9848, 343.8391,\n",
      "        343.8391, 343.8391, 343.8391, 343.8391,  55.4405,  55.4405, 343.8391,\n",
      "         55.4405,  55.4405,   5.2026, 343.8391, 343.8391, 343.8391, 343.8391,\n",
      "        343.8391,  55.4405,  55.4405, 343.8391,  55.4405,  55.4405,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 343.8391,   5.2026,   5.2025, 343.8391,   5.2026,\n",
      "          5.2025, 343.8391,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        343.8391, 343.8391, 343.8391, 343.8391,  55.4405,  55.4405,  55.4405,\n",
      "         55.4405, 343.8391, 343.8391, 343.8391,  55.4405,  55.4405,  55.4405,\n",
      "         55.4405,   5.2026,  55.4405,  55.4405,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 527 was 93.4%\n",
      "tensor([6.0687e-08, 3.6339e-06, 3.0161e-06, 2.8161e-06, 2.8446e-06, 1.4889e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1203e-06, 4.9997e-06, 5.0201e-06,\n",
      "        1.7289e-04, 1.5015e-04, 1.5039e-04, 4.7362e-06, 4.7591e-06, 9.6074e-05,\n",
      "        9.6323e-05, 4.1264e-01, 4.1625e-01, 1.6231e+00, 1.6195e+00, 4.6387e-06,\n",
      "        9.4969e-05, 3.9688e-01, 1.6390e+00, 3.5596e-01, 1.6806e+00, 4.5513e-01,\n",
      "        9.3437e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([182.0506, 217.1590, 231.6037, 229.3212,   7.9810,   7.9818,   7.9817,\n",
      "        344.2604, 344.2604, 344.2604,   7.9821,   7.9828, 344.2604, 344.2604,\n",
      "        344.2604, 344.2604, 344.2604,  55.5196,  55.5196,   7.9810, 344.2604,\n",
      "        344.2604, 344.2604, 344.2604, 344.2604,  55.5196,  55.5196, 344.2604,\n",
      "         55.5196,  55.5196,   5.2026, 344.2604, 344.2604, 344.2604, 344.2604,\n",
      "        344.2604,  55.5196,  55.5196, 344.2604,  55.5196,  55.5196,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 344.2604,   5.2026,   5.2025, 344.2604,   5.2026,\n",
      "          5.2025, 344.2604,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        344.2604, 344.2604, 344.2604, 344.2604,  55.5196,  55.5196,  55.5196,\n",
      "         55.5196, 344.2604, 344.2604, 344.2604,  55.5196,  55.5196,  55.5196,\n",
      "         55.5196,   5.2026,  55.5196,  55.5196,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 528 was 93.4%\n",
      "tensor([6.0188e-08, 3.6272e-06, 3.0111e-06, 2.8108e-06, 2.8411e-06, 9.9262e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1099e-06, 4.9870e-06, 5.0106e-06,\n",
      "        1.7118e-04, 1.4873e-04, 1.4903e-04, 4.7261e-06, 4.7489e-06, 9.5205e-05,\n",
      "        9.5423e-05, 4.1168e-01, 4.1551e-01, 1.6198e+00, 1.6160e+00, 4.6298e-06,\n",
      "        9.4134e-05, 3.9600e-01, 1.6356e+00, 3.5526e-01, 1.6770e+00, 4.5418e-01,\n",
      "        9.3451e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([182.3209, 217.4539, 231.9542, 229.5361,   7.9794,   7.9795,   7.9800,\n",
      "        344.6817, 344.6817, 344.6817,   7.9793,   7.9789, 344.6817, 344.6817,\n",
      "        344.6817, 344.6817, 344.6817,  55.5988,  55.5988,   7.9802, 344.6817,\n",
      "        344.6817, 344.6817, 344.6817, 344.6817,  55.5988,  55.5988, 344.6817,\n",
      "         55.5988,  55.5988,   5.2026, 344.6817, 344.6817, 344.6817, 344.6817,\n",
      "        344.6817,  55.5988,  55.5988, 344.6817,  55.5988,  55.5988,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 344.6817,   5.2026,   5.2025, 344.6817,   5.2026,\n",
      "          5.2025, 344.6817,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        344.6817, 344.6817, 344.6817, 344.6817,  55.5988,  55.5988,  55.5988,\n",
      "         55.5988, 344.6817, 344.6817, 344.6817,  55.5988,  55.5988,  55.5988,\n",
      "         55.5988,   5.2026,  55.5988,  55.5988,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 529 was 93.4%\n",
      "tensor([0.0000e+00, 3.6064e-06, 2.9929e-06, 2.7924e-06, 2.8246e-06, 1.1055e-08,\n",
      "        7.8376e-09, 7.2357e-09, 7.2707e-09, 5.0980e-06, 4.9762e-06, 5.0004e-06,\n",
      "        1.6839e-04, 1.4638e-04, 1.4667e-04, 4.7157e-06, 4.7407e-06, 9.3484e-05,\n",
      "        9.3735e-05, 4.1070e-01, 4.1473e-01, 1.6169e+00, 1.6129e+00, 4.6195e-06,\n",
      "        9.2398e-05, 3.9526e-01, 1.6324e+00, 3.5455e-01, 1.6737e+00, 4.5323e-01,\n",
      "        9.3463e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([182.5909, 217.7479, 232.3083, 229.7484,   7.9774,   7.9775,   7.9769,\n",
      "        345.1029, 345.1029, 345.1029,   7.9779,   7.9779, 345.1029, 345.1029,\n",
      "        345.1029, 345.1029, 345.1029,  55.6779,  55.6779,   7.9764, 345.1029,\n",
      "        345.1029, 345.1029, 345.1029, 345.1029,  55.6779,  55.6779, 345.1029,\n",
      "         55.6779,  55.6779,   5.2026, 345.1029, 345.1029, 345.1029, 345.1029,\n",
      "        345.1029,  55.6779,  55.6779, 345.1029,  55.6779,  55.6779,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 345.1029,   5.2026,   5.2025, 345.1029,   5.2026,\n",
      "          5.2025, 345.1029,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        345.1029, 345.1029, 345.1029, 345.1029,  55.6779,  55.6779,  55.6779,\n",
      "         55.6779, 345.1029, 345.1029, 345.1029,  55.6779,  55.6779,  55.6779,\n",
      "         55.6779,   5.2026,  55.6779,  55.6779,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 530 was 93.4%\n",
      "tensor([9.2644e-23, 3.6000e-06, 2.9882e-06, 2.7873e-06, 2.8212e-06, 1.0977e-08,\n",
      "        7.7832e-09, 7.1879e-09, 7.2247e-09, 5.0876e-06, 4.9646e-06, 4.9909e-06,\n",
      "        1.6673e-04, 1.4504e-04, 1.4536e-04, 4.7052e-06, 4.7310e-06, 9.2648e-05,\n",
      "        9.2898e-05, 4.0977e-01, 4.1399e-01, 1.6137e+00, 1.6094e+00, 4.6109e-06,\n",
      "        9.1603e-05, 3.9437e-01, 1.6291e+00, 3.5386e-01, 1.6702e+00, 4.5228e-01,\n",
      "        9.3477e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([182.8609, 218.0418, 232.6617, 229.9611,   7.9760,   7.9749,   7.9755,\n",
      "        345.5242, 345.5242, 345.5242,   7.9749,   7.9739, 345.5242, 345.5242,\n",
      "        345.5242, 345.5242, 345.5242,  55.7571,  55.7571,   7.9756, 345.5242,\n",
      "        345.5242, 345.5242, 345.5242, 345.5242,  55.7571,  55.7571, 345.5242,\n",
      "         55.7571,  55.7571,   5.2026, 345.5242, 345.5242, 345.5242, 345.5242,\n",
      "        345.5242,  55.7571,  55.7571, 345.5242,  55.7571,  55.7571,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 345.5242,   5.2026,   5.2025, 345.5242,   5.2026,\n",
      "          5.2025, 345.5242,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        345.5242, 345.5242, 345.5242, 345.5242,  55.7571,  55.7571,  55.7571,\n",
      "         55.7571, 345.5242, 345.5242, 345.5242,  55.7571,  55.7571,  55.7571,\n",
      "         55.7571,   5.2026,  55.7571,  55.7571,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 531 was 93.4%\n",
      "tensor([0.0000e+00, 3.5938e-06, 2.9833e-06, 2.7822e-06, 2.8179e-06, 1.0901e-08,\n",
      "        7.7295e-09, 7.1411e-09, 7.1795e-09, 5.0760e-06, 4.9542e-06, 4.9810e-06,\n",
      "        1.6506e-04, 1.4377e-04, 1.4408e-04, 4.6952e-06, 4.7230e-06, 9.1829e-05,\n",
      "        9.2101e-05, 4.0879e-01, 4.1323e-01, 1.6105e+00, 1.6060e+00, 4.6006e-06,\n",
      "        9.0794e-05, 3.9360e-01, 1.6257e+00, 3.5313e-01, 1.6667e+00, 4.5134e-01,\n",
      "        9.3490e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([183.1309, 218.3356, 233.0142, 230.1741,   7.9717,   7.9735,   7.9730,\n",
      "        345.9454, 345.9454, 345.9454,   7.9735,   7.9730, 345.9454, 345.9454,\n",
      "        345.9454, 345.9454, 345.9454,  55.8363,  55.8363,   7.9728, 345.9454,\n",
      "        345.9454, 345.9454, 345.9454, 345.9454,  55.8363,  55.8363, 345.9454,\n",
      "         55.8363,  55.8363,   5.2026, 345.9454, 345.9454, 345.9454, 345.9454,\n",
      "        345.9454,  55.8363,  55.8363, 345.9454,  55.8363,  55.8363,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 345.9454,   5.2026,   5.2025, 345.9454,   5.2026,\n",
      "          5.2025, 345.9454,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        345.9454, 345.9454, 345.9454, 345.9454,  55.8363,  55.8363,  55.8363,\n",
      "         55.8363, 345.9454, 345.9454, 345.9454,  55.8363,  55.8363,  55.8363,\n",
      "         55.8363,   5.2026,  55.8363,  55.8363,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 532 was 93.5%\n",
      "tensor([1.1250e-22, 3.5874e-06, 2.9787e-06, 2.7777e-06, 2.8150e-06, 1.0802e-08,\n",
      "        7.6612e-09, 7.0812e-09, 7.1210e-09, 5.0663e-06, 4.9424e-06, 4.9708e-06,\n",
      "        1.6308e-04, 1.4215e-04, 1.4247e-04, 4.6844e-06, 4.7129e-06, 9.0844e-05,\n",
      "        9.1115e-05, 4.0782e-01, 4.1243e-01, 1.6070e+00, 1.6024e+00, 4.5920e-06,\n",
      "        8.9878e-05, 3.9278e-01, 1.6222e+00, 3.5246e-01, 1.6631e+00, 4.5040e-01,\n",
      "        9.3505e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([183.4010, 218.6298, 233.3628, 230.3896,   7.9701,   7.9695,   7.9706,\n",
      "        346.3667, 346.3667, 346.3667,   7.9707,   7.9712, 346.3667, 346.3667,\n",
      "        346.3667, 346.3667, 346.3667,  55.9154,  55.9154,   7.9720, 346.3667,\n",
      "        346.3667, 346.3667, 346.3667, 346.3667,  55.9154,  55.9154, 346.3667,\n",
      "         55.9154,  55.9154,   5.2026, 346.3667, 346.3667, 346.3667, 346.3667,\n",
      "        346.3667,  55.9154,  55.9154, 346.3667,  55.9154,  55.9154,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 346.3667,   5.2026,   5.2025, 346.3667,   5.2026,\n",
      "          5.2025, 346.3667,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        346.3667, 346.3667, 346.3667, 346.3667,  55.9154,  55.9154,  55.9154,\n",
      "         55.9154, 346.3667, 346.3667, 346.3667,  55.9154,  55.9154,  55.9154,\n",
      "         55.9154,   5.2026,  55.9154,  55.9154,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 533 was 93.5%\n",
      "tensor([4.6322e-23, 3.5809e-06, 2.9738e-06, 2.7726e-06, 2.8118e-06, 1.0727e-08,\n",
      "        7.6088e-09, 7.0353e-09, 7.0764e-09, 5.0547e-06, 4.9322e-06, 4.9616e-06,\n",
      "        1.6144e-04, 1.4089e-04, 1.4122e-04, 4.6743e-06, 4.7042e-06, 9.0053e-05,\n",
      "        9.0334e-05, 4.0679e-01, 4.1169e-01, 1.6039e+00, 1.5990e+00, 4.5820e-06,\n",
      "        8.9084e-05, 3.9198e-01, 1.6189e+00, 3.5181e-01, 1.6596e+00, 4.4948e-01,\n",
      "        9.3518e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([183.6711, 218.9239, 233.7108, 230.6052,   7.9680,   7.9688,   7.9687,\n",
      "        346.7879, 346.7879, 346.7879,   7.9689,   7.9683, 346.7879, 346.7879,\n",
      "        346.7879, 346.7879, 346.7879,  55.9946,  55.9946,   7.9681, 346.7879,\n",
      "        346.7879, 346.7879, 346.7879, 346.7879,  55.9946,  55.9946, 346.7879,\n",
      "         55.9946,  55.9946,   5.2026, 346.7879, 346.7879, 346.7879, 346.7879,\n",
      "        346.7879,  55.9946,  55.9946, 346.7879,  55.9946,  55.9946,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 346.7879,   5.2026,   5.2025, 346.7879,   5.2026,\n",
      "          5.2025, 346.7879,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        346.7879, 346.7879, 346.7879, 346.7879,  55.9946,  55.9946,  55.9946,\n",
      "         55.9946, 346.7879, 346.7879, 346.7879,  55.9946,  55.9946,  55.9946,\n",
      "         55.9946,   5.2026,  55.9946,  55.9946,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 534 was 93.5%\n",
      "tensor([1.9852e-23, 3.5746e-06, 2.9689e-06, 2.7676e-06, 2.8082e-06, 1.0651e-08,\n",
      "        7.5545e-09, 6.9875e-09, 7.0300e-09, 5.0443e-06, 4.9203e-06, 4.9509e-06,\n",
      "        1.5984e-04, 1.3959e-04, 1.3992e-04, 4.6637e-06, 4.6950e-06, 8.9208e-05,\n",
      "        8.9500e-05, 4.0589e-01, 4.1092e-01, 1.6006e+00, 1.5955e+00, 4.5732e-06,\n",
      "        8.8295e-05, 3.9115e-01, 1.6155e+00, 3.5106e-01, 1.6562e+00, 4.4851e-01,\n",
      "        9.3532e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([183.9412, 219.2179, 234.0581, 230.8212,   7.9664,   7.9659,   7.9664,\n",
      "        347.2091, 347.2091, 347.2091,   7.9649,   7.9665, 347.2091, 347.2091,\n",
      "        347.2091, 347.2091, 347.2091,  56.0737,  56.0737,   7.9673, 347.2091,\n",
      "        347.2091, 347.2091, 347.2091, 347.2091,  56.0737,  56.0737, 347.2091,\n",
      "         56.0737,  56.0737,   5.2026, 347.2091, 347.2091, 347.2091, 347.2091,\n",
      "        347.2091,  56.0737,  56.0737, 347.2091,  56.0737,  56.0737,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 347.2091,   5.2026,   5.2025, 347.2091,   5.2026,\n",
      "          5.2025, 347.2091,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        347.2091, 347.2091, 347.2091, 347.2091,  56.0737,  56.0737,  56.0737,\n",
      "         56.0737, 347.2091, 347.2091, 347.2091,  56.0737,  56.0737,  56.0737,\n",
      "         56.0737,   5.2026,  56.0737,  56.0737,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 535 was 93.5%\n",
      "tensor([0.0000e+00, 3.5682e-06, 2.9640e-06, 2.7626e-06, 2.8050e-06, 1.0577e-08,\n",
      "        7.5024e-09, 6.9417e-09, 6.9859e-09, 5.0327e-06, 4.9098e-06, 4.9418e-06,\n",
      "        1.5824e-04, 1.3834e-04, 1.3871e-04, 4.6546e-06, 4.6861e-06, 8.8429e-05,\n",
      "        8.8720e-05, 4.0488e-01, 4.1018e-01, 1.5975e+00, 1.5922e+00, 4.5633e-06,\n",
      "        8.7507e-05, 3.9037e-01, 1.6122e+00, 3.5039e-01, 1.6527e+00, 4.4760e-01,\n",
      "        9.3545e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([184.2113, 219.5117, 234.4048, 231.0374,   7.9637,   7.9647,   7.9645,\n",
      "        347.6303, 347.6303, 347.6303,   7.9641,   7.9635, 347.6303, 347.6303,\n",
      "        347.6303, 347.6303, 347.6303,  56.1529,  56.1529,   7.9634, 347.6303,\n",
      "        347.6303, 347.6303, 347.6303, 347.6303,  56.1529,  56.1529, 347.6303,\n",
      "         56.1529,  56.1529,   5.2026, 347.6303, 347.6303, 347.6303, 347.6303,\n",
      "        347.6303,  56.1529,  56.1529, 347.6303,  56.1529,  56.1529,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 347.6303,   5.2026,   5.2025, 347.6303,   5.2026,\n",
      "          5.2025, 347.6303,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        347.6303, 347.6303, 347.6303, 347.6303,  56.1529,  56.1529,  56.1529,\n",
      "         56.1529, 347.6303, 347.6303, 347.6303,  56.1529,  56.1529,  56.1529,\n",
      "         56.1529,   5.2026,  56.1529,  56.1529,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 536 was 93.5%\n",
      "tensor([0.0000e+00, 3.5621e-06, 2.9592e-06, 2.7577e-06, 2.8014e-06, 1.0501e-08,\n",
      "        7.4488e-09, 6.8945e-09, 6.9396e-09, 5.0229e-06, 4.8983e-06, 4.9313e-06,\n",
      "        1.5668e-04, 1.3706e-04, 1.3741e-04, 4.6434e-06, 4.6771e-06, 8.7601e-05,\n",
      "        8.7900e-05, 4.0399e-01, 4.0941e-01, 1.5943e+00, 1.5888e+00, 4.5548e-06,\n",
      "        8.6738e-05, 3.8955e-01, 1.6088e+00, 3.4966e-01, 1.6493e+00, 4.4665e-01,\n",
      "        9.3558e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([184.4814, 219.8055, 234.7507, 231.2539,   7.9615,   7.9606,   7.9616,\n",
      "        348.0515, 348.0515, 348.0515,   7.9618,   7.9622, 348.0515, 348.0515,\n",
      "        348.0515, 348.0515, 348.0515,  56.2321,  56.2321,   7.9626, 348.0515,\n",
      "        348.0515, 348.0515, 348.0515, 348.0515,  56.2321,  56.2321, 348.0515,\n",
      "         56.2321,  56.2321,   5.2026, 348.0515, 348.0515, 348.0515, 348.0515,\n",
      "        348.0515,  56.2321,  56.2321, 348.0515,  56.2321,  56.2321,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 348.0515,   5.2026,   5.2025, 348.0515,   5.2026,\n",
      "          5.2025, 348.0515,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        348.0515, 348.0515, 348.0515, 348.0515,  56.2321,  56.2321,  56.2321,\n",
      "         56.2321, 348.0515, 348.0515, 348.0515,  56.2321,  56.2321,  56.2321,\n",
      "         56.2321,   5.2026,  56.2321,  56.2321,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 537 was 93.5%\n",
      "tensor([0.0000e+00, 3.5556e-06, 2.9544e-06, 2.7527e-06, 2.7982e-06, 1.0426e-08,\n",
      "        7.3966e-09, 6.8485e-09, 6.8949e-09, 5.0117e-06, 4.8882e-06, 4.9223e-06,\n",
      "        1.5508e-04, 1.3581e-04, 1.3617e-04, 4.6335e-06, 4.6680e-06, 8.6820e-05,\n",
      "        8.7127e-05, 4.0299e-01, 4.0866e-01, 1.5912e+00, 1.5855e+00, 4.5449e-06,\n",
      "        8.5958e-05, 3.8873e-01, 1.6055e+00, 3.4904e-01, 1.6458e+00, 4.4573e-01,\n",
      "        9.3571e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([184.7515, 220.0992, 235.0958, 231.4707,   7.9593,   7.9598,   7.9596,\n",
      "        348.4727, 348.4727, 348.4727,   7.9600,   7.9593, 348.4727, 348.4727,\n",
      "        348.4727, 348.4727, 348.4727,  56.3112,  56.3112,   7.9587, 348.4727,\n",
      "        348.4727, 348.4727, 348.4727, 348.4727,  56.3112,  56.3112, 348.4727,\n",
      "         56.3112,  56.3112,   5.2026, 348.4727, 348.4727, 348.4727, 348.4727,\n",
      "        348.4727,  56.3112,  56.3112, 348.4727,  56.3112,  56.3112,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 348.4727,   5.2026,   5.2025, 348.4727,   5.2026,\n",
      "          5.2025, 348.4727,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        348.4727, 348.4727, 348.4727, 348.4727,  56.3112,  56.3112,  56.3112,\n",
      "         56.3112, 348.4727, 348.4727, 348.4727,  56.3112,  56.3112,  56.3112,\n",
      "         56.3112,   5.2026,  56.3112,  56.3112,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 538 was 93.5%\n",
      "tensor([1.3235e-23, 3.5493e-06, 2.9496e-06, 2.7478e-06, 2.7947e-06, 1.0352e-08,\n",
      "        7.3437e-09, 6.8017e-09, 6.8492e-09, 5.0013e-06, 4.8765e-06, 4.9118e-06,\n",
      "        1.5355e-04, 1.3456e-04, 1.3491e-04, 4.6231e-06, 4.6590e-06, 8.6006e-05,\n",
      "        8.6319e-05, 4.0209e-01, 4.0789e-01, 1.5879e+00, 1.5821e+00, 4.5364e-06,\n",
      "        8.5188e-05, 3.8792e-01, 1.6022e+00, 3.4830e-01, 1.6424e+00, 4.4479e-01,\n",
      "        9.3585e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([185.0216, 220.3928, 235.4403, 231.6878,   7.9572,   7.9569,   7.9572,\n",
      "        348.8938, 348.8938, 348.8938,   7.9560,   7.9580, 348.8938, 348.8938,\n",
      "        348.8938, 348.8938, 348.8938,  56.3904,  56.3904,   7.9579, 348.8938,\n",
      "        348.8938, 348.8938, 348.8938, 348.8938,  56.3904,  56.3904, 348.8938,\n",
      "         56.3904,  56.3904,   5.2026, 348.8938, 348.8938, 348.8938, 348.8938,\n",
      "        348.8938,  56.3904,  56.3904, 348.8938,  56.3904,  56.3904,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 348.8938,   5.2026,   5.2025, 348.8938,   5.2026,\n",
      "          5.2025, 348.8938,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        348.8938, 348.8938, 348.8938, 348.8938,  56.3904,  56.3904,  56.3904,\n",
      "         56.3904, 348.8938, 348.8938, 348.8938,  56.3904,  56.3904,  56.3904,\n",
      "         56.3904,   5.2026,  56.3904,  56.3904,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 539 was 93.5%\n",
      "tensor([0.0000e+00, 3.5430e-06, 2.9448e-06, 2.7429e-06, 2.7915e-06, 1.0279e-08,\n",
      "        7.2921e-09, 6.7564e-09, 6.8053e-09, 4.9903e-06, 4.8658e-06, 4.9028e-06,\n",
      "        1.5200e-04, 1.3333e-04, 1.3372e-04, 4.6139e-06, 4.6499e-06, 8.5242e-05,\n",
      "        8.5545e-05, 4.0109e-01, 4.0716e-01, 1.5849e+00, 1.5788e+00, 4.5267e-06,\n",
      "        8.4425e-05, 3.8714e-01, 1.5989e+00, 3.4765e-01, 1.6390e+00, 4.4388e-01,\n",
      "        9.3598e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([185.2917, 220.6864, 235.7841, 231.9052,   7.9545,   7.9556,   7.9553,\n",
      "        349.3150, 349.3150, 349.3150,   7.9551,   7.9539, 349.3150, 349.3150,\n",
      "        349.3150, 349.3150, 349.3150,  56.4695,  56.4695,   7.9550, 349.3150,\n",
      "        349.3150, 349.3150, 349.3150, 349.3150,  56.4695,  56.4695, 349.3150,\n",
      "         56.4695,  56.4695,   5.2026, 349.3150, 349.3150, 349.3150, 349.3150,\n",
      "        349.3150,  56.4695,  56.4695, 349.3150,  56.4695,  56.4695,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 349.3150,   5.2026,   5.2025, 349.3150,   5.2026,\n",
      "          5.2025, 349.3150,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        349.3150, 349.3150, 349.3150, 349.3150,  56.4695,  56.4695,  56.4695,\n",
      "         56.4695, 349.3150, 349.3150, 349.3150,  56.4695,  56.4695,  56.4695,\n",
      "         56.4695,   5.2026,  56.4695,  56.4695,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 540 was 93.6%\n",
      "tensor([1.9852e-23, 3.5369e-06, 2.9399e-06, 2.7381e-06, 2.7880e-06, 1.0204e-08,\n",
      "        7.2390e-09, 6.7098e-09, 6.7595e-09, 4.9802e-06, 4.8548e-06, 4.8923e-06,\n",
      "        1.5046e-04, 1.3209e-04, 1.3246e-04, 4.6032e-06, 4.6415e-06, 8.4432e-05,\n",
      "        8.4753e-05, 4.0021e-01, 4.0636e-01, 1.5817e+00, 1.5755e+00, 4.5178e-06,\n",
      "        8.3662e-05, 3.8636e-01, 1.5956e+00, 3.4693e-01, 1.6356e+00, 4.4295e-01,\n",
      "        9.3611e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([185.5618, 220.9798, 236.1272, 232.1229,   7.9523,   7.9515,   7.9523,\n",
      "        349.7362, 349.7362, 349.7362,   7.9528,   7.9531, 349.7362, 349.7362,\n",
      "        349.7362, 349.7362, 349.7362,  56.5487,  56.5487,   7.9537, 349.7362,\n",
      "        349.7362, 349.7362, 349.7362, 349.7362,  56.5487,  56.5487, 349.7362,\n",
      "         56.5487,  56.5487,   5.2026, 349.7362, 349.7362, 349.7362, 349.7362,\n",
      "        349.7362,  56.5487,  56.5487, 349.7362,  56.5487,  56.5487,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 349.7362,   5.2026,   5.2025, 349.7362,   5.2026,\n",
      "          5.2025, 349.7362,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        349.7362, 349.7362, 349.7362, 349.7362,  56.5487,  56.5487,  56.5487,\n",
      "         56.5487, 349.7362, 349.7362, 349.7362,  56.5487,  56.5487,  56.5487,\n",
      "         56.5487,   5.2026,  56.5487,  56.5487,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 541 was 93.6%\n",
      "tensor([0.0000e+00, 3.5305e-06, 2.9352e-06, 2.7332e-06, 2.7847e-06, 1.0131e-08,\n",
      "        7.1880e-09, 6.6644e-09, 6.7154e-09, 4.9692e-06, 4.8449e-06, 4.8834e-06,\n",
      "        1.4893e-04, 1.3088e-04, 1.3126e-04, 4.5933e-06, 4.6322e-06, 8.3676e-05,\n",
      "        8.4001e-05, 3.9922e-01, 4.0562e-01, 1.5786e+00, 1.5722e+00, 4.5081e-06,\n",
      "        8.2902e-05, 3.8555e-01, 1.5924e+00, 3.4631e-01, 1.6321e+00, 4.4204e-01,\n",
      "        9.3624e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([185.8319, 221.2732, 236.4696, 232.3409,   7.9501,   7.9507,   7.9504,\n",
      "        350.1573, 350.1573, 350.1573,   7.9509,   7.9501, 350.1573, 350.1573,\n",
      "        350.1573, 350.1573, 350.1573,  56.6278,  56.6278,   7.9497, 350.1573,\n",
      "        350.1573, 350.1573, 350.1573, 350.1573,  56.6278,  56.6278, 350.1573,\n",
      "         56.6278,  56.6278,   5.2026, 350.1573, 350.1573, 350.1573, 350.1573,\n",
      "        350.1573,  56.6278,  56.6278, 350.1573,  56.6278,  56.6278,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 350.1573,   5.2026,   5.2025, 350.1573,   5.2026,\n",
      "          5.2025, 350.1573,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        350.1573, 350.1573, 350.1573, 350.1573,  56.6278,  56.6278,  56.6278,\n",
      "         56.6278, 350.1573, 350.1573, 350.1573,  56.6278,  56.6278,  56.6278,\n",
      "         56.6278,   5.2026,  56.6278,  56.6278,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 542 was 93.6%\n",
      "tensor([0.0000e+00, 3.5243e-06, 2.9304e-06, 2.7284e-06, 2.7812e-06, 1.0058e-08,\n",
      "        7.1359e-09, 6.6183e-09, 6.6701e-09, 4.9588e-06, 4.8333e-06, 4.8729e-06,\n",
      "        1.4745e-04, 1.2966e-04, 1.3003e-04, 4.5830e-06, 4.6233e-06, 8.2880e-05,\n",
      "        8.3211e-05, 3.9835e-01, 4.0485e-01, 1.5754e+00, 1.5688e+00, 4.4998e-06,\n",
      "        8.2151e-05, 3.8474e-01, 1.5891e+00, 3.4559e-01, 1.6288e+00, 4.4111e-01,\n",
      "        9.3637e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([186.1020, 221.5665, 236.8113, 232.5591,   7.9480,   7.9477,   7.9480,\n",
      "        350.5784, 350.5784, 350.5784,   7.9469,   7.9488, 350.5784, 350.5784,\n",
      "        350.5784, 350.5784, 350.5784,  56.7070,  56.7070,   7.9489, 350.5784,\n",
      "        350.5784, 350.5784, 350.5784, 350.5784,  56.7070,  56.7070, 350.5784,\n",
      "         56.7070,  56.7070,   5.2026, 350.5784, 350.5784, 350.5784, 350.5784,\n",
      "        350.5784,  56.7070,  56.7070, 350.5784,  56.7070,  56.7070,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 350.5784,   5.2026,   5.2025, 350.5784,   5.2026,\n",
      "          5.2025, 350.5784,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        350.5784, 350.5784, 350.5784, 350.5784,  56.7070,  56.7070,  56.7070,\n",
      "         56.7070, 350.5784, 350.5784, 350.5784,  56.7070,  56.7070,  56.7070,\n",
      "         56.7070,   5.2026,  56.7070,  56.7070,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 543 was 93.6%\n",
      "tensor([5.2751e-08, 3.5304e-06, 2.9367e-06, 2.7348e-06, 2.7891e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9479e-06, 4.8227e-06, 4.8641e-06,\n",
      "        1.4596e-04, 1.2847e-04, 1.2888e-04, 4.5740e-06, 4.6143e-06, 8.2144e-05,\n",
      "        8.2462e-05, 3.9735e-01, 4.0413e-01, 1.5723e+00, 1.5655e+00, 4.4901e-06,\n",
      "        8.1412e-05, 3.8397e-01, 1.5858e+00, 3.4494e-01, 1.6254e+00, 4.4021e-01,\n",
      "        9.3650e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([186.3721, 221.8597, 237.1524, 232.7776,   7.9446,   7.9464,   7.9466,\n",
      "        350.9996, 350.9996, 350.9996,   7.9460,   7.9457, 350.9996, 350.9996,\n",
      "        350.9996, 350.9996, 350.9996,  56.7862,  56.7862,   7.9449, 350.9996,\n",
      "        350.9996, 350.9996, 350.9996, 350.9996,  56.7862,  56.7862, 350.9996,\n",
      "         56.7862,  56.7862,   5.2026, 350.9996, 350.9996, 350.9996, 350.9996,\n",
      "        350.9996,  56.7862,  56.7862, 350.9996,  56.7862,  56.7862,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 350.9996,   5.2026,   5.2025, 350.9996,   5.2026,\n",
      "          5.2025, 350.9996,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        350.9996, 350.9996, 350.9996, 350.9996,  56.7862,  56.7862,  56.7862,\n",
      "         56.7862, 350.9996, 350.9996, 350.9996,  56.7862,  56.7862,  56.7862,\n",
      "         56.7862,   5.2026,  56.7862,  56.7862,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 544 was 93.6%\n",
      "tensor([5.2312e-08, 3.5244e-06, 2.9319e-06, 2.7300e-06, 2.7856e-06, 6.6174e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9388e-06, 4.8120e-06, 4.8537e-06,\n",
      "        1.4450e-04, 1.2728e-04, 1.2765e-04, 4.5633e-06, 4.6057e-06, 8.1357e-05,\n",
      "        8.1694e-05, 3.9648e-01, 4.0337e-01, 1.5692e+00, 1.5623e+00, 4.4820e-06,\n",
      "        8.0682e-05, 3.8320e-01, 1.5826e+00, 3.4422e-01, 1.6221e+00, 4.3930e-01,\n",
      "        9.3663e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([186.6423, 222.1529, 237.4927, 232.9966,   7.9430,   7.9435,   7.9424,\n",
      "        351.4207, 351.4207, 351.4207,   7.9436,   7.9439, 351.4207, 351.4207,\n",
      "        351.4207, 351.4207, 351.4207,  56.8653,  56.8653,   7.9441, 351.4207,\n",
      "        351.4207, 351.4207, 351.4207, 351.4207,  56.8653,  56.8653, 351.4207,\n",
      "         56.8653,  56.8653,   5.2026, 351.4207, 351.4207, 351.4207, 351.4207,\n",
      "        351.4207,  56.8653,  56.8653, 351.4207,  56.8653,  56.8653,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 351.4207,   5.2026,   5.2025, 351.4207,   5.2026,\n",
      "          5.2025, 351.4207,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        351.4207, 351.4207, 351.4207, 351.4207,  56.8653,  56.8653,  56.8653,\n",
      "         56.8653, 351.4207, 351.4207, 351.4207,  56.8653,  56.8653,  56.8653,\n",
      "         56.8653,   5.2026,  56.8653,  56.8653,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 545 was 93.6%\n",
      "tensor([5.1874e-08, 3.5178e-06, 2.9270e-06, 2.7251e-06, 2.7820e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9273e-06, 4.8014e-06, 4.8450e-06,\n",
      "        1.4299e-04, 1.2607e-04, 1.2647e-04, 4.5536e-06, 4.5964e-06, 8.0613e-05,\n",
      "        8.0938e-05, 3.9555e-01, 4.0259e-01, 1.5661e+00, 1.5590e+00, 4.4720e-06,\n",
      "        7.9926e-05, 3.8238e-01, 1.5793e+00, 3.4360e-01, 1.6186e+00, 4.3838e-01,\n",
      "        9.3676e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([186.9125, 222.4460, 237.8324, 233.2157,   7.9407,   7.9415,   7.9416,\n",
      "        351.8418, 351.8418, 351.8418,   7.9417,   7.9408, 351.8418, 351.8418,\n",
      "        351.8418, 351.8418, 351.8418,  56.9445,  56.9445,   7.9400, 351.8418,\n",
      "        351.8418, 351.8418, 351.8418, 351.8418,  56.9445,  56.9445, 351.8418,\n",
      "         56.9445,  56.9445,   5.2026, 351.8418, 351.8418, 351.8418, 351.8418,\n",
      "        351.8418,  56.9445,  56.9445, 351.8418,  56.9445,  56.9445,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 351.8418,   5.2026,   5.2025, 351.8418,   5.2026,\n",
      "          5.2025, 351.8418,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        351.8418, 351.8418, 351.8418, 351.8418,  56.9445,  56.9445,  56.9445,\n",
      "         56.9445, 351.8418, 351.8418, 351.8418,  56.9445,  56.9445,  56.9445,\n",
      "         56.9445,   5.2026,  56.9445,  56.9445,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 546 was 93.6%\n",
      "tensor([5.1446e-08, 3.5117e-06, 2.9223e-06, 2.7203e-06, 2.7786e-06, 1.4889e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9172e-06, 4.7908e-06, 4.8342e-06,\n",
      "        1.4158e-04, 1.2492e-04, 1.2529e-04, 4.5433e-06, 4.5882e-06, 7.9843e-05,\n",
      "        8.0191e-05, 3.9466e-01, 4.0185e-01, 1.5629e+00, 1.5557e+00, 4.4639e-06,\n",
      "        7.9203e-05, 3.8160e-01, 1.5761e+00, 3.4289e-01, 1.6153e+00, 4.3747e-01,\n",
      "        9.3689e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([187.1826, 222.7389, 238.1715, 233.4351,   7.9391,   7.9390,   7.9386,\n",
      "        352.2629, 352.2629, 352.2629,   7.9376,   7.9389, 352.2629, 352.2629,\n",
      "        352.2629, 352.2629, 352.2629,  57.0236,  57.0236,   7.9392, 352.2629,\n",
      "        352.2629, 352.2629, 352.2629, 352.2629,  57.0236,  57.0236, 352.2629,\n",
      "         57.0236,  57.0236,   5.2026, 352.2629, 352.2629, 352.2629, 352.2629,\n",
      "        352.2629,  57.0236,  57.0236, 352.2629,  57.0236,  57.0236,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 352.2629,   5.2026,   5.2025, 352.2629,   5.2026,\n",
      "          5.2025, 352.2629,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        352.2629, 352.2629, 352.2629, 352.2629,  57.0236,  57.0236,  57.0236,\n",
      "         57.0236, 352.2629, 352.2629, 352.2629,  57.0236,  57.0236,  57.0236,\n",
      "         57.0236,   5.2026,  57.0236,  57.0236,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 547 was 93.7%\n",
      "tensor([5.9557e-23, 3.4933e-06, 2.9067e-06, 2.7045e-06, 2.7644e-06, 9.7003e-09,\n",
      "        6.8822e-09, 6.3940e-09, 6.4505e-09, 4.9060e-06, 4.7800e-06, 4.8254e-06,\n",
      "        1.4011e-04, 1.2374e-04, 1.2416e-04, 4.5345e-06, 4.5790e-06, 7.9114e-05,\n",
      "        7.9445e-05, 3.9371e-01, 4.0111e-01, 1.5599e+00, 1.5524e+00, 4.4540e-06,\n",
      "        7.8465e-05, 3.8083e-01, 1.5729e+00, 3.4222e-01, 1.6119e+00, 4.3656e-01,\n",
      "        9.3702e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([187.4528, 223.0318, 238.5100, 233.6547,   7.9351,   7.9366,   7.9378,\n",
      "        352.6840, 352.6840, 352.6840,   7.9368,   7.9370, 352.6840, 352.6840,\n",
      "        352.6840, 352.6840, 352.6840,  57.1028,  57.1028,   7.9351, 352.6840,\n",
      "        352.6840, 352.6840, 352.6840, 352.6840,  57.1028,  57.1028, 352.6840,\n",
      "         57.1028,  57.1028,   5.2026, 352.6840, 352.6840, 352.6840, 352.6840,\n",
      "        352.6840,  57.1028,  57.1028, 352.6840,  57.1028,  57.1028,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 352.6840,   5.2026,   5.2025, 352.6840,   5.2026,\n",
      "          5.2025, 352.6840,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        352.6840, 352.6840, 352.6840, 352.6840,  57.1028,  57.1028,  57.1028,\n",
      "         57.1028, 352.6840, 352.6840, 352.6840,  57.1028,  57.1028,  57.1028,\n",
      "         57.1028,   5.2026,  57.1028,  57.1028,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 548 was 93.7%\n",
      "tensor([4.6322e-23, 3.4874e-06, 2.9021e-06, 2.6999e-06, 2.7612e-06, 9.6301e-09,\n",
      "        6.8327e-09, 6.3499e-09, 6.4069e-09, 4.8972e-06, 4.7699e-06, 4.8153e-06,\n",
      "        1.3873e-04, 1.2260e-04, 1.2297e-04, 4.5239e-06, 4.5705e-06, 7.8361e-05,\n",
      "        7.8714e-05, 3.9279e-01, 4.0040e-01, 1.5568e+00, 1.5492e+00, 4.4465e-06,\n",
      "        7.7769e-05, 3.8006e-01, 1.5697e+00, 3.4156e-01, 1.6087e+00, 4.3569e-01,\n",
      "        9.3715e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([187.7230, 223.3247, 238.8477, 233.8748,   7.9335,   7.9347,   7.9335,\n",
      "        353.1051, 353.1051, 353.1051,   7.9343,   7.9340, 353.1051, 353.1051,\n",
      "        353.1051, 353.1051, 353.1051,  57.1819,  57.1819,   7.9342, 353.1051,\n",
      "        353.1051, 353.1051, 353.1051, 353.1051,  57.1819,  57.1819, 353.1051,\n",
      "         57.1819,  57.1819,   5.2026, 353.1051, 353.1051, 353.1051, 353.1051,\n",
      "        353.1051,  57.1819,  57.1819, 353.1051,  57.1819,  57.1819,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 353.1051,   5.2026,   5.2025, 353.1051,   5.2026,\n",
      "          5.2025, 353.1051,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        353.1051, 353.1051, 353.1051, 353.1051,  57.1819,  57.1819,  57.1819,\n",
      "         57.1819, 353.1051, 353.1051, 353.1051,  57.1819,  57.1819,  57.1819,\n",
      "         57.1819,   5.2026,  57.1819,  57.1819,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 549 was 93.7%\n",
      "tensor([0.0000e+00, 3.4810e-06, 2.8972e-06, 2.6952e-06, 2.7576e-06, 9.5576e-09,\n",
      "        6.7814e-09, 6.3043e-09, 6.3623e-09, 4.8856e-06, 4.7588e-06, 4.8062e-06,\n",
      "        1.3726e-04, 1.2141e-04, 1.2182e-04, 4.5144e-06, 4.5610e-06, 7.7622e-05,\n",
      "        7.7956e-05, 3.9192e-01, 3.9956e-01, 1.5537e+00, 1.5460e+00, 4.4364e-06,\n",
      "        7.7020e-05, 3.7927e-01, 1.5664e+00, 3.4090e-01, 1.6052e+00, 4.3476e-01,\n",
      "        9.3728e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([187.9932, 223.6175, 239.1848, 234.0950,   7.9318,   7.9304,   7.9321,\n",
      "        353.5261, 353.5261, 353.5261,   7.9313,   7.9320, 353.5261, 353.5261,\n",
      "        353.5261, 353.5261, 353.5261,  57.2611,  57.2611,   7.9323, 353.5261,\n",
      "        353.5261, 353.5261, 353.5261, 353.5261,  57.2611,  57.2611, 353.5261,\n",
      "         57.2611,  57.2611,   5.2026, 353.5261, 353.5261, 353.5261, 353.5261,\n",
      "        353.5261,  57.2611,  57.2611, 353.5261,  57.2611,  57.2611,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 353.5261,   5.2026,   5.2025, 353.5261,   5.2026,\n",
      "          5.2025, 353.5261,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        353.5261, 353.5261, 353.5261, 353.5261,  57.2611,  57.2611,  57.2611,\n",
      "         57.2611, 353.5261, 353.5261, 353.5261,  57.2611,  57.2611,  57.2611,\n",
      "         57.2611,   5.2026,  57.2611,  57.2611,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 550 was 93.7%\n",
      "tensor([0.0000e+00, 3.4749e-06, 2.8925e-06, 2.6904e-06, 2.7543e-06, 9.4887e-09,\n",
      "        6.7325e-09, 6.2609e-09, 6.3197e-09, 4.8747e-06, 4.7493e-06, 4.7965e-06,\n",
      "        1.3586e-04, 1.2029e-04, 1.2069e-04, 4.5048e-06, 4.5528e-06, 7.6898e-05,\n",
      "        7.7249e-05, 3.9096e-01, 3.9886e-01, 1.5506e+00, 1.5427e+00, 4.4272e-06,\n",
      "        7.6304e-05, 3.7849e-01, 1.5632e+00, 3.4025e-01, 1.6019e+00, 4.3387e-01,\n",
      "        9.3741e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([188.2635, 223.9102, 239.5214, 234.3155,   7.9290,   7.9296,   7.9289,\n",
      "        353.9472, 353.9472, 353.9472,   7.9299,   7.9301, 353.9472, 353.9472,\n",
      "        353.9472, 353.9472, 353.9472,  57.3402,  57.3402,   7.9282, 353.9472,\n",
      "        353.9472, 353.9472, 353.9472, 353.9472,  57.3402,  57.3402, 353.9472,\n",
      "         57.3402,  57.3402,   5.2026, 353.9472, 353.9472, 353.9472, 353.9472,\n",
      "        353.9472,  57.3402,  57.3402, 353.9472,  57.3402,  57.3402,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 353.9472,   5.2026,   5.2025, 353.9472,   5.2026,\n",
      "          5.2025, 353.9472,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        353.9472, 353.9472, 353.9472, 353.9472,  57.3402,  57.3402,  57.3402,\n",
      "         57.3402, 353.9472, 353.9472, 353.9472,  57.3402,  57.3402,  57.3402,\n",
      "         57.3402,   5.2026,  57.3402,  57.3402,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 551 was 93.7%\n",
      "tensor([0.0000e+00, 3.4688e-06, 2.8880e-06, 2.6858e-06, 2.7509e-06, 9.4187e-09,\n",
      "        6.6829e-09, 6.2168e-09, 6.2760e-09, 4.8653e-06, 4.7378e-06, 4.7872e-06,\n",
      "        1.3449e-04, 1.1914e-04, 1.1955e-04, 4.4949e-06, 4.5435e-06, 7.6170e-05,\n",
      "        7.6503e-05, 3.9011e-01, 3.9810e-01, 1.5475e+00, 1.5395e+00, 4.4191e-06,\n",
      "        7.5606e-05, 3.7768e-01, 1.5601e+00, 3.3959e-01, 1.5986e+00, 4.3297e-01,\n",
      "        9.3754e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([188.5337, 224.2029, 239.8574, 234.5362,   7.9268,   7.9271,   7.9276,\n",
      "        354.3683, 354.3683, 354.3683,   7.9269,   7.9258, 354.3683, 354.3683,\n",
      "        354.3683, 354.3683, 354.3683,  57.4194,  57.4194,   7.9273, 354.3683,\n",
      "        354.3683, 354.3683, 354.3683, 354.3683,  57.4194,  57.4194, 354.3683,\n",
      "         57.4194,  57.4194,   5.2026, 354.3683, 354.3683, 354.3683, 354.3683,\n",
      "        354.3683,  57.4194,  57.4194, 354.3683,  57.4194,  57.4194,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 354.3683,   5.2026,   5.2025, 354.3683,   5.2026,\n",
      "          5.2025, 354.3683,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        354.3683, 354.3683, 354.3683, 354.3683,  57.4194,  57.4194,  57.4194,\n",
      "         57.4194, 354.3683, 354.3683, 354.3683,  57.4194,  57.4194,  57.4194,\n",
      "         57.4194,   5.2026,  57.4194,  57.4194,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 552 was 93.7%\n",
      "tensor([1.9852e-23, 3.4627e-06, 2.8831e-06, 2.6811e-06, 2.7475e-06, 9.3493e-09,\n",
      "        6.6330e-09, 6.1731e-09, 6.2327e-09, 4.8545e-06, 4.7277e-06, 4.7771e-06,\n",
      "        1.3308e-04, 1.1804e-04, 1.1842e-04, 4.4852e-06, 4.5358e-06, 7.5436e-05,\n",
      "        7.5788e-05, 3.8918e-01, 3.9734e-01, 1.5445e+00, 1.5363e+00, 4.4095e-06,\n",
      "        7.4892e-05, 3.7697e-01, 1.5568e+00, 3.3889e-01, 1.5953e+00, 4.3208e-01,\n",
      "        9.3767e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([188.8037, 224.4956, 240.1929, 234.7574,   7.9246,   7.9252,   7.9233,\n",
      "        354.7893, 354.7893, 354.7893,   7.9249,   7.9249, 354.7893, 354.7893,\n",
      "        354.7893, 354.7893, 354.7893,  57.4985,  57.4985,   7.9244, 354.7893,\n",
      "        354.7893, 354.7893, 354.7893, 354.7893,  57.4985,  57.4985, 354.7893,\n",
      "         57.4985,  57.4985,   5.2026, 354.7893, 354.7893, 354.7893, 354.7893,\n",
      "        354.7893,  57.4985,  57.4985, 354.7893,  57.4985,  57.4985,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 354.7893,   5.2026,   5.2025, 354.7893,   5.2026,\n",
      "          5.2025, 354.7893,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        354.7893, 354.7893, 354.7893, 354.7893,  57.4985,  57.4985,  57.4985,\n",
      "         57.4985, 354.7893, 354.7893, 354.7893,  57.4985,  57.4985,  57.4985,\n",
      "         57.4985,   5.2026,  57.4985,  57.4985,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 553 was 93.7%\n",
      "tensor([3.9705e-23, 3.4566e-06, 2.8786e-06, 2.6765e-06, 2.7441e-06, 9.2801e-09,\n",
      "        6.5845e-09, 6.1295e-09, 6.1898e-09, 4.8443e-06, 4.7169e-06, 4.7687e-06,\n",
      "        1.3173e-04, 1.1690e-04, 1.1731e-04, 4.4757e-06, 4.5261e-06, 7.4739e-05,\n",
      "        7.5065e-05, 3.8832e-01, 3.9658e-01, 1.5414e+00, 1.5331e+00, 4.4009e-06,\n",
      "        7.4194e-05, 3.7616e-01, 1.5537e+00, 3.3825e-01, 1.5920e+00, 4.3118e-01,\n",
      "        9.3779e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([189.0736, 224.7883, 240.5278, 234.9788,   7.9223,   7.9208,   7.9225,\n",
      "        355.2103, 355.2103, 355.2103,   7.9224,   7.9218, 355.2103, 355.2103,\n",
      "        355.2103, 355.2103, 355.2103,  57.5777,  57.5777,   7.9229, 355.2103,\n",
      "        355.2103, 355.2103, 355.2103, 355.2103,  57.5777,  57.5777, 355.2103,\n",
      "         57.5777,  57.5777,   5.2026, 355.2103, 355.2103, 355.2103, 355.2103,\n",
      "        355.2103,  57.5777,  57.5777, 355.2103,  57.5777,  57.5777,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 355.2103,   5.2026,   5.2025, 355.2103,   5.2026,\n",
      "          5.2025, 355.2103,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        355.2103, 355.2103, 355.2103, 355.2103,  57.5777,  57.5777,  57.5777,\n",
      "         57.5777, 355.2103, 355.2103, 355.2103,  57.5777,  57.5777,  57.5777,\n",
      "         57.5777,   5.2026,  57.5777,  57.5777,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 554 was 93.7%\n",
      "tensor([1.0588e-22, 3.4505e-06, 2.8739e-06, 2.6719e-06, 2.7408e-06, 9.2119e-09,\n",
      "        6.5360e-09, 6.0863e-09, 6.1476e-09, 4.8336e-06, 4.7079e-06, 4.7584e-06,\n",
      "        1.3036e-04, 1.1582e-04, 1.1620e-04, 4.4660e-06, 4.5181e-06, 7.4021e-05,\n",
      "        7.4380e-05, 3.8739e-01, 3.9585e-01, 1.5384e+00, 1.5299e+00, 4.3916e-06,\n",
      "        7.3495e-05, 3.7541e-01, 1.5505e+00, 3.3761e-01, 1.5887e+00, 4.3030e-01,\n",
      "        9.3792e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([189.3436, 225.0809, 240.8622, 235.2005,   7.9195,   7.9200,   7.9192,\n",
      "        355.6314, 355.6314, 355.6314,   7.9199,   7.9210, 355.6314, 355.6314,\n",
      "        355.6314, 355.6314, 355.6314,  57.6568,  57.6568,   7.9188, 355.6314,\n",
      "        355.6314, 355.6314, 355.6314, 355.6314,  57.6568,  57.6568, 355.6314,\n",
      "         57.6568,  57.6568,   5.2026, 355.6314, 355.6314, 355.6314, 355.6314,\n",
      "        355.6314,  57.6568,  57.6568, 355.6314,  57.6568,  57.6568,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 355.6314,   5.2026,   5.2025, 355.6314,   5.2026,\n",
      "          5.2025, 355.6314,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        355.6314, 355.6314, 355.6314, 355.6314,  57.6568,  57.6568,  57.6568,\n",
      "         57.6568, 355.6314, 355.6314, 355.6314,  57.6568,  57.6568,  57.6568,\n",
      "         57.6568,   5.2026,  57.6568,  57.6568,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 555 was 93.8%\n",
      "tensor([0.0000e+00, 3.4444e-06, 2.8693e-06, 2.6673e-06, 2.7374e-06, 9.1441e-09,\n",
      "        6.4878e-09, 6.0432e-09, 6.1049e-09, 4.8242e-06, 4.6960e-06, 4.7495e-06,\n",
      "        1.2906e-04, 1.1469e-04, 1.1511e-04, 4.4567e-06, 4.5084e-06, 7.3326e-05,\n",
      "        7.3647e-05, 3.8651e-01, 3.9513e-01, 1.5353e+00, 1.5267e+00, 4.3838e-06,\n",
      "        7.2821e-05, 3.7460e-01, 1.5473e+00, 3.3696e-01, 1.5854e+00, 4.2942e-01,\n",
      "        9.3805e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([189.6136, 225.3734, 241.1959, 235.4225,   7.9172,   7.9169,   7.9179,\n",
      "        356.0524, 356.0524, 356.0524,   7.9174,   7.9166, 356.0524, 356.0524,\n",
      "        356.0524, 356.0524, 356.0524,  57.7360,  57.7360,   7.9179, 356.0524,\n",
      "        356.0524, 356.0524, 356.0524, 356.0524,  57.7360,  57.7360, 356.0524,\n",
      "         57.7360,  57.7360,   5.2026, 356.0524, 356.0524, 356.0524, 356.0524,\n",
      "        356.0524,  57.7360,  57.7360, 356.0524,  57.7360,  57.7360,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 356.0524,   5.2026,   5.2025, 356.0524,   5.2026,\n",
      "          5.2025, 356.0524,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        356.0524, 356.0524, 356.0524, 356.0524,  57.7360,  57.7360,  57.7360,\n",
      "         57.7360, 356.0524, 356.0524, 356.0524,  57.7360,  57.7360,  57.7360,\n",
      "         57.7360,   5.2026,  57.7360,  57.7360,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 556 was 93.8%\n",
      "tensor([4.7290e-08, 3.4496e-06, 2.8745e-06, 2.6729e-06, 2.7440e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8133e-06, 4.6867e-06, 4.7393e-06,\n",
      "        1.2770e-04, 1.1363e-04, 1.1401e-04, 4.4467e-06, 4.5008e-06, 7.2613e-05,\n",
      "        7.2966e-05, 3.8561e-01, 3.9435e-01, 1.5323e+00, 1.5235e+00, 4.3741e-06,\n",
      "        7.2125e-05, 3.7389e-01, 1.5441e+00, 3.3628e-01, 1.5821e+00, 4.2852e-01,\n",
      "        9.3817e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([189.8836, 225.6659, 241.5291, 235.6448,   7.9144,   7.9161,   7.9135,\n",
      "        356.4734, 356.4734, 356.4734,   7.9148,   7.9157, 356.4734, 356.4734,\n",
      "        356.4734, 356.4734, 356.4734,  57.8152,  57.8152,   7.9148, 356.4734,\n",
      "        356.4734, 356.4734, 356.4734, 356.4734,  57.8152,  57.8152, 356.4734,\n",
      "         57.8152,  57.8152,   5.2026, 356.4734, 356.4734, 356.4734, 356.4734,\n",
      "        356.4734,  57.8152,  57.8152, 356.4734,  57.8152,  57.8152,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 356.4734,   5.2026,   5.2025, 356.4734,   5.2026,\n",
      "          5.2025, 356.4734,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        356.4734, 356.4734, 356.4734, 356.4734,  57.8152,  57.8152,  57.8152,\n",
      "         57.8152, 356.4734, 356.4734, 356.4734,  57.8152,  57.8152,  57.8152,\n",
      "         57.8152,   5.2026,  57.8152,  57.8152,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 557 was 93.8%\n",
      "tensor([4.6892e-08, 3.4436e-06, 2.8699e-06, 2.6684e-06, 2.7405e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8040e-06, 4.6754e-06, 4.7314e-06,\n",
      "        1.2641e-04, 1.1251e-04, 1.1295e-04, 4.4380e-06, 4.4908e-06, 7.1942e-05,\n",
      "        7.2253e-05, 3.8477e-01, 3.9360e-01, 1.5293e+00, 1.5204e+00, 4.3661e-06,\n",
      "        7.1459e-05, 3.7312e-01, 1.5410e+00, 3.3564e-01, 1.5789e+00, 4.2765e-01,\n",
      "        9.3830e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([190.1536, 225.9584, 241.8617, 235.8674,   7.9121,   7.9117,   7.9127,\n",
      "        356.8944, 356.8944, 356.8944,   7.9134,   7.9126, 356.8944, 356.8944,\n",
      "        356.8944, 356.8944, 356.8944,  57.8943,  57.8943,   7.9123, 356.8944,\n",
      "        356.8944, 356.8944, 356.8944, 356.8944,  57.8943,  57.8943, 356.8944,\n",
      "         57.8943,  57.8943,   5.2026, 356.8944, 356.8944, 356.8944, 356.8944,\n",
      "        356.8944,  57.8943,  57.8943, 356.8944,  57.8943,  57.8943,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 356.8944,   5.2026,   5.2025, 356.8944,   5.2026,\n",
      "          5.2025, 356.8944,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        356.8944, 356.8944, 356.8944, 356.8944,  57.8943,  57.8943,  57.8943,\n",
      "         57.8943, 356.8944, 356.8944, 356.8944,  57.8943,  57.8943,  57.8943,\n",
      "         57.8943,   5.2026,  57.8943,  57.8943,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 558 was 93.8%\n",
      "tensor([4.6491e-08, 3.4373e-06, 2.8652e-06, 2.6636e-06, 2.7370e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7934e-06, 4.6664e-06, 4.7203e-06,\n",
      "        1.2509e-04, 1.1147e-04, 1.1183e-04, 4.4273e-06, 4.4831e-06, 7.1221e-05,\n",
      "        7.1584e-05, 3.8387e-01, 3.9286e-01, 1.5262e+00, 1.5172e+00, 4.3570e-06,\n",
      "        7.0775e-05, 3.7233e-01, 1.5378e+00, 3.3500e-01, 1.5756e+00, 4.2676e-01,\n",
      "        9.3843e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([190.4236, 226.2508, 242.1937, 236.0902,   7.9099,   7.9108,   7.9095,\n",
      "        357.3154, 357.3154, 357.3154,   7.9091,   7.9100, 357.3154, 357.3154,\n",
      "        357.3154, 357.3154, 357.3154,  57.9735,  57.9735,   7.9109, 357.3154,\n",
      "        357.3154, 357.3154, 357.3154, 357.3154,  57.9735,  57.9735, 357.3154,\n",
      "         57.9735,  57.9735,   5.2026, 357.3154, 357.3154, 357.3154, 357.3154,\n",
      "        357.3154,  57.9735,  57.9735, 357.3154,  57.9735,  57.9735,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 357.3154,   5.2026,   5.2025, 357.3154,   5.2026,\n",
      "          5.2025, 357.3154,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        357.3154, 357.3154, 357.3154, 357.3154,  57.9735,  57.9735,  57.9735,\n",
      "         57.9735, 357.3154, 357.3154, 357.3154,  57.9735,  57.9735,  57.9735,\n",
      "         57.9735,   5.2026,  57.9735,  57.9735,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 559 was 93.8%\n",
      "tensor([2.6470e-23, 3.4204e-06, 2.8507e-06, 2.6492e-06, 2.7239e-06, 8.8755e-09,\n",
      "        6.2965e-09, 5.8730e-09, 5.9369e-09, 4.7829e-06, 4.6555e-06, 4.7118e-06,\n",
      "        1.2379e-04, 1.1040e-04, 1.1082e-04, 4.4193e-06, 4.4741e-06, 7.0557e-05,\n",
      "        7.0890e-05, 3.8299e-01, 3.9209e-01, 1.5232e+00, 1.5141e+00, 4.3479e-06,\n",
      "        7.0101e-05, 3.7163e-01, 1.5347e+00, 3.3433e-01, 1.5724e+00, 4.2589e-01,\n",
      "        9.3855e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([190.6936, 226.5431, 242.5252, 236.3132,   7.9070,   7.9076,   7.9086,\n",
      "        357.7364, 357.7364, 357.7364,   7.9082,   7.9074, 357.7364, 357.7364,\n",
      "        357.7364, 357.7364, 357.7364,  58.0526,  58.0526,   7.9066, 357.7364,\n",
      "        357.7364, 357.7364, 357.7364, 357.7364,  58.0526,  58.0526, 357.7364,\n",
      "         58.0526,  58.0526,   5.2026, 357.7364, 357.7364, 357.7364, 357.7364,\n",
      "        357.7364,  58.0526,  58.0526, 357.7364,  58.0526,  58.0526,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 357.7364,   5.2026,   5.2025, 357.7364,   5.2026,\n",
      "          5.2025, 357.7364,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        357.7364, 357.7364, 357.7364, 357.7364,  58.0526,  58.0526,  58.0526,\n",
      "         58.0526, 357.7364, 357.7364, 357.7364,  58.0526,  58.0526,  58.0526,\n",
      "         58.0526,   5.2026,  58.0526,  58.0526,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 560 was 93.8%\n",
      "tensor([3.9705e-23, 3.4145e-06, 2.8462e-06, 2.6446e-06, 2.7205e-06, 8.8091e-09,\n",
      "        6.2495e-09, 5.8309e-09, 5.8948e-09, 4.7736e-06, 4.6459e-06, 4.7013e-06,\n",
      "        1.2253e-04, 1.0936e-04, 1.0971e-04, 4.4084e-06, 4.4661e-06, 6.9856e-05,\n",
      "        7.0219e-05, 3.8212e-01, 3.9139e-01, 1.5202e+00, 1.5109e+00, 4.3401e-06,\n",
      "        6.9447e-05, 3.7085e-01, 1.5316e+00, 3.3366e-01, 1.5691e+00, 4.2501e-01,\n",
      "        9.3868e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([190.9637, 226.8354, 242.8560, 236.5366,   7.9053,   7.9050,   7.9041,\n",
      "        358.1574, 358.1574, 358.1574,   7.9050,   7.9054, 358.1574, 358.1574,\n",
      "        358.1574, 358.1574, 358.1574,  58.1318,  58.1318,   7.9057, 358.1574,\n",
      "        358.1574, 358.1574, 358.1574, 358.1574,  58.1318,  58.1318, 358.1574,\n",
      "         58.1318,  58.1318,   5.2026, 358.1574, 358.1574, 358.1574, 358.1574,\n",
      "        358.1574,  58.1318,  58.1318, 358.1574,  58.1318,  58.1318,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 358.1574,   5.2026,   5.2025, 358.1574,   5.2026,\n",
      "          5.2025, 358.1574,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        358.1574, 358.1574, 358.1574, 358.1574,  58.1318,  58.1318,  58.1318,\n",
      "         58.1318, 358.1574, 358.1574, 358.1574,  58.1318,  58.1318,  58.1318,\n",
      "         58.1318,   5.2026,  58.1318,  58.1318,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 561 was 93.8%\n",
      "tensor([9.2644e-23, 3.4083e-06, 2.8415e-06, 2.6401e-06, 2.7171e-06, 8.7424e-09,\n",
      "        6.2022e-09, 5.7888e-09, 5.8531e-09, 4.7623e-06, 4.6354e-06, 4.6932e-06,\n",
      "        1.2122e-04, 1.0829e-04, 1.0868e-04, 4.3997e-06, 4.4569e-06, 6.9202e-05,\n",
      "        6.9537e-05, 3.8123e-01, 3.9062e-01, 1.5172e+00, 1.5078e+00, 4.3303e-06,\n",
      "        6.8766e-05, 3.7007e-01, 1.5284e+00, 3.3304e-01, 1.5658e+00, 4.2413e-01,\n",
      "        9.3880e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([191.2338, 227.1276, 243.1864, 236.7602,   7.9018,   7.9036,   7.9033,\n",
      "        358.5784, 358.5784, 358.5784,   7.9036,   7.9022, 358.5784, 358.5784,\n",
      "        358.5784, 358.5784, 358.5784,  58.2109,  58.2109,   7.9015, 358.5784,\n",
      "        358.5784, 358.5784, 358.5784, 358.5784,  58.2109,  58.2109, 358.5784,\n",
      "         58.2109,  58.2109,   5.2026, 358.5784, 358.5784, 358.5784, 358.5784,\n",
      "        358.5784,  58.2109,  58.2109, 358.5784,  58.2109,  58.2109,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 358.5784,   5.2026,   5.2025, 358.5784,   5.2026,\n",
      "          5.2025, 358.5784,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        358.5784, 358.5784, 358.5784, 358.5784,  58.2109,  58.2109,  58.2109,\n",
      "         58.2109, 358.5784, 358.5784, 358.5784,  58.2109,  58.2109,  58.2109,\n",
      "         58.2109,   5.2026,  58.2109,  58.2109,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 562 was 93.8%\n",
      "tensor([0.0000e+00, 3.4026e-06, 2.8370e-06, 2.6358e-06, 2.7137e-06, 8.6775e-09,\n",
      "        6.1557e-09, 5.7471e-09, 5.8118e-09, 4.7536e-06, 4.6254e-06, 4.6829e-06,\n",
      "        1.2000e-04, 1.0726e-04, 1.0763e-04, 4.3898e-06, 4.4488e-06, 6.8517e-05,\n",
      "        6.8866e-05, 3.8041e-01, 3.8988e-01, 1.5142e+00, 1.5047e+00, 4.3230e-06,\n",
      "        6.8128e-05, 3.6934e-01, 1.5253e+00, 3.3237e-01, 1.5627e+00, 4.2327e-01,\n",
      "        9.3893e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([191.5039, 227.4198, 243.5162, 236.9841,   7.9001,   7.9003,   7.9007,\n",
      "        358.9994, 358.9994, 358.9994,   7.8992,   7.9001, 358.9994, 358.9994,\n",
      "        358.9994, 358.9994, 358.9994,  58.2901,  58.2901,   7.9005, 358.9994,\n",
      "        358.9994, 358.9994, 358.9994, 358.9994,  58.2901,  58.2901, 358.9994,\n",
      "         58.2901,  58.2901,   5.2026, 358.9994, 358.9994, 358.9994, 358.9994,\n",
      "        358.9994,  58.2901,  58.2901, 358.9994,  58.2901,  58.2901,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 358.9994,   5.2026,   5.2025, 358.9994,   5.2026,\n",
      "          5.2025, 358.9994,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        358.9994, 358.9994, 358.9994, 358.9994,  58.2901,  58.2901,  58.2901,\n",
      "         58.2901, 358.9994, 358.9994, 358.9994,  58.2901,  58.2901,  58.2901,\n",
      "         58.2901,   5.2026,  58.2901,  58.2901,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 563 was 93.9%\n",
      "tensor([6.6174e-24, 3.3965e-06, 2.8323e-06, 2.6311e-06, 2.7103e-06, 8.6116e-09,\n",
      "        6.1086e-09, 5.7052e-09, 5.7705e-09, 4.7425e-06, 4.6150e-06, 4.6737e-06,\n",
      "        1.1872e-04, 1.0622e-04, 1.0660e-04, 4.3811e-06, 4.4398e-06, 6.7854e-05,\n",
      "        6.8194e-05, 3.7948e-01, 3.8915e-01, 1.5112e+00, 1.5015e+00, 4.3131e-06,\n",
      "        6.7460e-05, 3.6859e-01, 1.5221e+00, 3.3172e-01, 1.5594e+00, 4.2238e-01,\n",
      "        9.3905e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([191.7739, 227.7119, 243.8455, 237.2082,   7.8979,   7.8983,   7.8962,\n",
      "        359.4203, 359.4203, 359.4203,   7.8983,   7.8981, 359.4203, 359.4203,\n",
      "        359.4203, 359.4203, 359.4203,  58.3692,  58.3692,   7.8974, 359.4203,\n",
      "        359.4203, 359.4203, 359.4203, 359.4203,  58.3692,  58.3692, 359.4203,\n",
      "         58.3692,  58.3692,   5.2026, 359.4203, 359.4203, 359.4203, 359.4203,\n",
      "        359.4203,  58.3692,  58.3692, 359.4203,  58.3692,  58.3692,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 359.4203,   5.2026,   5.2025, 359.4203,   5.2026,\n",
      "          5.2025, 359.4203,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        359.4203, 359.4203, 359.4203, 359.4203,  58.3692,  58.3692,  58.3692,\n",
      "         58.3692, 359.4203, 359.4203, 359.4203,  58.3692,  58.3692,  58.3692,\n",
      "         58.3692,   5.2026,  58.3692,  58.3692,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 564 was 93.9%\n",
      "tensor([0.0000e+00, 3.3906e-06, 2.8279e-06, 2.6268e-06, 2.7069e-06, 8.5467e-09,\n",
      "        6.0630e-09, 5.6642e-09, 5.7294e-09, 4.7326e-06, 4.6048e-06, 4.6655e-06,\n",
      "        1.1749e-04, 1.0519e-04, 1.0557e-04, 4.3715e-06, 4.4310e-06, 6.7211e-05,\n",
      "        6.7532e-05, 3.7868e-01, 3.8839e-01, 1.5082e+00, 1.4984e+00, 4.3050e-06,\n",
      "        6.6817e-05, 3.6781e-01, 1.5191e+00, 3.3111e-01, 1.5562e+00, 4.2152e-01,\n",
      "        9.3918e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([192.0441, 228.0040, 244.1743, 237.4325,   7.8956,   7.8938,   7.8953,\n",
      "        359.8413, 359.8413, 359.8413,   7.8951,   7.8954, 359.8413, 359.8413,\n",
      "        359.8413, 359.8413, 359.8413,  58.4484,  58.4484,   7.8959, 359.8413,\n",
      "        359.8413, 359.8413, 359.8413, 359.8413,  58.4484,  58.4484, 359.8413,\n",
      "         58.4484,  58.4484,   5.2026, 359.8413, 359.8413, 359.8413, 359.8413,\n",
      "        359.8413,  58.4484,  58.4484, 359.8413,  58.4484,  58.4484,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 359.8413,   5.2026,   5.2025, 359.8413,   5.2026,\n",
      "          5.2025, 359.8413,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        359.8413, 359.8413, 359.8413, 359.8413,  58.4484,  58.4484,  58.4484,\n",
      "         58.4484, 359.8413, 359.8413, 359.8413,  58.4484,  58.4484,  58.4484,\n",
      "         58.4484,   5.2026,  58.4484,  58.4484,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 565 was 93.9%\n",
      "tensor([0.0000e+00, 3.3846e-06, 2.8233e-06, 2.6223e-06, 2.7036e-06, 8.4821e-09,\n",
      "        6.0169e-09, 5.6229e-09, 5.6889e-09, 4.7221e-06, 4.5960e-06, 4.6555e-06,\n",
      "        1.1625e-04, 1.0418e-04, 1.0456e-04, 4.3623e-06, 4.4228e-06, 6.6549e-05,\n",
      "        6.6895e-05, 3.7776e-01, 3.8767e-01, 1.5052e+00, 1.4953e+00, 4.2957e-06,\n",
      "        6.6166e-05, 3.6708e-01, 1.5160e+00, 3.3047e-01, 1.5530e+00, 4.2065e-01,\n",
      "        9.3930e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([192.3142, 228.2959, 244.5026, 237.6571,   7.8914,   7.8929,   7.8938,\n",
      "        360.2622, 360.2622, 360.2622,   7.8936,   7.8927, 360.2622, 360.2622,\n",
      "        360.2622, 360.2622, 360.2622,  58.5275,  58.5275,   7.8916, 360.2622,\n",
      "        360.2622, 360.2622, 360.2622, 360.2622,  58.5275,  58.5275, 360.2622,\n",
      "         58.5275,  58.5275,   5.2026, 360.2622, 360.2622, 360.2622, 360.2622,\n",
      "        360.2622,  58.5275,  58.5275, 360.2622,  58.5275,  58.5275,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 360.2622,   5.2026,   5.2025, 360.2622,   5.2026,\n",
      "          5.2025, 360.2622,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        360.2622, 360.2622, 360.2622, 360.2622,  58.5275,  58.5275,  58.5275,\n",
      "         58.5275, 360.2622, 360.2622, 360.2622,  58.5275,  58.5275,  58.5275,\n",
      "         58.5275,   5.2026,  58.5275,  58.5275,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 566 was 93.9%\n",
      "tensor([3.3087e-23, 3.3790e-06, 2.8189e-06, 2.6180e-06, 2.7003e-06, 8.4180e-09,\n",
      "        5.9711e-09, 5.5820e-09, 5.6478e-09, 4.7139e-06, 4.5856e-06, 4.6455e-06,\n",
      "        1.1507e-04, 1.0318e-04, 1.0352e-04, 4.3524e-06, 4.4146e-06, 6.5882e-05,\n",
      "        6.6235e-05, 3.7694e-01, 3.8694e-01, 1.5023e+00, 1.4922e+00, 4.2886e-06,\n",
      "        6.5551e-05, 3.6635e-01, 1.5129e+00, 3.2982e-01, 1.5498e+00, 4.1981e-01,\n",
      "        9.3942e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([192.5844, 228.5879, 244.8301, 237.8821,   7.8897,   7.8903,   7.8893,\n",
      "        360.6832, 360.6832, 360.6832,   7.8904,   7.8907, 360.6832, 360.6832,\n",
      "        360.6832, 360.6832, 360.6832,  58.6067,  58.6067,   7.8907, 360.6832,\n",
      "        360.6832, 360.6832, 360.6832, 360.6832,  58.6067,  58.6067, 360.6832,\n",
      "         58.6067,  58.6067,   5.2026, 360.6832, 360.6832, 360.6832, 360.6832,\n",
      "        360.6832,  58.6067,  58.6067, 360.6832,  58.6067,  58.6067,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 360.6832,   5.2026,   5.2025, 360.6832,   5.2026,\n",
      "          5.2025, 360.6832,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        360.6832, 360.6832, 360.6832, 360.6832,  58.6067,  58.6067,  58.6067,\n",
      "         58.6067, 360.6832, 360.6832, 360.6832,  58.6067,  58.6067,  58.6067,\n",
      "         58.6067,   5.2026,  58.6067,  58.6067,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 567 was 93.9%\n",
      "tensor([4.3031e-08, 3.3830e-06, 2.8233e-06, 2.6228e-06, 2.7059e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7028e-06, 4.5750e-06, 4.6374e-06,\n",
      "        1.1383e-04, 1.0215e-04, 1.0253e-04, 4.3436e-06, 4.4051e-06, 6.5256e-05,\n",
      "        6.5580e-05, 3.7607e-01, 3.8617e-01, 1.4992e+00, 1.4891e+00, 4.2788e-06,\n",
      "        6.4901e-05, 3.6558e-01, 1.5098e+00, 3.2920e-01, 1.5465e+00, 4.1893e-01,\n",
      "        9.3955e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([192.8546, 228.8799, 245.1572, 238.1072,   7.8874,   7.8882,   7.8884,\n",
      "        361.1041, 361.1041, 361.1041,   7.8884,   7.8862, 361.1041, 361.1041,\n",
      "        361.1041, 361.1041, 361.1041,  58.6858,  58.6858,   7.8875, 361.1041,\n",
      "        361.1041, 361.1041, 361.1041, 361.1041,  58.6858,  58.6858, 361.1041,\n",
      "         58.6858,  58.6858,   5.2026, 361.1041, 361.1041, 361.1041, 361.1041,\n",
      "        361.1041,  58.6858,  58.6858, 361.1041,  58.6858,  58.6858,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 361.1041,   5.2026,   5.2025, 361.1041,   5.2026,\n",
      "          5.2025, 361.1041,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        361.1041, 361.1041, 361.1041, 361.1041,  58.6858,  58.6858,  58.6858,\n",
      "         58.6858, 361.1041, 361.1041, 361.1041,  58.6858,  58.6858,  58.6858,\n",
      "         58.6858,   5.2026,  58.6858,  58.6858,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 568 was 93.9%\n",
      "tensor([4.2663e-08, 3.3772e-06, 2.8187e-06, 2.6184e-06, 2.7024e-06, 1.6544e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6931e-06, 4.5654e-06, 4.6271e-06,\n",
      "        1.1266e-04, 1.0119e-04, 1.0153e-04, 4.3340e-06, 4.3979e-06, 6.4603e-05,\n",
      "        6.4946e-05, 3.7524e-01, 3.8544e-01, 1.4963e+00, 1.4860e+00, 4.2708e-06,\n",
      "        6.4279e-05, 3.6487e-01, 1.5067e+00, 3.2853e-01, 1.5434e+00, 4.1807e-01,\n",
      "        9.3967e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([193.1248, 229.1717, 245.4838, 238.3326,   7.8851,   7.8855,   7.8838,\n",
      "        361.5250, 361.5250, 361.5250,   7.8851,   7.8852, 361.5250, 361.5250,\n",
      "        361.5250, 361.5250, 361.5250,  58.7650,  58.7650,   7.8860, 361.5250,\n",
      "        361.5250, 361.5250, 361.5250, 361.5250,  58.7650,  58.7650, 361.5250,\n",
      "         58.7650,  58.7650,   5.2026, 361.5250, 361.5250, 361.5250, 361.5250,\n",
      "        361.5250,  58.7650,  58.7650, 361.5250,  58.7650,  58.7650,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 361.5250,   5.2026,   5.2025, 361.5250,   5.2026,\n",
      "          5.2025, 361.5250,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        361.5250, 361.5250, 361.5250, 361.5250,  58.7650,  58.7650,  58.7650,\n",
      "         58.7650, 361.5250, 361.5250, 361.5250,  58.7650,  58.7650,  58.7650,\n",
      "         58.7650,   5.2026,  58.7650,  58.7650,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 569 was 93.9%\n",
      "tensor([0.0000e+00, 3.3610e-06, 2.8051e-06, 2.6048e-06, 2.6900e-06, 8.2273e-09,\n",
      "        5.8354e-09, 5.4604e-09, 5.5270e-09, 4.6825e-06, 4.5552e-06, 4.6192e-06,\n",
      "        1.1145e-04, 1.0019e-04, 1.0056e-04, 4.3255e-06, 4.3884e-06, 6.3989e-05,\n",
      "        6.4307e-05, 3.7437e-01, 3.8468e-01, 1.4933e+00, 1.4830e+00, 4.2616e-06,\n",
      "        6.3645e-05, 3.6412e-01, 1.5036e+00, 3.2792e-01, 1.5402e+00, 4.1722e-01,\n",
      "        9.3979e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([193.3950, 229.4635, 245.8100, 238.5583,   7.8828,   7.8821,   7.8829,\n",
      "        361.9459, 361.9459, 361.9459,   7.8836,   7.8825, 361.9459, 361.9459,\n",
      "        361.9459, 361.9459, 361.9459,  58.8441,  58.8441,   7.8816, 361.9459,\n",
      "        361.9459, 361.9459, 361.9459, 361.9459,  58.8441,  58.8441, 361.9459,\n",
      "         58.8441,  58.8441,   5.2026, 361.9459, 361.9459, 361.9459, 361.9459,\n",
      "        361.9459,  58.8441,  58.8441, 361.9459,  58.8441,  58.8441,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 361.9459,   5.2026,   5.2025, 361.9459,   5.2026,\n",
      "          5.2025, 361.9459,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        361.9459, 361.9459, 361.9459, 361.9459,  58.8441,  58.8441,  58.8441,\n",
      "         58.8441, 361.9459, 361.9459, 361.9459,  58.8441,  58.8441,  58.8441,\n",
      "         58.8441,   5.2026,  58.8441,  58.8441,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 570 was 93.9%\n",
      "tensor([0.0000e+00, 3.3552e-06, 2.8008e-06, 2.6004e-06, 2.6866e-06, 8.1649e-09,\n",
      "        5.7908e-09, 5.4202e-09, 5.4871e-09, 4.6731e-06, 4.5459e-06, 4.6085e-06,\n",
      "        1.1031e-04, 9.9221e-05, 9.9558e-05, 4.3156e-06, 4.3803e-06, 6.3337e-05,\n",
      "        6.3683e-05, 3.7355e-01, 3.8398e-01, 1.4903e+00, 1.4799e+00, 4.2539e-06,\n",
      "        6.3036e-05, 3.6333e-01, 1.5006e+00, 3.2728e-01, 1.5370e+00, 4.1636e-01,\n",
      "        9.3992e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([193.6652, 229.7553, 246.1357, 238.7841,   7.8792,   7.8807,   7.8795,\n",
      "        362.3669, 362.3669, 362.3669,   7.8791,   7.8810, 362.3669, 362.3669,\n",
      "        362.3669, 362.3669, 362.3669,  58.9232,  58.9232,   7.8806, 362.3669,\n",
      "        362.3669, 362.3669, 362.3669, 362.3669,  58.9232,  58.9232, 362.3669,\n",
      "         58.9232,  58.9232,   5.2026, 362.3669, 362.3669, 362.3669, 362.3669,\n",
      "        362.3669,  58.9232,  58.9232, 362.3669,  58.9232,  58.9232,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 362.3669,   5.2026,   5.2025, 362.3669,   5.2026,\n",
      "          5.2025, 362.3669,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        362.3669, 362.3669, 362.3669, 362.3669,  58.9232,  58.9232,  58.9232,\n",
      "         58.9232, 362.3669, 362.3669, 362.3669,  58.9232,  58.9232,  58.9232,\n",
      "         58.9232,   5.2026,  58.9232,  58.9232,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 571 was 94.0%\n",
      "tensor([0.0000e+00, 3.3494e-06, 2.7962e-06, 2.5961e-06, 2.6834e-06, 8.1018e-09,\n",
      "        5.7457e-09, 5.3799e-09, 5.4471e-09, 4.6636e-06, 4.5349e-06, 4.6007e-06,\n",
      "        1.0913e-04, 9.8221e-05, 9.8612e-05, 4.3076e-06, 4.3709e-06, 6.2730e-05,\n",
      "        6.3032e-05, 3.7265e-01, 3.8324e-01, 1.4874e+00, 1.4768e+00, 4.2451e-06,\n",
      "        6.2420e-05, 3.6265e-01, 1.4975e+00, 3.2666e-01, 1.5338e+00, 4.1552e-01,\n",
      "        9.4004e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([193.9355, 230.0470, 246.4606, 239.0103,   7.8770,   7.8773,   7.8780,\n",
      "        362.7878, 362.7878, 362.7878,   7.8782,   7.8764, 362.7878, 362.7878,\n",
      "        362.7878, 362.7878, 362.7878,  59.0024,  59.0024,   7.8780, 362.7878,\n",
      "        362.7878, 362.7878, 362.7878, 362.7878,  59.0024,  59.0024, 362.7878,\n",
      "         59.0024,  59.0024,   5.2026, 362.7878, 362.7878, 362.7878, 362.7878,\n",
      "        362.7878,  59.0024,  59.0024, 362.7878,  59.0024,  59.0024,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 362.7878,   5.2026,   5.2025, 362.7878,   5.2026,\n",
      "          5.2025, 362.7878,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        362.7878, 362.7878, 362.7878, 362.7878,  59.0024,  59.0024,  59.0024,\n",
      "         59.0024, 362.7878, 362.7878, 362.7878,  59.0024,  59.0024,  59.0024,\n",
      "         59.0024,   5.2026,  59.0024,  59.0024,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 572 was 94.0%\n",
      "tensor([5.2940e-23, 3.3435e-06, 2.7917e-06, 2.5918e-06, 2.6799e-06, 8.0391e-09,\n",
      "        5.7009e-09, 5.3399e-09, 5.4069e-09, 4.6535e-06, 4.5261e-06, 4.5902e-06,\n",
      "        1.0797e-04, 9.7281e-05, 9.7610e-05, 4.2973e-06, 4.3637e-06, 6.2086e-05,\n",
      "        6.2422e-05, 3.7184e-01, 3.8248e-01, 1.4845e+00, 1.4738e+00, 4.2364e-06,\n",
      "        6.1801e-05, 3.6191e-01, 1.4945e+00, 3.2601e-01, 1.5307e+00, 4.1465e-01,\n",
      "        9.4016e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([194.2059, 230.3387, 246.7851, 239.2367,   7.8747,   7.8758,   7.8746,\n",
      "        363.2087, 363.2087, 363.2087,   7.8736,   7.8755, 363.2087, 363.2087,\n",
      "        363.2087, 363.2087, 363.2087,  59.0815,  59.0815,   7.8753, 363.2087,\n",
      "        363.2087, 363.2087, 363.2087, 363.2087,  59.0815,  59.0815, 363.2087,\n",
      "         59.0815,  59.0815,   5.2026, 363.2087, 363.2087, 363.2087, 363.2087,\n",
      "        363.2087,  59.0815,  59.0815, 363.2087,  59.0815,  59.0815,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 363.2087,   5.2026,   5.2025, 363.2087,   5.2026,\n",
      "          5.2025, 363.2087,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        363.2087, 363.2087, 363.2087, 363.2087,  59.0815,  59.0815,  59.0815,\n",
      "         59.0815, 363.2087, 363.2087, 363.2087,  59.0815,  59.0815,  59.0815,\n",
      "         59.0815,   5.2026,  59.0815,  59.0815,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 573 was 94.0%\n",
      "tensor([0.0000e+00, 3.3378e-06, 2.7872e-06, 2.5875e-06, 2.6765e-06, 7.9776e-09,\n",
      "        5.6570e-09, 5.3002e-09, 5.3678e-09, 4.6436e-06, 4.5154e-06, 4.5822e-06,\n",
      "        1.0683e-04, 9.6300e-05, 9.6684e-05, 4.2895e-06, 4.3540e-06, 6.1488e-05,\n",
      "        6.1789e-05, 3.7100e-01, 3.8176e-01, 1.4815e+00, 1.4707e+00, 4.2281e-06,\n",
      "        6.1196e-05, 3.6118e-01, 1.4914e+00, 3.2537e-01, 1.5275e+00, 4.1381e-01,\n",
      "        9.4028e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([194.4762, 230.6303, 247.1092, 239.4633,   7.8718,   7.8712,   7.8737,\n",
      "        363.6296, 363.6296, 363.6296,   7.8727,   7.8721, 363.6296, 363.6296,\n",
      "        363.6296, 363.6296, 363.6296,  59.1607,  59.1607,   7.8726, 363.6296,\n",
      "        363.6296, 363.6296, 363.6296, 363.6296,  59.1607,  59.1607, 363.6296,\n",
      "         59.1607,  59.1607,   5.2026, 363.6296, 363.6296, 363.6296, 363.6296,\n",
      "        363.6296,  59.1607,  59.1607, 363.6296,  59.1607,  59.1607,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 363.6296,   5.2026,   5.2025, 363.6296,   5.2026,\n",
      "          5.2025, 363.6296,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        363.6296, 363.6296, 363.6296, 363.6296,  59.1607,  59.1607,  59.1607,\n",
      "         59.1607, 363.6296, 363.6296, 363.6296,  59.1607,  59.1607,  59.1607,\n",
      "         59.1607,   5.2026,  59.1607,  59.1607,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 574 was 94.0%\n",
      "tensor([4.6322e-23, 3.3320e-06, 2.7827e-06, 2.5831e-06, 2.6733e-06, 7.9156e-09,\n",
      "        5.6132e-09, 5.2608e-09, 5.3281e-09, 4.6341e-06, 4.5071e-06, 4.5719e-06,\n",
      "        1.0571e-04, 9.5378e-05, 9.5688e-05, 4.2788e-06, 4.3467e-06, 6.0857e-05,\n",
      "        6.1197e-05, 3.7012e-01, 3.8106e-01, 1.4786e+00, 1.4677e+00, 4.2198e-06,\n",
      "        6.0597e-05, 3.6046e-01, 1.4884e+00, 3.2474e-01, 1.5244e+00, 4.1297e-01,\n",
      "        9.4040e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([194.7466, 230.9219, 247.4326, 239.6903,   7.8694,   7.8703,   7.8690,\n",
      "        364.0504, 364.0504, 364.0504,   7.8694,   7.8706, 364.0504, 364.0504,\n",
      "        364.0504, 364.0504, 364.0504,  59.2398,  59.2398,   7.8699, 364.0504,\n",
      "        364.0504, 364.0504, 364.0504, 364.0504,  59.2398,  59.2398, 364.0504,\n",
      "         59.2398,  59.2398,   5.2026, 364.0504, 364.0504, 364.0504, 364.0504,\n",
      "        364.0504,  59.2398,  59.2398, 364.0504,  59.2398,  59.2398,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 364.0504,   5.2026,   5.2025, 364.0504,   5.2026,\n",
      "          5.2025, 364.0504,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        364.0504, 364.0504, 364.0504, 364.0504,  59.2398,  59.2398,  59.2398,\n",
      "         59.2398, 364.0504, 364.0504, 364.0504,  59.2398,  59.2398,  59.2398,\n",
      "         59.2398,   5.2026,  59.2398,  59.2398,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 575 was 94.0%\n",
      "tensor([0.0000e+00, 3.3260e-06, 2.7783e-06, 2.5788e-06, 2.6698e-06, 7.8537e-09,\n",
      "        5.5690e-09, 5.2209e-09, 5.2884e-09, 4.6240e-06, 4.4958e-06, 4.5640e-06,\n",
      "        1.0457e-04, 9.4397e-05, 9.4765e-05, 4.2709e-06, 4.3370e-06, 6.0264e-05,\n",
      "        6.0558e-05, 3.6932e-01, 3.8030e-01, 1.4757e+00, 1.4647e+00, 4.2112e-06,\n",
      "        5.9990e-05, 3.5969e-01, 1.4853e+00, 3.2413e-01, 1.5212e+00, 4.1211e-01,\n",
      "        9.4053e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([195.0170, 231.2134, 247.7556, 239.9174,   7.8665,   7.8669,   7.8681,\n",
      "        364.4713, 364.4713, 364.4713,   7.8684,   7.8659, 364.4713, 364.4713,\n",
      "        364.4713, 364.4713, 364.4713,  59.3190,  59.3190,   7.8672, 364.4713,\n",
      "        364.4713, 364.4713, 364.4713, 364.4713,  59.3190,  59.3190, 364.4713,\n",
      "         59.3190,  59.3190,   5.2026, 364.4713, 364.4713, 364.4713, 364.4713,\n",
      "        364.4713,  59.3190,  59.3190, 364.4713,  59.3190,  59.3190,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 364.4713,   5.2026,   5.2025, 364.4713,   5.2026,\n",
      "          5.2025, 364.4713,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        364.4713, 364.4713, 364.4713, 364.4713,  59.3190,  59.3190,  59.3190,\n",
      "         59.3190, 364.4713, 364.4713, 364.4713,  59.3190,  59.3190,  59.3190,\n",
      "         59.3190,   5.2026,  59.3190,  59.3190,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 576 was 94.0%\n",
      "tensor([3.9776e-08, 3.3299e-06, 2.7823e-06, 2.5833e-06, 2.6748e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6148e-06, 4.4875e-06, 4.5533e-06,\n",
      "        1.0347e-04, 9.3511e-05, 9.3800e-05, 4.2607e-06, 4.3303e-06, 5.9640e-05,\n",
      "        5.9979e-05, 3.6851e-01, 3.7955e-01, 1.4728e+00, 1.4617e+00, 4.2032e-06,\n",
      "        5.9406e-05, 3.5898e-01, 1.4823e+00, 3.2351e-01, 1.5181e+00, 4.1128e-01,\n",
      "        9.4065e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([195.2875, 231.5050, 248.0780, 240.1448,   7.8642,   7.8653,   7.8646,\n",
      "        364.8922, 364.8922, 364.8922,   7.8638,   7.8649, 364.8922, 364.8922,\n",
      "        364.8922, 364.8922, 364.8922,  59.3981,  59.3981,   7.8645, 364.8922,\n",
      "        364.8922, 364.8922, 364.8922, 364.8922,  59.3981,  59.3981, 364.8922,\n",
      "         59.3981,  59.3981,   5.2026, 364.8922, 364.8922, 364.8922, 364.8922,\n",
      "        364.8922,  59.3981,  59.3981, 364.8922,  59.3981,  59.3981,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 364.8922,   5.2026,   5.2025, 364.8922,   5.2026,\n",
      "          5.2025, 364.8922,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        364.8922, 364.8922, 364.8922, 364.8922,  59.3981,  59.3981,  59.3981,\n",
      "         59.3981, 364.8922, 364.8922, 364.8922,  59.3981,  59.3981,  59.3981,\n",
      "         59.3981,   5.2026,  59.3981,  59.3981,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 577 was 94.0%\n",
      "tensor([0.0000e+00, 3.3134e-06, 2.7688e-06, 2.5699e-06, 2.6625e-06, 7.2581e-09,\n",
      "        5.1106e-09, 4.7810e-09, 4.8484e-09, 4.6052e-06, 4.4769e-06, 4.5460e-06,\n",
      "        9.6194e-05, 8.6606e-05, 8.7052e-05, 4.2538e-06, 4.3213e-06, 5.4598e-05,\n",
      "        5.4957e-05, 3.6780e-01, 3.7897e-01, 1.4702e+00, 1.4590e+00, 4.1953e-06,\n",
      "        5.4295e-05, 3.5839e-01, 1.4797e+00, 3.2298e-01, 1.5156e+00, 4.1057e-01,\n",
      "        9.4075e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([195.5559, 231.7937, 248.4085, 240.3683,   7.8625,   7.8604,   7.8616,\n",
      "        365.3131, 365.3131, 365.3131,   7.8627,   7.8614, 365.3131, 365.3131,\n",
      "        365.3131, 365.3131, 365.3131,  59.4773,  59.4773,   7.8630, 365.3131,\n",
      "        365.3131, 365.3131, 365.3131, 365.3131,  59.4773,  59.4773, 365.3131,\n",
      "         59.4773,  59.4773,   5.2026, 365.3131, 365.3131, 365.3131, 365.3131,\n",
      "        365.3131,  59.4773,  59.4773, 365.3131,  59.4773,  59.4773,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 365.3131,   5.2026,   5.2025, 365.3131,   5.2026,\n",
      "          5.2025, 365.3131,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        365.3131, 365.3131, 365.3131, 365.3131,  59.4773,  59.4773,  59.4773,\n",
      "         59.4773, 365.3131, 365.3131, 365.3131,  59.4773,  59.4773,  59.4773,\n",
      "         59.4773,   5.2026,  59.4773,  59.4773,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 578 was 94.0%\n",
      "tensor([3.3087e-23, 3.3077e-06, 2.7646e-06, 2.5656e-06, 2.6593e-06, 7.2060e-09,\n",
      "        5.0742e-09, 4.7487e-09, 4.8162e-09, 4.5948e-06, 4.4691e-06, 4.5371e-06,\n",
      "        9.5210e-05, 8.5826e-05, 8.6241e-05, 4.2444e-06, 4.3141e-06, 5.4095e-05,\n",
      "        5.4471e-05, 3.6698e-01, 3.7824e-01, 1.4674e+00, 1.4561e+00, 4.1863e-06,\n",
      "        5.3795e-05, 3.5764e-01, 1.4768e+00, 3.2240e-01, 1.5125e+00, 4.0975e-01,\n",
      "        9.4087e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([195.8244, 232.0825, 248.7383, 240.5922,   7.8594,   7.8593,   7.8593,\n",
      "        365.7339, 365.7339, 365.7339,   7.8592,   7.8603, 365.7339, 365.7339,\n",
      "        365.7339, 365.7339, 365.7339,  59.5564,  59.5564,   7.8585, 365.7339,\n",
      "        365.7339, 365.7339, 365.7339, 365.7339,  59.5564,  59.5564, 365.7339,\n",
      "         59.5564,  59.5564,   5.2026, 365.7339, 365.7339, 365.7339, 365.7339,\n",
      "        365.7339,  59.5564,  59.5564, 365.7339,  59.5564,  59.5564,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 365.7339,   5.2026,   5.2025, 365.7339,   5.2026,\n",
      "          5.2025, 365.7339,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        365.7339, 365.7339, 365.7339, 365.7339,  59.5564,  59.5564,  59.5564,\n",
      "         59.5564, 365.7339, 365.7339, 365.7339,  59.5564,  59.5564,  59.5564,\n",
      "         59.5564,   5.2026,  59.5564,  59.5564,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0824, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 579 was 94.0%\n",
      "tensor([3.6876e-06, 1.0770e-05, 4.2997e-06, 4.6163e-20, 2.1279e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8013e-05, 1.2335e-05, 1.5476e-05,\n",
      "        9.3981e-05, 8.4763e-05, 8.5188e-05, 3.8122e-06, 3.8718e-06, 5.3437e-05,\n",
      "        5.3791e-05, 3.6609e-01, 3.7753e-01, 1.4643e+00, 1.4528e+00, 3.7616e-06,\n",
      "        5.3156e-05, 3.5685e-01, 1.4737e+00, 3.2172e-01, 1.5093e+00, 4.0889e-01,\n",
      "        9.4099e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([196.0921, 232.3774, 249.0505, 240.8266,   7.8533,   7.8561,   7.8577,\n",
      "        366.1548, 366.1548, 366.1548,   7.8577,   7.8578, 366.1548, 366.1548,\n",
      "        366.1548, 366.1548, 366.1548,  59.6356,  59.6356,   7.8576, 366.1548,\n",
      "        366.1548, 366.1548, 366.1548, 366.1548,  59.6356,  59.6356, 366.1548,\n",
      "         59.6356,  59.6356,   5.2026, 366.1548, 366.1548, 366.1548, 366.1548,\n",
      "        366.1548,  59.6356,  59.6356, 366.1548,  59.6356,  59.6356,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 366.1548,   5.2026,   5.2025, 366.1548,   5.2026,\n",
      "          5.2025, 366.1548,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        366.1548, 366.1548, 366.1548, 366.1548,  59.6356,  59.6356,  59.6356,\n",
      "         59.6356, 366.1548, 366.1548, 366.1548,  59.6356,  59.6356,  59.6356,\n",
      "         59.6356,   5.2026,  59.6356,  59.6356,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 580 was 94.1%\n",
      "tensor([7.2792e-23, 3.2964e-06, 2.7558e-06, 2.5573e-06, 2.6527e-06, 7.0963e-09,\n",
      "        4.9971e-09, 4.6803e-09, 4.7472e-09, 4.5781e-06, 4.4494e-06, 4.5188e-06,\n",
      "        9.3222e-05, 8.4163e-05, 8.4547e-05, 4.2259e-06, 4.2968e-06, 5.3045e-05,\n",
      "        5.3406e-05, 3.6529e-01, 3.7681e-01, 1.4616e+00, 1.4500e+00, 4.1705e-06,\n",
      "        5.2780e-05, 3.5623e-01, 1.4708e+00, 3.2117e-01, 1.5063e+00, 4.0808e-01,\n",
      "        9.4111e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([196.3608, 232.6662, 249.3793, 241.0509,   7.8523,   7.8543,   7.8546,\n",
      "        366.5756, 366.5756, 366.5756,   7.8543,   7.8527, 366.5756, 366.5756,\n",
      "        366.5756, 366.5756, 366.5756,  59.7147,  59.7147,   7.8560, 366.5756,\n",
      "        366.5756, 366.5756, 366.5756, 366.5756,  59.7147,  59.7147, 366.5756,\n",
      "         59.7147,  59.7147,   5.2026, 366.5756, 366.5756, 366.5756, 366.5756,\n",
      "        366.5756,  59.7147,  59.7147, 366.5756,  59.7147,  59.7147,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 366.5756,   5.2026,   5.2025, 366.5756,   5.2026,\n",
      "          5.2025, 366.5756,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        366.5756, 366.5756, 366.5756, 366.5756,  59.7147,  59.7147,  59.7147,\n",
      "         59.7147, 366.5756, 366.5756, 366.5756,  59.7147,  59.7147,  59.7147,\n",
      "         59.7147,   5.2026,  59.7147,  59.7147,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 581 was 94.1%\n",
      "tensor([2.6470e-23, 3.2907e-06, 2.7515e-06, 2.5536e-06, 2.6497e-06, 7.0326e-09,\n",
      "        4.9525e-09, 4.6408e-09, 4.7078e-09, 4.5667e-06, 4.4396e-06, 4.5094e-06,\n",
      "        9.2086e-05, 8.3240e-05, 8.3623e-05, 4.2178e-06, 4.2894e-06, 5.2469e-05,\n",
      "        5.2829e-05, 3.6448e-01, 3.7602e-01, 1.4585e+00, 1.4469e+00, 4.1615e-06,\n",
      "        5.2211e-05, 3.5555e-01, 1.4675e+00, 3.2054e-01, 1.5031e+00, 4.0727e-01,\n",
      "        9.4124e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([196.6298, 232.9557, 249.7041, 241.2775,   7.8502,   7.8528,   7.8511,\n",
      "        366.9965, 366.9965, 366.9965,   7.8516,   7.8512, 366.9965, 366.9965,\n",
      "        366.9965, 366.9965, 366.9965,  59.7939,  59.7939,   7.8515, 366.9965,\n",
      "        366.9965, 366.9965, 366.9965, 366.9965,  59.7939,  59.7939, 366.9965,\n",
      "         59.7939,  59.7939,   5.2026, 366.9965, 366.9965, 366.9965, 366.9965,\n",
      "        366.9965,  59.7939,  59.7939, 366.9965,  59.7939,  59.7939,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 366.9965,   5.2026,   5.2025, 366.9965,   5.2026,\n",
      "          5.2025, 366.9965,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        366.9965, 366.9965, 366.9965, 366.9965,  59.7939,  59.7939,  59.7939,\n",
      "         59.7939, 366.9965, 366.9965, 366.9965,  59.7939,  59.7939,  59.7939,\n",
      "         59.7939,   5.2026,  59.7939,  59.7939,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 582 was 94.1%\n",
      "tensor([3.3087e-23, 3.2848e-06, 2.7467e-06, 2.5486e-06, 2.6456e-06, 6.9293e-09,\n",
      "        4.8743e-09, 4.5657e-09, 4.6335e-09, 4.5574e-06, 4.4290e-06, 4.5010e-06,\n",
      "        9.0520e-05, 8.1762e-05, 8.2198e-05, 4.2089e-06, 4.2796e-06, 5.1451e-05,\n",
      "        5.1805e-05, 3.6374e-01, 3.7532e-01, 1.4558e+00, 1.4442e+00, 4.1539e-06,\n",
      "        5.1192e-05, 3.5480e-01, 1.4648e+00, 3.1987e-01, 1.5001e+00, 4.0642e-01,\n",
      "        9.4135e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([196.8983, 233.2437, 250.0334, 241.5017,   7.8491,   7.8478,   7.8493,\n",
      "        367.4173, 367.4173, 367.4173,   7.8481,   7.8488, 367.4173, 367.4173,\n",
      "        367.4173, 367.4173, 367.4173,  59.8730,  59.8730,   7.8493, 367.4173,\n",
      "        367.4173, 367.4173, 367.4173, 367.4173,  59.8730,  59.8730, 367.4173,\n",
      "         59.8730,  59.8730,   5.2026, 367.4173, 367.4173, 367.4173, 367.4173,\n",
      "        367.4173,  59.8730,  59.8730, 367.4173,  59.8730,  59.8730,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 367.4173,   5.2026,   5.2025, 367.4173,   5.2026,\n",
      "          5.2025, 367.4173,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        367.4173, 367.4173, 367.4173, 367.4173,  59.8730,  59.8730,  59.8730,\n",
      "         59.8730, 367.4173, 367.4173, 367.4173,  59.8730,  59.8730,  59.8730,\n",
      "         59.8730,   5.2026,  59.8730,  59.8730,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 583 was 94.1%\n",
      "tensor([0.0000e+00, 3.2791e-06, 2.7424e-06, 2.5442e-06, 2.6424e-06, 6.8805e-09,\n",
      "        4.8402e-09, 4.5358e-09, 4.6031e-09, 4.5466e-06, 4.4204e-06, 4.4917e-06,\n",
      "        8.9601e-05, 8.1034e-05, 8.1436e-05, 4.1999e-06, 4.2720e-06, 5.0987e-05,\n",
      "        5.1344e-05, 3.6285e-01, 3.7467e-01, 1.4530e+00, 1.4411e+00, 4.1449e-06,\n",
      "        5.0728e-05, 3.5405e-01, 1.4618e+00, 3.1926e-01, 1.4970e+00, 4.0557e-01,\n",
      "        9.4147e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([197.1668, 233.5318, 250.3621, 241.7262,   7.8461,   7.8467,   7.8455,\n",
      "        367.8381, 367.8381, 367.8381,   7.8463,   7.8471, 367.8381, 367.8381,\n",
      "        367.8381, 367.8381, 367.8381,  59.9522,  59.9522,   7.8447, 367.8381,\n",
      "        367.8381, 367.8381, 367.8381, 367.8381,  59.9522,  59.9522, 367.8381,\n",
      "         59.9522,  59.9522,   5.2026, 367.8381, 367.8381, 367.8381, 367.8381,\n",
      "        367.8381,  59.9522,  59.9522, 367.8381,  59.9522,  59.9522,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 367.8381,   5.2026,   5.2025, 367.8381,   5.2026,\n",
      "          5.2025, 367.8381,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        367.8381, 367.8381, 367.8381, 367.8381,  59.9522,  59.9522,  59.9522,\n",
      "         59.9522, 367.8381, 367.8381, 367.8381,  59.9522,  59.9522,  59.9522,\n",
      "         59.9522,   5.2026,  59.9522,  59.9522,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 584 was 94.1%\n",
      "tensor([0.0000e+00, 3.2736e-06, 2.7385e-06, 2.5404e-06, 2.6394e-06, 6.8170e-09,\n",
      "        4.7969e-09, 4.4974e-09, 4.5642e-09, 4.5380e-06, 4.4095e-06, 4.4833e-06,\n",
      "        8.8522e-05, 8.0108e-05, 8.0512e-05, 4.1910e-06, 4.2631e-06, 5.0440e-05,\n",
      "        5.0767e-05, 3.6207e-01, 3.7396e-01, 1.4499e+00, 1.4379e+00, 4.1377e-06,\n",
      "        5.0202e-05, 3.5329e-01, 1.4587e+00, 3.1865e-01, 1.4939e+00, 4.0476e-01,\n",
      "        9.4159e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([197.4357, 233.8206, 250.6868, 241.9528,   7.8434,   7.8432,   7.8441,\n",
      "        368.2590, 368.2590, 368.2590,   7.8436,   7.8423, 368.2590, 368.2590,\n",
      "        368.2590, 368.2590, 368.2590,  60.0313,  60.0313,   7.8437, 368.2590,\n",
      "        368.2590, 368.2590, 368.2590, 368.2590,  60.0313,  60.0313, 368.2590,\n",
      "         60.0313,  60.0313,   5.2026, 368.2590, 368.2590, 368.2590, 368.2590,\n",
      "        368.2590,  60.0313,  60.0313, 368.2590,  60.0313,  60.0313,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 368.2590,   5.2026,   5.2025, 368.2590,   5.2026,\n",
      "          5.2025, 368.2590,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        368.2590, 368.2590, 368.2590, 368.2590,  60.0313,  60.0313,  60.0313,\n",
      "         60.0313, 368.2590, 368.2590, 368.2590,  60.0313,  60.0313,  60.0313,\n",
      "         60.0313,   5.2026,  60.0313,  60.0313,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 585 was 94.1%\n",
      "tensor([3.3087e-23, 3.2680e-06, 2.7340e-06, 2.5361e-06, 2.6361e-06, 6.7672e-09,\n",
      "        4.7618e-09, 4.4665e-09, 4.5330e-09, 4.5279e-06, 4.4009e-06, 4.4735e-06,\n",
      "        8.7600e-05, 7.9376e-05, 7.9739e-05, 4.1816e-06, 4.2559e-06, 4.9958e-05,\n",
      "        5.0304e-05, 3.6123e-01, 3.7322e-01, 1.4470e+00, 1.4349e+00, 4.1285e-06,\n",
      "        4.9733e-05, 3.5262e-01, 1.4557e+00, 3.1801e-01, 1.4908e+00, 4.0392e-01,\n",
      "        9.4171e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([197.7047, 234.1094, 251.0110, 242.1796,   7.8401,   7.8423,   7.8392,\n",
      "        368.6798, 368.6798, 368.6798,   7.8408,   7.8414, 368.6798, 368.6798,\n",
      "        368.6798, 368.6798, 368.6798,  60.1104,  60.1104,   7.8404, 368.6798,\n",
      "        368.6798, 368.6798, 368.6798, 368.6798,  60.1104,  60.1104, 368.6798,\n",
      "         60.1104,  60.1104,   5.2026, 368.6798, 368.6798, 368.6798, 368.6798,\n",
      "        368.6798,  60.1104,  60.1104, 368.6798,  60.1104,  60.1104,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 368.6798,   5.2026,   5.2025, 368.6798,   5.2026,\n",
      "          5.2025, 368.6798,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        368.6798, 368.6798, 368.6798, 368.6798,  60.1104,  60.1104,  60.1104,\n",
      "         60.1104, 368.6798, 368.6798, 368.6798,  60.1104,  60.1104,  60.1104,\n",
      "         60.1104,   5.2026,  60.1104,  60.1104,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 586 was 94.1%\n",
      "tensor([0.0000e+00, 3.2625e-06, 2.7298e-06, 2.5321e-06, 2.6327e-06, 6.7183e-09,\n",
      "        4.7280e-09, 4.4358e-09, 4.5028e-09, 4.5193e-06, 4.3904e-06, 4.4662e-06,\n",
      "        8.6733e-05, 7.8602e-05, 7.9016e-05, 4.1737e-06, 4.2461e-06, 4.9512e-05,\n",
      "        4.9822e-05, 3.6048e-01, 3.7247e-01, 1.4441e+00, 1.4320e+00, 4.1211e-06,\n",
      "        4.9288e-05, 3.5190e-01, 1.4528e+00, 3.1741e-01, 1.4878e+00, 4.0312e-01,\n",
      "        9.4183e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([197.9738, 234.3982, 251.3344, 242.4068,   7.8373,   7.8375,   7.8384,\n",
      "        369.1006, 369.1006, 369.1006,   7.8380,   7.8379, 369.1006, 369.1006,\n",
      "        369.1006, 369.1006, 369.1006,  60.1896,  60.1896,   7.8389, 369.1006,\n",
      "        369.1006, 369.1006, 369.1006, 369.1006,  60.1896,  60.1896, 369.1006,\n",
      "         60.1896,  60.1896,   5.2026, 369.1006, 369.1006, 369.1006, 369.1006,\n",
      "        369.1006,  60.1896,  60.1896, 369.1006,  60.1896,  60.1896,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 369.1006,   5.2026,   5.2025, 369.1006,   5.2026,\n",
      "          5.2025, 369.1006,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        369.1006, 369.1006, 369.1006, 369.1006,  60.1896,  60.1896,  60.1896,\n",
      "         60.1896, 369.1006, 369.1006, 369.1006,  60.1896,  60.1896,  60.1896,\n",
      "         60.1896,   5.2026,  60.1896,  60.1896,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 587 was 94.1%\n",
      "tensor([1.9852e-23, 3.2566e-06, 2.7253e-06, 2.5278e-06, 2.6294e-06, 6.6691e-09,\n",
      "        4.6934e-09, 4.4053e-09, 4.4719e-09, 4.5088e-06, 4.3819e-06, 4.4558e-06,\n",
      "        8.5819e-05, 7.7888e-05, 7.8247e-05, 4.1640e-06, 4.2389e-06, 4.9036e-05,\n",
      "        4.9369e-05, 3.5958e-01, 3.7177e-01, 1.4412e+00, 1.4290e+00, 4.1118e-06,\n",
      "        4.8820e-05, 3.5118e-01, 1.4497e+00, 3.1680e-01, 1.4846e+00, 4.0228e-01,\n",
      "        9.4195e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([198.2431, 234.6870, 251.6571, 242.6342,   7.8353,   7.8360,   7.8348,\n",
      "        369.5214, 369.5214, 369.5214,   7.8352,   7.8363, 369.5214, 369.5214,\n",
      "        369.5214, 369.5214, 369.5214,  60.2687,  60.2687,   7.8342, 369.5214,\n",
      "        369.5214, 369.5214, 369.5214, 369.5214,  60.2687,  60.2687, 369.5214,\n",
      "         60.2687,  60.2687,   5.2026, 369.5214, 369.5214, 369.5214, 369.5214,\n",
      "        369.5214,  60.2687,  60.2687, 369.5214,  60.2687,  60.2687,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 369.5214,   5.2026,   5.2025, 369.5214,   5.2026,\n",
      "          5.2025, 369.5214,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        369.5214, 369.5214, 369.5214, 369.5214,  60.2687,  60.2687,  60.2687,\n",
      "         60.2687, 369.5214, 369.5214, 369.5214,  60.2687,  60.2687,  60.2687,\n",
      "         60.2687,   5.2026,  60.2687,  60.2687,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 588 was 94.2%\n",
      "tensor([6.6174e-24, 3.2511e-06, 2.7211e-06, 2.5236e-06, 2.6260e-06, 6.6218e-09,\n",
      "        4.6604e-09, 4.3756e-09, 4.4422e-09, 4.4998e-06, 4.3714e-06, 4.4476e-06,\n",
      "        8.4982e-05, 7.7148e-05, 7.7533e-05, 4.1558e-06, 4.2298e-06, 4.8593e-05,\n",
      "        4.8899e-05, 3.5882e-01, 3.7108e-01, 1.4384e+00, 1.4261e+00, 4.1046e-06,\n",
      "        4.8387e-05, 3.5042e-01, 1.4469e+00, 3.1618e-01, 1.4816e+00, 4.0146e-01,\n",
      "        9.4207e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([198.5124, 234.9757, 251.9792, 242.8618,   7.8313,   7.8324,   7.8333,\n",
      "        369.9422, 369.9422, 369.9422,   7.8337,   7.8315, 369.9422, 369.9422,\n",
      "        369.9422, 369.9422, 369.9422,  60.3479,  60.3479,   7.8332, 369.9422,\n",
      "        369.9422, 369.9422, 369.9422, 369.9422,  60.3479,  60.3479, 369.9422,\n",
      "         60.3479,  60.3479,   5.2026, 369.9422, 369.9422, 369.9422, 369.9422,\n",
      "        369.9422,  60.3479,  60.3479, 369.9422,  60.3479,  60.3479,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 369.9422,   5.2026,   5.2025, 369.9422,   5.2026,\n",
      "          5.2025, 369.9422,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        369.9422, 369.9422, 369.9422, 369.9422,  60.3479,  60.3479,  60.3479,\n",
      "         60.3479, 369.9422, 369.9422, 369.9422,  60.3479,  60.3479,  60.3479,\n",
      "         60.3479,   5.2026,  60.3479,  60.3479,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 589 was 94.2%\n",
      "tensor([3.2929e-08, 3.2535e-06, 2.7237e-06, 2.5268e-06, 2.6296e-06, 6.6174e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4908e-06, 4.3634e-06, 4.4373e-06,\n",
      "        8.4095e-05, 7.6441e-05, 7.6772e-05, 4.1462e-06, 4.2230e-06, 4.8114e-05,\n",
      "        4.8452e-05, 3.5802e-01, 3.7031e-01, 1.4355e+00, 1.4232e+00, 4.0959e-06,\n",
      "        4.7934e-05, 3.4976e-01, 1.4439e+00, 3.1559e-01, 1.4785e+00, 4.0065e-01,\n",
      "        9.4219e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([198.7819, 235.2645, 252.3005, 243.0897,   7.8292,   7.8309,   7.8297,\n",
      "        370.3630, 370.3630, 370.3630,   7.8289,   7.8299, 370.3630, 370.3630,\n",
      "        370.3630, 370.3630, 370.3630,  60.4270,  60.4270,   7.8304, 370.3630,\n",
      "        370.3630, 370.3630, 370.3630, 370.3630,  60.4270,  60.4270, 370.3630,\n",
      "         60.4270,  60.4270,   5.2026, 370.3630, 370.3630, 370.3630, 370.3630,\n",
      "        370.3630,  60.4270,  60.4270, 370.3630,  60.4270,  60.4270,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 370.3630,   5.2026,   5.2025, 370.3630,   5.2026,\n",
      "          5.2025, 370.3630,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        370.3630, 370.3630, 370.3630, 370.3630,  60.4270,  60.4270,  60.4270,\n",
      "         60.4270, 370.3630, 370.3630, 370.3630,  60.4270,  60.4270,  60.4270,\n",
      "         60.4270,   5.2026,  60.4270,  60.4270,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 590 was 94.2%\n",
      "tensor([3.2660e-08, 3.2478e-06, 2.7192e-06, 2.5225e-06, 2.6261e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4807e-06, 4.3528e-06, 4.4295e-06,\n",
      "        8.3232e-05, 7.5701e-05, 7.6069e-05, 4.1386e-06, 4.2136e-06, 4.7677e-05,\n",
      "        4.7983e-05, 3.5720e-01, 3.6960e-01, 1.4327e+00, 1.4202e+00, 4.0874e-06,\n",
      "        4.7487e-05, 3.4906e-01, 1.4409e+00, 3.1494e-01, 1.4755e+00, 3.9983e-01,\n",
      "        9.4230e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([199.0515, 235.5532, 252.6212, 243.3179,   7.8266,   7.8260,   7.8281,\n",
      "        370.7838, 370.7838, 370.7838,   7.8279,   7.8270, 370.7838, 370.7838,\n",
      "        370.7838, 370.7838, 370.7838,  60.5062,  60.5062,   7.8270, 370.7838,\n",
      "        370.7838, 370.7838, 370.7838, 370.7838,  60.5062,  60.5062, 370.7838,\n",
      "         60.5062,  60.5062,   5.2026, 370.7838, 370.7838, 370.7838, 370.7838,\n",
      "        370.7838,  60.5062,  60.5062, 370.7838,  60.5062,  60.5062,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 370.7838,   5.2026,   5.2025, 370.7838,   5.2026,\n",
      "          5.2025, 370.7838,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        370.7838, 370.7838, 370.7838, 370.7838,  60.5062,  60.5062,  60.5062,\n",
      "         60.5062, 370.7838, 370.7838, 370.7838,  60.5062,  60.5062,  60.5062,\n",
      "         60.5062,   5.2026,  60.5062,  60.5062,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 591 was 94.2%\n",
      "tensor([0.0000e+00, 3.2343e-06, 2.7081e-06, 2.5112e-06, 2.6160e-06, 6.4768e-09,\n",
      "        4.5591e-09, 4.2852e-09, 4.3512e-09, 4.4716e-06, 4.3449e-06, 4.4197e-06,\n",
      "        8.2388e-05, 7.5003e-05, 7.5312e-05, 4.1283e-06, 4.2062e-06, 4.7217e-05,\n",
      "        4.7547e-05, 3.5639e-01, 3.6892e-01, 1.4299e+00, 1.4173e+00, 4.0797e-06,\n",
      "        4.7051e-05, 3.4832e-01, 1.4380e+00, 3.1434e-01, 1.4725e+00, 3.9901e-01,\n",
      "        9.4242e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([199.3212, 235.8419, 252.9411, 243.5462,   7.8239,   7.8251,   7.8232,\n",
      "        371.2046, 371.2046, 371.2046,   7.8245,   7.8254, 371.2046, 371.2046,\n",
      "        371.2046, 371.2046, 371.2046,  60.5853,  60.5853,   7.8242, 371.2046,\n",
      "        371.2046, 371.2046, 371.2046, 371.2046,  60.5853,  60.5853, 371.2046,\n",
      "         60.5853,  60.5853,   5.2026, 371.2046, 371.2046, 371.2046, 371.2046,\n",
      "        371.2046,  60.5853,  60.5853, 371.2046,  60.5853,  60.5853,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 371.2046,   5.2026,   5.2025, 371.2046,   5.2026,\n",
      "          5.2025, 371.2046,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        371.2046, 371.2046, 371.2046, 371.2046,  60.5853,  60.5853,  60.5853,\n",
      "         60.5853, 371.2046, 371.2046, 371.2046,  60.5853,  60.5853,  60.5853,\n",
      "         60.5853,   5.2026,  60.5853,  60.5853,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 592 was 94.2%\n",
      "tensor([0.0000e+00, 3.2287e-06, 2.7038e-06, 2.5071e-06, 2.6126e-06, 6.4284e-09,\n",
      "        4.5251e-09, 4.2547e-09, 4.3207e-09, 4.4621e-06, 4.3340e-06, 4.4124e-06,\n",
      "        8.1530e-05, 7.4254e-05, 7.4612e-05, 4.1208e-06, 4.1968e-06, 4.6783e-05,\n",
      "        4.7070e-05, 3.5561e-01, 3.6819e-01, 1.4270e+00, 1.4144e+00, 4.0715e-06,\n",
      "        4.6605e-05, 3.4759e-01, 1.4351e+00, 3.1375e-01, 1.4694e+00, 3.9821e-01,\n",
      "        9.4254e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([199.5911, 236.1305, 253.2603, 243.7748,   7.8211,   7.8215,   7.8223,\n",
      "        371.6254, 371.6254, 371.6254,   7.8216,   7.8205, 371.6254, 371.6254,\n",
      "        371.6254, 371.6254, 371.6254,  60.6645,  60.6645,   7.8226, 371.6254,\n",
      "        371.6254, 371.6254, 371.6254, 371.6254,  60.6645,  60.6645, 371.6254,\n",
      "         60.6645,  60.6645,   5.2026, 371.6254, 371.6254, 371.6254, 371.6254,\n",
      "        371.6254,  60.6645,  60.6645, 371.6254,  60.6645,  60.6645,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 371.6254,   5.2026,   5.2025, 371.6254,   5.2026,\n",
      "          5.2025, 371.6254,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        371.6254, 371.6254, 371.6254, 371.6254,  60.6645,  60.6645,  60.6645,\n",
      "         60.6645, 371.6254, 371.6254, 371.6254,  60.6645,  60.6645,  60.6645,\n",
      "         60.6645,   5.2026,  60.6645,  60.6645,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 593 was 94.2%\n",
      "tensor([3.9705e-23, 3.2230e-06, 2.6993e-06, 2.5029e-06, 2.6092e-06, 6.3802e-09,\n",
      "        4.4908e-09, 4.2245e-09, 4.2900e-09, 4.4521e-06, 4.3255e-06, 4.4023e-06,\n",
      "        8.0662e-05, 7.3566e-05, 7.3876e-05, 4.1117e-06, 4.1901e-06, 4.6320e-05,\n",
      "        4.6625e-05, 3.5478e-01, 3.6745e-01, 1.4242e+00, 1.4115e+00, 4.0627e-06,\n",
      "        4.6153e-05, 3.4693e-01, 1.4321e+00, 3.1312e-01, 1.4664e+00, 3.9740e-01,\n",
      "        9.4265e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([199.8612, 236.4191, 253.5786, 244.0036,   7.8185,   7.8199,   7.8186,\n",
      "        372.0461, 372.0461, 372.0461,   7.8188,   7.8195, 372.0461, 372.0461,\n",
      "        372.0461, 372.0461, 372.0461,  60.7436,  60.7436,   7.8179, 372.0461,\n",
      "        372.0461, 372.0461, 372.0461, 372.0461,  60.7436,  60.7436, 372.0461,\n",
      "         60.7436,  60.7436,   5.2026, 372.0461, 372.0461, 372.0461, 372.0461,\n",
      "        372.0461,  60.7436,  60.7436, 372.0461,  60.7436,  60.7436,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 372.0461,   5.2026,   5.2025, 372.0461,   5.2026,\n",
      "          5.2025, 372.0461,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        372.0461, 372.0461, 372.0461, 372.0461,  60.7436,  60.7436,  60.7436,\n",
      "         60.7436, 372.0461, 372.0461, 372.0461,  60.7436,  60.7436,  60.7436,\n",
      "         60.7436,   5.2026,  60.7436,  60.7436,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 594 was 94.2%\n",
      "tensor([0.0000e+00, 3.2175e-06, 2.6952e-06, 2.4988e-06, 2.6058e-06, 6.3317e-09,\n",
      "        4.4572e-09, 4.1938e-09, 4.2594e-09, 4.4433e-06, 4.3152e-06, 4.3942e-06,\n",
      "        7.9836e-05, 7.2821e-05, 7.3162e-05, 4.1034e-06, 4.1804e-06, 4.5878e-05,\n",
      "        4.6156e-05, 3.5403e-01, 3.6675e-01, 1.4214e+00, 1.4086e+00, 4.0556e-06,\n",
      "        4.5719e-05, 3.4619e-01, 1.4293e+00, 3.1250e-01, 1.4634e+00, 3.9659e-01,\n",
      "        9.4277e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([200.1315, 236.7076, 253.8961, 244.2326,   7.8164,   7.8149,   7.8164,\n",
      "        372.4669, 372.4669, 372.4669,   7.8159,   7.8159, 372.4669, 372.4669,\n",
      "        372.4669, 372.4669, 372.4669,  60.8227,  60.8227,   7.8169, 372.4669,\n",
      "        372.4669, 372.4669, 372.4669, 372.4669,  60.8227,  60.8227, 372.4669,\n",
      "         60.8227,  60.8227,   5.2026, 372.4669, 372.4669, 372.4669, 372.4669,\n",
      "        372.4669,  60.8227,  60.8227, 372.4669,  60.8227,  60.8227,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 372.4669,   5.2026,   5.2025, 372.4669,   5.2026,\n",
      "          5.2025, 372.4669,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        372.4669, 372.4669, 372.4669, 372.4669,  60.8227,  60.8227,  60.8227,\n",
      "         60.8227, 372.4669, 372.4669, 372.4669,  60.8227,  60.8227,  60.8227,\n",
      "         60.8227,   5.2026,  60.8227,  60.8227,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 595 was 94.2%\n",
      "tensor([3.1310e-08, 3.2195e-06, 2.6974e-06, 2.5015e-06, 2.6090e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4328e-06, 4.3073e-06, 4.3850e-06,\n",
      "        7.8967e-05, 7.2132e-05, 7.2438e-05, 4.0946e-06, 4.1732e-06, 4.5428e-05,\n",
      "        4.5722e-05, 3.5320e-01, 3.6604e-01, 1.4186e+00, 1.4057e+00, 4.0463e-06,\n",
      "        4.5267e-05, 3.4549e-01, 1.4264e+00, 3.1191e-01, 1.4604e+00, 3.9579e-01,\n",
      "        9.4289e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([200.4020, 236.9960, 254.2128, 244.4617,   7.8116,   7.8140,   7.8134,\n",
      "        372.8877, 372.8877, 372.8877,   7.8143,   7.8143, 372.8877, 372.8877,\n",
      "        372.8877, 372.8877, 372.8877,  60.9019,  60.9019,   7.8121, 372.8877,\n",
      "        372.8877, 372.8877, 372.8877, 372.8877,  60.9019,  60.9019, 372.8877,\n",
      "         60.9019,  60.9019,   5.2026, 372.8877, 372.8877, 372.8877, 372.8877,\n",
      "        372.8877,  60.9019,  60.9019, 372.8877,  60.9019,  60.9019,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 372.8877,   5.2026,   5.2025, 372.8877,   5.2026,\n",
      "          5.2025, 372.8877,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        372.8877, 372.8877, 372.8877, 372.8877,  60.9019,  60.9019,  60.9019,\n",
      "         60.9019, 372.8877, 372.8877, 372.8877,  60.9019,  60.9019,  60.9019,\n",
      "         60.9019,   5.2026,  60.9019,  60.9019,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 596 was 94.3%\n",
      "tensor([3.1034e-08, 3.2140e-06, 2.6933e-06, 2.4976e-06, 2.6057e-06, 1.0753e-23,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4254e-06, 4.2972e-06, 4.3763e-06,\n",
      "        7.8139e-05, 7.1394e-05, 7.1699e-05, 4.0859e-06, 4.1645e-06, 4.4969e-05,\n",
      "        4.5246e-05, 3.5246e-01, 3.6533e-01, 1.4158e+00, 1.4028e+00, 4.0397e-06,\n",
      "        4.4833e-05, 3.4477e-01, 1.4235e+00, 3.1133e-01, 1.4574e+00, 3.9501e-01,\n",
      "        9.4300e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([200.6728, 237.2844, 254.5281, 244.6912,   7.8096,   7.8111,   7.8112,\n",
      "        373.3084, 373.3084, 373.3084,   7.8107,   7.8094, 373.3084, 373.3084,\n",
      "        373.3084, 373.3084, 373.3084,  60.9810,  60.9810,   7.8111, 373.3084,\n",
      "        373.3084, 373.3084, 373.3084, 373.3084,  60.9810,  60.9810, 373.3084,\n",
      "         60.9810,  60.9810,   5.2026, 373.3084, 373.3084, 373.3084, 373.3084,\n",
      "        373.3084,  60.9810,  60.9810, 373.3084,  60.9810,  60.9810,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 373.3084,   5.2026,   5.2025, 373.3084,   5.2026,\n",
      "          5.2025, 373.3084,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        373.3084, 373.3084, 373.3084, 373.3084,  60.9810,  60.9810,  60.9810,\n",
      "         60.9810, 373.3084, 373.3084, 373.3084,  60.9810,  60.9810,  60.9810,\n",
      "         60.9810,   5.2026,  60.9810,  60.9810,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 597 was 94.3%\n",
      "tensor([0.0000e+00, 3.2008e-06, 2.6822e-06, 2.4866e-06, 2.5956e-06, 6.1858e-09,\n",
      "        4.3542e-09, 4.1020e-09, 4.1666e-09, 4.4151e-06, 4.2881e-06, 4.3666e-06,\n",
      "        7.7290e-05, 7.0706e-05, 7.0989e-05, 4.0772e-06, 4.1572e-06, 4.4520e-05,\n",
      "        4.4802e-05, 3.5165e-01, 3.6458e-01, 1.4130e+00, 1.4000e+00, 4.0305e-06,\n",
      "        4.4390e-05, 3.4411e-01, 1.4206e+00, 3.1069e-01, 1.4544e+00, 3.9419e-01,\n",
      "        9.4312e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([200.9434, 237.5722, 254.8447, 244.9208,   7.8070,   7.8075,   7.8061,\n",
      "        373.7292, 373.7292, 373.7292,   7.8084,   7.8083, 373.7292, 373.7292,\n",
      "        373.7292, 373.7292, 373.7292,  61.0602,  61.0602,   7.8089, 373.7292,\n",
      "        373.7292, 373.7292, 373.7292, 373.7292,  61.0602,  61.0602, 373.7292,\n",
      "         61.0602,  61.0602,   5.2026, 373.7292, 373.7292, 373.7292, 373.7292,\n",
      "        373.7292,  61.0602,  61.0602, 373.7292,  61.0602,  61.0602,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 373.7292,   5.2026,   5.2025, 373.7292,   5.2026,\n",
      "          5.2025, 373.7292,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        373.7292, 373.7292, 373.7292, 373.7292,  61.0602,  61.0602,  61.0602,\n",
      "         61.0602, 373.7292, 373.7292, 373.7292,  61.0602,  61.0602,  61.0602,\n",
      "         61.0602,   5.2026,  61.0602,  61.0602,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 598 was 94.3%\n",
      "tensor([0.0000e+00, 3.1951e-06, 2.6780e-06, 2.4826e-06, 2.5923e-06, 6.1373e-09,\n",
      "        4.3212e-09, 4.0720e-09, 4.1363e-09, 4.4056e-06, 4.2793e-06, 4.3595e-06,\n",
      "        7.6460e-05, 6.9994e-05, 7.0283e-05, 4.0686e-06, 4.1482e-06, 4.4099e-05,\n",
      "        4.4365e-05, 3.5086e-01, 3.6386e-01, 1.4102e+00, 1.3971e+00, 4.0222e-06,\n",
      "        4.3957e-05, 3.4338e-01, 1.4177e+00, 3.1015e-01, 1.4514e+00, 3.9341e-01,\n",
      "        9.4323e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([201.2142, 237.8598, 255.1604, 245.1505,   7.8042,   7.8051,   7.8051,\n",
      "        374.1499, 374.1499, 374.1499,   7.8048,   7.8060, 374.1499, 374.1499,\n",
      "        374.1499, 374.1499, 374.1499,  61.1393,  61.1393,   7.8040, 374.1499,\n",
      "        374.1499, 374.1499, 374.1499, 374.1499,  61.1393,  61.1393, 374.1499,\n",
      "         61.1393,  61.1393,   5.2026, 374.1499, 374.1499, 374.1499, 374.1499,\n",
      "        374.1499,  61.1393,  61.1393, 374.1499,  61.1393,  61.1393,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 374.1499,   5.2026,   5.2025, 374.1499,   5.2026,\n",
      "          5.2025, 374.1499,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        374.1499, 374.1499, 374.1499, 374.1499,  61.1393,  61.1393,  61.1393,\n",
      "         61.1393, 374.1499, 374.1499, 374.1499,  61.1393,  61.1393,  61.1393,\n",
      "         61.1393,   5.2026,  61.1393,  61.1393,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 599 was 94.3%\n",
      "tensor([0.0000e+00, 3.1896e-06, 2.6737e-06, 2.4784e-06, 2.5889e-06, 6.0894e-09,\n",
      "        4.2870e-09, 4.0412e-09, 4.1052e-09, 4.3965e-06, 4.2692e-06, 4.3498e-06,\n",
      "        7.5651e-05, 6.9284e-05, 6.9573e-05, 4.0602e-06, 4.1399e-06, 4.3647e-05,\n",
      "        4.3901e-05, 3.5006e-01, 3.6321e-01, 1.4074e+00, 1.3942e+00, 4.0150e-06,\n",
      "        4.3523e-05, 3.4266e-01, 1.4149e+00, 3.0951e-01, 1.4484e+00, 3.9261e-01,\n",
      "        9.4335e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([201.4855, 238.1472, 255.4750, 245.3802,   7.8023,   7.8022,   7.8014,\n",
      "        374.5707, 374.5707, 374.5707,   7.8026,   7.8010, 374.5707, 374.5707,\n",
      "        374.5707, 374.5707, 374.5707,  61.2185,  61.2185,   7.8030, 374.5707,\n",
      "        374.5707, 374.5707, 374.5707, 374.5707,  61.2185,  61.2185, 374.5707,\n",
      "         61.2185,  61.2185,   5.2026, 374.5707, 374.5707, 374.5707, 374.5707,\n",
      "        374.5707,  61.2185,  61.2185, 374.5707,  61.2185,  61.2185,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 374.5707,   5.2026,   5.2025, 374.5707,   5.2026,\n",
      "          5.2025, 374.5707,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        374.5707, 374.5707, 374.5707, 374.5707,  61.2185,  61.2185,  61.2185,\n",
      "         61.2185, 374.5707, 374.5707, 374.5707,  61.2185,  61.2185,  61.2185,\n",
      "         61.2185,   5.2026,  61.2185,  61.2185,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 600 was 94.3%\n",
      "tensor([0.0000e+00, 3.1840e-06, 2.6693e-06, 2.4745e-06, 2.5854e-06, 6.0393e-09,\n",
      "        4.2516e-09, 4.0095e-09, 4.0729e-09, 4.3861e-06, 4.2607e-06, 4.3412e-06,\n",
      "        7.4787e-05, 6.8583e-05, 6.8841e-05, 4.0515e-06, 4.1327e-06, 4.3193e-05,\n",
      "        4.3451e-05, 3.4931e-01, 3.6243e-01, 1.4046e+00, 1.3914e+00, 4.0061e-06,\n",
      "        4.3062e-05, 3.4199e-01, 1.4120e+00, 3.0891e-01, 1.4454e+00, 3.9183e-01,\n",
      "        9.4346e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([201.7571, 238.4341, 255.7885, 245.6099,   7.7981,   7.8006,   7.7998,\n",
      "        374.9914, 374.9914, 374.9914,   7.7989,   7.7999, 374.9914, 374.9914,\n",
      "        374.9914, 374.9914, 374.9914,  61.2976,  61.2976,   7.7981, 374.9914,\n",
      "        374.9914, 374.9914, 374.9914, 374.9914,  61.2976,  61.2976, 374.9914,\n",
      "         61.2976,  61.2976,   5.2026, 374.9914, 374.9914, 374.9914, 374.9914,\n",
      "        374.9914,  61.2976,  61.2976, 374.9914,  61.2976,  61.2976,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 374.9914,   5.2026,   5.2025, 374.9914,   5.2026,\n",
      "          5.2025, 374.9914,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        374.9914, 374.9914, 374.9914, 374.9914,  61.2976,  61.2976,  61.2976,\n",
      "         61.2976, 374.9914, 374.9914, 374.9914,  61.2976,  61.2976,  61.2976,\n",
      "         61.2976,   5.2026,  61.2976,  61.2976,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 601 was 94.3%\n",
      "tensor([2.9677e-08, 3.1860e-06, 2.6715e-06, 2.4769e-06, 2.5884e-06, 2.4815e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3785e-06, 4.2507e-06, 4.3324e-06,\n",
      "        7.3963e-05, 6.7836e-05, 6.8112e-05, 4.0435e-06, 4.1236e-06, 4.2732e-05,\n",
      "        4.2970e-05, 3.4854e-01, 3.6177e-01, 1.4019e+00, 1.3886e+00, 3.9994e-06,\n",
      "        4.2624e-05, 3.4132e-01, 1.4091e+00, 3.0828e-01, 1.4425e+00, 3.9106e-01,\n",
      "        9.4358e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([202.0295, 238.7206, 256.1002, 245.8395,   7.7962,   7.7954,   7.7968,\n",
      "        375.4121, 375.4121, 375.4121,   7.7967,   7.7963, 375.4121, 375.4121,\n",
      "        375.4121, 375.4121, 375.4121,  61.3767,  61.3767,   7.7971, 375.4121,\n",
      "        375.4121, 375.4121, 375.4121, 375.4121,  61.3767,  61.3767, 375.4121,\n",
      "         61.3767,  61.3767,   5.2026, 375.4121, 375.4121, 375.4121, 375.4121,\n",
      "        375.4121,  61.3767,  61.3767, 375.4121,  61.3767,  61.3767,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 375.4121,   5.2026,   5.2025, 375.4121,   5.2026,\n",
      "          5.2025, 375.4121,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        375.4121, 375.4121, 375.4121, 375.4121,  61.3767,  61.3767,  61.3767,\n",
      "         61.3767, 375.4121, 375.4121, 375.4121,  61.3767,  61.3767,  61.3767,\n",
      "         61.3767,   5.2026,  61.3767,  61.3767,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 602 was 94.3%\n",
      "tensor([0.0000e+00, 3.1729e-06, 2.6608e-06, 2.4663e-06, 2.5787e-06, 5.9336e-09,\n",
      "        4.1771e-09, 3.9420e-09, 4.0047e-09, 4.3680e-06, 4.2426e-06, 4.3231e-06,\n",
      "        7.3049e-05, 6.7085e-05, 6.7323e-05, 4.0343e-06, 4.1162e-06, 4.2240e-05,\n",
      "        4.2491e-05, 3.4772e-01, 3.6104e-01, 1.3991e+00, 1.3857e+00, 3.9903e-06,\n",
      "        4.2132e-05, 3.4060e-01, 1.4063e+00, 3.0772e-01, 1.4395e+00, 3.9027e-01,\n",
      "        9.4369e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([202.3025, 239.0064, 256.4104, 246.0688,   7.7935,   7.7945,   7.7930,\n",
      "        375.8329, 375.8329, 375.8329,   7.7938,   7.7946, 375.8329, 375.8329,\n",
      "        375.8329, 375.8329, 375.8329,  61.4559,  61.4559,   7.7921, 375.8329,\n",
      "        375.8329, 375.8329, 375.8329, 375.8329,  61.4559,  61.4559, 375.8329,\n",
      "         61.4559,  61.4559,   5.2026, 375.8329, 375.8329, 375.8329, 375.8329,\n",
      "        375.8329,  61.4559,  61.4559, 375.8329,  61.4559,  61.4559,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 375.8329,   5.2026,   5.2025, 375.8329,   5.2026,\n",
      "          5.2025, 375.8329,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        375.8329, 375.8329, 375.8329, 375.8329,  61.4559,  61.4559,  61.4559,\n",
      "         61.4559, 375.8329, 375.8329, 375.8329,  61.4559,  61.4559,  61.4559,\n",
      "         61.4559,   5.2026,  61.4559,  61.4559,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 603 was 94.3%\n",
      "tensor([1.3235e-23, 3.1674e-06, 2.6567e-06, 2.4623e-06, 2.5753e-06, 5.8768e-09,\n",
      "        4.1367e-09, 3.9050e-09, 3.9671e-09, 4.3594e-06, 4.2323e-06, 4.3153e-06,\n",
      "        7.2154e-05, 6.6274e-05, 6.6530e-05, 4.0265e-06, 4.1074e-06, 4.1740e-05,\n",
      "        4.1958e-05, 3.4700e-01, 3.6035e-01, 1.3964e+00, 1.3830e+00, 3.9835e-06,\n",
      "        4.1636e-05, 3.3988e-01, 1.4035e+00, 3.0712e-01, 1.4366e+00, 3.8951e-01,\n",
      "        9.4380e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([202.5765, 239.2913, 256.7184, 246.2977,   7.7909,   7.7908,   7.7914,\n",
      "        376.2536, 376.2536, 376.2536,   7.7908,   7.7895, 376.2536, 376.2536,\n",
      "        376.2536, 376.2536, 376.2536,  61.5350,  61.5350,   7.7911, 376.2536,\n",
      "        376.2536, 376.2536, 376.2536, 376.2536,  61.5350,  61.5350, 376.2536,\n",
      "         61.5350,  61.5350,   5.2026, 376.2536, 376.2536, 376.2536, 376.2536,\n",
      "        376.2536,  61.5350,  61.5350, 376.2536,  61.5350,  61.5350,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 376.2536,   5.2026,   5.2025, 376.2536,   5.2026,\n",
      "          5.2025, 376.2536,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        376.2536, 376.2536, 376.2536, 376.2536,  61.5350,  61.5350,  61.5350,\n",
      "         61.5350, 376.2536, 376.2536, 376.2536,  61.5350,  61.5350,  61.5350,\n",
      "         61.5350,   5.2026,  61.5350,  61.5350,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 604 was 94.3%\n",
      "tensor([0.0000e+00, 3.1617e-06, 2.6522e-06, 2.4582e-06, 2.5718e-06, 5.8132e-09,\n",
      "        4.0909e-09, 3.8637e-09, 3.9248e-09, 4.3495e-06, 4.2240e-06, 4.3056e-06,\n",
      "        7.1139e-05, 6.5433e-05, 6.5642e-05, 4.0175e-06, 4.1005e-06, 4.1170e-05,\n",
      "        4.1403e-05, 3.4620e-01, 3.5962e-01, 1.3937e+00, 1.3802e+00, 3.9744e-06,\n",
      "        4.1076e-05, 3.3923e-01, 1.4007e+00, 3.0651e-01, 1.4337e+00, 3.8875e-01,\n",
      "        9.4392e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([202.8518, 239.5748, 257.0236, 246.5256,   7.7869,   7.7892,   7.7862,\n",
      "        376.6743, 376.6743, 376.6743,   7.7892,   7.7884, 376.6743, 376.6743,\n",
      "        376.6743, 376.6743, 376.6743,  61.6142,  61.6142,   7.7875, 376.6743,\n",
      "        376.6743, 376.6743, 376.6743, 376.6743,  61.6142,  61.6142, 376.6743,\n",
      "         61.6142,  61.6142,   5.2026, 376.6743, 376.6743, 376.6743, 376.6743,\n",
      "        376.6743,  61.6142,  61.6142, 376.6743,  61.6142,  61.6142,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 376.6743,   5.2026,   5.2025, 376.6743,   5.2026,\n",
      "          5.2025, 376.6743,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        376.6743, 376.6743, 376.6743, 376.6743,  61.6142,  61.6142,  61.6142,\n",
      "         61.6142, 376.6743, 376.6743, 376.6743,  61.6142,  61.6142,  61.6142,\n",
      "         61.6142,   5.2026,  61.6142,  61.6142,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 605 was 94.4%\n",
      "tensor([0.0000e+00, 3.1560e-06, 2.6481e-06, 2.4545e-06, 2.5683e-06, 5.7429e-09,\n",
      "        4.0409e-09, 3.8173e-09, 3.8779e-09, 4.3413e-06, 4.2146e-06, 4.2982e-06,\n",
      "        7.0090e-05, 6.4475e-05, 6.4701e-05, 4.0096e-06, 4.0913e-06, 4.0572e-05,\n",
      "        4.0778e-05, 3.4550e-01, 3.5887e-01, 1.3910e+00, 1.3776e+00, 3.9676e-06,\n",
      "        4.0480e-05, 3.3853e-01, 1.3980e+00, 3.0597e-01, 1.4308e+00, 3.8805e-01,\n",
      "        9.4402e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([203.1290, 239.8562, 257.3248, 246.7522,   7.7843,   7.7841,   7.7853,\n",
      "        377.0950, 377.0950, 377.0950,   7.7855,   7.7854, 377.0950, 377.0950,\n",
      "        377.0950, 377.0950, 377.0950,  61.6933,  61.6933,   7.7859, 377.0950,\n",
      "        377.0950, 377.0950, 377.0950, 377.0950,  61.6933,  61.6933, 377.0950,\n",
      "         61.6933,  61.6933,   5.2026, 377.0950, 377.0950, 377.0950, 377.0950,\n",
      "        377.0950,  61.6933,  61.6933, 377.0950,  61.6933,  61.6933,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 377.0950,   5.2026,   5.2025, 377.0950,   5.2026,\n",
      "          5.2025, 377.0950,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        377.0950, 377.0950, 377.0950, 377.0950,  61.6933,  61.6933,  61.6933,\n",
      "         61.6933, 377.0950, 377.0950, 377.0950,  61.6933,  61.6933,  61.6933,\n",
      "         61.6933,   5.2026,  61.6933,  61.6933,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 606 was 94.4%\n",
      "tensor([0.0000e+00, 3.1495e-06, 2.6438e-06, 2.4506e-06, 2.5652e-06, 5.2871e-09,\n",
      "        3.6929e-09, 3.4806e-09, 3.5401e-09, 4.3324e-06, 4.2073e-06, 4.2895e-06,\n",
      "        6.4331e-05, 5.9007e-05, 5.9290e-05, 4.0017e-06, 4.0851e-06, 3.6635e-05,\n",
      "        3.6908e-05, 3.4480e-01, 3.5835e-01, 1.3885e+00, 1.3749e+00, 3.9598e-06,\n",
      "        3.6520e-05, 3.3799e-01, 1.3954e+00, 3.0553e-01, 1.4284e+00, 3.8742e-01,\n",
      "        9.4413e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([203.3984, 240.1439, 257.6406, 246.9839,   7.7813,   7.7831,   7.7828,\n",
      "        377.5157, 377.5157, 377.5157,   7.7818,   7.7830, 377.5157, 377.5157,\n",
      "        377.5157, 377.5157, 377.5157,  61.7724,  61.7724,   7.7809, 377.5157,\n",
      "        377.5157, 377.5157, 377.5157, 377.5157,  61.7724,  61.7724, 377.5157,\n",
      "         61.7724,  61.7724,   5.2026, 377.5157, 377.5157, 377.5157, 377.5157,\n",
      "        377.5157,  61.7724,  61.7724, 377.5157,  61.7724,  61.7724,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 377.5157,   5.2026,   5.2025, 377.5157,   5.2026,\n",
      "          5.2025, 377.5157,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        377.5157, 377.5157, 377.5157, 377.5157,  61.7724,  61.7724,  61.7724,\n",
      "         61.7724, 377.5157, 377.5157, 377.5157,  61.7724,  61.7724,  61.7724,\n",
      "         61.7724,   5.2026,  61.7724,  61.7724,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 607 was 94.4%\n",
      "tensor([2.5510e-08, 3.1506e-06, 2.6450e-06, 2.4521e-06, 2.5671e-06, 4.9631e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3240e-06, 4.1973e-06, 4.2811e-06,\n",
      "        6.3250e-05, 5.8017e-05, 5.8317e-05, 3.9943e-06, 4.0767e-06, 3.5987e-05,\n",
      "        3.6245e-05, 3.4407e-01, 3.5769e-01, 1.3858e+00, 1.3721e+00, 3.9531e-06,\n",
      "        3.5882e-05, 3.3732e-01, 1.3927e+00, 3.0491e-01, 1.4256e+00, 3.8666e-01,\n",
      "        9.4423e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([203.6687, 240.4300, 257.9556, 247.2145,   7.7791,   7.7779,   7.7798,\n",
      "        377.9364, 377.9364, 377.9364,   7.7796,   7.7794, 377.9364, 377.9364,\n",
      "        377.9364, 377.9364, 377.9364,  61.8516,  61.8516,   7.7799, 377.9364,\n",
      "        377.9364, 377.9364, 377.9364, 377.9364,  61.8516,  61.8516, 377.9364,\n",
      "         61.8516,  61.8516,   5.2026, 377.9364, 377.9364, 377.9364, 377.9364,\n",
      "        377.9364,  61.8516,  61.8516, 377.9364,  61.8516,  61.8516,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 377.9364,   5.2026,   5.2025, 377.9364,   5.2026,\n",
      "          5.2025, 377.9364,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        377.9364, 377.9364, 377.9364, 377.9364,  61.8516,  61.8516,  61.8516,\n",
      "         61.8516, 377.9364, 377.9364, 377.9364,  61.8516,  61.8516,  61.8516,\n",
      "         61.8516,   5.2026,  61.8516,  61.8516,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 608 was 94.4%\n",
      "tensor([1.9852e-23, 3.1386e-06, 2.6352e-06, 2.4424e-06, 2.5582e-06, 5.1897e-09,\n",
      "        3.6247e-09, 3.4189e-09, 3.4775e-09, 4.3139e-06, 4.1893e-06, 4.2719e-06,\n",
      "        6.2765e-05, 5.7664e-05, 5.7926e-05, 3.9851e-06, 4.0692e-06, 3.5795e-05,\n",
      "        3.6055e-05, 3.4327e-01, 3.5696e-01, 1.3831e+00, 1.3693e+00, 3.9440e-06,\n",
      "        3.5694e-05, 3.3661e-01, 1.3898e+00, 3.0433e-01, 1.4226e+00, 3.8588e-01,\n",
      "        9.4435e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([203.9409, 240.7136, 258.2667, 247.4436,   7.7762,   7.7770,   7.7760,\n",
      "        378.3571, 378.3571, 378.3571,   7.7766,   7.7777, 378.3571, 378.3571,\n",
      "        378.3571, 378.3571, 378.3571,  61.9307,  61.9307,   7.7749, 378.3571,\n",
      "        378.3571, 378.3571, 378.3571, 378.3571,  61.9307,  61.9307, 378.3571,\n",
      "         61.9307,  61.9307,   5.2026, 378.3571, 378.3571, 378.3571, 378.3571,\n",
      "        378.3571,  61.9307,  61.9307, 378.3571,  61.9307,  61.9307,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 378.3571,   5.2026,   5.2025, 378.3571,   5.2026,\n",
      "          5.2025, 378.3571,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        378.3571, 378.3571, 378.3571, 378.3571,  61.9307,  61.9307,  61.9307,\n",
      "         61.9307, 378.3571, 378.3571, 378.3571,  61.9307,  61.9307,  61.9307,\n",
      "         61.9307,   5.2026,  61.9307,  61.9307,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 609 was 94.4%\n",
      "tensor([9.9262e-24, 3.1331e-06, 2.6311e-06, 2.4383e-06, 2.5547e-06, 5.1590e-09,\n",
      "        3.6048e-09, 3.4021e-09, 3.4599e-09, 4.3054e-06, 4.1789e-06, 4.2640e-06,\n",
      "        6.2219e-05, 5.7192e-05, 5.7460e-05, 3.9773e-06, 4.0604e-06, 3.5546e-05,\n",
      "        3.5772e-05, 3.4254e-01, 3.5626e-01, 1.3804e+00, 1.3666e+00, 3.9372e-06,\n",
      "        3.5454e-05, 3.3589e-01, 1.3871e+00, 3.0374e-01, 1.4197e+00, 3.8516e-01,\n",
      "        9.4446e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([204.2165, 240.9929, 258.5714, 247.6697,   7.7733,   7.7733,   7.7744,\n",
      "        378.7778, 378.7778, 378.7778,   7.7736,   7.7725, 378.7778, 378.7778,\n",
      "        378.7778, 378.7778, 378.7778,  62.0099,  62.0099,   7.7739, 378.7778,\n",
      "        378.7778, 378.7778, 378.7778, 378.7778,  62.0099,  62.0099, 378.7778,\n",
      "         62.0099,  62.0099,   5.2026, 378.7778, 378.7778, 378.7778, 378.7778,\n",
      "        378.7778,  62.0099,  62.0099, 378.7778,  62.0099,  62.0099,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 378.7778,   5.2026,   5.2025, 378.7778,   5.2026,\n",
      "          5.2025, 378.7778,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        378.7778, 378.7778, 378.7778, 378.7778,  62.0099,  62.0099,  62.0099,\n",
      "         62.0099, 378.7778, 378.7778, 378.7778,  62.0099,  62.0099,  62.0099,\n",
      "         62.0099,   5.2026,  62.0099,  62.0099,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 610 was 94.4%\n",
      "tensor([0.0000e+00, 3.1274e-06, 2.6265e-06, 2.4341e-06, 2.5512e-06, 5.1060e-09,\n",
      "        3.5680e-09, 3.3699e-09, 3.4263e-09, 4.2956e-06, 4.1708e-06, 4.2543e-06,\n",
      "        6.1371e-05, 5.6510e-05, 5.6719e-05, 3.9682e-06, 4.0536e-06, 3.5106e-05,\n",
      "        3.5336e-05, 3.4174e-01, 3.5553e-01, 1.3778e+00, 1.3640e+00, 3.9283e-06,\n",
      "        3.5028e-05, 3.3525e-01, 1.3844e+00, 3.0312e-01, 1.4168e+00, 3.8445e-01,\n",
      "        9.4457e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([204.4981, 241.2641, 258.8654, 247.8899,   7.7699,   7.7724,   7.7692,\n",
      "        379.1985, 379.1985, 379.1985,   7.7707,   7.7716, 379.1985, 379.1985,\n",
      "        379.1985, 379.1985, 379.1985,  62.0890,  62.0890,   7.7703, 379.1985,\n",
      "        379.1985, 379.1985, 379.1985, 379.1985,  62.0890,  62.0890, 379.1985,\n",
      "         62.0890,  62.0890,   5.2026, 379.1985, 379.1985, 379.1985, 379.1985,\n",
      "        379.1985,  62.0890,  62.0890, 379.1985,  62.0890,  62.0890,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 379.1985,   5.2026,   5.2025, 379.1985,   5.2026,\n",
      "          5.2025, 379.1985,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        379.1985, 379.1985, 379.1985, 379.1985,  62.0890,  62.0890,  62.0890,\n",
      "         62.0890, 379.1985, 379.1985, 379.1985,  62.0890,  62.0890,  62.0890,\n",
      "         62.0890,   5.2026,  62.0890,  62.0890,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 611 was 94.4%\n",
      "tensor([0.0000e+00, 3.1219e-06, 2.6226e-06, 2.4305e-06, 2.5478e-06, 5.0714e-09,\n",
      "        3.5457e-09, 3.3499e-09, 3.4062e-09, 4.2877e-06, 4.1610e-06, 4.2476e-06,\n",
      "        6.0793e-05, 5.5982e-05, 5.6229e-05, 3.9614e-06, 4.0443e-06, 3.4836e-05,\n",
      "        3.5026e-05, 3.4106e-01, 3.5481e-01, 1.3752e+00, 1.3614e+00, 3.9215e-06,\n",
      "        3.4755e-05, 3.3457e-01, 1.3818e+00, 3.0258e-01, 1.4141e+00, 3.8375e-01,\n",
      "        9.4467e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([204.7721, 241.5423, 259.1725, 248.1222,   7.7671,   7.7671,   7.7682,\n",
      "        379.6192, 379.6192, 379.6192,   7.7677,   7.7678, 379.6192, 379.6192,\n",
      "        379.6192, 379.6192, 379.6192,  62.1681,  62.1681,   7.7687, 379.6192,\n",
      "        379.6192, 379.6192, 379.6192, 379.6192,  62.1681,  62.1681, 379.6192,\n",
      "         62.1681,  62.1681,   5.2026, 379.6192, 379.6192, 379.6192, 379.6192,\n",
      "        379.6192,  62.1681,  62.1681, 379.6192,  62.1681,  62.1681,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 379.6192,   5.2026,   5.2025, 379.6192,   5.2026,\n",
      "          5.2025, 379.6192,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        379.6192, 379.6192, 379.6192, 379.6192,  62.1681,  62.1681,  62.1681,\n",
      "         62.1681, 379.6192, 379.6192, 379.6192,  62.1681,  62.1681,  62.1681,\n",
      "         62.1681,   5.2026,  62.1681,  62.1681,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 612 was 94.4%\n",
      "tensor([2.4558e-08, 3.1223e-06, 2.6235e-06, 2.4318e-06, 2.5496e-06, 8.2718e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2776e-06, 4.1531e-06, 4.2376e-06,\n",
      "        6.0146e-05, 5.5469e-05, 5.5667e-05, 3.9521e-06, 4.0375e-06, 3.4498e-05,\n",
      "        3.4708e-05, 3.4023e-01, 3.5413e-01, 1.3726e+00, 1.3586e+00, 3.9126e-06,\n",
      "        3.4423e-05, 3.3389e-01, 1.3789e+00, 3.0201e-01, 1.4111e+00, 3.8298e-01,\n",
      "        9.4479e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([205.0409, 241.8340, 259.4864, 248.3616,   7.7651,   7.7654,   7.7642,\n",
      "        380.0399, 380.0399, 380.0399,   7.7652,   7.7653, 380.0399, 380.0399,\n",
      "        380.0399, 380.0399, 380.0399,  62.2473,  62.2473,   7.7635, 380.0399,\n",
      "        380.0399, 380.0399, 380.0399, 380.0399,  62.2473,  62.2473, 380.0399,\n",
      "         62.2473,  62.2473,   5.2026, 380.0399, 380.0399, 380.0399, 380.0399,\n",
      "        380.0399,  62.2473,  62.2473, 380.0399,  62.2473,  62.2473,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 380.0399,   5.2026,   5.2025, 380.0399,   5.2026,\n",
      "          5.2025, 380.0399,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        380.0399, 380.0399, 380.0399, 380.0399,  62.2473,  62.2473,  62.2473,\n",
      "         62.2473, 380.0399, 380.0399, 380.0399,  62.2473,  62.2473,  62.2473,\n",
      "         62.2473,   5.2026,  62.2473,  62.2473,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 613 was 94.4%\n",
      "tensor([1.9852e-23, 3.1109e-06, 2.6142e-06, 2.4224e-06, 2.5408e-06, 4.9944e-09,\n",
      "        3.4920e-09, 3.3015e-09, 3.3567e-09, 4.2686e-06, 4.1434e-06, 4.2292e-06,\n",
      "        5.9509e-05, 5.4897e-05, 5.5100e-05, 3.9440e-06, 4.0290e-06, 3.4144e-05,\n",
      "        3.4338e-05, 3.3953e-01, 3.5343e-01, 1.3698e+00, 1.3558e+00, 3.9055e-06,\n",
      "        3.4073e-05, 3.3315e-01, 1.3762e+00, 3.0140e-01, 1.4082e+00, 3.8219e-01,\n",
      "        9.4490e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([205.3126, 242.1210, 259.7943, 248.5998,   7.7623,   7.7600,   7.7626,\n",
      "        380.4605, 380.4605, 380.4605,   7.7621,   7.7615, 380.4605, 380.4605,\n",
      "        380.4605, 380.4605, 380.4605,  62.3264,  62.3264,   7.7624, 380.4605,\n",
      "        380.4605, 380.4605, 380.4605, 380.4605,  62.3264,  62.3264, 380.4605,\n",
      "         62.3264,  62.3264,   5.2026, 380.4605, 380.4605, 380.4605, 380.4605,\n",
      "        380.4605,  62.3264,  62.3264, 380.4605,  62.3264,  62.3264,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 380.4605,   5.2026,   5.2025, 380.4605,   5.2026,\n",
      "          5.2025, 380.4605,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        380.4605, 380.4605, 380.4605, 380.4605,  62.3264,  62.3264,  62.3264,\n",
      "         62.3264, 380.4605, 380.4605, 380.4605,  62.3264,  62.3264,  62.3264,\n",
      "         62.3264,   5.2026,  62.3264,  62.3264,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 614 was 94.5%\n",
      "tensor([2.3161e-23, 3.1063e-06, 2.6106e-06, 2.4191e-06, 2.5381e-06, 5.0537e-09,\n",
      "        3.5383e-09, 3.3458e-09, 3.4029e-09, 4.2597e-06, 4.1365e-06, 4.2206e-06,\n",
      "        6.0058e-05, 5.5456e-05, 5.5666e-05, 3.9359e-06, 4.0220e-06, 3.4560e-05,\n",
      "        3.4787e-05, 3.3876e-01, 3.5275e-01, 1.3669e+00, 1.3529e+00, 3.8973e-06,\n",
      "        3.4486e-05, 3.3251e-01, 1.3732e+00, 3.0083e-01, 1.4051e+00, 3.8120e-01,\n",
      "        9.4502e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([205.5731, 242.4197, 260.1230, 248.8501,   7.7581,   7.7589,   7.7570,\n",
      "        380.8812, 380.8812, 380.8812,   7.7596,   7.7602, 380.8812, 380.8812,\n",
      "        380.8812, 380.8812, 380.8812,  62.4056,  62.4056,   7.7585, 380.8812,\n",
      "        380.8812, 380.8812, 380.8812, 380.8812,  62.4056,  62.4056, 380.8812,\n",
      "         62.4056,  62.4056,   5.2026, 380.8812, 380.8812, 380.8812, 380.8812,\n",
      "        380.8812,  62.4056,  62.4056, 380.8812,  62.4056,  62.4056,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 380.8812,   5.2026,   5.2025, 380.8812,   5.2026,\n",
      "          5.2025, 380.8812,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        380.8812, 380.8812, 380.8812, 380.8812,  62.4056,  62.4056,  62.4056,\n",
      "         62.4056, 380.8812, 380.8812, 380.8812,  62.4056,  62.4056,  62.4056,\n",
      "         62.4056,   5.2026,  62.4056,  62.4056,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 615 was 94.5%\n",
      "tensor([1.5388e-06, 2.6491e-06, 1.2289e-06, 1.4662e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2523e-06, 4.1268e-06, 4.2137e-06,\n",
      "        5.9487e-05, 5.4769e-05, 5.5116e-05, 3.9283e-06, 4.0134e-06, 3.3980e-05,\n",
      "        3.4272e-05, 3.3808e-01, 3.5208e-01, 1.3641e+00, 1.3501e+00, 3.8903e-06,\n",
      "        3.3874e-05, 3.3183e-01, 1.3703e+00, 3.0032e-01, 1.4019e+00, 3.7997e-01,\n",
      "        9.4513e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([206.3479, 241.7819, 259.6532, 248.3757,   7.7618,   7.7617,   7.7607,\n",
      "        381.3019, 381.3019, 381.3019,   7.7617,   7.7613, 381.3019, 381.3019,\n",
      "        381.3019, 381.3019, 381.3019,  62.4847,  62.4847,   7.7636, 381.3019,\n",
      "        381.3019, 381.3019, 381.3019, 381.3019,  62.4847,  62.4847, 381.3019,\n",
      "         62.4847,  62.4847,   5.2026, 381.3019, 381.3019, 381.3019, 381.3019,\n",
      "        381.3019,  62.4847,  62.4847, 381.3019,  62.4847,  62.4847,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 381.3019,   5.2026,   5.2025, 381.3019,   5.2026,\n",
      "          5.2025, 381.3019,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        381.3019, 381.3019, 381.3019, 381.3019,  62.4847,  62.4847,  62.4847,\n",
      "         62.4847, 381.3019, 381.3019, 381.3019,  62.4847,  62.4847,  62.4847,\n",
      "         62.4847,   5.2026,  62.4847,  62.4847,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 616 was 94.5%\n",
      "tensor([3.3087e-23, 3.0886e-06, 2.6134e-06, 2.4197e-06, 2.5396e-06, 4.9307e-09,\n",
      "        3.4944e-09, 3.3029e-09, 3.3587e-09, 4.2541e-06, 4.1297e-06, 4.2160e-06,\n",
      "        5.8543e-05, 5.4001e-05, 5.4192e-05, 3.9382e-06, 4.0243e-06, 3.4209e-05,\n",
      "        3.4403e-05, 3.3833e-01, 3.5236e-01, 1.3671e+00, 1.3530e+00, 3.8978e-06,\n",
      "        3.4126e-05, 3.3202e-01, 1.3734e+00, 3.0157e-01, 1.4041e+00, 3.8152e-01,\n",
      "        9.4502e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([206.6211, 242.0519, 259.9532, 248.6051,   7.7569,   7.7586,   7.7597,\n",
      "        381.7225, 381.7225, 381.7225,   7.7600,   7.7595, 381.7225, 381.7225,\n",
      "        381.7225, 381.7225, 381.7225,  62.5638,  62.5638,   7.7584, 381.7225,\n",
      "        381.7225, 381.7225, 381.7225, 381.7225,  62.5638,  62.5638, 381.7225,\n",
      "         62.5638,  62.5638,   5.2026, 381.7225, 381.7225, 381.7225, 381.7225,\n",
      "        381.7225,  62.5638,  62.5638, 381.7225,  62.5638,  62.5638,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 381.7225,   5.2026,   5.2025, 381.7225,   5.2026,\n",
      "          5.2025, 381.7225,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        381.7225, 381.7225, 381.7225, 381.7225,  62.5638,  62.5638,  62.5638,\n",
      "         62.5638, 381.7225, 381.7225, 381.7225,  62.5638,  62.5638,  62.5638,\n",
      "         62.5638,   5.2026,  62.5638,  62.5638,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 617 was 94.5%\n",
      "tensor([2.3161e-23, 3.0840e-06, 2.6101e-06, 2.4163e-06, 2.5368e-06, 4.9569e-09,\n",
      "        3.5167e-09, 3.3242e-09, 3.3812e-09, 4.2479e-06, 4.1213e-06, 4.2065e-06,\n",
      "        5.8739e-05, 5.4173e-05, 5.4364e-05, 3.9294e-06, 4.0166e-06, 3.4363e-05,\n",
      "        3.4579e-05, 3.3764e-01, 3.5174e-01, 1.3643e+00, 1.3501e+00, 3.8917e-06,\n",
      "        3.4315e-05, 3.3132e-01, 1.3706e+00, 3.0101e-01, 1.4012e+00, 3.8061e-01,\n",
      "        9.4514e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([206.8893, 242.3297, 260.2633, 248.8405,   7.7549,   7.7562,   7.7558,\n",
      "        382.1432, 382.1432, 382.1432,   7.7547,   7.7563, 382.1432, 382.1432,\n",
      "        382.1432, 382.1432, 382.1432,  62.6430,  62.6430,   7.7573, 382.1432,\n",
      "        382.1432, 382.1432, 382.1432, 382.1432,  62.6430,  62.6430, 382.1432,\n",
      "         62.6430,  62.6430,   5.2026, 382.1432, 382.1432, 382.1432, 382.1432,\n",
      "        382.1432,  62.6430,  62.6430, 382.1432,  62.6430,  62.6430,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 382.1432,   5.2026,   5.2025, 382.1432,   5.2026,\n",
      "          5.2025, 382.1432,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        382.1432, 382.1432, 382.1432, 382.1432,  62.6430,  62.6430,  62.6430,\n",
      "         62.6430, 382.1432, 382.1432, 382.1432,  62.6430,  62.6430,  62.6430,\n",
      "         62.6430,   5.2026,  62.6430,  62.6430,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 618 was 94.5%\n",
      "tensor([4.6322e-23, 3.0795e-06, 2.6066e-06, 2.4131e-06, 2.5341e-06, 5.0378e-09,\n",
      "        3.5795e-09, 3.3837e-09, 3.4431e-09, 4.2382e-06, 4.1123e-06, 4.1996e-06,\n",
      "        5.9543e-05, 5.4953e-05, 5.5195e-05, 3.9229e-06, 4.0088e-06, 3.4963e-05,\n",
      "        3.5182e-05, 3.3687e-01, 3.5104e-01, 1.3614e+00, 1.3472e+00, 3.8834e-06,\n",
      "        3.4883e-05, 3.3071e-01, 1.3676e+00, 3.0044e-01, 1.3981e+00, 3.7956e-01,\n",
      "        9.4526e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([206.9270, 243.0594, 260.9660, 249.4222,   7.7493,   7.7494,   7.7512,\n",
      "        382.5639, 382.5639, 382.5639,   7.7507,   7.7488, 382.5639, 382.5639,\n",
      "        382.5639, 382.5639, 382.5639,  62.7221,  62.7221,   7.7488, 382.5639,\n",
      "        382.5639, 382.5639, 382.5639, 382.5639,  62.7221,  62.7221, 382.5639,\n",
      "         62.7221,  62.7221,   5.2026, 382.5639, 382.5639, 382.5639, 382.5639,\n",
      "        382.5639,  62.7221,  62.7221, 382.5639,  62.7221,  62.7221,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 382.5639,   5.2026,   5.2025, 382.5639,   5.2026,\n",
      "          5.2025, 382.5639,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        382.5639, 382.5639, 382.5639, 382.5639,  62.7221,  62.7221,  62.7221,\n",
      "         62.7221, 382.5639, 382.5639, 382.5639,  62.7221,  62.7221,  62.7221,\n",
      "         62.7221,   5.2026,  62.7221,  62.7221,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 619 was 94.5%\n",
      "tensor([0.0000e+00, 3.0789e-06, 2.5984e-06, 2.4062e-06, 2.5278e-06, 5.3980e-09,\n",
      "        3.8376e-09, 3.6368e-09, 3.6982e-09, 4.2226e-06, 4.0978e-06, 4.1829e-06,\n",
      "        6.3493e-05, 5.8875e-05, 5.9027e-05, 3.9029e-06, 3.9918e-06, 3.7555e-05,\n",
      "        3.7777e-05, 3.3551e-01, 3.4972e-01, 1.3549e+00, 1.3406e+00, 3.8674e-06,\n",
      "        3.7514e-05, 3.2945e-01, 1.3610e+00, 2.9876e-01, 1.3920e+00, 3.7750e-01,\n",
      "        9.4551e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([207.1914, 243.3447, 261.2832, 249.6524,   7.7464,   7.7462,   7.7456,\n",
      "        382.9845, 382.9845, 382.9845,   7.7468,   7.7471, 382.9845, 382.9845,\n",
      "        382.9845, 382.9845, 382.9845,  62.8013,  62.8013,   7.7477, 382.9845,\n",
      "        382.9845, 382.9845, 382.9845, 382.9845,  62.8013,  62.8013, 382.9845,\n",
      "         62.8013,  62.8013,   5.2026, 382.9845, 382.9845, 382.9845, 382.9845,\n",
      "        382.9845,  62.8013,  62.8013, 382.9845,  62.8013,  62.8013,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 382.9845,   5.2026,   5.2025, 382.9845,   5.2026,\n",
      "          5.2025, 382.9845,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        382.9845, 382.9845, 382.9845, 382.9845,  62.8013,  62.8013,  62.8013,\n",
      "         62.8013, 382.9845, 382.9845, 382.9845,  62.8013,  62.8013,  62.8013,\n",
      "         62.8013,   5.2026,  62.8013,  62.8013,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 620 was 94.5%\n",
      "tensor([2.6237e-08, 3.0799e-06, 2.5999e-06, 2.4082e-06, 2.5301e-06, 8.2718e-25,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2127e-06, 4.0885e-06, 4.1761e-06,\n",
      "        6.2910e-05, 5.8387e-05, 5.8570e-05, 3.8957e-06, 3.9829e-06, 3.7276e-05,\n",
      "        3.7471e-05, 3.3474e-01, 3.4899e-01, 1.3521e+00, 1.3378e+00, 3.8583e-06,\n",
      "        3.7209e-05, 3.2876e-01, 1.3582e+00, 2.9823e-01, 1.3891e+00, 3.7670e-01,\n",
      "        9.4563e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([207.4551, 243.6316, 261.6006, 249.8845,   7.7426,   7.7445,   7.7446,\n",
      "        383.4051, 383.4051, 383.4051,   7.7443,   7.7430, 383.4051, 383.4051,\n",
      "        383.4051, 383.4051, 383.4051,  62.8804,  62.8804,   7.7423, 383.4051,\n",
      "        383.4051, 383.4051, 383.4051, 383.4051,  62.8804,  62.8804, 383.4051,\n",
      "         62.8804,  62.8804,   5.2026, 383.4051, 383.4051, 383.4051, 383.4051,\n",
      "        383.4051,  62.8804,  62.8804, 383.4051,  62.8804,  62.8804,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 383.4051,   5.2026,   5.2025, 383.4051,   5.2026,\n",
      "          5.2025, 383.4051,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        383.4051, 383.4051, 383.4051, 383.4051,  62.8804,  62.8804,  62.8804,\n",
      "         62.8804, 383.4051, 383.4051, 383.4051,  62.8804,  62.8804,  62.8804,\n",
      "         62.8804,   5.2026,  62.8804,  62.8804,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 621 was 94.5%\n",
      "tensor([2.6055e-08, 3.0751e-06, 2.5959e-06, 2.4044e-06, 2.5268e-06, 4.9631e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2050e-06, 4.0797e-06, 4.1665e-06,\n",
      "        6.2370e-05, 5.7902e-05, 5.8075e-05, 3.8871e-06, 3.9756e-06, 3.6949e-05,\n",
      "        3.7155e-05, 3.3404e-01, 3.4833e-01, 1.3494e+00, 1.3350e+00, 3.8519e-06,\n",
      "        3.6904e-05, 3.2811e-01, 1.3553e+00, 2.9759e-01, 1.3862e+00, 3.7589e-01,\n",
      "        9.4574e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([207.7157, 243.9245, 261.9219, 250.1218,   7.7403,   7.7404,   7.7389,\n",
      "        383.8258, 383.8258, 383.8258,   7.7411,   7.7405, 383.8258, 383.8258,\n",
      "        383.8258, 383.8258, 383.8258,  62.9595,  62.9595,   7.7412, 383.8258,\n",
      "        383.8258, 383.8258, 383.8258, 383.8258,  62.9595,  62.9595, 383.8258,\n",
      "         62.9595,  62.9595,   5.2026, 383.8258, 383.8258, 383.8258, 383.8258,\n",
      "        383.8258,  62.9595,  62.9595, 383.8258,  62.9595,  62.9595,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 383.8258,   5.2026,   5.2025, 383.8258,   5.2026,\n",
      "          5.2025, 383.8258,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        383.8258, 383.8258, 383.8258, 383.8258,  62.9595,  62.9595,  62.9595,\n",
      "         62.9595, 383.8258, 383.8258, 383.8258,  62.9595,  62.9595,  62.9595,\n",
      "         62.9595,   5.2026,  62.9595,  62.9595,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 622 was 94.5%\n",
      "tensor([5.6248e-23, 3.0634e-06, 2.5863e-06, 2.3948e-06, 2.5179e-06, 5.3147e-09,\n",
      "        3.7795e-09, 3.5845e-09, 3.6464e-09, 4.1951e-06, 4.0710e-06, 4.1592e-06,\n",
      "        6.1960e-05, 5.7571e-05, 5.7756e-05, 3.8791e-06, 3.9671e-06, 3.6764e-05,\n",
      "        3.6962e-05, 3.3328e-01, 3.4760e-01, 1.3465e+00, 1.3321e+00, 3.8429e-06,\n",
      "        3.6703e-05, 3.2741e-01, 1.3525e+00, 2.9704e-01, 1.3832e+00, 3.7505e-01,\n",
      "        9.4585e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([207.9786, 244.2123, 262.2389, 250.3567,   7.7372,   7.7378,   7.7379,\n",
      "        384.2464, 384.2464, 384.2464,   7.7371,   7.7379, 384.2464, 384.2464,\n",
      "        384.2464, 384.2464, 384.2464,  63.0387,  63.0387,   7.7358, 384.2464,\n",
      "        384.2464, 384.2464, 384.2464, 384.2464,  63.0387,  63.0387, 384.2464,\n",
      "         63.0387,  63.0387,   5.2026, 384.2464, 384.2464, 384.2464, 384.2464,\n",
      "        384.2464,  63.0387,  63.0387, 384.2464,  63.0387,  63.0387,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 384.2464,   5.2026,   5.2025, 384.2464,   5.2026,\n",
      "          5.2025, 384.2464,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        384.2464, 384.2464, 384.2464, 384.2464,  63.0387,  63.0387,  63.0387,\n",
      "         63.0387, 384.2464, 384.2464, 384.2464,  63.0387,  63.0387,  63.0387,\n",
      "         63.0387,   5.2026,  63.0387,  63.0387,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 623 was 94.5%\n",
      "tensor([0.0000e+00, 3.0585e-06, 2.5823e-06, 2.3909e-06, 2.5148e-06, 5.2764e-09,\n",
      "        3.7513e-09, 3.5580e-09, 3.6201e-09, 4.1866e-06, 4.0617e-06, 4.1502e-06,\n",
      "        6.1347e-05, 5.7011e-05, 5.7206e-05, 3.8712e-06, 3.9591e-06, 3.6391e-05,\n",
      "        3.6590e-05, 3.3254e-01, 3.4698e-01, 1.3438e+00, 1.3293e+00, 3.8362e-06,\n",
      "        3.6338e-05, 3.2674e-01, 1.3496e+00, 2.9641e-01, 1.3803e+00, 3.7423e-01,\n",
      "        9.4597e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([208.2416, 244.4991, 262.5555, 250.5913,   7.7342,   7.7346,   7.7338,\n",
      "        384.6671, 384.6671, 384.6671,   7.7353,   7.7324, 384.6671, 384.6671,\n",
      "        384.6671, 384.6671, 384.6671,  63.1178,  63.1178,   7.7346, 384.6671,\n",
      "        384.6671, 384.6671, 384.6671, 384.6671,  63.1178,  63.1178, 384.6671,\n",
      "         63.1178,  63.1178,   5.2026, 384.6671, 384.6671, 384.6671, 384.6671,\n",
      "        384.6671,  63.1178,  63.1178, 384.6671,  63.1178,  63.1178,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 384.6671,   5.2026,   5.2025, 384.6671,   5.2026,\n",
      "          5.2025, 384.6671,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        384.6671, 384.6671, 384.6671, 384.6671,  63.1178,  63.1178,  63.1178,\n",
      "         63.1178, 384.6671, 384.6671, 384.6671,  63.1178,  63.1178,  63.1178,\n",
      "         63.1178,   5.2026,  63.1178,  63.1178,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 624 was 94.6%\n",
      "tensor([1.3235e-23, 3.0534e-06, 2.5783e-06, 2.3873e-06, 2.5114e-06, 5.2301e-09,\n",
      "        3.7172e-09, 3.5263e-09, 3.5882e-09, 4.1775e-06, 4.0537e-06, 4.1417e-06,\n",
      "        6.0627e-05, 5.6387e-05, 5.6567e-05, 3.8628e-06, 3.9524e-06, 3.5961e-05,\n",
      "        3.6174e-05, 3.3185e-01, 3.4623e-01, 1.3410e+00, 1.3266e+00, 3.8278e-06,\n",
      "        3.5908e-05, 3.2609e-01, 1.3468e+00, 2.9586e-01, 1.3775e+00, 3.7344e-01,\n",
      "        9.4608e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([208.5054, 244.7840, 262.8704, 250.8249,   7.7303,   7.7319,   7.7320,\n",
      "        385.0877, 385.0877, 385.0877,   7.7299,   7.7312, 385.0877, 385.0877,\n",
      "        385.0877, 385.0877, 385.0877,  63.1970,  63.1970,   7.7307, 385.0877,\n",
      "        385.0877, 385.0877, 385.0877, 385.0877,  63.1970,  63.1970, 385.0877,\n",
      "         63.1970,  63.1970,   5.2026, 385.0877, 385.0877, 385.0877, 385.0877,\n",
      "        385.0877,  63.1970,  63.1970, 385.0877,  63.1970,  63.1970,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 385.0877,   5.2026,   5.2025, 385.0877,   5.2026,\n",
      "          5.2025, 385.0877,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        385.0877, 385.0877, 385.0877, 385.0877,  63.1970,  63.1970,  63.1970,\n",
      "         63.1970, 385.0877, 385.0877, 385.0877,  63.1970,  63.1970,  63.1970,\n",
      "         63.1970,   5.2026,  63.1970,  63.1970,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 625 was 94.6%\n",
      "tensor([0.0000e+00, 3.0485e-06, 2.5742e-06, 2.3833e-06, 2.5083e-06, 5.2078e-09,\n",
      "        3.7023e-09, 3.5136e-09, 3.5756e-09, 4.1695e-06, 4.0443e-06, 4.1334e-06,\n",
      "        6.0196e-05, 5.6018e-05, 5.6210e-05, 3.8552e-06, 3.9436e-06, 3.5754e-05,\n",
      "        3.5951e-05, 3.3105e-01, 3.4561e-01, 1.3384e+00, 1.3237e+00, 3.8203e-06,\n",
      "        3.5708e-05, 3.2545e-01, 1.3440e+00, 2.9523e-01, 1.3746e+00, 3.7265e-01,\n",
      "        9.4619e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([208.7699, 245.0676, 263.1835, 251.0583,   7.7273,   7.7279,   7.7264,\n",
      "        385.5083, 385.5083, 385.5083,   7.7287,   7.7280, 385.5083, 385.5083,\n",
      "        385.5083, 385.5083, 385.5083,  63.2761,  63.2761,   7.7289, 385.5083,\n",
      "        385.5083, 385.5083, 385.5083, 385.5083,  63.2761,  63.2761, 385.5083,\n",
      "         63.2761,  63.2761,   5.2026, 385.5083, 385.5083, 385.5083, 385.5083,\n",
      "        385.5083,  63.2761,  63.2761, 385.5083,  63.2761,  63.2761,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 385.5083,   5.2026,   5.2025, 385.5083,   5.2026,\n",
      "          5.2025, 385.5083,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        385.5083, 385.5083, 385.5083, 385.5083,  63.2761,  63.2761,  63.2761,\n",
      "         63.2761, 385.5083, 385.5083, 385.5083,  63.2761,  63.2761,  63.2761,\n",
      "         63.2761,   5.2026,  63.2761,  63.2761,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 626 was 94.6%\n",
      "tensor([9.9262e-24, 3.0431e-06, 2.5703e-06, 2.3797e-06, 2.5049e-06, 5.1645e-09,\n",
      "        3.6716e-09, 3.4849e-09, 3.5467e-09, 4.1601e-06, 4.0364e-06, 4.1258e-06,\n",
      "        5.9520e-05, 5.5425e-05, 5.5612e-05, 3.8467e-06, 3.9358e-06, 3.5373e-05,\n",
      "        3.5571e-05, 3.3035e-01, 3.4486e-01, 1.3356e+00, 1.3210e+00, 3.8121e-06,\n",
      "        3.5317e-05, 3.2475e-01, 1.3413e+00, 2.9472e-01, 1.3717e+00, 3.7187e-01,\n",
      "        9.4630e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([209.0345, 245.3511, 263.4959, 251.2918,   7.7242,   7.7253,   7.7253,\n",
      "        385.9289, 385.9289, 385.9289,   7.7247,   7.7254, 385.9289, 385.9289,\n",
      "        385.9289, 385.9289, 385.9289,  63.3552,  63.3552,   7.7235, 385.9289,\n",
      "        385.9289, 385.9289, 385.9289, 385.9289,  63.3552,  63.3552, 385.9289,\n",
      "         63.3552,  63.3552,   5.2026, 385.9289, 385.9289, 385.9289, 385.9289,\n",
      "        385.9289,  63.3552,  63.3552, 385.9289,  63.3552,  63.3552,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 385.9289,   5.2026,   5.2025, 385.9289,   5.2026,\n",
      "          5.2025, 385.9289,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        385.9289, 385.9289, 385.9289, 385.9289,  63.3552,  63.3552,  63.3552,\n",
      "         63.3552, 385.9289, 385.9289, 385.9289,  63.3552,  63.3552,  63.3552,\n",
      "         63.3552,   5.2026,  63.3552,  63.3552,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 627 was 94.6%\n",
      "tensor([0.0000e+00, 3.0382e-06, 2.5664e-06, 2.3759e-06, 2.5018e-06, 5.1148e-09,\n",
      "        3.6357e-09, 3.4514e-09, 3.5130e-09, 4.1517e-06, 4.0270e-06, 4.1167e-06,\n",
      "        5.8783e-05, 5.4752e-05, 5.4942e-05, 3.8387e-06, 3.9278e-06, 3.4934e-05,\n",
      "        3.5130e-05, 3.2961e-01, 3.4425e-01, 1.3329e+00, 1.3182e+00, 3.8053e-06,\n",
      "        3.4890e-05, 3.2409e-01, 1.3384e+00, 2.9409e-01, 1.3688e+00, 3.7106e-01,\n",
      "        9.4641e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([209.2979, 245.6348, 263.8108, 251.5262,   7.7218,   7.7221,   7.7212,\n",
      "        386.3496, 386.3496, 386.3496,   7.7222,   7.7198, 386.3496, 386.3496,\n",
      "        386.3496, 386.3496, 386.3496,  63.4344,  63.4344,   7.7224, 386.3496,\n",
      "        386.3496, 386.3496, 386.3496, 386.3496,  63.4344,  63.4344, 386.3496,\n",
      "         63.4344,  63.4344,   5.2026, 386.3496, 386.3496, 386.3496, 386.3496,\n",
      "        386.3496,  63.4344,  63.4344, 386.3496,  63.4344,  63.4344,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 386.3496,   5.2026,   5.2025, 386.3496,   5.2026,\n",
      "          5.2025, 386.3496,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        386.3496, 386.3496, 386.3496, 386.3496,  63.4344,  63.4344,  63.4344,\n",
      "         63.4344, 386.3496, 386.3496, 386.3496,  63.4344,  63.4344,  63.4344,\n",
      "         63.4344,   5.2026,  63.4344,  63.4344,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 628 was 94.6%\n",
      "tensor([0.0000e+00, 3.0331e-06, 2.5624e-06, 2.3722e-06, 2.4984e-06, 5.0696e-09,\n",
      "        3.6025e-09, 3.4204e-09, 3.4818e-09, 4.1421e-06, 4.0190e-06, 4.1086e-06,\n",
      "        5.8086e-05, 5.4145e-05, 5.4327e-05, 3.8306e-06, 3.9212e-06, 3.4523e-05,\n",
      "        3.4727e-05, 3.2891e-01, 3.4351e-01, 1.3302e+00, 1.3154e+00, 3.7968e-06,\n",
      "        3.4470e-05, 3.2344e-01, 1.3357e+00, 2.9353e-01, 1.3660e+00, 3.7027e-01,\n",
      "        9.4652e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([209.5614, 245.9181, 264.1255, 251.7604,   7.7178,   7.7194,   7.7194,\n",
      "        386.7702, 386.7702, 386.7702,   7.7181,   7.7187, 386.7702, 386.7702,\n",
      "        386.7702, 386.7702, 386.7702,  63.5135,  63.5135,   7.7169, 386.7702,\n",
      "        386.7702, 386.7702, 386.7702, 386.7702,  63.5135,  63.5135, 386.7702,\n",
      "         63.5135,  63.5135,   5.2026, 386.7702, 386.7702, 386.7702, 386.7702,\n",
      "        386.7702,  63.5135,  63.5135, 386.7702,  63.5135,  63.5135,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 386.7702,   5.2026,   5.2025, 386.7702,   5.2026,\n",
      "          5.2025, 386.7702,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        386.7702, 386.7702, 386.7702, 386.7702,  63.5135,  63.5135,  63.5135,\n",
      "         63.5135, 386.7702, 386.7702, 386.7702,  63.5135,  63.5135,  63.5135,\n",
      "         63.5135,   5.2026,  63.5135,  63.5135,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 629 was 94.6%\n",
      "tensor([1.3235e-23, 3.0282e-06, 2.5584e-06, 2.3683e-06, 2.4952e-06, 5.0444e-09,\n",
      "        3.5856e-09, 3.4053e-09, 3.4667e-09, 4.1346e-06, 4.0098e-06, 4.1000e-06,\n",
      "        5.7643e-05, 5.3750e-05, 5.3936e-05, 3.8226e-06, 3.9125e-06, 3.4291e-05,\n",
      "        3.4486e-05, 3.2816e-01, 3.4289e-01, 1.3275e+00, 1.3127e+00, 3.7901e-06,\n",
      "        3.4251e-05, 3.2278e-01, 1.3329e+00, 2.9291e-01, 1.3632e+00, 3.6950e-01,\n",
      "        9.4664e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([209.8258, 246.2003, 264.4380, 251.9941,   7.7154,   7.7154,   7.7137,\n",
      "        387.1908, 387.1908, 387.1908,   7.7156,   7.7154, 387.1908, 387.1908,\n",
      "        387.1908, 387.1908, 387.1908,  63.5926,  63.5926,   7.7158, 387.1908,\n",
      "        387.1908, 387.1908, 387.1908, 387.1908,  63.5926,  63.5926, 387.1908,\n",
      "         63.5926,  63.5926,   5.2026, 387.1908, 387.1908, 387.1908, 387.1908,\n",
      "        387.1908,  63.5926,  63.5926, 387.1908,  63.5926,  63.5926,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 387.1908,   5.2026,   5.2025, 387.1908,   5.2026,\n",
      "          5.2025, 387.1908,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        387.1908, 387.1908, 387.1908, 387.1908,  63.5926,  63.5926,  63.5926,\n",
      "         63.5926, 387.1908, 387.1908, 387.1908,  63.5926,  63.5926,  63.5926,\n",
      "         63.5926,   5.2026,  63.5926,  63.5926,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 630 was 94.6%\n",
      "tensor([2.4254e-08, 3.0289e-06, 2.5597e-06, 2.3700e-06, 2.4970e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1248e-06, 4.0016e-06, 4.0924e-06,\n",
      "        5.7005e-05, 5.3198e-05, 5.3379e-05, 3.8144e-06, 3.9048e-06, 3.3936e-05,\n",
      "        3.4129e-05, 3.2744e-01, 3.4217e-01, 1.3248e+00, 1.3099e+00, 3.7813e-06,\n",
      "        3.3887e-05, 3.2209e-01, 1.3302e+00, 2.9239e-01, 1.3603e+00, 3.6871e-01,\n",
      "        9.4675e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([210.0902, 246.4822, 264.7503, 252.2277,   7.7109,   7.7135,   7.7124,\n",
      "        387.6114, 387.6114, 387.6114,   7.7115,   7.7135, 387.6114, 387.6114,\n",
      "        387.6114, 387.6114, 387.6114,  63.6718,  63.6718,   7.7103, 387.6114,\n",
      "        387.6114, 387.6114, 387.6114, 387.6114,  63.6718,  63.6718, 387.6114,\n",
      "         63.6718,  63.6718,   5.2026, 387.6114, 387.6114, 387.6114, 387.6114,\n",
      "        387.6114,  63.6718,  63.6718, 387.6114,  63.6718,  63.6718,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 387.6114,   5.2026,   5.2025, 387.6114,   5.2026,\n",
      "          5.2025, 387.6114,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        387.6114, 387.6114, 387.6114, 387.6114,  63.6718,  63.6718,  63.6718,\n",
      "         63.6718, 387.6114, 387.6114, 387.6114,  63.6718,  63.6718,  63.6718,\n",
      "         63.6718,   5.2026,  63.6718,  63.6718,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 631 was 94.6%\n",
      "tensor([0.0000e+00, 3.0182e-06, 2.5507e-06, 2.3610e-06, 2.4889e-06, 4.9601e-09,\n",
      "        3.5247e-09, 3.3485e-09, 3.4097e-09, 4.1179e-06, 3.9922e-06, 4.0843e-06,\n",
      "        5.6364e-05, 5.2589e-05, 5.2794e-05, 3.8074e-06, 3.8965e-06, 3.3544e-05,\n",
      "        3.3725e-05, 3.2673e-01, 3.4155e-01, 1.3221e+00, 1.3072e+00, 3.7755e-06,\n",
      "        3.3505e-05, 3.2146e-01, 1.3275e+00, 2.9180e-01, 1.3575e+00, 3.6796e-01,\n",
      "        9.4685e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([210.3544, 246.7645, 265.0627, 252.4620,   7.7084,   7.7078,   7.7090,\n",
      "        388.0320, 388.0320, 388.0320,   7.7090,   7.7095, 388.0320, 388.0320,\n",
      "        388.0320, 388.0320, 388.0320,  63.7509,  63.7509,   7.7092, 388.0320,\n",
      "        388.0320, 388.0320, 388.0320, 388.0320,  63.7509,  63.7509, 388.0320,\n",
      "         63.7509,  63.7509,   5.2026, 388.0320, 388.0320, 388.0320, 388.0320,\n",
      "        388.0320,  63.7509,  63.7509, 388.0320,  63.7509,  63.7509,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 388.0320,   5.2026,   5.2025, 388.0320,   5.2026,\n",
      "          5.2025, 388.0320,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        388.0320, 388.0320, 388.0320, 388.0320,  63.7509,  63.7509,  63.7509,\n",
      "         63.7509, 388.0320, 388.0320, 388.0320,  63.7509,  63.7509,  63.7509,\n",
      "         63.7509,   5.2026,  63.7509,  63.7509,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 632 was 94.6%\n",
      "tensor([0.0000e+00, 3.0128e-06, 2.5466e-06, 2.3570e-06, 2.4854e-06, 4.9310e-09,\n",
      "        3.5050e-09, 3.3311e-09, 3.3918e-09, 4.1078e-06, 3.9847e-06, 4.0751e-06,\n",
      "        5.5853e-05, 5.2181e-05, 5.2353e-05, 3.7981e-06, 3.8892e-06, 3.3285e-05,\n",
      "        3.3475e-05, 3.2596e-01, 3.4085e-01, 1.3194e+00, 1.3044e+00, 3.7662e-06,\n",
      "        3.3245e-05, 3.2077e-01, 1.3247e+00, 2.9124e-01, 1.3546e+00, 3.6716e-01,\n",
      "        9.4697e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([210.6194, 247.0458, 265.3735, 252.6958,   7.7052,   7.7068,   7.7063,\n",
      "        388.4526, 388.4526, 388.4526,   7.7065,   7.7038, 388.4526, 388.4526,\n",
      "        388.4526, 388.4526, 388.4526,  63.8301,  63.8301,   7.7051, 388.4526,\n",
      "        388.4526, 388.4526, 388.4526, 388.4526,  63.8301,  63.8301, 388.4526,\n",
      "         63.8301,  63.8301,   5.2026, 388.4526, 388.4526, 388.4526, 388.4526,\n",
      "        388.4526,  63.8301,  63.8301, 388.4526,  63.8301,  63.8301,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 388.4526,   5.2026,   5.2025, 388.4526,   5.2026,\n",
      "          5.2025, 388.4526,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        388.4526, 388.4526, 388.4526, 388.4526,  63.8301,  63.8301,  63.8301,\n",
      "         63.8301, 388.4526, 388.4526, 388.4526,  63.8301,  63.8301,  63.8301,\n",
      "         63.8301,   5.2026,  63.8301,  63.8301,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 633 was 94.7%\n",
      "tensor([0.0000e+00, 3.0080e-06, 2.5426e-06, 2.3534e-06, 2.4820e-06, 4.8920e-09,\n",
      "        3.4768e-09, 3.3052e-09, 3.3654e-09, 4.0997e-06, 3.9760e-06, 4.0666e-06,\n",
      "        5.5256e-05, 5.1653e-05, 5.1813e-05, 3.7902e-06, 3.8826e-06, 3.2934e-05,\n",
      "        3.3125e-05, 3.2532e-01, 3.4014e-01, 1.3168e+00, 1.3018e+00, 3.7594e-06,\n",
      "        3.2902e-05, 3.2016e-01, 1.3220e+00, 2.9063e-01, 1.3519e+00, 3.6642e-01,\n",
      "        9.4707e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([210.8845, 247.3271, 265.6838, 252.9297,   7.7020,   7.7010,   7.7030,\n",
      "        388.8732, 388.8732, 388.8732,   7.7024,   7.7026, 388.8732, 388.8732,\n",
      "        388.8732, 388.8732, 388.8732,  63.9092,  63.9092,   7.7033, 388.8732,\n",
      "        388.8732, 388.8732, 388.8732, 388.8732,  63.9092,  63.9092, 388.8732,\n",
      "         63.9092,  63.9092,   5.2026, 388.8732, 388.8732, 388.8732, 388.8732,\n",
      "        388.8732,  63.9092,  63.9092, 388.8732,  63.9092,  63.9092,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 388.8732,   5.2026,   5.2025, 388.8732,   5.2026,\n",
      "          5.2025, 388.8732,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        388.8732, 388.8732, 388.8732, 388.8732,  63.9092,  63.9092,  63.9092,\n",
      "         63.9092, 388.8732, 388.8732, 388.8732,  63.9092,  63.9092,  63.9092,\n",
      "         63.9092,   5.2026,  63.9092,  63.9092,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 634 was 94.7%\n",
      "tensor([3.3087e-23, 3.0027e-06, 2.5386e-06, 2.3495e-06, 2.4789e-06, 4.8531e-09,\n",
      "        3.4493e-09, 3.2797e-09, 3.3398e-09, 4.0904e-06, 3.9680e-06, 4.0586e-06,\n",
      "        5.4649e-05, 5.1122e-05, 5.1283e-05, 3.7823e-06, 3.8743e-06, 3.2598e-05,\n",
      "        3.2787e-05, 3.2452e-01, 3.3949e-01, 1.3141e+00, 1.2991e+00, 3.7510e-06,\n",
      "        3.2560e-05, 3.1948e-01, 1.3192e+00, 2.9010e-01, 1.3490e+00, 3.6565e-01,\n",
      "        9.4718e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([211.1493, 247.6091, 265.9944, 253.1641,   7.6988,   7.7000,   7.6987,\n",
      "        389.2938, 389.2938, 389.2938,   7.6998,   7.7000, 389.2938, 389.2938,\n",
      "        389.2938, 389.2938, 389.2938,  63.9883,  63.9883,   7.6978, 389.2938,\n",
      "        389.2938, 389.2938, 389.2938, 389.2938,  63.9883,  63.9883, 389.2938,\n",
      "         63.9883,  63.9883,   5.2026, 389.2938, 389.2938, 389.2938, 389.2938,\n",
      "        389.2938,  63.9883,  63.9883, 389.2938,  63.9883,  63.9883,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 389.2938,   5.2026,   5.2025, 389.2938,   5.2026,\n",
      "          5.2025, 389.2938,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        389.2938, 389.2938, 389.2938, 389.2938,  63.9883,  63.9883,  63.9883,\n",
      "         63.9883, 389.2938, 389.2938, 389.2938,  63.9883,  63.9883,  63.9883,\n",
      "         63.9883,   5.2026,  63.9883,  63.9883,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 635 was 94.7%\n",
      "tensor([9.9262e-24, 2.9977e-06, 2.5348e-06, 2.3459e-06, 2.4755e-06, 4.8117e-09,\n",
      "        3.4194e-09, 3.2518e-09, 3.3117e-09, 4.0824e-06, 3.9584e-06, 4.0508e-06,\n",
      "        5.4037e-05, 5.0553e-05, 5.0726e-05, 3.7747e-06, 3.8658e-06, 3.2235e-05,\n",
      "        3.2413e-05, 3.2387e-01, 3.3881e-01, 1.3114e+00, 1.2964e+00, 3.7444e-06,\n",
      "        3.2202e-05, 3.1879e-01, 1.3165e+00, 2.8952e-01, 1.3462e+00, 3.6488e-01,\n",
      "        9.4729e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([211.4144, 247.8907, 266.3044, 253.3985,   7.6955,   7.6958,   7.6969,\n",
      "        389.7144, 389.7144, 389.7144,   7.6965,   7.6942, 389.7144, 389.7144,\n",
      "        389.7144, 389.7144, 389.7144,  64.0675,  64.0675,   7.6966, 389.7144,\n",
      "        389.7144, 389.7144, 389.7144, 389.7144,  64.0675,  64.0675, 389.7144,\n",
      "         64.0675,  64.0675,   5.2026, 389.7144, 389.7144, 389.7144, 389.7144,\n",
      "        389.7144,  64.0675,  64.0675, 389.7144,  64.0675,  64.0675,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 389.7144,   5.2026,   5.2025, 389.7144,   5.2026,\n",
      "          5.2025, 389.7144,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        389.7144, 389.7144, 389.7144, 389.7144,  64.0675,  64.0675,  64.0675,\n",
      "         64.0675, 389.7144, 389.7144, 389.7144,  64.0675,  64.0675,  64.0675,\n",
      "         64.0675,   5.2026,  64.0675,  64.0675,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 636 was 94.7%\n",
      "tensor([2.2996e-08, 2.9984e-06, 2.5357e-06, 2.3473e-06, 2.4772e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0735e-06, 3.9509e-06, 4.0417e-06,\n",
      "        5.3400e-05, 5.0007e-05, 5.0155e-05, 3.7663e-06, 3.8597e-06, 3.1860e-05,\n",
      "        3.2051e-05, 3.2313e-01, 3.3813e-01, 1.3088e+00, 1.2937e+00, 3.7361e-06,\n",
      "        3.1832e-05, 3.1819e-01, 1.3138e+00, 2.8894e-01, 1.3434e+00, 3.6412e-01,\n",
      "        9.4740e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([211.6793, 248.1725, 266.6145, 253.6331,   7.6922,   7.6939,   7.6911,\n",
      "        390.1349, 390.1349, 390.1349,   7.6931,   7.6931, 390.1349, 390.1349,\n",
      "        390.1349, 390.1349, 390.1349,  64.1466,  64.1466,   7.6926, 390.1349,\n",
      "        390.1349, 390.1349, 390.1349, 390.1349,  64.1466,  64.1466, 390.1349,\n",
      "         64.1466,  64.1466,   5.2026, 390.1349, 390.1349, 390.1349, 390.1349,\n",
      "        390.1349,  64.1466,  64.1466, 390.1349,  64.1466,  64.1466,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 390.1349,   5.2026,   5.2025, 390.1349,   5.2026,\n",
      "          5.2025, 390.1349,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        390.1349, 390.1349, 390.1349, 390.1349,  64.1466,  64.1466,  64.1466,\n",
      "         64.1466, 390.1349, 390.1349, 390.1349,  64.1466,  64.1466,  64.1466,\n",
      "         64.1466,   5.2026,  64.1466,  64.1466,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 637 was 94.7%\n",
      "tensor([4.6322e-23, 2.9876e-06, 2.5268e-06, 2.3385e-06, 2.4688e-06, 4.7422e-09,\n",
      "        3.3704e-09, 3.2071e-09, 3.2663e-09, 4.0650e-06, 3.9415e-06, 4.0348e-06,\n",
      "        5.2943e-05, 4.9595e-05, 4.9762e-05, 3.7590e-06, 3.8503e-06, 3.1633e-05,\n",
      "        3.1799e-05, 3.2246e-01, 3.3743e-01, 1.3061e+00, 1.2910e+00, 3.7288e-06,\n",
      "        3.1600e-05, 3.1751e-01, 1.3111e+00, 2.8837e-01, 1.3406e+00, 3.6338e-01,\n",
      "        9.4751e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([211.9449, 248.4536, 266.9232, 253.8677,   7.6889,   7.6881,   7.6900,\n",
      "        390.5555, 390.5555, 390.5555,   7.6890,   7.6896, 390.5555, 390.5555,\n",
      "        390.5555, 390.5555, 390.5555,  64.2257,  64.2257,   7.6907, 390.5555,\n",
      "        390.5555, 390.5555, 390.5555, 390.5555,  64.2257,  64.2257, 390.5555,\n",
      "         64.2257,  64.2257,   5.2026, 390.5555, 390.5555, 390.5555, 390.5555,\n",
      "        390.5555,  64.2257,  64.2257, 390.5555,  64.2257,  64.2257,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 390.5555,   5.2026,   5.2025, 390.5555,   5.2026,\n",
      "          5.2025, 390.5555,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        390.5555, 390.5555, 390.5555, 390.5555,  64.2257,  64.2257,  64.2257,\n",
      "         64.2257, 390.5555, 390.5555, 390.5555,  64.2257,  64.2257,  64.2257,\n",
      "         64.2257,   5.2026,  64.2257,  64.2257,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 638 was 94.7%\n",
      "tensor([0.0000e+00, 2.9824e-06, 2.5228e-06, 2.3346e-06, 2.4657e-06, 4.7056e-09,\n",
      "        3.3443e-09, 3.1832e-09, 3.2419e-09, 4.0557e-06, 3.9340e-06, 4.0258e-06,\n",
      "        5.2370e-05, 4.9112e-05, 4.9255e-05, 3.7508e-06, 3.8436e-06, 3.1311e-05,\n",
      "        3.1485e-05, 3.2165e-01, 3.3679e-01, 1.3035e+00, 1.2883e+00, 3.7207e-06,\n",
      "        3.1277e-05, 3.1688e-01, 1.3084e+00, 2.8783e-01, 1.3378e+00, 3.6262e-01,\n",
      "        9.4762e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([212.2105, 248.7348, 267.2316, 254.1025,   7.6857,   7.6870,   7.6857,\n",
      "        390.9761, 390.9761, 390.9761,   7.6864,   7.6870, 390.9761, 390.9761,\n",
      "        390.9761, 390.9761, 390.9761,  64.3049,  64.3049,   7.6851, 390.9761,\n",
      "        390.9761, 390.9761, 390.9761, 390.9761,  64.3049,  64.3049, 390.9761,\n",
      "         64.3049,  64.3049,   5.2026, 390.9761, 390.9761, 390.9761, 390.9761,\n",
      "        390.9761,  64.3049,  64.3049, 390.9761,  64.3049,  64.3049,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 390.9761,   5.2026,   5.2025, 390.9761,   5.2026,\n",
      "          5.2025, 390.9761,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        390.9761, 390.9761, 390.9761, 390.9761,  64.3049,  64.3049,  64.3049,\n",
      "         64.3049, 390.9761, 390.9761, 390.9761,  64.3049,  64.3049,  64.3049,\n",
      "         64.3049,   5.2026,  64.3049,  64.3049,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 639 was 94.7%\n",
      "tensor([1.9852e-23, 2.9775e-06, 2.5191e-06, 2.3310e-06, 2.4623e-06, 4.6557e-09,\n",
      "        3.3076e-09, 3.1484e-09, 3.2071e-09, 4.0480e-06, 3.9244e-06, 4.0179e-06,\n",
      "        5.1676e-05, 4.8450e-05, 4.8615e-05, 3.7433e-06, 3.8350e-06, 3.0879e-05,\n",
      "        3.1044e-05, 3.2102e-01, 3.3612e-01, 1.3008e+00, 1.2856e+00, 3.7142e-06,\n",
      "        3.0851e-05, 3.1619e-01, 1.3057e+00, 2.8725e-01, 1.3350e+00, 3.6185e-01,\n",
      "        9.4773e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([212.4758, 249.0160, 267.5402, 254.3375,   7.6831,   7.6812,   7.6830,\n",
      "        391.3967, 391.3967, 391.3967,   7.6830,   7.6828, 391.3967, 391.3967,\n",
      "        391.3967, 391.3967, 391.3967,  64.3840,  64.3840,   7.6839, 391.3967,\n",
      "        391.3967, 391.3967, 391.3967, 391.3967,  64.3840,  64.3840, 391.3967,\n",
      "         64.3840,  64.3840,   5.2026, 391.3967, 391.3967, 391.3967, 391.3967,\n",
      "        391.3967,  64.3840,  64.3840, 391.3967,  64.3840,  64.3840,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 391.3967,   5.2026,   5.2025, 391.3967,   5.2026,\n",
      "          5.2025, 391.3967,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        391.3967, 391.3967, 391.3967, 391.3967,  64.3840,  64.3840,  64.3840,\n",
      "         64.3840, 391.3967, 391.3967, 391.3967,  64.3840,  64.3840,  64.3840,\n",
      "         64.3840,   5.2026,  64.3840,  64.3840,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 640 was 94.7%\n",
      "tensor([0.0000e+00, 2.9724e-06, 2.5151e-06, 2.3273e-06, 2.4591e-06, 4.6169e-09,\n",
      "        3.2798e-09, 3.1228e-09, 3.1811e-09, 4.0385e-06, 3.9176e-06, 4.0094e-06,\n",
      "        5.1081e-05, 4.7946e-05, 4.8093e-05, 3.7352e-06, 3.8283e-06, 3.0543e-05,\n",
      "        3.0719e-05, 3.2028e-01, 3.3545e-01, 1.2982e+00, 1.2830e+00, 3.7055e-06,\n",
      "        3.0510e-05, 3.1556e-01, 1.3030e+00, 2.8670e-01, 1.3323e+00, 3.6109e-01,\n",
      "        9.4783e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([212.7410, 249.2974, 267.8490, 254.5728,   7.6773,   7.6801,   7.6796,\n",
      "        391.8173, 391.8173, 391.8173,   7.6804,   7.6816, 391.8173, 391.8173,\n",
      "        391.8173, 391.8173, 391.8173,  64.4631,  64.4631,   7.6782, 391.8173,\n",
      "        391.8173, 391.8173, 391.8173, 391.8173,  64.4631,  64.4631, 391.8173,\n",
      "         64.4631,  64.4631,   5.2026, 391.8173, 391.8173, 391.8173, 391.8173,\n",
      "        391.8173,  64.4631,  64.4631, 391.8173,  64.4631,  64.4631,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 391.8173,   5.2026,   5.2025, 391.8173,   5.2026,\n",
      "          5.2025, 391.8173,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        391.8173, 391.8173, 391.8173, 391.8173,  64.4631,  64.4631,  64.4631,\n",
      "         64.4631, 391.8173, 391.8173, 391.8173,  64.4631,  64.4631,  64.4631,\n",
      "         64.4631,   5.2026,  64.4631,  64.4631,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 641 was 94.7%\n",
      "tensor([1.3235e-23, 2.9676e-06, 2.5115e-06, 2.3238e-06, 2.4560e-06, 4.5764e-09,\n",
      "        3.2505e-09, 3.0954e-09, 3.1535e-09, 4.0323e-06, 3.9079e-06, 4.0017e-06,\n",
      "        5.0505e-05, 4.7397e-05, 4.7556e-05, 3.7276e-06, 3.8199e-06, 3.0194e-05,\n",
      "        3.0354e-05, 3.1959e-01, 3.3482e-01, 1.2956e+00, 1.2803e+00, 3.6997e-06,\n",
      "        3.0175e-05, 3.1488e-01, 1.3004e+00, 2.8617e-01, 1.3295e+00, 3.6037e-01,\n",
      "        9.4794e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([213.0063, 249.5791, 268.1574, 254.8086,   7.6748,   7.6766,   7.6769,\n",
      "        392.2378, 392.2378, 392.2378,   7.6762,   7.6757, 392.2378, 392.2378,\n",
      "        392.2378, 392.2378, 392.2378,  64.5423,  64.5423,   7.6771, 392.2378,\n",
      "        392.2378, 392.2378, 392.2378, 392.2378,  64.5423,  64.5423, 392.2378,\n",
      "         64.5423,  64.5423,   5.2026, 392.2378, 392.2378, 392.2378, 392.2378,\n",
      "        392.2378,  64.5423,  64.5423, 392.2378,  64.5423,  64.5423,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 392.2378,   5.2026,   5.2025, 392.2378,   5.2026,\n",
      "          5.2025, 392.2378,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        392.2378, 392.2378, 392.2378, 392.2378,  64.5423,  64.5423,  64.5423,\n",
      "         64.5423, 392.2378, 392.2378, 392.2378,  64.5423,  64.5423,  64.5423,\n",
      "         64.5423,   5.2026,  64.5423,  64.5423,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 642 was 94.8%\n",
      "tensor([2.1749e-08, 2.9679e-06, 2.5119e-06, 2.3249e-06, 2.4572e-06, 2.4815e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0224e-06, 3.8998e-06, 3.9926e-06,\n",
      "        4.9890e-05, 4.6870e-05, 4.7012e-05, 3.7195e-06, 3.8131e-06, 2.9835e-05,\n",
      "        3.0005e-05, 3.1887e-01, 3.3410e-01, 1.2929e+00, 1.2776e+00, 3.6908e-06,\n",
      "        2.9814e-05, 3.1429e-01, 1.2975e+00, 2.8555e-01, 1.3267e+00, 3.5958e-01,\n",
      "        9.4805e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([213.2716, 249.8606, 268.4657, 255.0444,   7.6722,   7.6740,   7.6725,\n",
      "        392.6584, 392.6584, 392.6584,   7.6735,   7.6738, 392.6584, 392.6584,\n",
      "        392.6584, 392.6584, 392.6584,  64.6214,  64.6214,   7.6713, 392.6584,\n",
      "        392.6584, 392.6584, 392.6584, 392.6584,  64.6214,  64.6214, 392.6584,\n",
      "         64.6214,  64.6214,   5.2026, 392.6584, 392.6584, 392.6584, 392.6584,\n",
      "        392.6584,  64.6214,  64.6214, 392.6584,  64.6214,  64.6214,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 392.6584,   5.2026,   5.2025, 392.6584,   5.2026,\n",
      "          5.2025, 392.6584,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        392.6584, 392.6584, 392.6584, 392.6584,  64.6214,  64.6214,  64.6214,\n",
      "         64.6214, 392.6584, 392.6584, 392.6584,  64.6214,  64.6214,  64.6214,\n",
      "         64.6214,   5.2026,  64.6214,  64.6214,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 643 was 94.8%\n",
      "tensor([2.1542e-08, 2.9629e-06, 2.5081e-06, 2.3212e-06, 2.4538e-06, 6.6174e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0141e-06, 3.8910e-06, 3.9852e-06,\n",
      "        4.9329e-05, 4.6342e-05, 4.6496e-05, 3.7119e-06, 3.8046e-06, 2.9503e-05,\n",
      "        2.9663e-05, 3.1822e-01, 3.3344e-01, 1.2903e+00, 1.2750e+00, 3.6845e-06,\n",
      "        2.9482e-05, 3.1360e-01, 1.2949e+00, 2.8499e-01, 1.3240e+00, 3.5883e-01,\n",
      "        9.4816e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([213.5368, 250.1420, 268.7740, 255.2802,   7.6697,   7.6680,   7.6699,\n",
      "        393.0789, 393.0789, 393.0789,   7.6701,   7.6695, 393.0789, 393.0789,\n",
      "        393.0789, 393.0789, 393.0789,  64.7006,  64.7006,   7.6702, 393.0789,\n",
      "        393.0789, 393.0789, 393.0789, 393.0789,  64.7006,  64.7006, 393.0789,\n",
      "         64.7006,  64.7006,   5.2026, 393.0789, 393.0789, 393.0789, 393.0789,\n",
      "        393.0789,  64.7006,  64.7006, 393.0789,  64.7006,  64.7006,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 393.0789,   5.2026,   5.2025, 393.0789,   5.2026,\n",
      "          5.2025, 393.0789,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        393.0789, 393.0789, 393.0789, 393.0789,  64.7006,  64.7006,  64.7006,\n",
      "         64.7006, 393.0789, 393.0789, 393.0789,  64.7006,  64.7006,  64.7006,\n",
      "         64.7006,   5.2026,  64.7006,  64.7006,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 644 was 94.8%\n",
      "tensor([6.6174e-24, 2.9524e-06, 2.4995e-06, 2.3126e-06, 2.4459e-06, 4.4673e-09,\n",
      "        3.1728e-09, 3.0237e-09, 3.0807e-09, 4.0046e-06, 3.8839e-06, 3.9764e-06,\n",
      "        4.8852e-05, 4.5950e-05, 4.6081e-05, 3.7035e-06, 3.7976e-06, 2.9254e-05,\n",
      "        2.9419e-05, 3.1747e-01, 3.3277e-01, 1.2877e+00, 1.2723e+00, 3.6758e-06,\n",
      "        2.9232e-05, 3.1296e-01, 1.2922e+00, 2.8443e-01, 1.3212e+00, 3.5808e-01,\n",
      "        9.4826e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([213.8023, 250.4231, 269.0815, 255.5161,   7.6655,   7.6669,   7.6663,\n",
      "        393.4995, 393.4995, 393.4995,   7.6658,   7.6683, 393.4995, 393.4995,\n",
      "        393.4995, 393.4995, 393.4995,  64.7797,  64.7797,   7.6644, 393.4995,\n",
      "        393.4995, 393.4995, 393.4995, 393.4995,  64.7797,  64.7797, 393.4995,\n",
      "         64.7797,  64.7797,   5.2026, 393.4995, 393.4995, 393.4995, 393.4995,\n",
      "        393.4995,  64.7797,  64.7797, 393.4995,  64.7797,  64.7797,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 393.4995,   5.2026,   5.2025, 393.4995,   5.2026,\n",
      "          5.2025, 393.4995,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        393.4995, 393.4995, 393.4995, 393.4995,  64.7797,  64.7797,  64.7797,\n",
      "         64.7797, 393.4995, 393.4995, 393.4995,  64.7797,  64.7797,  64.7797,\n",
      "         64.7797,   5.2026,  64.7797,  64.7797,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 645 was 94.8%\n",
      "tensor([0.0000e+00, 2.9476e-06, 2.4958e-06, 2.3089e-06, 2.4428e-06, 4.4314e-09,\n",
      "        3.1470e-09, 2.9997e-09, 3.0564e-09, 3.9975e-06, 3.8739e-06, 3.9692e-06,\n",
      "        4.8334e-05, 4.5455e-05, 4.5609e-05, 3.6967e-06, 3.7891e-06, 2.8951e-05,\n",
      "        2.9092e-05, 3.1677e-01, 3.3216e-01, 1.2851e+00, 1.2696e+00, 3.6699e-06,\n",
      "        2.8932e-05, 3.1230e-01, 1.2896e+00, 2.8388e-01, 1.3185e+00, 3.5736e-01,\n",
      "        9.4837e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([214.0678, 250.7043, 269.3887, 255.7523,   7.6629,   7.6626,   7.6628,\n",
      "        393.9201, 393.9201, 393.9201,   7.6632,   7.6624, 393.9201, 393.9201,\n",
      "        393.9201, 393.9201, 393.9201,  64.8588,  64.8588,   7.6632, 393.9201,\n",
      "        393.9201, 393.9201, 393.9201, 393.9201,  64.8588,  64.8588, 393.9201,\n",
      "         64.8588,  64.8588,   5.2026, 393.9201, 393.9201, 393.9201, 393.9201,\n",
      "        393.9201,  64.8588,  64.8588, 393.9201,  64.8588,  64.8588,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 393.9201,   5.2026,   5.2025, 393.9201,   5.2026,\n",
      "          5.2025, 393.9201,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        393.9201, 393.9201, 393.9201, 393.9201,  64.8588,  64.8588,  64.8588,\n",
      "         64.8588, 393.9201, 393.9201, 393.9201,  64.8588,  64.8588,  64.8588,\n",
      "         64.8588,   5.2026,  64.8588,  64.8588,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 646 was 94.8%\n",
      "tensor([1.9852e-23, 2.9424e-06, 2.4916e-06, 2.3052e-06, 2.4392e-06, 4.3928e-09,\n",
      "        3.1193e-09, 2.9741e-09, 3.0304e-09, 3.9875e-06, 3.8664e-06, 3.9601e-06,\n",
      "        4.7753e-05, 4.4965e-05, 4.5091e-05, 3.6880e-06, 3.7823e-06, 2.8618e-05,\n",
      "        2.8774e-05, 3.1608e-01, 3.3141e-01, 1.2824e+00, 1.2670e+00, 3.6607e-06,\n",
      "        2.8598e-05, 3.1166e-01, 1.2868e+00, 2.8330e-01, 1.3156e+00, 3.5657e-01,\n",
      "        9.4848e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([214.3333, 250.9854, 269.6957, 255.9886,   7.6578,   7.6615,   7.6601,\n",
      "        394.3406, 394.3406, 394.3406,   7.6589,   7.6612, 394.3406, 394.3406,\n",
      "        394.3406, 394.3406, 394.3406,  64.9380,  64.9380,   7.6574, 394.3406,\n",
      "        394.3406, 394.3406, 394.3406, 394.3406,  64.9380,  64.9380, 394.3406,\n",
      "         64.9380,  64.9380,   5.2026, 394.3406, 394.3406, 394.3406, 394.3406,\n",
      "        394.3406,  64.9380,  64.9380, 394.3406,  64.9380,  64.9380,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 394.3406,   5.2026,   5.2025, 394.3406,   5.2026,\n",
      "          5.2025, 394.3406,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        394.3406, 394.3406, 394.3406, 394.3406,  64.9380,  64.9380,  64.9380,\n",
      "         64.9380, 394.3406, 394.3406, 394.3406,  64.9380,  64.9380,  64.9380,\n",
      "         64.9380,   5.2026,  64.9380,  64.9380,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 647 was 94.8%\n",
      "tensor([0.0000e+00, 2.9380e-06, 2.4880e-06, 2.3019e-06, 2.4363e-06, 4.3558e-09,\n",
      "        3.0926e-09, 2.9491e-09, 3.0052e-09, 3.9813e-06, 3.8573e-06, 3.9531e-06,\n",
      "        4.7233e-05, 4.4462e-05, 4.4613e-05, 3.6816e-06, 3.7739e-06, 2.8306e-05,\n",
      "        2.8444e-05, 3.1541e-01, 3.3081e-01, 1.2799e+00, 1.2644e+00, 3.6555e-06,\n",
      "        2.8292e-05, 3.1107e-01, 1.2843e+00, 2.8273e-01, 1.3130e+00, 3.5587e-01,\n",
      "        9.4858e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([214.5989, 251.2667, 270.0024, 256.2253,   7.6552,   7.6555,   7.6566,\n",
      "        394.7612, 394.7612, 394.7612,   7.6562,   7.6569, 394.7612, 394.7612,\n",
      "        394.7612, 394.7612, 394.7612,  65.0171,  65.0171,   7.6562, 394.7612,\n",
      "        394.7612, 394.7612, 394.7612, 394.7612,  65.0171,  65.0171, 394.7612,\n",
      "         65.0171,  65.0171,   5.2026, 394.7612, 394.7612, 394.7612, 394.7612,\n",
      "        394.7612,  65.0171,  65.0171, 394.7612,  65.0171,  65.0171,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 394.7612,   5.2026,   5.2025, 394.7612,   5.2026,\n",
      "          5.2025, 394.7612,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        394.7612, 394.7612, 394.7612, 394.7612,  65.0171,  65.0171,  65.0171,\n",
      "         65.0171, 394.7612, 394.7612, 394.7612,  65.0171,  65.0171,  65.0171,\n",
      "         65.0171,   5.2026,  65.0171,  65.0171,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 648 was 94.8%\n",
      "tensor([2.0601e-08, 2.9377e-06, 2.4884e-06, 2.3025e-06, 2.4372e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9713e-06, 3.8498e-06, 3.9439e-06,\n",
      "        4.6669e-05, 4.3983e-05, 4.4104e-05, 3.6723e-06, 3.7669e-06, 2.7984e-05,\n",
      "        2.8133e-05, 3.1466e-01, 3.3012e-01, 1.2772e+00, 1.2616e+00, 3.6463e-06,\n",
      "        2.7968e-05, 3.1038e-01, 1.2815e+00, 2.8219e-01, 1.3101e+00, 3.5509e-01,\n",
      "        9.4869e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([214.8645, 251.5479, 270.3090, 256.4621,   7.6526,   7.6535,   7.6521,\n",
      "        395.1817, 395.1817, 395.1817,   7.6528,   7.6508, 395.1817, 395.1817,\n",
      "        395.1817, 395.1817, 395.1817,  65.0962,  65.0962,   7.6543, 395.1817,\n",
      "        395.1817, 395.1817, 395.1817, 395.1817,  65.0962,  65.0962, 395.1817,\n",
      "         65.0962,  65.0962,   5.2026, 395.1817, 395.1817, 395.1817, 395.1817,\n",
      "        395.1817,  65.0962,  65.0962, 395.1817,  65.0962,  65.0962,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 395.1817,   5.2026,   5.2025, 395.1817,   5.2026,\n",
      "          5.2025, 395.1817,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        395.1817, 395.1817, 395.1817, 395.1817,  65.0962,  65.0962,  65.0962,\n",
      "         65.0962, 395.1817, 395.1817, 395.1817,  65.0962,  65.0962,  65.0962,\n",
      "         65.0962,   5.2026,  65.0962,  65.0962,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 649 was 94.8%\n",
      "tensor([0.0000e+00, 2.9276e-06, 2.4800e-06, 2.2946e-06, 2.4295e-06, 4.2822e-09,\n",
      "        3.0395e-09, 2.9000e-09, 2.9553e-09, 3.9621e-06, 3.8417e-06, 3.9363e-06,\n",
      "        4.6135e-05, 4.3516e-05, 4.3638e-05, 3.6655e-06, 3.7603e-06, 2.7677e-05,\n",
      "        2.7827e-05, 3.1401e-01, 3.2937e-01, 1.2746e+00, 1.2591e+00, 3.6385e-06,\n",
      "        2.7655e-05, 3.0980e-01, 1.2789e+00, 2.8164e-01, 1.3074e+00, 3.5437e-01,\n",
      "        9.4880e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([215.1301, 251.8291, 270.6156, 256.6990,   7.6483,   7.6491,   7.6502,\n",
      "        395.6022, 395.6022, 395.6022,   7.6500,   7.6496, 395.6022, 395.6022,\n",
      "        395.6022, 395.6022, 395.6022,  65.1754,  65.1754,   7.6484, 395.6022,\n",
      "        395.6022, 395.6022, 395.6022, 395.6022,  65.1754,  65.1754, 395.6022,\n",
      "         65.1754,  65.1754,   5.2026, 395.6022, 395.6022, 395.6022, 395.6022,\n",
      "        395.6022,  65.1754,  65.1754, 395.6022,  65.1754,  65.1754,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 395.6022,   5.2026,   5.2025, 395.6022,   5.2026,\n",
      "          5.2025, 395.6022,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        395.6022, 395.6022, 395.6022, 395.6022,  65.1754,  65.1754,  65.1754,\n",
      "         65.1754, 395.6022, 395.6022, 395.6022,  65.1754,  65.1754,  65.1754,\n",
      "         65.1754,   5.2026,  65.1754,  65.1754,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 650 was 94.8%\n",
      "tensor([1.9852e-23, 2.9228e-06, 2.4763e-06, 2.2908e-06, 2.4263e-06, 4.2452e-09,\n",
      "        3.0132e-09, 2.8755e-09, 2.9303e-09, 3.9548e-06, 3.8336e-06, 3.9273e-06,\n",
      "        4.5614e-05, 4.3033e-05, 4.3140e-05, 3.6567e-06, 3.7522e-06, 2.7361e-05,\n",
      "        2.7513e-05, 3.1330e-01, 3.2879e-01, 1.2720e+00, 1.2564e+00, 3.6320e-06,\n",
      "        2.7354e-05, 3.0911e-01, 1.2762e+00, 2.8106e-01, 1.3047e+00, 3.5361e-01,\n",
      "        9.4891e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([215.3956, 252.1104, 270.9220, 256.9362,   7.6456,   7.6464,   7.6441,\n",
      "        396.0228, 396.0228, 396.0228,   7.6458,   7.6460, 396.0228, 396.0228,\n",
      "        396.0228, 396.0228, 396.0228,  65.2545,  65.2545,   7.6472, 396.0228,\n",
      "        396.0228, 396.0228, 396.0228, 396.0228,  65.2545,  65.2545, 396.0228,\n",
      "         65.2545,  65.2545,   5.2026, 396.0228, 396.0228, 396.0228, 396.0228,\n",
      "        396.0228,  65.2545,  65.2545, 396.0228,  65.2545,  65.2545,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 396.0228,   5.2026,   5.2025, 396.0228,   5.2026,\n",
      "          5.2025, 396.0228,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        396.0228, 396.0228, 396.0228, 396.0228,  65.2545,  65.2545,  65.2545,\n",
      "         65.2545, 396.0228, 396.0228, 396.0228,  65.2545,  65.2545,  65.2545,\n",
      "         65.2545,   5.2026,  65.2545,  65.2545,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 651 was 94.9%\n",
      "tensor([3.3087e-24, 2.9177e-06, 2.4723e-06, 2.2873e-06, 2.4230e-06, 4.2081e-09,\n",
      "        2.9865e-09, 2.8506e-09, 2.9052e-09, 3.9454e-06, 3.8250e-06, 3.9208e-06,\n",
      "        4.5070e-05, 4.2549e-05, 4.2671e-05, 3.6500e-06, 3.7443e-06, 2.7057e-05,\n",
      "        2.7197e-05, 3.1262e-01, 3.2807e-01, 1.2694e+00, 1.2538e+00, 3.6236e-06,\n",
      "        2.7035e-05, 3.0849e-01, 1.2736e+00, 2.8053e-01, 1.3019e+00, 3.5287e-01,\n",
      "        9.4901e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([215.6611, 252.3919, 271.2285, 257.1733,   7.6424,   7.6419,   7.6426,\n",
      "        396.4433, 396.4433, 396.4433,   7.6438,   7.6424, 396.4433, 396.4433,\n",
      "        396.4433, 396.4433, 396.4433,  65.3336,  65.3336,   7.6413, 396.4433,\n",
      "        396.4433, 396.4433, 396.4433, 396.4433,  65.3336,  65.3336, 396.4433,\n",
      "         65.3336,  65.3336,   5.2026, 396.4433, 396.4433, 396.4433, 396.4433,\n",
      "        396.4433,  65.3336,  65.3336, 396.4433,  65.3336,  65.3336,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 396.4433,   5.2026,   5.2025, 396.4433,   5.2026,\n",
      "          5.2025, 396.4433,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        396.4433, 396.4433, 396.4433, 396.4433,  65.3336,  65.3336,  65.3336,\n",
      "         65.3336, 396.4433, 396.4433, 396.4433,  65.3336,  65.3336,  65.3336,\n",
      "         65.3336,   5.2026,  65.3336,  65.3336,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 652 was 94.9%\n",
      "tensor([0.0000e+00, 2.9128e-06, 2.4686e-06, 2.2836e-06, 2.4195e-06, 4.1720e-09,\n",
      "        2.9605e-09, 2.8263e-09, 2.8806e-09, 3.9375e-06, 3.8172e-06, 3.9109e-06,\n",
      "        4.4561e-05, 4.2083e-05, 4.2184e-05, 3.6413e-06, 3.7371e-06, 2.6740e-05,\n",
      "        2.6893e-05, 3.1196e-01, 3.2743e-01, 1.2667e+00, 1.2512e+00, 3.6171e-06,\n",
      "        2.6737e-05, 3.0779e-01, 1.2709e+00, 2.7996e-01, 1.2992e+00, 3.5212e-01,\n",
      "        9.4912e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([215.9266, 252.6731, 271.5347, 257.4108,   7.6388,   7.6401,   7.6381,\n",
      "        396.8639, 396.8639, 396.8639,   7.6378,   7.6388, 396.8639, 396.8639,\n",
      "        396.8639, 396.8639, 396.8639,  65.4128,  65.4128,   7.6401, 396.8639,\n",
      "        396.8639, 396.8639, 396.8639, 396.8639,  65.4128,  65.4128, 396.8639,\n",
      "         65.4128,  65.4128,   5.2026, 396.8639, 396.8639, 396.8639, 396.8639,\n",
      "        396.8639,  65.4128,  65.4128, 396.8639,  65.4128,  65.4128,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 396.8639,   5.2026,   5.2025, 396.8639,   5.2026,\n",
      "          5.2025, 396.8639,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        396.8639, 396.8639, 396.8639, 396.8639,  65.4128,  65.4128,  65.4128,\n",
      "         65.4128, 396.8639, 396.8639, 396.8639,  65.4128,  65.4128,  65.4128,\n",
      "         65.4128,   5.2026,  65.4128,  65.4128,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 653 was 94.9%\n",
      "tensor([1.9642e-08, 2.9128e-06, 2.4688e-06, 2.2845e-06, 2.4206e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9287e-06, 3.8083e-06, 3.9041e-06,\n",
      "        4.4034e-05, 4.1609e-05, 4.1731e-05, 3.6351e-06, 3.7293e-06, 2.6445e-05,\n",
      "        2.6582e-05, 3.1125e-01, 3.2674e-01, 1.2642e+00, 1.2486e+00, 3.6090e-06,\n",
      "        2.6428e-05, 3.0723e-01, 1.2682e+00, 2.7939e-01, 1.2965e+00, 3.5139e-01,\n",
      "        9.4922e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([216.1921, 252.9542, 271.8409, 257.6484,   7.6336,   7.6356,   7.6370,\n",
      "        397.2844, 397.2844, 397.2844,   7.6365,   7.6361, 397.2844, 397.2844,\n",
      "        397.2844, 397.2844, 397.2844,  65.4919,  65.4919,   7.6341, 397.2844,\n",
      "        397.2844, 397.2844, 397.2844, 397.2844,  65.4919,  65.4919, 397.2844,\n",
      "         65.4919,  65.4919,   5.2026, 397.2844, 397.2844, 397.2844, 397.2844,\n",
      "        397.2844,  65.4919,  65.4919, 397.2844,  65.4919,  65.4919,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 397.2844,   5.2026,   5.2025, 397.2844,   5.2026,\n",
      "          5.2025, 397.2844,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        397.2844, 397.2844, 397.2844, 397.2844,  65.4919,  65.4919,  65.4919,\n",
      "         65.4919, 397.2844, 397.2844, 397.2844,  65.4919,  65.4919,  65.4919,\n",
      "         65.4919,   5.2026,  65.4919,  65.4919,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 654 was 94.9%\n",
      "tensor([1.9454e-08, 2.9081e-06, 2.4652e-06, 2.2808e-06, 2.4175e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9220e-06, 3.8009e-06, 3.8950e-06,\n",
      "        4.3535e-05, 4.1152e-05, 4.1247e-05, 3.6260e-06, 3.7223e-06, 2.6137e-05,\n",
      "        2.6283e-05, 3.1055e-01, 3.2615e-01, 1.2616e+00, 1.2459e+00, 3.6031e-06,\n",
      "        2.6137e-05, 3.0657e-01, 1.2656e+00, 2.7885e-01, 1.2938e+00, 3.5065e-01,\n",
      "        9.4933e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([216.4577, 253.2355, 272.1466, 257.8862,   7.6309,   7.6328,   7.6308,\n",
      "        397.7049, 397.7049, 397.7049,   7.6322,   7.6324, 397.7049, 397.7049,\n",
      "        397.7049, 397.7049, 397.7049,  65.5710,  65.5710,   7.6329, 397.7049,\n",
      "        397.7049, 397.7049, 397.7049, 397.7049,  65.5710,  65.5710, 397.7049,\n",
      "         65.5710,  65.5710,   5.2026, 397.7049, 397.7049, 397.7049, 397.7049,\n",
      "        397.7049,  65.5710,  65.5710, 397.7049,  65.5710,  65.5710,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 397.7049,   5.2026,   5.2025, 397.7049,   5.2026,\n",
      "          5.2025, 397.7049,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        397.7049, 397.7049, 397.7049, 397.7049,  65.5710,  65.5710,  65.5710,\n",
      "         65.5710, 397.7049, 397.7049, 397.7049,  65.5710,  65.5710,  65.5710,\n",
      "         65.5710,   5.2026,  65.5710,  65.5710,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 655 was 94.9%\n",
      "tensor([9.9262e-24, 2.8981e-06, 2.4569e-06, 2.2729e-06, 2.4098e-06, 4.0700e-09,\n",
      "        2.8879e-09, 2.7589e-09, 2.8122e-09, 3.9125e-06, 3.7919e-06, 3.8881e-06,\n",
      "        4.3078e-05, 4.0748e-05, 4.0860e-05, 3.6190e-06, 3.7137e-06, 2.5899e-05,\n",
      "        2.6029e-05, 3.0987e-01, 3.2541e-01, 1.2590e+00, 1.2433e+00, 3.5944e-06,\n",
      "        2.5886e-05, 3.0593e-01, 1.2629e+00, 2.7830e-01, 1.2910e+00, 3.4991e-01,\n",
      "        9.4944e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([216.7235, 253.5167, 272.4517, 258.1242,   7.6273,   7.6283,   7.6296,\n",
      "        398.1254, 398.1254, 398.1254,   7.6302,   7.6288, 398.1254, 398.1254,\n",
      "        398.1254, 398.1254, 398.1254,  65.6502,  65.6502,   7.6269, 398.1254,\n",
      "        398.1254, 398.1254, 398.1254, 398.1254,  65.6502,  65.6502, 398.1254,\n",
      "         65.6502,  65.6502,   5.2026, 398.1254, 398.1254, 398.1254, 398.1254,\n",
      "        398.1254,  65.6502,  65.6502, 398.1254,  65.6502,  65.6502,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 398.1254,   5.2026,   5.2025, 398.1254,   5.2026,\n",
      "          5.2025, 398.1254,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        398.1254, 398.1254, 398.1254, 398.1254,  65.6502,  65.6502,  65.6502,\n",
      "         65.6502, 398.1254, 398.1254, 398.1254,  65.6502,  65.6502,  65.6502,\n",
      "         65.6502,   5.2026,  65.6502,  65.6502,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 656 was 94.9%\n",
      "tensor([6.6174e-24, 2.8933e-06, 2.4533e-06, 2.2693e-06, 2.4066e-06, 4.0377e-09,\n",
      "        2.8648e-09, 2.7376e-09, 2.7902e-09, 3.9050e-06, 3.7846e-06, 3.8787e-06,\n",
      "        4.2620e-05, 4.0337e-05, 4.0418e-05, 3.6104e-06, 3.7073e-06, 2.5617e-05,\n",
      "        2.5759e-05, 3.0920e-01, 3.2480e-01, 1.2564e+00, 1.2407e+00, 3.5884e-06,\n",
      "        2.5622e-05, 3.0527e-01, 1.2604e+00, 2.7775e-01, 1.2883e+00, 3.4918e-01,\n",
      "        9.4954e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([216.9894, 253.7978, 272.7566, 258.3623,   7.6246,   7.6255,   7.6251,\n",
      "        398.5460, 398.5460, 398.5460,   7.6241,   7.6251, 398.5460, 398.5460,\n",
      "        398.5460, 398.5460, 398.5460,  65.7293,  65.7293,   7.6257, 398.5460,\n",
      "        398.5460, 398.5460, 398.5460, 398.5460,  65.7293,  65.7293, 398.5460,\n",
      "         65.7293,  65.7293,   5.2026, 398.5460, 398.5460, 398.5460, 398.5460,\n",
      "        398.5460,  65.7293,  65.7293, 398.5460,  65.7293,  65.7293,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 398.5460,   5.2026,   5.2025, 398.5460,   5.2026,\n",
      "          5.2025, 398.5460,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        398.5460, 398.5460, 398.5460, 398.5460,  65.7293,  65.7293,  65.7293,\n",
      "         65.7293, 398.5460, 398.5460, 398.5460,  65.7293,  65.7293,  65.7293,\n",
      "         65.7293,   5.2026,  65.7293,  65.7293,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 657 was 94.9%\n",
      "tensor([0.0000e+00, 2.8882e-06, 2.4492e-06, 2.2656e-06, 2.4032e-06, 4.0021e-09,\n",
      "        2.8390e-09, 2.7136e-09, 2.7661e-09, 3.8953e-06, 3.7754e-06, 3.8713e-06,\n",
      "        4.2102e-05, 3.9874e-05, 3.9975e-05, 3.6038e-06, 3.6990e-06, 2.5329e-05,\n",
      "        2.5455e-05, 3.0848e-01, 3.2411e-01, 1.2538e+00, 1.2381e+00, 3.5795e-06,\n",
      "        2.5319e-05, 3.0466e-01, 1.2577e+00, 2.7717e-01, 1.2856e+00, 3.4842e-01,\n",
      "        9.4965e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([217.2551, 254.0789, 273.0615, 258.6006,   7.6211,   7.6210,   7.6231,\n",
      "        398.9665, 398.9665, 398.9665,   7.6228,   7.6215, 398.9665, 398.9665,\n",
      "        398.9665, 398.9665, 398.9665,  65.8084,  65.8084,   7.6197, 398.9665,\n",
      "        398.9665, 398.9665, 398.9665, 398.9665,  65.8084,  65.8084, 398.9665,\n",
      "         65.8084,  65.8084,   5.2026, 398.9665, 398.9665, 398.9665, 398.9665,\n",
      "        398.9665,  65.8084,  65.8084, 398.9665,  65.8084,  65.8084,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 398.9665,   5.2026,   5.2025, 398.9665,   5.2026,\n",
      "          5.2025, 398.9665,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        398.9665, 398.9665, 398.9665, 398.9665,  65.8084,  65.8084,  65.8084,\n",
      "         65.8084, 398.9665, 398.9665, 398.9665,  65.8084,  65.8084,  65.8084,\n",
      "         65.8084,   5.2026,  65.8084,  65.8084,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 658 was 94.9%\n",
      "tensor([0.0000e+00, 2.8836e-06, 2.4456e-06, 2.2620e-06, 2.4000e-06, 3.9695e-09,\n",
      "        2.8159e-09, 2.6920e-09, 2.7439e-09, 3.8880e-06, 3.7684e-06, 3.8624e-06,\n",
      "        4.1649e-05, 3.9460e-05, 3.9532e-05, 3.5949e-06, 3.6925e-06, 2.5049e-05,\n",
      "        2.5188e-05, 3.0783e-01, 3.2350e-01, 1.2513e+00, 1.2355e+00, 3.5738e-06,\n",
      "        2.5055e-05, 3.0401e-01, 1.2551e+00, 2.7662e-01, 1.2829e+00, 3.4771e-01,\n",
      "        9.4975e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([217.5209, 254.3600, 273.3663, 258.8391,   7.6175,   7.6191,   7.6167,\n",
      "        399.3870, 399.3870, 399.3870,   7.6185,   7.6178, 399.3870, 399.3870,\n",
      "        399.3870, 399.3870, 399.3870,  65.8876,  65.8876,   7.6184, 399.3870,\n",
      "        399.3870, 399.3870, 399.3870, 399.3870,  65.8876,  65.8876, 399.3870,\n",
      "         65.8876,  65.8876,   5.2026, 399.3870, 399.3870, 399.3870, 399.3870,\n",
      "        399.3870,  65.8876,  65.8876, 399.3870,  65.8876,  65.8876,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 399.3870,   5.2026,   5.2025, 399.3870,   5.2026,\n",
      "          5.2025, 399.3870,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        399.3870, 399.3870, 399.3870, 399.3870,  65.8876,  65.8876,  65.8876,\n",
      "         65.8876, 399.3870, 399.3870, 399.3870,  65.8876,  65.8876,  65.8876,\n",
      "         65.8876,   5.2026,  65.8876,  65.8876,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 659 was 94.9%\n",
      "tensor([1.8597e-08, 2.8831e-06, 2.4455e-06, 2.2627e-06, 2.4005e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8788e-06, 3.7592e-06, 3.8557e-06,\n",
      "        4.1158e-05, 3.9012e-05, 3.9110e-05, 3.5883e-06, 3.6838e-06, 2.4778e-05,\n",
      "        2.4899e-05, 3.0716e-01, 3.2275e-01, 1.2486e+00, 1.2329e+00, 3.5652e-06,\n",
      "        2.4769e-05, 3.0339e-01, 1.2524e+00, 2.7607e-01, 1.2802e+00, 3.4696e-01,\n",
      "        9.4986e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([217.7867, 254.6410, 273.6709, 259.0778,   7.6138,   7.6128,   7.6156,\n",
      "        399.8075, 399.8075, 399.8075,   7.6140,   7.6149, 399.8075, 399.8075,\n",
      "        399.8075, 399.8075, 399.8075,  65.9667,  65.9667,   7.6156, 399.8075,\n",
      "        399.8075, 399.8075, 399.8075, 399.8075,  65.9667,  65.9667, 399.8075,\n",
      "         65.9667,  65.9667,   5.2026, 399.8075, 399.8075, 399.8075, 399.8075,\n",
      "        399.8075,  65.9667,  65.9667, 399.8075,  65.9667,  65.9667,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 399.8075,   5.2026,   5.2025, 399.8075,   5.2026,\n",
      "          5.2025, 399.8075,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        399.8075, 399.8075, 399.8075, 399.8075,  65.9667,  65.9667,  65.9667,\n",
      "         65.9667, 399.8075, 399.8075, 399.8075,  65.9667,  65.9667,  65.9667,\n",
      "         65.9667,   5.2026,  65.9667,  65.9667,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 660 was 94.9%\n",
      "tensor([1.6544e-23, 2.8736e-06, 2.4377e-06, 2.2548e-06, 2.3936e-06, 3.9038e-09,\n",
      "        2.7689e-09, 2.6485e-09, 2.6996e-09, 3.8704e-06, 3.7519e-06, 3.8473e-06,\n",
      "        4.0702e-05, 3.8614e-05, 3.8693e-05, 3.5804e-06, 3.6772e-06, 2.4515e-05,\n",
      "        2.4637e-05, 3.0639e-01, 3.2217e-01, 1.2461e+00, 1.2303e+00, 3.5577e-06,\n",
      "        2.4507e-05, 3.0278e-01, 1.2498e+00, 2.7553e-01, 1.2775e+00, 3.4624e-01,\n",
      "        9.4996e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([218.0526, 254.9220, 273.9752, 259.3166,   7.6102,   7.6116,   7.6109,\n",
      "        400.2280, 400.2280, 400.2280,   7.6112,   7.6120, 400.2280, 400.2280,\n",
      "        400.2280, 400.2280, 400.2280,  66.0458,  66.0458,   7.6095, 400.2280,\n",
      "        400.2280, 400.2280, 400.2280, 400.2280,  66.0458,  66.0458, 400.2280,\n",
      "         66.0458,  66.0458,   5.2026, 400.2280, 400.2280, 400.2280, 400.2280,\n",
      "        400.2280,  66.0458,  66.0458, 400.2280,  66.0458,  66.0458,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 400.2280,   5.2026,   5.2025, 400.2280,   5.2026,\n",
      "          5.2025, 400.2280,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        400.2280, 400.2280, 400.2280, 400.2280,  66.0458,  66.0458,  66.0458,\n",
      "         66.0458, 400.2280, 400.2280, 400.2280,  66.0458,  66.0458,  66.0458,\n",
      "         66.0458,   5.2026,  66.0458,  66.0458,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 661 was 95.0%\n",
      "tensor([0.0000e+00, 2.8688e-06, 2.4341e-06, 2.2513e-06, 2.3901e-06, 3.8713e-09,\n",
      "        2.7456e-09, 2.6266e-09, 2.6777e-09, 3.8628e-06, 3.7427e-06, 3.8396e-06,\n",
      "        4.0248e-05, 3.8185e-05, 3.8277e-05, 3.5732e-06, 3.6688e-06, 2.4247e-05,\n",
      "        2.4359e-05, 3.0578e-01, 3.2150e-01, 1.2435e+00, 1.2277e+00, 3.5513e-06,\n",
      "        2.4244e-05, 3.0210e-01, 1.2472e+00, 2.7497e-01, 1.2748e+00, 3.4550e-01,\n",
      "        9.5007e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([218.3185, 255.2030, 274.2793, 259.5557,   7.6074,   7.6070,   7.6080,\n",
      "        400.6485, 400.6485, 400.6485,   7.6075,   7.6056, 400.6485, 400.6485,\n",
      "        400.6485, 400.6485, 400.6485,  66.1250,  66.1250,   7.6083, 400.6485,\n",
      "        400.6485, 400.6485, 400.6485, 400.6485,  66.1250,  66.1250, 400.6485,\n",
      "         66.1250,  66.1250,   5.2026, 400.6485, 400.6485, 400.6485, 400.6485,\n",
      "        400.6485,  66.1250,  66.1250, 400.6485,  66.1250,  66.1250,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 400.6485,   5.2026,   5.2025, 400.6485,   5.2026,\n",
      "          5.2025, 400.6485,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        400.6485, 400.6485, 400.6485, 400.6485,  66.1250,  66.1250,  66.1250,\n",
      "         66.1250, 400.6485, 400.6485, 400.6485,  66.1250,  66.1250,  66.1250,\n",
      "         66.1250,   5.2026,  66.1250,  66.1250,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 662 was 95.0%\n",
      "tensor([1.9852e-23, 2.8639e-06, 2.4301e-06, 2.2478e-06, 2.3868e-06, 3.8387e-09,\n",
      "        2.7221e-09, 2.6050e-09, 2.6555e-09, 3.8536e-06, 3.7354e-06, 3.8311e-06,\n",
      "        3.9778e-05, 3.7782e-05, 3.7854e-05, 3.5652e-06, 3.6627e-06, 2.3977e-05,\n",
      "        2.4095e-05, 3.0509e-01, 3.2081e-01, 1.2410e+00, 1.2251e+00, 3.5429e-06,\n",
      "        2.3971e-05, 3.0151e-01, 1.2446e+00, 2.7441e-01, 1.2721e+00, 3.4477e-01,\n",
      "        9.5017e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([218.5842, 255.4843, 274.5836, 259.7950,   7.6029,   7.6059,   7.6033,\n",
      "        401.0690, 401.0690, 401.0690,   7.6039,   7.6044, 401.0690, 401.0690,\n",
      "        401.0690, 401.0690, 401.0690,  66.2041,  66.2041,   7.6021, 401.0690,\n",
      "        401.0690, 401.0690, 401.0690, 401.0690,  66.2041,  66.2041, 401.0690,\n",
      "         66.2041,  66.2041,   5.2026, 401.0690, 401.0690, 401.0690, 401.0690,\n",
      "        401.0690,  66.2041,  66.2041, 401.0690,  66.2041,  66.2041,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 401.0690,   5.2026,   5.2025, 401.0690,   5.2026,\n",
      "          5.2025, 401.0690,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        401.0690, 401.0690, 401.0690, 401.0690,  66.2041,  66.2041,  66.2041,\n",
      "         66.2041, 401.0690, 401.0690, 401.0690,  66.2041,  66.2041,  66.2041,\n",
      "         66.2041,   5.2026,  66.2041,  66.2041,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 663 was 95.0%\n",
      "tensor([0.0000e+00, 2.8593e-06, 2.4264e-06, 2.2444e-06, 2.3835e-06, 3.8060e-09,\n",
      "        2.6988e-09, 2.5829e-09, 2.6333e-09, 3.8466e-06, 3.7261e-06, 3.8241e-06,\n",
      "        3.9336e-05, 3.7347e-05, 3.7445e-05, 3.5584e-06, 3.6535e-06, 2.3712e-05,\n",
      "        2.3815e-05, 3.0448e-01, 3.2015e-01, 1.2384e+00, 1.2226e+00, 3.5371e-06,\n",
      "        2.3709e-05, 3.0088e-01, 1.2420e+00, 2.7384e-01, 1.2694e+00, 3.4406e-01,\n",
      "        9.5027e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([218.8500, 255.7656, 274.8877, 260.0345,   7.6001,   7.5995,   7.6004,\n",
      "        401.4895, 401.4895, 401.4895,   7.6002,   7.5998, 401.4895, 401.4895,\n",
      "        401.4895, 401.4895, 401.4895,  66.2832,  66.2832,   7.6009, 401.4895,\n",
      "        401.4895, 401.4895, 401.4895, 401.4895,  66.2832,  66.2832, 401.4895,\n",
      "         66.2832,  66.2832,   5.2026, 401.4895, 401.4895, 401.4895, 401.4895,\n",
      "        401.4895,  66.2832,  66.2832, 401.4895,  66.2832,  66.2832,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 401.4895,   5.2026,   5.2025, 401.4895,   5.2026,\n",
      "          5.2025, 401.4895,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        401.4895, 401.4895, 401.4895, 401.4895,  66.2832,  66.2832,  66.2832,\n",
      "         66.2832, 401.4895, 401.4895, 401.4895,  66.2832,  66.2832,  66.2832,\n",
      "         66.2832,   5.2026,  66.2832,  66.2832,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 664 was 95.0%\n",
      "tensor([1.7753e-08, 2.8586e-06, 2.4263e-06, 2.2446e-06, 2.3840e-06, 4.9631e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8370e-06, 3.7191e-06, 3.8151e-06,\n",
      "        3.8860e-05, 3.6944e-05, 3.7016e-05, 3.5501e-06, 3.6470e-06, 2.3438e-05,\n",
      "        2.3551e-05, 3.0372e-01, 3.1950e-01, 1.2358e+00, 1.2199e+00, 3.5282e-06,\n",
      "        2.3432e-05, 3.0023e-01, 1.2393e+00, 2.7331e-01, 1.2666e+00, 3.4329e-01,\n",
      "        9.5038e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([219.1157, 256.0468, 275.1917, 260.2740,   7.5955,   7.5983,   7.5957,\n",
      "        401.9100, 401.9100, 401.9100,   7.5965,   7.5985, 401.9100, 401.9100,\n",
      "        401.9100, 401.9100, 401.9100,  66.3624,  66.3624,   7.5947, 401.9100,\n",
      "        401.9100, 401.9100, 401.9100, 401.9100,  66.3624,  66.3624, 401.9100,\n",
      "         66.3624,  66.3624,   5.2026, 401.9100, 401.9100, 401.9100, 401.9100,\n",
      "        401.9100,  66.3624,  66.3624, 401.9100,  66.3624,  66.3624,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 401.9100,   5.2026,   5.2025, 401.9100,   5.2026,\n",
      "          5.2025, 401.9100,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        401.9100, 401.9100, 401.9100, 401.9100,  66.3624,  66.3624,  66.3624,\n",
      "         66.3624, 401.9100, 401.9100, 401.9100,  66.3624,  66.3624,  66.3624,\n",
      "         66.3624,   5.2026,  66.3624,  66.3624,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 665 was 95.0%\n",
      "tensor([9.9262e-24, 2.8496e-06, 2.4190e-06, 2.2373e-06, 2.3771e-06, 3.7449e-09,\n",
      "        2.6553e-09, 2.5425e-09, 2.5922e-09, 3.8305e-06, 3.7097e-06, 3.8086e-06,\n",
      "        3.8473e-05, 3.6563e-05, 3.6659e-05, 3.5437e-06, 3.6383e-06, 2.3214e-05,\n",
      "        2.3306e-05, 3.0310e-01, 3.1887e-01, 1.2333e+00, 1.2174e+00, 3.5229e-06,\n",
      "        2.3213e-05, 2.9959e-01, 1.2368e+00, 2.7278e-01, 1.2640e+00, 3.4260e-01,\n",
      "        9.5048e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([219.3817, 256.3279, 275.4950, 260.5138,   7.5927,   7.5937,   7.5928,\n",
      "        402.3305, 402.3305, 402.3305,   7.5928,   7.5921, 402.3305, 402.3305,\n",
      "        402.3305, 402.3305, 402.3305,  66.4415,  66.4415,   7.5934, 402.3305,\n",
      "        402.3305, 402.3305, 402.3305, 402.3305,  66.4415,  66.4415, 402.3305,\n",
      "         66.4415,  66.4415,   5.2026, 402.3305, 402.3305, 402.3305, 402.3305,\n",
      "        402.3305,  66.4415,  66.4415, 402.3305,  66.4415,  66.4415,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 402.3305,   5.2026,   5.2025, 402.3305,   5.2026,\n",
      "          5.2025, 402.3305,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        402.3305, 402.3305, 402.3305, 402.3305,  66.4415,  66.4415,  66.4415,\n",
      "         66.4415, 402.3305, 402.3305, 402.3305,  66.4415,  66.4415,  66.4415,\n",
      "         66.4415,   5.2026,  66.4415,  66.4415,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 666 was 95.0%\n",
      "tensor([1.9852e-23, 2.8445e-06, 2.4148e-06, 2.2336e-06, 2.3735e-06, 3.7126e-09,\n",
      "        2.6320e-09, 2.5211e-09, 2.5702e-09, 3.8206e-06, 3.7024e-06, 3.7993e-06,\n",
      "        3.8008e-05, 3.6169e-05, 3.6240e-05, 3.5353e-06, 3.6319e-06, 2.2945e-05,\n",
      "        2.3050e-05, 3.0240e-01, 3.1816e-01, 1.2307e+00, 1.2148e+00, 3.5138e-06,\n",
      "        2.2943e-05, 2.9899e-01, 1.2341e+00, 2.7220e-01, 1.2613e+00, 3.4184e-01,\n",
      "        9.5059e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([219.6477, 256.6088, 275.7983, 260.7536,   7.5890,   7.5872,   7.5899,\n",
      "        402.7510, 402.7510, 402.7510,   7.5899,   7.5908, 402.7510, 402.7510,\n",
      "        402.7510, 402.7510, 402.7510,  66.5206,  66.5206,   7.5889, 402.7510,\n",
      "        402.7510, 402.7510, 402.7510, 402.7510,  66.5206,  66.5206, 402.7510,\n",
      "         66.5206,  66.5206,   5.2026, 402.7510, 402.7510, 402.7510, 402.7510,\n",
      "        402.7510,  66.5206,  66.5206, 402.7510,  66.5206,  66.5206,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 402.7510,   5.2026,   5.2025, 402.7510,   5.2026,\n",
      "          5.2025, 402.7510,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        402.7510, 402.7510, 402.7510, 402.7510,  66.5206,  66.5206,  66.5206,\n",
      "         66.5206, 402.7510, 402.7510, 402.7510,  66.5206,  66.5206,  66.5206,\n",
      "         66.5206,   5.2026,  66.5206,  66.5206,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 667 was 95.0%\n",
      "tensor([0.0000e+00, 2.8397e-06, 2.4113e-06, 2.2300e-06, 2.3705e-06, 3.6827e-09,\n",
      "        2.6110e-09, 2.5014e-09, 2.5502e-09, 3.8131e-06, 3.6954e-06, 3.7914e-06,\n",
      "        3.7595e-05, 3.5789e-05, 3.5854e-05, 3.5275e-06, 3.6244e-06, 2.2703e-05,\n",
      "        2.2807e-05, 3.0170e-01, 3.1759e-01, 1.2282e+00, 1.2122e+00, 3.5073e-06,\n",
      "        2.2705e-05, 2.9831e-01, 1.2316e+00, 2.7170e-01, 1.2586e+00, 3.4114e-01,\n",
      "        9.5069e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([219.9138, 256.8898, 276.1013, 260.9937,   7.5852,   7.5860,   7.5860,\n",
      "        403.1715, 403.1715, 403.1715,   7.5853,   7.5844, 403.1715, 403.1715,\n",
      "        403.1715, 403.1715, 403.1715,  66.5998,  66.5998,   7.5868, 403.1715,\n",
      "        403.1715, 403.1715, 403.1715, 403.1715,  66.5998,  66.5998, 403.1715,\n",
      "         66.5998,  66.5998,   5.2026, 403.1715, 403.1715, 403.1715, 403.1715,\n",
      "        403.1715,  66.5998,  66.5998, 403.1715,  66.5998,  66.5998,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 403.1715,   5.2026,   5.2025, 403.1715,   5.2026,\n",
      "          5.2025, 403.1715,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        403.1715, 403.1715, 403.1715, 403.1715,  66.5998,  66.5998,  66.5998,\n",
      "         66.5998, 403.1715, 403.1715, 403.1715,  66.5998,  66.5998,  66.5998,\n",
      "         66.5998,   5.2026,  66.5998,  66.5998,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 668 was 95.0%\n",
      "tensor([1.7123e-08, 2.8392e-06, 2.4109e-06, 2.2305e-06, 2.3708e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8042e-06, 3.6866e-06, 3.7834e-06,\n",
      "        3.7147e-05, 3.5397e-05, 3.5457e-05, 3.5203e-06, 3.6177e-06, 2.2445e-05,\n",
      "        2.2547e-05, 3.0104e-01, 3.1685e-01, 1.2256e+00, 1.2097e+00, 3.4990e-06,\n",
      "        2.2442e-05, 2.9776e-01, 1.2289e+00, 2.7112e-01, 1.2559e+00, 3.4040e-01,\n",
      "        9.5080e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([220.1798, 257.1708, 276.4042, 261.2339,   7.5815,   7.5831,   7.5812,\n",
      "        403.5920, 403.5920, 403.5920,   7.5823,   7.5831, 403.5920, 403.5920,\n",
      "        403.5920, 403.5920, 403.5920,  66.6789,  66.6789,   7.5806, 403.5920,\n",
      "        403.5920, 403.5920, 403.5920, 403.5920,  66.6789,  66.6789, 403.5920,\n",
      "         66.6789,  66.6789,   5.2026, 403.5920, 403.5920, 403.5920, 403.5920,\n",
      "        403.5920,  66.6789,  66.6789, 403.5920,  66.6789,  66.6789,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 403.5920,   5.2026,   5.2025, 403.5920,   5.2026,\n",
      "          5.2025, 403.5920,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        403.5920, 403.5920, 403.5920, 403.5920,  66.6789,  66.6789,  66.6789,\n",
      "         66.6789, 403.5920, 403.5920, 403.5920,  66.6789,  66.6789,  66.6789,\n",
      "         66.6789,   5.2026,  66.6789,  66.6789,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 669 was 95.0%\n",
      "tensor([3.3087e-24, 2.8302e-06, 2.4037e-06, 2.2231e-06, 2.3638e-06, 3.6210e-09,\n",
      "        2.5667e-09, 2.4601e-09, 2.5082e-09, 3.7968e-06, 3.6779e-06, 3.7763e-06,\n",
      "        3.6742e-05, 3.5004e-05, 3.5075e-05, 3.5130e-06, 3.6090e-06, 2.2204e-05,\n",
      "        2.2294e-05, 3.0042e-01, 3.1623e-01, 1.2230e+00, 1.2071e+00, 3.4932e-06,\n",
      "        2.2205e-05, 2.9708e-01, 1.2264e+00, 2.7058e-01, 1.2533e+00, 3.3968e-01,\n",
      "        9.5090e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([220.4459, 257.4518, 276.7069, 261.4743,   7.5777,   7.5766,   7.5792,\n",
      "        404.0125, 404.0125, 404.0125,   7.5786,   7.5784, 404.0125, 404.0125,\n",
      "        404.0125, 404.0125, 404.0125,  66.7580,  66.7580,   7.5793, 404.0125,\n",
      "        404.0125, 404.0125, 404.0125, 404.0125,  66.7580,  66.7580, 404.0125,\n",
      "         66.7580,  66.7580,   5.2026, 404.0125, 404.0125, 404.0125, 404.0125,\n",
      "        404.0125,  66.7580,  66.7580, 404.0125,  66.7580,  66.7580,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 404.0125,   5.2026,   5.2025, 404.0125,   5.2026,\n",
      "          5.2025, 404.0125,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        404.0125, 404.0125, 404.0125, 404.0125,  66.7580,  66.7580,  66.7580,\n",
      "         66.7580, 404.0125, 404.0125, 404.0125,  66.7580,  66.7580,  66.7580,\n",
      "         66.7580,   5.2026,  66.7580,  66.7580,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 670 was 95.1%\n",
      "tensor([0.0000e+00, 2.8253e-06, 2.3998e-06, 2.2195e-06, 2.3606e-06, 3.5903e-09,\n",
      "        2.5448e-09, 2.4399e-09, 2.4874e-09, 3.7881e-06, 3.6714e-06, 3.7674e-06,\n",
      "        3.6311e-05, 3.4632e-05, 3.4680e-05, 3.5047e-06, 3.6026e-06, 2.1955e-05,\n",
      "        2.2054e-05, 2.9968e-01, 3.1558e-01, 1.2205e+00, 1.2045e+00, 3.4849e-06,\n",
      "        2.1955e-05, 2.9649e-01, 1.2238e+00, 2.7004e-01, 1.2506e+00, 3.3896e-01,\n",
      "        9.5100e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([220.7120, 257.7328, 277.0094, 261.7148,   7.5739,   7.5754,   7.5743,\n",
      "        404.4330, 404.4330, 404.4330,   7.5748,   7.5762, 404.4330, 404.4330,\n",
      "        404.4330, 404.4330, 404.4330,  66.8372,  66.8372,   7.5729, 404.4330,\n",
      "        404.4330, 404.4330, 404.4330, 404.4330,  66.8372,  66.8372, 404.4330,\n",
      "         66.8372,  66.8372,   5.2026, 404.4330, 404.4330, 404.4330, 404.4330,\n",
      "        404.4330,  66.8372,  66.8372, 404.4330,  66.8372,  66.8372,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 404.4330,   5.2026,   5.2025, 404.4330,   5.2026,\n",
      "          5.2025, 404.4330,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        404.4330, 404.4330, 404.4330, 404.4330,  66.8372,  66.8372,  66.8372,\n",
      "         66.8372, 404.4330, 404.4330, 404.4330,  66.8372,  66.8372,  66.8372,\n",
      "         66.8372,   5.2026,  66.8372,  66.8372,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 671 was 95.1%\n",
      "tensor([0.0000e+00, 2.8205e-06, 2.3962e-06, 2.2161e-06, 2.3573e-06, 3.5601e-09,\n",
      "        2.5232e-09, 2.4194e-09, 2.4668e-09, 3.7807e-06, 3.6620e-06, 3.7603e-06,\n",
      "        3.5905e-05, 3.4239e-05, 3.4306e-05, 3.4980e-06, 3.5942e-06, 2.1713e-05,\n",
      "        2.1798e-05, 2.9906e-01, 3.1495e-01, 1.2180e+00, 1.2020e+00, 3.4790e-06,\n",
      "        2.1715e-05, 2.9582e-01, 1.2212e+00, 2.6950e-01, 1.2480e+00, 3.3824e-01,\n",
      "        9.5111e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([220.9780, 258.0140, 277.3119, 261.9557,   7.5710,   7.5707,   7.5714,\n",
      "        404.8534, 404.8534, 404.8534,   7.5710,   7.5697, 404.8534, 404.8534,\n",
      "        404.8534, 404.8534, 404.8534,  66.9163,  66.9163,   7.5716, 404.8534,\n",
      "        404.8534, 404.8534, 404.8534, 404.8534,  66.9163,  66.9163, 404.8534,\n",
      "         66.9163,  66.9163,   5.2026, 404.8534, 404.8534, 404.8534, 404.8534,\n",
      "        404.8534,  66.9163,  66.9163, 404.8534,  66.9163,  66.9163,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 404.8534,   5.2026,   5.2025, 404.8534,   5.2026,\n",
      "          5.2025, 404.8534,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        404.8534, 404.8534, 404.8534, 404.8534,  66.9163,  66.9163,  66.9163,\n",
      "         66.9163, 404.8534, 404.8534, 404.8534,  66.9163,  66.9163,  66.9163,\n",
      "         66.9163,   5.2026,  66.9163,  66.9163,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 672 was 95.1%\n",
      "tensor([0.0000e+00, 2.8156e-06, 2.3922e-06, 2.2125e-06, 2.3540e-06, 3.5287e-09,\n",
      "        2.5005e-09, 2.3984e-09, 2.4452e-09, 3.7713e-06, 3.6548e-06, 3.7516e-06,\n",
      "        3.5466e-05, 3.3862e-05, 3.3908e-05, 3.4900e-06, 3.5880e-06, 2.1457e-05,\n",
      "        2.1550e-05, 2.9837e-01, 3.1425e-01, 1.2154e+00, 1.1994e+00, 3.4703e-06,\n",
      "        2.1456e-05, 2.9524e-01, 1.2186e+00, 2.6893e-01, 1.2453e+00, 3.3750e-01,\n",
      "        9.5121e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([221.2439, 258.2952, 277.6144, 262.1967,   7.5654,   7.5695,   7.5665,\n",
      "        405.2739, 405.2739, 405.2739,   7.5681,   7.5684, 405.2739, 405.2739,\n",
      "        405.2739, 405.2739, 405.2739,  66.9954,  66.9954,   7.5653, 405.2739,\n",
      "        405.2739, 405.2739, 405.2739, 405.2739,  66.9954,  66.9954, 405.2739,\n",
      "         66.9954,  66.9954,   5.2026, 405.2739, 405.2739, 405.2739, 405.2739,\n",
      "        405.2739,  66.9954,  66.9954, 405.2739,  66.9954,  66.9954,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 405.2739,   5.2026,   5.2025, 405.2739,   5.2026,\n",
      "          5.2025, 405.2739,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        405.2739, 405.2739, 405.2739, 405.2739,  66.9954,  66.9954,  66.9954,\n",
      "         66.9954, 405.2739, 405.2739, 405.2739,  66.9954,  66.9954,  66.9954,\n",
      "         66.9954,   5.2026,  66.9954,  66.9954,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 673 was 95.1%\n",
      "tensor([1.6340e-08, 2.8153e-06, 2.3922e-06, 2.2131e-06, 2.3543e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7652e-06, 3.6460e-06, 3.7449e-06,\n",
      "        3.5074e-05, 3.3473e-05, 3.3540e-05, 3.4833e-06, 3.5793e-06, 2.1219e-05,\n",
      "        2.1300e-05, 2.9779e-01, 3.1360e-01, 1.2129e+00, 1.1970e+00, 3.4651e-06,\n",
      "        2.1224e-05, 2.9462e-01, 1.2161e+00, 2.6840e-01, 1.2427e+00, 3.3682e-01,\n",
      "        9.5131e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([221.5099, 258.5765, 277.9165, 262.4380,   7.5625,   7.5628,   7.5635,\n",
      "        405.6944, 405.6944, 405.6944,   7.5642,   7.5636, 405.6944, 405.6944,\n",
      "        405.6944, 405.6944, 405.6944,  67.0746,  67.0746,   7.5639, 405.6944,\n",
      "        405.6944, 405.6944, 405.6944, 405.6944,  67.0746,  67.0746, 405.6944,\n",
      "         67.0746,  67.0746,   5.2026, 405.6944, 405.6944, 405.6944, 405.6944,\n",
      "        405.6944,  67.0746,  67.0746, 405.6944,  67.0746,  67.0746,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 405.6944,   5.2026,   5.2025, 405.6944,   5.2026,\n",
      "          5.2025, 405.6944,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        405.6944, 405.6944, 405.6944, 405.6944,  67.0746,  67.0746,  67.0746,\n",
      "         67.0746, 405.6944, 405.6944, 405.6944,  67.0746,  67.0746,  67.0746,\n",
      "         67.0746,   5.2026,  67.0746,  67.0746,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 674 was 95.1%\n",
      "tensor([3.3087e-24, 2.8060e-06, 2.3847e-06, 2.2056e-06, 2.3474e-06, 3.4674e-09,\n",
      "        2.4568e-09, 2.3574e-09, 2.4035e-09, 3.7555e-06, 3.6391e-06, 3.7358e-06,\n",
      "        3.4641e-05, 3.3100e-05, 3.3142e-05, 3.4747e-06, 3.5726e-06, 2.0966e-05,\n",
      "        2.1058e-05, 2.9705e-01, 3.1294e-01, 1.2103e+00, 1.1943e+00, 3.4561e-06,\n",
      "        2.0970e-05, 2.9397e-01, 1.2134e+00, 2.6787e-01, 1.2399e+00, 3.3606e-01,\n",
      "        9.5142e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([221.7758, 258.8576, 278.2186, 262.6794,   7.5595,   7.5607,   7.5604,\n",
      "        406.1149, 406.1149, 406.1149,   7.5577,   7.5606, 406.1149, 406.1149,\n",
      "        406.1149, 406.1149, 406.1149,  67.1537,  67.1537,   7.5593, 406.1149,\n",
      "        406.1149, 406.1149, 406.1149, 406.1149,  67.1537,  67.1537, 406.1149,\n",
      "         67.1537,  67.1537,   5.2026, 406.1149, 406.1149, 406.1149, 406.1149,\n",
      "        406.1149,  67.1537,  67.1537, 406.1149,  67.1537,  67.1537,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 406.1149,   5.2026,   5.2025, 406.1149,   5.2026,\n",
      "          5.2025, 406.1149,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        406.1149, 406.1149, 406.1149, 406.1149,  67.1537,  67.1537,  67.1537,\n",
      "         67.1537, 406.1149, 406.1149, 406.1149,  67.1537,  67.1537,  67.1537,\n",
      "         67.1537,   5.2026,  67.1537,  67.1537,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 675 was 95.1%\n",
      "tensor([6.6174e-24, 2.8015e-06, 2.3810e-06, 2.2021e-06, 2.3442e-06, 3.4388e-09,\n",
      "        2.4360e-09, 2.3379e-09, 2.3839e-09, 3.7476e-06, 3.6304e-06, 3.7284e-06,\n",
      "        3.4250e-05, 3.2735e-05, 3.2791e-05, 3.4687e-06, 3.5648e-06, 2.0737e-05,\n",
      "        2.0819e-05, 2.9639e-01, 3.1234e-01, 1.2078e+00, 1.1918e+00, 3.4495e-06,\n",
      "        2.0739e-05, 2.9338e-01, 1.2109e+00, 2.6728e-01, 1.2373e+00, 3.3534e-01,\n",
      "        9.5152e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([222.0418, 259.1387, 278.5206, 262.9209,   7.5557,   7.5540,   7.5565,\n",
      "        406.5353, 406.5353, 406.5353,   7.5564,   7.5558, 406.5353, 406.5353,\n",
      "        406.5353, 406.5353, 406.5353,  67.2328,  67.2328,   7.5572, 406.5353,\n",
      "        406.5353, 406.5353, 406.5353, 406.5353,  67.2328,  67.2328, 406.5353,\n",
      "         67.2328,  67.2328,   5.2026, 406.5353, 406.5353, 406.5353, 406.5353,\n",
      "        406.5353,  67.2328,  67.2328, 406.5353,  67.2328,  67.2328,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 406.5353,   5.2026,   5.2025, 406.5353,   5.2026,\n",
      "          5.2025, 406.5353,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        406.5353, 406.5353, 406.5353, 406.5353,  67.2328,  67.2328,  67.2328,\n",
      "         67.2328, 406.5353, 406.5353, 406.5353,  67.2328,  67.2328,  67.2328,\n",
      "         67.2328,   5.2026,  67.2328,  67.2328,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 676 was 95.1%\n",
      "tensor([9.9262e-24, 2.7966e-06, 2.3772e-06, 2.1987e-06, 2.3410e-06, 3.4082e-09,\n",
      "        2.4142e-09, 2.3175e-09, 2.3631e-09, 3.7389e-06, 3.6239e-06, 3.7202e-06,\n",
      "        3.3836e-05, 3.2368e-05, 3.2407e-05, 3.4602e-06, 3.5584e-06, 2.0493e-05,\n",
      "        2.0583e-05, 2.9571e-01, 3.1165e-01, 1.2053e+00, 1.1892e+00, 3.4416e-06,\n",
      "        2.0494e-05, 2.9276e-01, 1.2083e+00, 2.6679e-01, 1.2347e+00, 3.3463e-01,\n",
      "        9.5162e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([222.3077, 259.4198, 278.8226, 263.1624,   7.5518,   7.5528,   7.5515,\n",
      "        406.9558, 406.9558, 406.9558,   7.5526,   7.5536, 406.9558, 406.9558,\n",
      "        406.9558, 406.9558, 406.9558,  67.3120,  67.3120,   7.5507, 406.9558,\n",
      "        406.9558, 406.9558, 406.9558, 406.9558,  67.3120,  67.3120, 406.9558,\n",
      "         67.3120,  67.3120,   5.2026, 406.9558, 406.9558, 406.9558, 406.9558,\n",
      "        406.9558,  67.3120,  67.3120, 406.9558,  67.3120,  67.3120,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 406.9558,   5.2026,   5.2025, 406.9558,   5.2026,\n",
      "          5.2025, 406.9558,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        406.9558, 406.9558, 406.9558, 406.9558,  67.3120,  67.3120,  67.3120,\n",
      "         67.3120, 406.9558, 406.9558, 406.9558,  67.3120,  67.3120,  67.3120,\n",
      "         67.3120,   5.2026,  67.3120,  67.3120,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 677 was 95.1%\n",
      "tensor([3.3087e-24, 2.7918e-06, 2.3736e-06, 2.1952e-06, 2.3376e-06, 3.3788e-09,\n",
      "        2.3931e-09, 2.2976e-09, 2.3428e-09, 3.7315e-06, 3.6143e-06, 3.7130e-06,\n",
      "        3.3448e-05, 3.1994e-05, 3.2045e-05, 3.4532e-06, 3.5499e-06, 2.0261e-05,\n",
      "        2.0336e-05, 2.9509e-01, 3.1103e-01, 1.2027e+00, 1.1867e+00, 3.4356e-06,\n",
      "        2.0264e-05, 2.9209e-01, 1.2058e+00, 2.6624e-01, 1.2320e+00, 3.3391e-01,\n",
      "        9.5173e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([222.5737, 259.7008, 279.1244, 263.4042,   7.5478,   7.5480,   7.5495,\n",
      "        407.3763, 407.3763, 407.3763,   7.5487,   7.5469, 407.3763, 407.3763,\n",
      "        407.3763, 407.3763, 407.3763,  67.3911,  67.3911,   7.5494, 407.3763,\n",
      "        407.3763, 407.3763, 407.3763, 407.3763,  67.3911,  67.3911, 407.3763,\n",
      "         67.3911,  67.3911,   5.2026, 407.3763, 407.3763, 407.3763, 407.3763,\n",
      "        407.3763,  67.3911,  67.3911, 407.3763,  67.3911,  67.3911,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 407.3763,   5.2026,   5.2025, 407.3763,   5.2026,\n",
      "          5.2025, 407.3763,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        407.3763, 407.3763, 407.3763, 407.3763,  67.3911,  67.3911,  67.3911,\n",
      "         67.3911, 407.3763, 407.3763, 407.3763,  67.3911,  67.3911,  67.3911,\n",
      "         67.3911,   5.2026,  67.3911,  67.3911,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 678 was 95.1%\n",
      "tensor([9.9262e-24, 2.7871e-06, 2.3697e-06, 2.1917e-06, 2.3344e-06, 3.3491e-09,\n",
      "        2.3716e-09, 2.2777e-09, 2.3224e-09, 3.7230e-06, 3.6075e-06, 3.7041e-06,\n",
      "        3.3045e-05, 3.1642e-05, 3.1672e-05, 3.4452e-06, 3.5442e-06, 2.0020e-05,\n",
      "        2.0106e-05, 2.9440e-01, 3.1035e-01, 1.2002e+00, 1.1842e+00, 3.4275e-06,\n",
      "        2.0025e-05, 2.9154e-01, 1.2031e+00, 2.6568e-01, 1.2294e+00, 3.3319e-01,\n",
      "        9.5183e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([222.8396, 259.9818, 279.4260, 263.6461,   7.5439,   7.5458,   7.5427,\n",
      "        407.7967, 407.7967, 407.7967,   7.5448,   7.5456, 407.7967, 407.7967,\n",
      "        407.7967, 407.7967, 407.7967,  67.4702,  67.4702,   7.5447, 407.7967,\n",
      "        407.7967, 407.7967, 407.7967, 407.7967,  67.4702,  67.4702, 407.7967,\n",
      "         67.4702,  67.4702,   5.2026, 407.7967, 407.7967, 407.7967, 407.7967,\n",
      "        407.7967,  67.4702,  67.4702, 407.7967,  67.4702,  67.4702,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 407.7967,   5.2026,   5.2025, 407.7967,   5.2026,\n",
      "          5.2025, 407.7967,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        407.7967, 407.7967, 407.7967, 407.7967,  67.4702,  67.4702,  67.4702,\n",
      "         67.4702, 407.7967, 407.7967, 407.7967,  67.4702,  67.4702,  67.4702,\n",
      "         67.4702,   5.2026,  67.4702,  67.4702,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 679 was 95.1%\n",
      "tensor([2.9779e-23, 2.7824e-06, 2.3661e-06, 2.1884e-06, 2.3311e-06, 3.3195e-09,\n",
      "        2.3506e-09, 2.2577e-09, 2.3023e-09, 3.7153e-06, 3.5986e-06, 3.6980e-06,\n",
      "        3.2656e-05, 3.1266e-05, 3.1317e-05, 3.4386e-06, 3.5351e-06, 1.9793e-05,\n",
      "        1.9865e-05, 2.9379e-01, 3.0969e-01, 1.1977e+00, 1.1817e+00, 3.4208e-06,\n",
      "        1.9795e-05, 2.9089e-01, 1.2006e+00, 2.6515e-01, 1.2267e+00, 3.3247e-01,\n",
      "        9.5193e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([223.1056, 260.2629, 279.7275, 263.8880,   7.5403,   7.5391,   7.5411,\n",
      "        408.2172, 408.2172, 408.2172,   7.5409,   7.5407, 408.2172, 408.2172,\n",
      "        408.2172, 408.2172, 408.2172,  67.5494,  67.5494,   7.5426, 408.2172,\n",
      "        408.2172, 408.2172, 408.2172, 408.2172,  67.5494,  67.5494, 408.2172,\n",
      "         67.5494,  67.5494,   5.2026, 408.2172, 408.2172, 408.2172, 408.2172,\n",
      "        408.2172,  67.5494,  67.5494, 408.2172,  67.5494,  67.5494,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 408.2172,   5.2026,   5.2025, 408.2172,   5.2026,\n",
      "          5.2025, 408.2172,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        408.2172, 408.2172, 408.2172, 408.2172,  67.5494,  67.5494,  67.5494,\n",
      "         67.5494, 408.2172, 408.2172, 408.2172,  67.5494,  67.5494,  67.5494,\n",
      "         67.5494,   5.2026,  67.5494,  67.5494,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 680 was 95.2%\n",
      "tensor([0.0000e+00, 2.7775e-06, 2.3622e-06, 2.1849e-06, 2.3279e-06, 3.2908e-09,\n",
      "        2.3299e-09, 2.2385e-09, 2.2826e-09, 3.7063e-06, 3.5923e-06, 3.6891e-06,\n",
      "        3.2262e-05, 3.0926e-05, 3.0958e-05, 3.4307e-06, 3.5290e-06, 1.9563e-05,\n",
      "        1.9645e-05, 2.9306e-01, 3.0904e-01, 1.1952e+00, 1.1791e+00, 3.4128e-06,\n",
      "        1.9561e-05, 2.9030e-01, 1.1980e+00, 2.6464e-01, 1.2241e+00, 3.3177e-01,\n",
      "        9.5203e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([223.3716, 260.5438, 280.0289, 264.1301,   7.5363,   7.5378,   7.5360,\n",
      "        408.6377, 408.6377, 408.6377,   7.5370,   7.5385, 408.6377, 408.6377,\n",
      "        408.6377, 408.6377, 408.6377,  67.6285,  67.6285,   7.5360, 408.6377,\n",
      "        408.6377, 408.6377, 408.6377, 408.6377,  67.6285,  67.6285, 408.6377,\n",
      "         67.6285,  67.6285,   5.2026, 408.6377, 408.6377, 408.6377, 408.6377,\n",
      "        408.6377,  67.6285,  67.6285, 408.6377,  67.6285,  67.6285,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 408.6377,   5.2026,   5.2025, 408.6377,   5.2026,\n",
      "          5.2025, 408.6377,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        408.6377, 408.6377, 408.6377, 408.6377,  67.6285,  67.6285,  67.6285,\n",
      "         67.6285, 408.6377, 408.6377, 408.6377,  67.6285,  67.6285,  67.6285,\n",
      "         67.6285,   5.2026,  67.6285,  67.6285,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 681 was 95.2%\n",
      "tensor([1.3235e-23, 2.7729e-06, 2.3587e-06, 2.1814e-06, 2.3245e-06, 3.2621e-09,\n",
      "        2.3093e-09, 2.2190e-09, 2.2629e-09, 3.6993e-06, 3.5825e-06, 3.6819e-06,\n",
      "        3.1892e-05, 3.0562e-05, 3.0609e-05, 3.4238e-06, 3.5203e-06, 1.9338e-05,\n",
      "        1.9405e-05, 2.9246e-01, 3.0842e-01, 1.1926e+00, 1.1766e+00, 3.4069e-06,\n",
      "        1.9342e-05, 2.8963e-01, 1.1955e+00, 2.6408e-01, 1.2215e+00, 3.3105e-01,\n",
      "        9.5214e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([223.6376, 260.8247, 280.3302, 264.3725,   7.5323,   7.5330,   7.5340,\n",
      "        409.0581, 409.0581, 409.0581,   7.5331,   7.5317, 409.0581, 409.0581,\n",
      "        409.0581, 409.0581, 409.0581,  67.7076,  67.7076,   7.5347, 409.0581,\n",
      "        409.0581, 409.0581, 409.0581, 409.0581,  67.7076,  67.7076, 409.0581,\n",
      "         67.7076,  67.7076,   5.2026, 409.0581, 409.0581, 409.0581, 409.0581,\n",
      "        409.0581,  67.7076,  67.7076, 409.0581,  67.7076,  67.7076,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 409.0581,   5.2026,   5.2025, 409.0581,   5.2026,\n",
      "          5.2025, 409.0581,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        409.0581, 409.0581, 409.0581, 409.0581,  67.7076,  67.7076,  67.7076,\n",
      "         67.7076, 409.0581, 409.0581, 409.0581,  67.7076,  67.7076,  67.7076,\n",
      "         67.7076,   5.2026,  67.7076,  67.7076,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 682 was 95.2%\n",
      "tensor([1.4983e-08, 2.7719e-06, 2.3580e-06, 2.1814e-06, 2.3246e-06, 4.9631e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6905e-06, 3.5759e-06, 3.6730e-06,\n",
      "        3.1501e-05, 3.0225e-05, 3.0251e-05, 3.4160e-06, 3.5148e-06, 1.9106e-05,\n",
      "        1.9184e-05, 2.9177e-01, 3.0774e-01, 1.1902e+00, 1.1741e+00, 3.3987e-06,\n",
      "        1.9109e-05, 2.8909e-01, 1.1929e+00, 2.6353e-01, 1.2188e+00, 3.3034e-01,\n",
      "        9.5224e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([223.9035, 261.1056, 280.6312, 264.6149,   7.5283,   7.5308,   7.5289,\n",
      "        409.4786, 409.4786, 409.4786,   7.5292,   7.5303, 409.4786, 409.4786,\n",
      "        409.4786, 409.4786, 409.4786,  67.7868,  67.7868,   7.5281, 409.4786,\n",
      "        409.4786, 409.4786, 409.4786, 409.4786,  67.7868,  67.7868, 409.4786,\n",
      "         67.7868,  67.7868,   5.2026, 409.4786, 409.4786, 409.4786, 409.4786,\n",
      "        409.4786,  67.7868,  67.7868, 409.4786,  67.7868,  67.7868,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 409.4786,   5.2026,   5.2025, 409.4786,   5.2026,\n",
      "          5.2025, 409.4786,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        409.4786, 409.4786, 409.4786, 409.4786,  67.7868,  67.7868,  67.7868,\n",
      "         67.7868, 409.4786, 409.4786, 409.4786,  67.7868,  67.7868,  67.7868,\n",
      "         67.7868,   5.2026,  67.7868,  67.7868,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 683 was 95.2%\n",
      "tensor([4.9631e-24, 2.7636e-06, 2.3512e-06, 2.1746e-06, 2.3180e-06, 3.2051e-09,\n",
      "        2.2685e-09, 2.1806e-09, 2.2238e-09, 3.6834e-06, 3.5669e-06, 3.6662e-06,\n",
      "        3.1141e-05, 2.9868e-05, 2.9912e-05, 3.4092e-06, 3.5057e-06, 1.8890e-05,\n",
      "        1.8955e-05, 2.9117e-01, 3.0712e-01, 1.1876e+00, 1.1715e+00, 3.3929e-06,\n",
      "        1.8895e-05, 2.8844e-01, 1.1904e+00, 2.6298e-01, 1.2162e+00, 3.2962e-01,\n",
      "        9.5234e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([224.1695, 261.3865, 280.9322, 264.8576,   7.5252,   7.5239,   7.5258,\n",
      "        409.8990, 409.8990, 409.8990,   7.5252,   7.5255, 409.8990, 409.8990,\n",
      "        409.8990, 409.8990, 409.8990,  67.8659,  67.8659,   7.5267, 409.8990,\n",
      "        409.8990, 409.8990, 409.8990, 409.8990,  67.8659,  67.8659, 409.8990,\n",
      "         67.8659,  67.8659,   5.2026, 409.8990, 409.8990, 409.8990, 409.8990,\n",
      "        409.8990,  67.8659,  67.8659, 409.8990,  67.8659,  67.8659,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 409.8990,   5.2026,   5.2025, 409.8990,   5.2026,\n",
      "          5.2025, 409.8990,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        409.8990, 409.8990, 409.8990, 409.8990,  67.8659,  67.8659,  67.8659,\n",
      "         67.8659, 409.8990, 409.8990, 409.8990,  67.8659,  67.8659,  67.8659,\n",
      "         67.8659,   5.2026,  67.8659,  67.8659,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 684 was 95.2%\n",
      "tensor([1.3235e-23, 2.7586e-06, 2.3473e-06, 2.1710e-06, 2.3148e-06, 3.1771e-09,\n",
      "        2.2484e-09, 2.1619e-09, 2.2046e-09, 3.6740e-06, 3.5605e-06, 3.6577e-06,\n",
      "        3.0760e-05, 2.9540e-05, 2.9565e-05, 3.4013e-06, 3.4995e-06, 1.8669e-05,\n",
      "        1.8742e-05, 2.9045e-01, 3.0647e-01, 1.1851e+00, 1.1690e+00, 3.3844e-06,\n",
      "        1.8669e-05, 2.8784e-01, 1.1878e+00, 2.6246e-01, 1.2136e+00, 3.2890e-01,\n",
      "        9.5244e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([224.4354, 261.6672, 281.2332, 265.1003,   7.5211,   7.5226,   7.5207,\n",
      "        410.3195, 410.3195, 410.3195,   7.5221,   7.5223, 410.3195, 410.3195,\n",
      "        410.3195, 410.3195, 410.3195,  67.9450,  67.9450,   7.5200, 410.3195,\n",
      "        410.3195, 410.3195, 410.3195, 410.3195,  67.9450,  67.9450, 410.3195,\n",
      "         67.9450,  67.9450,   5.2026, 410.3195, 410.3195, 410.3195, 410.3195,\n",
      "        410.3195,  67.9450,  67.9450, 410.3195,  67.9450,  67.9450,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 410.3195,   5.2026,   5.2025, 410.3195,   5.2026,\n",
      "          5.2025, 410.3195,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        410.3195, 410.3195, 410.3195, 410.3195,  67.9450,  67.9450,  67.9450,\n",
      "         67.9450, 410.3195, 410.3195, 410.3195,  67.9450,  67.9450,  67.9450,\n",
      "         67.9450,   5.2026,  67.9450,  67.9450,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 685 was 95.2%\n",
      "tensor([0.0000e+00, 2.7541e-06, 2.3438e-06, 2.1677e-06, 2.3114e-06, 3.1492e-09,\n",
      "        2.2284e-09, 2.1430e-09, 2.1854e-09, 3.6669e-06, 3.5514e-06, 3.6504e-06,\n",
      "        3.0403e-05, 2.9193e-05, 2.9227e-05, 3.3941e-06, 3.4914e-06, 1.8451e-05,\n",
      "        1.8516e-05, 2.8988e-01, 3.0582e-01, 1.1826e+00, 1.1665e+00, 3.3785e-06,\n",
      "        1.8456e-05, 2.8718e-01, 1.1853e+00, 2.6191e-01, 1.2110e+00, 3.2819e-01,\n",
      "        9.5255e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([224.7013, 261.9480, 281.5341, 265.3432,   7.5170,   7.5157,   7.5186,\n",
      "        410.7399, 410.7399, 410.7399,   7.5181,   7.5174, 410.7399, 410.7399,\n",
      "        410.7399, 410.7399, 410.7399,  68.0242,  68.0242,   7.5187, 410.7399,\n",
      "        410.7399, 410.7399, 410.7399, 410.7399,  68.0242,  68.0242, 410.7399,\n",
      "         68.0242,  68.0242,   5.2026, 410.7399, 410.7399, 410.7399, 410.7399,\n",
      "        410.7399,  68.0242,  68.0242, 410.7399,  68.0242,  68.0242,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 410.7399,   5.2026,   5.2025, 410.7399,   5.2026,\n",
      "          5.2025, 410.7399,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        410.7399, 410.7399, 410.7399, 410.7399,  68.0242,  68.0242,  68.0242,\n",
      "         68.0242, 410.7399, 410.7399, 410.7399,  68.0242,  68.0242,  68.0242,\n",
      "         68.0242,   5.2026,  68.0242,  68.0242,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 686 was 95.2%\n",
      "tensor([1.4418e-08, 2.7530e-06, 2.3431e-06, 2.1675e-06, 2.3114e-06, 1.6544e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6586e-06, 3.5452e-06, 3.6418e-06,\n",
      "        3.0037e-05, 2.8871e-05, 2.8888e-05, 3.3862e-06, 3.4852e-06, 1.8235e-05,\n",
      "        1.8308e-05, 2.8916e-01, 3.0519e-01, 1.1801e+00, 1.1640e+00, 3.3705e-06,\n",
      "        1.8241e-05, 2.8661e-01, 1.1827e+00, 2.6139e-01, 1.2083e+00, 3.2748e-01,\n",
      "        9.5265e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([224.9673, 262.2288, 281.8347, 265.5862,   7.5128,   7.5145,   7.5135,\n",
      "        411.1604, 411.1604, 411.1604,   7.5141,   7.5151, 411.1604, 411.1604,\n",
      "        411.1604, 411.1604, 411.1604,  68.1033,  68.1033,   7.5120, 411.1604,\n",
      "        411.1604, 411.1604, 411.1604, 411.1604,  68.1033,  68.1033, 411.1604,\n",
      "         68.1033,  68.1033,   5.2026, 411.1604, 411.1604, 411.1604, 411.1604,\n",
      "        411.1604,  68.1033,  68.1033, 411.1604,  68.1033,  68.1033,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 411.1604,   5.2026,   5.2025, 411.1604,   5.2026,\n",
      "          5.2025, 411.1604,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        411.1604, 411.1604, 411.1604, 411.1604,  68.1033,  68.1033,  68.1033,\n",
      "         68.1033, 411.1604, 411.1604, 411.1604,  68.1033,  68.1033,  68.1033,\n",
      "         68.1033,   5.2026,  68.1033,  68.1033,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 687 was 95.2%\n",
      "tensor([0.0000e+00, 2.7447e-06, 2.3364e-06, 2.1608e-06, 2.3049e-06, 3.0946e-09,\n",
      "        2.1892e-09, 2.1062e-09, 2.1480e-09, 3.6512e-06, 3.5359e-06, 3.6348e-06,\n",
      "        2.9688e-05, 2.8533e-05, 2.8563e-05, 3.3796e-06, 3.4768e-06, 1.8026e-05,\n",
      "        1.8087e-05, 2.8856e-01, 3.0456e-01, 1.1776e+00, 1.1615e+00, 3.3645e-06,\n",
      "        1.8032e-05, 2.8596e-01, 1.1802e+00, 2.6085e-01, 1.2057e+00, 3.2677e-01,\n",
      "        9.5275e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([225.2332, 262.5095, 282.1352, 265.8294,   7.5097,   7.5095,   7.5104,\n",
      "        411.5808, 411.5808, 411.5808,   7.5101,   7.5082, 411.5808, 411.5808,\n",
      "        411.5808, 411.5808, 411.5808,  68.1824,  68.1824,   7.5106, 411.5808,\n",
      "        411.5808, 411.5808, 411.5808, 411.5808,  68.1824,  68.1824, 411.5808,\n",
      "         68.1824,  68.1824,   5.2026, 411.5808, 411.5808, 411.5808, 411.5808,\n",
      "        411.5808,  68.1824,  68.1824, 411.5808,  68.1824,  68.1824,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 411.5808,   5.2026,   5.2025, 411.5808,   5.2026,\n",
      "          5.2025, 411.5808,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        411.5808, 411.5808, 411.5808, 411.5808,  68.1824,  68.1824,  68.1824,\n",
      "         68.1824, 411.5808, 411.5808, 411.5808,  68.1824,  68.1824,  68.1824,\n",
      "         68.1824,   5.2026,  68.1824,  68.1824,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 688 was 95.2%\n",
      "tensor([0.0000e+00, 2.7399e-06, 2.3325e-06, 2.1574e-06, 2.3016e-06, 3.0668e-09,\n",
      "        2.1692e-09, 2.0875e-09, 2.1288e-09, 3.6422e-06, 3.5289e-06, 3.6263e-06,\n",
      "        2.9320e-05, 2.8209e-05, 2.8225e-05, 3.3718e-06, 3.4709e-06, 1.7808e-05,\n",
      "        1.7876e-05, 2.8789e-01, 3.0388e-01, 1.1751e+00, 1.1590e+00, 3.3562e-06,\n",
      "        1.7813e-05, 2.8539e-01, 1.1776e+00, 2.6030e-01, 1.2031e+00, 3.2605e-01,\n",
      "        9.5285e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([225.4991, 262.7901, 282.4358, 266.0726,   7.5046,   7.5082,   7.5052,\n",
      "        412.0013, 412.0013, 412.0013,   7.5061,   7.5068, 412.0013, 412.0013,\n",
      "        412.0013, 412.0013, 412.0013,  68.2616,  68.2616,   7.5039, 412.0013,\n",
      "        412.0013, 412.0013, 412.0013, 412.0013,  68.2616,  68.2616, 412.0013,\n",
      "         68.2616,  68.2616,   5.2026, 412.0013, 412.0013, 412.0013, 412.0013,\n",
      "        412.0013,  68.2616,  68.2616, 412.0013,  68.2616,  68.2616,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 412.0013,   5.2026,   5.2025, 412.0013,   5.2026,\n",
      "          5.2025, 412.0013,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        412.0013, 412.0013, 412.0013, 412.0013,  68.2616,  68.2616,  68.2616,\n",
      "         68.2616, 412.0013, 412.0013, 412.0013,  68.2616,  68.2616,  68.2616,\n",
      "         68.2616,   5.2026,  68.2616,  68.2616,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 689 was 95.2%\n",
      "tensor([0.0000e+00, 2.7355e-06, 2.3290e-06, 2.1542e-06, 2.2984e-06, 3.0401e-09,\n",
      "        2.1502e-09, 2.0693e-09, 2.1106e-09, 3.6357e-06, 3.5200e-06, 3.6198e-06,\n",
      "        2.8986e-05, 2.7874e-05, 2.7911e-05, 3.3654e-06, 3.4619e-06, 1.7606e-05,\n",
      "        1.7661e-05, 2.8731e-01, 3.0323e-01, 1.1726e+00, 1.1565e+00, 3.3509e-06,\n",
      "        1.7612e-05, 2.8478e-01, 1.1751e+00, 2.5975e-01, 1.2006e+00, 3.2538e-01,\n",
      "        9.5295e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([225.7651, 263.0708, 282.7360, 266.3161,   7.5014,   7.5012,   7.5021,\n",
      "        412.4217, 412.4217, 412.4217,   7.5020,   7.5018, 412.4217, 412.4217,\n",
      "        412.4217, 412.4217, 412.4217,  68.3407,  68.3407,   7.5025, 412.4217,\n",
      "        412.4217, 412.4217, 412.4217, 412.4217,  68.3407,  68.3407, 412.4217,\n",
      "         68.3407,  68.3407,   5.2026, 412.4217, 412.4217, 412.4217, 412.4217,\n",
      "        412.4217,  68.3407,  68.3407, 412.4217,  68.3407,  68.3407,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 412.4217,   5.2026,   5.2025, 412.4217,   5.2026,\n",
      "          5.2025, 412.4217,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        412.4217, 412.4217, 412.4217, 412.4217,  68.3407,  68.3407,  68.3407,\n",
      "         68.3407, 412.4217, 412.4217, 412.4217,  68.3407,  68.3407,  68.3407,\n",
      "         68.3407,   5.2026,  68.3407,  68.3407,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 690 was 95.3%\n",
      "tensor([1.3868e-08, 2.7340e-06, 2.3281e-06, 2.1536e-06, 2.2980e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6262e-06, 3.5133e-06, 3.6108e-06,\n",
      "        2.8619e-05, 2.7558e-05, 2.7574e-05, 3.3570e-06, 3.4555e-06, 1.7392e-05,\n",
      "        1.7456e-05, 2.8658e-01, 3.0259e-01, 1.1701e+00, 1.1539e+00, 3.3420e-06,\n",
      "        1.7396e-05, 2.8415e-01, 1.1725e+00, 2.5923e-01, 1.1979e+00, 3.2462e-01,\n",
      "        9.5306e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([226.0310, 263.3514, 283.0362, 266.5596,   7.4972,   7.4999,   7.4968,\n",
      "        412.8421, 412.8421, 412.8421,   7.4980,   7.4995, 412.8421, 412.8421,\n",
      "        412.8421, 412.8421, 412.8421,  68.4198,  68.4198,   7.4957, 412.8421,\n",
      "        412.8421, 412.8421, 412.8421, 412.8421,  68.4198,  68.4198, 412.8421,\n",
      "         68.4198,  68.4198,   5.2026, 412.8421, 412.8421, 412.8421, 412.8421,\n",
      "        412.8421,  68.4198,  68.4198, 412.8421,  68.4198,  68.4198,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 412.8421,   5.2026,   5.2025, 412.8421,   5.2026,\n",
      "          5.2025, 412.8421,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        412.8421, 412.8421, 412.8421, 412.8421,  68.4198,  68.4198,  68.4198,\n",
      "         68.4198, 412.8421, 412.8421, 412.8421,  68.4198,  68.4198,  68.4198,\n",
      "         68.4198,   5.2026,  68.4198,  68.4198,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 691 was 95.3%\n",
      "tensor([8.2718e-24, 2.7262e-06, 2.3217e-06, 2.1473e-06, 2.2919e-06, 2.9871e-09,\n",
      "        2.1122e-09, 2.0337e-09, 2.0742e-09, 3.6197e-06, 3.5043e-06, 3.6045e-06,\n",
      "        2.8299e-05, 2.7239e-05, 2.7273e-05, 3.3510e-06, 3.4473e-06, 1.7197e-05,\n",
      "        1.7248e-05, 2.8601e-01, 3.0197e-01, 1.1676e+00, 1.1515e+00, 3.3368e-06,\n",
      "        1.7204e-05, 2.8354e-01, 1.1701e+00, 2.5870e-01, 1.1954e+00, 3.2395e-01,\n",
      "        9.5315e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([226.2970, 263.6320, 283.3363, 266.8033,   7.4929,   7.4928,   7.4947,\n",
      "        413.2626, 413.2626, 413.2626,   7.4939,   7.4945, 413.2626, 413.2626,\n",
      "        413.2626, 413.2626, 413.2626,  68.4990,  68.4990,   7.4943, 413.2626,\n",
      "        413.2626, 413.2626, 413.2626, 413.2626,  68.4990,  68.4990, 413.2626,\n",
      "         68.4990,  68.4990,   5.2026, 413.2626, 413.2626, 413.2626, 413.2626,\n",
      "        413.2626,  68.4990,  68.4990, 413.2626,  68.4990,  68.4990,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 413.2626,   5.2026,   5.2025, 413.2626,   5.2026,\n",
      "          5.2025, 413.2626,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        413.2626, 413.2626, 413.2626, 413.2626,  68.4990,  68.4990,  68.4990,\n",
      "         68.4990, 413.2626, 413.2626, 413.2626,  68.4990,  68.4990,  68.4990,\n",
      "         68.4990,   5.2026,  68.4990,  68.4990,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 692 was 95.3%\n",
      "tensor([2.6470e-23, 2.7212e-06, 2.3178e-06, 2.1437e-06, 2.2886e-06, 2.9597e-09,\n",
      "        2.0926e-09, 2.0154e-09, 2.0553e-09, 3.6107e-06, 3.4978e-06, 3.5954e-06,\n",
      "        2.7940e-05, 2.6927e-05, 2.6936e-05, 3.3423e-06, 3.4410e-06, 1.6985e-05,\n",
      "        1.7046e-05, 2.8527e-01, 3.0134e-01, 1.1651e+00, 1.1489e+00, 3.3282e-06,\n",
      "        1.6991e-05, 2.8294e-01, 1.1675e+00, 2.5816e-01, 1.1927e+00, 3.2322e-01,\n",
      "        9.5326e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([226.5629, 263.9126, 283.6362, 267.0471,   7.4887,   7.4915,   7.4875,\n",
      "        413.6830, 413.6830, 413.6830,   7.4908,   7.4894, 413.6830, 413.6830,\n",
      "        413.6830, 413.6830, 413.6830,  68.5781,  68.5781,   7.4912, 413.6830,\n",
      "        413.6830, 413.6830, 413.6830, 413.6830,  68.5781,  68.5781, 413.6830,\n",
      "         68.5781,  68.5781,   5.2026, 413.6830, 413.6830, 413.6830, 413.6830,\n",
      "        413.6830,  68.5781,  68.5781, 413.6830,  68.5781,  68.5781,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 413.6830,   5.2026,   5.2025, 413.6830,   5.2026,\n",
      "          5.2025, 413.6830,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        413.6830, 413.6830, 413.6830, 413.6830,  68.5781,  68.5781,  68.5781,\n",
      "         68.5781, 413.6830, 413.6830, 413.6830,  68.5781,  68.5781,  68.5781,\n",
      "         68.5781,   5.2026,  68.5781,  68.5781,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 693 was 95.3%\n",
      "tensor([3.3087e-24, 2.7166e-06, 2.3141e-06, 2.1407e-06, 2.2852e-06, 2.9328e-09,\n",
      "        2.0732e-09, 1.9968e-09, 2.0368e-09, 3.6028e-06, 3.4899e-06, 3.5888e-06,\n",
      "        2.7599e-05, 2.6601e-05, 2.6625e-05, 3.3362e-06, 3.4334e-06, 1.6779e-05,\n",
      "        1.6838e-05, 2.8472e-01, 3.0059e-01, 1.1626e+00, 1.1466e+00, 3.3214e-06,\n",
      "        1.6783e-05, 2.8237e-01, 1.1650e+00, 2.5766e-01, 1.1901e+00, 3.2254e-01,\n",
      "        9.5336e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([226.8289, 264.1933, 283.9360, 267.2909,   7.4848,   7.4844,   7.4858,\n",
      "        414.1034, 414.1034, 414.1034,   7.4876,   7.4861, 414.1034, 414.1034,\n",
      "        414.1034, 414.1034, 414.1034,  68.6572,  68.6572,   7.4863, 414.1034,\n",
      "        414.1034, 414.1034, 414.1034, 414.1034,  68.6572,  68.6572, 414.1034,\n",
      "         68.6572,  68.6572,   5.2026, 414.1034, 414.1034, 414.1034, 414.1034,\n",
      "        414.1034,  68.6572,  68.6572, 414.1034,  68.6572,  68.6572,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 414.1034,   5.2026,   5.2025, 414.1034,   5.2026,\n",
      "          5.2025, 414.1034,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        414.1034, 414.1034, 414.1034, 414.1034,  68.6572,  68.6572,  68.6572,\n",
      "         68.6572, 414.1034, 414.1034, 414.1034,  68.6572,  68.6572,  68.6572,\n",
      "         68.6572,   5.2026,  68.6572,  68.6572,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 694 was 95.3%\n",
      "tensor([1.3338e-08, 2.7153e-06, 2.3134e-06, 2.1401e-06, 2.2849e-06, 4.5495e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5952e-06, 3.4830e-06, 3.5798e-06,\n",
      "        2.7271e-05, 2.6306e-05, 2.6309e-05, 3.3276e-06, 3.4267e-06, 1.6581e-05,\n",
      "        1.6645e-05, 2.8404e-01, 3.0002e-01, 1.1601e+00, 1.1440e+00, 3.3142e-06,\n",
      "        1.6592e-05, 2.8169e-01, 1.1625e+00, 2.5714e-01, 1.1875e+00, 3.2183e-01,\n",
      "        9.5346e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([227.0949, 264.4738, 284.2356, 267.5350,   7.4805,   7.4831,   7.4825,\n",
      "        414.5239, 414.5239, 414.5239,   7.4806,   7.4829, 414.5239, 414.5239,\n",
      "        414.5239, 414.5239, 414.5239,  68.7363,  68.7363,   7.4812, 414.5239,\n",
      "        414.5239, 414.5239, 414.5239, 414.5239,  68.7363,  68.7363, 414.5239,\n",
      "         68.7363,  68.7363,   5.2026, 414.5239, 414.5239, 414.5239, 414.5239,\n",
      "        414.5239,  68.7363,  68.7363, 414.5239,  68.7363,  68.7363,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 414.5239,   5.2026,   5.2025, 414.5239,   5.2026,\n",
      "          5.2025, 414.5239,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        414.5239, 414.5239, 414.5239, 414.5239,  68.7363,  68.7363,  68.7363,\n",
      "         68.7363, 414.5239, 414.5239, 414.5239,  68.7363,  68.7363,  68.7363,\n",
      "         68.7363,   5.2026,  68.7363,  68.7363,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 695 was 95.3%\n",
      "tensor([0.0000e+00, 2.7075e-06, 2.3068e-06, 2.1336e-06, 2.2789e-06, 2.8820e-09,\n",
      "        2.0367e-09, 1.9627e-09, 2.0018e-09, 3.5876e-06, 3.4736e-06, 3.5728e-06,\n",
      "        2.6947e-05, 2.5997e-05, 2.6016e-05, 3.3218e-06, 3.4187e-06, 1.6391e-05,\n",
      "        1.6441e-05, 2.8338e-01, 2.9942e-01, 1.1577e+00, 1.1415e+00, 3.3078e-06,\n",
      "        1.6398e-05, 2.8114e-01, 1.1599e+00, 2.5654e-01, 1.1849e+00, 3.2112e-01,\n",
      "        9.5356e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([227.3608, 264.7543, 284.5351, 267.7793,   7.4772,   7.4759,   7.4783,\n",
      "        414.9443, 414.9443, 414.9443,   7.4783,   7.4778, 414.9443, 414.9443,\n",
      "        414.9443, 414.9443, 414.9443,  68.8155,  68.8155,   7.4790, 414.9443,\n",
      "        414.9443, 414.9443, 414.9443, 414.9443,  68.8155,  68.8155, 414.9443,\n",
      "         68.8155,  68.8155,   5.2026, 414.9443, 414.9443, 414.9443, 414.9443,\n",
      "        414.9443,  68.8155,  68.8155, 414.9443,  68.8155,  68.8155,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 414.9443,   5.2026,   5.2025, 414.9443,   5.2026,\n",
      "          5.2025, 414.9443,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        414.9443, 414.9443, 414.9443, 414.9443,  68.8155,  68.8155,  68.8155,\n",
      "         68.8155, 414.9443, 414.9443, 414.9443,  68.8155,  68.8155,  68.8155,\n",
      "         68.8155,   5.2026,  68.8155,  68.8155,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 696 was 95.3%\n",
      "tensor([8.2718e-24, 2.7026e-06, 2.3031e-06, 2.1302e-06, 2.2756e-06, 2.8560e-09,\n",
      "        2.0182e-09, 1.9453e-09, 1.9839e-09, 3.5787e-06, 3.4677e-06, 3.5646e-06,\n",
      "        2.6612e-05, 2.5698e-05, 2.5703e-05, 3.3136e-06, 3.4124e-06, 1.6193e-05,\n",
      "        1.6250e-05, 2.8272e-01, 2.9875e-01, 1.1552e+00, 1.1390e+00, 3.2998e-06,\n",
      "        1.6197e-05, 2.8052e-01, 1.1574e+00, 2.5606e-01, 1.1823e+00, 3.2041e-01,\n",
      "        9.5366e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([227.6268, 265.0347, 284.8346, 268.0236,   7.4729,   7.4746,   7.4740,\n",
      "        415.3647, 415.3647, 415.3647,   7.4732,   7.4754, 415.3647, 415.3647,\n",
      "        415.3647, 415.3647, 415.3647,  68.8946,  68.8946,   7.4721, 415.3647,\n",
      "        415.3647, 415.3647, 415.3647, 415.3647,  68.8946,  68.8946, 415.3647,\n",
      "         68.8946,  68.8946,   5.2026, 415.3647, 415.3647, 415.3647, 415.3647,\n",
      "        415.3647,  68.8946,  68.8946, 415.3647,  68.8946,  68.8946,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 415.3647,   5.2026,   5.2025, 415.3647,   5.2026,\n",
      "          5.2025, 415.3647,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        415.3647, 415.3647, 415.3647, 415.3647,  68.8946,  68.8946,  68.8946,\n",
      "         68.8946, 415.3647, 415.3647, 415.3647,  68.8946,  68.8946,  68.8946,\n",
      "         68.8946,   5.2026,  68.8946,  68.8946,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 697 was 95.3%\n",
      "tensor([0.0000e+00, 2.6982e-06, 2.2996e-06, 2.1268e-06, 2.2723e-06, 2.8311e-09,\n",
      "        2.0003e-09, 1.9284e-09, 1.9668e-09, 3.5718e-06, 3.4582e-06, 3.5575e-06,\n",
      "        2.6303e-05, 2.5394e-05, 2.5412e-05, 3.3072e-06, 3.4041e-06, 1.6005e-05,\n",
      "        1.6051e-05, 2.8210e-01, 2.9816e-01, 1.1527e+00, 1.1366e+00, 3.2941e-06,\n",
      "        1.6012e-05, 2.7990e-01, 1.1550e+00, 2.5550e-01, 1.1798e+00, 3.1972e-01,\n",
      "        9.5376e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([227.8927, 265.3151, 285.1339, 268.2681,   7.4696,   7.4695,   7.4698,\n",
      "        415.7852, 415.7852, 415.7852,   7.4700,   7.4682, 415.7852, 415.7852,\n",
      "        415.7852, 415.7852, 415.7852,  68.9737,  68.9737,   7.4707, 415.7852,\n",
      "        415.7852, 415.7852, 415.7852, 415.7852,  68.9737,  68.9737, 415.7852,\n",
      "         68.9737,  68.9737,   5.2026, 415.7852, 415.7852, 415.7852, 415.7852,\n",
      "        415.7852,  68.9737,  68.9737, 415.7852,  68.9737,  68.9737,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 415.7852,   5.2026,   5.2025, 415.7852,   5.2026,\n",
      "          5.2025, 415.7852,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        415.7852, 415.7852, 415.7852, 415.7852,  68.9737,  68.9737,  68.9737,\n",
      "         68.9737, 415.7852, 415.7852, 415.7852,  68.9737,  68.9737,  68.9737,\n",
      "         68.9737,   5.2026,  68.9737,  68.9737,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 698 was 95.3%\n",
      "tensor([1.2825e-08, 2.6966e-06, 2.2985e-06, 2.1264e-06, 2.2717e-06, 4.5495e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5626e-06, 3.4516e-06, 3.5492e-06,\n",
      "        2.5966e-05, 2.5098e-05, 2.5101e-05, 3.2993e-06, 3.3982e-06, 1.5805e-05,\n",
      "        1.5859e-05, 2.8147e-01, 2.9745e-01, 1.1502e+00, 1.1341e+00, 3.2857e-06,\n",
      "        1.5809e-05, 2.7932e-01, 1.1524e+00, 2.5497e-01, 1.1772e+00, 3.1900e-01,\n",
      "        9.5386e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([228.1586, 265.5953, 285.4333, 268.5126,   7.4642,   7.4682,   7.4654,\n",
      "        416.2056, 416.2056, 416.2056,   7.4648,   7.4668, 416.2056, 416.2056,\n",
      "        416.2056, 416.2056, 416.2056,  69.0529,  69.0529,   7.4637, 416.2056,\n",
      "        416.2056, 416.2056, 416.2056, 416.2056,  69.0529,  69.0529, 416.2056,\n",
      "         69.0529,  69.0529,   5.2026, 416.2056, 416.2056, 416.2056, 416.2056,\n",
      "        416.2056,  69.0529,  69.0529, 416.2056,  69.0529,  69.0529,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 416.2056,   5.2026,   5.2025, 416.2056,   5.2026,\n",
      "          5.2025, 416.2056,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        416.2056, 416.2056, 416.2056, 416.2056,  69.0529,  69.0529,  69.0529,\n",
      "         69.0529, 416.2056, 416.2056, 416.2056,  69.0529,  69.0529,  69.0529,\n",
      "         69.0529,   5.2026,  69.0529,  69.0529,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 699 was 95.3%\n",
      "tensor([0.0000e+00, 2.6892e-06, 2.2922e-06, 2.1203e-06, 2.2658e-06, 2.7806e-09,\n",
      "        1.9641e-09, 1.8940e-09, 1.9320e-09, 3.5566e-06, 3.4426e-06, 3.5427e-06,\n",
      "        2.5670e-05, 2.4797e-05, 2.4820e-05, 3.2933e-06, 3.3894e-06, 1.5625e-05,\n",
      "        1.5665e-05, 2.8088e-01, 2.9685e-01, 1.1478e+00, 1.1317e+00, 3.2807e-06,\n",
      "        1.5632e-05, 2.7874e-01, 1.1500e+00, 2.5441e-01, 1.1747e+00, 3.1834e-01,\n",
      "        9.5396e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([228.4246, 265.8757, 285.7323, 268.7574,   7.4609,   7.4609,   7.4612,\n",
      "        416.6260, 416.6260, 416.6260,   7.4616,   7.4616, 416.6260, 416.6260,\n",
      "        416.6260, 416.6260, 416.6260,  69.1320,  69.1320,   7.4623, 416.6260,\n",
      "        416.6260, 416.6260, 416.6260, 416.6260,  69.1320,  69.1320, 416.6260,\n",
      "         69.1320,  69.1320,   5.2026, 416.6260, 416.6260, 416.6260, 416.6260,\n",
      "        416.6260,  69.1320,  69.1320, 416.6260,  69.1320,  69.1320,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 416.6260,   5.2026,   5.2025, 416.6260,   5.2026,\n",
      "          5.2025, 416.6260,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        416.6260, 416.6260, 416.6260, 416.6260,  69.1320,  69.1320,  69.1320,\n",
      "         69.1320, 416.6260, 416.6260, 416.6260,  69.1320,  69.1320,  69.1320,\n",
      "         69.1320,   5.2026,  69.1320,  69.1320,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 700 was 95.4%\n",
      "tensor([0.0000e+00, 2.6840e-06, 2.2884e-06, 2.1167e-06, 2.2624e-06, 2.7544e-09,\n",
      "        1.9454e-09, 1.8766e-09, 1.9140e-09, 3.5470e-06, 3.4361e-06, 3.5340e-06,\n",
      "        2.5332e-05, 2.4505e-05, 2.4508e-05, 3.2847e-06, 3.3830e-06, 1.5427e-05,\n",
      "        1.5477e-05, 2.8018e-01, 2.9619e-01, 1.1452e+00, 1.1291e+00, 3.2716e-06,\n",
      "        1.5431e-05, 2.7809e-01, 1.1474e+00, 2.5392e-01, 1.1720e+00, 3.1759e-01,\n",
      "        9.5406e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([228.6905, 266.1559, 286.0314, 269.0022,   7.4574,   7.4586,   7.4578,\n",
      "        417.0464, 417.0464, 417.0464,   7.4564,   7.4583, 417.0464, 417.0464,\n",
      "        417.0464, 417.0464, 417.0464,  69.2111,  69.2111,   7.4552, 417.0464,\n",
      "        417.0464, 417.0464, 417.0464, 417.0464,  69.2111,  69.2111, 417.0464,\n",
      "         69.2111,  69.2111,   5.2026, 417.0464, 417.0464, 417.0464, 417.0464,\n",
      "        417.0464,  69.2111,  69.2111, 417.0464,  69.2111,  69.2111,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 417.0464,   5.2026,   5.2025, 417.0464,   5.2026,\n",
      "          5.2025, 417.0464,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        417.0464, 417.0464, 417.0464, 417.0464,  69.2111,  69.2111,  69.2111,\n",
      "         69.2111, 417.0464, 417.0464, 417.0464,  69.2111,  69.2111,  69.2111,\n",
      "         69.2111,   5.2026,  69.2111,  69.2111,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 701 was 95.4%\n",
      "tensor([3.3087e-24, 2.6798e-06, 2.2849e-06, 2.1133e-06, 2.2591e-06, 2.7312e-09,\n",
      "        1.9287e-09, 1.8607e-09, 1.8979e-09, 3.5398e-06, 3.4278e-06, 3.5266e-06,\n",
      "        2.5044e-05, 2.4224e-05, 2.4235e-05, 3.2785e-06, 3.3753e-06, 1.5251e-05,\n",
      "        1.5295e-05, 2.7959e-01, 2.9560e-01, 1.1428e+00, 1.1267e+00, 3.2661e-06,\n",
      "        1.5257e-05, 2.7750e-01, 1.1449e+00, 2.5334e-01, 1.1695e+00, 3.1691e-01,\n",
      "        9.5416e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([228.9564, 266.4360, 286.3304, 269.2471,   7.4531,   7.4513,   7.4535,\n",
      "        417.4668, 417.4668, 417.4668,   7.4541,   7.4531, 417.4668, 417.4668,\n",
      "        417.4668, 417.4668, 417.4668,  69.2903,  69.2903,   7.4538, 417.4668,\n",
      "        417.4668, 417.4668, 417.4668, 417.4668,  69.2903,  69.2903, 417.4668,\n",
      "         69.2903,  69.2903,   5.2026, 417.4668, 417.4668, 417.4668, 417.4668,\n",
      "        417.4668,  69.2903,  69.2903, 417.4668,  69.2903,  69.2903,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 417.4668,   5.2026,   5.2025, 417.4668,   5.2026,\n",
      "          5.2025, 417.4668,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        417.4668, 417.4668, 417.4668, 417.4668,  69.2903,  69.2903,  69.2903,\n",
      "         69.2903, 417.4668, 417.4668, 417.4668,  69.2903,  69.2903,  69.2903,\n",
      "         69.2903,   5.2026,  69.2903,  69.2903,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 702 was 95.4%\n",
      "tensor([1.2331e-08, 2.6781e-06, 2.2839e-06, 2.1128e-06, 2.2585e-06, 5.7903e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5314e-06, 3.4216e-06, 3.5183e-06,\n",
      "        2.4725e-05, 2.3938e-05, 2.3935e-05, 3.2703e-06, 3.3690e-06, 1.5059e-05,\n",
      "        1.5110e-05, 2.7893e-01, 2.9493e-01, 1.1403e+00, 1.1242e+00, 3.2580e-06,\n",
      "        1.5067e-05, 2.7688e-01, 1.1424e+00, 2.5287e-01, 1.1669e+00, 3.1620e-01,\n",
      "        9.5426e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([229.2222, 266.7161, 286.6293, 269.4921,   7.4477,   7.4499,   7.4491,\n",
      "        417.8873, 417.8873, 417.8873,   7.4469,   7.4516, 417.8873, 417.8873,\n",
      "        417.8873, 417.8873, 417.8873,  69.3694,  69.3694,   7.4486, 417.8873,\n",
      "        417.8873, 417.8873, 417.8873, 417.8873,  69.3694,  69.3694, 417.8873,\n",
      "         69.3694,  69.3694,   5.2026, 417.8873, 417.8873, 417.8873, 417.8873,\n",
      "        417.8873,  69.3694,  69.3694, 417.8873,  69.3694,  69.3694,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 417.8873,   5.2026,   5.2025, 417.8873,   5.2026,\n",
      "          5.2025, 417.8873,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        417.8873, 417.8873, 417.8873, 417.8873,  69.3694,  69.3694,  69.3694,\n",
      "         69.3694, 417.8873, 417.8873, 417.8873,  69.3694,  69.3694,  69.3694,\n",
      "         69.3694,   5.2026,  69.3694,  69.3694,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 703 was 95.4%\n",
      "tensor([0.0000e+00, 2.6705e-06, 2.2777e-06, 2.1066e-06, 2.2529e-06, 2.6822e-09,\n",
      "        1.8935e-09, 1.8276e-09, 1.8641e-09, 3.5249e-06, 3.4119e-06, 3.5120e-06,\n",
      "        2.4435e-05, 2.3652e-05, 2.3667e-05, 3.2649e-06, 3.3608e-06, 1.4887e-05,\n",
      "        1.4921e-05, 2.7826e-01, 2.9436e-01, 1.1380e+00, 1.1218e+00, 3.2520e-06,\n",
      "        1.4893e-05, 2.7629e-01, 1.1400e+00, 2.5235e-01, 1.1643e+00, 3.1554e-01,\n",
      "        9.5436e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([229.4882, 266.9963, 286.9279, 269.7373,   7.4433,   7.4447,   7.4448,\n",
      "        418.3077, 418.3077, 418.3077,   7.4455,   7.4443, 418.3077, 418.3077,\n",
      "        418.3077, 418.3077, 418.3077,  69.4485,  69.4485,   7.4464, 418.3077,\n",
      "        418.3077, 418.3077, 418.3077, 418.3077,  69.4485,  69.4485, 418.3077,\n",
      "         69.4485,  69.4485,   5.2026, 418.3077, 418.3077, 418.3077, 418.3077,\n",
      "        418.3077,  69.4485,  69.4485, 418.3077,  69.4485,  69.4485,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 418.3077,   5.2026,   5.2025, 418.3077,   5.2026,\n",
      "          5.2025, 418.3077,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        418.3077, 418.3077, 418.3077, 418.3077,  69.4485,  69.4485,  69.4485,\n",
      "         69.4485, 418.3077, 418.3077, 418.3077,  69.4485,  69.4485,  69.4485,\n",
      "         69.4485,   5.2026,  69.4485,  69.4485,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 704 was 95.4%\n",
      "tensor([6.6174e-24, 2.6657e-06, 2.2738e-06, 2.1034e-06, 2.2494e-06, 2.6561e-09,\n",
      "        1.8747e-09, 1.8098e-09, 1.8460e-09, 3.5159e-06, 3.4059e-06, 3.5033e-06,\n",
      "        2.4108e-05, 2.3362e-05, 2.3361e-05, 3.2563e-06, 3.3547e-06, 1.4689e-05,\n",
      "        1.4737e-05, 2.7765e-01, 2.9361e-01, 1.1354e+00, 1.1193e+00, 3.2438e-06,\n",
      "        1.4694e-05, 2.7572e-01, 1.1374e+00, 2.5182e-01, 1.1617e+00, 3.1482e-01,\n",
      "        9.5446e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([229.7541, 267.2765, 287.2263, 269.9827,   7.4398,   7.4423,   7.4404,\n",
      "        418.7281, 418.7281, 418.7281,   7.4402,   7.4418, 418.7281, 418.7281,\n",
      "        418.7281, 418.7281, 418.7281,  69.5277,  69.5277,   7.4392, 418.7281,\n",
      "        418.7281, 418.7281, 418.7281, 418.7281,  69.5277,  69.5277, 418.7281,\n",
      "         69.5277,  69.5277,   5.2026, 418.7281, 418.7281, 418.7281, 418.7281,\n",
      "        418.7281,  69.5277,  69.5277, 418.7281,  69.5277,  69.5277,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 418.7281,   5.2026,   5.2025, 418.7281,   5.2026,\n",
      "          5.2025, 418.7281,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        418.7281, 418.7281, 418.7281, 418.7281,  69.5277,  69.5277,  69.5277,\n",
      "         69.5277, 418.7281, 418.7281, 418.7281,  69.5277,  69.5277,  69.5277,\n",
      "         69.5277,   5.2026,  69.5277,  69.5277,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 705 was 95.4%\n",
      "tensor([0.0000e+00, 2.6614e-06, 2.2703e-06, 2.1000e-06, 2.2461e-06, 2.6330e-09,\n",
      "        1.8583e-09, 1.7941e-09, 1.8301e-09, 3.5089e-06, 3.3969e-06, 3.4965e-06,\n",
      "        2.3828e-05, 2.3084e-05, 2.3095e-05, 3.2499e-06, 3.3464e-06, 1.4520e-05,\n",
      "        1.4556e-05, 2.7706e-01, 2.9304e-01, 1.1330e+00, 1.1169e+00, 3.2383e-06,\n",
      "        1.4526e-05, 2.7510e-01, 1.1349e+00, 2.5125e-01, 1.1592e+00, 3.1412e-01,\n",
      "        9.5456e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([230.0200, 267.5566, 287.5248, 270.2282,   7.4363,   7.4349,   7.4360,\n",
      "        419.1485, 419.1485, 419.1485,   7.4370,   7.4366, 419.1485, 419.1485,\n",
      "        419.1485, 419.1485, 419.1485,  69.6068,  69.6068,   7.4378, 419.1485,\n",
      "        419.1485, 419.1485, 419.1485, 419.1485,  69.6068,  69.6068, 419.1485,\n",
      "         69.6068,  69.6068,   5.2026, 419.1485, 419.1485, 419.1485, 419.1485,\n",
      "        419.1485,  69.6068,  69.6068, 419.1485,  69.6068,  69.6068,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 419.1485,   5.2026,   5.2025, 419.1485,   5.2026,\n",
      "          5.2025, 419.1485,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        419.1485, 419.1485, 419.1485, 419.1485,  69.6068,  69.6068,  69.6068,\n",
      "         69.6068, 419.1485, 419.1485, 419.1485,  69.6068,  69.6068,  69.6068,\n",
      "         69.6068,   5.2026,  69.6068,  69.6068,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 706 was 95.4%\n",
      "tensor([1.1581e-23, 2.6565e-06, 2.2666e-06, 2.0966e-06, 2.2428e-06, 2.6026e-09,\n",
      "        1.8362e-09, 1.7732e-09, 1.8087e-09, 3.4998e-06, 3.3910e-06, 3.4883e-06,\n",
      "        2.3462e-05, 2.2757e-05, 2.2754e-05, 3.2420e-06, 3.3402e-06, 1.4297e-05,\n",
      "        1.4342e-05, 2.7639e-01, 2.9238e-01, 1.1305e+00, 1.1144e+00, 3.2297e-06,\n",
      "        1.4300e-05, 2.7449e-01, 1.1324e+00, 2.5077e-01, 1.1566e+00, 3.1343e-01,\n",
      "        9.5466e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([230.2859, 267.8364, 287.8233, 270.4736,   7.4306,   7.4336,   7.4337,\n",
      "        419.5689, 419.5689, 419.5689,   7.4316,   7.4332, 419.5689, 419.5689,\n",
      "        419.5689, 419.5689, 419.5689,  69.6859,  69.6859,   7.4306, 419.5689,\n",
      "        419.5689, 419.5689, 419.5689, 419.5689,  69.6859,  69.6859, 419.5689,\n",
      "         69.6859,  69.6859,   5.2026, 419.5689, 419.5689, 419.5689, 419.5689,\n",
      "        419.5689,  69.6859,  69.6859, 419.5689,  69.6859,  69.6859,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 419.5689,   5.2026,   5.2025, 419.5689,   5.2026,\n",
      "          5.2025, 419.5689,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        419.5689, 419.5689, 419.5689, 419.5689,  69.6859,  69.6859,  69.6859,\n",
      "         69.6859, 419.5689, 419.5689, 419.5689,  69.6859,  69.6859,  69.6859,\n",
      "         69.6859,   5.2026,  69.6859,  69.6859,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 707 was 95.4%\n",
      "tensor([0.0000e+00, 2.6523e-06, 2.2631e-06, 2.0933e-06, 2.2397e-06, 2.5793e-09,\n",
      "        1.8195e-09, 1.7574e-09, 1.7925e-09, 3.4936e-06, 3.3822e-06, 3.4806e-06,\n",
      "        2.3183e-05, 2.2485e-05, 2.2484e-05, 3.2353e-06, 3.3327e-06, 1.4124e-05,\n",
      "        1.4164e-05, 2.7578e-01, 2.9180e-01, 1.1281e+00, 1.1119e+00, 3.2244e-06,\n",
      "        1.4132e-05, 2.7393e-01, 1.1300e+00, 2.5018e-01, 1.1541e+00, 3.1275e-01,\n",
      "        9.5476e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([230.5519, 268.1164, 288.1214, 270.7194,   7.4271,   7.4282,   7.4261,\n",
      "        419.9893, 419.9893, 419.9893,   7.4284,   7.4289, 419.9893, 419.9893,\n",
      "        419.9893, 419.9893, 419.9893,  69.7650,  69.7650,   7.4291, 419.9893,\n",
      "        419.9893, 419.9893, 419.9893, 419.9893,  69.7650,  69.7650, 419.9893,\n",
      "         69.7650,  69.7650,   5.2026, 419.9893, 419.9893, 419.9893, 419.9893,\n",
      "        419.9893,  69.7650,  69.7650, 419.9893,  69.7650,  69.7650,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 419.9893,   5.2026,   5.2025, 419.9893,   5.2026,\n",
      "          5.2025, 419.9893,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        419.9893, 419.9893, 419.9893, 419.9893,  69.7650,  69.7650,  69.7650,\n",
      "         69.7650, 419.9893, 419.9893, 419.9893,  69.7650,  69.7650,  69.7650,\n",
      "         69.7650,   5.2026,  69.7650,  69.7650,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 708 was 95.4%\n",
      "tensor([0.0000e+00, 2.6474e-06, 2.2594e-06, 2.0900e-06, 2.2363e-06, 2.5547e-09,\n",
      "        1.8019e-09, 1.7406e-09, 1.7755e-09, 3.4847e-06, 3.3750e-06, 3.4739e-06,\n",
      "        2.2880e-05, 2.2204e-05, 2.2204e-05, 3.2279e-06, 3.3253e-06, 1.3945e-05,\n",
      "        1.3985e-05, 2.7514e-01, 2.9110e-01, 1.1256e+00, 1.1095e+00, 3.2162e-06,\n",
      "        1.3949e-05, 2.7330e-01, 1.1275e+00, 2.4972e-01, 1.1515e+00, 3.1204e-01,\n",
      "        9.5486e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([230.8179, 268.3965, 288.4195, 270.9650,   7.4229,   7.4248,   7.4243,\n",
      "        420.4097, 420.4097, 420.4097,   7.4251,   7.4234, 420.4097, 420.4097,\n",
      "        420.4097, 420.4097, 420.4097,  69.8442,  69.8442,   7.4219, 420.4097,\n",
      "        420.4097, 420.4097, 420.4097, 420.4097,  69.8442,  69.8442, 420.4097,\n",
      "         69.8442,  69.8442,   5.2026, 420.4097, 420.4097, 420.4097, 420.4097,\n",
      "        420.4097,  69.8442,  69.8442, 420.4097,  69.8442,  69.8442,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 420.4097,   5.2026,   5.2025, 420.4097,   5.2026,\n",
      "          5.2025, 420.4097,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        420.4097, 420.4097, 420.4097, 420.4097,  69.8442,  69.8442,  69.8442,\n",
      "         69.8442, 420.4097, 420.4097, 420.4097,  69.8442,  69.8442,  69.8442,\n",
      "         69.8442,   5.2026,  69.8442,  69.8442,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 709 was 95.4%\n",
      "tensor([1.1470e-08, 2.6460e-06, 2.2583e-06, 2.0893e-06, 2.2355e-06, 7.0310e-24,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4774e-06, 3.3675e-06, 3.4649e-06,\n",
      "        2.2608e-05, 2.1947e-05, 2.1939e-05, 3.2203e-06, 3.3189e-06, 1.3774e-05,\n",
      "        1.3817e-05, 2.7457e-01, 2.9048e-01, 1.1231e+00, 1.1071e+00, 3.2106e-06,\n",
      "        1.3784e-05, 2.7270e-01, 1.1250e+00, 2.4915e-01, 1.1490e+00, 3.1135e-01,\n",
      "        9.5496e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([231.0838, 268.6763, 288.7175, 271.2109,   7.4193,   7.4193,   7.4199,\n",
      "        420.8301, 420.8301, 420.8301,   7.4177,   7.4201, 420.8301, 420.8301,\n",
      "        420.8301, 420.8301, 420.8301,  69.9233,  69.9233,   7.4204, 420.8301,\n",
      "        420.8301, 420.8301, 420.8301, 420.8301,  69.9233,  69.9233, 420.8301,\n",
      "         69.9233,  69.9233,   5.2026, 420.8301, 420.8301, 420.8301, 420.8301,\n",
      "        420.8301,  69.9233,  69.9233, 420.8301,  69.9233,  69.9233,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 420.8301,   5.2026,   5.2025, 420.8301,   5.2026,\n",
      "          5.2025, 420.8301,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        420.8301, 420.8301, 420.8301, 420.8301,  69.9233,  69.9233,  69.9233,\n",
      "         69.9233, 420.8301, 420.8301, 420.8301,  69.9233,  69.9233,  69.9233,\n",
      "         69.9233,   5.2026,  69.9233,  69.9233,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 710 was 95.5%\n",
      "tensor([0.0000e+00, 2.6383e-06, 2.2520e-06, 2.0832e-06, 2.2298e-06, 2.5094e-09,\n",
      "        1.7693e-09, 1.7100e-09, 1.7441e-09, 3.4686e-06, 3.3598e-06, 3.4579e-06,\n",
      "        2.2323e-05, 2.1686e-05, 2.1680e-05, 3.2141e-06, 3.3115e-06, 1.3610e-05,\n",
      "        1.3647e-05, 2.7385e-01, 2.8988e-01, 1.1207e+00, 1.1046e+00, 3.2023e-06,\n",
      "        1.3613e-05, 2.7212e-01, 1.1225e+00, 2.4863e-01, 1.1464e+00, 3.1065e-01,\n",
      "        9.5506e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([231.3497, 268.9560, 289.0156, 271.4568,   7.4138,   7.4170,   7.4164,\n",
      "        421.2505, 421.2505, 421.2505,   7.4162,   7.4146, 421.2505, 421.2505,\n",
      "        421.2505, 421.2505, 421.2505,  70.0024,  70.0024,   7.4131, 421.2505,\n",
      "        421.2505, 421.2505, 421.2505, 421.2505,  70.0024,  70.0024, 421.2505,\n",
      "         70.0024,  70.0024,   5.2026, 421.2505, 421.2505, 421.2505, 421.2505,\n",
      "        421.2505,  70.0024,  70.0024, 421.2505,  70.0024,  70.0024,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 421.2505,   5.2026,   5.2025, 421.2505,   5.2026,\n",
      "          5.2025, 421.2505,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        421.2505, 421.2505, 421.2505, 421.2505,  70.0024,  70.0024,  70.0024,\n",
      "         70.0024, 421.2505, 421.2505, 421.2505,  70.0024,  70.0024,  70.0024,\n",
      "         70.0024,   5.2026,  70.0024,  70.0024,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 711 was 95.5%\n",
      "tensor([0.0000e+00, 2.6341e-06, 2.2486e-06, 2.0801e-06, 2.2265e-06, 2.4860e-09,\n",
      "        1.7526e-09, 1.6940e-09, 1.7279e-09, 3.4625e-06, 3.3524e-06, 3.4498e-06,\n",
      "        2.2047e-05, 2.1420e-05, 2.1411e-05, 3.2063e-06, 3.3048e-06, 1.3436e-05,\n",
      "        1.3476e-05, 2.7332e-01, 2.8923e-01, 1.1183e+00, 1.1022e+00, 3.1970e-06,\n",
      "        1.3446e-05, 2.7155e-01, 1.1201e+00, 2.4808e-01, 1.1440e+00, 3.0998e-01,\n",
      "        9.5515e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([231.6156, 269.2359, 289.3133, 271.7030,   7.4101,   7.4094,   7.4109,\n",
      "        421.6709, 421.6709, 421.6709,   7.4119,   7.4112, 421.6709, 421.6709,\n",
      "        421.6709, 421.6709, 421.6709,  70.0816,  70.0816,   7.4117, 421.6709,\n",
      "        421.6709, 421.6709, 421.6709, 421.6709,  70.0816,  70.0816, 421.6709,\n",
      "         70.0816,  70.0816,   5.2026, 421.6709, 421.6709, 421.6709, 421.6709,\n",
      "        421.6709,  70.0816,  70.0816, 421.6709,  70.0816,  70.0816,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 421.6709,   5.2026,   5.2025, 421.6709,   5.2026,\n",
      "          5.2025, 421.6709,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        421.6709, 421.6709, 421.6709, 421.6709,  70.0816,  70.0816,  70.0816,\n",
      "         70.0816, 421.6709, 421.6709, 421.6709,  70.0816,  70.0816,  70.0816,\n",
      "         70.0816,   5.2026,  70.0816,  70.0816,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 712 was 95.5%\n",
      "tensor([0.0000e+00, 2.6291e-06, 2.2449e-06, 2.0766e-06, 2.2232e-06, 2.4627e-09,\n",
      "        1.7360e-09, 1.6783e-09, 1.7119e-09, 3.4536e-06, 3.3455e-06, 3.4424e-06,\n",
      "        2.1761e-05, 2.1158e-05, 2.1146e-05, 3.1988e-06, 3.2972e-06, 1.3269e-05,\n",
      "        1.3308e-05, 2.7263e-01, 2.8859e-01, 1.1158e+00, 1.0997e+00, 3.1885e-06,\n",
      "        1.3276e-05, 2.7090e-01, 1.1176e+00, 2.4761e-01, 1.1413e+00, 3.0927e-01,\n",
      "        9.5525e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([231.8815, 269.5156, 289.6110, 271.9492,   7.4054,   7.4081,   7.4074,\n",
      "        422.0913, 422.0913, 422.0913,   7.4045,   7.4077, 422.0913, 422.0913,\n",
      "        422.0913, 422.0913, 422.0913,  70.1607,  70.1607,   7.4063, 422.0913,\n",
      "        422.0913, 422.0913, 422.0913, 422.0913,  70.1607,  70.1607, 422.0913,\n",
      "         70.1607,  70.1607,   5.2026, 422.0913, 422.0913, 422.0913, 422.0913,\n",
      "        422.0913,  70.1607,  70.1607, 422.0913,  70.1607,  70.1607,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 422.0913,   5.2026,   5.2025, 422.0913,   5.2026,\n",
      "          5.2025, 422.0913,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        422.0913, 422.0913, 422.0913, 422.0913,  70.1607,  70.1607,  70.1607,\n",
      "         70.1607, 422.0913, 422.0913, 422.0913,  70.1607,  70.1607,  70.1607,\n",
      "         70.1607,   5.2026,  70.1607,  70.1607,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 713 was 95.5%\n",
      "tensor([0.0000e+00, 2.6249e-06, 2.2413e-06, 2.0733e-06, 2.2201e-06, 2.4411e-09,\n",
      "        1.7203e-09, 1.6635e-09, 1.6969e-09, 3.4466e-06, 3.3365e-06, 3.4354e-06,\n",
      "        2.1500e-05, 2.0906e-05, 2.0903e-05, 3.1934e-06, 3.2897e-06, 1.3112e-05,\n",
      "        1.3142e-05, 2.7201e-01, 2.8800e-01, 1.1134e+00, 1.0973e+00, 3.1825e-06,\n",
      "        1.3118e-05, 2.7036e-01, 1.1151e+00, 2.4704e-01, 1.1388e+00, 3.0859e-01,\n",
      "        9.5535e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([232.1474, 269.7953, 289.9085, 272.1956,   7.4008,   7.4004,   7.4029,\n",
      "        422.5117, 422.5117, 422.5117,   7.4030,   7.4023, 422.5117, 422.5117,\n",
      "        422.5117, 422.5117, 422.5117,  70.2398,  70.2398,   7.4040, 422.5117,\n",
      "        422.5117, 422.5117, 422.5117, 422.5117,  70.2398,  70.2398, 422.5117,\n",
      "         70.2398,  70.2398,   5.2026, 422.5117, 422.5117, 422.5117, 422.5117,\n",
      "        422.5117,  70.2398,  70.2398, 422.5117,  70.2398,  70.2398,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 422.5117,   5.2026,   5.2025, 422.5117,   5.2026,\n",
      "          5.2025, 422.5117,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        422.5117, 422.5117, 422.5117, 422.5117,  70.2398,  70.2398,  70.2398,\n",
      "         70.2398, 422.5117, 422.5117, 422.5117,  70.2398,  70.2398,  70.2398,\n",
      "         70.2398,   5.2026,  70.2398,  70.2398,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 714 was 95.5%\n",
      "tensor([0.0000e+00, 2.6201e-06, 2.2377e-06, 2.0701e-06, 2.2169e-06, 2.4177e-09,\n",
      "        1.7037e-09, 1.6478e-09, 1.6806e-09, 3.4382e-06, 3.3308e-06, 3.4274e-06,\n",
      "        2.1218e-05, 2.0650e-05, 2.0634e-05, 3.1848e-06, 3.2835e-06, 1.2942e-05,\n",
      "        1.2979e-05, 2.7136e-01, 2.8733e-01, 1.1110e+00, 1.0949e+00, 3.1748e-06,\n",
      "        1.2946e-05, 2.6975e-01, 1.1126e+00, 2.4658e-01, 1.1363e+00, 3.0791e-01,\n",
      "        9.5545e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([232.4133, 270.0750, 290.2059, 272.4421,   7.3961,   7.3990,   7.3984,\n",
      "        422.9321, 422.9321, 422.9321,   7.3975,   7.3998, 422.9321, 422.9321,\n",
      "        422.9321, 422.9321, 422.9321,  70.3190,  70.3190,   7.3966, 422.9321,\n",
      "        422.9321, 422.9321, 422.9321, 422.9321,  70.3190,  70.3190, 422.9321,\n",
      "         70.3190,  70.3190,   5.2026, 422.9321, 422.9321, 422.9321, 422.9321,\n",
      "        422.9321,  70.3190,  70.3190, 422.9321,  70.3190,  70.3190,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 422.9321,   5.2026,   5.2025, 422.9321,   5.2026,\n",
      "          5.2025, 422.9321,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        422.9321, 422.9321, 422.9321, 422.9321,  70.3190,  70.3190,  70.3190,\n",
      "         70.3190, 422.9321, 422.9321, 422.9321,  70.3190,  70.3190,  70.3190,\n",
      "         70.3190,   5.2026,  70.3190,  70.3190,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 715 was 95.5%\n",
      "tensor([0.0000e+00, 2.6158e-06, 2.2342e-06, 2.0667e-06, 2.2137e-06, 2.3960e-09,\n",
      "        1.6881e-09, 1.6329e-09, 1.6656e-09, 3.4316e-06, 3.3215e-06, 3.4204e-06,\n",
      "        2.0961e-05, 2.0395e-05, 2.0392e-05, 3.1788e-06, 3.2752e-06, 1.2785e-05,\n",
      "        1.2813e-05, 2.7077e-01, 2.8675e-01, 1.1085e+00, 1.0924e+00, 3.1692e-06,\n",
      "        1.2792e-05, 2.6913e-01, 1.1102e+00, 2.4602e-01, 1.1338e+00, 3.0722e-01,\n",
      "        9.5555e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([232.6793, 270.3547, 290.5031, 272.6888,   7.3924,   7.3936,   7.3939,\n",
      "        423.3525, 423.3525, 423.3525,   7.3941,   7.3922, 423.3525, 423.3525,\n",
      "        423.3525, 423.3525, 423.3525,  70.3981,  70.3981,   7.3951, 423.3525,\n",
      "        423.3525, 423.3525, 423.3525, 423.3525,  70.3981,  70.3981, 423.3525,\n",
      "         70.3981,  70.3981,   5.2026, 423.3525, 423.3525, 423.3525, 423.3525,\n",
      "        423.3525,  70.3981,  70.3981, 423.3525,  70.3981,  70.3981,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 423.3525,   5.2026,   5.2025, 423.3525,   5.2026,\n",
      "          5.2025, 423.3525,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        423.3525, 423.3525, 423.3525, 423.3525,  70.3981,  70.3981,  70.3981,\n",
      "         70.3981, 423.3525, 423.3525, 423.3525,  70.3981,  70.3981,  70.3981,\n",
      "         70.3981,   5.2026,  70.3981,  70.3981,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 716 was 95.5%\n",
      "tensor([1.0686e-08, 2.6138e-06, 2.2327e-06, 2.0659e-06, 2.2125e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4225e-06, 3.3152e-06, 3.4119e-06,\n",
      "        2.0681e-05, 2.0145e-05, 2.0131e-05, 3.1711e-06, 3.2695e-06, 1.2616e-05,\n",
      "        1.2652e-05, 2.7015e-01, 2.8603e-01, 1.1061e+00, 1.0900e+00, 3.1609e-06,\n",
      "        1.2621e-05, 2.6857e-01, 1.1077e+00, 2.4551e-01, 1.1312e+00, 3.0652e-01,\n",
      "        9.5565e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([232.9451, 270.6343, 290.8003, 272.9355,   7.3877,   7.3911,   7.3893,\n",
      "        423.7729, 423.7729, 423.7729,   7.3886,   7.3907, 423.7729, 423.7729,\n",
      "        423.7729, 423.7729, 423.7729,  70.4772,  70.4772,   7.3877, 423.7729,\n",
      "        423.7729, 423.7729, 423.7729, 423.7729,  70.4772,  70.4772, 423.7729,\n",
      "         70.4772,  70.4772,   5.2026, 423.7729, 423.7729, 423.7729, 423.7729,\n",
      "        423.7729,  70.4772,  70.4772, 423.7729,  70.4772,  70.4772,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 423.7729,   5.2026,   5.2025, 423.7729,   5.2026,\n",
      "          5.2025, 423.7729,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        423.7729, 423.7729, 423.7729, 423.7729,  70.4772,  70.4772,  70.4772,\n",
      "         70.4772, 423.7729, 423.7729, 423.7729,  70.4772,  70.4772,  70.4772,\n",
      "         70.4772,   5.2026,  70.4772,  70.4772,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 717 was 95.5%\n",
      "tensor([0.0000e+00, 2.6068e-06, 2.2270e-06, 2.0602e-06, 2.2071e-06, 2.3518e-09,\n",
      "        1.6565e-09, 1.6028e-09, 1.6350e-09, 3.4161e-06, 3.3063e-06, 3.4055e-06,\n",
      "        2.0436e-05, 1.9897e-05, 1.9895e-05, 3.1649e-06, 3.2608e-06, 1.2467e-05,\n",
      "        1.2493e-05, 2.6956e-01, 2.8547e-01, 1.1037e+00, 1.0876e+00, 3.1556e-06,\n",
      "        1.2473e-05, 2.6797e-01, 1.1053e+00, 2.4496e-01, 1.1287e+00, 3.0584e-01,\n",
      "        9.5575e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([233.2111, 270.9139, 291.0973, 273.1824,   7.3839,   7.3834,   7.3847,\n",
      "        424.1933, 424.1933, 424.1933,   7.3853,   7.3852, 424.1933, 424.1933,\n",
      "        424.1933, 424.1933, 424.1933,  70.5563,  70.5563,   7.3862, 424.1933,\n",
      "        424.1933, 424.1933, 424.1933, 424.1933,  70.5563,  70.5563, 424.1933,\n",
      "         70.5563,  70.5563,   5.2026, 424.1933, 424.1933, 424.1933, 424.1933,\n",
      "        424.1933,  70.5563,  70.5563, 424.1933,  70.5563,  70.5563,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 424.1933,   5.2026,   5.2025, 424.1933,   5.2026,\n",
      "          5.2025, 424.1933,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        424.1933, 424.1933, 424.1933, 424.1933,  70.5563,  70.5563,  70.5563,\n",
      "         70.5563, 424.1933, 424.1933, 424.1933,  70.5563,  70.5563,  70.5563,\n",
      "         70.5563,   5.2026,  70.5563,  70.5563,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 718 was 95.5%\n",
      "tensor([0.0000e+00, 2.6019e-06, 2.2232e-06, 2.0568e-06, 2.2037e-06, 2.3293e-09,\n",
      "        1.6404e-09, 1.5877e-09, 1.6194e-09, 3.4070e-06, 3.3004e-06, 3.3974e-06,\n",
      "        2.0162e-05, 1.9655e-05, 1.9639e-05, 3.1567e-06, 3.2547e-06, 1.2305e-05,\n",
      "        1.2337e-05, 2.6888e-01, 2.8481e-01, 1.1012e+00, 1.0852e+00, 3.1470e-06,\n",
      "        1.2308e-05, 2.6736e-01, 1.1028e+00, 2.4448e-01, 1.1261e+00, 3.0514e-01,\n",
      "        9.5585e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([233.4769, 271.1933, 291.3944, 273.4293,   7.3791,   7.3820,   7.3811,\n",
      "        424.6137, 424.6137, 424.6137,   7.3797,   7.3816, 424.6137, 424.6137,\n",
      "        424.6137, 424.6137, 424.6137,  70.6355,  70.6355,   7.3787, 424.6137,\n",
      "        424.6137, 424.6137, 424.6137, 424.6137,  70.6355,  70.6355, 424.6137,\n",
      "         70.6355,  70.6355,   5.2026, 424.6137, 424.6137, 424.6137, 424.6137,\n",
      "        424.6137,  70.6355,  70.6355, 424.6137,  70.6355,  70.6355,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 424.6137,   5.2026,   5.2025, 424.6137,   5.2026,\n",
      "          5.2025, 424.6137,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        424.6137, 424.6137, 424.6137, 424.6137,  70.6355,  70.6355,  70.6355,\n",
      "         70.6355, 424.6137, 424.6137, 424.6137,  70.6355,  70.6355,  70.6355,\n",
      "         70.6355,   5.2026,  70.6355,  70.6355,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 719 was 95.5%\n",
      "tensor([1.0371e-08, 2.6004e-06, 2.2220e-06, 2.0559e-06, 2.2028e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4005e-06, 3.2915e-06, 3.3901e-06,\n",
      "        1.9920e-05, 1.9416e-05, 1.9408e-05, 3.1506e-06, 3.2469e-06, 1.2155e-05,\n",
      "        1.2182e-05, 2.6831e-01, 2.8423e-01, 1.0988e+00, 1.0828e+00, 3.1417e-06,\n",
      "        1.2162e-05, 2.6679e-01, 1.1004e+00, 2.4390e-01, 1.1237e+00, 3.0447e-01,\n",
      "        9.5594e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([233.7428, 271.4728, 291.6912, 273.6764,   7.3753,   7.3742,   7.3766,\n",
      "        425.0341, 425.0341, 425.0341,   7.3763,   7.3761, 425.0341, 425.0341,\n",
      "        425.0341, 425.0341, 425.0341,  70.7146,  70.7146,   7.3772, 425.0341,\n",
      "        425.0341, 425.0341, 425.0341, 425.0341,  70.7146,  70.7146, 425.0341,\n",
      "         70.7146,  70.7146,   5.2026, 425.0341, 425.0341, 425.0341, 425.0341,\n",
      "        425.0341,  70.7146,  70.7146, 425.0341,  70.7146,  70.7146,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 425.0341,   5.2026,   5.2025, 425.0341,   5.2026,\n",
      "          5.2025, 425.0341,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        425.0341, 425.0341, 425.0341, 425.0341,  70.7146,  70.7146,  70.7146,\n",
      "         70.7146, 425.0341, 425.0341, 425.0341,  70.7146,  70.7146,  70.7146,\n",
      "         70.7146,   5.2026,  70.7146,  70.7146,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 720 was 95.6%\n",
      "tensor([6.6174e-24, 2.5929e-06, 2.2160e-06, 2.0501e-06, 2.1972e-06, 2.2866e-09,\n",
      "        1.6097e-09, 1.5586e-09, 1.5897e-09, 3.3916e-06, 3.2856e-06, 3.3820e-06,\n",
      "        1.9656e-05, 1.9178e-05, 1.9159e-05, 3.1426e-06, 3.2407e-06, 1.1998e-05,\n",
      "        1.2029e-05, 2.6764e-01, 2.8357e-01, 1.0964e+00, 1.0803e+00, 3.1334e-06,\n",
      "        1.2002e-05, 2.6619e-01, 1.0979e+00, 2.4342e-01, 1.1211e+00, 3.0377e-01,\n",
      "        9.5604e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([234.0086, 271.7522, 291.9881, 273.9235,   7.3704,   7.3728,   7.3708,\n",
      "        425.4544, 425.4544, 425.4544,   7.3719,   7.3735, 425.4544, 425.4544,\n",
      "        425.4544, 425.4544, 425.4544,  70.7937,  70.7937,   7.3696, 425.4544,\n",
      "        425.4544, 425.4544, 425.4544, 425.4544,  70.7937,  70.7937, 425.4544,\n",
      "         70.7937,  70.7937,   5.2026, 425.4544, 425.4544, 425.4544, 425.4544,\n",
      "        425.4544,  70.7937,  70.7937, 425.4544,  70.7937,  70.7937,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 425.4544,   5.2026,   5.2025, 425.4544,   5.2026,\n",
      "          5.2025, 425.4544,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        425.4544, 425.4544, 425.4544, 425.4544,  70.7937,  70.7937,  70.7937,\n",
      "         70.7937, 425.4544, 425.4544, 425.4544,  70.7937,  70.7937,  70.7937,\n",
      "         70.7937,   5.2026,  70.7937,  70.7937,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 721 was 95.6%\n",
      "tensor([6.6174e-24, 2.5886e-06, 2.2127e-06, 2.0469e-06, 2.1940e-06, 2.2657e-09,\n",
      "        1.5947e-09, 1.5442e-09, 1.5752e-09, 3.3851e-06, 3.2764e-06, 3.3755e-06,\n",
      "        1.9415e-05, 1.8936e-05, 1.8929e-05, 3.1366e-06, 3.2325e-06, 1.1849e-05,\n",
      "        1.1872e-05, 2.6708e-01, 2.8297e-01, 1.0940e+00, 1.0779e+00, 3.1282e-06,\n",
      "        1.1856e-05, 2.6556e-01, 1.0955e+00, 2.4291e-01, 1.1186e+00, 3.0310e-01,\n",
      "        9.5614e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([234.2744, 272.0315, 292.2848, 274.1707,   7.3666,   7.3672,   7.3673,\n",
      "        425.8748, 425.8748, 425.8748,   7.3673,   7.3657, 425.8748, 425.8748,\n",
      "        425.8748, 425.8748, 425.8748,  70.8729,  70.8729,   7.3681, 425.8748,\n",
      "        425.8748, 425.8748, 425.8748, 425.8748,  70.8729,  70.8729, 425.8748,\n",
      "         70.8729,  70.8729,   5.2026, 425.8748, 425.8748, 425.8748, 425.8748,\n",
      "        425.8748,  70.8729,  70.8729, 425.8748,  70.8729,  70.8729,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 425.8748,   5.2026,   5.2025, 425.8748,   5.2026,\n",
      "          5.2025, 425.8748,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        425.8748, 425.8748, 425.8748, 425.8748,  70.8729,  70.8729,  70.8729,\n",
      "         70.8729, 425.8748, 425.8748, 425.8748,  70.8729,  70.8729,  70.8729,\n",
      "         70.8729,   5.2026,  70.8729,  70.8729,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 722 was 95.6%\n",
      "tensor([8.2718e-24, 2.5839e-06, 2.2088e-06, 2.0436e-06, 2.1906e-06, 2.2434e-09,\n",
      "        1.5787e-09, 1.5291e-09, 1.5597e-09, 3.3760e-06, 3.2700e-06, 3.3668e-06,\n",
      "        1.9149e-05, 1.8699e-05, 1.8681e-05, 3.1288e-06, 3.2268e-06, 1.1689e-05,\n",
      "        1.1719e-05, 2.6644e-01, 2.8229e-01, 1.0915e+00, 1.0755e+00, 3.1196e-06,\n",
      "        1.1694e-05, 2.6501e-01, 1.0930e+00, 2.4236e-01, 1.1160e+00, 3.0239e-01,\n",
      "        9.5624e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([234.5402, 272.3108, 292.5815, 274.4180,   7.3617,   7.3647,   7.3626,\n",
      "        426.2952, 426.2952, 426.2952,   7.3617,   7.3642, 426.2952, 426.2952,\n",
      "        426.2952, 426.2952, 426.2952,  70.9520,  70.9520,   7.3605, 426.2952,\n",
      "        426.2952, 426.2952, 426.2952, 426.2952,  70.9520,  70.9520, 426.2952,\n",
      "         70.9520,  70.9520,   5.2026, 426.2952, 426.2952, 426.2952, 426.2952,\n",
      "        426.2952,  70.9520,  70.9520, 426.2952,  70.9520,  70.9520,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 426.2952,   5.2026,   5.2025, 426.2952,   5.2026,\n",
      "          5.2025, 426.2952,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        426.2952, 426.2952, 426.2952, 426.2952,  70.9520,  70.9520,  70.9520,\n",
      "         70.9520, 426.2952, 426.2952, 426.2952,  70.9520,  70.9520,  70.9520,\n",
      "         70.9520,   5.2026,  70.9520,  70.9520,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 723 was 95.6%\n",
      "tensor([0.0000e+00, 2.5798e-06, 2.2055e-06, 2.0404e-06, 2.1875e-06, 2.2238e-09,\n",
      "        1.5648e-09, 1.5157e-09, 1.5462e-09, 3.3698e-06, 3.2614e-06, 3.3605e-06,\n",
      "        1.8925e-05, 1.8470e-05, 1.8464e-05, 3.1230e-06, 3.2183e-06, 1.1552e-05,\n",
      "        1.1572e-05, 2.6585e-01, 2.8172e-01, 1.0891e+00, 1.0731e+00, 3.1147e-06,\n",
      "        1.1558e-05, 2.6443e-01, 1.0906e+00, 2.4182e-01, 1.1136e+00, 3.0173e-01,\n",
      "        9.5633e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([234.8060, 272.5900, 292.8780, 274.6655,   7.3578,   7.3568,   7.3580,\n",
      "        426.7156, 426.7156, 426.7156,   7.3583,   7.3586, 426.7156, 426.7156,\n",
      "        426.7156, 426.7156, 426.7156,  71.0311,  71.0311,   7.3590, 426.7156,\n",
      "        426.7156, 426.7156, 426.7156, 426.7156,  71.0311,  71.0311, 426.7156,\n",
      "         71.0311,  71.0311,   5.2026, 426.7156, 426.7156, 426.7156, 426.7156,\n",
      "        426.7156,  71.0311,  71.0311, 426.7156,  71.0311,  71.0311,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 426.7156,   5.2026,   5.2025, 426.7156,   5.2026,\n",
      "          5.2025, 426.7156,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        426.7156, 426.7156, 426.7156, 426.7156,  71.0311,  71.0311,  71.0311,\n",
      "         71.0311, 426.7156, 426.7156, 426.7156,  71.0311,  71.0311,  71.0311,\n",
      "         71.0311,   5.2026,  71.0311,  71.0311,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 724 was 95.6%\n",
      "tensor([0.0000e+00, 2.5749e-06, 2.2017e-06, 2.0369e-06, 2.1841e-06, 2.2020e-09,\n",
      "        1.5492e-09, 1.5011e-09, 1.5311e-09, 3.3607e-06, 3.2554e-06, 3.3522e-06,\n",
      "        1.8665e-05, 1.8240e-05, 1.8221e-05, 3.1147e-06, 3.2120e-06, 1.1397e-05,\n",
      "        1.1424e-05, 2.6519e-01, 2.8107e-01, 1.0867e+00, 1.0707e+00, 3.1059e-06,\n",
      "        1.1401e-05, 2.6381e-01, 1.0881e+00, 2.4134e-01, 1.1110e+00, 3.0102e-01,\n",
      "        9.5643e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.0717, 272.8691, 293.1746, 274.9130,   7.3528,   7.3554,   7.3543,\n",
      "        427.1360, 427.1360, 427.1360,   7.3548,   7.3528, 427.1360, 427.1360,\n",
      "        427.1360, 427.1360, 427.1360,  71.1102,  71.1102,   7.3513, 427.1360,\n",
      "        427.1360, 427.1360, 427.1360, 427.1360,  71.1102,  71.1102, 427.1360,\n",
      "         71.1102,  71.1102,   5.2026, 427.1360, 427.1360, 427.1360, 427.1360,\n",
      "        427.1360,  71.1102,  71.1102, 427.1360,  71.1102,  71.1102,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 427.1360,   5.2026,   5.2025, 427.1360,   5.2026,\n",
      "          5.2025, 427.1360,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        427.1360, 427.1360, 427.1360, 427.1360,  71.1102,  71.1102,  71.1102,\n",
      "         71.1102, 427.1360, 427.1360, 427.1360,  71.1102,  71.1102,  71.1102,\n",
      "         71.1102,   5.2026,  71.1102,  71.1102,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 725 was 95.6%\n",
      "tensor([4.9631e-24, 2.5708e-06, 2.1982e-06, 2.0339e-06, 2.1808e-06, 2.1815e-09,\n",
      "        1.5344e-09, 1.4869e-09, 1.5167e-09, 3.3541e-06, 3.2475e-06, 3.3443e-06,\n",
      "        1.8432e-05, 1.8011e-05, 1.7993e-05, 3.1077e-06, 3.2054e-06, 1.1250e-05,\n",
      "        1.1277e-05, 2.6466e-01, 2.8043e-01, 1.0843e+00, 1.0683e+00, 3.1009e-06,\n",
      "        1.1258e-05, 2.6325e-01, 1.0857e+00, 2.4077e-01, 1.1086e+00, 3.0037e-01,\n",
      "        9.5653e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.3375, 273.1483, 293.4709, 275.1606,   7.3479,   7.3474,   7.3497,\n",
      "        427.5563, 427.5563, 427.5563,   7.3492,   7.3503, 427.5563, 427.5563,\n",
      "        427.5563, 427.5563, 427.5563,  71.1894,  71.1894,   7.3498, 427.5563,\n",
      "        427.5563, 427.5563, 427.5563, 427.5563,  71.1894,  71.1894, 427.5563,\n",
      "         71.1894,  71.1894,   5.2026, 427.5563, 427.5563, 427.5563, 427.5563,\n",
      "        427.5563,  71.1894,  71.1894, 427.5563,  71.1894,  71.1894,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 427.5563,   5.2026,   5.2025, 427.5563,   5.2026,\n",
      "          5.2025, 427.5563,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        427.5563, 427.5563, 427.5563, 427.5563,  71.1894,  71.1894,  71.1894,\n",
      "         71.1894, 427.5563, 427.5563, 427.5563,  71.1894,  71.1894,  71.1894,\n",
      "         71.1894,   5.2026,  71.1894,  71.1894,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.8359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 726 was 95.6%\n",
      "tensor([0.0000e+00, 0.0000e+00, 3.0114e-06, 4.2366e-04, 1.3245e-06, 5.0952e-07,\n",
      "        3.5833e-07, 3.4732e-07, 3.5422e-07, 3.3442e-06, 3.2379e-06, 3.3347e-06,\n",
      "        1.7841e-05, 1.7415e-05, 1.7423e-05, 3.0982e-06, 3.1956e-06, 1.0899e-05,\n",
      "        1.0942e-05, 2.6375e-01, 2.7965e-01, 1.0814e+00, 1.0658e+00, 3.0903e-06,\n",
      "        1.0901e-05, 2.6245e-01, 1.0827e+00, 2.4014e-01, 1.1055e+00, 2.9968e-01,\n",
      "        9.5665e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.6104, 273.4254, 293.7406, 275.4359,   7.2858,   7.3460,   7.4029,\n",
      "        427.9767, 427.9767, 427.9767,   7.3445,   7.3423, 427.9767, 427.9767,\n",
      "        427.9767, 427.9767, 427.9767,  71.2685,  71.2685,   7.3453, 427.9767,\n",
      "        427.9767, 427.9767, 427.9767, 427.9767,  71.2685,  71.2685, 427.9767,\n",
      "         71.2685,  71.2685,   5.2026, 427.9767, 427.9767, 427.9767, 427.9767,\n",
      "        427.9767,  71.2685,  71.2685, 427.9767,  71.2685,  71.2685,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 427.9767,   5.2026,   5.2025, 427.9767,   5.2026,\n",
      "          5.2025, 427.9767,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        427.9767, 427.9767, 427.9767, 427.9767,  71.2685,  71.2685,  71.2685,\n",
      "         71.2685, 427.9767, 427.9767, 427.9767,  71.2685,  71.2685,  71.2685,\n",
      "         71.2685,   5.2026,  71.2685,  71.2685,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 727 was 95.6%\n",
      "tensor([1.7339e-06, 7.6190e-06, 1.6240e-06, 1.0003e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3656e-06, 3.2358e-06, 3.3220e-06,\n",
      "        1.8358e-05, 1.7921e-05, 1.7682e-05, 3.0755e-06, 3.1962e-06, 1.1131e-05,\n",
      "        1.1220e-05, 2.6266e-01, 2.8044e-01, 1.0836e+00, 1.0659e+00, 3.0963e-06,\n",
      "        1.1178e-05, 2.6387e-01, 1.0826e+00, 2.3950e-01, 1.1072e+00, 3.0024e-01,\n",
      "        9.5661e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.8730, 273.6978, 294.0429, 275.6783,   7.2839,   7.3397,   7.3946,\n",
      "        428.3971, 428.3971, 428.3971,   7.3406,   7.3394, 428.3971, 428.3971,\n",
      "        428.3971, 428.3971, 428.3971,  71.3476,  71.3476,   7.3414, 428.3971,\n",
      "        428.3971, 428.3971, 428.3971, 428.3971,  71.3476,  71.3476, 428.3971,\n",
      "         71.3476,  71.3476,   5.2026, 428.3971, 428.3971, 428.3971, 428.3971,\n",
      "        428.3971,  71.3476,  71.3476, 428.3971,  71.3476,  71.3476,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 428.3971,   5.2026,   5.2025, 428.3971,   5.2026,\n",
      "          5.2025, 428.3971,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        428.3971, 428.3971, 428.3971, 428.3971,  71.3476,  71.3476,  71.3476,\n",
      "         71.3476, 428.3971, 428.3971, 428.3971,  71.3476,  71.3476,  71.3476,\n",
      "         71.3476,   5.2026,  71.3476,  71.3476,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 728 was 95.6%\n",
      "tensor([1.0716e-06, 4.0750e-06, 1.3682e-06, 6.1537e-05, 1.4823e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3721e-06, 3.2440e-06, 3.3153e-06,\n",
      "        1.8117e-05, 1.7697e-05, 1.7468e-05, 3.0817e-06, 3.2039e-06, 1.0992e-05,\n",
      "        1.1072e-05, 2.6206e-01, 2.7978e-01, 1.0810e+00, 1.0633e+00, 3.1000e-06,\n",
      "        1.1032e-05, 2.6316e-01, 1.0801e+00, 2.3906e-01, 1.1045e+00, 2.9948e-01,\n",
      "        9.5671e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.1379, 273.9748, 294.3440, 275.9233,   7.2819,   7.3367,   7.3861,\n",
      "        428.8175, 428.8175, 428.8175,   7.3359,   7.3363, 428.8175, 428.8175,\n",
      "        428.8175, 428.8175, 428.8175,  71.4268,  71.4268,   7.3355, 428.8175,\n",
      "        428.8175, 428.8175, 428.8175, 428.8175,  71.4268,  71.4268, 428.8175,\n",
      "         71.4268,  71.4268,   5.2026, 428.8175, 428.8175, 428.8175, 428.8175,\n",
      "        428.8175,  71.4268,  71.4268, 428.8175,  71.4268,  71.4268,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 428.8175,   5.2026,   5.2025, 428.8175,   5.2026,\n",
      "          5.2025, 428.8175,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        428.8175, 428.8175, 428.8175, 428.8175,  71.4268,  71.4268,  71.4268,\n",
      "         71.4268, 428.8175, 428.8175, 428.8175,  71.4268,  71.4268,  71.4268,\n",
      "         71.4268,   5.2026,  71.4268,  71.4268,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 729 was 95.6%\n",
      "tensor([6.8736e-07, 2.8442e-06, 1.2188e-06, 3.9107e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3616e-06, 3.2336e-06, 3.3087e-06,\n",
      "        1.7846e-05, 1.7439e-05, 1.7231e-05, 3.0747e-06, 3.1936e-06, 1.0836e-05,\n",
      "        1.0909e-05, 2.6152e-01, 2.7908e-01, 1.0783e+00, 1.0608e+00, 3.0914e-06,\n",
      "        1.0871e-05, 2.6244e-01, 1.0775e+00, 2.3854e-01, 1.1017e+00, 2.9871e-01,\n",
      "        9.5682e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.4008, 274.2535, 294.6480, 276.1685,   7.2802,   7.3308,   7.3765,\n",
      "        429.2378, 429.2378, 429.2378,   7.3325,   7.3310, 429.2378, 429.2378,\n",
      "        429.2378, 429.2378, 429.2378,  71.5059,  71.5059,   7.3337, 429.2378,\n",
      "        429.2378, 429.2378, 429.2378, 429.2378,  71.5059,  71.5059, 429.2378,\n",
      "         71.5059,  71.5059,   5.2026, 429.2378, 429.2378, 429.2378, 429.2378,\n",
      "        429.2378,  71.5059,  71.5059, 429.2378,  71.5059,  71.5059,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 429.2378,   5.2026,   5.2025, 429.2378,   5.2026,\n",
      "          5.2025, 429.2378,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        429.2378, 429.2378, 429.2378, 429.2378,  71.5059,  71.5059,  71.5059,\n",
      "         71.5059, 429.2378, 429.2378, 429.2378,  71.5059,  71.5059,  71.5059,\n",
      "         71.5059,   5.2026,  71.5059,  71.5059,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 730 was 95.6%\n",
      "tensor([0.0000e+00, 2.5596e-06, 2.2689e-06, 3.0493e-20, 2.3391e-06, 1.9866e-09,\n",
      "        1.3990e-09, 1.3610e-09, 1.3783e-09, 3.3517e-06, 3.2263e-06, 3.3021e-06,\n",
      "        1.7596e-05, 1.7206e-05, 1.7017e-05, 3.0689e-06, 3.1867e-06, 1.0689e-05,\n",
      "        1.0754e-05, 2.6096e-01, 2.7831e-01, 1.0757e+00, 1.0583e+00, 3.0829e-06,\n",
      "        1.0716e-05, 2.6174e-01, 1.0750e+00, 2.3813e-01, 1.0989e+00, 2.9794e-01,\n",
      "        9.5692e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.6625, 274.5348, 294.9482, 276.4192,   7.2782,   7.3274,   7.3679,\n",
      "        429.6582, 429.6582, 429.6582,   7.3275,   7.3281, 429.6582, 429.6582,\n",
      "        429.6582, 429.6582, 429.6582,  71.5850,  71.5850,   7.3278, 429.6582,\n",
      "        429.6582, 429.6582, 429.6582, 429.6582,  71.5850,  71.5850, 429.6582,\n",
      "         71.5850,  71.5850,   5.2026, 429.6582, 429.6582, 429.6582, 429.6582,\n",
      "        429.6582,  71.5850,  71.5850, 429.6582,  71.5850,  71.5850,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 429.6582,   5.2026,   5.2025, 429.6582,   5.2026,\n",
      "          5.2025, 429.6582,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        429.6582, 429.6582, 429.6582, 429.6582,  71.5850,  71.5850,  71.5850,\n",
      "         71.5850, 429.6582, 429.6582, 429.6582,  71.5850,  71.5850,  71.5850,\n",
      "         71.5850,   5.2026,  71.5850,  71.5850,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 731 was 95.7%\n",
      "tensor([2.9532e-07, 2.7424e-06, 8.8278e-07, 1.5773e-05, 4.6587e-21, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3416e-06, 3.2167e-06, 3.2953e-06,\n",
      "        1.7335e-05, 1.6956e-05, 1.6785e-05, 3.0624e-06, 3.1771e-06, 1.0534e-05,\n",
      "        1.0594e-05, 2.6040e-01, 2.7763e-01, 1.0730e+00, 1.0557e+00, 3.0748e-06,\n",
      "        1.0558e-05, 2.6101e-01, 1.0725e+00, 2.3760e-01, 1.0962e+00, 2.9715e-01,\n",
      "        9.5703e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.9227, 274.8161, 295.2487, 276.6703,   7.2762,   7.3240,   7.3591,\n",
      "        430.0786, 430.0786, 430.0786,   7.3234,   7.3222, 430.0786, 430.0786,\n",
      "        430.0786, 430.0786, 430.0786,  71.6642,  71.6642,   7.3241, 430.0786,\n",
      "        430.0786, 430.0786, 430.0786, 430.0786,  71.6642,  71.6642, 430.0786,\n",
      "         71.6642,  71.6642,   5.2026, 430.0786, 430.0786, 430.0786, 430.0786,\n",
      "        430.0786,  71.6642,  71.6642, 430.0786,  71.6642,  71.6642,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 430.0786,   5.2026,   5.2025, 430.0786,   5.2026,\n",
      "          5.2025, 430.0786,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        430.0786, 430.0786, 430.0786, 430.0786,  71.6642,  71.6642,  71.6642,\n",
      "         71.6642, 430.0786, 430.0786, 430.0786,  71.6642,  71.6642,  71.6642,\n",
      "         71.6642,   5.2026,  71.6642,  71.6642,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 732 was 95.7%\n",
      "tensor([8.7267e-06, 3.6973e-19, 1.2794e-05, 1.2377e-04, 2.3563e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3309e-06, 3.2070e-06, 3.2874e-06,\n",
      "        1.6966e-05, 1.6592e-05, 1.6454e-05, 3.0555e-06, 3.1683e-06, 1.0314e-05,\n",
      "        1.0376e-05, 2.5983e-01, 2.7680e-01, 1.0701e+00, 1.0532e+00, 3.0654e-06,\n",
      "        1.0333e-05, 2.6027e-01, 1.0698e+00, 2.3706e-01, 1.0933e+00, 2.9639e-01,\n",
      "        9.5714e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.1690, 275.1023, 295.5593, 276.9228,   7.2745,   7.3203,   7.3470,\n",
      "        430.4990, 430.4990, 430.4990,   7.3207,   7.3189, 430.4990, 430.4990,\n",
      "        430.4990, 430.4990, 430.4990,  71.7433,  71.7433,   7.3193, 430.4990,\n",
      "        430.4990, 430.4990, 430.4990, 430.4990,  71.7433,  71.7433, 430.4990,\n",
      "         71.7433,  71.7433,   5.2026, 430.4990, 430.4990, 430.4990, 430.4990,\n",
      "        430.4990,  71.7433,  71.7433, 430.4990,  71.7433,  71.7433,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 430.4990,   5.2026,   5.2025, 430.4990,   5.2026,\n",
      "          5.2025, 430.4990,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        430.4990, 430.4990, 430.4990, 430.4990,  71.7433,  71.7433,  71.7433,\n",
      "         71.7433, 430.4990, 430.4990, 430.4990,  71.7433,  71.7433,  71.7433,\n",
      "         71.7433,   5.2026,  71.7433,  71.7433,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 733 was 95.7%\n",
      "tensor([0.0000e+00, 9.1480e-20, 5.2648e-06, 7.0006e-05, 6.4911e-06, 4.4224e-07,\n",
      "        3.1050e-07, 3.0122e-07, 3.0650e-07, 3.3060e-06, 3.1929e-06, 3.2821e-06,\n",
      "        1.6780e-05, 1.6423e-05, 1.6310e-05, 3.0478e-06, 3.1549e-06, 1.0202e-05,\n",
      "        1.0253e-05, 2.5940e-01, 2.7605e-01, 1.0673e+00, 1.0507e+00, 3.0555e-06,\n",
      "        1.0215e-05, 2.5951e-01, 1.0673e+00, 2.3666e-01, 1.0905e+00, 2.9555e-01,\n",
      "        9.5724e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.4234, 275.3855, 295.8641, 277.1734,   7.2727,   7.3153,   7.3359,\n",
      "        430.9193, 430.9193, 430.9193,   7.3156,   7.3158, 430.9193, 430.9193,\n",
      "        430.9193, 430.9193, 430.9193,  71.8224,  71.8224,   7.3172, 430.9193,\n",
      "        430.9193, 430.9193, 430.9193, 430.9193,  71.8224,  71.8224, 430.9193,\n",
      "         71.8224,  71.8224,   5.2026, 430.9193, 430.9193, 430.9193, 430.9193,\n",
      "        430.9193,  71.8224,  71.8224, 430.9193,  71.8224,  71.8224,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 430.9193,   5.2026,   5.2025, 430.9193,   5.2026,\n",
      "          5.2025, 430.9193,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        430.9193, 430.9193, 430.9193, 430.9193,  71.8224,  71.8224,  71.8224,\n",
      "         71.8224, 430.9193, 430.9193, 430.9193,  71.8224,  71.8224,  71.8224,\n",
      "         71.8224,   5.2026,  71.8224,  71.8224,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 734 was 95.7%\n",
      "tensor([0.0000e+00, 0.0000e+00, 3.1682e-06, 9.6588e-05, 1.8809e-06, 6.0795e-07,\n",
      "        4.2651e-07, 4.1386e-07, 4.2128e-07, 3.2158e-06, 3.1614e-06, 3.2763e-06,\n",
      "        1.6383e-05, 1.6036e-05, 1.5959e-05, 3.0404e-06, 3.1326e-06, 9.9720e-06,\n",
      "        1.0018e-05, 2.5874e-01, 2.7520e-01, 1.0644e+00, 1.0480e+00, 3.0474e-06,\n",
      "        9.9736e-06, 2.5869e-01, 1.0645e+00, 2.3616e-01, 1.0874e+00, 2.9475e-01,\n",
      "        9.5736e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.6672, 275.6738, 296.1754, 277.4272,   7.2712,   7.3131,   7.3229,\n",
      "        431.3397, 431.3397, 431.3397,   7.3136,   7.3116, 431.3397, 431.3397,\n",
      "        431.3397, 431.3397, 431.3397,  71.9015,  71.9015,   7.3116, 431.3397,\n",
      "        431.3397, 431.3397, 431.3397, 431.3397,  71.9015,  71.9015, 431.3397,\n",
      "         71.9015,  71.9015,   5.2026, 431.3397, 431.3397, 431.3397, 431.3397,\n",
      "        431.3397,  71.9015,  71.9015, 431.3397,  71.9015,  71.9015,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 431.3397,   5.2026,   5.2025, 431.3397,   5.2026,\n",
      "          5.2025, 431.3397,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        431.3397, 431.3397, 431.3397, 431.3397,  71.9015,  71.9015,  71.9015,\n",
      "         71.9015, 431.3397, 431.3397, 431.3397,  71.9015,  71.9015,  71.9015,\n",
      "         71.9015,   5.2026,  71.9015,  71.9015,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 735 was 95.7%\n",
      "tensor([7.7871e-06, 0.0000e+00, 2.0562e-05, 1.1349e-04, 4.3894e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2984e-06, 3.1782e-06, 3.2695e-06,\n",
      "        1.6179e-05, 1.5851e-05, 1.5799e-05, 3.0377e-06, 3.1395e-06, 9.8486e-06,\n",
      "        9.8875e-06, 2.5838e-01, 2.7440e-01, 1.0615e+00, 1.0454e+00, 3.0381e-06,\n",
      "        9.8472e-06, 2.5791e-01, 1.0620e+00, 2.3574e-01, 1.0846e+00, 2.9390e-01,\n",
      "        9.5746e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.9127, 275.9338, 296.4854, 277.6951,   7.2702,   7.2614,   7.3581,\n",
      "        431.7601, 431.7601, 431.7601,   7.3070,   7.3088, 431.7601, 431.7601,\n",
      "        431.7601, 431.7601, 431.7601,  71.9807,  71.9807,   7.3099, 431.7601,\n",
      "        431.7601, 431.7601, 431.7601, 431.7601,  71.9807,  71.9807, 431.7601,\n",
      "         71.9807,  71.9807,   5.2026, 431.7601, 431.7601, 431.7601, 431.7601,\n",
      "        431.7601,  71.9807,  71.9807, 431.7601,  71.9807,  71.9807,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 431.7601,   5.2026,   5.2025, 431.7601,   5.2026,\n",
      "          5.2025, 431.7601,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        431.7601, 431.7601, 431.7601, 431.7601,  71.9807,  71.9807,  71.9807,\n",
      "         71.9807, 431.7601, 431.7601, 431.7601,  71.9807,  71.9807,  71.9807,\n",
      "         71.9807,   5.2026,  71.9807,  71.9807,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 736 was 95.7%\n",
      "tensor([6.4863e-06, 6.0986e-20, 1.3541e-05, 9.4173e-05, 2.5031e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2950e-06, 3.1948e-06, 3.2592e-06,\n",
      "        1.6406e-05, 1.6101e-05, 1.5815e-05, 3.0132e-06, 3.1445e-06, 9.9769e-06,\n",
      "        1.0016e-05, 2.5675e-01, 2.7520e-01, 1.0622e+00, 1.0438e+00, 3.0402e-06,\n",
      "        9.9970e-06, 2.5819e-01, 1.0609e+00, 2.3517e-01, 1.0842e+00, 2.9409e-01,\n",
      "        9.5749e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.1702, 276.2153, 296.7873, 277.9468,   7.2668,   7.2598,   7.3489,\n",
      "        432.1804, 432.1804, 432.1804,   7.3029,   7.3049, 432.1804, 432.1804,\n",
      "        432.1804, 432.1804, 432.1804,  72.0598,  72.0598,   7.3039, 432.1804,\n",
      "        432.1804, 432.1804, 432.1804, 432.1804,  72.0598,  72.0598, 432.1804,\n",
      "         72.0598,  72.0598,   5.2026, 432.1804, 432.1804, 432.1804, 432.1804,\n",
      "        432.1804,  72.0598,  72.0598, 432.1804,  72.0598,  72.0598,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 432.1804,   5.2026,   5.2025, 432.1804,   5.2026,\n",
      "          5.2025, 432.1804,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        432.1804, 432.1804, 432.1804, 432.1804,  72.0598,  72.0598,  72.0598,\n",
      "         72.0598, 432.1804, 432.1804, 432.1804,  72.0598,  72.0598,  72.0598,\n",
      "         72.0598,   5.2026,  72.0598,  72.0598,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(41.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 737 was 95.8%\n",
      "tensor([0.0000e+00, 1.5615e-03, 2.2585e-04, 2.0185e-02, 6.2335e-04, 0.0000e+00,\n",
      "        5.6877e-06, 1.4033e-05, 6.0569e-06, 5.8255e-06, 5.1621e-06, 3.0977e-06,\n",
      "        1.3611e-06, 3.3881e-21, 1.4067e-06, 4.2681e-06, 4.7447e-06, 1.1947e-06,\n",
      "        2.0658e-06, 2.4757e-01, 2.6527e-01, 1.0346e+00, 1.0364e+00, 4.1177e-06,\n",
      "        1.1368e-06, 2.4871e-01, 1.0332e+00, 2.2669e-01, 1.0569e+00, 2.9380e-01,\n",
      "        9.5839e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.4227, 276.7051, 296.7885, 278.2658,   7.2178,   7.2630,   7.5547,\n",
      "        432.6008, 432.6008, 432.6008,   7.2602,   7.2434, 432.6008, 432.6008,\n",
      "        432.6008, 432.6008, 432.6008,  72.1389,  72.1389,   7.2209, 432.6008,\n",
      "        432.6008, 432.6008, 432.6008, 432.6008,  72.1389,  72.1389, 432.6008,\n",
      "         72.1389,  72.1389,   5.2026, 432.6008, 432.6008, 432.6008, 432.6008,\n",
      "        432.6008,  72.1389,  72.1389, 432.6008,  72.1389,  72.1389,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 432.6008,   5.2026,   5.2025, 432.6008,   5.2026,\n",
      "          5.2025, 432.6008,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        432.6008, 432.6008, 432.6008, 432.6008,  72.1389,  72.1389,  72.1389,\n",
      "         72.1389, 432.6008, 432.6008, 432.6008,  72.1389,  72.1389,  72.1389,\n",
      "         72.1389,   5.2026,  72.1389,  72.1389,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 738 was 95.7%\n",
      "tensor([5.3784e-06, 2.5668e-06, 1.2451e-19, 3.0234e-04, 1.2178e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3674e-06, 3.2438e-06, 3.1934e-06,\n",
      "        1.7181e-05, 1.6873e-05, 1.5757e-05, 2.9777e-06, 3.2128e-06, 1.0175e-05,\n",
      "        1.0512e-05, 2.5346e-01, 2.7879e-01, 1.0679e+00, 1.0429e+00, 3.1165e-06,\n",
      "        1.0502e-05, 2.6242e-01, 1.0593e+00, 2.3046e-01, 1.0913e+00, 2.9663e-01,\n",
      "        9.5739e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.4724, 277.3232, 299.1564, 278.1759,   7.2093,   7.2583,   7.5354,\n",
      "        433.0211, 433.0211, 433.0211,   7.2714,   7.2379, 433.0211, 433.0211,\n",
      "        433.0211, 433.0211, 433.0211,  72.2181,  72.2181,   7.2231, 433.0211,\n",
      "        433.0211, 433.0211, 433.0211, 433.0211,  72.2181,  72.2181, 433.0211,\n",
      "         72.2181,  72.2181,   5.2026, 433.0211, 433.0211, 433.0211, 433.0211,\n",
      "        433.0211,  72.2181,  72.2181, 433.0211,  72.2181,  72.2181,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 433.0211,   5.2026,   5.2025, 433.0211,   5.2026,\n",
      "          5.2025, 433.0211,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        433.0211, 433.0211, 433.0211, 433.0211,  72.2181,  72.2181,  72.2181,\n",
      "         72.2181, 433.0211, 433.0211, 433.0211,  72.2181,  72.2181,  72.2181,\n",
      "         72.2181,   5.2026,  72.2181,  72.2181,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 739 was 95.7%\n",
      "tensor([1.7512e-06, 9.6854e-06, 1.7952e-06, 1.0140e-04, 1.4908e-19, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3868e-06, 3.2542e-06, 3.1988e-06,\n",
      "        1.7575e-05, 1.7433e-05, 1.6288e-05, 2.9743e-06, 3.2219e-06, 1.0009e-05,\n",
      "        1.0403e-05, 2.5339e-01, 2.7969e-01, 1.0655e+00, 1.0392e+00, 3.1129e-06,\n",
      "        1.0417e-05, 2.6189e-01, 1.0572e+00, 2.2888e-01, 1.0903e+00, 2.9533e-01,\n",
      "        9.5748e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.6615, 277.5959, 299.3999, 278.4258,   7.2072,   7.2529,   7.5267,\n",
      "        433.4415, 433.4415, 433.4415,   7.2653,   7.2338, 433.4415, 433.4415,\n",
      "        433.4415, 433.4415, 433.4415,  72.2972,  72.2972,   7.2210, 433.4415,\n",
      "        433.4415, 433.4415, 433.4415, 433.4415,  72.2972,  72.2972, 433.4415,\n",
      "         72.2972,  72.2972,   5.2026, 433.4415, 433.4415, 433.4415, 433.4415,\n",
      "        433.4415,  72.2972,  72.2972, 433.4415,  72.2972,  72.2972,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 433.4415,   5.2026,   5.2025, 433.4415,   5.2026,\n",
      "          5.2025, 433.4415,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        433.4415, 433.4415, 433.4415, 433.4415,  72.2972,  72.2972,  72.2972,\n",
      "         72.2972, 433.4415, 433.4415, 433.4415,  72.2972,  72.2972,  72.2972,\n",
      "         72.2972,   5.2026,  72.2972,  72.2972,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 740 was 95.7%\n",
      "tensor([1.1895e-06, 5.5882e-06, 1.5245e-06, 6.8816e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3645e-06, 3.2314e-06, 3.1965e-06,\n",
      "        1.7361e-05, 1.7231e-05, 1.6108e-05, 2.9552e-06, 3.1999e-06, 9.8885e-06,\n",
      "        1.0267e-05, 2.5285e-01, 2.7902e-01, 1.0630e+00, 1.0369e+00, 3.0917e-06,\n",
      "        1.0281e-05, 2.6127e-01, 1.0548e+00, 2.2841e-01, 1.0877e+00, 2.9460e-01,\n",
      "        9.5758e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([235.8552, 277.8710, 299.6440, 278.6771,   7.2051,   7.2475,   7.5180,\n",
      "        433.8619, 433.8619, 433.8619,   7.2592,   7.2297, 433.8619, 433.8619,\n",
      "        433.8619, 433.8619, 433.8619,  72.3763,  72.3763,   7.2190, 433.8619,\n",
      "        433.8619, 433.8619, 433.8619, 433.8619,  72.3763,  72.3763, 433.8619,\n",
      "         72.3763,  72.3763,   5.2026, 433.8619, 433.8619, 433.8619, 433.8619,\n",
      "        433.8619,  72.3763,  72.3763, 433.8619,  72.3763,  72.3763,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 433.8619,   5.2026,   5.2025, 433.8619,   5.2026,\n",
      "          5.2025, 433.8619,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        433.8619, 433.8619, 433.8619, 433.8619,  72.3763,  72.3763,  72.3763,\n",
      "         72.3763, 433.8619, 433.8619, 433.8619,  72.3763,  72.3763,  72.3763,\n",
      "         72.3763,   5.2026,  72.3763,  72.3763,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 741 was 95.7%\n",
      "tensor([8.8940e-07, 3.9141e-06, 1.3754e-06, 5.1374e-05, 6.4375e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3506e-06, 3.2188e-06, 3.1915e-06,\n",
      "        1.7134e-05, 1.7015e-05, 1.5919e-05, 2.9454e-06, 3.1872e-06, 9.7617e-06,\n",
      "        1.0126e-05, 2.5230e-01, 2.7833e-01, 1.0605e+00, 1.0345e+00, 3.0789e-06,\n",
      "        1.0139e-05, 2.6065e-01, 1.0524e+00, 2.2794e-01, 1.0851e+00, 2.9387e-01,\n",
      "        9.5767e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.0505, 278.1471, 299.8887, 278.9289,   7.2030,   7.2420,   7.5091,\n",
      "        434.2822, 434.2822, 434.2822,   7.2531,   7.2255, 434.2822, 434.2822,\n",
      "        434.2822, 434.2822, 434.2822,  72.4554,  72.4554,   7.2169, 434.2822,\n",
      "        434.2822, 434.2822, 434.2822, 434.2822,  72.4554,  72.4554, 434.2822,\n",
      "         72.4554,  72.4554,   5.2026, 434.2822, 434.2822, 434.2822, 434.2822,\n",
      "        434.2822,  72.4554,  72.4554, 434.2822,  72.4554,  72.4554,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 434.2822,   5.2026,   5.2025, 434.2822,   5.2026,\n",
      "          5.2025, 434.2822,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        434.2822, 434.2822, 434.2822, 434.2822,  72.4554,  72.4554,  72.4554,\n",
      "         72.4554, 434.2822, 434.2822, 434.2822,  72.4554,  72.4554,  72.4554,\n",
      "         72.4554,   5.2026,  72.4554,  72.4554,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 742 was 95.7%\n",
      "tensor([7.0413e-07, 3.1632e-06, 1.2808e-06, 4.0582e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3393e-06, 3.2094e-06, 3.1857e-06,\n",
      "        1.6903e-05, 1.6795e-05, 1.5725e-05, 2.9385e-06, 3.1774e-06, 9.6327e-06,\n",
      "        9.9822e-06, 2.5175e-01, 2.7764e-01, 1.0579e+00, 1.0321e+00, 3.0687e-06,\n",
      "        9.9938e-06, 2.6001e-01, 1.0499e+00, 2.2746e-01, 1.0825e+00, 2.9314e-01,\n",
      "        9.5777e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.2467, 278.4238, 300.1339, 279.1809,   7.2009,   7.2364,   7.5001,\n",
      "        434.7026, 434.7026, 434.7026,   7.2469,   7.2212, 434.7026, 434.7026,\n",
      "        434.7026, 434.7026, 434.7026,  72.5346,  72.5346,   7.2149, 434.7026,\n",
      "        434.7026, 434.7026, 434.7026, 434.7026,  72.5346,  72.5346, 434.7026,\n",
      "         72.5346,  72.5346,   5.2026, 434.7026, 434.7026, 434.7026, 434.7026,\n",
      "        434.7026,  72.5346,  72.5346, 434.7026,  72.5346,  72.5346,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 434.7026,   5.2026,   5.2025, 434.7026,   5.2026,\n",
      "          5.2025, 434.7026,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        434.7026, 434.7026, 434.7026, 434.7026,  72.5346,  72.5346,  72.5346,\n",
      "         72.5346, 434.7026, 434.7026, 434.7026,  72.5346,  72.5346,  72.5346,\n",
      "         72.5346,   5.2026,  72.5346,  72.5346,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 743 was 95.7%\n",
      "tensor([5.7878e-07, 2.8160e-06, 1.2151e-06, 3.3263e-05, 2.5411e-21, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3289e-06, 3.2009e-06, 3.1795e-06,\n",
      "        1.6671e-05, 1.6572e-05, 1.5529e-05, 2.9326e-06, 3.1685e-06, 9.5028e-06,\n",
      "        9.8382e-06, 2.5119e-01, 2.7694e-01, 1.0554e+00, 1.0296e+00, 3.0593e-06,\n",
      "        9.8485e-06, 2.5938e-01, 1.0475e+00, 2.2699e-01, 1.0799e+00, 2.9240e-01,\n",
      "        9.5788e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.4433, 278.7010, 300.3797, 279.4332,   7.1987,   7.2309,   7.4911,\n",
      "        435.1229, 435.1229, 435.1229,   7.2408,   7.2170, 435.1229, 435.1229,\n",
      "        435.1229, 435.1229, 435.1229,  72.6137,  72.6137,   7.2128, 435.1229,\n",
      "        435.1229, 435.1229, 435.1229, 435.1229,  72.6137,  72.6137, 435.1229,\n",
      "         72.6137,  72.6137,   5.2026, 435.1229, 435.1229, 435.1229, 435.1229,\n",
      "        435.1229,  72.6137,  72.6137, 435.1229,  72.6137,  72.6137,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 435.1229,   5.2026,   5.2025, 435.1229,   5.2026,\n",
      "          5.2025, 435.1229,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        435.1229, 435.1229, 435.1229, 435.1229,  72.6137,  72.6137,  72.6137,\n",
      "         72.6137, 435.1229, 435.1229, 435.1229,  72.6137,  72.6137,  72.6137,\n",
      "         72.6137,   5.2026,  72.6137,  72.6137,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 744 was 95.7%\n",
      "tensor([4.8853e-07, 2.6596e-06, 1.1667e-06, 2.7980e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3187e-06, 3.1927e-06, 3.1731e-06,\n",
      "        1.6438e-05, 1.6349e-05, 1.5333e-05, 2.9269e-06, 3.1598e-06, 9.3728e-06,\n",
      "        9.6944e-06, 2.5064e-01, 2.7624e-01, 1.0528e+00, 1.0272e+00, 3.0501e-06,\n",
      "        9.7033e-06, 2.5874e-01, 1.0450e+00, 2.2651e-01, 1.0773e+00, 2.9167e-01,\n",
      "        9.5798e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.6401, 278.9785, 300.6260, 279.6855,   7.1966,   7.2254,   7.4821,\n",
      "        435.5433, 435.5433, 435.5433,   7.2346,   7.2127, 435.5433, 435.5433,\n",
      "        435.5433, 435.5433, 435.5433,  72.6928,  72.6928,   7.2107, 435.5433,\n",
      "        435.5433, 435.5433, 435.5433, 435.5433,  72.6928,  72.6928, 435.5433,\n",
      "         72.6928,  72.6928,   5.2026, 435.5433, 435.5433, 435.5433, 435.5433,\n",
      "        435.5433,  72.6928,  72.6928, 435.5433,  72.6928,  72.6928,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 435.5433,   5.2026,   5.2025, 435.5433,   5.2026,\n",
      "          5.2025, 435.5433,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        435.5433, 435.5433, 435.5433, 435.5433,  72.6928,  72.6928,  72.6928,\n",
      "         72.6928, 435.5433, 435.5433, 435.5433,  72.6928,  72.6928,  72.6928,\n",
      "         72.6928,   5.2026,  72.6928,  72.6928,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 745 was 95.8%\n",
      "tensor([2.7533e-07, 2.6890e-06, 9.4163e-07, 1.4882e-05, 1.6941e-21, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3088e-06, 3.1849e-06, 3.1668e-06,\n",
      "        1.6222e-05, 1.6143e-05, 1.5151e-05, 2.9216e-06, 3.1515e-06, 9.2514e-06,\n",
      "        9.5591e-06, 2.5009e-01, 2.7555e-01, 1.0503e+00, 1.0248e+00, 3.0413e-06,\n",
      "        9.5676e-06, 2.5811e-01, 1.0425e+00, 2.2604e-01, 1.0747e+00, 2.9093e-01,\n",
      "        9.5808e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([236.8371, 279.2568, 300.8730, 279.9383,   7.1944,   7.2198,   7.4729,\n",
      "        435.9636, 435.9636, 435.9636,   7.2284,   7.2084, 435.9636, 435.9636,\n",
      "        435.9636, 435.9636, 435.9636,  72.7720,  72.7720,   7.2087, 435.9636,\n",
      "        435.9636, 435.9636, 435.9636, 435.9636,  72.7720,  72.7720, 435.9636,\n",
      "         72.7720,  72.7720,   5.2026, 435.9636, 435.9636, 435.9636, 435.9636,\n",
      "        435.9636,  72.7720,  72.7720, 435.9636,  72.7720,  72.7720,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 435.9636,   5.2026,   5.2025, 435.9636,   5.2026,\n",
      "          5.2025, 435.9636,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        435.9636, 435.9636, 435.9636, 435.9636,  72.7720,  72.7720,  72.7720,\n",
      "         72.7720, 435.9636, 435.9636, 435.9636,  72.7720,  72.7720,  72.7720,\n",
      "         72.7720,   5.2026,  72.7720,  72.7720,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 746 was 95.8%\n",
      "tensor([1.7890e-07, 3.8658e-06, 8.1571e-07, 1.0079e-05, 1.0164e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2958e-06, 3.1737e-06, 3.1612e-06,\n",
      "        1.5999e-05, 1.5929e-05, 1.4962e-05, 2.9131e-06, 3.1399e-06, 9.1256e-06,\n",
      "        9.4200e-06, 2.4954e-01, 2.7485e-01, 1.0478e+00, 1.0224e+00, 3.0293e-06,\n",
      "        9.4275e-06, 2.5747e-01, 1.0401e+00, 2.2556e-01, 1.0720e+00, 2.9020e-01,\n",
      "        9.5818e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.0340, 279.5356, 301.1207, 280.1911,   7.1922,   7.2142,   7.4638,\n",
      "        436.3840, 436.3840, 436.3840,   7.2222,   7.2050, 436.3840, 436.3840,\n",
      "        436.3840, 436.3840, 436.3840,  72.8511,  72.8511,   7.2056, 436.3840,\n",
      "        436.3840, 436.3840, 436.3840, 436.3840,  72.8511,  72.8511, 436.3840,\n",
      "         72.8511,  72.8511,   5.2026, 436.3840, 436.3840, 436.3840, 436.3840,\n",
      "        436.3840,  72.8511,  72.8511, 436.3840,  72.8511,  72.8511,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 436.3840,   5.2026,   5.2025, 436.3840,   5.2026,\n",
      "          5.2025, 436.3840,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        436.3840, 436.3840, 436.3840, 436.3840,  72.8511,  72.8511,  72.8511,\n",
      "         72.8511, 436.3840, 436.3840, 436.3840,  72.8511,  72.8511,  72.8511,\n",
      "         72.8511,   5.2026,  72.8511,  72.8511,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 747 was 95.8%\n",
      "tensor([5.9833e-06, 1.6094e-20, 1.2886e-05, 8.8599e-05, 2.5926e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2794e-06, 3.1582e-06, 3.1571e-06,\n",
      "        1.5776e-05, 1.5714e-05, 1.4775e-05, 2.9010e-06, 3.1243e-06, 9.0005e-06,\n",
      "        9.2816e-06, 2.4898e-01, 2.7417e-01, 1.0452e+00, 1.0201e+00, 3.0140e-06,\n",
      "        9.2882e-06, 2.5681e-01, 1.0376e+00, 2.2510e-01, 1.0694e+00, 2.8946e-01,\n",
      "        9.5828e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.2304, 279.8143, 301.3691, 280.4438,   7.1900,   7.2085,   7.4545,\n",
      "        436.8043, 436.8043, 436.8043,   7.2159,   7.2017, 436.8043, 436.8043,\n",
      "        436.8043, 436.8043, 436.8043,  72.9302,  72.9302,   7.2025, 436.8043,\n",
      "        436.8043, 436.8043, 436.8043, 436.8043,  72.9302,  72.9302, 436.8043,\n",
      "         72.9302,  72.9302,   5.2026, 436.8043, 436.8043, 436.8043, 436.8043,\n",
      "        436.8043,  72.9302,  72.9302, 436.8043,  72.9302,  72.9302,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 436.8043,   5.2026,   5.2025, 436.8043,   5.2026,\n",
      "          5.2025, 436.8043,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        436.8043, 436.8043, 436.8043, 436.8043,  72.9302,  72.9302,  72.9302,\n",
      "         72.9302, 436.8043, 436.8043, 436.8043,  72.9302,  72.9302,  72.9302,\n",
      "         72.9302,   5.2026,  72.9302,  72.9302,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 748 was 95.8%\n",
      "tensor([6.1721e-06, 3.3034e-20, 1.3469e-05, 9.1943e-05, 2.7000e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2714e-06, 3.1522e-06, 3.1507e-06,\n",
      "        1.5547e-05, 1.5492e-05, 1.4581e-05, 2.8977e-06, 3.1175e-06, 8.8722e-06,\n",
      "        9.1399e-06, 2.4842e-01, 2.7348e-01, 1.0427e+00, 1.0177e+00, 3.0073e-06,\n",
      "        9.1458e-06, 2.5616e-01, 1.0352e+00, 2.2463e-01, 1.0668e+00, 2.8872e-01,\n",
      "        9.5838e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.4265, 280.0934, 301.6182, 280.6965,   7.1878,   7.2029,   7.4453,\n",
      "        437.2247, 437.2247, 437.2247,   7.2097,   7.1983, 437.2247, 437.2247,\n",
      "        437.2247, 437.2247, 437.2247,  73.0093,  73.0093,   7.1994, 437.2247,\n",
      "        437.2247, 437.2247, 437.2247, 437.2247,  73.0093,  73.0093, 437.2247,\n",
      "         73.0093,  73.0093,   5.2026, 437.2247, 437.2247, 437.2247, 437.2247,\n",
      "        437.2247,  73.0093,  73.0093, 437.2247,  73.0093,  73.0093,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 437.2247,   5.2026,   5.2025, 437.2247,   5.2026,\n",
      "          5.2025, 437.2247,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        437.2247, 437.2247, 437.2247, 437.2247,  73.0093,  73.0093,  73.0093,\n",
      "         73.0093, 437.2247, 437.2247, 437.2247,  73.0093,  73.0093,  73.0093,\n",
      "         73.0093,   5.2026,  73.0093,  73.0093,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 749 was 95.8%\n",
      "tensor([6.3755e-06, 5.5057e-21, 1.4096e-05, 9.5549e-05, 2.8155e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2636e-06, 3.1464e-06, 3.1443e-06,\n",
      "        1.5319e-05, 1.5271e-05, 1.4387e-05, 2.8945e-06, 3.1109e-06, 8.7446e-06,\n",
      "        8.9993e-06, 2.4786e-01, 2.7280e-01, 1.0401e+00, 1.0152e+00, 3.0007e-06,\n",
      "        9.0045e-06, 2.5550e-01, 1.0327e+00, 2.2416e-01, 1.0641e+00, 2.8798e-01,\n",
      "        9.5848e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.6221, 280.3728, 301.8681, 280.9492,   7.1856,   7.1972,   7.4359,\n",
      "        437.6450, 437.6450, 437.6450,   7.2034,   7.1949, 437.6450, 437.6450,\n",
      "        437.6450, 437.6450, 437.6450,  73.0885,  73.0885,   7.1963, 437.6450,\n",
      "        437.6450, 437.6450, 437.6450, 437.6450,  73.0885,  73.0885, 437.6450,\n",
      "         73.0885,  73.0885,   5.2026, 437.6450, 437.6450, 437.6450, 437.6450,\n",
      "        437.6450,  73.0885,  73.0885, 437.6450,  73.0885,  73.0885,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 437.6450,   5.2026,   5.2025, 437.6450,   5.2026,\n",
      "          5.2025, 437.6450,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        437.6450, 437.6450, 437.6450, 437.6450,  73.0885,  73.0885,  73.0885,\n",
      "         73.0885, 437.6450, 437.6450, 437.6450,  73.0885,  73.0885,  73.0885,\n",
      "         73.0885,   5.2026,  73.0885,  73.0885,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 750 was 95.8%\n",
      "tensor([6.5955e-06, 0.0000e+00, 1.4774e-05, 9.9450e-05, 2.9402e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2560e-06, 3.1408e-06, 3.1379e-06,\n",
      "        1.5093e-05, 1.5051e-05, 1.4195e-05, 2.8916e-06, 3.1045e-06, 8.6176e-06,\n",
      "        8.8597e-06, 2.4730e-01, 2.7211e-01, 1.0376e+00, 1.0128e+00, 2.9943e-06,\n",
      "        8.8643e-06, 2.5483e-01, 1.0303e+00, 2.2369e-01, 1.0615e+00, 2.8724e-01,\n",
      "        9.5858e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([237.8170, 280.6526, 302.1188, 281.2018,   7.1834,   7.1915,   7.4266,\n",
      "        438.0654, 438.0654, 438.0654,   7.1972,   7.1915, 438.0654, 438.0654,\n",
      "        438.0654, 438.0654, 438.0654,  73.1676,  73.1676,   7.1932, 438.0654,\n",
      "        438.0654, 438.0654, 438.0654, 438.0654,  73.1676,  73.1676, 438.0654,\n",
      "         73.1676,  73.1676,   5.2026, 438.0654, 438.0654, 438.0654, 438.0654,\n",
      "        438.0654,  73.1676,  73.1676, 438.0654,  73.1676,  73.1676,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 438.0654,   5.2026,   5.2025, 438.0654,   5.2026,\n",
      "          5.2025, 438.0654,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        438.0654, 438.0654, 438.0654, 438.0654,  73.1676,  73.1676,  73.1676,\n",
      "         73.1676, 438.0654, 438.0654, 438.0654,  73.1676,  73.1676,  73.1676,\n",
      "         73.1676,   5.2026,  73.1676,  73.1676,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 751 was 95.8%\n",
      "tensor([6.8348e-06, 1.5840e-19, 1.5495e-05, 1.0368e-04, 3.0747e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2487e-06, 3.1354e-06, 3.1319e-06,\n",
      "        1.4869e-05, 1.4834e-05, 1.4006e-05, 2.8888e-06, 3.0983e-06, 8.4941e-06,\n",
      "        8.7217e-06, 2.4674e-01, 2.7142e-01, 1.0350e+00, 1.0104e+00, 2.9882e-06,\n",
      "        8.7253e-06, 2.5419e-01, 1.0278e+00, 2.2322e-01, 1.0588e+00, 2.8652e-01,\n",
      "        9.5868e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.0112, 280.9328, 302.3706, 281.4544,   7.1811,   7.1881,   7.4171,\n",
      "        438.4857, 438.4857, 438.4857,   7.1909,   7.1881, 438.4857, 438.4857,\n",
      "        438.4857, 438.4857, 438.4857,  73.2467,  73.2467,   7.1877, 438.4857,\n",
      "        438.4857, 438.4857, 438.4857, 438.4857,  73.2467,  73.2467, 438.4857,\n",
      "         73.2467,  73.2467,   5.2026, 438.4857, 438.4857, 438.4857, 438.4857,\n",
      "        438.4857,  73.2467,  73.2467, 438.4857,  73.2467,  73.2467,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 438.4857,   5.2026,   5.2025, 438.4857,   5.2026,\n",
      "          5.2025, 438.4857,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        438.4857, 438.4857, 438.4857, 438.4857,  73.2467,  73.2467,  73.2467,\n",
      "         73.2467, 438.4857, 438.4857, 438.4857,  73.2467,  73.2467,  73.2467,\n",
      "         73.2467,   5.2026,  73.2467,  73.2467,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 752 was 95.8%\n",
      "tensor([7.0845e-06, 4.3495e-19, 1.6281e-05, 1.0814e-04, 3.2139e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2418e-06, 3.1293e-06, 3.1256e-06,\n",
      "        1.4646e-05, 1.4616e-05, 1.3818e-05, 2.8862e-06, 3.0920e-06, 8.3694e-06,\n",
      "        8.5845e-06, 2.4622e-01, 2.7073e-01, 1.0324e+00, 1.0080e+00, 2.9830e-06,\n",
      "        8.5883e-06, 2.5353e-01, 1.0254e+00, 2.2270e-01, 1.0563e+00, 2.8578e-01,\n",
      "        9.5878e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.2044, 281.2135, 302.6235, 281.7069,   7.1788,   7.1824,   7.4076,\n",
      "        438.9061, 438.9061, 438.9061,   7.1846,   7.1836, 438.9061, 438.9061,\n",
      "        438.9061, 438.9061, 438.9061,  73.3258,  73.3258,   7.1856, 438.9061,\n",
      "        438.9061, 438.9061, 438.9061, 438.9061,  73.3258,  73.3258, 438.9061,\n",
      "         73.3258,  73.3258,   5.2026, 438.9061, 438.9061, 438.9061, 438.9061,\n",
      "        438.9061,  73.3258,  73.3258, 438.9061,  73.3258,  73.3258,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 438.9061,   5.2026,   5.2025, 438.9061,   5.2026,\n",
      "          5.2025, 438.9061,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        438.9061, 438.9061, 438.9061, 438.9061,  73.3258,  73.3258,  73.3258,\n",
      "         73.3258, 438.9061, 438.9061, 438.9061,  73.3258,  73.3258,  73.3258,\n",
      "         73.3258,   5.2026,  73.3258,  73.3258,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 753 was 95.8%\n",
      "tensor([7.3895e-06, 0.0000e+00, 1.7136e-05, 1.1348e-04, 3.3765e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2352e-06, 3.1250e-06, 3.1197e-06,\n",
      "        1.4423e-05, 1.4399e-05, 1.3631e-05, 2.8845e-06, 3.0873e-06, 8.2470e-06,\n",
      "        8.4476e-06, 2.4566e-01, 2.7001e-01, 1.0299e+00, 1.0056e+00, 2.9776e-06,\n",
      "        8.4494e-06, 2.5291e-01, 1.0229e+00, 2.2225e-01, 1.0536e+00, 2.8507e-01,\n",
      "        9.5888e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.3964, 281.4948, 302.8778, 281.9594,   7.1766,   7.1790,   7.3981,\n",
      "        439.3264, 439.3264, 439.3264,   7.1793,   7.1801, 439.3264, 439.3264,\n",
      "        439.3264, 439.3264, 439.3264,  73.4050,  73.4050,   7.1791, 439.3264,\n",
      "        439.3264, 439.3264, 439.3264, 439.3264,  73.4050,  73.4050, 439.3264,\n",
      "         73.4050,  73.4050,   5.2026, 439.3264, 439.3264, 439.3264, 439.3264,\n",
      "        439.3264,  73.4050,  73.4050, 439.3264,  73.4050,  73.4050,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 439.3264,   5.2026,   5.2025, 439.3264,   5.2026,\n",
      "          5.2025, 439.3264,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        439.3264, 439.3264, 439.3264, 439.3264,  73.4050,  73.4050,  73.4050,\n",
      "         73.4050, 439.3264, 439.3264, 439.3264,  73.4050,  73.4050,  73.4050,\n",
      "         73.4050,   5.2026,  73.4050,  73.4050,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 754 was 95.8%\n",
      "tensor([8.1093e-06, 0.0000e+00, 1.8312e-05, 1.2519e-04, 3.6185e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2378e-06, 3.1278e-06, 3.1125e-06,\n",
      "        1.4187e-05, 1.4164e-05, 1.3427e-05, 2.8892e-06, 3.0897e-06, 8.1122e-06,\n",
      "        8.3041e-06, 2.4516e-01, 2.6931e-01, 1.0273e+00, 1.0032e+00, 2.9806e-06,\n",
      "        8.3052e-06, 2.5220e-01, 1.0204e+00, 2.2174e-01, 1.0510e+00, 2.8433e-01,\n",
      "        9.5898e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.5849, 281.7771, 303.1361, 282.2117,   7.1824,   7.1756,   7.3882,\n",
      "        439.7468, 439.7468, 439.7468,   7.1680,   7.1732, 439.7468, 439.7468,\n",
      "        439.7468, 439.7468, 439.7468,  73.4841,  73.4841,   7.1739, 439.7468,\n",
      "        439.7468, 439.7468, 439.7468, 439.7468,  73.4841,  73.4841, 439.7468,\n",
      "         73.4841,  73.4841,   5.2026, 439.7468, 439.7468, 439.7468, 439.7468,\n",
      "        439.7468,  73.4841,  73.4841, 439.7468,  73.4841,  73.4841,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 439.7468,   5.2026,   5.2025, 439.7468,   5.2026,\n",
      "          5.2025, 439.7468,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        439.7468, 439.7468, 439.7468, 439.7468,  73.4841,  73.4841,  73.4841,\n",
      "         73.4841, 439.7468, 439.7468, 439.7468,  73.4841,  73.4841,  73.4841,\n",
      "         73.4841,   5.2026,  73.4841,  73.4841,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.5711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 755 was 95.9%\n",
      "tensor([0.0000e+00, 3.5999e-20, 7.5368e-06, 1.0655e-04, 1.5743e-05, 6.0838e-07,\n",
      "        4.1086e-07, 4.0270e-07, 4.0484e-07, 3.2275e-06, 3.1149e-06, 3.1070e-06,\n",
      "        1.3932e-05, 1.3916e-05, 1.3232e-05, 2.8741e-06, 3.0731e-06, 7.9841e-06,\n",
      "        8.1653e-06, 2.4484e-01, 2.6867e-01, 1.0246e+00, 1.0009e+00, 2.9633e-06,\n",
      "        8.1605e-06, 2.5149e-01, 1.0182e+00, 2.2111e-01, 1.0487e+00, 2.8367e-01,\n",
      "        9.5908e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.7637, 282.0665, 303.3931, 282.4761,   7.1817,   7.1711,   7.3786,\n",
      "        440.1671, 440.1671, 440.1671,   7.1623,   7.1700, 440.1671, 440.1671,\n",
      "        440.1671, 440.1671, 440.1671,  73.5632,  73.5632,   7.1667, 440.1671,\n",
      "        440.1671, 440.1671, 440.1671, 440.1671,  73.5632,  73.5632, 440.1671,\n",
      "         73.5632,  73.5632,   5.2026, 440.1671, 440.1671, 440.1671, 440.1671,\n",
      "        440.1671,  73.5632,  73.5632, 440.1671,  73.5632,  73.5632,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 440.1671,   5.2026,   5.2025, 440.1671,   5.2026,\n",
      "          5.2025, 440.1671,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        440.1671, 440.1671, 440.1671, 440.1671,  73.5632,  73.5632,  73.5632,\n",
      "         73.5632, 440.1671, 440.1671, 440.1671,  73.5632,  73.5632,  73.5632,\n",
      "         73.5632,   5.2026,  73.5632,  73.5632,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.7671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 756 was 95.9%\n",
      "tensor([0.0000e+00, 0.0000e+00, 4.8462e-06, 5.7922e-04, 1.7888e-05, 0.0000e+00,\n",
      "        1.5116e-07, 3.6238e-07, 1.4933e-07, 3.1944e-06, 3.0926e-06, 3.1030e-06,\n",
      "        1.3695e-05, 1.3668e-05, 1.3036e-05, 2.8643e-06, 3.0509e-06, 7.8487e-06,\n",
      "        8.0259e-06, 2.4442e-01, 2.6799e-01, 1.0220e+00, 9.9914e-01, 2.9441e-06,\n",
      "        8.0123e-06, 2.5076e-01, 1.0158e+00, 2.2058e-01, 1.0461e+00, 2.8297e-01,\n",
      "        9.5917e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([238.9615, 282.3425, 303.6469, 282.7200,   7.1750,   7.1664,   7.3691,\n",
      "        440.5874, 440.5874, 440.5874,   7.1599,   7.1659, 440.5874, 440.5874,\n",
      "        440.5874, 440.5874, 440.5874,  73.6424,  73.6424,   7.1635, 440.5874,\n",
      "        440.5874, 440.5874, 440.5874, 440.5874,  73.6424,  73.6424, 440.5874,\n",
      "         73.6424,  73.6424,   5.2026, 440.5874, 440.5874, 440.5874, 440.5874,\n",
      "        440.5874,  73.6424,  73.6424, 440.5874,  73.6424,  73.6424,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 440.5874,   5.2026,   5.2025, 440.5874,   5.2026,\n",
      "          5.2025, 440.5874,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        440.5874, 440.5874, 440.5874, 440.5874,  73.6424,  73.6424,  73.6424,\n",
      "         73.6424, 440.5874, 440.5874, 440.5874,  73.6424,  73.6424,  73.6424,\n",
      "         73.6424,   5.2026,  73.6424,  73.6424,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.9918, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 757 was 95.9%\n",
      "tensor([0.0000e+00, 0.0000e+00, 7.8604e-06, 1.3925e-04, 1.7801e-05, 7.8229e-07,\n",
      "        5.2720e-07, 5.1687e-07, 5.1984e-07, 3.1891e-06, 3.0849e-06, 3.0945e-06,\n",
      "        1.3415e-05, 1.3394e-05, 1.2783e-05, 2.8574e-06, 3.0435e-06, 7.6940e-06,\n",
      "        7.8610e-06, 2.4383e-01, 2.6718e-01, 1.0194e+00, 9.9612e-01, 2.9366e-06,\n",
      "        7.8486e-06, 2.5009e-01, 1.0133e+00, 2.2016e-01, 1.0433e+00, 2.8224e-01,\n",
      "        9.5928e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([239.1239, 282.6447, 303.9115, 282.9946,   7.1790,   7.1617,   7.3594,\n",
      "        441.0078, 441.0078, 441.0078,   7.1515,   7.1617, 441.0078, 441.0078,\n",
      "        441.0078, 441.0078, 441.0078,  73.7215,  73.7215,   7.1548, 441.0078,\n",
      "        441.0078, 441.0078, 441.0078, 441.0078,  73.7215,  73.7215, 441.0078,\n",
      "         73.7215,  73.7215,   5.2026, 441.0078, 441.0078, 441.0078, 441.0078,\n",
      "        441.0078,  73.7215,  73.7215, 441.0078,  73.7215,  73.7215,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 441.0078,   5.2026,   5.2025, 441.0078,   5.2026,\n",
      "          5.2025, 441.0078,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        441.0078, 441.0078, 441.0078, 441.0078,  73.7215,  73.7215,  73.7215,\n",
      "         73.7215, 441.0078, 441.0078, 441.0078,  73.7215,  73.7215,  73.7215,\n",
      "         73.7215,   5.2026,  73.7215,  73.7215,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.7363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 758 was 95.9%\n",
      "tensor([6.7229e-08, 4.8562e-07, 0.0000e+00, 4.5999e-04, 2.0786e-05, 0.0000e+00,\n",
      "        3.7260e-08, 2.7728e-07, 3.6786e-08, 3.1756e-06, 3.0784e-06, 3.0926e-06,\n",
      "        1.3332e-05, 1.3317e-05, 1.2744e-05, 2.8556e-06, 3.0335e-06, 7.6437e-06,\n",
      "        7.7990e-06, 2.4361e-01, 2.6668e-01, 1.0170e+00, 9.9451e-01, 2.9288e-06,\n",
      "        7.7862e-06, 2.4942e-01, 1.0114e+00, 2.1963e-01, 1.0413e+00, 2.8158e-01,\n",
      "        9.5936e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([239.3824, 283.1018, 302.9630, 284.5260,   7.1278,   7.1871,   7.3571,\n",
      "        441.4281, 441.4281, 441.4281,   7.1826,   7.1257, 441.4281, 441.4281,\n",
      "        441.4281, 441.4281, 441.4281,  73.8006,  73.8006,   7.1553, 441.4281,\n",
      "        441.4281, 441.4281, 441.4281, 441.4281,  73.8006,  73.8006, 441.4281,\n",
      "         73.8006,  73.8006,   5.2026, 441.4281, 441.4281, 441.4281, 441.4281,\n",
      "        441.4281,  73.8006,  73.8006, 441.4281,  73.8006,  73.8006,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 441.4281,   5.2026,   5.2025, 441.4281,   5.2026,\n",
      "          5.2025, 441.4281,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        441.4281, 441.4281, 441.4281, 441.4281,  73.8006,  73.8006,  73.8006,\n",
      "         73.8006, 441.4281, 441.4281, 441.4281,  73.8006,  73.8006,  73.8006,\n",
      "         73.8006,   5.2026,  73.8006,  73.8006,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.4305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 759 was 95.9%\n",
      "tensor([7.7819e-06, 0.0000e+00, 2.7145e-05, 1.3075e-04, 5.2268e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1716e-06, 3.0619e-06, 3.0726e-06,\n",
      "        1.2797e-05, 1.2551e-05, 1.2057e-05, 2.8385e-06, 3.0210e-06, 7.1280e-06,\n",
      "        7.2746e-06, 2.4474e-01, 2.6371e-01, 1.0143e+00, 9.9528e-01, 2.9195e-06,\n",
      "        7.2168e-06, 2.4983e-01, 1.0094e+00, 2.1992e-01, 1.0395e+00, 2.8120e-01,\n",
      "        9.5942e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([239.5631, 283.3844, 303.2197, 284.7603,   7.1183,   7.1801,   7.3474,\n",
      "        441.8485, 441.8485, 441.8485,   7.1773,   7.1293, 441.8485, 441.8485,\n",
      "        441.8485, 441.8485, 441.8485,  73.8797,  73.8797,   7.1521, 441.8485,\n",
      "        441.8485, 441.8485, 441.8485, 441.8485,  73.8797,  73.8797, 441.8485,\n",
      "         73.8797,  73.8797,   5.2026, 441.8485, 441.8485, 441.8485, 441.8485,\n",
      "        441.8485,  73.8797,  73.8797, 441.8485,  73.8797,  73.8797,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 441.8485,   5.2026,   5.2025, 441.8485,   5.2026,\n",
      "          5.2025, 441.8485,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        441.8485, 441.8485, 441.8485, 441.8485,  73.8797,  73.8797,  73.8797,\n",
      "         73.8797, 441.8485, 441.8485, 441.8485,  73.8797,  73.8797,  73.8797,\n",
      "         73.8797,   5.2026,  73.8797,  73.8797,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.8158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 760 was 95.9%\n",
      "tensor([1.0157e-05, 0.0000e+00, 3.1588e-05, 1.7144e-04, 6.2770e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1789e-06, 3.0701e-06, 3.0655e-06,\n",
      "        1.2494e-05, 1.2256e-05, 1.1789e-05, 2.8471e-06, 3.0216e-06, 6.9684e-06,\n",
      "        7.1064e-06, 2.4404e-01, 2.6304e-01, 1.0117e+00, 9.9267e-01, 2.9263e-06,\n",
      "        7.0435e-06, 2.4908e-01, 1.0068e+00, 2.1948e-01, 1.0366e+00, 2.8046e-01,\n",
      "        9.5952e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([239.7262, 283.6781, 303.4853, 284.9986,   7.1158,   7.1730,   7.3373,\n",
      "        442.2688, 442.2688, 442.2688,   7.1721,   7.1256, 442.2688, 442.2688,\n",
      "        442.2688, 442.2688, 442.2688,  73.9589,  73.9589,   7.1490, 442.2688,\n",
      "        442.2688, 442.2688, 442.2688, 442.2688,  73.9589,  73.9589, 442.2688,\n",
      "         73.9589,  73.9589,   5.2026, 442.2688, 442.2688, 442.2688, 442.2688,\n",
      "        442.2688,  73.9589,  73.9589, 442.2688,  73.9589,  73.9589,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 442.2688,   5.2026,   5.2025, 442.2688,   5.2026,\n",
      "          5.2025, 442.2688,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        442.2688, 442.2688, 442.2688, 442.2688,  73.9589,  73.9589,  73.9589,\n",
      "         73.9589, 442.2688, 442.2688, 442.2688,  73.9589,  73.9589,  73.9589,\n",
      "         73.9589,   5.2026,  73.9589,  73.9589,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.9548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 761 was 95.9%\n",
      "tensor([1.0924e-05, 3.4686e-19, 3.4394e-05, 1.8579e-04, 6.7978e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1704e-06, 3.0645e-06, 3.0586e-06,\n",
      "        1.2263e-05, 1.2035e-05, 1.1590e-05, 2.8433e-06, 3.0148e-06, 6.8365e-06,\n",
      "        6.9691e-06, 2.4345e-01, 2.6235e-01, 1.0090e+00, 9.9018e-01, 2.9198e-06,\n",
      "        6.9051e-06, 2.4837e-01, 1.0043e+00, 2.1902e-01, 1.0339e+00, 2.7971e-01,\n",
      "        9.5963e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([239.8806, 283.9760, 303.7564, 285.2376,   7.1132,   7.1659,   7.3271,\n",
      "        442.6891, 442.6891, 442.6891,   7.1669,   7.1218, 442.6891, 442.6891,\n",
      "        442.6891, 442.6891, 442.6891,  74.0380,  74.0380,   7.1459, 442.6891,\n",
      "        442.6891, 442.6891, 442.6891, 442.6891,  74.0380,  74.0380, 442.6891,\n",
      "         74.0380,  74.0380,   5.2026, 442.6891, 442.6891, 442.6891, 442.6891,\n",
      "        442.6891,  74.0380,  74.0380, 442.6891,  74.0380,  74.0380,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 442.6891,   5.2026,   5.2025, 442.6891,   5.2026,\n",
      "          5.2025, 442.6891,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        442.6891, 442.6891, 442.6891, 442.6891,  74.0380,  74.0380,  74.0380,\n",
      "         74.0380, 442.6891, 442.6891, 442.6891,  74.0380,  74.0380,  74.0380,\n",
      "         74.0380,   5.2026,  74.0380,  74.0380,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.1336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 762 was 95.9%\n",
      "tensor([1.1923e-05, 0.0000e+00, 3.7951e-05, 2.0430e-04, 7.4579e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1647e-06, 3.0616e-06, 3.0515e-06,\n",
      "        1.2025e-05, 1.1806e-05, 1.1384e-05, 2.8419e-06, 3.0105e-06, 6.7013e-06,\n",
      "        6.8293e-06, 2.4286e-01, 2.6164e-01, 1.0064e+00, 9.8767e-01, 2.9157e-06,\n",
      "        6.7642e-06, 2.4766e-01, 1.0018e+00, 2.1855e-01, 1.0311e+00, 2.7895e-01,\n",
      "        9.5973e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([240.0225, 284.2800, 304.0349, 285.4775,   7.1106,   7.1598,   7.3168,\n",
      "        443.1095, 443.1095, 443.1095,   7.1609,   7.1179, 443.1095, 443.1095,\n",
      "        443.1095, 443.1095, 443.1095,  74.1171,  74.1171,   7.1429, 443.1095,\n",
      "        443.1095, 443.1095, 443.1095, 443.1095,  74.1171,  74.1171, 443.1095,\n",
      "         74.1171,  74.1171,   5.2026, 443.1095, 443.1095, 443.1095, 443.1095,\n",
      "        443.1095,  74.1171,  74.1171, 443.1095,  74.1171,  74.1171,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 443.1095,   5.2026,   5.2025, 443.1095,   5.2026,\n",
      "          5.2025, 443.1095,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        443.1095, 443.1095, 443.1095, 443.1095,  74.1171,  74.1171,  74.1171,\n",
      "         74.1171, 443.1095, 443.1095, 443.1095,  74.1171,  74.1171,  74.1171,\n",
      "         74.1171,   5.2026,  74.1171,  74.1171,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 763 was 95.9%\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.5128e-05, 7.9321e-05, 2.9420e-05, 3.9305e-07,\n",
      "        2.6131e-07, 2.5431e-07, 2.5594e-07, 3.1595e-06, 3.0541e-06, 3.0488e-06,\n",
      "        1.2071e-05, 1.1881e-05, 1.1445e-05, 2.8369e-06, 3.0054e-06, 6.6960e-06,\n",
      "        6.8083e-06, 2.4249e-01, 2.6116e-01, 1.0043e+00, 9.8563e-01, 2.9089e-06,\n",
      "        6.7561e-06, 2.4719e-01, 9.9986e-01, 2.1825e-01, 1.0290e+00, 2.7818e-01,\n",
      "        9.5981e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([240.2092, 284.5592, 304.2864, 285.7139,   7.1082,   7.1538,   7.3069,\n",
      "        443.5298, 443.5298, 443.5298,   7.1543,   7.1143, 443.5298, 443.5298,\n",
      "        443.5298, 443.5298, 443.5298,  74.1963,  74.1963,   7.1397, 443.5298,\n",
      "        443.5298, 443.5298, 443.5298, 443.5298,  74.1963,  74.1963, 443.5298,\n",
      "         74.1963,  74.1963,   5.2026, 443.5298, 443.5298, 443.5298, 443.5298,\n",
      "        443.5298,  74.1963,  74.1963, 443.5298,  74.1963,  74.1963,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 443.5298,   5.2026,   5.2025, 443.5298,   5.2026,\n",
      "          5.2025, 443.5298,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        443.5298, 443.5298, 443.5298, 443.5298,  74.1963,  74.1963,  74.1963,\n",
      "         74.1963, 443.5298, 443.5298, 443.5298,  74.1963,  74.1963,  74.1963,\n",
      "         74.1963,   5.2026,  74.1963,  74.1963,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 764 was 95.9%\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.5798e-05, 8.2321e-05, 3.0595e-05, 4.0348e-07,\n",
      "        2.6788e-07, 2.6078e-07, 2.6248e-07, 3.1495e-06, 3.0460e-06, 3.0428e-06,\n",
      "        1.1869e-05, 1.1687e-05, 1.1271e-05, 2.8317e-06, 2.9966e-06, 6.5818e-06,\n",
      "        6.6867e-06, 2.4193e-01, 2.6050e-01, 1.0018e+00, 9.8322e-01, 2.9003e-06,\n",
      "        6.6354e-06, 2.4653e-01, 9.9743e-01, 2.1778e-01, 1.0264e+00, 2.7745e-01,\n",
      "        9.5991e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([240.3942, 284.8391, 304.5390, 285.9505,   7.1058,   7.1477,   7.2969,\n",
      "        443.9501, 443.9501, 443.9501,   7.1478,   7.1107, 443.9501, 443.9501,\n",
      "        443.9501, 443.9501, 443.9501,  74.2754,  74.2754,   7.1365, 443.9501,\n",
      "        443.9501, 443.9501, 443.9501, 443.9501,  74.2754,  74.2754, 443.9501,\n",
      "         74.2754,  74.2754,   5.2026, 443.9501, 443.9501, 443.9501, 443.9501,\n",
      "        443.9501,  74.2754,  74.2754, 443.9501,  74.2754,  74.2754,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 443.9501,   5.2026,   5.2025, 443.9501,   5.2026,\n",
      "          5.2025, 443.9501,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        443.9501, 443.9501, 443.9501, 443.9501,  74.2754,  74.2754,  74.2754,\n",
      "         74.2754, 443.9501, 443.9501, 443.9501,  74.2754,  74.2754,  74.2754,\n",
      "         74.2754,   5.2026,  74.2754,  74.2754,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 765 was 96.0%\n",
      "tensor([0.0000e+00, 7.9621e-20, 1.6524e-05, 8.5595e-05, 3.1872e-05, 4.1494e-07,\n",
      "        2.7510e-07, 2.6790e-07, 2.6968e-07, 3.1396e-06, 3.0381e-06, 3.0369e-06,\n",
      "        1.1668e-05, 1.1495e-05, 1.1098e-05, 2.8267e-06, 2.9879e-06, 6.4684e-06,\n",
      "        6.5662e-06, 2.4136e-01, 2.5983e-01, 9.9929e-01, 9.8080e-01, 2.8920e-06,\n",
      "        6.5158e-06, 2.4588e-01, 9.9500e-01, 2.1732e-01, 1.0238e+00, 2.7672e-01,\n",
      "        9.6001e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([240.5773, 285.1197, 304.7929, 286.1872,   7.1034,   7.1417,   7.2869,\n",
      "        444.3705, 444.3705, 444.3705,   7.1412,   7.1071, 444.3705, 444.3705,\n",
      "        444.3705, 444.3705, 444.3705,  74.3545,  74.3545,   7.1332, 444.3705,\n",
      "        444.3705, 444.3705, 444.3705, 444.3705,  74.3545,  74.3545, 444.3705,\n",
      "         74.3545,  74.3545,   5.2026, 444.3705, 444.3705, 444.3705, 444.3705,\n",
      "        444.3705,  74.3545,  74.3545, 444.3705,  74.3545,  74.3545,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 444.3705,   5.2026,   5.2025, 444.3705,   5.2026,\n",
      "          5.2025, 444.3705,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        444.3705, 444.3705, 444.3705, 444.3705,  74.3545,  74.3545,  74.3545,\n",
      "         74.3545, 444.3705, 444.3705, 444.3705,  74.3545,  74.3545,  74.3545,\n",
      "         74.3545,   5.2026,  74.3545,  74.3545,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.3838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 766 was 96.0%\n",
      "tensor([0.0000e+00, 9.6562e-20, 1.7321e-05, 8.9224e-05, 3.3268e-05, 4.2779e-07,\n",
      "        2.8321e-07, 2.7589e-07, 2.7776e-07, 3.1302e-06, 3.0304e-06, 3.0310e-06,\n",
      "        1.1468e-05, 1.1304e-05, 1.0926e-05, 2.8219e-06, 2.9795e-06, 6.3555e-06,\n",
      "        6.4467e-06, 2.4080e-01, 2.5917e-01, 9.9677e-01, 9.7839e-01, 2.8839e-06,\n",
      "        6.3975e-06, 2.4522e-01, 9.9257e-01, 2.1686e-01, 1.0212e+00, 2.7598e-01,\n",
      "        9.6011e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([240.7580, 285.4013, 305.0484, 286.4241,   7.1010,   7.1344,   7.2769,\n",
      "        444.7908, 444.7908, 444.7908,   7.1357,   7.1035, 444.7908, 444.7908,\n",
      "        444.7908, 444.7908, 444.7908,  74.4336,  74.4336,   7.1300, 444.7908,\n",
      "        444.7908, 444.7908, 444.7908, 444.7908,  74.4336,  74.4336, 444.7908,\n",
      "         74.4336,  74.4336,   5.2026, 444.7908, 444.7908, 444.7908, 444.7908,\n",
      "        444.7908,  74.4336,  74.4336, 444.7908,  74.4336,  74.4336,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 444.7908,   5.2026,   5.2025, 444.7908,   5.2026,\n",
      "          5.2025, 444.7908,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        444.7908, 444.7908, 444.7908, 444.7908,  74.4336,  74.4336,  74.4336,\n",
      "         74.4336, 444.7908, 444.7908, 444.7908,  74.4336,  74.4336,  74.4336,\n",
      "         74.4336,   5.2026,  74.4336,  74.4336,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.1358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 767 was 96.0%\n",
      "tensor([7.9827e-06, 6.8935e-06, 0.0000e+00, 1.4118e-04, 4.8164e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4181e-06, 5.1285e-06, 2.9460e-06,\n",
      "        1.1326e-05, 1.1167e-05, 1.0812e-05, 4.7323e-06, 5.1584e-06, 6.3130e-06,\n",
      "        6.4132e-06, 2.4009e-01, 2.5833e-01, 9.9372e-01, 9.7554e-01, 4.9042e-06,\n",
      "        6.3632e-06, 2.4437e-01, 9.8965e-01, 2.1629e-01, 1.0180e+00, 2.7524e-01,\n",
      "        9.6023e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([241.1218, 285.7332, 305.1393, 286.7120,   7.1276,   7.1284,   7.2663,\n",
      "        445.2111, 445.2111, 445.2111,   7.1278,   7.0722, 445.2111, 445.2111,\n",
      "        445.2111, 445.2111, 445.2111,  74.5128,  74.5128,   7.1260, 445.2111,\n",
      "        445.2111, 445.2111, 445.2111, 445.2111,  74.5128,  74.5128, 445.2111,\n",
      "         74.5128,  74.5128,   5.2026, 445.2111, 445.2111, 445.2111, 445.2111,\n",
      "        445.2111,  74.5128,  74.5128, 445.2111,  74.5128,  74.5128,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 445.2111,   5.2026,   5.2025, 445.2111,   5.2026,\n",
      "          5.2025, 445.2111,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        445.2111, 445.2111, 445.2111, 445.2111,  74.5128,  74.5128,  74.5128,\n",
      "         74.5128, 445.2111, 445.2111, 445.2111,  74.5128,  74.5128,  74.5128,\n",
      "         74.5128,   5.2026,  74.5128,  74.5128,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.4046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 768 was 96.0%\n",
      "tensor([0.0000e+00, 5.0230e-06, 1.0461e-19, 1.2725e-04, 6.0148e-06, 5.9924e-07,\n",
      "        3.9765e-07, 3.8780e-07, 3.9062e-07, 5.8642e-06, 5.7126e-06, 2.9189e-06,\n",
      "        1.0983e-05, 1.0824e-05, 1.0507e-05, 5.2687e-06, 5.8514e-06, 6.1487e-06,\n",
      "        6.2274e-06, 2.3970e-01, 2.5772e-01, 9.9098e-01, 9.7298e-01, 5.4302e-06,\n",
      "        6.1847e-06, 2.4365e-01, 9.8721e-01, 2.1559e-01, 1.0156e+00, 2.7449e-01,\n",
      "        9.6033e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([241.4633, 286.1094, 305.2234, 286.9927,   7.1246,   7.1206,   7.2563,\n",
      "        445.6314, 445.6314, 445.6314,   7.1215,   7.0696, 445.6314, 445.6314,\n",
      "        445.6314, 445.6314, 445.6314,  74.5919,  74.5919,   7.1222, 445.6314,\n",
      "        445.6314, 445.6314, 445.6314, 445.6314,  74.5919,  74.5919, 445.6314,\n",
      "         74.5919,  74.5919,   5.2026, 445.6314, 445.6314, 445.6314, 445.6314,\n",
      "        445.6314,  74.5919,  74.5919, 445.6314,  74.5919,  74.5919,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 445.6314,   5.2026,   5.2025, 445.6314,   5.2026,\n",
      "          5.2025, 445.6314,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        445.6314, 445.6314, 445.6314, 445.6314,  74.5919,  74.5919,  74.5919,\n",
      "         74.5919, 445.6314, 445.6314, 445.6314,  74.5919,  74.5919,  74.5919,\n",
      "         74.5919,   5.2026,  74.5919,  74.5919,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 769 was 96.0%\n",
      "tensor([7.1792e-06, 0.0000e+00, 2.2430e-05, 1.0765e-04, 4.2375e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0755e-06, 2.9909e-06, 3.0193e-06,\n",
      "        1.3338e-05, 1.3334e-05, 1.2831e-05, 2.7904e-06, 2.9468e-06, 7.6647e-06,\n",
      "        7.7843e-06, 2.3926e-01, 2.5699e-01, 9.8881e-01, 9.7111e-01, 2.8409e-06,\n",
      "        7.8072e-06, 2.4308e-01, 9.8508e-01, 2.1527e-01, 1.0129e+00, 2.7360e-01,\n",
      "        9.6042e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([241.6547, 286.3862, 305.4766, 287.2260,   7.1171,   7.1183,   7.2461,\n",
      "        446.0518, 446.0518, 446.0518,   7.1171,   7.0673, 446.0518, 446.0518,\n",
      "        446.0518, 446.0518, 446.0518,  74.6710,  74.6710,   7.1167, 446.0518,\n",
      "        446.0518, 446.0518, 446.0518, 446.0518,  74.6710,  74.6710, 446.0518,\n",
      "         74.6710,  74.6710,   5.2026, 446.0518, 446.0518, 446.0518, 446.0518,\n",
      "        446.0518,  74.6710,  74.6710, 446.0518,  74.6710,  74.6710,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 446.0518,   5.2026,   5.2025, 446.0518,   5.2026,\n",
      "          5.2025, 446.0518,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        446.0518, 446.0518, 446.0518, 446.0518,  74.6710,  74.6710,  74.6710,\n",
      "         74.6710, 446.0518, 446.0518, 446.0518,  74.6710,  74.6710,  74.6710,\n",
      "         74.6710,   5.2026,  74.6710,  74.6710,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 770 was 96.0%\n",
      "tensor([7.5790e-06, 2.7952e-20, 2.3686e-05, 1.1420e-04, 4.3600e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0690e-06, 2.9824e-06, 3.0127e-06,\n",
      "        1.3142e-05, 1.3138e-05, 1.2657e-05, 2.7851e-06, 2.9383e-06, 7.5530e-06,\n",
      "        7.6640e-06, 2.3873e-01, 2.5623e-01, 9.8626e-01, 9.6879e-01, 2.8347e-06,\n",
      "        7.6895e-06, 2.4245e-01, 9.8262e-01, 2.1483e-01, 1.0103e+00, 2.7287e-01,\n",
      "        9.6052e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([241.8436, 286.6631, 305.7315, 287.4605,   7.1134,   7.1111,   7.2358,\n",
      "        446.4721, 446.4721, 446.4721,   7.1115,   7.0649, 446.4721, 446.4721,\n",
      "        446.4721, 446.4721, 446.4721,  74.7501,  74.7501,   7.1134, 446.4721,\n",
      "        446.4721, 446.4721, 446.4721, 446.4721,  74.7501,  74.7501, 446.4721,\n",
      "         74.7501,  74.7501,   5.2026, 446.4721, 446.4721, 446.4721, 446.4721,\n",
      "        446.4721,  74.7501,  74.7501, 446.4721,  74.7501,  74.7501,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 446.4721,   5.2026,   5.2025, 446.4721,   5.2026,\n",
      "          5.2025, 446.4721,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        446.4721, 446.4721, 446.4721, 446.4721,  74.7501,  74.7501,  74.7501,\n",
      "         74.7501, 446.4721, 446.4721, 446.4721,  74.7501,  74.7501,  74.7501,\n",
      "         74.7501,   5.2026,  74.7501,  74.7501,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.3746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 771 was 96.0%\n",
      "tensor([7.7782e-06, 0.0000e+00, 2.4648e-05, 1.1784e-04, 4.5984e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0579e-06, 2.9733e-06, 3.0070e-06,\n",
      "        1.2956e-05, 1.2960e-05, 1.2502e-05, 2.7783e-06, 2.9278e-06, 7.4513e-06,\n",
      "        7.5545e-06, 2.3820e-01, 2.5556e-01, 9.8380e-01, 9.6648e-01, 2.8248e-06,\n",
      "        7.5771e-06, 2.4178e-01, 9.8030e-01, 2.1443e-01, 1.0077e+00, 2.7215e-01,\n",
      "        9.6062e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([242.0312, 286.9404, 305.9892, 287.6929,   7.1071,   7.1088,   7.2255,\n",
      "        446.8924, 446.8924, 446.8924,   7.1071,   7.0625, 446.8924, 446.8924,\n",
      "        446.8924, 446.8924, 446.8924,  74.8293,  74.8293,   7.1065, 446.8924,\n",
      "        446.8924, 446.8924, 446.8924, 446.8924,  74.8293,  74.8293, 446.8924,\n",
      "         74.8293,  74.8293,   5.2026, 446.8924, 446.8924, 446.8924, 446.8924,\n",
      "        446.8924,  74.8293,  74.8293, 446.8924,  74.8293,  74.8293,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 446.8924,   5.2026,   5.2025, 446.8924,   5.2026,\n",
      "          5.2025, 446.8924,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        446.8924, 446.8924, 446.8924, 446.8924,  74.8293,  74.8293,  74.8293,\n",
      "         74.8293, 446.8924, 446.8924, 446.8924,  74.8293,  74.8293,  74.8293,\n",
      "         74.8293,   5.2026,  74.8293,  74.8293,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.4553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 772 was 96.0%\n",
      "tensor([8.2637e-06, 4.3665e-19, 2.6234e-05, 1.2581e-04, 4.7562e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0534e-06, 2.9671e-06, 3.0005e-06,\n",
      "        1.2761e-05, 1.2765e-05, 1.2331e-05, 2.7749e-06, 2.9209e-06, 7.3416e-06,\n",
      "        7.4366e-06, 2.3772e-01, 2.5483e-01, 9.8122e-01, 9.6414e-01, 2.8204e-06,\n",
      "        7.4613e-06, 2.4112e-01, 9.7788e-01, 2.1395e-01, 1.0051e+00, 2.7143e-01,\n",
      "        9.6072e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([242.2153, 287.2179, 306.2491, 287.9266,   7.1022,   7.1015,   7.2150,\n",
      "        447.3127, 447.3127, 447.3127,   7.1028,   7.0601, 447.3127, 447.3127,\n",
      "        447.3127, 447.3127, 447.3127,  74.9084,  74.9084,   7.1032, 447.3127,\n",
      "        447.3127, 447.3127, 447.3127, 447.3127,  74.9084,  74.9084, 447.3127,\n",
      "         74.9084,  74.9084,   5.2026, 447.3127, 447.3127, 447.3127, 447.3127,\n",
      "        447.3127,  74.9084,  74.9084, 447.3127,  74.9084,  74.9084,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 447.3127,   5.2026,   5.2025, 447.3127,   5.2026,\n",
      "          5.2025, 447.3127,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        447.3127, 447.3127, 447.3127, 447.3127,  74.9084,  74.9084,  74.9084,\n",
      "         74.9084, 447.3127, 447.3127, 447.3127,  74.9084,  74.9084,  74.9084,\n",
      "         74.9084,   5.2026,  74.9084,  74.9084,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.5320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 773 was 96.0%\n",
      "tensor([8.7119e-06, 9.2327e-20, 2.7849e-05, 1.3332e-04, 5.0149e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0469e-06, 2.9618e-06, 2.9941e-06,\n",
      "        1.2568e-05, 1.2577e-05, 1.2164e-05, 2.7713e-06, 2.9145e-06, 7.2337e-06,\n",
      "        7.3230e-06, 2.3717e-01, 2.5413e-01, 9.7872e-01, 9.6180e-01, 2.8147e-06,\n",
      "        7.3451e-06, 2.4044e-01, 9.7551e-01, 2.1357e-01, 1.0024e+00, 2.7071e-01,\n",
      "        9.6081e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([242.3959, 287.4960, 306.5126, 288.1599,   7.0971,   7.0992,   7.2045,\n",
      "        447.7331, 447.7331, 447.7331,   7.0972,   7.0577, 447.7331, 447.7331,\n",
      "        447.7331, 447.7331, 447.7331,  74.9875,  74.9875,   7.0963, 447.7331,\n",
      "        447.7331, 447.7331, 447.7331, 447.7331,  74.9875,  74.9875, 447.7331,\n",
      "         74.9875,  74.9875,   5.2026, 447.7331, 447.7331, 447.7331, 447.7331,\n",
      "        447.7331,  74.9875,  74.9875, 447.7331,  74.9875,  74.9875,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 447.7331,   5.2026,   5.2025, 447.7331,   5.2026,\n",
      "          5.2025, 447.7331,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        447.7331, 447.7331, 447.7331, 447.7331,  74.9875,  74.9875,  74.9875,\n",
      "         74.9875, 447.7331, 447.7331, 447.7331,  74.9875,  74.9875,  74.9875,\n",
      "         74.9875,   5.2026,  74.9875,  74.9875,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 774 was 96.0%\n",
      "tensor([9.1937e-06, 3.8201e-19, 2.9581e-05, 1.4142e-04, 5.2842e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0418e-06, 2.9557e-06, 2.9882e-06,\n",
      "        1.2377e-05, 1.2387e-05, 1.2001e-05, 2.7685e-06, 2.9074e-06, 7.1279e-06,\n",
      "        7.2084e-06, 2.3670e-01, 2.5342e-01, 9.7614e-01, 9.5946e-01, 2.8098e-06,\n",
      "        7.2316e-06, 2.3978e-01, 9.7311e-01, 2.1307e-01, 9.9988e-01, 2.6999e-01,\n",
      "        9.6091e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([242.5724, 287.7745, 306.7801, 288.3926,   7.0932,   7.0918,   7.1938,\n",
      "        448.1534, 448.1534, 448.1534,   7.0916,   7.0553, 448.1534, 448.1534,\n",
      "        448.1534, 448.1534, 448.1534,  75.0667,  75.0667,   7.0930, 448.1534,\n",
      "        448.1534, 448.1534, 448.1534, 448.1534,  75.0667,  75.0667, 448.1534,\n",
      "         75.0667,  75.0667,   5.2026, 448.1534, 448.1534, 448.1534, 448.1534,\n",
      "        448.1534,  75.0667,  75.0667, 448.1534,  75.0667,  75.0667,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 448.1534,   5.2026,   5.2025, 448.1534,   5.2026,\n",
      "          5.2025, 448.1534,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        448.1534, 448.1534, 448.1534, 448.1534,  75.0667,  75.0667,  75.0667,\n",
      "         75.0667, 448.1534, 448.1534, 448.1534,  75.0667,  75.0667,  75.0667,\n",
      "         75.0667,   5.2026,  75.0667,  75.0667,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 775 was 96.1%\n",
      "tensor([9.5836e-06, 0.0000e+00, 3.1223e-05, 1.4823e-04, 5.6515e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0328e-06, 2.9484e-06, 2.9821e-06,\n",
      "        1.2189e-05, 1.2206e-05, 1.1841e-05, 2.7634e-06, 2.8989e-06, 7.0235e-06,\n",
      "        7.0982e-06, 2.3615e-01, 2.5275e-01, 9.7362e-01, 9.5708e-01, 2.8018e-06,\n",
      "        7.1183e-06, 2.3909e-01, 9.7073e-01, 2.1265e-01, 9.9722e-01, 2.6926e-01,\n",
      "        9.6101e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([242.7453, 288.0537, 307.0540, 288.6212,   7.0853,   7.0884,   7.1831,\n",
      "        448.5737, 448.5737, 448.5737,   7.0883,   7.0528, 448.5737, 448.5737,\n",
      "        448.5737, 448.5737, 448.5737,  75.1458,  75.1458,   7.0875, 448.5737,\n",
      "        448.5737, 448.5737, 448.5737, 448.5737,  75.1458,  75.1458, 448.5737,\n",
      "         75.1458,  75.1458,   5.2026, 448.5737, 448.5737, 448.5737, 448.5737,\n",
      "        448.5737,  75.1458,  75.1458, 448.5737,  75.1458,  75.1458,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 448.5737,   5.2026,   5.2025, 448.5737,   5.2026,\n",
      "          5.2025, 448.5737,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        448.5737, 448.5737, 448.5737, 448.5737,  75.1458,  75.1458,  75.1458,\n",
      "         75.1458, 448.5737, 448.5737, 448.5737,  75.1458,  75.1458,  75.1458,\n",
      "         75.1458,   5.2026,  75.1458,  75.1458,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.8597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 776 was 96.1%\n",
      "tensor([1.0653e-05, 0.0000e+00, 3.4553e-05, 1.6554e-04, 6.0849e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0402e-06, 2.9544e-06, 2.9747e-06,\n",
      "        1.1978e-05, 1.1994e-05, 1.1655e-05, 2.7711e-06, 2.9039e-06, 6.9041e-06,\n",
      "        6.9749e-06, 2.3564e-01, 2.5197e-01, 9.7100e-01, 9.5474e-01, 2.8084e-06,\n",
      "        6.9937e-06, 2.3840e-01, 9.6828e-01, 2.1222e-01, 9.9453e-01, 2.6853e-01,\n",
      "        9.6111e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([242.9080, 288.3340, 307.3352, 288.8517,   7.0813,   7.0811,   7.1721,\n",
      "        448.9940, 448.9940, 448.9940,   7.0829,   7.0503, 448.9940, 448.9940,\n",
      "        448.9940, 448.9940, 448.9940,  75.2249,  75.2249,   7.0843, 448.9940,\n",
      "        448.9940, 448.9940, 448.9940, 448.9940,  75.2249,  75.2249, 448.9940,\n",
      "         75.2249,  75.2249,   5.2026, 448.9940, 448.9940, 448.9940, 448.9940,\n",
      "        448.9940,  75.2249,  75.2249, 448.9940,  75.2249,  75.2249,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 448.9940,   5.2026,   5.2025, 448.9940,   5.2026,\n",
      "          5.2025, 448.9940,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        448.9940, 448.9940, 448.9940, 448.9940,  75.2249,  75.2249,  75.2249,\n",
      "         75.2249, 448.9940, 448.9940, 448.9940,  75.2249,  75.2249,  75.2249,\n",
      "         75.2249,   5.2026,  75.2249,  75.2249,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.9856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 777 was 96.1%\n",
      "tensor([1.1384e-05, 0.0000e+00, 3.7206e-05, 1.7786e-04, 6.6423e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0378e-06, 2.9530e-06, 2.9690e-06,\n",
      "        1.1781e-05, 1.1803e-05, 1.1486e-05, 2.7716e-06, 2.9016e-06, 6.7966e-06,\n",
      "        6.8598e-06, 2.3506e-01, 2.5128e-01, 9.6847e-01, 9.5234e-01, 2.8064e-06,\n",
      "        6.8760e-06, 2.3772e-01, 9.6586e-01, 2.1179e-01, 9.9185e-01, 2.6780e-01,\n",
      "        9.6121e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([243.0629, 288.6155, 307.6283, 289.0754,   7.0759,   7.0787,   7.1609,\n",
      "        449.4144, 449.4144, 449.4144,   7.0774,   7.0479, 449.4144, 449.4144,\n",
      "        449.4144, 449.4144, 449.4144,  75.3040,  75.3040,   7.0775, 449.4144,\n",
      "        449.4144, 449.4144, 449.4144, 449.4144,  75.3040,  75.3040, 449.4144,\n",
      "         75.3040,  75.3040,   5.2026, 449.4144, 449.4144, 449.4144, 449.4144,\n",
      "        449.4144,  75.3040,  75.3040, 449.4144,  75.3040,  75.3040,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 449.4144,   5.2026,   5.2025, 449.4144,   5.2026,\n",
      "          5.2025, 449.4144,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        449.4144, 449.4144, 449.4144, 449.4144,  75.3040,  75.3040,  75.3040,\n",
      "         75.3040, 449.4144, 449.4144, 449.4144,  75.3040,  75.3040,  75.3040,\n",
      "         75.3040,   5.2026,  75.3040,  75.3040,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 778 was 96.1%\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.5115e-05, 7.1558e-05, 2.6260e-05, 3.6951e-07,\n",
      "        2.4608e-07, 2.4252e-07, 2.4444e-07, 3.0304e-06, 2.9444e-06, 2.9652e-06,\n",
      "        1.1828e-05, 1.1873e-05, 1.1553e-05, 2.7666e-06, 2.8943e-06, 6.8056e-06,\n",
      "        6.8519e-06, 2.3476e-01, 2.5075e-01, 9.6628e-01, 9.5030e-01, 2.7987e-06,\n",
      "        6.8827e-06, 2.3720e-01, 9.6390e-01, 2.1144e-01, 9.8975e-01, 2.6705e-01,\n",
      "        9.6130e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([243.2543, 288.8901, 307.8815, 289.3110,   7.0721,   7.0712,   7.1499,\n",
      "        449.8347, 449.8347, 449.8347,   7.0727,   7.0457, 449.8347, 449.8347,\n",
      "        449.8347, 449.8347, 449.8347,  75.3832,  75.3832,   7.0732, 449.8347,\n",
      "        449.8347, 449.8347, 449.8347, 449.8347,  75.3832,  75.3832, 449.8347,\n",
      "         75.3832,  75.3832,   5.2026, 449.8347, 449.8347, 449.8347, 449.8347,\n",
      "        449.8347,  75.3832,  75.3832, 449.8347,  75.3832,  75.3832,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 449.8347,   5.2026,   5.2025, 449.8347,   5.2026,\n",
      "          5.2025, 449.8347,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        449.8347, 449.8347, 449.8347, 449.8347,  75.3832,  75.3832,  75.3832,\n",
      "         75.3832, 449.8347, 449.8347, 449.8347,  75.3832,  75.3832,  75.3832,\n",
      "         75.3832,   5.2026,  75.3832,  75.3832,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 779 was 96.1%\n",
      "tensor([0.0000e+00, 4.1674e-19, 1.6171e-05, 8.1283e-05, 2.8775e-05, 4.1710e-07,\n",
      "        2.7754e-07, 2.7359e-07, 2.7579e-07, 3.0604e-06, 2.9749e-06, 2.9585e-06,\n",
      "        1.1632e-05, 1.1680e-05, 1.1380e-05, 2.7950e-06, 2.9236e-06, 6.6987e-06,\n",
      "        6.7395e-06, 2.3421e-01, 2.5006e-01, 9.6374e-01, 9.4791e-01, 2.8229e-06,\n",
      "        6.7674e-06, 2.3649e-01, 9.6151e-01, 2.1102e-01, 9.8707e-01, 2.6632e-01,\n",
      "        9.6140e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([243.4394, 289.1627, 308.1440, 289.5431,   7.0670,   7.0688,   7.1371,\n",
      "        450.2550, 450.2550, 450.2550,   7.0676,   7.0444, 450.2550, 450.2550,\n",
      "        450.2550, 450.2550, 450.2550,  75.4623,  75.4623,   7.0664, 450.2550,\n",
      "        450.2550, 450.2550, 450.2550, 450.2550,  75.4623,  75.4623, 450.2550,\n",
      "         75.4623,  75.4623,   5.2026, 450.2550, 450.2550, 450.2550, 450.2550,\n",
      "        450.2550,  75.4623,  75.4623, 450.2550,  75.4623,  75.4623,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 450.2550,   5.2026,   5.2025, 450.2550,   5.2026,\n",
      "          5.2025, 450.2550,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        450.2550, 450.2550, 450.2550, 450.2550,  75.4623,  75.4623,  75.4623,\n",
      "         75.4623, 450.2550, 450.2550, 450.2550,  75.4623,  75.4623,  75.4623,\n",
      "         75.4623,   5.2026,  75.4623,  75.4623,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 780 was 96.1%\n",
      "tensor([0.0000e+00, 2.9858e-19, 1.9284e-05, 1.0832e-04, 3.4009e-05, 5.5368e-07,\n",
      "        3.6807e-07, 3.6290e-07, 3.6598e-07, 3.1752e-06, 3.0851e-06, 2.9497e-06,\n",
      "        1.1374e-05, 1.1415e-05, 1.1153e-05, 2.8862e-06, 3.0320e-06, 6.5622e-06,\n",
      "        6.5979e-06, 2.3371e-01, 2.4925e-01, 9.6090e-01, 9.4540e-01, 2.9099e-06,\n",
      "        6.6222e-06, 2.3572e-01, 9.5893e-01, 2.1052e-01, 9.8423e-01, 2.6557e-01,\n",
      "        9.6150e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([243.6063, 289.4364, 308.4261, 289.7714,   7.0630,   7.0615,   7.1220,\n",
      "        450.6753, 450.6753, 450.6753,   7.0641,   7.0430, 450.6753, 450.6753,\n",
      "        450.6753, 450.6753, 450.6753,  75.5414,  75.5414,   7.0639, 450.6753,\n",
      "        450.6753, 450.6753, 450.6753, 450.6753,  75.5414,  75.5414, 450.6753,\n",
      "         75.5414,  75.5414,   5.2026, 450.6753, 450.6753, 450.6753, 450.6753,\n",
      "        450.6753,  75.5414,  75.5414, 450.6753,  75.5414,  75.5414,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 450.6753,   5.2026,   5.2025, 450.6753,   5.2026,\n",
      "          5.2025, 450.6753,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        450.6753, 450.6753, 450.6753, 450.6753,  75.5414,  75.5414,  75.5414,\n",
      "         75.5414, 450.6753, 450.6753, 450.6753,  75.5414,  75.5414,  75.5414,\n",
      "         75.5414,   5.2026,  75.5414,  75.5414,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 781 was 96.1%\n",
      "tensor([2.9054e-07, 0.0000e+00, 2.3717e-06, 1.5535e-05, 2.1353e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9635e-06, 2.8811e-06, 2.9503e-06,\n",
      "        1.1369e-05, 1.1432e-05, 1.1179e-05, 2.7175e-06, 2.8294e-06, 6.5490e-06,\n",
      "        6.5667e-06, 2.3336e-01, 2.4861e-01, 9.5854e-01, 9.4328e-01, 2.7404e-06,\n",
      "        6.6000e-06, 2.3506e-01, 9.5689e-01, 2.1031e-01, 9.8178e-01, 2.6475e-01,\n",
      "        9.6159e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([243.8131, 289.7128, 308.6642, 290.0108,   7.0580,   7.0591,   7.1116,\n",
      "        451.0956, 451.0956, 451.0956,   7.0569,   7.0406, 451.0956, 451.0956,\n",
      "        451.0956, 451.0956, 451.0956,  75.6205,  75.6205,   7.0577, 451.0956,\n",
      "        451.0956, 451.0956, 451.0956, 451.0956,  75.6205,  75.6205, 451.0956,\n",
      "         75.6205,  75.6205,   5.2026, 451.0956, 451.0956, 451.0956, 451.0956,\n",
      "        451.0956,  75.6205,  75.6205, 451.0956,  75.6205,  75.6205,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 451.0956,   5.2026,   5.2025, 451.0956,   5.2026,\n",
      "          5.2025, 451.0956,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        451.0956, 451.0956, 451.0956, 451.0956,  75.6205,  75.6205,  75.6205,\n",
      "         75.6205, 451.0956, 451.0956, 451.0956,  75.6205,  75.6205,  75.6205,\n",
      "         75.6205,   5.2026,  75.6205,  75.6205,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 782 was 96.1%\n",
      "tensor([8.7853e-08, 0.0000e+00, 2.1694e-06, 6.3553e-06, 2.0767e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0705e-06, 2.9763e-06, 2.9424e-06,\n",
      "        1.1215e-05, 1.1282e-05, 1.1047e-05, 2.7948e-06, 2.9304e-06, 6.4634e-06,\n",
      "        6.4734e-06, 2.3288e-01, 2.4792e-01, 9.5605e-01, 9.4098e-01, 2.8113e-06,\n",
      "        6.5084e-06, 2.3444e-01, 9.5453e-01, 2.0983e-01, 9.7928e-01, 2.6404e-01,\n",
      "        9.6169e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([244.0206, 289.9889, 308.9026, 290.2505,   7.0531,   7.0514,   7.1011,\n",
      "        451.5159, 451.5159, 451.5159,   7.0533,   7.0382, 451.5159, 451.5159,\n",
      "        451.5159, 451.5159, 451.5159,  75.6997,  75.6997,   7.0530, 451.5159,\n",
      "        451.5159, 451.5159, 451.5159, 451.5159,  75.6997,  75.6997, 451.5159,\n",
      "         75.6997,  75.6997,   5.2026, 451.5159, 451.5159, 451.5159, 451.5159,\n",
      "        451.5159,  75.6997,  75.6997, 451.5159,  75.6997,  75.6997,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 451.5159,   5.2026,   5.2025, 451.5159,   5.2026,\n",
      "          5.2025, 451.5159,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        451.5159, 451.5159, 451.5159, 451.5159,  75.6997,  75.6997,  75.6997,\n",
      "         75.6997, 451.5159, 451.5159, 451.5159,  75.6997,  75.6997,  75.6997,\n",
      "         75.6997,   5.2026,  75.6997,  75.6997,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 783 was 96.1%\n",
      "tensor([1.2155e-06, 1.1947e-05, 0.0000e+00, 8.1666e-05, 7.6834e-07, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3645e-06, 3.2474e-06, 2.9303e-06,\n",
      "        1.1059e-05, 1.1128e-05, 1.0908e-05, 2.9832e-06, 3.2113e-06, 6.3736e-06,\n",
      "        6.3802e-06, 2.3237e-01, 2.4724e-01, 9.5358e-01, 9.3877e-01, 2.9942e-06,\n",
      "        6.4138e-06, 2.3376e-01, 9.5223e-01, 2.0946e-01, 9.7669e-01, 2.6332e-01,\n",
      "        9.6179e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([244.2276, 290.2737, 309.1425, 290.4830,   7.0466,   7.0490,   7.0903,\n",
      "        451.9363, 451.9363, 451.9363,   7.0462,   7.0358, 451.9363, 451.9363,\n",
      "        451.9363, 451.9363, 451.9363,  75.7788,  75.7788,   7.0483, 451.9363,\n",
      "        451.9363, 451.9363, 451.9363, 451.9363,  75.7788,  75.7788, 451.9363,\n",
      "         75.7788,  75.7788,   5.2026, 451.9363, 451.9363, 451.9363, 451.9363,\n",
      "        451.9363,  75.7788,  75.7788, 451.9363,  75.7788,  75.7788,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 451.9363,   5.2026,   5.2025, 451.9363,   5.2026,\n",
      "          5.2025, 451.9363,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        451.9363, 451.9363, 451.9363, 451.9363,  75.7788,  75.7788,  75.7788,\n",
      "         75.7788, 451.9363, 451.9363, 451.9363,  75.7788,  75.7788,  75.7788,\n",
      "         75.7788,   5.2026,  75.7788,  75.7788,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.8300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 784 was 96.1%\n",
      "tensor([0.0000e+00, 3.0821e-06, 0.0000e+00, 9.3504e-05, 1.0815e-06, 4.5667e-07,\n",
      "        3.0276e-07, 2.9870e-07, 3.0176e-07, 3.2652e-06, 3.1161e-06, 2.9242e-06,\n",
      "        1.0710e-05, 1.0766e-05, 1.0588e-05, 2.8998e-06, 3.0860e-06, 6.1956e-06,\n",
      "        6.2050e-06, 2.3171e-01, 2.4634e-01, 9.5065e-01, 9.3608e-01, 2.8977e-06,\n",
      "        6.2286e-06, 2.3300e-01, 9.4940e-01, 2.0889e-01, 9.7368e-01, 2.6262e-01,\n",
      "        9.6190e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([244.5053, 290.6091, 309.3101, 290.7202,   7.0450,   7.0383,   7.0854,\n",
      "        452.3566, 452.3566, 452.3566,   7.0396,   7.0344, 452.3566, 452.3566,\n",
      "        452.3566, 452.3566, 452.3566,  75.8579,  75.8579,   7.0389, 452.3566,\n",
      "        452.3566, 452.3566, 452.3566, 452.3566,  75.8579,  75.8579, 452.3566,\n",
      "         75.8579,  75.8579,   5.2026, 452.3566, 452.3566, 452.3566, 452.3566,\n",
      "        452.3566,  75.8579,  75.8579, 452.3566,  75.8579,  75.8579,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 452.3566,   5.2026,   5.2025, 452.3566,   5.2026,\n",
      "          5.2025, 452.3566,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        452.3566, 452.3566, 452.3566, 452.3566,  75.8579,  75.8579,  75.8579,\n",
      "         75.8579, 452.3566, 452.3566, 452.3566,  75.8579,  75.8579,  75.8579,\n",
      "         75.8579,   5.2026,  75.8579,  75.8579,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 785 was 96.1%\n",
      "tensor([1.4943e-06, 1.4794e-05, 0.0000e+00, 1.0185e-04, 1.9855e-07, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5320e-06, 3.4127e-06, 2.9135e-06,\n",
      "        1.0745e-05, 1.0828e-05, 1.0633e-05, 3.0963e-06, 3.3200e-06, 6.2021e-06,\n",
      "        6.2028e-06, 2.3131e-01, 2.4600e-01, 9.4884e-01, 9.3422e-01, 3.1059e-06,\n",
      "        6.2341e-06, 2.3253e-01, 9.4765e-01, 2.0849e-01, 9.7188e-01, 2.6202e-01,\n",
      "        9.6197e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([244.7136, 290.8850, 309.5496, 290.9603,   7.0374,   7.0358,   7.0747,\n",
      "        452.7769, 452.7769, 452.7769,   7.0335,   7.0320, 452.7769, 452.7769,\n",
      "        452.7769, 452.7769, 452.7769,  75.9371,  75.9371,   7.0340, 452.7769,\n",
      "        452.7769, 452.7769, 452.7769, 452.7769,  75.9371,  75.9371, 452.7769,\n",
      "         75.9371,  75.9371,   5.2026, 452.7769, 452.7769, 452.7769, 452.7769,\n",
      "        452.7769,  75.9371,  75.9371, 452.7769,  75.9371,  75.9371,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 452.7769,   5.2026,   5.2025, 452.7769,   5.2026,\n",
      "          5.2025, 452.7769,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        452.7769, 452.7769, 452.7769, 452.7769,  75.9371,  75.9371,  75.9371,\n",
      "         75.9371, 452.7769, 452.7769, 452.7769,  75.9371,  75.9371,  75.9371,\n",
      "         75.9371,   5.2026,  75.9371,  75.9371,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 786 was 96.2%\n",
      "tensor([1.3728e-06, 1.4138e-05, 1.3742e-07, 9.4979e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3246e-06, 3.1842e-06, 2.9110e-06,\n",
      "        1.0588e-05, 1.0672e-05, 1.0491e-05, 2.9408e-06, 3.1034e-06, 6.1120e-06,\n",
      "        6.1072e-06, 2.3077e-01, 2.4526e-01, 9.4633e-01, 9.3191e-01, 2.9431e-06,\n",
      "        6.1402e-06, 2.3193e-01, 9.4520e-01, 2.0806e-01, 9.6926e-01, 2.6129e-01,\n",
      "        9.6207e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([244.9216, 291.1507, 309.7895, 291.2073,   7.0297,   7.0308,   7.0641,\n",
      "        453.1972, 453.1972, 453.1972,   7.0299,   7.0295, 453.1972, 453.1972,\n",
      "        453.1972, 453.1972, 453.1972,  76.0162,  76.0162,   7.0291, 453.1972,\n",
      "        453.1972, 453.1972, 453.1972, 453.1972,  76.0162,  76.0162, 453.1972,\n",
      "         76.0162,  76.0162,   5.2026, 453.1972, 453.1972, 453.1972, 453.1972,\n",
      "        453.1972,  76.0162,  76.0162, 453.1972,  76.0162,  76.0162,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 453.1972,   5.2026,   5.2025, 453.1972,   5.2026,\n",
      "          5.2025, 453.1972,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        453.1972, 453.1972, 453.1972, 453.1972,  76.0162,  76.0162,  76.0162,\n",
      "         76.0162, 453.1972, 453.1972, 453.1972,  76.0162,  76.0162,  76.0162,\n",
      "         76.0162,   5.2026,  76.0162,  76.0162,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 787 was 96.2%\n",
      "tensor([0.0000e+00, 3.6169e-06, 2.7327e-07, 7.6546e-05, 6.3104e-20, 3.6143e-07,\n",
      "        2.3921e-07, 2.3620e-07, 2.3867e-07, 3.1012e-06, 2.9809e-06, 2.9070e-06,\n",
      "        1.0315e-05, 1.0387e-05, 1.0230e-05, 2.7807e-06, 2.9030e-06, 5.9657e-06,\n",
      "        5.9637e-06, 2.3014e-01, 2.4441e-01, 9.4355e-01, 9.2933e-01, 2.7935e-06,\n",
      "        5.9902e-06, 2.3119e-01, 9.4253e-01, 2.0760e-01, 9.6630e-01, 2.6057e-01,\n",
      "        9.6218e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([245.1731, 291.3516, 309.9897, 291.5186,   7.0303,   7.0200,   7.0606,\n",
      "        453.6175, 453.6175, 453.6175,   7.0205,   7.0253, 453.6175, 453.6175,\n",
      "        453.6175, 453.6175, 453.6175,  76.0953,  76.0953,   7.0216, 453.6175,\n",
      "        453.6175, 453.6175, 453.6175, 453.6175,  76.0953,  76.0953, 453.6175,\n",
      "         76.0953,  76.0953,   5.2026, 453.6175, 453.6175, 453.6175, 453.6175,\n",
      "        453.6175,  76.0953,  76.0953, 453.6175,  76.0953,  76.0953,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 453.6175,   5.2026,   5.2025, 453.6175,   5.2026,\n",
      "          5.2025, 453.6175,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        453.6175, 453.6175, 453.6175, 453.6175,  76.0953,  76.0953,  76.0953,\n",
      "         76.0953, 453.6175, 453.6175, 453.6175,  76.0953,  76.0953,  76.0953,\n",
      "         76.0953,   5.2026,  76.0953,  76.0953,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.7040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 788 was 96.2%\n",
      "tensor([0.0000e+00, 0.0000e+00, 6.6801e-06, 4.5320e-04, 1.1235e-05, 3.8811e-07,\n",
      "        2.5717e-07, 2.5387e-07, 2.5653e-07, 2.9173e-06, 2.8407e-06, 2.9039e-06,\n",
      "        1.0262e-05, 1.0322e-05, 1.0174e-05, 2.6878e-06, 2.7797e-06, 5.9425e-06,\n",
      "        5.9429e-06, 2.2966e-01, 2.4398e-01, 9.4153e-01, 9.2765e-01, 2.6990e-06,\n",
      "        5.9660e-06, 2.3056e-01, 9.4065e-01, 2.0708e-01, 9.6427e-01, 2.6008e-01,\n",
      "        9.6226e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([245.3786, 291.6258, 310.2363, 291.7501,   7.0224,   7.0178,   7.0497,\n",
      "        454.0378, 454.0378, 454.0378,   7.0169,   7.0204, 454.0378, 454.0378,\n",
      "        454.0378, 454.0378, 454.0378,  76.1744,  76.1744,   7.0166, 454.0378,\n",
      "        454.0378, 454.0378, 454.0378, 454.0378,  76.1744,  76.1744, 454.0378,\n",
      "         76.1744,  76.1744,   5.2026, 454.0378, 454.0378, 454.0378, 454.0378,\n",
      "        454.0378,  76.1744,  76.1744, 454.0378,  76.1744,  76.1744,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 454.0378,   5.2026,   5.2025, 454.0378,   5.2026,\n",
      "          5.2025, 454.0378,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        454.0378, 454.0378, 454.0378, 454.0378,  76.1744,  76.1744,  76.1744,\n",
      "         76.1744, 454.0378, 454.0378, 454.0378,  76.1744,  76.1744,  76.1744,\n",
      "         76.1744,   5.2026,  76.1744,  76.1744,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.1895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 789 was 96.2%\n",
      "tensor([0.0000e+00, 4.6319e-06, 6.3652e-07, 1.1634e-04, 0.0000e+00, 5.4653e-07,\n",
      "        3.6188e-07, 3.5735e-07, 3.6111e-07, 3.5346e-06, 3.4083e-06, 2.8807e-06,\n",
      "        1.0009e-05, 1.0065e-05, 9.9348e-06, 3.0621e-06, 3.1928e-06, 5.8106e-06,\n",
      "        5.8102e-06, 2.2906e-01, 2.4312e-01, 9.3874e-01, 9.2479e-01, 3.0638e-06,\n",
      "        5.8314e-06, 2.2986e-01, 9.3796e-01, 2.0660e-01, 9.6139e-01, 2.5935e-01,\n",
      "        9.6237e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([245.6875, 291.6913, 310.3775, 292.1860,   7.0317,   7.0048,   7.0549,\n",
      "        454.4581, 454.4581, 454.4581,   7.0058,   7.0142, 454.4581, 454.4581,\n",
      "        454.4581, 454.4581, 454.4581,  76.2536,  76.2536,   6.9973, 454.4581,\n",
      "        454.4581, 454.4581, 454.4581, 454.4581,  76.2536,  76.2536, 454.4581,\n",
      "         76.2536,  76.2536,   5.2026, 454.4581, 454.4581, 454.4581, 454.4581,\n",
      "        454.4581,  76.2536,  76.2536, 454.4581,  76.2536,  76.2536,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 454.4581,   5.2026,   5.2025, 454.4581,   5.2026,\n",
      "          5.2025, 454.4581,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        454.4581, 454.4581, 454.4581, 454.4581,  76.2536,  76.2536,  76.2536,\n",
      "         76.2536, 454.4581, 454.4581, 454.4581,  76.2536,  76.2536,  76.2536,\n",
      "         76.2536,   5.2026,  76.2536,  76.2536,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.2047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 790 was 96.2%\n",
      "tensor([1.2828e-07, 4.6587e-20, 1.5600e-05, 5.8926e-04, 2.4341e-05, 0.0000e+00,\n",
      "        2.2874e-08, 2.9768e-07, 2.5384e-08, 2.9020e-06, 2.8330e-06, 2.8897e-06,\n",
      "        9.9553e-06, 9.9646e-06, 9.8477e-06, 2.6795e-06, 2.7672e-06, 5.7662e-06,\n",
      "        5.7794e-06, 2.2888e-01, 2.4308e-01, 9.3708e-01, 9.2355e-01, 2.6898e-06,\n",
      "        5.7914e-06, 2.2925e-01, 9.3681e-01, 2.0591e-01, 9.6019e-01, 2.5909e-01,\n",
      "        9.6242e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([245.8689, 291.9668, 310.7792, 292.2456,   7.0121,   6.9956,   7.0422,\n",
      "        454.8784, 454.8784, 454.8784,   7.0112,   7.0095, 454.8784, 454.8784,\n",
      "        454.8784, 454.8784, 454.8784,  76.3327,  76.3327,   7.0036, 454.8784,\n",
      "        454.8784, 454.8784, 454.8784, 454.8784,  76.3327,  76.3327, 454.8784,\n",
      "         76.3327,  76.3327,   5.2026, 454.8784, 454.8784, 454.8784, 454.8784,\n",
      "        454.8784,  76.3327,  76.3327, 454.8784,  76.3327,  76.3327,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 454.8784,   5.2026,   5.2025, 454.8784,   5.2026,\n",
      "          5.2025, 454.8784,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        454.8784, 454.8784, 454.8784, 454.8784,  76.3327,  76.3327,  76.3327,\n",
      "         76.3327, 454.8784, 454.8784, 454.8784,  76.3327,  76.3327,  76.3327,\n",
      "         76.3327,   5.2026,  76.3327,  76.3327,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(2.0341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 791 was 96.2%\n",
      "tensor([7.3592e-08, 1.3383e-19, 1.2334e-05, 6.0442e-04, 1.9224e-05, 0.0000e+00,\n",
      "        1.1972e-07, 3.0657e-07, 1.2076e-07, 2.8981e-06, 2.8221e-06, 2.8818e-06,\n",
      "        9.8390e-06, 9.8811e-06, 9.7402e-06, 2.6672e-06, 2.7613e-06, 5.7014e-06,\n",
      "        5.7082e-06, 2.2808e-01, 2.4218e-01, 9.3479e-01, 9.2127e-01, 2.6806e-06,\n",
      "        5.7295e-06, 2.2873e-01, 9.3414e-01, 2.0582e-01, 9.5721e-01, 2.5822e-01,\n",
      "        9.6253e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([246.0731, 292.2392, 311.0411, 292.4607,   7.0040,   6.9928,   7.0275,\n",
      "        455.2988, 455.2988, 455.2988,   7.0058,   7.0073, 455.2988, 455.2988,\n",
      "        455.2988, 455.2988, 455.2988,  76.4118,  76.4118,   7.0018, 455.2988,\n",
      "        455.2988, 455.2988, 455.2988, 455.2988,  76.4118,  76.4118, 455.2988,\n",
      "         76.4118,  76.4118,   5.2026, 455.2988, 455.2988, 455.2988, 455.2988,\n",
      "        455.2988,  76.4118,  76.4118, 455.2988,  76.4118,  76.4118,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 455.2988,   5.2026,   5.2025, 455.2988,   5.2026,\n",
      "          5.2025, 455.2988,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        455.2988, 455.2988, 455.2988, 455.2988,  76.4118,  76.4118,  76.4118,\n",
      "         76.4118, 455.2988, 455.2988, 455.2988,  76.4118,  76.4118,  76.4118,\n",
      "         76.4118,   5.2026,  76.4118,  76.4118,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.9883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 792 was 96.2%\n",
      "tensor([5.8608e-08, 1.4781e-19, 1.8775e-05, 6.0515e-04, 8.6554e-06, 0.0000e+00,\n",
      "        1.2721e-07, 3.0399e-07, 1.2848e-07, 2.8891e-06, 2.8116e-06, 2.8775e-06,\n",
      "        9.6975e-06, 9.7446e-06, 9.6253e-06, 2.6621e-06, 2.7511e-06, 5.6267e-06,\n",
      "        5.6220e-06, 2.2755e-01, 2.4139e-01, 9.3221e-01, 9.1897e-01, 2.6715e-06,\n",
      "        5.6445e-06, 2.2807e-01, 9.3172e-01, 2.0550e-01, 9.5445e-01, 2.5744e-01,\n",
      "        9.6263e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([246.2776, 292.4951, 311.2928, 292.7005,   6.9999,   6.9907,   7.0162,\n",
      "        455.7191, 455.7191, 455.7191,   6.9998,   6.9990, 455.7191, 455.7191,\n",
      "        455.7191, 455.7191, 455.7191,  76.4909,  76.4909,   6.9987, 455.7191,\n",
      "        455.7191, 455.7191, 455.7191, 455.7191,  76.4909,  76.4909, 455.7191,\n",
      "         76.4909,  76.4909,   5.2026, 455.7191, 455.7191, 455.7191, 455.7191,\n",
      "        455.7191,  76.4909,  76.4909, 455.7191,  76.4909,  76.4909,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 455.7191,   5.2026,   5.2025, 455.7191,   5.2026,\n",
      "          5.2025, 455.7191,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        455.7191, 455.7191, 455.7191, 455.7191,  76.4909,  76.4909,  76.4909,\n",
      "         76.4909, 455.7191, 455.7191, 455.7191,  76.4909,  76.4909,  76.4909,\n",
      "         76.4909,   5.2026,  76.4909,  76.4909,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 793 was 96.2%\n",
      "tensor([7.7097e-06, 3.4461e-04, 3.6968e-04, 3.6618e-04, 4.4689e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7131e-05, 9.0472e-05, 2.3971e-19,\n",
      "        9.7469e-06, 9.8233e-06, 9.6878e-06, 1.3729e-05, 3.5376e-05, 5.6374e-06,\n",
      "        5.6174e-06, 2.2727e-01, 2.4081e-01, 9.3059e-01, 9.1701e-01, 1.6091e-05,\n",
      "        5.6537e-06, 2.2766e-01, 9.3021e-01, 2.0516e-01, 9.5292e-01, 2.5668e-01,\n",
      "        9.6269e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([246.4842, 292.7702, 311.5325, 292.9393,   6.9918,   6.9883,   7.0054,\n",
      "        456.1394, 456.1394, 456.1394,   6.9935,   6.9952, 456.1394, 456.1394,\n",
      "        456.1394, 456.1394, 456.1394,  76.5701,  76.5701,   6.9950, 456.1394,\n",
      "        456.1394, 456.1394, 456.1394, 456.1394,  76.5701,  76.5701, 456.1394,\n",
      "         76.5701,  76.5701,   5.2026, 456.1394, 456.1394, 456.1394, 456.1394,\n",
      "        456.1394,  76.5701,  76.5701, 456.1394,  76.5701,  76.5701,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 456.1394,   5.2026,   5.2025, 456.1394,   5.2026,\n",
      "          5.2025, 456.1394,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        456.1394, 456.1394, 456.1394, 456.1394,  76.5701,  76.5701,  76.5701,\n",
      "         76.5701, 456.1394, 456.1394, 456.1394,  76.5701,  76.5701,  76.5701,\n",
      "         76.5701,   5.2026,  76.5701,  76.5701,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.4835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 794 was 96.2%\n",
      "tensor([4.4602e-06, 5.2313e-05, 1.3012e-05, 2.8186e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6651e-05, 5.8053e-05, 0.0000e+00,\n",
      "        9.5153e-06, 9.5824e-06, 9.4725e-06, 8.5706e-08, 5.2415e-06, 5.5167e-06,\n",
      "        5.4959e-06, 2.2664e-01, 2.4001e-01, 9.2746e-01, 9.1439e-01, 7.5252e-08,\n",
      "        5.5263e-06, 2.2698e-01, 9.2720e-01, 2.0470e-01, 9.4978e-01, 2.5599e-01,\n",
      "        9.6281e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([246.6926, 293.0527, 311.7615, 293.1847,   6.9805,   6.9862,   7.0001,\n",
      "        456.5597, 456.5597, 456.5597,   6.9888,   6.9877, 456.5597, 456.5597,\n",
      "        456.5597, 456.5597, 456.5597,  76.6492,  76.6492,   6.9905, 456.5597,\n",
      "        456.5597, 456.5597, 456.5597, 456.5597,  76.6492,  76.6492, 456.5597,\n",
      "         76.6492,  76.6492,   5.2026, 456.5597, 456.5597, 456.5597, 456.5597,\n",
      "        456.5597,  76.6492,  76.6492, 456.5597,  76.6492,  76.6492,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 456.5597,   5.2026,   5.2025, 456.5597,   5.2026,\n",
      "          5.2025, 456.5597,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        456.5597, 456.5597, 456.5597, 456.5597,  76.6492,  76.6492,  76.6492,\n",
      "         76.6492, 456.5597, 456.5597, 456.5597,  76.6492,  76.6492,  76.6492,\n",
      "         76.6492,   5.2026,  76.6492,  76.6492,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 795 was 96.2%\n",
      "tensor([7.6739e-06, 3.8340e-04, 3.9505e-04, 4.5305e-04, 4.9242e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4474e-05, 4.3468e-05, 1.2705e-20,\n",
      "        9.4806e-06, 9.5623e-06, 9.4417e-06, 9.1162e-08, 1.4943e-05, 5.4832e-06,\n",
      "        5.4557e-06, 2.2621e-01, 2.3944e-01, 9.2604e-01, 9.1276e-01, 7.7654e-08,\n",
      "        5.4942e-06, 2.2663e-01, 9.2563e-01, 2.0432e-01, 9.4816e-01, 2.5538e-01,\n",
      "        9.6287e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([246.8994, 293.3284, 312.0008, 293.4240,   6.9779,   6.9823,   6.9884,\n",
      "        456.9800, 456.9800, 456.9800,   6.9829,   6.9838, 456.9800, 456.9800,\n",
      "        456.9800, 456.9800, 456.9800,  76.7283,  76.7283,   6.9832, 456.9800,\n",
      "        456.9800, 456.9800, 456.9800, 456.9800,  76.7283,  76.7283, 456.9800,\n",
      "         76.7283,  76.7283,   5.2026, 456.9800, 456.9800, 456.9800, 456.9800,\n",
      "        456.9800,  76.7283,  76.7283, 456.9800,  76.7283,  76.7283,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 456.9800,   5.2026,   5.2025, 456.9800,   5.2026,\n",
      "          5.2025, 456.9800,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        456.9800, 456.9800, 456.9800, 456.9800,  76.7283,  76.7283,  76.7283,\n",
      "         76.7283, 456.9800, 456.9800, 456.9800,  76.7283,  76.7283,  76.7283,\n",
      "         76.7283,   5.2026,  76.7283,  76.7283,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.9460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 796 was 96.3%\n",
      "tensor([0.0000e+00, 0.0000e+00, 3.8191e-06, 5.1207e-04, 1.4718e-06, 4.0348e-07,\n",
      "        2.6661e-07, 2.6342e-07, 2.6638e-07, 2.8582e-06, 2.7771e-06, 2.8533e-06,\n",
      "        9.1730e-06, 9.2332e-06, 9.1514e-06, 2.6390e-06, 2.7196e-06, 5.3272e-06,\n",
      "        5.3073e-06, 2.2559e-01, 2.3859e-01, 9.2246e-01, 9.0994e-01, 2.6412e-06,\n",
      "        5.3307e-06, 2.2577e-01, 9.2230e-01, 2.0370e-01, 9.4460e-01, 2.5466e-01,\n",
      "        9.6301e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([246.9825, 293.3620, 312.4542, 293.6654,   7.1057,   6.5027,   7.3213,\n",
      "        457.4003, 457.4003, 457.4003,   6.9713,   6.9863, 457.4003, 457.4003,\n",
      "        457.4003, 457.4003, 457.4003,  76.8075,  76.8075,   6.9773, 457.4003,\n",
      "        457.4003, 457.4003, 457.4003, 457.4003,  76.8075,  76.8075, 457.4003,\n",
      "         76.8075,  76.8075,   5.2026, 457.4003, 457.4003, 457.4003, 457.4003,\n",
      "        457.4003,  76.8075,  76.8075, 457.4003,  76.8075,  76.8075,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 457.4003,   5.2026,   5.2025, 457.4003,   5.2026,\n",
      "          5.2025, 457.4003,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        457.4003, 457.4003, 457.4003, 457.4003,  76.8075,  76.8075,  76.8075,\n",
      "         76.8075, 457.4003, 457.4003, 457.4003,  76.8075,  76.8075,  76.8075,\n",
      "         76.8075,   5.2026,  76.8075,  76.8075,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 797 was 96.2%\n",
      "tensor([8.8175e-07, 2.0785e-06, 6.7294e-07, 1.8497e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9414e-06, 3.0994e-06, 2.8490e-06,\n",
      "        9.3066e-06, 9.4665e-06, 8.8235e-06, 2.6489e-06, 2.8599e-06, 5.1916e-06,\n",
      "        5.3659e-06, 2.2382e-01, 2.5114e-01, 9.4511e-01, 9.1837e-01, 2.7317e-06,\n",
      "        5.3223e-06, 2.3042e-01, 9.3859e-01, 2.0234e-01, 9.6726e-01, 2.6195e-01,\n",
      "        9.6231e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([247.1954, 293.6436, 312.7052, 293.8984,   7.0976,   6.5000,   7.3103,\n",
      "        457.8206, 457.8206, 457.8206,   6.9675,   6.9813, 457.8206, 457.8206,\n",
      "        457.8206, 457.8206, 457.8206,  76.8866,  76.8866,   6.9722, 457.8206,\n",
      "        457.8206, 457.8206, 457.8206, 457.8206,  76.8866,  76.8866, 457.8206,\n",
      "         76.8866,  76.8866,   5.2026, 457.8206, 457.8206, 457.8206, 457.8206,\n",
      "        457.8206,  76.8866,  76.8866, 457.8206,  76.8866,  76.8866,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 457.8206,   5.2026,   5.2025, 457.8206,   5.2026,\n",
      "          5.2025, 457.8206,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        457.8206, 457.8206, 457.8206, 457.8206,  76.8866,  76.8866,  76.8866,\n",
      "         76.8866, 457.8206, 457.8206, 457.8206,  76.8866,  76.8866,  76.8866,\n",
      "         76.8866,   5.2026,  76.8866,  76.8866,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 798 was 96.2%\n",
      "tensor([3.4093e-07, 2.6792e-06, 8.5445e-07, 2.5828e-05, 4.7010e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9334e-06, 3.0887e-06, 2.8422e-06,\n",
      "        9.1597e-06, 9.3210e-06, 8.6938e-06, 2.6421e-06, 2.8510e-06, 5.1109e-06,\n",
      "        5.2709e-06, 2.2330e-01, 2.5035e-01, 9.4254e-01, 9.1608e-01, 2.7241e-06,\n",
      "        5.2365e-06, 2.2980e-01, 9.3612e-01, 2.0194e-01, 9.6458e-01, 2.6120e-01,\n",
      "        9.6241e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([247.4086, 293.9221, 312.9572, 294.1325,   7.0893,   6.4974,   7.2992,\n",
      "        458.2409, 458.2409, 458.2409,   6.9637,   6.9763, 458.2409, 458.2409,\n",
      "        458.2409, 458.2409, 458.2409,  76.9657,  76.9657,   6.9670, 458.2409,\n",
      "        458.2409, 458.2409, 458.2409, 458.2409,  76.9657,  76.9657, 458.2409,\n",
      "         76.9657,  76.9657,   5.2026, 458.2409, 458.2409, 458.2409, 458.2409,\n",
      "        458.2409,  76.9657,  76.9657, 458.2409,  76.9657,  76.9657,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 458.2409,   5.2026,   5.2025, 458.2409,   5.2026,\n",
      "          5.2025, 458.2409,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        458.2409, 458.2409, 458.2409, 458.2409,  76.9657,  76.9657,  76.9657,\n",
      "         76.9657, 458.2409, 458.2409, 458.2409,  76.9657,  76.9657,  76.9657,\n",
      "         76.9657,   5.2026,  76.9657,  76.9657,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 799 was 96.2%\n",
      "tensor([3.5864e-07, 2.7176e-06, 8.3410e-07, 2.7519e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9255e-06, 3.0780e-06, 2.8354e-06,\n",
      "        9.0134e-06, 9.1757e-06, 8.5642e-06, 2.6352e-06, 2.8422e-06, 5.0306e-06,\n",
      "        5.1767e-06, 2.2277e-01, 2.4956e-01, 9.3997e-01, 9.1379e-01, 2.7164e-06,\n",
      "        5.1511e-06, 2.2918e-01, 9.3364e-01, 2.0153e-01, 9.6190e-01, 2.6045e-01,\n",
      "        9.6251e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([247.6216, 294.2037, 313.2102, 294.3634,   7.0811,   6.4947,   7.2881,\n",
      "        458.6612, 458.6612, 458.6612,   6.9600,   6.9712, 458.6612, 458.6612,\n",
      "        458.6612, 458.6612, 458.6612,  77.0448,  77.0448,   6.9619, 458.6612,\n",
      "        458.6612, 458.6612, 458.6612, 458.6612,  77.0448,  77.0448, 458.6612,\n",
      "         77.0448,  77.0448,   5.2026, 458.6612, 458.6612, 458.6612, 458.6612,\n",
      "        458.6612,  77.0448,  77.0448, 458.6612,  77.0448,  77.0448,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 458.6612,   5.2026,   5.2025, 458.6612,   5.2026,\n",
      "          5.2025, 458.6612,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        458.6612, 458.6612, 458.6612, 458.6612,  77.0448,  77.0448,  77.0448,\n",
      "         77.0448, 458.6612, 458.6612, 458.6612,  77.0448,  77.0448,  77.0448,\n",
      "         77.0448,   5.2026,  77.0448,  77.0448,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 800 was 96.2%\n",
      "tensor([8.7223e-07, 2.0685e-06, 6.2341e-07, 1.8714e-05, 9.7409e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9177e-06, 3.0674e-06, 2.8287e-06,\n",
      "        8.8774e-06, 9.0424e-06, 8.4445e-06, 2.6284e-06, 2.8334e-06, 4.9543e-06,\n",
      "        5.0866e-06, 2.2226e-01, 2.4878e-01, 9.3742e-01, 9.1151e-01, 2.7089e-06,\n",
      "        5.0702e-06, 2.2856e-01, 9.3120e-01, 2.0113e-01, 9.5924e-01, 2.5970e-01,\n",
      "        9.6261e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([247.8348, 294.4848, 313.4619, 294.5963,   7.0729,   6.4921,   7.2769,\n",
      "        459.0815, 459.0815, 459.0815,   6.9561,   6.9661, 459.0815, 459.0815,\n",
      "        459.0815, 459.0815, 459.0815,  77.1240,  77.1240,   6.9567, 459.0815,\n",
      "        459.0815, 459.0815, 459.0815, 459.0815,  77.1240,  77.1240, 459.0815,\n",
      "         77.1240,  77.1240,   5.2026, 459.0815, 459.0815, 459.0815, 459.0815,\n",
      "        459.0815,  77.1240,  77.1240, 459.0815,  77.1240,  77.1240,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 459.0815,   5.2026,   5.2025, 459.0815,   5.2026,\n",
      "          5.2025, 459.0815,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        459.0815, 459.0815, 459.0815, 459.0815,  77.1240,  77.1240,  77.1240,\n",
      "         77.1240, 459.0815, 459.0815, 459.0815,  77.1240,  77.1240,  77.1240,\n",
      "         77.1240,   5.2026,  77.1240,  77.1240,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 801 was 96.2%\n",
      "tensor([3.3373e-07, 2.6602e-06, 7.9071e-07, 2.5962e-05, 2.9646e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9098e-06, 3.0567e-06, 2.8219e-06,\n",
      "        8.7345e-06, 8.9006e-06, 8.3180e-06, 2.6216e-06, 2.8245e-06, 4.8754e-06,\n",
      "        4.9943e-06, 2.2174e-01, 2.4799e-01, 9.3486e-01, 9.0923e-01, 2.7012e-06,\n",
      "        4.9864e-06, 2.2794e-01, 9.2873e-01, 2.0073e-01, 9.5657e-01, 2.5896e-01,\n",
      "        9.6271e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([248.0479, 294.7658, 313.7146, 294.8281,   7.0646,   6.4894,   7.2657,\n",
      "        459.5018, 459.5018, 459.5018,   6.9523,   6.9610, 459.5018, 459.5018,\n",
      "        459.5018, 459.5018, 459.5018,  77.2031,  77.2031,   6.9514, 459.5018,\n",
      "        459.5018, 459.5018, 459.5018, 459.5018,  77.2031,  77.2031, 459.5018,\n",
      "         77.2031,  77.2031,   5.2026, 459.5018, 459.5018, 459.5018, 459.5018,\n",
      "        459.5018,  77.2031,  77.2031, 459.5018,  77.2031,  77.2031,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 459.5018,   5.2026,   5.2025, 459.5018,   5.2026,\n",
      "          5.2025, 459.5018,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        459.5018, 459.5018, 459.5018, 459.5018,  77.2031,  77.2031,  77.2031,\n",
      "         77.2031, 459.5018, 459.5018, 459.5018,  77.2031,  77.2031,  77.2031,\n",
      "         77.2031,   5.2026,  77.2031,  77.2031,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 802 was 96.2%\n",
      "tensor([3.5793e-07, 2.7133e-06, 7.6520e-07, 2.8245e-05, 1.7364e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9018e-06, 3.0460e-06, 2.8151e-06,\n",
      "        8.5907e-06, 8.7583e-06, 8.1907e-06, 2.6148e-06, 2.8158e-06, 4.7963e-06,\n",
      "        4.9022e-06, 2.2121e-01, 2.4720e-01, 9.3229e-01, 9.0694e-01, 2.6936e-06,\n",
      "        4.9025e-06, 2.2732e-01, 9.2626e-01, 2.0033e-01, 9.5388e-01, 2.5821e-01,\n",
      "        9.6281e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([248.2614, 295.0424, 313.9679, 295.0622,   7.0562,   6.4867,   7.2544,\n",
      "        459.9221, 459.9221, 459.9221,   6.9472,   6.9559, 459.9221, 459.9221,\n",
      "        459.9221, 459.9221, 459.9221,  77.2822,  77.2822,   6.9475, 459.9221,\n",
      "        459.9221, 459.9221, 459.9221, 459.9221,  77.2822,  77.2822, 459.9221,\n",
      "         77.2822,  77.2822,   5.2026, 459.9221, 459.9221, 459.9221, 459.9221,\n",
      "        459.9221,  77.2822,  77.2822, 459.9221,  77.2822,  77.2822,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 459.9221,   5.2026,   5.2025, 459.9221,   5.2026,\n",
      "          5.2025, 459.9221,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        459.9221, 459.9221, 459.9221, 459.9221,  77.2822,  77.2822,  77.2822,\n",
      "         77.2822, 459.9221, 459.9221, 459.9221,  77.2822,  77.2822,  77.2822,\n",
      "         77.2822,   5.2026,  77.2822,  77.2822,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 803 was 96.2%\n",
      "tensor([8.5452e-07, 2.0617e-06, 5.7310e-07, 1.8775e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8937e-06, 3.0354e-06, 2.8088e-06,\n",
      "        8.4588e-06, 8.6281e-06, 8.0733e-06, 2.6084e-06, 2.8072e-06, 4.7222e-06,\n",
      "        4.8146e-06, 2.2068e-01, 2.4642e-01, 9.2978e-01, 9.0467e-01, 2.6858e-06,\n",
      "        4.8227e-06, 2.2673e-01, 9.2380e-01, 1.9994e-01, 9.5123e-01, 2.5746e-01,\n",
      "        9.6291e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([248.4747, 295.3230, 314.2200, 295.2951,   7.0479,   6.4840,   7.2431,\n",
      "        460.3424, 460.3424, 460.3424,   6.9433,   6.9508, 460.3424, 460.3424,\n",
      "        460.3424, 460.3424, 460.3424,  77.3613,  77.3613,   6.9423, 460.3424,\n",
      "        460.3424, 460.3424, 460.3424, 460.3424,  77.3613,  77.3613, 460.3424,\n",
      "         77.3613,  77.3613,   5.2026, 460.3424, 460.3424, 460.3424, 460.3424,\n",
      "        460.3424,  77.3613,  77.3613, 460.3424,  77.3613,  77.3613,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 460.3424,   5.2026,   5.2025, 460.3424,   5.2026,\n",
      "          5.2025, 460.3424,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        460.3424, 460.3424, 460.3424, 460.3424,  77.3613,  77.3613,  77.3613,\n",
      "         77.3613, 460.3424, 460.3424, 460.3424,  77.3613,  77.3613,  77.3613,\n",
      "         77.3613,   5.2026,  77.3613,  77.3613,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 804 was 96.3%\n",
      "tensor([8.9203e-07, 2.0430e-06, 5.3990e-07, 1.9729e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8857e-06, 3.0247e-06, 2.8020e-06,\n",
      "        8.3181e-06, 8.4858e-06, 7.9483e-06, 2.6016e-06, 2.7985e-06, 4.6443e-06,\n",
      "        4.7244e-06, 2.2015e-01, 2.4563e-01, 9.2720e-01, 9.0237e-01, 2.6782e-06,\n",
      "        4.7402e-06, 2.2611e-01, 9.2133e-01, 1.9954e-01, 9.4854e-01, 2.5671e-01,\n",
      "        9.6301e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([248.6880, 295.6677, 314.4719, 295.4825,   7.0395,   6.4813,   7.2317,\n",
      "        460.7627, 460.7627, 460.7627,   6.9382,   6.9456, 460.7627, 460.7627,\n",
      "        460.7627, 460.7627, 460.7627,  77.4405,  77.4405,   6.9383, 460.7627,\n",
      "        460.7627, 460.7627, 460.7627, 460.7627,  77.4405,  77.4405, 460.7627,\n",
      "         77.4405,  77.4405,   5.2026, 460.7627, 460.7627, 460.7627, 460.7627,\n",
      "        460.7627,  77.4405,  77.4405, 460.7627,  77.4405,  77.4405,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 460.7627,   5.2026,   5.2025, 460.7627,   5.2026,\n",
      "          5.2025, 460.7627,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        460.7627, 460.7627, 460.7627, 460.7627,  77.4405,  77.4405,  77.4405,\n",
      "         77.4405, 460.7627, 460.7627, 460.7627,  77.4405,  77.4405,  77.4405,\n",
      "         77.4405,   5.2026,  77.4405,  77.4405,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 805 was 96.3%\n",
      "tensor([3.5332e-07, 2.6998e-06, 6.7016e-07, 2.8699e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8770e-06, 3.0139e-06, 2.7957e-06,\n",
      "        8.1722e-06, 8.3353e-06, 7.8279e-06, 2.5948e-06, 2.7894e-06, 4.5665e-06,\n",
      "        4.6334e-06, 2.1958e-01, 2.4481e-01, 9.2463e-01, 9.0005e-01, 2.6703e-06,\n",
      "        4.6562e-06, 2.2554e-01, 9.1875e-01, 1.9913e-01, 9.4581e-01, 2.5595e-01,\n",
      "        9.6311e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([248.9013, 296.0123, 314.7252, 295.6682,   7.0310,   6.4786,   7.2202,\n",
      "        461.1830, 461.1830, 461.1830,   6.9344,   6.9405, 461.1830, 461.1830,\n",
      "        461.1830, 461.1830, 461.1830,  77.5196,  77.5196,   6.9331, 461.1830,\n",
      "        461.1830, 461.1830, 461.1830, 461.1830,  77.5196,  77.5196, 461.1830,\n",
      "         77.5196,  77.5196,   5.2026, 461.1830, 461.1830, 461.1830, 461.1830,\n",
      "        461.1830,  77.5196,  77.5196, 461.1830,  77.5196,  77.5196,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 461.1830,   5.2026,   5.2025, 461.1830,   5.2026,\n",
      "          5.2025, 461.1830,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        461.1830, 461.1830, 461.1830, 461.1830,  77.5196,  77.5196,  77.5196,\n",
      "         77.5196, 461.1830, 461.1830, 461.1830,  77.5196,  77.5196,  77.5196,\n",
      "         77.5196,   5.2026,  77.5196,  77.5196,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 806 was 96.3%\n",
      "tensor([8.5811e-07, 2.0467e-06, 4.5386e-07, 1.9339e-05, 2.3717e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8689e-06, 3.0033e-06, 2.7890e-06,\n",
      "        8.0348e-06, 8.1952e-06, 7.7151e-06, 2.5878e-06, 2.7807e-06, 4.4910e-06,\n",
      "        4.5454e-06, 2.1904e-01, 2.4400e-01, 9.2207e-01, 8.9774e-01, 2.6629e-06,\n",
      "        4.5762e-06, 2.2495e-01, 9.1624e-01, 1.9873e-01, 9.4311e-01, 2.5518e-01,\n",
      "        9.6321e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([249.1146, 296.3558, 314.9769, 295.8561,   7.0225,   6.4759,   7.2087,\n",
      "        461.6033, 461.6033, 461.6033,   6.9292,   6.9353, 461.6033, 461.6033,\n",
      "        461.6033, 461.6033, 461.6033,  77.5987,  77.5987,   6.9291, 461.6033,\n",
      "        461.6033, 461.6033, 461.6033, 461.6033,  77.5987,  77.5987, 461.6033,\n",
      "         77.5987,  77.5987,   5.2026, 461.6033, 461.6033, 461.6033, 461.6033,\n",
      "        461.6033,  77.5987,  77.5987, 461.6033,  77.5987,  77.5987,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 461.6033,   5.2026,   5.2025, 461.6033,   5.2026,\n",
      "          5.2025, 461.6033,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        461.6033, 461.6033, 461.6033, 461.6033,  77.5987,  77.5987,  77.5987,\n",
      "         77.5987, 461.6033, 461.6033, 461.6033,  77.5987,  77.5987,  77.5987,\n",
      "         77.5987,   5.2026,  77.5987,  77.5987,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 807 was 96.3%\n",
      "tensor([3.3293e-07, 2.6505e-06, 5.4003e-07, 2.7511e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8603e-06, 2.9926e-06, 2.7827e-06,\n",
      "        7.8921e-06, 8.0479e-06, 7.5963e-06, 2.5810e-06, 2.7716e-06, 4.4143e-06,\n",
      "        4.4561e-06, 2.1846e-01, 2.4319e-01, 9.1950e-01, 8.9542e-01, 2.6550e-06,\n",
      "        4.4936e-06, 2.2438e-01, 9.1367e-01, 1.9832e-01, 9.4039e-01, 2.5442e-01,\n",
      "        9.6331e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([249.3280, 296.6989, 315.2298, 296.0428,   7.0140,   6.4732,   7.1972,\n",
      "        462.0236, 462.0236, 462.0236,   6.9240,   6.9301, 462.0236, 462.0236,\n",
      "        462.0236, 462.0236, 462.0236,  77.6778,  77.6778,   6.9251, 462.0236,\n",
      "        462.0236, 462.0236, 462.0236, 462.0236,  77.6778,  77.6778, 462.0236,\n",
      "         77.6778,  77.6778,   5.2026, 462.0236, 462.0236, 462.0236, 462.0236,\n",
      "        462.0236,  77.6778,  77.6778, 462.0236,  77.6778,  77.6778,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 462.0236,   5.2026,   5.2025, 462.0236,   5.2026,\n",
      "          5.2025, 462.0236,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        462.0236, 462.0236, 462.0236, 462.0236,  77.6778,  77.6778,  77.6778,\n",
      "         77.6778, 462.0236, 462.0236, 462.0236,  77.6778,  77.6778,  77.6778,\n",
      "         77.6778,   5.2026,  77.6778,  77.6778,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 808 was 96.3%\n",
      "tensor([3.6704e-07, 2.7278e-06, 4.8608e-07, 3.0836e-05, 1.5670e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8516e-06, 2.9818e-06, 2.7763e-06,\n",
      "        7.7483e-06, 7.8998e-06, 7.4762e-06, 2.5743e-06, 2.7627e-06, 4.3374e-06,\n",
      "        4.3670e-06, 2.1788e-01, 2.4237e-01, 9.1693e-01, 8.9309e-01, 2.6471e-06,\n",
      "        4.4108e-06, 2.2381e-01, 9.1109e-01, 1.9791e-01, 9.3766e-01, 2.5365e-01,\n",
      "        9.6341e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([249.5414, 297.0418, 315.4840, 296.2281,   7.0055,   6.4705,   7.1855,\n",
      "        462.4439, 462.4439, 462.4439,   6.9202,   6.9249, 462.4439, 462.4439,\n",
      "        462.4439, 462.4439, 462.4439,  77.7570,  77.7570,   6.9198, 462.4439,\n",
      "        462.4439, 462.4439, 462.4439, 462.4439,  77.7570,  77.7570, 462.4439,\n",
      "         77.7570,  77.7570,   5.2026, 462.4439, 462.4439, 462.4439, 462.4439,\n",
      "        462.4439,  77.7570,  77.7570, 462.4439,  77.7570,  77.7570,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 462.4439,   5.2026,   5.2025, 462.4439,   5.2026,\n",
      "          5.2025, 462.4439,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        462.4439, 462.4439, 462.4439, 462.4439,  77.7570,  77.7570,  77.7570,\n",
      "         77.7570, 462.4439, 462.4439, 462.4439,  77.7570,  77.7570,  77.7570,\n",
      "         77.7570,   5.2026,  77.7570,  77.7570,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 809 was 96.3%\n",
      "tensor([8.6480e-07, 2.0305e-06, 2.8789e-07, 2.0025e-05, 4.6587e-21, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8435e-06, 2.9712e-06, 2.7697e-06,\n",
      "        7.6145e-06, 7.7629e-06, 7.3653e-06, 2.5673e-06, 2.7538e-06, 4.2632e-06,\n",
      "        4.2812e-06, 2.1734e-01, 2.4157e-01, 9.1436e-01, 8.9078e-01, 2.6397e-06,\n",
      "        4.3325e-06, 2.2322e-01, 9.0858e-01, 1.9751e-01, 9.3496e-01, 2.5289e-01,\n",
      "        9.6351e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([249.7549, 297.3833, 315.7363, 296.4162,   6.9969,   6.4677,   7.1739,\n",
      "        462.8642, 462.8642, 462.8642,   6.9149,   6.9196, 462.8642, 462.8642,\n",
      "        462.8642, 462.8642, 462.8642,  77.8361,  77.8361,   6.9158, 462.8642,\n",
      "        462.8642, 462.8642, 462.8642, 462.8642,  77.8361,  77.8361, 462.8642,\n",
      "         77.8361,  77.8361,   5.2026, 462.8642, 462.8642, 462.8642, 462.8642,\n",
      "        462.8642,  77.8361,  77.8361, 462.8642,  77.8361,  77.8361,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 462.8642,   5.2026,   5.2025, 462.8642,   5.2026,\n",
      "          5.2025, 462.8642,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        462.8642, 462.8642, 462.8642, 462.8642,  77.8361,  77.8361,  77.8361,\n",
      "         77.8361, 462.8642, 462.8642, 462.8642,  77.8361,  77.8361,  77.8361,\n",
      "         77.8361,   5.2026,  77.8361,  77.8361,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 810 was 96.3%\n",
      "tensor([3.3601e-07, 2.6529e-06, 3.2025e-07, 2.8704e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8349e-06, 2.9605e-06, 2.7633e-06,\n",
      "        7.4761e-06, 7.6204e-06, 7.2488e-06, 2.5606e-06, 2.7450e-06, 4.1880e-06,\n",
      "        4.1942e-06, 2.1677e-01, 2.4075e-01, 9.1180e-01, 8.8847e-01, 2.6319e-06,\n",
      "        4.2517e-06, 2.2265e-01, 9.0602e-01, 1.9710e-01, 9.3224e-01, 2.5213e-01,\n",
      "        9.6361e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([249.9684, 297.7234, 315.9896, 296.6038,   6.9883,   6.4650,   7.1622,\n",
      "        463.2845, 463.2845, 463.2845,   6.9110,   6.9144, 463.2845, 463.2845,\n",
      "        463.2845, 463.2845, 463.2845,  77.9152,  77.9152,   6.9104, 463.2845,\n",
      "        463.2845, 463.2845, 463.2845, 463.2845,  77.9152,  77.9152, 463.2845,\n",
      "         77.9152,  77.9152,   5.2026, 463.2845, 463.2845, 463.2845, 463.2845,\n",
      "        463.2845,  77.9152,  77.9152, 463.2845,  77.9152,  77.9152,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 463.2845,   5.2026,   5.2025, 463.2845,   5.2026,\n",
      "          5.2025, 463.2845,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        463.2845, 463.2845, 463.2845, 463.2845,  77.9152,  77.9152,  77.9152,\n",
      "         77.9152, 463.2845, 463.2845, 463.2845,  77.9152,  77.9152,  77.9152,\n",
      "         77.9152,   5.2026,  77.9152,  77.9152,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 811 was 96.3%\n",
      "tensor([3.7009e-07, 2.7311e-06, 2.5193e-07, 3.2144e-05, 3.0917e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8266e-06, 2.9497e-06, 2.7566e-06,\n",
      "        7.3363e-06, 7.4764e-06, 7.1309e-06, 2.5535e-06, 2.7360e-06, 4.1119e-06,\n",
      "        4.1076e-06, 2.1622e-01, 2.3994e-01, 9.0921e-01, 8.8613e-01, 2.6243e-06,\n",
      "        4.1715e-06, 2.2205e-01, 9.0347e-01, 1.9669e-01, 9.2951e-01, 2.5136e-01,\n",
      "        9.6372e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([250.1819, 298.0616, 316.2440, 296.7914,   6.9797,   6.4623,   7.1504,\n",
      "        463.7048, 463.7048, 463.7048,   6.9058,   6.9091, 463.7048, 463.7048,\n",
      "        463.7048, 463.7048, 463.7048,  77.9943,  77.9943,   6.9064, 463.7048,\n",
      "        463.7048, 463.7048, 463.7048, 463.7048,  77.9943,  77.9943, 463.7048,\n",
      "         77.9943,  77.9943,   5.2026, 463.7048, 463.7048, 463.7048, 463.7048,\n",
      "        463.7048,  77.9943,  77.9943, 463.7048,  77.9943,  77.9943,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 463.7048,   5.2026,   5.2025, 463.7048,   5.2026,\n",
      "          5.2025, 463.7048,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        463.7048, 463.7048, 463.7048, 463.7048,  77.9943,  77.9943,  77.9943,\n",
      "         77.9943, 463.7048, 463.7048, 463.7048,  77.9943,  77.9943,  77.9943,\n",
      "         77.9943,   5.2026,  77.9943,  77.9943,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 812 was 96.3%\n",
      "tensor([8.3321e-07, 2.0286e-06, 9.5197e-08, 1.9878e-05, 7.4539e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8181e-06, 2.9391e-06, 2.7504e-06,\n",
      "        7.2073e-06, 7.3444e-06, 7.0220e-06, 2.5470e-06, 2.7272e-06, 4.0398e-06,\n",
      "        4.0240e-06, 2.1566e-01, 2.3914e-01, 9.0667e-01, 8.8383e-01, 2.6165e-06,\n",
      "        4.0943e-06, 2.2148e-01, 9.0094e-01, 1.9630e-01, 9.2682e-01, 2.5060e-01,\n",
      "        9.6382e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([250.3956, 298.3953, 316.4961, 296.9845,   6.9710,   6.4595,   7.1387,\n",
      "        464.1251, 464.1251, 464.1251,   6.9018,   6.9038, 464.1251, 464.1251,\n",
      "        464.1251, 464.1251, 464.1251,  78.0735,  78.0735,   6.9011, 464.1251,\n",
      "        464.1251, 464.1251, 464.1251, 464.1251,  78.0735,  78.0735, 464.1251,\n",
      "         78.0735,  78.0735,   5.2026, 464.1251, 464.1251, 464.1251, 464.1251,\n",
      "        464.1251,  78.0735,  78.0735, 464.1251,  78.0735,  78.0735,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 464.1251,   5.2026,   5.2025, 464.1251,   5.2026,\n",
      "          5.2025, 464.1251,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        464.1251, 464.1251, 464.1251, 464.1251,  78.0735,  78.0735,  78.0735,\n",
      "         78.0735, 464.1251, 464.1251, 464.1251,  78.0735,  78.0735,  78.0735,\n",
      "         78.0735,   5.2026,  78.0735,  78.0735,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 813 was 96.3%\n",
      "tensor([8.5835e-07, 2.0147e-06, 2.4996e-08, 2.0661e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8100e-06, 2.9283e-06, 2.7436e-06,\n",
      "        7.0722e-06, 7.2054e-06, 6.9063e-06, 2.5399e-06, 2.7183e-06, 3.9650e-06,\n",
      "        3.9391e-06, 2.1512e-01, 2.3833e-01, 9.0409e-01, 8.8151e-01, 2.6090e-06,\n",
      "        4.0156e-06, 2.2088e-01, 8.9841e-01, 1.9589e-01, 9.2411e-01, 2.4984e-01,\n",
      "        9.6392e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([250.6094, 298.7228, 316.7486, 297.1816,   6.9622,   6.4567,   7.1269,\n",
      "        464.5454, 464.5454, 464.5454,   6.8965,   6.8985, 464.5454, 464.5454,\n",
      "        464.5454, 464.5454, 464.5454,  78.1526,  78.1526,   6.8971, 464.5454,\n",
      "        464.5454, 464.5454, 464.5454, 464.5454,  78.1526,  78.1526, 464.5454,\n",
      "         78.1526,  78.1526,   5.2026, 464.5454, 464.5454, 464.5454, 464.5454,\n",
      "        464.5454,  78.1526,  78.1526, 464.5454,  78.1526,  78.1526,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 464.5454,   5.2026,   5.2025, 464.5454,   5.2026,\n",
      "          5.2025, 464.5454,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        464.5454, 464.5454, 464.5454, 464.5454,  78.1526,  78.1526,  78.1526,\n",
      "         78.1526, 464.5454, 464.5454, 464.5454,  78.1526,  78.1526,  78.1526,\n",
      "         78.1526,   5.2026,  78.1526,  78.1526,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 814 was 96.4%\n",
      "tensor([8.5846e-07, 2.0102e-06, 0.0000e+00, 2.0867e-05, 3.5130e-08, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8015e-06, 2.9176e-06, 2.7373e-06,\n",
      "        6.9399e-06, 7.0691e-06, 6.7915e-06, 2.5333e-06, 2.7095e-06, 3.8917e-06,\n",
      "        3.8553e-06, 2.1455e-01, 2.3752e-01, 9.0154e-01, 8.7919e-01, 2.6011e-06,\n",
      "        3.9374e-06, 2.2031e-01, 8.9586e-01, 1.9549e-01, 9.2140e-01, 2.4908e-01,\n",
      "        9.6402e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([250.8233, 299.0413, 317.0017, 297.3844,   6.9533,   6.4539,   7.1152,\n",
      "        464.9657, 464.9657, 464.9657,   6.8924,   6.8932, 464.9657, 464.9657,\n",
      "        464.9657, 464.9657, 464.9657,  78.2317,  78.2317,   6.8918, 464.9657,\n",
      "        464.9657, 464.9657, 464.9657, 464.9657,  78.2317,  78.2317, 464.9657,\n",
      "         78.2317,  78.2317,   5.2026, 464.9657, 464.9657, 464.9657, 464.9657,\n",
      "        464.9657,  78.2317,  78.2317, 464.9657,  78.2317,  78.2317,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 464.9657,   5.2026,   5.2025, 464.9657,   5.2026,\n",
      "          5.2025, 464.9657,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        464.9657, 464.9657, 464.9657, 464.9657,  78.2317,  78.2317,  78.2317,\n",
      "         78.2317, 464.9657, 464.9657, 464.9657,  78.2317,  78.2317,  78.2317,\n",
      "         78.2317,   5.2026,  78.2317,  78.2317,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 815 was 96.4%\n",
      "tensor([8.4724e-07, 2.0097e-06, 7.6233e-21, 2.0816e-05, 9.4407e-08, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7935e-06, 2.9069e-06, 2.7305e-06,\n",
      "        6.8099e-06, 6.9354e-06, 6.6775e-06, 2.5263e-06, 2.7007e-06, 3.8185e-06,\n",
      "        3.7728e-06, 2.1401e-01, 2.3671e-01, 8.9896e-01, 8.7687e-01, 2.5936e-06,\n",
      "        3.8607e-06, 2.1971e-01, 8.9335e-01, 1.9509e-01, 9.1869e-01, 2.4832e-01,\n",
      "        9.6412e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([251.0372, 299.3592, 317.2549, 297.5873,   6.9443,   6.4511,   7.1034,\n",
      "        465.3860, 465.3860, 465.3860,   6.8870,   6.8878, 465.3860, 465.3860,\n",
      "        465.3860, 465.3860, 465.3860,  78.3109,  78.3109,   6.8878, 465.3860,\n",
      "        465.3860, 465.3860, 465.3860, 465.3860,  78.3109,  78.3109, 465.3860,\n",
      "         78.3109,  78.3109,   5.2026, 465.3860, 465.3860, 465.3860, 465.3860,\n",
      "        465.3860,  78.3109,  78.3109, 465.3860,  78.3109,  78.3109,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 465.3860,   5.2026,   5.2025, 465.3860,   5.2026,\n",
      "          5.2025, 465.3860,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        465.3860, 465.3860, 465.3860, 465.3860,  78.3109,  78.3109,  78.3109,\n",
      "         78.3109, 465.3860, 465.3860, 465.3860,  78.3109,  78.3109,  78.3109,\n",
      "         78.3109,   5.2026,  78.3109,  78.3109,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 816 was 96.4%\n",
      "tensor([8.4034e-07, 2.0077e-06, 8.9785e-20, 2.0869e-05, 1.4439e-07, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7850e-06, 2.8962e-06, 2.7242e-06,\n",
      "        6.6811e-06, 6.8026e-06, 6.5637e-06, 2.5197e-06, 2.6919e-06, 3.7463e-06,\n",
      "        3.6908e-06, 2.1344e-01, 2.3591e-01, 8.9642e-01, 8.7456e-01, 2.5857e-06,\n",
      "        3.7839e-06, 2.1913e-01, 8.9081e-01, 1.9469e-01, 9.1599e-01, 2.4756e-01,\n",
      "        9.6422e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([251.2511, 299.6765, 317.5083, 297.7903,   6.9353,   6.4483,   7.0916,\n",
      "        465.8063, 465.8063, 465.8063,   6.8828,   6.8825, 465.8063, 465.8063,\n",
      "        465.8063, 465.8063, 465.8063,  78.3900,  78.3900,   6.8825, 465.8063,\n",
      "        465.8063, 465.8063, 465.8063, 465.8063,  78.3900,  78.3900, 465.8063,\n",
      "         78.3900,  78.3900,   5.2026, 465.8063, 465.8063, 465.8063, 465.8063,\n",
      "        465.8063,  78.3900,  78.3900, 465.8063,  78.3900,  78.3900,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 465.8063,   5.2026,   5.2025, 465.8063,   5.2026,\n",
      "          5.2025, 465.8063,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        465.8063, 465.8063, 465.8063, 465.8063,  78.3900,  78.3900,  78.3900,\n",
      "         78.3900, 465.8063, 465.8063, 465.8063,  78.3900,  78.3900,  78.3900,\n",
      "         78.3900,   5.2026,  78.3900,  78.3900,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 817 was 96.4%\n",
      "tensor([8.2976e-07, 2.0070e-06, 0.0000e+00, 2.0834e-05, 1.9931e-07, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7770e-06, 2.8855e-06, 2.7174e-06,\n",
      "        6.5534e-06, 6.6711e-06, 6.4510e-06, 2.5127e-06, 2.6831e-06, 3.6739e-06,\n",
      "        3.6097e-06, 2.1290e-01, 2.3511e-01, 8.9385e-01, 8.7225e-01, 2.5783e-06,\n",
      "        3.7082e-06, 2.1853e-01, 8.8830e-01, 1.9429e-01, 9.1328e-01, 2.4680e-01,\n",
      "        9.6432e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([251.4651, 299.9932, 317.7619, 297.9934,   6.9263,   6.4455,   7.0797,\n",
      "        466.2266, 466.2266, 466.2266,   6.8761,   6.8784, 466.2266, 466.2266,\n",
      "        466.2266, 466.2266, 466.2266,  78.4691,  78.4691,   6.8785, 466.2266,\n",
      "        466.2266, 466.2266, 466.2266, 466.2266,  78.4691,  78.4691, 466.2266,\n",
      "         78.4691,  78.4691,   5.2026, 466.2266, 466.2266, 466.2266, 466.2266,\n",
      "        466.2266,  78.4691,  78.4691, 466.2266,  78.4691,  78.4691,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 466.2266,   5.2026,   5.2025, 466.2266,   5.2026,\n",
      "          5.2025, 466.2266,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        466.2266, 466.2266, 466.2266, 466.2266,  78.4691,  78.4691,  78.4691,\n",
      "         78.4691, 466.2266, 466.2266, 466.2266,  78.4691,  78.4691,  78.4691,\n",
      "         78.4691,   5.2026,  78.4691,  78.4691,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 818 was 96.4%\n",
      "tensor([0.0000e+00, 2.2499e-06, 6.0927e-07, 4.4777e-06, 0.0000e+00, 2.0338e-09,\n",
      "        1.3150e-09, 1.3130e-09, 1.3131e-09, 2.7684e-06, 2.8747e-06, 2.7113e-06,\n",
      "        6.4359e-06, 6.5508e-06, 6.3471e-06, 2.5069e-06, 2.6743e-06, 3.6055e-06,\n",
      "        3.5320e-06, 2.1232e-01, 2.3433e-01, 8.9136e-01, 8.6994e-01, 2.5708e-06,\n",
      "        3.6351e-06, 2.1796e-01, 8.8581e-01, 1.9392e-01, 9.1060e-01, 2.4604e-01,\n",
      "        9.6442e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([251.6788, 300.3217, 318.0076, 298.1959,   6.9175,   6.4427,   7.0677,\n",
      "        466.6469, 466.6469, 466.6469,   6.8719,   6.8744, 466.6469, 466.6469,\n",
      "        466.6469, 466.6469, 466.6469,  78.5482,  78.5482,   6.8717, 466.6469,\n",
      "        466.6469, 466.6469, 466.6469, 466.6469,  78.5482,  78.5482, 466.6469,\n",
      "         78.5482,  78.5482,   5.2026, 466.6469, 466.6469, 466.6469, 466.6469,\n",
      "        466.6469,  78.5482,  78.5482, 466.6469,  78.5482,  78.5482,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 466.6469,   5.2026,   5.2025, 466.6469,   5.2026,\n",
      "          5.2025, 466.6469,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        466.6469, 466.6469, 466.6469, 466.6469,  78.5482,  78.5482,  78.5482,\n",
      "         78.5482, 466.6469, 466.6469, 466.6469,  78.5482,  78.5482,  78.5482,\n",
      "         78.5482,   5.2026,  78.5482,  78.5482,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 819 was 96.4%\n",
      "tensor([0.0000e+00, 2.2440e-06, 5.1914e-07, 4.5661e-06, 0.0000e+00, 2.0438e-09,\n",
      "        1.3192e-09, 1.3179e-09, 1.3184e-09, 2.7604e-06, 2.8639e-06, 2.7043e-06,\n",
      "        6.3101e-06, 6.4207e-06, 6.2374e-06, 2.5003e-06, 2.6647e-06, 3.5334e-06,\n",
      "        3.4519e-06, 2.1178e-01, 2.3354e-01, 8.8878e-01, 8.6761e-01, 2.5639e-06,\n",
      "        3.5605e-06, 2.1733e-01, 8.8331e-01, 1.9353e-01, 9.0788e-01, 2.4528e-01,\n",
      "        9.6452e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([251.8929, 300.6497, 318.2536, 298.3981,   6.9086,   6.4399,   7.0556,\n",
      "        467.0671, 467.0671, 467.0671,   6.8664,   6.8690, 467.0671, 467.0671,\n",
      "        467.0671, 467.0671, 467.0671,  78.6274,  78.6274,   6.8676, 467.0671,\n",
      "        467.0671, 467.0671, 467.0671, 467.0671,  78.6274,  78.6274, 467.0671,\n",
      "         78.6274,  78.6274,   5.2026, 467.0671, 467.0671, 467.0671, 467.0671,\n",
      "        467.0671,  78.6274,  78.6274, 467.0671,  78.6274,  78.6274,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 467.0671,   5.2026,   5.2025, 467.0671,   5.2026,\n",
      "          5.2025, 467.0671,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        467.0671, 467.0671, 467.0671, 467.0671,  78.6274,  78.6274,  78.6274,\n",
      "         78.6274, 467.0671, 467.0671, 467.0671,  78.6274,  78.6274,  78.6274,\n",
      "         78.6274,   5.2026,  78.6274,  78.6274,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 820 was 96.4%\n",
      "tensor([0.0000e+00, 2.2439e-06, 4.4989e-07, 4.2627e-06, 8.4703e-22, 1.8790e-09,\n",
      "        1.2106e-09, 1.2101e-09, 1.2107e-09, 2.7518e-06, 2.8532e-06, 2.6980e-06,\n",
      "        6.1833e-06, 6.2902e-06, 6.1250e-06, 2.4938e-06, 2.6560e-06, 3.4609e-06,\n",
      "        3.3699e-06, 2.1122e-01, 2.3273e-01, 8.8623e-01, 8.6531e-01, 2.5561e-06,\n",
      "        3.4836e-06, 2.1676e-01, 8.8079e-01, 1.9313e-01, 9.0518e-01, 2.4452e-01,\n",
      "        9.6462e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([252.1113, 300.9801, 318.5006, 298.5946,   6.8997,   6.4371,   7.0433,\n",
      "        467.4874, 467.4874, 467.4874,   6.8622,   6.8637, 467.4874, 467.4874,\n",
      "        467.4874, 467.4874, 467.4874,  78.7065,  78.7065,   6.8622, 467.4874,\n",
      "        467.4874, 467.4874, 467.4874, 467.4874,  78.7065,  78.7065, 467.4874,\n",
      "         78.7065,  78.7065,   5.2026, 467.4874, 467.4874, 467.4874, 467.4874,\n",
      "        467.4874,  78.7065,  78.7065, 467.4874,  78.7065,  78.7065,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 467.4874,   5.2026,   5.2025, 467.4874,   5.2026,\n",
      "          5.2025, 467.4874,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        467.4874, 467.4874, 467.4874, 467.4874,  78.7065,  78.7065,  78.7065,\n",
      "         78.7065, 467.4874, 467.4874, 467.4874,  78.7065,  78.7065,  78.7065,\n",
      "         78.7065,   5.2026,  78.7065,  78.7065,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 821 was 96.4%\n",
      "tensor([6.1530e-08, 2.3003e-06, 3.2267e-06, 1.6941e-21, 3.6046e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7437e-06, 2.8425e-06, 2.6914e-06,\n",
      "        6.0558e-06, 6.1590e-06, 6.0132e-06, 2.4869e-06, 2.6470e-06, 3.3882e-06,\n",
      "        3.2887e-06, 2.1068e-01, 2.3192e-01, 8.8365e-01, 8.6298e-01, 2.5485e-06,\n",
      "        3.4078e-06, 2.1615e-01, 8.7827e-01, 1.9273e-01, 9.0246e-01, 2.4376e-01,\n",
      "        9.6473e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([252.3312, 301.3095, 318.7485, 298.7895,   6.8908,   6.4343,   7.0309,\n",
      "        467.9077, 467.9077, 467.9077,   6.8566,   6.8584, 467.9077, 467.9077,\n",
      "        467.9077, 467.9077, 467.9077,  78.7856,  78.7856,   6.8581, 467.9077,\n",
      "        467.9077, 467.9077, 467.9077, 467.9077,  78.7856,  78.7856, 467.9077,\n",
      "         78.7856,  78.7856,   5.2026, 467.9077, 467.9077, 467.9077, 467.9077,\n",
      "        467.9077,  78.7856,  78.7856, 467.9077,  78.7856,  78.7856,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 467.9077,   5.2026,   5.2025, 467.9077,   5.2026,\n",
      "          5.2025, 467.9077,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        467.9077, 467.9077, 467.9077, 467.9077,  78.7856,  78.7856,  78.7856,\n",
      "         78.7856, 467.9077, 467.9077, 467.9077,  78.7856,  78.7856,  78.7856,\n",
      "         78.7856,   5.2026,  78.7856,  78.7856,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 822 was 96.4%\n",
      "tensor([0.0000e+00, 2.2385e-06, 2.7588e-07, 3.9950e-06, 2.5411e-21, 1.7060e-09,\n",
      "        1.0952e-09, 1.0960e-09, 1.0971e-09, 2.7350e-06, 2.8318e-06, 2.6851e-06,\n",
      "        5.9298e-06, 6.0293e-06, 5.9016e-06, 2.4805e-06, 2.6383e-06, 3.3164e-06,\n",
      "        3.2082e-06, 2.1012e-01, 2.3111e-01, 8.8109e-01, 8.6068e-01, 2.5406e-06,\n",
      "        3.3318e-06, 2.1557e-01, 8.7573e-01, 1.9235e-01, 8.9975e-01, 2.4299e-01,\n",
      "        9.6483e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([252.5444, 301.6347, 318.9947, 298.9933,   6.8818,   6.4315,   7.0186,\n",
      "        468.3280, 468.3280, 468.3280,   6.8524,   6.8530, 468.3280, 468.3280,\n",
      "        468.3280, 468.3280, 468.3280,  78.8647,  78.8647,   6.8526, 468.3280,\n",
      "        468.3280, 468.3280, 468.3280, 468.3280,  78.8647,  78.8647, 468.3280,\n",
      "         78.8647,  78.8647,   5.2026, 468.3280, 468.3280, 468.3280, 468.3280,\n",
      "        468.3280,  78.8647,  78.8647, 468.3280,  78.8647,  78.8647,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 468.3280,   5.2026,   5.2025, 468.3280,   5.2026,\n",
      "          5.2025, 468.3280,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        468.3280, 468.3280, 468.3280, 468.3280,  78.8647,  78.8647,  78.8647,\n",
      "         78.8647, 468.3280, 468.3280, 468.3280,  78.8647,  78.8647,  78.8647,\n",
      "         78.8647,   5.2026,  78.8647,  78.8647,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 823 was 96.4%\n",
      "tensor([0.0000e+00, 2.2378e-06, 1.9957e-07, 3.7135e-06, 0.0000e+00, 1.5604e-09,\n",
      "        9.9965e-10, 1.0010e-09, 1.0022e-09, 2.7270e-06, 2.8211e-06, 2.6785e-06,\n",
      "        5.8050e-06, 5.9008e-06, 5.7905e-06, 2.4736e-06, 2.6293e-06, 3.2438e-06,\n",
      "        3.1276e-06, 2.0959e-01, 2.3030e-01, 8.7851e-01, 8.5837e-01, 2.5331e-06,\n",
      "        3.2563e-06, 2.1497e-01, 8.7322e-01, 1.9194e-01, 8.9705e-01, 2.4223e-01,\n",
      "        9.6493e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([252.7576, 301.9594, 319.2410, 299.1973,   6.8728,   6.4286,   7.0063,\n",
      "        468.7483, 468.7483, 468.7483,   6.8482,   6.8476, 468.7483, 468.7483,\n",
      "        468.7483, 468.7483, 468.7483,  78.9439,  78.9439,   6.8471, 468.7483,\n",
      "        468.7483, 468.7483, 468.7483, 468.7483,  78.9439,  78.9439, 468.7483,\n",
      "         78.9439,  78.9439,   5.2026, 468.7483, 468.7483, 468.7483, 468.7483,\n",
      "        468.7483,  78.9439,  78.9439, 468.7483,  78.9439,  78.9439,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 468.7483,   5.2026,   5.2025, 468.7483,   5.2026,\n",
      "          5.2025, 468.7483,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        468.7483, 468.7483, 468.7483, 468.7483,  78.9439,  78.9439,  78.9439,\n",
      "         78.9439, 468.7483, 468.7483, 468.7483,  78.9439,  78.9439,  78.9439,\n",
      "         78.9439,   5.2026,  78.9439,  78.9439,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 824 was 96.5%\n",
      "tensor([5.8777e-08, 2.2839e-06, 3.5260e-06, 0.0000e+00, 3.6907e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7189e-06, 2.8104e-06, 2.6718e-06,\n",
      "        5.6808e-06, 5.7731e-06, 5.6794e-06, 2.4668e-06, 2.6206e-06, 3.1713e-06,\n",
      "        3.0475e-06, 2.0906e-01, 2.2949e-01, 8.7595e-01, 8.5606e-01, 2.5257e-06,\n",
      "        3.1811e-06, 2.1436e-01, 8.7073e-01, 1.9156e-01, 8.9434e-01, 2.4147e-01,\n",
      "        9.6503e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([252.9709, 302.2833, 319.4875, 299.4014,   6.8638,   6.4258,   6.9939,\n",
      "        469.1686, 469.1686, 469.1686,   6.8413,   6.8434, 469.1686, 469.1686,\n",
      "        469.1686, 469.1686, 469.1686,  79.0230,  79.0230,   6.8430, 469.1686,\n",
      "        469.1686, 469.1686, 469.1686, 469.1686,  79.0230,  79.0230, 469.1686,\n",
      "         79.0230,  79.0230,   5.2026, 469.1686, 469.1686, 469.1686, 469.1686,\n",
      "        469.1686,  79.0230,  79.0230, 469.1686,  79.0230,  79.0230,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 469.1686,   5.2026,   5.2025, 469.1686,   5.2026,\n",
      "          5.2025, 469.1686,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        469.1686, 469.1686, 469.1686, 469.1686,  79.0230,  79.0230,  79.0230,\n",
      "         79.0230, 469.1686, 469.1686, 469.1686,  79.0230,  79.0230,  79.0230,\n",
      "         79.0230,   5.2026,  79.0230,  79.0230,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 825 was 96.5%\n",
      "tensor([0.0000e+00, 2.2350e-06, 6.2189e-08, 3.2308e-06, 3.3881e-21, 1.3139e-09,\n",
      "        8.3819e-10, 8.4026e-10, 8.4151e-10, 2.7100e-06, 2.7996e-06, 2.6657e-06,\n",
      "        5.5618e-06, 5.6503e-06, 5.5719e-06, 2.4610e-06, 2.6114e-06, 3.1016e-06,\n",
      "        2.9704e-06, 2.0848e-01, 2.2870e-01, 8.7342e-01, 8.5375e-01, 2.5180e-06,\n",
      "        3.1074e-06, 2.1378e-01, 8.6820e-01, 1.9118e-01, 8.9163e-01, 2.4071e-01,\n",
      "        9.6513e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([253.1841, 302.6066, 319.7341, 299.6056,   6.8547,   6.4230,   6.9814,\n",
      "        469.5889, 469.5889, 469.5889,   6.8370,   6.8380, 469.5889, 469.5889,\n",
      "        469.5889, 469.5889, 469.5889,  79.1021,  79.1021,   6.8375, 469.5889,\n",
      "        469.5889, 469.5889, 469.5889, 469.5889,  79.1021,  79.1021, 469.5889,\n",
      "         79.1021,  79.1021,   5.2026, 469.5889, 469.5889, 469.5889, 469.5889,\n",
      "        469.5889,  79.1021,  79.1021, 469.5889,  79.1021,  79.1021,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 469.5889,   5.2026,   5.2025, 469.5889,   5.2026,\n",
      "          5.2025, 469.5889,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        469.5889, 469.5889, 469.5889, 469.5889,  79.1021,  79.1021,  79.1021,\n",
      "         79.1021, 469.5889, 469.5889, 469.5889,  79.1021,  79.1021,  79.1021,\n",
      "         79.1021,   5.2026,  79.1021,  79.1021,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 826 was 96.5%\n",
      "tensor([5.8809e-08, 2.2730e-06, 4.2320e-06, 3.8116e-21, 4.2846e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7019e-06, 2.7889e-06, 2.6590e-06,\n",
      "        5.4382e-06, 5.5230e-06, 5.4608e-06, 2.4541e-06, 2.6024e-06, 3.0293e-06,\n",
      "        2.8912e-06, 2.0795e-01, 2.2789e-01, 8.7084e-01, 8.5143e-01, 2.5104e-06,\n",
      "        3.0327e-06, 2.1317e-01, 8.6570e-01, 1.9078e-01, 8.8893e-01, 2.3995e-01,\n",
      "        9.6523e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([253.3974, 302.9293, 319.9808, 299.8099,   6.8456,   6.4201,   6.9689,\n",
      "        470.0092, 470.0092, 470.0092,   6.8327,   6.8325, 470.0092, 470.0092,\n",
      "        470.0092, 470.0092, 470.0092,  79.1812,  79.1812,   6.8319, 470.0092,\n",
      "        470.0092, 470.0092, 470.0092, 470.0092,  79.1812,  79.1812, 470.0092,\n",
      "         79.1812,  79.1812,   5.2026, 470.0092, 470.0092, 470.0092, 470.0092,\n",
      "        470.0092,  79.1812,  79.1812, 470.0092,  79.1812,  79.1812,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 470.0092,   5.2026,   5.2025, 470.0092,   5.2026,\n",
      "          5.2025, 470.0092,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        470.0092, 470.0092, 470.0092, 470.0092,  79.1812,  79.1812,  79.1812,\n",
      "         79.1812, 470.0092, 470.0092, 470.0092,  79.1812,  79.1812,  79.1812,\n",
      "         79.1812,   5.2026,  79.1812,  79.1812,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 827 was 96.5%\n",
      "tensor([5.9766e-08, 2.2676e-06, 4.6165e-06, 0.0000e+00, 4.6728e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6939e-06, 2.7782e-06, 2.6524e-06,\n",
      "        5.3159e-06, 5.3973e-06, 5.3505e-06, 2.4473e-06, 2.5936e-06, 2.9571e-06,\n",
      "        2.8123e-06, 2.0742e-01, 2.2709e-01, 8.6826e-01, 8.4913e-01, 2.5029e-06,\n",
      "        2.9581e-06, 2.1256e-01, 8.6320e-01, 1.9039e-01, 8.8622e-01, 2.3919e-01,\n",
      "        9.6533e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([253.6107, 303.2514, 320.2276, 300.0144,   6.8365,   6.4173,   6.9562,\n",
      "        470.4295, 470.4295, 470.4295,   6.8257,   6.8284, 470.4295, 470.4295,\n",
      "        470.4295, 470.4295, 470.4295,  79.2604,  79.2604,   6.8278, 470.4295,\n",
      "        470.4295, 470.4295, 470.4295, 470.4295,  79.2604,  79.2604, 470.4295,\n",
      "         79.2604,  79.2604,   5.2026, 470.4295, 470.4295, 470.4295, 470.4295,\n",
      "        470.4295,  79.2604,  79.2604, 470.4295,  79.2604,  79.2604,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 470.4295,   5.2026,   5.2025, 470.4295,   5.2026,\n",
      "          5.2025, 470.4295,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        470.4295, 470.4295, 470.4295, 470.4295,  79.2604,  79.2604,  79.2604,\n",
      "         79.2604, 470.4295, 470.4295, 470.4295,  79.2604,  79.2604,  79.2604,\n",
      "         79.2604,   5.2026,  79.2604,  79.2604,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 828 was 96.5%\n",
      "tensor([0.0000e+00, 2.2277e-06, 0.0000e+00, 2.6747e-06, 0.0000e+00, 1.0325e-09,\n",
      "        6.5424e-10, 6.5685e-10, 6.5835e-10, 2.6850e-06, 2.7673e-06, 2.6463e-06,\n",
      "        5.1993e-06, 5.2769e-06, 5.2438e-06, 2.4416e-06, 2.5845e-06, 2.8879e-06,\n",
      "        2.7366e-06, 2.0684e-01, 2.2629e-01, 8.6574e-01, 8.4682e-01, 2.4953e-06,\n",
      "        2.8852e-06, 2.1198e-01, 8.6067e-01, 1.9001e-01, 8.8351e-01, 2.3843e-01,\n",
      "        9.6543e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([253.8241, 303.5729, 320.4745, 300.2189,   6.8273,   6.4144,   6.9435,\n",
      "        470.8497, 470.8497, 470.8497,   6.8214,   6.8228, 470.8497, 470.8497,\n",
      "        470.8497, 470.8497, 470.8497,  79.3395,  79.3395,   6.8223, 470.8497,\n",
      "        470.8497, 470.8497, 470.8497, 470.8497,  79.3395,  79.3395, 470.8497,\n",
      "         79.3395,  79.3395,   5.2026, 470.8497, 470.8497, 470.8497, 470.8497,\n",
      "        470.8497,  79.3395,  79.3395, 470.8497,  79.3395,  79.3395,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 470.8497,   5.2026,   5.2025, 470.8497,   5.2026,\n",
      "          5.2025, 470.8497,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        470.8497, 470.8497, 470.8497, 470.8497,  79.3395,  79.3395,  79.3395,\n",
      "         79.3395, 470.8497, 470.8497, 470.8497,  79.3395,  79.3395,  79.3395,\n",
      "         79.3395,   5.2026,  79.3395,  79.3395,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 829 was 96.5%\n",
      "tensor([1.0365e-07, 2.2241e-06, 1.0903e-05, 0.0000e+00, 1.1033e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6769e-06, 2.7565e-06, 2.6396e-06,\n",
      "        5.0772e-06, 5.1512e-06, 5.1329e-06, 2.4347e-06, 2.5755e-06, 2.8159e-06,\n",
      "        2.6588e-06, 2.0631e-01, 2.2548e-01, 8.6315e-01, 8.4449e-01, 2.4877e-06,\n",
      "        2.8112e-06, 2.1137e-01, 8.5817e-01, 1.8961e-01, 8.8079e-01, 2.3766e-01,\n",
      "        9.6553e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([254.0295, 303.9018, 320.7181, 300.4290,   6.8179,   6.4113,   6.9315,\n",
      "        471.2700, 471.2700, 471.2700,   6.8171,   6.8173, 471.2700, 471.2700,\n",
      "        471.2700, 471.2700, 471.2700,  79.4186,  79.4186,   6.8164, 471.2700,\n",
      "        471.2700, 471.2700, 471.2700, 471.2700,  79.4186,  79.4186, 471.2700,\n",
      "         79.4186,  79.4186,   5.2026, 471.2700, 471.2700, 471.2700, 471.2700,\n",
      "        471.2700,  79.4186,  79.4186, 471.2700,  79.4186,  79.4186,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 471.2700,   5.2026,   5.2025, 471.2700,   5.2026,\n",
      "          5.2025, 471.2700,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        471.2700, 471.2700, 471.2700, 471.2700,  79.4186,  79.4186,  79.4186,\n",
      "         79.4186, 471.2700, 471.2700, 471.2700,  79.4186,  79.4186,  79.4186,\n",
      "         79.4186,   5.2026,  79.4186,  79.4186,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 830 was 96.5%\n",
      "tensor([7.7112e-08, 2.2537e-06, 7.6497e-06, 4.2352e-22, 7.7395e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6691e-06, 2.7462e-06, 2.6328e-06,\n",
      "        4.9583e-06, 5.0292e-06, 5.0240e-06, 2.4278e-06, 2.5669e-06, 2.7432e-06,\n",
      "        2.5801e-06, 2.0578e-01, 2.2469e-01, 8.6060e-01, 8.4220e-01, 2.4804e-06,\n",
      "        2.7367e-06, 2.1078e-01, 8.5568e-01, 1.8921e-01, 8.7813e-01, 2.3691e-01,\n",
      "        9.6563e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([254.2388, 304.2257, 320.9636, 300.6367,   6.8086,   6.4084,   6.9190,\n",
      "        471.6903, 471.6903, 471.6903,   6.8113,   6.8117, 471.6903, 471.6903,\n",
      "        471.6903, 471.6903, 471.6903,  79.4977,  79.4977,   6.8122, 471.6903,\n",
      "        471.6903, 471.6903, 471.6903, 471.6903,  79.4977,  79.4977, 471.6903,\n",
      "         79.4977,  79.4977,   5.2026, 471.6903, 471.6903, 471.6903, 471.6903,\n",
      "        471.6903,  79.4977,  79.4977, 471.6903,  79.4977,  79.4977,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 471.6903,   5.2026,   5.2025, 471.6903,   5.2026,\n",
      "          5.2025, 471.6903,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        471.6903, 471.6903, 471.6903, 471.6903,  79.4977,  79.4977,  79.4977,\n",
      "         79.4977, 471.6903, 471.6903, 471.6903,  79.4977,  79.4977,  79.4977,\n",
      "         79.4977,   5.2026,  79.4977,  79.4977,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 831 was 96.5%\n",
      "tensor([9.9200e-08, 2.2178e-06, 1.0765e-05, 0.0000e+00, 1.0891e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6610e-06, 2.7361e-06, 2.6273e-06,\n",
      "        4.8405e-06, 4.9078e-06, 4.9168e-06, 2.4215e-06, 2.5583e-06, 2.6740e-06,\n",
      "        2.5041e-06, 2.0524e-01, 2.2392e-01, 8.5812e-01, 8.3994e-01, 2.4724e-06,\n",
      "        2.6633e-06, 2.1019e-01, 8.5325e-01, 1.8882e-01, 8.7552e-01, 2.3619e-01,\n",
      "        9.6573e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([254.4481, 304.5542, 321.2085, 300.8424,   6.8039,   6.4053,   6.9067,\n",
      "        472.1106, 472.1106, 472.1106,   6.8056,   6.8059, 472.1106, 472.1106,\n",
      "        472.1106, 472.1106, 472.1106,  79.5769,  79.5769,   6.8032, 472.1106,\n",
      "        472.1106, 472.1106, 472.1106, 472.1106,  79.5769,  79.5769, 472.1106,\n",
      "         79.5769,  79.5769,   5.2026, 472.1106, 472.1106, 472.1106, 472.1106,\n",
      "        472.1106,  79.5769,  79.5769, 472.1106,  79.5769,  79.5769,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 472.1106,   5.2026,   5.2025, 472.1106,   5.2026,\n",
      "          5.2025, 472.1106,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        472.1106, 472.1106, 472.1106, 472.1106,  79.5769,  79.5769,  79.5769,\n",
      "         79.5769, 472.1106, 472.1106, 472.1106,  79.5769,  79.5769,  79.5769,\n",
      "         79.5769,   5.2026,  79.5769,  79.5769,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 832 was 96.5%\n",
      "tensor([9.4452e-08, 2.2367e-06, 1.0328e-05, 1.6094e-20, 1.0442e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6519e-06, 2.7265e-06, 2.6207e-06,\n",
      "        4.7321e-06, 4.7987e-06, 4.8243e-06, 2.4160e-06, 2.5495e-06, 2.6115e-06,\n",
      "        2.4391e-06, 2.0480e-01, 2.2320e-01, 8.5554e-01, 8.3764e-01, 2.4653e-06,\n",
      "        2.6013e-06, 2.0952e-01, 8.5089e-01, 1.8836e-01, 8.7295e-01, 2.3546e-01,\n",
      "        9.6583e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([254.6591, 304.8811, 321.4542, 301.0468,   6.7993,   6.4023,   6.8941,\n",
      "        472.5309, 472.5309, 472.5309,   6.7984,   6.7970, 472.5309, 472.5309,\n",
      "        472.5309, 472.5309, 472.5309,  79.6560,  79.6560,   6.7989, 472.5309,\n",
      "        472.5309, 472.5309, 472.5309, 472.5309,  79.6560,  79.6560, 472.5309,\n",
      "         79.6560,  79.6560,   5.2026, 472.5309, 472.5309, 472.5309, 472.5309,\n",
      "        472.5309,  79.6560,  79.6560, 472.5309,  79.6560,  79.6560,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 472.5309,   5.2026,   5.2025, 472.5309,   5.2026,\n",
      "          5.2025, 472.5309,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        472.5309, 472.5309, 472.5309, 472.5309,  79.6560,  79.6560,  79.6560,\n",
      "         79.6560, 472.5309, 472.5309, 472.5309,  79.6560,  79.6560,  79.6560,\n",
      "         79.6560,   5.2026,  79.6560,  79.6560,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 833 was 96.5%\n",
      "tensor([0.0000e+00, 2.2118e-06, 0.0000e+00, 2.0816e-06, 1.0164e-20, 7.3324e-10,\n",
      "        4.5986e-10, 4.6163e-10, 4.6525e-10, 2.6413e-06, 2.7168e-06, 2.6153e-06,\n",
      "        4.6174e-06, 4.6795e-06, 4.7218e-06, 2.4099e-06, 2.5405e-06, 2.5442e-06,\n",
      "        2.3670e-06, 2.0433e-01, 2.2244e-01, 8.5297e-01, 8.3536e-01, 2.4558e-06,\n",
      "        2.5324e-06, 2.0894e-01, 8.4843e-01, 1.8788e-01, 8.7041e-01, 2.3472e-01,\n",
      "        9.6593e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([254.8717, 305.2041, 321.7007, 301.2510,   6.7898,   6.3993,   6.8812,\n",
      "        472.9512, 472.9512, 472.9512,   6.7927,   6.7942, 472.9512, 472.9512,\n",
      "        472.9512, 472.9512, 472.9512,  79.7351,  79.7351,   6.7918, 472.9512,\n",
      "        472.9512, 472.9512, 472.9512, 472.9512,  79.7351,  79.7351, 472.9512,\n",
      "         79.7351,  79.7351,   5.2026, 472.9512, 472.9512, 472.9512, 472.9512,\n",
      "        472.9512,  79.7351,  79.7351, 472.9512,  79.7351,  79.7351,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 472.9512,   5.2026,   5.2025, 472.9512,   5.2026,\n",
      "          5.2025, 472.9512,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        472.9512, 472.9512, 472.9512, 472.9512,  79.7351,  79.7351,  79.7351,\n",
      "         79.7351, 472.9512, 472.9512, 472.9512,  79.7351,  79.7351,  79.7351,\n",
      "         79.7351,   5.2026,  79.7351,  79.7351,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 834 was 96.6%\n",
      "tensor([1.1795e-07, 2.7125e-06, 1.3786e-05, 0.0000e+00, 1.3919e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6330e-06, 2.7062e-06, 2.6094e-06,\n",
      "        4.5074e-06, 4.5682e-06, 4.6232e-06, 2.4033e-06, 2.5306e-06, 2.4805e-06,\n",
      "        2.2992e-06, 2.0380e-01, 2.2170e-01, 8.5047e-01, 8.3305e-01, 2.4484e-06,\n",
      "        2.4662e-06, 2.0829e-01, 8.4604e-01, 1.8749e-01, 8.6776e-01, 2.3400e-01,\n",
      "        9.6603e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([255.0849, 305.5271, 321.9472, 301.4549,   6.7852,   6.3964,   6.8682,\n",
      "        473.3714, 473.3714, 473.3714,   6.7855,   6.7852, 473.3714, 473.3714,\n",
      "        473.3714, 473.3714, 473.3714,  79.8142,  79.8142,   6.7876, 473.3714,\n",
      "        473.3714, 473.3714, 473.3714, 473.3714,  79.8142,  79.8142, 473.3714,\n",
      "         79.8142,  79.8142,   5.2026, 473.3714, 473.3714, 473.3714, 473.3714,\n",
      "        473.3714,  79.8142,  79.8142, 473.3714,  79.8142,  79.8142,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 473.3714,   5.2026,   5.2025, 473.3714,   5.2026,\n",
      "          5.2025, 473.3714,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        473.3714, 473.3714, 473.3714, 473.3714,  79.8142,  79.8142,  79.8142,\n",
      "         79.8142, 473.3714, 473.3714, 473.3714,  79.8142,  79.8142,  79.8142,\n",
      "         79.8142,   5.2026,  79.8142,  79.8142,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 835 was 96.6%\n",
      "tensor([1.4211e-07, 1.0164e-20, 1.7508e-05, 2.9163e-07, 1.7703e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6314e-06, 2.6998e-06, 2.6027e-06,\n",
      "        4.3925e-06, 4.4494e-06, 4.5202e-06, 2.4058e-06, 2.5310e-06, 2.4121e-06,\n",
      "        2.2272e-06, 2.0332e-01, 2.2090e-01, 8.4789e-01, 8.3077e-01, 2.4474e-06,\n",
      "        2.3973e-06, 2.0770e-01, 8.4356e-01, 1.8703e-01, 8.6516e-01, 2.3326e-01,\n",
      "        9.6613e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([255.2984, 305.8487, 322.1938, 301.6590,   6.7790,   6.3935,   6.8550,\n",
      "        473.7917, 473.7917, 473.7917,   6.7782,   6.7824, 473.7917, 473.7917,\n",
      "        473.7917, 473.7917, 473.7917,  79.8934,  79.8934,   6.7788, 473.7917,\n",
      "        473.7917, 473.7917, 473.7917, 473.7917,  79.8934,  79.8934, 473.7917,\n",
      "         79.8934,  79.8934,   5.2026, 473.7917, 473.7917, 473.7917, 473.7917,\n",
      "        473.7917,  79.8934,  79.8934, 473.7917,  79.8934,  79.8934,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 473.7917,   5.2026,   5.2025, 473.7917,   5.2026,\n",
      "          5.2025, 473.7917,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        473.7917, 473.7917, 473.7917, 473.7917,  79.8934,  79.8934,  79.8934,\n",
      "         79.8934, 473.7917, 473.7917, 473.7917,  79.8934,  79.8934,  79.8934,\n",
      "         79.8934,   5.2026,  79.8934,  79.8934,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 836 was 96.6%\n",
      "tensor([5.0996e-07, 6.5620e-06, 5.2284e-05, 0.0000e+00, 6.3488e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5948e-06, 2.6767e-06, 2.5991e-06,\n",
      "        4.2923e-06, 4.3487e-06, 4.4322e-06, 2.3754e-06, 2.4942e-06, 2.3559e-06,\n",
      "        2.1692e-06, 2.0282e-01, 2.2021e-01, 8.4538e-01, 8.2841e-01, 2.4147e-06,\n",
      "        2.3406e-06, 2.0700e-01, 8.4124e-01, 1.8660e-01, 8.6255e-01, 2.3253e-01,\n",
      "        9.6622e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([255.5119, 306.1685, 322.4403, 301.8642,   6.7728,   6.3906,   6.8417,\n",
      "        474.2120, 474.2120, 474.2120,   6.7738,   6.7736, 474.2120, 474.2120,\n",
      "        474.2120, 474.2120, 474.2120,  79.9725,  79.9725,   6.7732, 474.2120,\n",
      "        474.2120, 474.2120, 474.2120, 474.2120,  79.9725,  79.9725, 474.2120,\n",
      "         79.9725,  79.9725,   5.2026, 474.2120, 474.2120, 474.2120, 474.2120,\n",
      "        474.2120,  79.9725,  79.9725, 474.2120,  79.9725,  79.9725,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 474.2120,   5.2026,   5.2025, 474.2120,   5.2026,\n",
      "          5.2025, 474.2120,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        474.2120, 474.2120, 474.2120, 474.2120,  79.9725,  79.9725,  79.9725,\n",
      "         79.9725, 474.2120, 474.2120, 474.2120,  79.9725,  79.9725,  79.9725,\n",
      "         79.9725,   5.2026,  79.9725,  79.9725,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 837 was 96.6%\n",
      "tensor([0.0000e+00, 2.1294e-06, 1.0588e-20, 7.6317e-06, 7.3347e-07, 2.5571e-09,\n",
      "        1.5868e-09, 1.6019e-09, 1.6149e-09, 2.6066e-06, 2.6770e-06, 2.5911e-06,\n",
      "        4.2961e-06, 4.3538e-06, 4.4493e-06, 2.3876e-06, 2.5058e-06, 2.3631e-06,\n",
      "        2.1896e-06, 2.0239e-01, 2.1939e-01, 8.4263e-01, 8.2607e-01, 2.4253e-06,\n",
      "        2.3512e-06, 2.0638e-01, 8.3867e-01, 1.8613e-01, 8.5991e-01, 2.3176e-01,\n",
      "        9.6633e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([255.7262, 306.4918, 322.6854, 302.0684,   6.7681,   6.3876,   6.8284,\n",
      "        474.6323, 474.6323, 474.6323,   6.7651,   6.7660, 474.6323, 474.6323,\n",
      "        474.6323, 474.6323, 474.6323,  80.0516,  80.0516,   6.7690, 474.6323,\n",
      "        474.6323, 474.6323, 474.6323, 474.6323,  80.0516,  80.0516, 474.6323,\n",
      "         80.0516,  80.0516,   5.2026, 474.6323, 474.6323, 474.6323, 474.6323,\n",
      "        474.6323,  80.0516,  80.0516, 474.6323,  80.0516,  80.0516,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 474.6323,   5.2026,   5.2025, 474.6323,   5.2026,\n",
      "          5.2025, 474.6323,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        474.6323, 474.6323, 474.6323, 474.6323,  80.0516,  80.0516,  80.0516,\n",
      "         80.0516, 474.6323, 474.6323, 474.6323,  80.0516,  80.0516,  80.0516,\n",
      "         80.0516,   5.2026,  80.0516,  80.0516,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 838 was 96.6%\n",
      "tensor([0.0000e+00, 2.1447e-06, 0.0000e+00, 5.9383e-06, 6.8611e-07, 1.9506e-09,\n",
      "        1.2068e-09, 1.2192e-09, 1.2300e-09, 2.5966e-06, 2.6676e-06, 2.5861e-06,\n",
      "        4.1888e-06, 4.2435e-06, 4.3534e-06, 2.3834e-06, 2.4978e-06, 2.3003e-06,\n",
      "        2.1233e-06, 2.0190e-01, 2.1864e-01, 8.4011e-01, 8.2381e-01, 2.4166e-06,\n",
      "        2.2870e-06, 2.0578e-01, 8.3626e-01, 1.8569e-01, 8.5735e-01, 2.3104e-01,\n",
      "        9.6642e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([255.9405, 306.8156, 322.9296, 302.2729,   6.7603,   6.3847,   6.8149,\n",
      "        475.0526, 475.0526, 475.0526,   6.7606,   6.7620, 475.0526, 475.0526,\n",
      "        475.0526, 475.0526, 475.0526,  80.1308,  80.1308,   6.7601, 475.0526,\n",
      "        475.0526, 475.0526, 475.0526, 475.0526,  80.1308,  80.1308, 475.0526,\n",
      "         80.1308,  80.1308,   5.2026, 475.0526, 475.0526, 475.0526, 475.0526,\n",
      "        475.0526,  80.1308,  80.1308, 475.0526,  80.1308,  80.1308,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 475.0526,   5.2026,   5.2025, 475.0526,   5.2026,\n",
      "          5.2025, 475.0526,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        475.0526, 475.0526, 475.0526, 475.0526,  80.1308,  80.1308,  80.1308,\n",
      "         80.1308, 475.0526, 475.0526, 475.0526,  80.1308,  80.1308,  80.1308,\n",
      "         80.1308,   5.2026,  80.1308,  80.1308,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 839 was 96.6%\n",
      "tensor([4.6544e-08, 2.2070e-06, 3.0165e-06, 4.2352e-21, 2.6532e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5914e-06, 2.6622e-06, 2.5794e-06,\n",
      "        4.0812e-06, 4.1348e-06, 4.2567e-06, 2.3794e-06, 2.4908e-06, 2.2352e-06,\n",
      "        2.0562e-06, 2.0143e-01, 2.1789e-01, 8.3750e-01, 8.2146e-01, 2.4124e-06,\n",
      "        2.2228e-06, 2.0510e-01, 8.3386e-01, 1.8527e-01, 8.5470e-01, 2.3029e-01,\n",
      "        9.6652e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([256.1550, 307.1403, 323.1729, 302.4778,   6.7555,   6.3817,   6.8013,\n",
      "        475.4729, 475.4729, 475.4729,   6.7533,   6.7530, 475.4729, 475.4729,\n",
      "        475.4729, 475.4729, 475.4729,  80.2099,  80.2099,   6.7559, 475.4729,\n",
      "        475.4729, 475.4729, 475.4729, 475.4729,  80.2099,  80.2099, 475.4729,\n",
      "         80.2099,  80.2099,   5.2026, 475.4729, 475.4729, 475.4729, 475.4729,\n",
      "        475.4729,  80.2099,  80.2099, 475.4729,  80.2099,  80.2099,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 475.4729,   5.2026,   5.2025, 475.4729,   5.2026,\n",
      "          5.2025, 475.4729,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        475.4729, 475.4729, 475.4729, 475.4729,  80.2099,  80.2099,  80.2099,\n",
      "         80.2099, 475.4729, 475.4729, 475.4729,  80.2099,  80.2099,  80.2099,\n",
      "         80.2099,   5.2026,  80.2099,  80.2099,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 840 was 96.6%\n",
      "tensor([0.0000e+00, 3.8179e-06, 5.3701e-07, 1.6869e-06, 0.0000e+00, 1.5504e-09,\n",
      "        1.0094e-09, 1.0022e-09, 1.0322e-09, 2.5572e-06, 2.6389e-06, 2.5737e-06,\n",
      "        5.3832e-06, 5.4835e-06, 5.6129e-06, 2.3520e-06, 2.4593e-06, 3.1241e-06,\n",
      "        3.1239e-06, 2.0082e-01, 2.1695e-01, 8.3490e-01, 8.1904e-01, 2.3806e-06,\n",
      "        3.1291e-06, 2.0434e-01, 8.3140e-01, 1.8467e-01, 8.5148e-01, 2.2937e-01,\n",
      "        9.6663e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([256.3721, 307.4670, 323.4113, 302.6842,   6.7478,   6.3789,   6.7879,\n",
      "        475.8931, 475.8931, 475.8931,   6.7474,   6.7500, 475.8931, 475.8931,\n",
      "        475.8931, 475.8931, 475.8931,  80.2890,  80.2890,   6.7469, 475.8931,\n",
      "        475.8931, 475.8931, 475.8931, 475.8931,  80.2890,  80.2890, 475.8931,\n",
      "         80.2890,  80.2890,   5.2026, 475.8931, 475.8931, 475.8931, 475.8931,\n",
      "        475.8931,  80.2890,  80.2890, 475.8931,  80.2890,  80.2890,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 475.8931,   5.2026,   5.2025, 475.8931,   5.2026,\n",
      "          5.2025, 475.8931,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        475.8931, 475.8931, 475.8931, 475.8931,  80.2890,  80.2890,  80.2890,\n",
      "         80.2890, 475.8931, 475.8931, 475.8931,  80.2890,  80.2890,  80.2890,\n",
      "         80.2890,   5.2026,  80.2890,  80.2890,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 841 was 96.6%\n",
      "tensor([0.0000e+00, 9.2478e-06, 6.5480e-07, 1.7390e-06, 0.0000e+00, 4.3989e-09,\n",
      "        2.8591e-09, 2.8402e-09, 2.9263e-09, 2.4971e-06, 2.6112e-06, 2.5699e-06,\n",
      "        5.2938e-06, 5.3895e-06, 5.5339e-06, 2.2984e-06, 2.4002e-06, 3.0741e-06,\n",
      "        3.0676e-06, 2.0031e-01, 2.1622e-01, 8.3233e-01, 8.1669e-01, 2.3256e-06,\n",
      "        3.0764e-06, 2.0366e-01, 8.2901e-01, 1.8425e-01, 8.4883e-01, 2.2864e-01,\n",
      "        9.6673e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([256.5893, 307.7935, 323.6493, 302.8910,   6.7416,   6.3761,   6.7745,\n",
      "        476.3134, 476.3134, 476.3134,   6.7414,   6.7408, 476.3134, 476.3134,\n",
      "        476.3134, 476.3134, 476.3134,  80.3681,  80.3681,   6.7425, 476.3134,\n",
      "        476.3134, 476.3134, 476.3134, 476.3134,  80.3681,  80.3681, 476.3134,\n",
      "         80.3681,  80.3681,   5.2026, 476.3134, 476.3134, 476.3134, 476.3134,\n",
      "        476.3134,  80.3681,  80.3681, 476.3134,  80.3681,  80.3681,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 476.3134,   5.2026,   5.2025, 476.3134,   5.2026,\n",
      "          5.2025, 476.3134,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        476.3134, 476.3134, 476.3134, 476.3134,  80.3681,  80.3681,  80.3681,\n",
      "         80.3681, 476.3134, 476.3134, 476.3134,  80.3681,  80.3681,  80.3681,\n",
      "         80.3681,   5.2026,  80.3681,  80.3681,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 842 was 96.6%\n",
      "tensor([2.2136e-07, 9.0322e-05, 8.3313e-05, 0.0000e+00, 8.8527e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3155e-06, 2.6989e-06,\n",
      "        5.2004e-06, 5.2962e-06, 5.4528e-06, 1.7191e-09, 0.0000e+00, 3.0232e-06,\n",
      "        3.0109e-06, 1.9986e-01, 2.1541e-01, 8.2980e-01, 8.1442e-01, 0.0000e+00,\n",
      "        3.0224e-06, 2.0306e-01, 8.2660e-01, 1.8380e-01, 8.4630e-01, 2.2788e-01,\n",
      "        9.6683e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([256.8066, 308.1197, 323.8871, 303.0979,   6.7337,   6.3733,   6.7611,\n",
      "        476.7337, 476.7337, 476.7337,   6.7355,   6.7378, 476.7337, 476.7337,\n",
      "        476.7337, 476.7337, 476.7337,  80.4473,  80.4473,   6.7334, 476.7337,\n",
      "        476.7337, 476.7337, 476.7337, 476.7337,  80.4473,  80.4473, 476.7337,\n",
      "         80.4473,  80.4473,   5.2026, 476.7337, 476.7337, 476.7337, 476.7337,\n",
      "        476.7337,  80.4473,  80.4473, 476.7337,  80.4473,  80.4473,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 476.7337,   5.2026,   5.2025, 476.7337,   5.2026,\n",
      "          5.2025, 476.7337,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        476.7337, 476.7337, 476.7337, 476.7337,  80.4473,  80.4473,  80.4473,\n",
      "         80.4473, 476.7337, 476.7337, 476.7337,  80.4473,  80.4473,  80.4473,\n",
      "         80.4473,   5.2026,  80.4473,  80.4473,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 843 was 96.6%\n",
      "tensor([3.2749e-06, 1.0487e-04, 6.5364e-05, 2.4864e-05, 4.8287e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5736e-05, 5.4327e-05, 1.7364e-20,\n",
      "        5.1161e-06, 5.2073e-06, 5.3805e-06, 5.0764e-05, 3.8848e-05, 2.9750e-06,\n",
      "        2.9586e-06, 1.9937e-01, 2.1469e-01, 8.2732e-01, 8.1230e-01, 5.2018e-05,\n",
      "        2.9729e-06, 2.0238e-01, 8.2440e-01, 1.8340e-01, 8.4380e-01, 2.2716e-01,\n",
      "        9.6692e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([257.0238, 308.4457, 324.1249, 303.3049,   6.7290,   6.3704,   6.7464,\n",
      "        477.1540, 477.1540, 477.1540,   6.7286,   6.7290, 477.1540, 477.1540,\n",
      "        477.1540, 477.1540, 477.1540,  80.5264,  80.5264,   6.7290, 477.1540,\n",
      "        477.1540, 477.1540, 477.1540, 477.1540,  80.5264,  80.5264, 477.1540,\n",
      "         80.5264,  80.5264,   5.2026, 477.1540, 477.1540, 477.1540, 477.1540,\n",
      "        477.1540,  80.5264,  80.5264, 477.1540,  80.5264,  80.5264,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 477.1540,   5.2026,   5.2025, 477.1540,   5.2026,\n",
      "          5.2025, 477.1540,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        477.1540, 477.1540, 477.1540, 477.1540,  80.5264,  80.5264,  80.5264,\n",
      "         80.5264, 477.1540, 477.1540, 477.1540,  80.5264,  80.5264,  80.5264,\n",
      "         80.5264,   5.2026,  80.5264,  80.5264,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.5015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 844 was 96.7%\n",
      "tensor([0.0000e+00, 1.6602e-19, 6.1707e-06, 6.5985e-04, 9.7001e-07, 3.3375e-07,\n",
      "        2.1565e-07, 2.1456e-07, 2.2148e-07, 2.5381e-06, 2.6022e-06, 2.5456e-06,\n",
      "        4.9380e-06, 5.0075e-06, 5.2044e-06, 2.3443e-06, 2.4393e-06, 2.9177e-06,\n",
      "        2.9088e-06, 1.9869e-01, 2.1362e-01, 8.2381e-01, 8.0979e-01, 2.3648e-06,\n",
      "        2.9136e-06, 2.0152e-01, 8.2098e-01, 1.8271e-01, 8.4023e-01, 2.2639e-01,\n",
      "        9.6705e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([257.2413, 308.7794, 324.3583, 303.5122,   6.7227,   6.3674,   6.7338,\n",
      "        477.5743, 477.5743, 477.5743,   6.7237,   6.7228, 477.5743, 477.5743,\n",
      "        477.5743, 477.5743, 477.5743,  80.6055,  80.6055,   6.7194, 477.5743,\n",
      "        477.5743, 477.5743, 477.5743, 477.5743,  80.6055,  80.6055, 477.5743,\n",
      "         80.6055,  80.6055,   5.2026, 477.5743, 477.5743, 477.5743, 477.5743,\n",
      "        477.5743,  80.6055,  80.6055, 477.5743,  80.6055,  80.6055,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 477.5743,   5.2026,   5.2025, 477.5743,   5.2026,\n",
      "          5.2025, 477.5743,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        477.5743, 477.5743, 477.5743, 477.5743,  80.6055,  80.6055,  80.6055,\n",
      "         80.6055, 477.5743, 477.5743, 477.5743,  80.6055,  80.6055,  80.6055,\n",
      "         80.6055,   5.2026,  80.6055,  80.6055,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.4436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 845 was 96.7%\n",
      "tensor([0.0000e+00, 0.0000e+00, 6.3530e-06, 6.6545e-04, 6.2010e-07, 3.3260e-07,\n",
      "        2.1452e-07, 2.1352e-07, 2.2058e-07, 2.5299e-06, 2.5930e-06, 2.5389e-06,\n",
      "        4.8584e-06, 4.9264e-06, 5.1346e-06, 2.3387e-06, 2.4312e-06, 2.8706e-06,\n",
      "        2.8578e-06, 1.9826e-01, 2.1290e-01, 8.2127e-01, 8.0755e-01, 2.3583e-06,\n",
      "        2.8658e-06, 2.0086e-01, 8.1867e-01, 1.8229e-01, 8.3770e-01, 2.2567e-01,\n",
      "        9.6715e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([257.4581, 309.1098, 324.5942, 303.7190,   6.7198,   6.3643,   6.7174,\n",
      "        477.9945, 477.9945, 477.9945,   6.7152,   6.7153, 477.9945, 477.9945,\n",
      "        477.9945, 477.9945, 477.9945,  80.6846,  80.6846,   6.7152, 477.9945,\n",
      "        477.9945, 477.9945, 477.9945, 477.9945,  80.6846,  80.6846, 477.9945,\n",
      "         80.6846,  80.6846,   5.2026, 477.9945, 477.9945, 477.9945, 477.9945,\n",
      "        477.9945,  80.6846,  80.6846, 477.9945,  80.6846,  80.6846,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 477.9945,   5.2026,   5.2025, 477.9945,   5.2026,\n",
      "          5.2025, 477.9945,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        477.9945, 477.9945, 477.9945, 477.9945,  80.6846,  80.6846,  80.6846,\n",
      "         80.6846, 477.9945, 477.9945, 477.9945,  80.6846,  80.6846,  80.6846,\n",
      "         80.6846,   5.2026,  80.6846,  80.6846,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.3519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 846 was 96.7%\n",
      "tensor([0.0000e+00, 4.0483e-05, 7.9955e-07, 3.9569e-04, 0.0000e+00, 1.9504e-07,\n",
      "        1.2531e-07, 1.2485e-07, 1.2905e-07, 2.5195e-06, 2.4812e-06, 2.5354e-06,\n",
      "        4.8198e-06, 4.9027e-06, 5.1219e-06, 2.3347e-06, 2.4226e-06, 2.8238e-06,\n",
      "        2.7943e-06, 1.9801e-01, 2.1232e-01, 8.1903e-01, 8.0537e-01, 2.3487e-06,\n",
      "        2.8109e-06, 2.0036e-01, 8.1666e-01, 1.8196e-01, 8.3564e-01, 2.2492e-01,\n",
      "        9.6723e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([257.6762, 309.4273, 324.8365, 303.9213,   6.7071,   6.3614,   6.7056,\n",
      "        478.4148, 478.4148, 478.4148,   6.7111,   6.7098, 478.4148, 478.4148,\n",
      "        478.4148, 478.4148, 478.4148,  80.7638,  80.7638,   6.7095, 478.4148,\n",
      "        478.4148, 478.4148, 478.4148, 478.4148,  80.7638,  80.7638, 478.4148,\n",
      "         80.7638,  80.7638,   5.2026, 478.4148, 478.4148, 478.4148, 478.4148,\n",
      "        478.4148,  80.7638,  80.7638, 478.4148,  80.7638,  80.7638,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 478.4148,   5.2026,   5.2025, 478.4148,   5.2026,\n",
      "          5.2025, 478.4148,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        478.4148, 478.4148, 478.4148, 478.4148,  80.7638,  80.7638,  80.7638,\n",
      "         80.7638, 478.4148, 478.4148, 478.4148,  80.7638,  80.7638,  80.7638,\n",
      "         80.7638,   5.2026,  80.7638,  80.7638,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 847 was 96.7%\n",
      "tensor([0.0000e+00, 3.9791e-05, 7.4706e-07, 3.8552e-04, 1.0164e-20, 1.8747e-07,\n",
      "        1.2034e-07, 1.1994e-07, 1.2401e-07, 2.5140e-06, 2.4755e-06, 2.5291e-06,\n",
      "        4.7400e-06, 4.8190e-06, 5.0410e-06, 2.3272e-06, 2.4146e-06, 2.7749e-06,\n",
      "        2.7432e-06, 1.9744e-01, 2.1157e-01, 8.1668e-01, 8.0318e-01, 2.3424e-06,\n",
      "        2.7638e-06, 1.9983e-01, 8.1426e-01, 1.8161e-01, 8.3313e-01, 2.2427e-01,\n",
      "        9.6733e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([257.8931, 309.7448, 325.0796, 304.1235,   6.7011,   6.3585,   6.6987,\n",
      "        478.8351, 478.8351, 478.8351,   6.6988,   6.7005, 478.8351, 478.8351,\n",
      "        478.8351, 478.8351, 478.8351,  80.8429,  80.8429,   6.7039, 478.8351,\n",
      "        478.8351, 478.8351, 478.8351, 478.8351,  80.8429,  80.8429, 478.8351,\n",
      "         80.8429,  80.8429,   5.2026, 478.8351, 478.8351, 478.8351, 478.8351,\n",
      "        478.8351,  80.8429,  80.8429, 478.8351,  80.8429,  80.8429,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 478.8351,   5.2026,   5.2025, 478.8351,   5.2026,\n",
      "          5.2025, 478.8351,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        478.8351, 478.8351, 478.8351, 478.8351,  80.8429,  80.8429,  80.8429,\n",
      "         80.8429, 478.8351, 478.8351, 478.8351,  80.8429,  80.8429,  80.8429,\n",
      "         80.8429,   5.2026,  80.8429,  80.8429,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.3030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 848 was 96.7%\n",
      "tensor([0.0000e+00, 3.8571e-05, 7.2849e-07, 3.7572e-04, 0.0000e+00, 1.8066e-07,\n",
      "        1.1586e-07, 1.1549e-07, 1.1948e-07, 2.5046e-06, 2.4779e-06, 2.5225e-06,\n",
      "        4.6666e-06, 4.7475e-06, 4.9745e-06, 2.3223e-06, 2.4084e-06, 2.7335e-06,\n",
      "        2.6994e-06, 1.9683e-01, 2.1096e-01, 8.1447e-01, 8.0097e-01, 2.3353e-06,\n",
      "        2.7187e-06, 1.9941e-01, 8.1189e-01, 1.8107e-01, 8.3085e-01, 2.2363e-01,\n",
      "        9.6742e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([258.1098, 310.0617, 325.3234, 304.3256,   6.6920,   6.3556,   6.6918,\n",
      "        479.2554, 479.2554, 479.2554,   6.6947,   6.6930, 479.2554, 479.2554,\n",
      "        479.2554, 479.2554, 479.2554,  80.9220,  80.9220,   6.6916, 479.2554,\n",
      "        479.2554, 479.2554, 479.2554, 479.2554,  80.9220,  80.9220, 479.2554,\n",
      "         80.9220,  80.9220,   5.2026, 479.2554, 479.2554, 479.2554, 479.2554,\n",
      "        479.2554,  80.9220,  80.9220, 479.2554,  80.9220,  80.9220,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 479.2554,   5.2026,   5.2025, 479.2554,   5.2026,\n",
      "          5.2025, 479.2554,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        479.2554, 479.2554, 479.2554, 479.2554,  80.9220,  80.9220,  80.9220,\n",
      "         80.9220, 479.2554, 479.2554, 479.2554,  80.9220,  80.9220,  80.9220,\n",
      "         80.9220,   5.2026,  80.9220,  80.9220,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.9647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 849 was 96.7%\n",
      "tensor([7.4253e-06, 7.3964e-05, 1.4816e-06, 7.5079e-04, 6.6492e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4963e-06, 2.4187e-06, 2.5109e-06,\n",
      "        4.5678e-06, 4.6338e-06, 4.8663e-06, 2.3114e-06, 2.3980e-06, 2.6915e-06,\n",
      "        2.6640e-06, 1.9625e-01, 2.1022e-01, 8.1176e-01, 7.9877e-01, 2.3279e-06,\n",
      "        2.6821e-06, 1.9870e-01, 8.0928e-01, 1.8044e-01, 8.2820e-01, 2.2297e-01,\n",
      "        9.6752e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([258.3264, 310.3552, 325.5880, 304.5114,   6.6862,   6.3529,   6.6832,\n",
      "        479.6756, 479.6756, 479.6756,   6.6824,   6.6839, 479.6756, 479.6756,\n",
      "        479.6756, 479.6756, 479.6756,  81.0011,  81.0011,   6.6873, 479.6756,\n",
      "        479.6756, 479.6756, 479.6756, 479.6756,  81.0011,  81.0011, 479.6756,\n",
      "         81.0011,  81.0011,   5.2026, 479.6756, 479.6756, 479.6756, 479.6756,\n",
      "        479.6756,  81.0011,  81.0011, 479.6756,  81.0011,  81.0011,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 479.6756,   5.2026,   5.2025, 479.6756,   5.2026,\n",
      "          5.2025, 479.6756,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        479.6756, 479.6756, 479.6756, 479.6756,  81.0011,  81.0011,  81.0011,\n",
      "         81.0011, 479.6756, 479.6756, 479.6756,  81.0011,  81.0011,  81.0011,\n",
      "         81.0011,   5.2026,  81.0011,  81.0011,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.8985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 850 was 96.7%\n",
      "tensor([7.0595e-06, 7.0588e-05, 1.3937e-06, 7.1891e-04, 1.1731e-19, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4872e-06, 2.4275e-06, 2.5059e-06,\n",
      "        4.4993e-06, 4.5691e-06, 4.8056e-06, 2.3068e-06, 2.3922e-06, 2.6540e-06,\n",
      "        2.6241e-06, 1.9566e-01, 2.0965e-01, 8.0960e-01, 7.9658e-01, 2.3201e-06,\n",
      "        2.6402e-06, 1.9829e-01, 8.0696e-01, 1.7992e-01, 8.2597e-01, 2.2233e-01,\n",
      "        9.6761e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([258.5423, 310.6506, 325.8515, 304.6986,   6.6772,   6.3501,   6.6762,\n",
      "        480.0959, 480.0959, 480.0959,   6.6782,   6.6766, 480.0959, 480.0959,\n",
      "        480.0959, 480.0959, 480.0959,  81.0803,  81.0803,   6.6748, 480.0959,\n",
      "        480.0959, 480.0959, 480.0959, 480.0959,  81.0803,  81.0803, 480.0959,\n",
      "         81.0803,  81.0803,   5.2026, 480.0959, 480.0959, 480.0959, 480.0959,\n",
      "        480.0959,  81.0803,  81.0803, 480.0959,  81.0803,  81.0803,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 480.0959,   5.2026,   5.2025, 480.0959,   5.2026,\n",
      "          5.2025, 480.0959,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        480.0959, 480.0959, 480.0959, 480.0959,  81.0803,  81.0803,  81.0803,\n",
      "         81.0803, 480.0959, 480.0959, 480.0959,  81.0803,  81.0803,  81.0803,\n",
      "         81.0803,   5.2026,  81.0803,  81.0803,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.8407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 851 was 96.7%\n",
      "tensor([6.7334e-06, 6.7695e-05, 1.3375e-06, 6.9070e-04, 3.7799e-19, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4816e-06, 2.4323e-06, 2.4971e-06,\n",
      "        4.4360e-06, 4.5014e-06, 4.7384e-06, 2.2986e-06, 2.3846e-06, 2.6126e-06,\n",
      "        2.5825e-06, 1.9517e-01, 2.0904e-01, 8.0725e-01, 7.9431e-01, 2.3154e-06,\n",
      "        2.6025e-06, 1.9769e-01, 8.0470e-01, 1.7940e-01, 8.2364e-01, 2.2168e-01,\n",
      "        9.6770e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([258.7571, 310.9474, 326.1150, 304.8865,   6.6678,   6.3473,   6.6676,\n",
      "        480.5162, 480.5162, 480.5162,   6.6659,   6.6708, 480.5162, 480.5162,\n",
      "        480.5162, 480.5162, 480.5162,  81.1594,  81.1594,   6.6705, 480.5162,\n",
      "        480.5162, 480.5162, 480.5162, 480.5162,  81.1594,  81.1594, 480.5162,\n",
      "         81.1594,  81.1594,   5.2026, 480.5162, 480.5162, 480.5162, 480.5162,\n",
      "        480.5162,  81.1594,  81.1594, 480.5162,  81.1594,  81.1594,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 480.5162,   5.2026,   5.2025, 480.5162,   5.2026,\n",
      "          5.2025, 480.5162,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        480.5162, 480.5162, 480.5162, 480.5162,  81.1594,  81.1594,  81.1594,\n",
      "         81.1594, 480.5162, 480.5162, 480.5162,  81.1594,  81.1594,  81.1594,\n",
      "         81.1594,   5.2026,  81.1594,  81.1594,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.7835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 852 was 96.7%\n",
      "tensor([6.4167e-06, 6.4947e-05, 1.2667e-06, 6.6305e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4742e-06, 2.4355e-06, 2.4922e-06,\n",
      "        4.3710e-06, 4.4353e-06, 4.6763e-06, 2.2933e-06, 2.3771e-06, 2.5756e-06,\n",
      "        2.5422e-06, 1.9450e-01, 2.0847e-01, 8.0514e-01, 7.9209e-01, 2.3085e-06,\n",
      "        2.5627e-06, 1.9727e-01, 8.0238e-01, 1.7893e-01, 8.2136e-01, 2.2106e-01,\n",
      "        9.6779e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([258.9714, 311.2455, 326.3775, 305.0757,   6.6604,   6.3445,   6.6604,\n",
      "        480.9365, 480.9365, 480.9365,   6.6617,   6.6582, 480.9365, 480.9365,\n",
      "        480.9365, 480.9365, 480.9365,  81.2385,  81.2385,   6.6614, 480.9365,\n",
      "        480.9365, 480.9365, 480.9365, 480.9365,  81.2385,  81.2385, 480.9365,\n",
      "         81.2385,  81.2385,   5.2026, 480.9365, 480.9365, 480.9365, 480.9365,\n",
      "        480.9365,  81.2385,  81.2385, 480.9365,  81.2385,  81.2385,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 480.9365,   5.2026,   5.2025, 480.9365,   5.2026,\n",
      "          5.2025, 480.9365,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        480.9365, 480.9365, 480.9365, 480.9365,  81.2385,  81.2385,  81.2385,\n",
      "         81.2385, 480.9365, 480.9365, 480.9365,  81.2385,  81.2385,  81.2385,\n",
      "         81.2385,   5.2026,  81.2385,  81.2385,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.7207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 853 was 96.7%\n",
      "tensor([6.0775e-06, 6.2007e-05, 1.1595e-06, 6.3330e-04, 1.3764e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4674e-06, 2.4394e-06, 2.4839e-06,\n",
      "        4.3036e-06, 4.3678e-06, 4.6092e-06, 2.2858e-06, 2.3715e-06, 2.5335e-06,\n",
      "        2.5003e-06, 1.9406e-01, 2.0780e-01, 8.0278e-01, 7.8988e-01, 2.3024e-06,\n",
      "        2.5219e-06, 1.9675e-01, 8.0007e-01, 1.7838e-01, 8.1907e-01, 2.2039e-01,\n",
      "        9.6788e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([259.1844, 311.5446, 326.6406, 305.2653,   6.6548,   6.3416,   6.6497,\n",
      "        481.3567, 481.3567, 481.3567,   6.6493,   6.6557, 481.3567, 481.3567,\n",
      "        481.3567, 481.3567, 481.3567,  81.3176,  81.3176,   6.6521, 481.3567,\n",
      "        481.3567, 481.3567, 481.3567, 481.3567,  81.3176,  81.3176, 481.3567,\n",
      "         81.3176,  81.3176,   5.2026, 481.3567, 481.3567, 481.3567, 481.3567,\n",
      "        481.3567,  81.3176,  81.3176, 481.3567,  81.3176,  81.3176,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 481.3567,   5.2026,   5.2025, 481.3567,   5.2026,\n",
      "          5.2025, 481.3567,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        481.3567, 481.3567, 481.3567, 481.3567,  81.3176,  81.3176,  81.3176,\n",
      "         81.3176, 481.3567, 481.3567, 481.3567,  81.3176,  81.3176,  81.3176,\n",
      "         81.3176,   5.2026,  81.3176,  81.3176,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 854 was 96.7%\n",
      "tensor([5.9277e-06, 6.0419e-05, 1.2037e-06, 6.2127e-04, 7.4751e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4598e-06, 2.4418e-06, 2.4788e-06,\n",
      "        4.2413e-06, 4.3052e-06, 4.5520e-06, 2.2815e-06, 2.3635e-06, 2.4988e-06,\n",
      "        2.4639e-06, 1.9349e-01, 2.0734e-01, 8.0059e-01, 7.8761e-01, 2.2959e-06,\n",
      "        2.4863e-06, 1.9616e-01, 7.9789e-01, 1.7789e-01, 8.1681e-01, 2.1980e-01,\n",
      "        9.6797e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([259.3980, 311.8451, 326.9016, 305.4563,   6.6455,   6.3387,   6.6425,\n",
      "        481.7770, 481.7770, 481.7770,   6.6450,   6.6429, 481.7770, 481.7770,\n",
      "        481.7770, 481.7770, 481.7770,  81.3968,  81.3968,   6.6447, 481.7770,\n",
      "        481.7770, 481.7770, 481.7770, 481.7770,  81.3968,  81.3968, 481.7770,\n",
      "         81.3968,  81.3968,   5.2026, 481.7770, 481.7770, 481.7770, 481.7770,\n",
      "        481.7770,  81.3968,  81.3968, 481.7770,  81.3968,  81.3968,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 481.7770,   5.2026,   5.2025, 481.7770,   5.2026,\n",
      "          5.2025, 481.7770,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        481.7770, 481.7770, 481.7770, 481.7770,  81.3968,  81.3968,  81.3968,\n",
      "         81.3968, 481.7770, 481.7770, 481.7770,  81.3968,  81.3968,  81.3968,\n",
      "         81.3968,   5.2026,  81.3968,  81.3968,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.6349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 855 was 96.8%\n",
      "tensor([5.5879e-06, 5.7642e-05, 1.0635e-06, 5.9124e-04, 2.2870e-20, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4526e-06, 2.4427e-06, 2.4710e-06,\n",
      "        4.1717e-06, 4.2357e-06, 4.4816e-06, 2.2731e-06, 2.3576e-06, 2.4559e-06,\n",
      "        2.4204e-06, 1.9299e-01, 2.0661e-01, 7.9820e-01, 7.8538e-01, 2.2893e-06,\n",
      "        2.4434e-06, 1.9570e-01, 7.9546e-01, 1.7735e-01, 8.1445e-01, 2.1911e-01,\n",
      "        9.6806e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([259.6103, 312.1461, 327.1634, 305.6476,   6.6326,   6.3358,   6.6353,\n",
      "        482.1973, 482.1973, 482.1973,   6.6359,   6.6387, 482.1973, 482.1973,\n",
      "        482.1973, 482.1973, 482.1973,  81.4759,  81.4759,   6.6373, 482.1973,\n",
      "        482.1973, 482.1973, 482.1973, 482.1973,  81.4759,  81.4759, 482.1973,\n",
      "         81.4759,  81.4759,   5.2026, 482.1973, 482.1973, 482.1973, 482.1973,\n",
      "        482.1973,  81.4759,  81.4759, 482.1973,  81.4759,  81.4759,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 482.1973,   5.2026,   5.2025, 482.1973,   5.2026,\n",
      "          5.2025, 482.1973,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        482.1973, 482.1973, 482.1973, 482.1973,  81.4759,  81.4759,  81.4759,\n",
      "         81.4759, 482.1973, 482.1973, 482.1973,  81.4759,  81.4759,  81.4759,\n",
      "         81.4759,   5.2026,  81.4759,  81.4759,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 856 was 96.8%\n",
      "tensor([1.2710e-06, 1.4823e-20, 4.6198e-06, 1.2316e-04, 1.5802e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4509e-06, 2.4988e-06, 2.4687e-06,\n",
      "        4.1223e-06, 4.1892e-06, 4.4336e-06, 2.2701e-06, 2.3536e-06, 2.4127e-06,\n",
      "        2.3697e-06, 1.9239e-01, 2.0611e-01, 7.9627e-01, 7.8291e-01, 2.2879e-06,\n",
      "        2.3989e-06, 1.9529e-01, 7.9337e-01, 1.7696e-01, 8.1228e-01, 2.1849e-01,\n",
      "        9.6815e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([259.6635, 312.5617, 327.4301, 305.8696,   6.5733,   6.3323,   6.6802,\n",
      "        482.6176, 482.6176, 482.6176,   6.6295,   6.6264, 482.6176, 482.6176,\n",
      "        482.6176, 482.6176, 482.6176,  81.5550,  81.5550,   6.6290, 482.6176,\n",
      "        482.6176, 482.6176, 482.6176, 482.6176,  81.5550,  81.5550, 482.6176,\n",
      "         81.5550,  81.5550,   5.2026, 482.6176, 482.6176, 482.6176, 482.6176,\n",
      "        482.6176,  81.5550,  81.5550, 482.6176,  81.5550,  81.5550,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 482.6176,   5.2026,   5.2025, 482.6176,   5.2026,\n",
      "          5.2025, 482.6176,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        482.6176, 482.6176, 482.6176, 482.6176,  81.5550,  81.5550,  81.5550,\n",
      "         81.5550, 482.6176, 482.6176, 482.6176,  81.5550,  81.5550,  81.5550,\n",
      "         81.5550,   5.2026,  81.5550,  81.5550,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 857 was 96.8%\n",
      "tensor([2.8153e-06, 1.0319e-04, 6.3303e-05, 2.3785e-05, 7.0840e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2927e-05, 5.1517e-05, 0.0000e+00,\n",
      "        4.1430e-06, 4.2071e-06, 4.3812e-06, 4.8246e-05, 5.1494e-05, 2.3981e-06,\n",
      "        2.3663e-06, 1.9089e-01, 2.0644e-01, 7.9726e-01, 7.8196e-01, 4.9902e-05,\n",
      "        2.3923e-06, 1.9621e-01, 7.9204e-01, 1.7623e-01, 8.1245e-01, 2.1872e-01,\n",
      "        9.6816e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([259.8824, 312.8819, 327.6684, 306.0789,   6.5683,   6.3292,   6.6660,\n",
      "        483.0378, 483.0378, 483.0378,   6.6201,   6.6216, 483.0378, 483.0378,\n",
      "        483.0378, 483.0378, 483.0378,  81.6341,  81.6341,   6.6209, 483.0378,\n",
      "        483.0378, 483.0378, 483.0378, 483.0378,  81.6341,  81.6341, 483.0378,\n",
      "         81.6341,  81.6341,   5.2026, 483.0378, 483.0378, 483.0378, 483.0378,\n",
      "        483.0378,  81.6341,  81.6341, 483.0378,  81.6341,  81.6341,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 483.0378,   5.2026,   5.2025, 483.0378,   5.2026,\n",
      "          5.2025, 483.0378,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        483.0378, 483.0378, 483.0378, 483.0378,  81.6341,  81.6341,  81.6341,\n",
      "         81.6341, 483.0378, 483.0378, 483.0378,  81.6341,  81.6341,  81.6341,\n",
      "         81.6341,   5.2026,  81.6341,  81.6341,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 858 was 96.8%\n",
      "tensor([2.9488e-06, 1.0857e-04, 6.6555e-05, 2.5217e-05, 7.4469e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5899e-05, 5.4416e-05, 1.4823e-20,\n",
      "        4.0638e-06, 4.1262e-06, 4.3110e-06, 5.1043e-05, 5.4291e-05, 2.3563e-06,\n",
      "        2.3206e-06, 1.9037e-01, 2.0573e-01, 7.9465e-01, 7.7955e-01, 5.2668e-05,\n",
      "        2.3477e-06, 1.9554e-01, 7.8959e-01, 1.7575e-01, 8.0981e-01, 2.1798e-01,\n",
      "        9.6826e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.1013, 313.2017, 327.9064, 306.2884,   6.5632,   6.3262,   6.6518,\n",
      "        483.4581, 483.4581, 483.4581,   6.6139,   6.6117, 483.4581, 483.4581,\n",
      "        483.4581, 483.4581, 483.4581,  81.7133,  81.7133,   6.6147, 483.4581,\n",
      "        483.4581, 483.4581, 483.4581, 483.4581,  81.7133,  81.7133, 483.4581,\n",
      "         81.7133,  81.7133,   5.2026, 483.4581, 483.4581, 483.4581, 483.4581,\n",
      "        483.4581,  81.7133,  81.7133, 483.4581,  81.7133,  81.7133,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 483.4581,   5.2026,   5.2025, 483.4581,   5.2026,\n",
      "          5.2025, 483.4581,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        483.4581, 483.4581, 483.4581, 483.4581,  81.7133,  81.7133,  81.7133,\n",
      "         81.7133, 483.4581, 483.4581, 483.4581,  81.7133,  81.7133,  81.7133,\n",
      "         81.7133,   5.2026,  81.7133,  81.7133,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 859 was 96.8%\n",
      "tensor([3.0749e-06, 1.1387e-04, 6.9752e-05, 2.6650e-05, 7.8042e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8835e-05, 5.7329e-05, 0.0000e+00,\n",
      "        3.9826e-06, 4.0430e-06, 4.2388e-06, 5.3818e-05, 5.7063e-05, 2.3116e-06,\n",
      "        2.2737e-06, 1.8994e-01, 2.0491e-01, 7.9200e-01, 7.7728e-01, 5.5390e-05,\n",
      "        2.3015e-06, 1.9490e-01, 7.8715e-01, 1.7529e-01, 8.0720e-01, 2.1723e-01,\n",
      "        9.6836e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.3201, 313.5212, 328.1443, 306.4980,   6.5581,   6.3231,   6.6374,\n",
      "        483.8784, 483.8784, 483.8784,   6.6060,   6.6069, 483.8784, 483.8784,\n",
      "        483.8784, 483.8784, 483.8784,  81.7924,  81.7924,   6.6050, 483.8784,\n",
      "        483.8784, 483.8784, 483.8784, 483.8784,  81.7924,  81.7924, 483.8784,\n",
      "         81.7924,  81.7924,   5.2026, 483.8784, 483.8784, 483.8784, 483.8784,\n",
      "        483.8784,  81.7924,  81.7924, 483.8784,  81.7924,  81.7924,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 483.8784,   5.2026,   5.2025, 483.8784,   5.2026,\n",
      "          5.2025, 483.8784,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        483.8784, 483.8784, 483.8784, 483.8784,  81.7924,  81.7924,  81.7924,\n",
      "         81.7924, 483.8784, 483.8784, 483.8784,  81.7924,  81.7924,  81.7924,\n",
      "         81.7924,   5.2026,  81.7924,  81.7924,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.2022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 860 was 96.8%\n",
      "tensor([3.2312e-06, 1.2013e-04, 7.3517e-05, 2.8355e-05, 8.2229e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2357e-05, 6.0762e-05, 0.0000e+00,\n",
      "        3.9055e-06, 3.9640e-06, 4.1697e-06, 5.7119e-05, 6.0344e-05, 2.2704e-06,\n",
      "        2.2300e-06, 1.8947e-01, 2.0420e-01, 7.8936e-01, 7.7487e-01, 5.8644e-05,\n",
      "        2.2589e-06, 1.9419e-01, 7.8474e-01, 1.7481e-01, 8.0457e-01, 2.1648e-01,\n",
      "        9.6846e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.5389, 313.8405, 328.3819, 306.7077,   6.5530,   6.3200,   6.6230,\n",
      "        484.2987, 484.2987, 484.2987,   6.5981,   6.5970, 484.2987, 484.2987,\n",
      "        484.2987, 484.2987, 484.2987,  81.8715,  81.8715,   6.6003, 484.2987,\n",
      "        484.2987, 484.2987, 484.2987, 484.2987,  81.8715,  81.8715, 484.2987,\n",
      "         81.8715,  81.8715,   5.2026, 484.2987, 484.2987, 484.2987, 484.2987,\n",
      "        484.2987,  81.8715,  81.8715, 484.2987,  81.8715,  81.8715,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 484.2987,   5.2026,   5.2025, 484.2987,   5.2026,\n",
      "          5.2025, 484.2987,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        484.2987, 484.2987, 484.2987, 484.2987,  81.8715,  81.8715,  81.8715,\n",
      "         81.8715, 484.2987, 484.2987, 484.2987,  81.8715,  81.8715,  81.8715,\n",
      "         81.8715,   5.2026,  81.8715,  81.8715,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0730, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 861 was 96.8%\n",
      "tensor([1.3868e-06, 2.1186e-06, 1.3214e-19, 1.6080e-04, 2.0619e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4337e-06, 2.4603e-06, 2.4315e-06,\n",
      "        3.8266e-06, 3.8840e-06, 4.1000e-06, 2.2259e-06, 2.3272e-06, 2.2214e-06,\n",
      "        2.1762e-06, 1.8903e-01, 2.0341e-01, 7.8662e-01, 7.7262e-01, 2.2653e-06,\n",
      "        2.2061e-06, 1.9361e-01, 7.8207e-01, 1.7437e-01, 8.0178e-01, 2.1574e-01,\n",
      "        9.6857e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.7339, 313.9680, 328.7582, 306.9121,   6.5473,   6.3183,   6.5765,\n",
      "        484.7189, 484.7189, 484.7189,   6.6059,   6.5993, 484.7189, 484.7189,\n",
      "        484.7189, 484.7189, 484.7189,  81.9506,  81.9506,   6.5994, 484.7189,\n",
      "        484.7189, 484.7189, 484.7189, 484.7189,  81.9506,  81.9506, 484.7189,\n",
      "         81.9506,  81.9506,   5.2026, 484.7189, 484.7189, 484.7189, 484.7189,\n",
      "        484.7189,  81.9506,  81.9506, 484.7189,  81.9506,  81.9506,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 484.7189,   5.2026,   5.2025, 484.7189,   5.2026,\n",
      "          5.2025, 484.7189,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        484.7189, 484.7189, 484.7189, 484.7189,  81.9506,  81.9506,  81.9506,\n",
      "         81.9506, 484.7189, 484.7189, 484.7189,  81.9506,  81.9506,  81.9506,\n",
      "         81.9506,   5.2026,  81.9506,  81.9506,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.9322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 862 was 96.8%\n",
      "tensor([0.0000e+00, 7.2845e-20, 4.7825e-06, 7.6620e-04, 0.0000e+00, 3.1080e-07,\n",
      "        1.9839e-07, 1.9788e-07, 2.0576e-07, 2.4218e-06, 2.4461e-06, 2.4304e-06,\n",
      "        3.7029e-06, 3.7405e-06, 3.9804e-06, 2.2197e-06, 2.3090e-06, 2.2122e-06,\n",
      "        2.1841e-06, 1.8874e-01, 2.0195e-01, 7.8248e-01, 7.7020e-01, 2.2483e-06,\n",
      "        2.2029e-06, 1.9205e-01, 7.7915e-01, 1.7427e-01, 7.9777e-01, 2.1503e-01,\n",
      "        9.6870e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.9549, 314.3140, 328.9744, 307.1261,   6.5421,   6.3151,   6.5678,\n",
      "        485.1392, 485.1392, 485.1392,   6.5931,   6.5933, 485.1392, 485.1392,\n",
      "        485.1392, 485.1392, 485.1392,  82.0298,  82.0298,   6.5898, 485.1392,\n",
      "        485.1392, 485.1392, 485.1392, 485.1392,  82.0298,  82.0298, 485.1392,\n",
      "         82.0298,  82.0298,   5.2026, 485.1392, 485.1392, 485.1392, 485.1392,\n",
      "        485.1392,  82.0298,  82.0298, 485.1392,  82.0298,  82.0298,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 485.1392,   5.2026,   5.2025, 485.1392,   5.2026,\n",
      "          5.2025, 485.1392,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        485.1392, 485.1392, 485.1392, 485.1392,  82.0298,  82.0298,  82.0298,\n",
      "         82.0298, 485.1392, 485.1392, 485.1392,  82.0298,  82.0298,  82.0298,\n",
      "         82.0298,   5.2026,  82.0298,  82.0298,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.4246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 863 was 96.8%\n",
      "tensor([6.1945e-06, 2.1064e-06, 0.0000e+00, 7.3789e-04, 2.0841e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4141e-06, 2.4368e-06, 2.4251e-06,\n",
      "        3.6452e-06, 3.6862e-06, 3.9328e-06, 2.2156e-06, 2.3012e-06, 2.1651e-06,\n",
      "        2.1292e-06, 1.8820e-01, 2.0148e-01, 7.8030e-01, 7.6795e-01, 2.2419e-06,\n",
      "        2.1529e-06, 1.9160e-01, 7.7689e-01, 1.7374e-01, 7.9559e-01, 2.1431e-01,\n",
      "        9.6879e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.8445, 311.8476, 331.1796, 307.3222,   6.5278,   6.3218,   6.5563,\n",
      "        485.5595, 485.5595, 485.5595,   6.5900,   6.5463, 485.5595, 485.5595,\n",
      "        485.5595, 485.5595, 485.5595,  82.1089,  82.1089,   6.6151, 485.5595,\n",
      "        485.5595, 485.5595, 485.5595, 485.5595,  82.1089,  82.1089, 485.5595,\n",
      "         82.1089,  82.1089,   5.2026, 485.5595, 485.5595, 485.5595, 485.5595,\n",
      "        485.5595,  82.1089,  82.1089, 485.5595,  82.1089,  82.1089,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 485.5595,   5.2026,   5.2025, 485.5595,   5.2026,\n",
      "          5.2025, 485.5595,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        485.5595, 485.5595, 485.5595, 485.5595,  82.1089,  82.1089,  82.1089,\n",
      "         82.1089, 485.5595, 485.5595, 485.5595,  82.1089,  82.1089,  82.1089,\n",
      "         82.1089,   5.2026,  82.1089,  82.1089,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(2.6182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 864 was 96.8%\n",
      "tensor([5.4365e-06, 2.0969e-06, 0.0000e+00, 8.5581e-04, 2.3351e-06, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4094e-06, 2.4330e-06, 2.4208e-06,\n",
      "        2.8479e-06, 2.8560e-06, 2.9967e-06, 2.2169e-06, 2.3194e-06, 1.6132e-06,\n",
      "        1.5616e-06, 1.8794e-01, 2.0138e-01, 7.7975e-01, 7.6707e-01, 2.2284e-06,\n",
      "        1.5935e-06, 1.9106e-01, 7.7679e-01, 1.7390e-01, 7.9504e-01, 2.1465e-01,\n",
      "        9.6881e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "current params: tensor([260.8047, 309.1559, 333.5697, 307.4003,   6.5127,   6.3279,   6.5291,\n",
      "        485.9798, 485.9798, 485.9798,   6.5769,   6.5213, 485.9798, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798,  82.1880,  82.1880,   6.6461, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880, 485.9798,\n",
      "         82.1880,  82.1880,   5.2026, 485.9798, 485.9798, 485.9798, 485.9798,\n",
      "        485.9798,  82.1880,  82.1880, 485.9798,  82.1880,  82.1880,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 485.9798,   5.2026,   5.2025, 485.9798,   5.2026,\n",
      "          5.2025, 485.9798,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880,   5.2026,  82.1880,  82.1880,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n",
      "Killing optimization because too much RAM being used.\n",
      "533012480 0.49640655517578125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<steric_free_simulator.vectorized_rxn_net.VectorizedRxnNet at 0x7f8ef5637eb8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=1000,\n",
    "                  learning_rate=new_kon[0].item()/1e2,\n",
    "                  device='cpu',method=\"RMSprop\")\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9688, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([260.8047, 309.1559, 333.5697, 307.4003,   6.5127,   6.3279,   6.5291,\n",
      "        485.9798, 485.9798, 485.9798,   6.5769,   6.5213, 485.9798, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798,  82.1880,  82.1880,   6.6461, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880, 485.9798,\n",
      "         82.1880,  82.1880,   5.2026, 485.9798, 485.9798, 485.9798, 485.9798,\n",
      "        485.9798,  82.1880,  82.1880, 485.9798,  82.1880,  82.1880,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 485.9798,   5.2026,   5.2025, 485.9798,   5.2026,\n",
      "          5.2025, 485.9798,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880,   5.2026,  82.1880,  82.1880,   5.2026,   5.2026],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(optim.final_yields[-1])\n",
    "print(optim.final_solns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var(v1,v2):\n",
    "    sq_sum=0\n",
    "    for i in range(len(v1)):\n",
    "        sq_sum=(v1[i]-v2[i])**2+sq_sum\n",
    "    \n",
    "    sq_sum = ((sq_sum)**0.5)/(len(v1)-1)\n",
    "    return(sq_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "26.008937252438837\n",
      "Yield:  0.7647179222339995 \n",
      "Params:  [50.28360487 50.06760231 49.24477967 48.15563119  5.19931392  5.19965886\n",
      "  5.19822672 77.6117498  77.6117498  77.6117498   5.19696501  5.19955119\n",
      " 77.6117498  77.6117498  77.6117498  77.6117498  77.6117498  12.96365627\n",
      " 12.96365627  5.19843361 77.6117498  77.6117498  77.6117498  77.6117498\n",
      " 77.6117498  12.96365627 12.96365627 77.6117498  12.96365627 12.96365627\n",
      "  5.20256996 77.6117498  77.6117498  77.6117498  77.6117498  77.6117498\n",
      " 12.96365627 12.96365627 77.6117498  12.96365627 12.96365627  5.20256996\n",
      "  5.20256996  5.20256996  5.20256996  5.20246996  5.20256996  5.20256996\n",
      "  5.20256996  5.20246996  5.20256996  5.20256996  5.20256996  5.20246996\n",
      "  5.20256996  5.20256996  5.20256996  5.20246996 77.6117498   5.20256996\n",
      "  5.20246996 77.6117498   5.20256996  5.20246996 77.6117498   5.20256996\n",
      "  5.20246996  5.20246996  5.20246996  5.20246996 77.6117498  77.6117498\n",
      " 77.6117498  77.6117498  12.96365627 12.96365627 12.96365627 12.96365627\n",
      " 77.6117498  77.6117498  77.6117498  12.96365627 12.96365627 12.96365627\n",
      " 12.96365627  5.20256996 12.96365627 12.96365627  5.20256996  5.20256996]\n",
      "Yield:  0.9688133393172207 \n",
      "Params:  [260.80474379 309.15585444 333.56969976 307.40028681   6.51270626\n",
      "   6.32791213   6.52906865 485.97975086 485.97975086 485.97975086\n",
      "   6.57685345   6.52125125 485.97975086 485.97975086 485.97975086\n",
      " 485.97975086 485.97975086  82.18801871  82.18801871   6.64609651\n",
      " 485.97975086 485.97975086 485.97975086 485.97975086 485.97975086\n",
      "  82.18801871  82.18801871 485.97975086  82.18801871  82.18801871\n",
      "   5.20256996 485.97975086 485.97975086 485.97975086 485.97975086\n",
      " 485.97975086  82.18801871  82.18801871 485.97975086  82.18801871\n",
      "  82.18801871   5.20256996   5.20256996   5.20256996   5.20256996\n",
      "   5.20246996   5.20256996   5.20256996   5.20256996   5.20246996\n",
      "   5.20256996   5.20256996   5.20256996   5.20246996   5.20256996\n",
      "   5.20256996   5.20256996   5.20246996 485.97975086   5.20256996\n",
      "   5.20246996 485.97975086   5.20256996   5.20246996 485.97975086\n",
      "   5.20256996   5.20246996   5.20246996   5.20246996   5.20246996\n",
      " 485.97975086 485.97975086 485.97975086 485.97975086  82.18801871\n",
      "  82.18801871  82.18801871  82.18801871 485.97975086 485.97975086\n",
      " 485.97975086  82.18801871  82.18801871  82.18801871  82.18801871\n",
      "   5.20256996  82.18801871  82.18801871   5.20256996   5.20256996]\n",
      "Max Yield:  0.9688133393172207 \n",
      "Params:  [260.80474379 309.15585444 333.56969976 307.40028681   6.51270626\n",
      "   6.32791213   6.52906865 485.97975086 485.97975086 485.97975086\n",
      "   6.57685345   6.52125125 485.97975086 485.97975086 485.97975086\n",
      " 485.97975086 485.97975086  82.18801871  82.18801871   6.64609651\n",
      " 485.97975086 485.97975086 485.97975086 485.97975086 485.97975086\n",
      "  82.18801871  82.18801871 485.97975086  82.18801871  82.18801871\n",
      "   5.20256996 485.97975086 485.97975086 485.97975086 485.97975086\n",
      " 485.97975086  82.18801871  82.18801871 485.97975086  82.18801871\n",
      "  82.18801871   5.20256996   5.20256996   5.20256996   5.20256996\n",
      "   5.20246996   5.20256996   5.20256996   5.20256996   5.20246996\n",
      "   5.20256996   5.20256996   5.20256996   5.20246996   5.20256996\n",
      "   5.20256996   5.20256996   5.20246996 485.97975086   5.20256996\n",
      "   5.20246996 485.97975086   5.20256996   5.20246996 485.97975086\n",
      "   5.20256996   5.20246996   5.20246996   5.20246996   5.20246996\n",
      " 485.97975086 485.97975086 485.97975086 485.97975086  82.18801871\n",
      "  82.18801871  82.18801871  82.18801871 485.97975086 485.97975086\n",
      " 485.97975086  82.18801871  82.18801871  82.18801871  82.18801871\n",
      "   5.20256996  82.18801871  82.18801871   5.20256996   5.20256996]\n"
     ]
    }
   ],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    final_params.append(optim.final_solns[i].numpy())\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)[sort_indx]\n",
    "sorted_params = np.array(final_params)[sort_indx]\n",
    "\n",
    "p0 = sorted_params[0]\n",
    "var_params = []\n",
    "for i in range(len(sorted_params)):\n",
    "    var_params.append(calc_var(p0,sorted_params[i]))\n",
    "    \n",
    "arg_indx = np.argsort(np.array(var_params))\n",
    "sorted_var = np.array(var_params)[arg_indx]\n",
    "\n",
    "print(sorted_var[0])\n",
    "print(sorted_var[-1])\n",
    "print(\"Yield: \",sorted_yields[arg_indx[0]],\"\\nParams: \",sorted_params[arg_indx[0]])\n",
    "\n",
    "print(\"Yield: \",sorted_yields[arg_indx[-1]],\"\\nParams: \",sorted_params[arg_indx[-1]])\n",
    "print(\"Max Yield: \",sorted_yields[-1],\"\\nParams: \",sorted_params[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "PQ\n",
      "PR\n",
      "PS\n",
      "PT\n",
      "QR\n",
      "QS\n",
      "QT\n",
      "PQR\n",
      "PQS\n",
      "PQT\n",
      "RS\n",
      "RT\n",
      "PRS\n",
      "PRT\n",
      "QRS\n",
      "QRT\n",
      "PQRS\n",
      "PQRT\n",
      "ST\n",
      "PST\n",
      "QST\n",
      "PQST\n",
      "RST\n",
      "PRST\n",
      "QRST\n",
      "PQRST\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'R', 'T', 'Q'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q', 'T'}, {'R', 'S'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q', 'S'}, {'R', 'T'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q', 'R'}, {'S', 'T'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'T'}, {'P', 'R', 'S'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'S'}, {'P', 'R', 'T'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'Q', 'S', 'T'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R', 'Q'}, {'P', 'S', 'T'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'R', 'S', 'T'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'R', 'S', 'Q'}), 'kon': 1.0, 'score': tensor([-72.], dtype=torch.float64), 'koff': 5.380186160021136e-26}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'S', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'S', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'Q', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'R', 'S', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'R', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'R', 'S'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'Q', 'S'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'R', 'Q'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'R', 'Q'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'R', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'R', 'S', 'Q'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'Q', 'S'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'R', 'S'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R', 'Q'}, {'S', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'S'}, {'R', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'T'}, {'R', 'S'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q', 'S', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'Q', 'T'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'R', 'T', 'Q'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'S', 'T', 'Q'}), 'kon': 1.0001, 'score': tensor([-48.], dtype=torch.float64), 'koff': 1.4253065991492085e-15}\n",
      "tensor(6.3279, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'S'}), 'kon': 1.0029, 'score': tensor([-12.], dtype=torch.float64), 'koff': 6.162030569152858}\n",
      "tensor(6.5127, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'R'}), 'kon': 0.9985, 'score': tensor([-12.], dtype=torch.float64), 'koff': 6.134996034798211}\n",
      "tensor(6.5213, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'T'}), 'kon': 0.998, 'score': tensor([-12.], dtype=torch.float64), 'koff': 6.131923928621548}\n",
      "tensor(6.5291, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'T'}), 'kon': 0.9985, 'score': tensor([-12.], dtype=torch.float64), 'koff': 6.134996034798211}\n",
      "tensor(6.5769, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'S'}), 'kon': 0.9986, 'score': tensor([-12.], dtype=torch.float64), 'koff': 6.135610456033548}\n",
      "tensor(6.6461, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'T'}), 'kon': 0.9983, 'score': tensor([-12.], dtype=torch.float64), 'koff': 6.133767192327553}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'S', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'Q', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'Q', 'S'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'R', 'S'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'S', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'Q', 'S', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'S', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'R', 'T', 'Q'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'R', 'S', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q', 'S'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'S', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'R', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'R', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q', 'R'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q', 'S'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'R', 'S'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'R', 'S', 'Q'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q', 'T'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q', 'R'}), 'kon': 12.774, 'score': tensor([-36.], dtype=torch.float64), 'koff': 2.9629584633531247e-09}\n",
      "tensor(260.8047, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q'}), 'kon': 42.024699999999996, 'score': tensor([-12.], dtype=torch.float64), 'koff': 258.20868088491164}\n",
      "tensor(307.4003, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'T'}), 'kon': 39.90999999999999, 'score': tensor([-12.], dtype=torch.float64), 'koff': 245.21551502132888}\n",
      "tensor(309.1559, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R'}), 'kon': 41.7901, 'score': tensor([-12.], dtype=torch.float64), 'koff': 256.767248666821}\n",
      "tensor(333.5697, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'S'}), 'kon': 41.0026, 'score': tensor([-12.], dtype=torch.float64), 'koff': 251.928681438575}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'R'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'R', 'Q'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'Q', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'Q', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'S', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'S', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'S', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'Q', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'R', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'R', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'R', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'R', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'R', 'Q'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R', 'Q'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'R'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'S'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'Q', 'T'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n",
      "tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'R'}), 'kon': 70.43189999999997, 'score': tensor([-24.], dtype=torch.float64), 'koff': 0.0026588989870921097}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off']}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['P', 'PQR', 'PQRS', 'PQRST'], ['Q', 'PQR', 'PQRS', 'PQRST'], ['R', 'PQR', 'PQRS', 'PQRST'], ['S', 'PQS', 'PQRS', 'PQRST'], ['T', 'PQT', 'PQRT', 'PQRST'], ['PQ', 'PQR', 'PQRS', 'PQRST'], ['PR', 'PQR', 'PQRS', 'PQRST'], ['PS', 'PQS', 'PQRS', 'PQRST'], ['PT', 'PQT', 'PQRT', 'PQRST'], ['QR', 'QRS', 'QRST', 'PQRST'], ['QS', 'QRS', 'QRST', 'PQRST'], ['QT', 'QRT', 'QRST', 'PQRST'], ['PQR', 'PQRS', 'PQRST'], ['PQS', 'PQRS', 'PQRST'], ['PQT', 'PQRT', 'PQRST'], ['RS', 'RST', 'PRST', 'PQRST'], ['RT', 'RST', 'PRST', 'PQRST'], ['PRS', 'PRST', 'PQRST'], ['PRT', 'PRST', 'PQRST'], ['QRS', 'QRST', 'PQRST'], ['QRT', 'QRST', 'PQRST'], ['PQRS', 'PQRST'], ['PQRT', 'PQRST'], ['ST', 'PST', 'PQST', 'PQRST'], ['PST', 'PQST', 'PQRST'], ['QST', 'PQST', 'PQRST'], ['PQST', 'PQRST'], ['RST', 'PRST', 'PQRST'], ['PRST', 'PQRST'], ['QRST', 'PQRST'], ['PQRST']]\n",
      "[573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 87.39058867265406, 87.39058867265406, 87.39058867265406, 573.3703395314593, 573.3703395314593, 87.39058867265406, 87.39058867265406, 87.39058867265406, 87.39058867265406, 5.202569958065913, 5.202569958065913, 573.3703395314593, 87.39058867265406, 87.39058867265406, 5.202569958065913, 87.39058867265406, 5.202569958065913, 5.202569958065913, 0]\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "#             #Calculate k_off also\n",
    "#             std_c = Tensor([1.])\n",
    "#             l_kon = torch.log(temp_kon)\n",
    "#             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQRS  :  5.202569958065913\n",
      "PQRT  :  5.202569958065913\n",
      "QRST  :  5.202569958065913\n",
      "PRST  :  5.202569958065913\n",
      "PQST  :  5.202569958065913\n",
      "PQR  :  169.5785073871516\n",
      "PQS  :  169.5785073871516\n",
      "PQT  :  169.5785073871516\n",
      "QRS  :  169.5785073871516\n",
      "QRT  :  169.5785073871516\n",
      "RST  :  169.5785073871516\n",
      "PRS  :  169.5785073871516\n",
      "PRT  :  169.5785073871516\n",
      "PST  :  169.5785073871516\n",
      "QST  :  169.5785073871516\n",
      "PQ  :  1478.7494324085885\n",
      "PR  :  1478.7494324085885\n",
      "PS  :  1478.7494324085885\n",
      "PT  :  1478.7494324085885\n",
      "RS  :  1478.7494324085885\n",
      "RT  :  1478.7494324085885\n",
      "ST  :  1478.7494324085885\n",
      "QR  :  1478.7494324085887\n",
      "QS  :  1478.7494324085887\n",
      "QT  :  1478.7494324085887\n",
      "Q  :  3530.0075807961075\n",
      "T  :  3576.929853183084\n",
      "R  :  3578.599815364904\n",
      "S  :  3602.953711817983\n",
      "P  :  4460.763734756372\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes_list = ['A','B','S','M','AB','BMS','ABS','AMS','ABMS','AM','AS']\n",
    "#nodes_list = ['A','B','ABMS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(2.3907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(8.0513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Using CPU\n",
      "Next time:  tensor(67.2128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "{'P': 0, 'Q': 1, 'R': 2, 'S': 3, 'T': 4, 'PQ': 5, 'PR': 6, 'PS': 7, 'PT': 8, 'QR': 9, 'QS': 10, 'QT': 11, 'PQR': 12, 'PQS': 13, 'PQT': 14, 'RS': 15, 'RT': 16, 'PRS': 17, 'PRT': 18, 'QRS': 19, 'QRT': 20, 'PQRS': 21, 'PQRT': 22, 'ST': 23, 'PST': 24, 'QST': 25, 'PQST': 26, 'RST': 27, 'PRST': 28, 'QRST': 29, 'PQRST': 30}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([1, 8, 64]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i],)\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 0, 'Q': 1, 'R': 2, 'S': 3, 'T': 4, 'PQ': 5, 'PR': 6, 'PS': 7, 'PT': 8, 'QR': 9, 'QS': 10, 'QT': 11, 'PQR': 12, 'PQS': 13, 'PQT': 14, 'RS': 15, 'RT': 16, 'PRS': 17, 'PRT': 18, 'QRS': 19, 'QRT': 20, 'PQRS': 21, 'PQRT': 22, 'ST': 23, 'PST': 24, 'QST': 25, 'PQST': 26, 'RST': 27, 'PRST': 28, 'QRST': 29, 'PQRST': 30}\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  P + Q  ->  PQ\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(260.8047, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([259.4303], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 42.024699999999996, 'k_off': 258.20868088491164, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  P + R  ->  PR\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(309.1559, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([307.5266], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 41.7901, 'k_off': 256.767248666821, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  P + S  ->  PS\n",
      "Net flux:  tensor([-4.1715e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(333.5697, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([331.8117], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 41.0026, 'k_off': 251.928681438575, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  P + T  ->  PT\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(307.4003, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([305.7802], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 39.90999999999999, 'k_off': 245.21551502132888, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  P + QR  ->  PQR\n",
      "Net flux:  tensor([0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 58}\n",
      "Reaction:  P + QS  ->  PQS\n",
      "Net flux:  tensor([0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 61}\n",
      "Reaction:  P + QT  ->  PQT\n",
      "Net flux:  tensor([0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 64}\n",
      "Reaction:  P + RS  ->  PRS\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 70}\n",
      "Reaction:  P + RT  ->  PRT\n",
      "Net flux:  tensor([0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 72}\n",
      "Reaction:  P + QRS  ->  PQRS\n",
      "Net flux:  tensor([60.9239], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 76}\n",
      "Reaction:  P + QRT  ->  PQRT\n",
      "Net flux:  tensor([59.8282], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 77}\n",
      "Reaction:  P + ST  ->  PST\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 78}\n",
      "Reaction:  P + QST  ->  PQST\n",
      "Net flux:  tensor([60.7273], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 83}\n",
      "Reaction:  P + RST  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 86}\n",
      "Reaction:  P + QRST  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 89}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  Q + P  ->  PQ\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(260.8047, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([259.4303], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 42.024699999999996, 'k_off': 258.20868088491164, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  Q + R  ->  QR\n",
      "Net flux:  tensor([1.4829e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5127, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4784], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9985, 'k_off': 6.134996034798211, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  Q + S  ->  QS\n",
      "Net flux:  tensor([1.4525e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.3279, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.2946], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0029, 'k_off': 6.162030569152858, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  Q + T  ->  QT\n",
      "Net flux:  tensor([1.5007e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5291, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4947], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9985, 'k_off': 6.134996034798211, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 6}\n",
      "Reaction:  Q + PR  ->  PQR\n",
      "Net flux:  tensor([0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 7}\n",
      "Reaction:  Q + PS  ->  PQS\n",
      "Net flux:  tensor([0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 8}\n",
      "Reaction:  Q + PT  ->  PQT\n",
      "Net flux:  tensor([0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 9}\n",
      "Reaction:  Q + RS  ->  QRS\n",
      "Net flux:  tensor([85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 71}\n",
      "Reaction:  Q + RT  ->  QRT\n",
      "Net flux:  tensor([92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 73}\n",
      "Reaction:  Q + PRS  ->  PQRS\n",
      "Net flux:  tensor([60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 74}\n",
      "Reaction:  Q + PRT  ->  PQRT\n",
      "Net flux:  tensor([59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 75}\n",
      "Reaction:  Q + ST  ->  QST\n",
      "Net flux:  tensor([87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 79}\n",
      "Reaction:  Q + PST  ->  PQST\n",
      "Net flux:  tensor([60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 81}\n",
      "Reaction:  Q + RST  ->  QRST\n",
      "Net flux:  tensor([17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 87}\n",
      "Reaction:  Q + PRST  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 88}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  R + P  ->  PR\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(309.1559, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([307.5266], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 41.7901, 'k_off': 256.767248666821, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  R + Q  ->  QR\n",
      "Net flux:  tensor([1.4829e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5127, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4784], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9985, 'k_off': 6.134996034798211, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  R + S  ->  RS\n",
      "Net flux:  tensor([1.3832e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5769, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.5422], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9986, 'k_off': 6.135610456033548, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 10}\n",
      "Reaction:  R + T  ->  RT\n",
      "Net flux:  tensor([1.4396e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5213, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4869], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.998, 'k_off': 6.131923928621548, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 11}\n",
      "Reaction:  R + PQ  ->  PQR\n",
      "Net flux:  tensor([0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 12}\n",
      "Reaction:  R + PS  ->  PRS\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 13}\n",
      "Reaction:  R + PT  ->  PRT\n",
      "Net flux:  tensor([0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 14}\n",
      "Reaction:  R + QS  ->  QRS\n",
      "Net flux:  tensor([85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 15}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction:  R + QT  ->  QRT\n",
      "Net flux:  tensor([92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 16}\n",
      "Reaction:  R + PQS  ->  PQRS\n",
      "Net flux:  tensor([60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 17}\n",
      "Reaction:  R + PQT  ->  PQRT\n",
      "Net flux:  tensor([59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 18}\n",
      "Reaction:  R + ST  ->  RST\n",
      "Net flux:  tensor([79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 80}\n",
      "Reaction:  R + PST  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 82}\n",
      "Reaction:  R + QST  ->  QRST\n",
      "Net flux:  tensor([17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 84}\n",
      "Reaction:  R + PQST  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 85}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  S + P  ->  PS\n",
      "Net flux:  tensor([-4.1715e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(333.5697, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([331.8117], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 41.0026, 'k_off': 251.928681438575, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  S + Q  ->  QS\n",
      "Net flux:  tensor([1.4525e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.3279, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.2946], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0029, 'k_off': 6.162030569152858, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  S + R  ->  RS\n",
      "Net flux:  tensor([1.3832e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5769, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.5422], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9986, 'k_off': 6.135610456033548, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 10}\n",
      "Reaction:  S + T  ->  ST\n",
      "Net flux:  tensor([1.3890e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.6461, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.6111], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9983, 'k_off': 6.133767192327553, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 19}\n",
      "Reaction:  S + PQ  ->  PQS\n",
      "Net flux:  tensor([0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 20}\n",
      "Reaction:  S + PR  ->  PRS\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 21}\n",
      "Reaction:  S + PT  ->  PST\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 22}\n",
      "Reaction:  S + QR  ->  QRS\n",
      "Net flux:  tensor([85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 23}\n",
      "Reaction:  S + QT  ->  QST\n",
      "Net flux:  tensor([87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction:  S + PQR  ->  PQRS\n",
      "Net flux:  tensor([60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 25}\n",
      "Reaction:  S + PQT  ->  PQST\n",
      "Net flux:  tensor([60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 26}\n",
      "Reaction:  S + RT  ->  RST\n",
      "Net flux:  tensor([79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 27}\n",
      "Reaction:  S + PRT  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 28}\n",
      "Reaction:  S + QRT  ->  QRST\n",
      "Net flux:  tensor([17.4190], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 29}\n",
      "Reaction:  S + PQRT  ->  PQRST\n",
      "Net flux:  tensor([494.0435], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 30}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  T + P  ->  PT\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(307.4003, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([305.7802], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 39.90999999999999, 'k_off': 245.21551502132888, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  T + Q  ->  QT\n",
      "Net flux:  tensor([1.5007e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5291, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4947], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9985, 'k_off': 6.134996034798211, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 6}\n",
      "Reaction:  T + R  ->  RT\n",
      "Net flux:  tensor([1.4396e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5213, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4869], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.998, 'k_off': 6.131923928621548, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 11}\n",
      "Reaction:  T + S  ->  ST\n",
      "Net flux:  tensor([1.3890e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.6461, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.6111], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.9983, 'k_off': 6.133767192327553, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 19}\n",
      "Reaction:  T + PQ  ->  PQT\n",
      "Net flux:  tensor([0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 31}\n",
      "Reaction:  T + PR  ->  PRT\n",
      "Net flux:  tensor([0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 32}\n",
      "Reaction:  T + PS  ->  PST\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 33}\n",
      "Reaction:  T + QR  ->  QRT\n",
      "Net flux:  tensor([92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 34}\n",
      "Reaction:  T + QS  ->  QST\n",
      "Net flux:  tensor([87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 35}\n",
      "Reaction:  T + PQR  ->  PQRT\n",
      "Net flux:  tensor([59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 36}\n",
      "Reaction:  T + PQS  ->  PQST\n",
      "Net flux:  tensor([60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 37}\n",
      "Reaction:  T + RS  ->  RST\n",
      "Net flux:  tensor([79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 38}\n",
      "Reaction:  T + PRS  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction:  T + QRS  ->  QRST\n",
      "Net flux:  tensor([17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 40}\n",
      "Reaction:  T + PQRS  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 41}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQ + R  ->  PQR\n",
      "Net flux:  tensor([0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 12}\n",
      "Reaction:  PQ + S  ->  PQS\n",
      "Net flux:  tensor([0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 20}\n",
      "Reaction:  PQ + T  ->  PQT\n",
      "Net flux:  tensor([0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 31}\n",
      "Reaction:  PQ + RS  ->  PQRS\n",
      "Net flux:  tensor([3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 42}\n",
      "Reaction:  PQ + RT  ->  PQRT\n",
      "Net flux:  tensor([3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 43}\n",
      "Reaction:  PQ + ST  ->  PQST\n",
      "Net flux:  tensor([3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 44}\n",
      "Reaction:  PQ + RST  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 45}\n",
      "Reaction:  PQ  ->  P + Q\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(260.8047, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([259.4303], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 42.024699999999996, 'k_off': 258.20868088491164, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 0}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PR + Q  ->  PQR\n",
      "Net flux:  tensor([0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 7}\n",
      "Reaction:  PR + S  ->  PRS\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 21}\n",
      "Reaction:  PR + T  ->  PRT\n",
      "Net flux:  tensor([0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 32}\n",
      "Reaction:  PR + QS  ->  PQRS\n",
      "Net flux:  tensor([3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 46}\n",
      "Reaction:  PR + QT  ->  PQRT\n",
      "Net flux:  tensor([3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 47}\n",
      "Reaction:  PR + ST  ->  PRST\n",
      "Net flux:  tensor([3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 48}\n",
      "Reaction:  PR + QST  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 49}\n",
      "Reaction:  PR  ->  P + R\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(309.1559, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([307.5266], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 41.7901, 'k_off': 256.767248666821, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 1}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PS + Q  ->  PQS\n",
      "Net flux:  tensor([0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 8}\n",
      "Reaction:  PS + R  ->  PRS\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 13}\n",
      "Reaction:  PS + T  ->  PST\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 33}\n",
      "Reaction:  PS + QR  ->  PQRS\n",
      "Net flux:  tensor([3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 50}\n",
      "Reaction:  PS + QT  ->  PQST\n",
      "Net flux:  tensor([3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 51}\n",
      "Reaction:  PS + RT  ->  PRST\n",
      "Net flux:  tensor([3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 52}\n",
      "Reaction:  PS + QRT  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 53}\n",
      "Reaction:  PS  ->  P + S\n",
      "Net flux:  tensor([4.1715e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(333.5697, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([331.8117], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 41.0026, 'k_off': 251.928681438575, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 2}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PT + Q  ->  PQT\n",
      "Net flux:  tensor([0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 9}\n",
      "Reaction:  PT + R  ->  PRT\n",
      "Net flux:  tensor([0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 14}\n",
      "Reaction:  PT + S  ->  PST\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 22}\n",
      "Reaction:  PT + QR  ->  PQRT\n",
      "Net flux:  tensor([3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 54}\n",
      "Reaction:  PT + QS  ->  PQST\n",
      "Net flux:  tensor([3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 55}\n",
      "Reaction:  PT + RS  ->  PRST\n",
      "Net flux:  tensor([3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 56}\n",
      "Reaction:  PT + QRS  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 57}\n",
      "Reaction:  PT  ->  P + T\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(307.4003, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([305.7802], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 39.90999999999999, 'k_off': 245.21551502132888, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 3}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QR + S  ->  QRS\n",
      "Net flux:  tensor([85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 23}\n",
      "Reaction:  QR + T  ->  QRT\n",
      "Net flux:  tensor([92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 34}\n",
      "Reaction:  QR + PS  ->  PQRS\n",
      "Net flux:  tensor([3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 50}\n",
      "Reaction:  QR + PT  ->  PQRT\n",
      "Net flux:  tensor([3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 54}\n",
      "Reaction:  QR + P  ->  PQR\n",
      "Net flux:  tensor([0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 58}\n",
      "Reaction:  QR + ST  ->  QRST\n",
      "Net flux:  tensor([1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 59}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction:  QR + PST  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 60}\n",
      "Reaction:  QR  ->  Q + R\n",
      "Net flux:  tensor([-1.4829e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5127, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4784], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.9985, 'k_off': 6.134996034798211, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 4}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QS + R  ->  QRS\n",
      "Net flux:  tensor([85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 15}\n",
      "Reaction:  QS + T  ->  QST\n",
      "Net flux:  tensor([87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 35}\n",
      "Reaction:  QS + PR  ->  PQRS\n",
      "Net flux:  tensor([3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 46}\n",
      "Reaction:  QS + PT  ->  PQST\n",
      "Net flux:  tensor([3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 55}\n",
      "Reaction:  QS + P  ->  PQS\n",
      "Net flux:  tensor([0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 61}\n",
      "Reaction:  QS + RT  ->  QRST\n",
      "Net flux:  tensor([1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 62}\n",
      "Reaction:  QS + PRT  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 63}\n",
      "Reaction:  QS  ->  Q + S\n",
      "Net flux:  tensor([-1.4525e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.3279, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.2946], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0029, 'k_off': 6.162030569152858, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QT + R  ->  QRT\n",
      "Net flux:  tensor([92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 16}\n",
      "Reaction:  QT + S  ->  QST\n",
      "Net flux:  tensor([87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction:  QT + PR  ->  PQRT\n",
      "Net flux:  tensor([3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 47}\n",
      "Reaction:  QT + PS  ->  PQST\n",
      "Net flux:  tensor([3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 51}\n",
      "Reaction:  QT + P  ->  PQT\n",
      "Net flux:  tensor([0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 64}\n",
      "Reaction:  QT + RS  ->  QRST\n",
      "Net flux:  tensor([1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 65}\n",
      "Reaction:  QT + PRS  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 66}\n",
      "Reaction:  QT  ->  Q + T\n",
      "Net flux:  tensor([-1.5007e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5291, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4947], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.9985, 'k_off': 6.134996034798211, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 6}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQR + S  ->  PQRS\n",
      "Net flux:  tensor([60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 25}\n",
      "Reaction:  PQR + T  ->  PQRT\n",
      "Net flux:  tensor([59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 36}\n",
      "Reaction:  PQR + ST  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 67}\n",
      "Reaction:  PQR  ->  Q + PR\n",
      "Net flux:  tensor([-0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 7}\n",
      "Reaction:  PQR  ->  R + PQ\n",
      "Net flux:  tensor([-0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 12}\n",
      "Reaction:  PQR  ->  QR + P\n",
      "Net flux:  tensor([-0.0015], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 58}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQS + R  ->  PQRS\n",
      "Net flux:  tensor([60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 17}\n",
      "Reaction:  PQS + T  ->  PQST\n",
      "Net flux:  tensor([60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 37}\n",
      "Reaction:  PQS + RT  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 68}\n",
      "Reaction:  PQS  ->  Q + PS\n",
      "Net flux:  tensor([-0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 8}\n",
      "Reaction:  PQS  ->  S + PQ\n",
      "Net flux:  tensor([-0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 20}\n",
      "Reaction:  PQS  ->  QS + P\n",
      "Net flux:  tensor([-0.0014], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 61}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQT + R  ->  PQRT\n",
      "Net flux:  tensor([59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 18}\n",
      "Reaction:  PQT + S  ->  PQST\n",
      "Net flux:  tensor([60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 26}\n",
      "Reaction:  PQT + RS  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction:  PQT  ->  Q + PT\n",
      "Net flux:  tensor([-0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 9}\n",
      "Reaction:  PQT  ->  T + PQ\n",
      "Net flux:  tensor([-0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 31}\n",
      "Reaction:  PQT  ->  QT + P\n",
      "Net flux:  tensor([-0.0016], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 64}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  RS + T  ->  RST\n",
      "Net flux:  tensor([79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 38}\n",
      "Reaction:  RS + PQ  ->  PQRS\n",
      "Net flux:  tensor([3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 42}\n",
      "Reaction:  RS + PT  ->  PRST\n",
      "Net flux:  tensor([3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 56}\n",
      "Reaction:  RS + QT  ->  QRST\n",
      "Net flux:  tensor([1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 65}\n",
      "Reaction:  RS + PQT  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction:  RS + P  ->  PRS\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 70}\n",
      "Reaction:  RS + Q  ->  QRS\n",
      "Net flux:  tensor([85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 71}\n",
      "Reaction:  RS  ->  R + S\n",
      "Net flux:  tensor([-1.3832e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5769, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.5422], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.9986, 'k_off': 6.135610456033548, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 10}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  RT + S  ->  RST\n",
      "Net flux:  tensor([79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 27}\n",
      "Reaction:  RT + PQ  ->  PQRT\n",
      "Net flux:  tensor([3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 43}\n",
      "Reaction:  RT + PS  ->  PRST\n",
      "Net flux:  tensor([3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 52}\n",
      "Reaction:  RT + QS  ->  QRST\n",
      "Net flux:  tensor([1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 62}\n",
      "Reaction:  RT + PQS  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 68}\n",
      "Reaction:  RT + P  ->  PRT\n",
      "Net flux:  tensor([0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 72}\n",
      "Reaction:  RT + Q  ->  QRT\n",
      "Net flux:  tensor([92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 73}\n",
      "Reaction:  RT  ->  R + T\n",
      "Net flux:  tensor([-1.4396e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.5213, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.4869], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.998, 'k_off': 6.131923928621548, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 11}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PRS + T  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction:  PRS + QT  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 66}\n",
      "Reaction:  PRS + Q  ->  PQRS\n",
      "Net flux:  tensor([60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 74}\n",
      "Reaction:  PRS  ->  R + PS\n",
      "Net flux:  tensor([-0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 13}\n",
      "Reaction:  PRS  ->  S + PR\n",
      "Net flux:  tensor([-0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 21}\n",
      "Reaction:  PRS  ->  RS + P\n",
      "Net flux:  tensor([-0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 70}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PRT + S  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 28}\n",
      "Reaction:  PRT + QS  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 63}\n",
      "Reaction:  PRT + Q  ->  PQRT\n",
      "Net flux:  tensor([59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 75}\n",
      "Reaction:  PRT  ->  R + PT\n",
      "Net flux:  tensor([-0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 14}\n",
      "Reaction:  PRT  ->  T + PR\n",
      "Net flux:  tensor([-0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 32}\n",
      "Reaction:  PRT  ->  RT + P\n",
      "Net flux:  tensor([-0.0013], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 72}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QRS + T  ->  QRST\n",
      "Net flux:  tensor([17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 40}\n",
      "Reaction:  QRS + PT  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 57}\n",
      "Reaction:  QRS + P  ->  PQRS\n",
      "Net flux:  tensor([60.9239], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 76}\n",
      "Reaction:  QRS  ->  R + QS\n",
      "Net flux:  tensor([-85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 15}\n",
      "Reaction:  QRS  ->  S + QR\n",
      "Net flux:  tensor([-85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 23}\n",
      "Reaction:  QRS  ->  RS + Q\n",
      "Net flux:  tensor([-85.7200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 71}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QRT + S  ->  QRST\n",
      "Net flux:  tensor([17.4190], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 29}\n",
      "Reaction:  QRT + PS  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 53}\n",
      "Reaction:  QRT + P  ->  PQRT\n",
      "Net flux:  tensor([59.8282], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 77}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction:  QRT  ->  R + QT\n",
      "Net flux:  tensor([-92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 16}\n",
      "Reaction:  QRT  ->  T + QR\n",
      "Net flux:  tensor([-92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 34}\n",
      "Reaction:  QRT  ->  RT + Q\n",
      "Net flux:  tensor([-92.2744], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 73}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQRS + T  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 41}\n",
      "Reaction:  PQRS  ->  R + PQS\n",
      "Net flux:  tensor([-60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 17}\n",
      "Reaction:  PQRS  ->  S + PQR\n",
      "Net flux:  tensor([-60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 25}\n",
      "Reaction:  PQRS  ->  PQ + RS\n",
      "Net flux:  tensor([-3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 42}\n",
      "Reaction:  PQRS  ->  PR + QS\n",
      "Net flux:  tensor([-3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 46}\n",
      "Reaction:  PQRS  ->  PS + QR\n",
      "Net flux:  tensor([-3.8362], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 50}\n",
      "Reaction:  PQRS  ->  PRS + Q\n",
      "Net flux:  tensor([-60.9240], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 74}\n",
      "Reaction:  PQRS  ->  QRS + P\n",
      "Net flux:  tensor([-60.9239], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 76}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQRT + S  ->  PQRST\n",
      "Net flux:  tensor([494.0435], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 30}\n",
      "Reaction:  PQRT  ->  R + PQT\n",
      "Net flux:  tensor([-59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 18}\n",
      "Reaction:  PQRT  ->  T + PQR\n",
      "Net flux:  tensor([-59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 36}\n",
      "Reaction:  PQRT  ->  PQ + RT\n",
      "Net flux:  tensor([-3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 43}\n",
      "Reaction:  PQRT  ->  PR + QT\n",
      "Net flux:  tensor([-3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 47}\n",
      "Reaction:  PQRT  ->  PT + QR\n",
      "Net flux:  tensor([-3.7672], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 54}\n",
      "Reaction:  PQRT  ->  PRT + Q\n",
      "Net flux:  tensor([-59.8283], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 75}\n",
      "Reaction:  PQRT  ->  QRT + P\n",
      "Net flux:  tensor([-59.8282], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 77}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  ST + PQ  ->  PQST\n",
      "Net flux:  tensor([3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 44}\n",
      "Reaction:  ST + PR  ->  PRST\n",
      "Net flux:  tensor([3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 48}\n",
      "Reaction:  ST + QR  ->  QRST\n",
      "Net flux:  tensor([1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 59}\n",
      "Reaction:  ST + PQR  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 67}\n",
      "Reaction:  ST + P  ->  PST\n",
      "Net flux:  tensor([0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 78}\n",
      "Reaction:  ST + Q  ->  QST\n",
      "Net flux:  tensor([87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 79}\n",
      "Reaction:  ST + R  ->  RST\n",
      "Net flux:  tensor([79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 80}\n",
      "Reaction:  ST  ->  S + T\n",
      "Net flux:  tensor([-1.3890e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(6.6461, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([6.6111], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.9983, 'k_off': 6.133767192327553, 'lcf': 1, 'rxn_score': tensor([-12.], dtype=torch.float64), 'uid': 19}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PST + QR  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 60}\n",
      "Reaction:  PST + Q  ->  PQST\n",
      "Net flux:  tensor([60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 81}\n",
      "Reaction:  PST + R  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 82}\n",
      "Reaction:  PST  ->  S + PT\n",
      "Net flux:  tensor([-0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 22}\n",
      "Reaction:  PST  ->  T + PS\n",
      "Net flux:  tensor([-0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 33}\n",
      "Reaction:  PST  ->  ST + P\n",
      "Net flux:  tensor([-0.0012], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 78}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QST + PR  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 49}\n",
      "Reaction:  QST + P  ->  PQST\n",
      "Net flux:  tensor([60.7273], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 83}\n",
      "Reaction:  QST + R  ->  QRST\n",
      "Net flux:  tensor([17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 84}\n",
      "Reaction:  QST  ->  S + QT\n",
      "Net flux:  tensor([-87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction:  QST  ->  T + QS\n",
      "Net flux:  tensor([-87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 35}\n",
      "Reaction:  QST  ->  ST + Q\n",
      "Net flux:  tensor([-87.0493], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 79}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction:  PQST + R  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 85}\n",
      "Reaction:  PQST  ->  S + PQT\n",
      "Net flux:  tensor([-60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 26}\n",
      "Reaction:  PQST  ->  T + PQS\n",
      "Net flux:  tensor([-60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 37}\n",
      "Reaction:  PQST  ->  PQ + ST\n",
      "Net flux:  tensor([-3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 44}\n",
      "Reaction:  PQST  ->  PS + QT\n",
      "Net flux:  tensor([-3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 51}\n",
      "Reaction:  PQST  ->  PT + QS\n",
      "Net flux:  tensor([-3.8238], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 55}\n",
      "Reaction:  PQST  ->  PST + Q\n",
      "Net flux:  tensor([-60.7274], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 81}\n",
      "Reaction:  PQST  ->  QST + P\n",
      "Net flux:  tensor([-60.7273], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 83}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  RST + PQ  ->  PQRST\n",
      "Net flux:  tensor([488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 45}\n",
      "Reaction:  RST + P  ->  PRST\n",
      "Net flux:  tensor([62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 86}\n",
      "Reaction:  RST + Q  ->  QRST\n",
      "Net flux:  tensor([17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 87}\n",
      "Reaction:  RST  ->  S + RT\n",
      "Net flux:  tensor([-79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 27}\n",
      "Reaction:  RST  ->  T + RS\n",
      "Net flux:  tensor([-79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 38}\n",
      "Reaction:  RST  ->  ST + R\n",
      "Net flux:  tensor([-79.7134], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(485.9798, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([480.8709], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 70.43189999999997, 'k_off': 0.0026588989870921097, 'lcf': 1, 'rxn_score': tensor([-24.], dtype=torch.float64), 'uid': 80}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PRST + Q  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 88}\n",
      "Reaction:  PRST  ->  S + PRT\n",
      "Net flux:  tensor([-62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 28}\n",
      "Reaction:  PRST  ->  T + PRS\n",
      "Net flux:  tensor([-62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction:  PRST  ->  PR + ST\n",
      "Net flux:  tensor([-3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 48}\n",
      "Reaction:  PRST  ->  PS + RT\n",
      "Net flux:  tensor([-3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 52}\n",
      "Reaction:  PRST  ->  PT + RS\n",
      "Net flux:  tensor([-3.9052], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 56}\n",
      "Reaction:  PRST  ->  PST + R\n",
      "Net flux:  tensor([-62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 82}\n",
      "Reaction:  PRST  ->  RST + P\n",
      "Net flux:  tensor([-62.0200], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 86}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QRST + P  ->  PQRST\n",
      "Net flux:  tensor([494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 89}\n",
      "Reaction:  QRST  ->  S + QRT\n",
      "Net flux:  tensor([-17.4190], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 29}\n",
      "Reaction:  QRST  ->  T + QRS\n",
      "Net flux:  tensor([-17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 40}\n",
      "Reaction:  QRST  ->  QR + ST\n",
      "Net flux:  tensor([-1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 59}\n",
      "Reaction:  QRST  ->  QS + RT\n",
      "Net flux:  tensor([-1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 62}\n",
      "Reaction:  QRST  ->  QT + RS\n",
      "Net flux:  tensor([-1.0970], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 65}\n",
      "Reaction:  QRST  ->  QST + R\n",
      "Net flux:  tensor([-17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 84}\n",
      "Reaction:  QRST  ->  RST + Q\n",
      "Net flux:  tensor([-17.4223], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(82.1880, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([80.8954], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 12.774, 'k_off': 2.9629584633531247e-09, 'lcf': 1, 'rxn_score': tensor([-36.], dtype=torch.float64), 'uid': 87}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQRST  ->  S + PQRT\n",
      "Net flux:  tensor([-494.0435], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 30}\n",
      "Reaction:  PQRST  ->  T + PQRS\n",
      "Net flux:  tensor([-494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 41}\n",
      "Reaction:  PQRST  ->  PQ + RST\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 45}\n",
      "Reaction:  PQRST  ->  PR + QST\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 49}\n",
      "Reaction:  PQRST  ->  PS + QRT\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 53}\n",
      "Reaction:  PQRST  ->  PT + QRS\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 57}\n",
      "Reaction:  PQRST  ->  QR + PST\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 60}\n",
      "Reaction:  PQRST  ->  QS + PRT\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 63}\n",
      "Reaction:  PQRST  ->  QT + PRS\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 66}\n",
      "Reaction:  PQRST  ->  PQR + ST\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 67}\n",
      "Reaction:  PQRST  ->  PQS + RT\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 68}\n",
      "Reaction:  PQRST  ->  PQT + RS\n",
      "Net flux:  tensor([-488.8412], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2025, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0401], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 5.380186160021136e-26, 'lcf': 1, 'rxn_score': tensor([-72.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction:  PQRST  ->  PQST + R\n",
      "Net flux:  tensor([-494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 85}\n",
      "Reaction:  PQRST  ->  PRST + Q\n",
      "Net flux:  tensor([-494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 88}\n",
      "Reaction:  PQRST  ->  QRST + P\n",
      "Net flux:  tensor([-494.0443], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(5.2026, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([5.0938], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0001, 'k_off': 1.4253065991492085e-15, 'lcf': 1, 'rxn_score': tensor([-48.], dtype=torch.float64), 'uid': 89}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "[['P', 'PQR', 'PQRS', 'PQRST'], ['Q', 'PQR', 'PQRS', 'PQRST'], ['R', 'PQR', 'PQRS', 'PQRST'], ['S', 'PQS', 'PQRS', 'PQRST'], ['T', 'PQT', 'PQRT', 'PQRST'], ['PQ', 'PQR', 'PQRS', 'PQRST'], ['PR', 'PQR', 'PQRS', 'PQRST'], ['PS', 'PQS', 'PQRS', 'PQRST'], ['PT', 'PQT', 'PQRT', 'PQRST'], ['QR', 'QRS', 'QRST', 'PQRST'], ['QS', 'QRS', 'QRST', 'PQRST'], ['QT', 'QRT', 'QRST', 'PQRST'], ['PQR', 'PQRS', 'PQRST'], ['PQS', 'PQRS', 'PQRST'], ['PQT', 'PQRT', 'PQRST'], ['RS', 'RST', 'PRST', 'PQRST'], ['RT', 'RST', 'PRST', 'PQRST'], ['PRS', 'PRST', 'PQRST'], ['PRT', 'PRST', 'PQRST'], ['QRS', 'QRST', 'PQRST'], ['QRT', 'QRST', 'PQRST'], ['PQRS', 'PQRST'], ['PQRT', 'PQRST'], ['ST', 'PST', 'PQST', 'PQRST'], ['PST', 'PQST', 'PQRST'], ['QST', 'PQST', 'PQRST'], ['PQST', 'PQRST'], ['RST', 'PRST', 'PQRST'], ['PRST', 'PQRST'], ['QRST', 'PQRST'], ['PQRST']]\n",
      "[573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 573.3703395314593, 87.39058867265406, 87.39058867265406, 87.39058867265406, 573.3703395314593, 573.3703395314593, 87.39058867265406, 87.39058867265406, 87.39058867265406, 87.39058867265406, 5.202569958065913, 5.202569958065913, 573.3703395314593, 87.39058867265406, 87.39058867265406, 5.202569958065913, 87.39058867265406, 5.202569958065913, 5.202569958065913, 0]\n"
     ]
    }
   ],
   "source": [
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQRST  :  tensor([-7358.6329], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PRST  :  tensor([234.2485], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQRS  :  tensor([238.8399], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQST  :  tensor([239.6632], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQRT  :  tensor([243.4288], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QRT  :  tensor([289.2652], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QST  :  tensor([305.8430], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QRS  :  tensor([310.0275], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RST  :  tensor([329.1432], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QRST  :  tensor([421.0672], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQ  :  tensor([500.2730], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PT  :  tensor([500.3415], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PR  :  tensor([500.3539], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PS  :  tensor([500.4104], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQT  :  tensor([609.3923], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQR  :  tensor([609.5888], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQS  :  tensor([610.4883], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PRT  :  tensor([610.6855], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PST  :  tensor([611.5850], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PRS  :  tensor([611.7815], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RS  :  tensor([663.1143], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "ST  :  tensor([664.4313], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RT  :  tensor([669.5999], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QS  :  tensor([670.3690], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QR  :  tensor([675.5376], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QT  :  tensor([676.8545], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "P  :  tensor([737.5522], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "S  :  tensor([947.6205], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "R  :  tensor([951.9509], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "T  :  tensor([953.0837], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Q  :  tensor([957.9945], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([5.9966e-06, 0.0000e+00, 1.5197e-06, 2.0855e-04, 1.9664e-06, 0.0000e+00,\n",
      "        3.4150e-07, 0.0000e+00, 3.4322e-07, 2.2890e-06, 2.3075e-06, 2.3107e-06,\n",
      "        3.2099e-06, 2.9813e-06, 3.2320e-06, 2.1147e-06, 2.2192e-06, 2.5726e-06,\n",
      "        2.7817e-06, 1.7826e-01, 1.9189e-01, 7.5312e-01, 7.3958e-01, 2.1014e-06,\n",
      "        2.5787e-06, 1.8102e-01, 7.5069e-01, 1.6577e-01, 7.6667e-01, 2.1537e-01,\n",
      "        9.6990e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "Parameter containing:\n",
      "tensor([260.8047, 309.1559, 333.5697, 307.4003,   6.5127,   6.3279,   6.5291,\n",
      "        485.9798, 485.9798, 485.9798,   6.5769,   6.5213, 485.9798, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798,  82.1880,  82.1880,   6.6461, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880, 485.9798,\n",
      "         82.1880,  82.1880,   5.2026, 485.9798, 485.9798, 485.9798, 485.9798,\n",
      "        485.9798,  82.1880,  82.1880, 485.9798,  82.1880,  82.1880,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 485.9798,   5.2026,   5.2025, 485.9798,   5.2026,\n",
      "          5.2025, 485.9798,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880,   5.2026,  82.1880,  82.1880,   5.2026,   5.2026],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix([[5.996602e-6], [-2.285653e-13], [1.519770e-6], [0.0002085480], [1.966476e-6], [-1.441913e-19], [1.653000e-12], [2.035376e-10], [2.100608e-12], [4.162724e-16], [-2.237439e-16], [4.993409e-16], [2.159226e-10], [-5.553456e-11], [2.260561e-10], [5.158409e-11], [4.859933e-13], [-2.660593e-11], [2.408731e-10], [3.681289e-10], [1.482967e-9], [-0.0002063612], [2.188641e-7], [6.674628e-11], [-1.032411e-11], [4.440829e-10], [-0.0002068080], [-4.343310e-10], [-0.0002083270], [-0.0002023323], [100.0006]])\n",
      "Equilibrium expected yield:  100.000615234375 %\n",
      "Parameter containing:\n",
      "tensor([260.8047, 309.1559, 333.5697, 307.4003,   6.5127,   6.3279,   6.5291,\n",
      "        485.9798, 485.9798, 485.9798,   6.5769,   6.5213, 485.9798, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798,  82.1880,  82.1880,   6.6461, 485.9798,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880, 485.9798,\n",
      "         82.1880,  82.1880,   5.2026, 485.9798, 485.9798, 485.9798, 485.9798,\n",
      "        485.9798,  82.1880,  82.1880, 485.9798,  82.1880,  82.1880,   5.2026,\n",
      "          5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,   5.2026,\n",
      "          5.2025,   5.2026,   5.2026,   5.2026,   5.2025,   5.2026,   5.2026,\n",
      "          5.2026,   5.2025, 485.9798,   5.2026,   5.2025, 485.9798,   5.2026,\n",
      "          5.2025, 485.9798,   5.2026,   5.2025,   5.2025,   5.2025,   5.2025,\n",
      "        485.9798, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880, 485.9798, 485.9798, 485.9798,  82.1880,  82.1880,  82.1880,\n",
      "         82.1880,   5.2026,  82.1880,  82.1880,   5.2026,   5.2026],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
