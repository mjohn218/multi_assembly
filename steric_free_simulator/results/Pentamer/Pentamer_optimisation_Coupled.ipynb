{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x149473172320>\n"
     ]
    }
   ],
   "source": [
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['rxn_coupling', True]\n",
      "True\n",
      "['monomer_add_only', -1]\n",
      "['P']\n",
      "100.0\n",
      "['Q']\n",
      "100.0\n",
      "['R']\n",
      "100.0\n",
      "['S']\n",
      "100.0\n",
      "['T']\n",
      "100.0\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['P(a)+Q(b)', 'P(a!1).Q(a!1)']\n",
      "['P', 'Q', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['P(b)+R(a)', 'P(b!1).R(a!1)']\n",
      "['P', 'R', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['P(c)+S(a)', 'P(c!1).S(a!1)']\n",
      "['P', 'S', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['P(b)+T(b)', 'P(b!1).T(b!1)']\n",
      "['P', 'T', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['Q(c)+R(b)', 'Q(c!1).R(b!1)']\n",
      "['Q', 'R', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['Q(c)+S(b)', 'Q(c!1).S(b!1)']\n",
      "['Q', 'S', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['Q(c)+T(b)', 'Q(c!1).T(b!1)']\n",
      "['Q', 'T', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['R(c)+S(b)', 'R(c!1).S(b!1)']\n",
      "['R', 'S', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['R(c)+T(b)', 'R(c!1).T(b!1)']\n",
      "['R', 'T', '']\n",
      "GGGGGGGGGgg\n",
      "Parsing rule...\n",
      "SPLIT_01:  ['S(c)+T(b)', 'S(c!1).T(b!1)']\n",
      "['S', 'T', '']\n",
      "GGGGGGGGGgg\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'Q'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('P', 'Q')]\n",
      "New node added--1\n",
      "['P', 'Q']\n",
      "Adding an new edge-- 0 5\n",
      "Adding an new edge-- 1 5\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'R'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('P', 'R')]\n",
      "New node added--1\n",
      "['P', 'R']\n",
      "Adding an new edge-- 0 6\n",
      "Adding an new edge-- 2 6\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'S'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('P', 'S')]\n",
      "New node added--1\n",
      "['P', 'S']\n",
      "Adding an new edge-- 0 7\n",
      "Adding an new edge-- 3 7\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Node-1 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P'}\n",
      "{'T'}\n",
      "{'P'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('P', 'T')]\n",
      "New node added--1\n",
      "['P', 'T']\n",
      "Adding an new edge-- 0 8\n",
      "Adding an new edge-- 4 8\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('Q', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'R'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'R')]\n",
      "New node added--1\n",
      "['Q', 'R']\n",
      "Adding an new edge-- 1 9\n",
      "Adding an new edge-- 2 9\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'S'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'S')]\n",
      "New node added--1\n",
      "['Q', 'S']\n",
      "Adding an new edge-- 1 10\n",
      "Adding an new edge-- 3 10\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q'}\n",
      "{'T'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'T')]\n",
      "New node added--1\n",
      "['Q', 'T']\n",
      "Adding an new edge-- 1 11\n",
      "Adding an new edge-- 4 11\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "New node added--1\n",
      "['Q', 'P', 'R']\n",
      "Adding an new edge-- 1 12\n",
      "Adding an new edge-- 6 12\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "New node added--1\n",
      "['Q', 'P', 'S']\n",
      "Adding an new edge-- 1 13\n",
      "Adding an new edge-- 7 13\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Node-1 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['Q', 'P', 'T']\n",
      "Adding an new edge-- 1 14\n",
      "Adding an new edge-- 8 14\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'P'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('R', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('R', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'S')]\n",
      "New node added--1\n",
      "['R', 'S']\n",
      "Adding an new edge-- 2 15\n",
      "Adding an new edge-- 3 15\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'R'}\n",
      "{'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'T')]\n",
      "New node added--1\n",
      "['R', 'T']\n",
      "Adding an new edge-- 2 16\n",
      "Adding an new edge-- 4 16\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('P', 'Q')]\n",
      "Adding an new edge-- 2 12\n",
      "Adding an new edge-- 5 12\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "New node added--1\n",
      "['R', 'P', 'S']\n",
      "Adding an new edge-- 2 17\n",
      "Adding an new edge-- 7 17\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['R', 'P', 'T']\n",
      "Adding an new edge-- 2 18\n",
      "Adding an new edge-- 8 18\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "New node added--1\n",
      "['R', 'Q', 'S']\n",
      "Adding an new edge-- 2 19\n",
      "Adding an new edge-- 10 19\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "New node added--1\n",
      "['R', 'Q', 'T']\n",
      "Adding an new edge-- 2 20\n",
      "Adding an new edge-- 11 20\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "New node added--1\n",
      "['R', 'Q', 'P', 'S']\n",
      "Adding an new edge-- 2 21\n",
      "Adding an new edge-- 13 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 21\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Node-1 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['R', 'Q', 'P', 'T']\n",
      "Adding an new edge-- 2 22\n",
      "Adding an new edge-- 14 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 22\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'P'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('S', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('S', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S'}\n",
      "{'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'T')]\n",
      "New node added--1\n",
      "['S', 'T']\n",
      "Adding an new edge-- 3 23\n",
      "Adding an new edge-- 4 23\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('P', 'Q')]\n",
      "Adding an new edge-- 3 13\n",
      "Adding an new edge-- 5 13\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 3 17\n",
      "Adding an new edge-- 6 17\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'P', 'T']\n",
      "Adding an new edge-- 3 24\n",
      "Adding an new edge-- 8 24\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 3 19\n",
      "Adding an new edge-- 9 19\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "New node added--1\n",
      "['S', 'Q', 'T']\n",
      "Adding an new edge-- 3 25\n",
      "Adding an new edge-- 11 25\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'R'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 3 21\n",
      "Adding an new edge-- 12 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 21\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'Q', 'P', 'T']\n",
      "Adding an new edge-- 3 26\n",
      "Adding an new edge-- 14 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 26\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S'}\n",
      "{'T', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'T']\n",
      "Adding an new edge-- 3 27\n",
      "Adding an new edge-- 16 27\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'P', 'T']\n",
      "Adding an new edge-- 3 28\n",
      "Adding an new edge-- 18 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 28\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'Q', 'T']\n",
      "Adding an new edge-- 3 29\n",
      "Adding an new edge-- 20 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 29\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "New node added--1\n",
      "['S', 'R', 'Q', 'P', 'T']\n",
      "Adding an new edge-- 3 30\n",
      "Adding an new edge-- 22 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 30\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'P'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'P')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  []\n",
      "Item edges:  []\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})]\n",
      "Connected item Edges:  [('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T'}\n",
      "{'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "Adding an new edge-- 4 14\n",
      "Adding an new edge-- 5 14\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 4 18\n",
      "Adding an new edge-- 6 18\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 24\n",
      "Adding an new edge-- 7 24\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 4 20\n",
      "Adding an new edge-- 9 20\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 4 25\n",
      "Adding an new edge-- 10 25\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('T', 'R'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Adding an new edge-- 4 22\n",
      "Adding an new edge-- 12 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 22\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('T', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 26\n",
      "Adding an new edge-- 13 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 26\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T', 'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'S', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 4 27\n",
      "Adding an new edge-- 15 27\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'R'), ('T', 'S'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 28\n",
      "Adding an new edge-- 17 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 28\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('T', 'Q'), ('T', 'R'), ('T', 'S'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 4 29\n",
      "Adding an new edge-- 19 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 29\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "False\n",
      "Orig edges:  []\n",
      "Nextn edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('T', 'P'), ('T', 'Q'), ('T', 'R'), ('T', 'S'), ('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 4 30\n",
      "Adding an new edge-- 21 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  T\n",
      "Edge added between:  4 30\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T'}\n",
      "{'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T'}\n",
      "{'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'T'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('Q', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'S'), ('Q', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'T'), ('Q', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T', 'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('P', 'Q'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('P', 'S'), ('Q', 'R'), ('Q', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 5 21\n",
      "Adding an new edge-- 15 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'T', 'R'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('P', 'Q'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('P', 'T'), ('Q', 'R'), ('Q', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 5 22\n",
      "Adding an new edge-- 16 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'T', 'S'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('P', 'Q'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'S'), ('P', 'T'), ('Q', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 5 26\n",
      "Adding an new edge-- 23 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "False\n",
      "Orig edges:  [('P', 'Q')]\n",
      "Nextn edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Item edges:  [('P', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'Q'), ('P', 'R'), ('P', 'S'), ('P', 'T'), ('Q', 'R'), ('Q', 'S'), ('Q', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 5 30\n",
      "Adding an new edge-- 27 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'Q'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'Q')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('R', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'S'), ('R', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'T'), ('R', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('P', 'R'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('P', 'S'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 6 21\n",
      "Adding an new edge-- 10 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('P', 'R'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('P', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 6 22\n",
      "Adding an new edge-- 11 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'T', 'S'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('P', 'R'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'S'), ('P', 'T'), ('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 6 28\n",
      "Adding an new edge-- 23 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('P', 'R')]\n",
      "Nextn edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Item edges:  [('P', 'R'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'R'), ('P', 'Q'), ('P', 'S'), ('P', 'T'), ('R', 'Q'), ('R', 'S'), ('R', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 6 30\n",
      "Adding an new edge-- 25 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('S', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'R'), ('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('P', 'S'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('P', 'R'), ('S', 'Q'), ('S', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 7 21\n",
      "Adding an new edge-- 9 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('P', 'S'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('P', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 7 26\n",
      "Adding an new edge-- 11 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'T', 'R'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('P', 'S'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'R'), ('P', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 7 28\n",
      "Adding an new edge-- 16 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('P', 'S')]\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Item edges:  [('P', 'S'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'S'), ('P', 'Q'), ('P', 'R'), ('P', 'T'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Adding an new edge-- 7 30\n",
      "Adding an new edge-- 20 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('P', 'T'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('P', 'R'), ('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "Adding an new edge-- 8 22\n",
      "Adding an new edge-- 9 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('P', 'T'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('P', 'S'), ('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 8 26\n",
      "Adding an new edge-- 10 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T', 'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'S', 'R'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('P', 'T'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'R'), ('P', 'S'), ('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 8 28\n",
      "Adding an new edge-- 15 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "False\n",
      "Orig edges:  [('P', 'T')]\n",
      "Nextn edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Item edges:  [('P', 'T'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('P', 'T'), ('P', 'Q'), ('P', 'R'), ('P', 'S'), ('T', 'Q'), ('T', 'R'), ('T', 'S'), ('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Adding an new edge-- 8 30\n",
      "Adding an new edge-- 19 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'T'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "[(12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('R', 'P')]\n",
      "Adding an new edge-- 9 12\n",
      "Adding an new edge-- 0 12\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'S'), ('R', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'T'), ('R', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('Q', 'R'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('Q', 'S'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('Q', 'R'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('Q', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('Q', 'R'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'S'), ('Q', 'T'), ('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 9 29\n",
      "Adding an new edge-- 23 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'R')]\n",
      "Nextn edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'R'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'R'), ('Q', 'P'), ('Q', 'S'), ('Q', 'T'), ('R', 'P'), ('R', 'S'), ('R', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Adding an new edge-- 9 30\n",
      "Adding an new edge-- 24 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('S', 'P')]\n",
      "Adding an new edge-- 10 13\n",
      "Adding an new edge-- 0 13\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'R'), ('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('Q', 'S'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('Q', 'R'), ('S', 'P'), ('S', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('Q', 'S'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('Q', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('Q', 'S'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'R'), ('Q', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 10 29\n",
      "Adding an new edge-- 16 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'S')]\n",
      "Nextn edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Item edges:  [('Q', 'S'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'S'), ('Q', 'P'), ('Q', 'R'), ('Q', 'T'), ('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Adding an new edge-- 10 30\n",
      "Adding an new edge-- 18 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 11 14\n",
      "Adding an new edge-- 0 14\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'R'), ('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('Q', 'T'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('Q', 'R'), ('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('Q', 'T'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('Q', 'S'), ('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T', 'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('Q', 'T'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'R'), ('Q', 'S'), ('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 11 29\n",
      "Adding an new edge-- 15 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "False\n",
      "Orig edges:  [('Q', 'T')]\n",
      "Nextn edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Item edges:  [('Q', 'T'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'T'), ('Q', 'P'), ('Q', 'R'), ('Q', 'S'), ('T', 'P'), ('T', 'R'), ('T', 'S'), ('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Adding an new edge-- 11 30\n",
      "Adding an new edge-- 17 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('Q', 'S'), ('P', 'R'), ('P', 'S'), ('R', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('Q', 'T'), ('P', 'R'), ('P', 'T'), ('R', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Nextn edges:  [('S', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R'), ('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'R'), ('Q', 'S'), ('Q', 'T'), ('P', 'R'), ('P', 'S'), ('P', 'T'), ('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "Adding an new edge-- 12 30\n",
      "Adding an new edge-- 23 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'P', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('Q', 'R'), ('P', 'S'), ('P', 'R'), ('S', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'S'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "{'Q', 'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('Q', 'T'), ('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  [('R', 'T')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'S'), ('Q', 'R'), ('Q', 'T'), ('P', 'S'), ('P', 'R'), ('P', 'T'), ('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Adding an new edge-- 13 30\n",
      "Adding an new edge-- 16 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'P', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('Q', 'R'), ('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('Q', 'S'), ('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'T'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'Q'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'T'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T', 'P'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "False\n",
      "Orig edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  [('R', 'S')]\n",
      "Item edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T'), ('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('Q', 'P'), ('Q', 'T'), ('Q', 'R'), ('Q', 'S'), ('P', 'T'), ('P', 'R'), ('P', 'S'), ('T', 'R'), ('T', 'S'), ('R', 'S')]\n",
      "Adding an new edge-- 14 30\n",
      "Adding an new edge-- 15 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T', 'P'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('S', 'P')]\n",
      "Adding an new edge-- 15 17\n",
      "Adding an new edge-- 0 17\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'Q'), ('S', 'Q')]\n",
      "Adding an new edge-- 15 19\n",
      "Adding an new edge-- 1 19\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'T'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('R', 'S'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('R', 'Q'), ('S', 'P'), ('S', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('R', 'S'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('R', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('R', 'S'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'Q'), ('R', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'S')]\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Item edges:  [('R', 'S'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'S'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 16 18\n",
      "Adding an new edge-- 0 18\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 16 20\n",
      "Adding an new edge-- 1 20\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'S'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('R', 'T'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('R', 'Q'), ('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'S'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('R', 'T'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('R', 'S'), ('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('R', 'T'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'Q'), ('R', 'S'), ('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'T')]\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Item edges:  [('R', 'T'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'S'), ('T', 'P'), ('T', 'Q'), ('T', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'T', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('R', 'Q'), ('P', 'S'), ('P', 'Q'), ('S', 'Q')]\n",
      "Adding an new edge-- 17 21\n",
      "Adding an new edge-- 1 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 21\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "{'P', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('R', 'T'), ('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "Nextn edges:  [('Q', 'T')]\n",
      "Item edges:  [('R', 'P'), ('R', 'S'), ('P', 'S'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'S'), ('R', 'Q'), ('R', 'T'), ('P', 'S'), ('P', 'Q'), ('P', 'T'), ('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('R', 'Q'), ('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 18 22\n",
      "Adding an new edge-- 1 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 22\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "{'P', 'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('R', 'S'), ('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  [('Q', 'S')]\n",
      "Item edges:  [('R', 'P'), ('R', 'T'), ('P', 'T'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'T'), ('R', 'Q'), ('R', 'S'), ('P', 'T'), ('P', 'Q'), ('P', 'S'), ('T', 'Q'), ('T', 'S'), ('Q', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'T', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "[(21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('R', 'P'), ('Q', 'S'), ('Q', 'P'), ('S', 'P')]\n",
      "Adding an new edge-- 19 21\n",
      "Adding an new edge-- 0 21\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 21\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('R', 'T'), ('Q', 'S'), ('Q', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "Nextn edges:  [('P', 'T')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'S'), ('Q', 'S'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'S'), ('R', 'P'), ('R', 'T'), ('Q', 'S'), ('Q', 'P'), ('Q', 'T'), ('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'S'), ('Q', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "[(22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('R', 'P'), ('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 20 22\n",
      "Adding an new edge-- 0 22\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 22\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('R', 'S'), ('Q', 'T'), ('Q', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  [('P', 'S')]\n",
      "Item edges:  [('R', 'Q'), ('R', 'T'), ('Q', 'T'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'Q'), ('R', 'T'), ('R', 'P'), ('R', 'S'), ('Q', 'T'), ('Q', 'P'), ('Q', 'S'), ('T', 'P'), ('T', 'S'), ('P', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'S'), ('R', 'T'), ('Q', 'P'), ('Q', 'S'), ('Q', 'T'), ('P', 'S'), ('P', 'T'), ('S', 'T')]\n",
      "$$$$$$$\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'S'), ('Q', 'P'), ('Q', 'S'), ('P', 'S')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, False]\n",
      "False\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "False\n",
      "Orig edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('R', 'P'), ('R', 'Q'), ('R', 'T'), ('R', 'S'), ('Q', 'P'), ('Q', 'T'), ('Q', 'S'), ('P', 'T'), ('P', 'S'), ('T', 'S')]\n",
      "$$$$$$$\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 23 24\n",
      "Adding an new edge-- 0 24\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 23 25\n",
      "Adding an new edge-- 1 25\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'R'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 23 27\n",
      "Adding an new edge-- 2 27\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('S', 'T'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('S', 'Q'), ('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'R'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('S', 'T'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('S', 'R'), ('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('S', 'T'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'Q'), ('S', 'R'), ('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'T')]\n",
      "Nextn edges:  [('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Item edges:  [('S', 'T'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'T'), ('S', 'P'), ('S', 'Q'), ('S', 'R'), ('T', 'P'), ('T', 'Q'), ('T', 'R'), ('Q', 'P'), ('Q', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'T', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'T')]\n",
      "False\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('S', 'Q'), ('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 24 26\n",
      "Adding an new edge-- 1 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 26\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "{'P', 'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('S', 'R'), ('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 24 28\n",
      "Adding an new edge-- 2 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 28\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "Nextn edges:  [('Q', 'R')]\n",
      "Item edges:  [('S', 'P'), ('S', 'T'), ('P', 'T'), ('Q', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'T'), ('S', 'Q'), ('S', 'R'), ('P', 'T'), ('P', 'Q'), ('P', 'R'), ('T', 'Q'), ('T', 'R'), ('Q', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'T', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'T'), ('P', 'T')]\n",
      "False\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "{'Q', 'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('S', 'P'), ('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 25 26\n",
      "Adding an new edge-- 0 26\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 26\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('S', 'R'), ('Q', 'T'), ('Q', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 25 29\n",
      "Adding an new edge-- 2 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 29\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  [('P', 'R')]\n",
      "Item edges:  [('S', 'Q'), ('S', 'T'), ('Q', 'T'), ('P', 'R')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'T'), ('S', 'P'), ('S', 'R'), ('Q', 'T'), ('Q', 'P'), ('Q', 'R'), ('T', 'P'), ('T', 'R'), ('P', 'R')]\n",
      "$$$$$$$\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P'}\n",
      "{'Q', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q'}\n",
      "{'P', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'Q'), ('S', 'T'), ('S', 'R'), ('Q', 'P'), ('Q', 'T'), ('Q', 'R'), ('P', 'T'), ('P', 'R'), ('T', 'R')]\n",
      "Adding an new edge-- 26 30\n",
      "Adding an new edge-- 2 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  R\n",
      "Edge added between:  2 30\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'T'}\n",
      "{'Q', 'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "{'T', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('S', 'P'), ('R', 'T'), ('R', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 27 28\n",
      "Adding an new edge-- 0 28\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 28\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('S', 'Q'), ('R', 'T'), ('R', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 27 29\n",
      "Adding an new edge-- 1 29\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 29\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "Nextn edges:  [('P', 'Q')]\n",
      "Item edges:  [('S', 'R'), ('S', 'T'), ('R', 'T'), ('P', 'Q')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'R'), ('S', 'T'), ('S', 'P'), ('S', 'Q'), ('R', 'T'), ('R', 'P'), ('R', 'Q'), ('T', 'P'), ('T', 'Q'), ('P', 'Q')]\n",
      "$$$$$$$\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'R'), ('S', 'T'), ('R', 'T')]\n",
      "False\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "{'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'P'), ('S', 'R'), ('S', 'T'), ('S', 'Q'), ('R', 'P'), ('R', 'T'), ('R', 'Q'), ('P', 'T'), ('P', 'Q'), ('T', 'Q')]\n",
      "Adding an new edge-- 28 30\n",
      "Adding an new edge-- 1 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  Q\n",
      "Edge added between:  1 30\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'R'}\n",
      "{'P', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'S'}\n",
      "{'P', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'T'}\n",
      "{'P', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, False]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'T'), ('P', 'T')]\n",
      "False\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "False\n",
      "Orig edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Nextn edges:  []\n",
      "Item edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "False\n",
      "############################3\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "[(30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})]\n",
      "Connected item Edges:  [('S', 'Q'), ('S', 'R'), ('S', 'T'), ('S', 'P'), ('R', 'Q'), ('R', 'T'), ('R', 'P'), ('Q', 'T'), ('Q', 'P'), ('T', 'P')]\n",
      "Adding an new edge-- 29 30\n",
      "Adding an new edge-- 0 30\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "The common reactant is:  P\n",
      "Edge added between:  0 30\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Node-1 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[False, True]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'Q'), ('R', 'T'), ('Q', 'T')]\n",
      "False\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (0, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f240>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (1, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f0f0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (2, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f208>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'R'}\n",
      "{'P', 'Q', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (3, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f2e8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'S'}\n",
      "{'P', 'Q', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (4, {'struct': <networkx.classes.graph.Graph object at 0x149471a9f390>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'T'}\n",
      "{'P', 'Q', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (5, {'struct': <networkx.classes.graph.Graph object at 0x149471cd6a20>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (6, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cd518>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'R'}\n",
      "{'Q', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (7, {'struct': <networkx.classes.graph.Graph object at 0x1493de5cdf60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'S'}\n",
      "{'Q', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (8, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'T'}\n",
      "{'Q', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (9, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e080>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'R'}\n",
      "{'P', 'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (10, {'struct': <networkx.classes.graph.Graph object at 0x1493de56ef60>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'S'}\n",
      "{'P', 'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (11, {'struct': <networkx.classes.graph.Graph object at 0x1493de5812b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T'}\n",
      "{'P', 'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (12, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e2b0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'P', 'R'}\n",
      "{'T', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (13, {'struct': <networkx.classes.graph.Graph object at 0x1493de581860>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'P', 'S'}\n",
      "{'T', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (14, {'struct': <networkx.classes.graph.Graph object at 0x1493de581358>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T', 'P'}\n",
      "{'S', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (15, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f320>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'S', 'R'}\n",
      "{'P', 'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (16, {'struct': <networkx.classes.graph.Graph object at 0x1493de56eda0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'T', 'R'}\n",
      "{'P', 'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (17, {'struct': <networkx.classes.graph.Graph object at 0x1493de56e9e8>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'S', 'R'}\n",
      "{'Q', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (18, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fa58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'T', 'R'}\n",
      "{'Q', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (19, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'S', 'R'}\n",
      "{'P', 'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (20, {'struct': <networkx.classes.graph.Graph object at 0x1493de50fcc0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T', 'R'}\n",
      "{'P', 'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (21, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f908>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'P', 'S', 'R'}\n",
      "{'T'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (22, {'struct': <networkx.classes.graph.Graph object at 0x1493de581a58>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T', 'P', 'R'}\n",
      "{'S'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (23, {'struct': <networkx.classes.graph.Graph object at 0x1493de581780>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 2})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'T', 'S'}\n",
      "{'P', 'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (24, {'struct': <networkx.classes.graph.Graph object at 0x1493de50f390>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'T', 'S'}\n",
      "{'Q', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (25, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c160>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T', 'S'}\n",
      "{'P', 'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (26, {'struct': <networkx.classes.graph.Graph object at 0x1493de565828>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T', 'P', 'S'}\n",
      "{'R'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (27, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c438>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 6})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'T', 'S', 'R'}\n",
      "{'P', 'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (28, {'struct': <networkx.classes.graph.Graph object at 0x1493de565240>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'T', 'S', 'R'}\n",
      "{'Q'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (29, {'struct': <networkx.classes.graph.Graph object at 0x1493de565da0>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 21})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'Q', 'T', 'S', 'R'}\n",
      "{'P'}\n",
      "Steric hindrance detected\n",
      "Node-1 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "Node-2 :  (30, {'struct': <networkx.classes.graph.Graph object at 0x1493de51c710>, 'copies': tensor([0.], dtype=torch.float64), 'subunits': 88})\n",
      "-----\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "{'P', 'S', 'T', 'R', 'Q'}\n",
      "set()\n",
      "Steric hindrance detected\n",
      "Trying internal bonds\n",
      "Allowed edges: \n",
      "('P', 'Q')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('P', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'R')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('Q', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'S')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('R', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Allowed edges: \n",
      "('S', 'T')\n",
      "[True, True]\n",
      "True\n",
      "*********************************************\n",
      "Adding extra new bonds for the repeating unit - \n",
      "[('S', 'P'), ('S', 'Q'), ('S', 'R'), ('S', 'T'), ('R', 'P'), ('R', 'Q'), ('R', 'T'), ('Q', 'P'), ('Q', 'T'), ('P', 'T')]\n",
      "False\n",
      "Coupling Reaction ID:  {7: [0, 4], 8: [0, 5], 9: [0, 6], 12: [1, 4], 13: [1, 10], 14: [1, 11], 15: [4, 10], 16: [4, 11], 17: [1, 4, 10], 18: [1, 4, 11], 20: [2, 5], 21: [2, 10], 22: [2, 19], 23: [5, 10], 24: [5, 19], 25: [2, 5, 10], 26: [2, 5, 19], 27: [10, 19], 28: [2, 10, 19], 29: [5, 10, 19], 30: [2, 5, 10, 19], 31: [3, 6], 32: [3, 11], 33: [3, 19], 34: [6, 11], 35: [6, 19], 36: [3, 6, 11], 37: [3, 6, 19], 38: [11, 19], 39: [3, 11, 19], 40: [6, 11, 19], 41: [3, 6, 11, 19], 42: [1, 2, 4, 5], 43: [1, 3, 4, 6], 44: [2, 3, 5, 6], 45: [1, 2, 3, 4, 5, 6], 46: [0, 2, 4, 10], 47: [0, 3, 4, 11], 48: [2, 3, 10, 11], 49: [0, 2, 3, 4, 10, 11], 50: [0, 1, 5, 10], 51: [0, 3, 5, 19], 52: [1, 3, 10, 19], 53: [0, 1, 3, 5, 10, 19], 54: [0, 1, 6, 11], 55: [0, 2, 6, 19], 56: [1, 2, 11, 19], 57: [0, 1, 2, 6, 11, 19], 58: [0, 1], 59: [5, 6, 10, 11], 60: [0, 5, 6, 1, 10, 11], 61: [0, 2], 62: [4, 6, 10, 19], 63: [0, 4, 6, 2, 10, 19], 64: [0, 3], 65: [4, 5, 11, 19], 66: [0, 4, 5, 3, 11, 19], 67: [2, 3, 5, 6, 10, 11], 68: [1, 3, 4, 6, 10, 19], 69: [1, 2, 4, 5, 11, 19], 70: [1, 2], 71: [4, 5], 72: [1, 3], 73: [4, 6], 74: [0, 4, 5], 75: [0, 4, 6], 76: [0, 1, 2], 77: [0, 1, 3], 78: [2, 3], 79: [5, 6], 80: [10, 11], 81: [0, 5, 6], 82: [1, 10, 11], 83: [0, 2, 3], 84: [4, 10, 11], 85: [1, 4, 10, 11], 86: [1, 2, 3], 87: [4, 5, 6], 88: [0, 4, 5, 6], 89: [0, 1, 2, 3]}\n",
      "P\n",
      "Reactant Sets:\n",
      "Q\n",
      "Reactant Sets:\n",
      "R\n",
      "Reactant Sets:\n",
      "S\n",
      "Reactant Sets:\n",
      "T\n",
      "Reactant Sets:\n",
      "PQ\n",
      "Reactant Sets:\n",
      "(0, 1)\n",
      "PR\n",
      "Reactant Sets:\n",
      "(0, 2)\n",
      "PS\n",
      "Reactant Sets:\n",
      "(0, 3)\n",
      "PT\n",
      "Reactant Sets:\n",
      "(0, 4)\n",
      "QR\n",
      "Reactant Sets:\n",
      "(1, 2)\n",
      "QS\n",
      "Reactant Sets:\n",
      "(1, 3)\n",
      "QT\n",
      "Reactant Sets:\n",
      "(1, 4)\n",
      "PQR\n",
      "Reactant Sets:\n",
      "(1, 6)\n",
      "(2, 5)\n",
      "(0, 9)\n",
      "PQS\n",
      "Reactant Sets:\n",
      "(3, 5)\n",
      "(1, 7)\n",
      "(0, 10)\n",
      "PQT\n",
      "Reactant Sets:\n",
      "(8, 1)\n",
      "(0, 11)\n",
      "(4, 5)\n",
      "RS\n",
      "Reactant Sets:\n",
      "(2, 3)\n",
      "RT\n",
      "Reactant Sets:\n",
      "(2, 4)\n",
      "PRS\n",
      "Reactant Sets:\n",
      "(0, 15)\n",
      "(2, 7)\n",
      "(3, 6)\n",
      "PRT\n",
      "Reactant Sets:\n",
      "(4, 6)\n",
      "(8, 2)\n",
      "(0, 16)\n",
      "QRS\n",
      "Reactant Sets:\n",
      "(2, 10)\n",
      "(1, 15)\n",
      "(9, 3)\n",
      "QRT\n",
      "Reactant Sets:\n",
      "(9, 4)\n",
      "(2, 11)\n",
      "(16, 1)\n",
      "PQRS\n",
      "Reactant Sets:\n",
      "(3, 12)\n",
      "(1, 17)\n",
      "(9, 7)\n",
      "(0, 19)\n",
      "(2, 13)\n",
      "(5, 15)\n",
      "(10, 6)\n",
      "PQRT\n",
      "Reactant Sets:\n",
      "(0, 20)\n",
      "(1, 18)\n",
      "(8, 9)\n",
      "(11, 6)\n",
      "(16, 5)\n",
      "(2, 14)\n",
      "(4, 12)\n",
      "ST\n",
      "Reactant Sets:\n",
      "(3, 4)\n",
      "PST\n",
      "Reactant Sets:\n",
      "(8, 3)\n",
      "(0, 23)\n",
      "(4, 7)\n",
      "QST\n",
      "Reactant Sets:\n",
      "(11, 3)\n",
      "(1, 23)\n",
      "(10, 4)\n",
      "PQST\n",
      "Reactant Sets:\n",
      "(0, 25)\n",
      "(11, 7)\n",
      "(24, 1)\n",
      "(4, 13)\n",
      "(3, 14)\n",
      "(5, 23)\n",
      "(8, 10)\n",
      "RST\n",
      "Reactant Sets:\n",
      "(4, 15)\n",
      "(16, 3)\n",
      "(2, 23)\n",
      "PRST\n",
      "Reactant Sets:\n",
      "(17, 4)\n",
      "(24, 2)\n",
      "(6, 23)\n",
      "(16, 7)\n",
      "(8, 15)\n",
      "(18, 3)\n",
      "(0, 27)\n",
      "QRST\n",
      "Reactant Sets:\n",
      "(19, 4)\n",
      "(25, 2)\n",
      "(9, 23)\n",
      "(16, 10)\n",
      "(11, 15)\n",
      "(3, 20)\n",
      "(1, 27)\n",
      "PQRST\n",
      "Reactant Sets:\n",
      "(24, 9)\n",
      "(14, 15)\n",
      "(16, 13)\n",
      "(18, 10)\n",
      "(27, 5)\n",
      "(12, 23)\n",
      "(25, 6)\n",
      "(1, 28)\n",
      "(2, 26)\n",
      "(20, 7)\n",
      "(17, 11)\n",
      "(0, 29)\n",
      "(3, 22)\n",
      "(4, 21)\n",
      "(8, 19)\n",
      "Before:  tensor([[-1., -1., -1.,  ..., -0., -0.,  1.],\n",
      "        [-1.,  0.,  0.,  ...,  1.,  1., -0.],\n",
      "        [ 0., -1.,  0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., -0.,  1., -0.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -0., -1., -1.]], dtype=torch.float64)\n",
      "tensor([[-1., -1., -1.,  ..., -0., -0.,  1.],\n",
      "        [-1.,  0.,  0.,  ...,  1.,  1., -0.],\n",
      "        [ 0., -1.,  0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., -0.,  1., -0.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -0., -1., -1.]], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "base_input = '../../input_files/pentamer_coup.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 5): 0, (0, 6): 1, (0, 7): 2, (0, 8): 3, (0, 12): 58, (0, 13): 61, (0, 14): 64, (0, 17): 70, (0, 18): 72, (0, 21): 76, (0, 22): 77, (0, 24): 78, (0, 26): 83, (0, 28): 86, (0, 30): 89, (1, 5): 0, (1, 9): 4, (1, 10): 5, (1, 11): 6, (1, 12): 7, (1, 13): 8, (1, 14): 9, (1, 19): 71, (1, 20): 73, (1, 21): 74, (1, 22): 75, (1, 25): 79, (1, 26): 81, (1, 29): 87, (1, 30): 88, (2, 6): 1, (2, 9): 4, (2, 15): 10, (2, 16): 11, (2, 12): 12, (2, 17): 13, (2, 18): 14, (2, 19): 15, (2, 20): 16, (2, 21): 17, (2, 22): 18, (2, 27): 80, (2, 28): 82, (2, 29): 84, (2, 30): 85, (3, 7): 2, (3, 10): 5, (3, 15): 10, (3, 23): 19, (3, 13): 20, (3, 17): 21, (3, 24): 22, (3, 19): 23, (3, 25): 24, (3, 21): 25, (3, 26): 26, (3, 27): 27, (3, 28): 28, (3, 29): 29, (3, 30): 30, (4, 8): 3, (4, 11): 6, (4, 16): 11, (4, 23): 19, (4, 14): 31, (4, 18): 32, (4, 24): 33, (4, 20): 34, (4, 25): 35, (4, 22): 36, (4, 26): 37, (4, 27): 38, (4, 28): 39, (4, 29): 40, (4, 30): 41, (5, 12): 12, (5, 13): 20, (5, 14): 31, (5, 21): 42, (5, 22): 43, (5, 26): 44, (5, 30): 45, (6, 12): 7, (6, 17): 21, (6, 18): 32, (6, 21): 46, (6, 22): 47, (6, 28): 48, (6, 30): 49, (7, 13): 8, (7, 17): 13, (7, 24): 33, (7, 21): 50, (7, 26): 51, (7, 28): 52, (7, 30): 53, (8, 14): 9, (8, 18): 14, (8, 24): 22, (8, 22): 54, (8, 26): 55, (8, 28): 56, (8, 30): 57, (9, 19): 23, (9, 20): 34, (9, 21): 50, (9, 22): 54, (9, 12): 58, (9, 29): 59, (9, 30): 60, (10, 19): 15, (10, 25): 35, (10, 21): 46, (10, 26): 55, (10, 13): 61, (10, 29): 62, (10, 30): 63, (11, 20): 16, (11, 25): 24, (11, 22): 47, (11, 26): 51, (11, 14): 64, (11, 29): 65, (11, 30): 66, (12, 21): 25, (12, 22): 36, (12, 30): 67, (13, 21): 17, (13, 26): 37, (13, 30): 68, (14, 22): 18, (14, 26): 26, (14, 30): 69, (15, 27): 38, (15, 21): 42, (15, 28): 56, (15, 29): 65, (15, 30): 69, (15, 17): 70, (15, 19): 71, (16, 27): 27, (16, 22): 43, (16, 28): 52, (16, 29): 62, (16, 30): 68, (16, 18): 72, (16, 20): 73, (17, 28): 39, (17, 30): 66, (17, 21): 74, (18, 28): 28, (18, 30): 63, (18, 22): 75, (19, 29): 40, (19, 30): 57, (19, 21): 76, (20, 29): 29, (20, 30): 53, (20, 22): 77, (21, 30): 41, (22, 30): 30, (23, 26): 44, (23, 28): 48, (23, 29): 59, (23, 30): 67, (23, 24): 78, (23, 25): 79, (23, 27): 80, (24, 30): 60, (24, 26): 81, (24, 28): 82, (25, 30): 49, (25, 26): 83, (25, 29): 84, (26, 30): 85, (27, 30): 45, (27, 28): 86, (27, 29): 87, (28, 30): 88, (29, 30): 89}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 1): [0, 1, 2, 3, 4, 5, 6, 10, 11, 19], (2, 1): [7, 8, 9, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 27, 31, 32, 33, 34, 35, 38, 58, 61, 64, 70, 71, 72, 73, 78, 79, 80], (3, 1): [17, 18, 25, 26, 28, 29, 36, 37, 39, 40, 74, 75, 76, 77, 81, 82, 83, 84, 86, 87], (4, 1): [30, 41, 85, 88, 89], (2, 2): [42, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 56, 59, 62, 65], (3, 2): [45, 49, 53, 57, 60, 63, 66, 67, 68, 69]}\n"
     ]
    }
   ],
   "source": [
    "print(vec_rn.rxn_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 58}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 61}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 70}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 72}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 76}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 77}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 78}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 83}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 86}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 89}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 71}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 73}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 74}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 75}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 79}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 81}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 87}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 88}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 80}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 82}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 84}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 85}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 40}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 41}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 42}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 43}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 44}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 45}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 46}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 47}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 48}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 49}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 50}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 51}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 52}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 53}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 54}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 55}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 56}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 57}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 50}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 54}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 58}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 59}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 60}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 46}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 55}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 61}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 62}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 63}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 47}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 51}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 65}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 66}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 67}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 68}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 69}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 42}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 56}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 65}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 69}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 70}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 71}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 43}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 52}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 62}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 68}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 72}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 73}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 66}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 74}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 63}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 75}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 40}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 57}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 76}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 53}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 77}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 41}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 44}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 48}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 59}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 67}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 78}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 79}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 80}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 60}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 81}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 82}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 49}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 83}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 84}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 85}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 45}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 86}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 87}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 88}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 89}\n",
      "P\n",
      "Reactant Sets:\n",
      "Q\n",
      "Reactant Sets:\n",
      "R\n",
      "Reactant Sets:\n",
      "S\n",
      "Reactant Sets:\n",
      "T\n",
      "Reactant Sets:\n",
      "PQ\n",
      "Reactant Sets:\n",
      "(0, 1)\n",
      "PR\n",
      "Reactant Sets:\n",
      "(0, 2)\n",
      "PS\n",
      "Reactant Sets:\n",
      "(0, 3)\n",
      "PT\n",
      "Reactant Sets:\n",
      "(0, 4)\n",
      "QR\n",
      "Reactant Sets:\n",
      "(1, 2)\n",
      "QS\n",
      "Reactant Sets:\n",
      "(1, 3)\n",
      "QT\n",
      "Reactant Sets:\n",
      "(1, 4)\n",
      "PQR\n",
      "Reactant Sets:\n",
      "(1, 6)\n",
      "(2, 5)\n",
      "(0, 9)\n",
      "PQS\n",
      "Reactant Sets:\n",
      "(3, 5)\n",
      "(1, 7)\n",
      "(0, 10)\n",
      "PQT\n",
      "Reactant Sets:\n",
      "(8, 1)\n",
      "(0, 11)\n",
      "(4, 5)\n",
      "RS\n",
      "Reactant Sets:\n",
      "(2, 3)\n",
      "RT\n",
      "Reactant Sets:\n",
      "(2, 4)\n",
      "PRS\n",
      "Reactant Sets:\n",
      "(0, 15)\n",
      "(2, 7)\n",
      "(3, 6)\n",
      "PRT\n",
      "Reactant Sets:\n",
      "(4, 6)\n",
      "(8, 2)\n",
      "(0, 16)\n",
      "QRS\n",
      "Reactant Sets:\n",
      "(2, 10)\n",
      "(1, 15)\n",
      "(9, 3)\n",
      "QRT\n",
      "Reactant Sets:\n",
      "(9, 4)\n",
      "(2, 11)\n",
      "(16, 1)\n",
      "PQRS\n",
      "Reactant Sets:\n",
      "(3, 12)\n",
      "(1, 17)\n",
      "(9, 7)\n",
      "(0, 19)\n",
      "(2, 13)\n",
      "(5, 15)\n",
      "(10, 6)\n",
      "PQRT\n",
      "Reactant Sets:\n",
      "(0, 20)\n",
      "(1, 18)\n",
      "(8, 9)\n",
      "(11, 6)\n",
      "(16, 5)\n",
      "(2, 14)\n",
      "(4, 12)\n",
      "ST\n",
      "Reactant Sets:\n",
      "(3, 4)\n",
      "PST\n",
      "Reactant Sets:\n",
      "(8, 3)\n",
      "(0, 23)\n",
      "(4, 7)\n",
      "QST\n",
      "Reactant Sets:\n",
      "(11, 3)\n",
      "(1, 23)\n",
      "(10, 4)\n",
      "PQST\n",
      "Reactant Sets:\n",
      "(0, 25)\n",
      "(11, 7)\n",
      "(24, 1)\n",
      "(4, 13)\n",
      "(3, 14)\n",
      "(5, 23)\n",
      "(8, 10)\n",
      "RST\n",
      "Reactant Sets:\n",
      "(4, 15)\n",
      "(16, 3)\n",
      "(2, 23)\n",
      "PRST\n",
      "Reactant Sets:\n",
      "(17, 4)\n",
      "(24, 2)\n",
      "(6, 23)\n",
      "(16, 7)\n",
      "(8, 15)\n",
      "(18, 3)\n",
      "(0, 27)\n",
      "QRST\n",
      "Reactant Sets:\n",
      "(19, 4)\n",
      "(25, 2)\n",
      "(9, 23)\n",
      "(16, 10)\n",
      "(11, 15)\n",
      "(3, 20)\n",
      "(1, 27)\n",
      "PQRST\n",
      "Reactant Sets:\n",
      "(24, 9)\n",
      "(14, 15)\n",
      "(16, 13)\n",
      "(18, 10)\n",
      "(27, 5)\n",
      "(12, 23)\n",
      "(25, 6)\n",
      "(1, 28)\n",
      "(2, 26)\n",
      "(20, 7)\n",
      "(17, 11)\n",
      "(0, 29)\n",
      "(3, 22)\n",
      "(4, 21)\n",
      "(8, 19)\n",
      "Before:  tensor([[-1., -1., -1.,  ..., -0., -0.,  1.],\n",
      "        [-1.,  0.,  0.,  ...,  1.,  1., -0.],\n",
      "        [ 0., -1.,  0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., -0.,  1., -0.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -0., -1., -1.]], dtype=torch.float64)\n",
      "tensor([[-1., -1., -1.,  ..., -0., -0.,  1.],\n",
      "        [-1.,  0.,  0.,  ...,  1.,  1., -0.],\n",
      "        [ 0., -1.,  0.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ..., -0.,  1., -0.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -0., -1., -1.]], dtype=torch.float64)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Do modifications here\n",
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "new_kon = new_kon + Tensor([1.]*np.array(1e-1))\n",
    "new_kon[0]=1\n",
    "new_kon[1]=1\n",
    "new_kon[2]=1\n",
    "new_kon[3]=1\n",
    "# new_kon[3]=2\n",
    "# new_kon[3]=2\n",
    "# new_kon[3]=1\n",
    "# new_kon = new_kon + Tensor([42.0247, 41.7901, 41.0026, 39.9100,  0.9985,  1.0029,  0.9985, 70.4319,\n",
    "#         70.4319, 70.4319,  0.9986,  0.9980, 70.4319, 70.4319, 70.4319, 70.4319,\n",
    "#         70.4319, 12.7740, 12.7740,  0.9983, 70.4319, 70.4319, 70.4319, 70.4319,\n",
    "#         70.4319, 12.7740, 12.7740, 70.4319, 12.7740, 12.7740,  1.0001, 70.4319,\n",
    "#         70.4319, 70.4319, 70.4319, 70.4319, 12.7740, 12.7740, 70.4319, 12.7740,\n",
    "#         12.7740,  1.0001,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
    "#          1.0001,  1.0000,  1.0001,  1.0001,  1.0001,  1.0000,  1.0001,  1.0001,\n",
    "#          1.0001,  1.0000, 70.4319,  1.0001,  1.0000, 70.4319,  1.0001,  1.0000,\n",
    "#         70.4319,  1.0001,  1.0000,  1.0000,  1.0000,  1.0000, 70.4319, 70.4319,\n",
    "#         70.4319, 70.4319, 12.7740, 12.7740, 12.7740, 12.7740, 70.4319, 70.4319,\n",
    "#         70.4319, 12.7740, 12.7740, 12.7740, 12.7740,  1.0001, 12.7740, 12.7740,\n",
    "#          1.0001,  1.0001])\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "optim_rates=[0,1,2,3]\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu',optim_rates=optim_rates)\n",
    "print(vec_rn.kon)\n",
    "\n",
    "#Changing initial concentrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Equilibrium Solution ##\n",
    "First we will find the equilibrium solution for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vec_rn.update_reaction_net(rn)\n",
    "# poly_system = EquilibriumSolver(rn)\n",
    "# solution = poly_system.solve()\n",
    "# print(solution)\n",
    "# if solution == None:\n",
    "#     print(\"No Equilibrium solution\")\n",
    "# else:\n",
    "#     print(solution)\n",
    "#     print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "# print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uid_dict = {}\n",
    "# sys.path.append(\"../\")\n",
    "# import numpy as np\n",
    "# from reaction_network import gtostr\n",
    "# from torch import DoubleTensor as Tensor\n",
    "\n",
    "# def get_max_edge(n):\n",
    "#     \"\"\"\n",
    "#     Calculates the max rate (k_on) for a given node\n",
    "#     To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "#     Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "#     Can tell which component is used quickly.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         edges = rn.network.out_edges(n)\n",
    "#         #Loop over all edges\n",
    "#         #Get attributes\n",
    "#         if len(edges)==0:\n",
    "#             return(False)\n",
    "#         kon_max = -1\n",
    "#         next_node = -1\n",
    "        \n",
    "#         kon_sum = 0\n",
    "#         for edge in edges:\n",
    "#             data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "#             #print(data)\n",
    "#             #Get uid\n",
    "#             uid = data['uid']\n",
    "#             #Get updated kon\n",
    "#             temp_kon = vec_rn.kon[uid]\n",
    "#             kon_sum+=temp_kon\n",
    "            \n",
    "# #             #Calculate k_off also\n",
    "# #             std_c = Tensor([1.])\n",
    "# #             l_kon = torch.log(temp_kon)\n",
    "# #             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "#             if temp_kon > kon_max:\n",
    "#                 kon_max = temp_kon\n",
    "#                 next_node=edge[1]\n",
    "#         return(kon_max,next_node,kon_sum)\n",
    "#     except Exception as err:\n",
    "#         raise(err)\n",
    "\n",
    "# pathway = []\n",
    "# kon_sumarray = []\n",
    "# total_con_rate = {}\n",
    "# for n in rn.network.nodes():\n",
    "    \n",
    "#     n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "#     paths = [n_str]\n",
    "#     kon_sum = 0\n",
    "#     temp_node = n\n",
    "#     max_edge = True\n",
    "#     consumption_rate = 0\n",
    "#     if n < len(rn.network.nodes()):#num_monomers:\n",
    "# #         print(\"Current node: \")\n",
    "# #         print(n_str)\n",
    "#         while max_edge:\n",
    "#             max_edge = get_max_edge(temp_node)\n",
    "#             if max_edge:\n",
    "#                 total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "#                 temp_node = max_edge[1]\n",
    "#                 kon_sum += max_edge[0].item()\n",
    "                \n",
    "# #                 print(\"Next node: \")\n",
    "# #                 print(temp_node)\n",
    "\n",
    "#                 paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "#             else:\n",
    "#                 break\n",
    "#         pathway.append(paths)\n",
    "#         kon_sumarray.append(kon_sum)\n",
    "#         paths=[]\n",
    "\n",
    "# print(pathway)\n",
    "# print(kon_sumarray)\n",
    "# #print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if solution != None:\n",
    "#     for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "#         print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if solution !=None:\n",
    "#     for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "#         print(k,\" : \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer with a 1 second simulation runtime ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.4\n",
      "SLow rates:  tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000, 0.1000, 1.0000, 1.0000,\n",
      "         1.0000, 0.1000, 0.1000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000, 1.0000,\n",
      "         1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000, 1.0000, 1.0000,\n",
      "         0.1000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000,\n",
      "         1.0000, 1.0000, 0.1000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000,\n",
      "         1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 0 was 65.0%\n",
      "current params: tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.4\n",
      "SLow rates:  tensor([[2.0000, 2.0000, 2.0000, 2.0000, 0.1000, 0.1000, 0.1000, 2.0000, 2.0000,\n",
      "         2.0000, 0.1000, 0.1000, 2.0000, 2.0000, 2.0000, 0.1000, 0.1000, 2.0000,\n",
      "         2.0000, 0.1000, 2.0000, 2.0000, 2.0000, 0.1000, 0.1000, 2.0000, 2.0000,\n",
      "         0.1000, 2.0000, 0.1000, 2.0000, 2.0000, 2.0000, 2.0000, 0.1000, 0.1000,\n",
      "         2.0000, 2.0000, 0.1000, 2.0000, 0.1000, 2.0000, 2.0000, 2.0000, 2.0000,\n",
      "         2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000,\n",
      "         2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 0.1000, 2.0000, 2.0000, 0.1000,\n",
      "         2.0000, 2.0000, 0.1000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 0.1000,\n",
      "         2.0000, 0.1000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 0.1000, 0.1000,\n",
      "         2.0000, 2.0000, 2.0000, 0.1000, 2.0000, 2.0000, 0.1000, 2.0000, 2.0000]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1 was 76.5%\n",
      "current params: tensor([2.0000, 2.0000, 2.0000, 2.0000], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.4\n",
      "SLow rates:  tensor([[2.6301, 2.6623, 2.6703, 2.7429, 0.1000, 0.1000, 0.1000, 2.6301, 2.6301,\n",
      "         2.6301, 0.1000, 0.1000, 2.6623, 2.6623, 2.6623, 0.1000, 0.1000, 2.6623,\n",
      "         2.6623, 0.1000, 2.6703, 2.6703, 2.6703, 0.1000, 0.1000, 2.6703, 2.6703,\n",
      "         0.1000, 2.6703, 0.1000, 2.6703, 2.7429, 2.7429, 2.7429, 0.1000, 0.1000,\n",
      "         2.7429, 2.7429, 0.1000, 2.7429, 0.1000, 2.7429, 2.6703, 2.7429, 2.7429,\n",
      "         2.7429, 2.6703, 2.7429, 2.7429, 2.7429, 2.6623, 2.7429, 2.7429, 2.7429,\n",
      "         2.6623, 2.6703, 2.6703, 2.6703, 2.6623, 0.1000, 2.6623, 2.6703, 0.1000,\n",
      "         2.6703, 2.7429, 0.1000, 2.7429, 2.7429, 2.7429, 2.6703, 2.6703, 0.1000,\n",
      "         2.7429, 0.1000, 2.6301, 2.6301, 2.6703, 2.7429, 2.7429, 0.1000, 0.1000,\n",
      "         2.6301, 2.6623, 2.7429, 0.1000, 2.6623, 2.7429, 0.1000, 2.6301, 2.7429]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2 was 80.8%\n",
      "current params: tensor([2.6301, 2.6623, 2.6703, 2.7429], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.4\n",
      "SLow rates:  tensor([[3.1577, 3.2143, 3.2207, 3.3059, 0.1000, 0.1000, 0.1000, 3.1577, 3.1577,\n",
      "         3.1577, 0.1000, 0.1000, 3.2143, 3.2143, 3.2143, 0.1000, 0.1000, 3.2143,\n",
      "         3.2143, 0.1000, 3.2207, 3.2207, 3.2207, 0.1000, 0.1000, 3.2207, 3.2207,\n",
      "         0.1000, 3.2207, 0.1000, 3.2207, 3.3059, 3.3059, 3.3059, 0.1000, 0.1000,\n",
      "         3.3059, 3.3059, 0.1000, 3.3059, 0.1000, 3.3059, 3.2207, 3.3059, 3.3059,\n",
      "         3.3059, 3.2207, 3.3059, 3.3059, 3.3059, 3.2143, 3.3059, 3.3059, 3.3059,\n",
      "         3.2143, 3.2207, 3.2207, 3.2207, 3.2143, 0.1000, 3.2143, 3.2207, 0.1000,\n",
      "         3.2207, 3.3059, 0.1000, 3.3059, 3.3059, 3.3059, 3.2207, 3.2207, 0.1000,\n",
      "         3.3059, 0.1000, 3.1577, 3.1577, 3.2207, 3.3059, 3.3059, 0.1000, 0.1000,\n",
      "         3.1577, 3.2143, 3.3059, 0.1000, 3.2143, 3.3059, 0.1000, 3.1577, 3.3059]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.2773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 3 was 83.2%\n",
      "current params: tensor([3.1577, 3.2143, 3.2207, 3.3059], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.4\n",
      "SLow rates:  tensor([[3.6240, 3.6950, 3.6984, 3.7909, 0.1000, 0.1000, 0.1000, 3.6240, 3.6240,\n",
      "         3.6240, 0.1000, 0.1000, 3.6950, 3.6950, 3.6950, 0.1000, 0.1000, 3.6950,\n",
      "         3.6950, 0.1000, 3.6984, 3.6984, 3.6984, 0.1000, 0.1000, 3.6984, 3.6984,\n",
      "         0.1000, 3.6984, 0.1000, 3.6984, 3.7909, 3.7909, 3.7909, 0.1000, 0.1000,\n",
      "         3.7909, 3.7909, 0.1000, 3.7909, 0.1000, 3.7909, 3.6984, 3.7909, 3.7909,\n",
      "         3.7909, 3.6984, 3.7909, 3.7909, 3.7909, 3.6950, 3.7909, 3.7909, 3.7909,\n",
      "         3.6950, 3.6984, 3.6984, 3.6984, 3.6950, 0.1000, 3.6950, 3.6984, 0.1000,\n",
      "         3.6984, 3.7909, 0.1000, 3.7909, 3.7909, 3.7909, 3.6984, 3.6984, 0.1000,\n",
      "         3.7909, 0.1000, 3.6240, 3.6240, 3.6984, 3.7909, 3.7909, 0.1000, 0.1000,\n",
      "         3.6240, 3.6950, 3.7909, 0.1000, 3.6950, 3.7909, 0.1000, 3.6240, 3.7909]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 4 was 84.9%\n",
      "current params: tensor([3.6240, 3.6950, 3.6984, 3.7909], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.5\n",
      "SLow rates:  tensor([[4.0469, 4.1275, 4.1279, 4.2250, 0.1000, 0.1000, 0.1000, 4.0469, 4.0469,\n",
      "         4.0469, 0.1000, 0.1000, 4.1275, 4.1275, 4.1275, 0.1000, 0.1000, 4.1275,\n",
      "         4.1275, 0.1000, 4.1279, 4.1279, 4.1279, 0.1000, 0.1000, 4.1279, 4.1279,\n",
      "         0.1000, 4.1279, 0.1000, 4.1279, 4.2250, 4.2250, 4.2250, 0.1000, 0.1000,\n",
      "         4.2250, 4.2250, 0.1000, 4.2250, 0.1000, 4.2250, 4.1279, 4.2250, 4.2250,\n",
      "         4.2250, 4.1279, 4.2250, 4.2250, 4.2250, 4.1275, 4.2250, 4.2250, 4.2250,\n",
      "         4.1275, 4.1279, 4.1279, 4.1279, 4.1275, 0.1000, 4.1275, 4.1279, 0.1000,\n",
      "         4.1279, 4.2250, 0.1000, 4.2250, 4.2250, 4.2250, 4.1279, 4.1279, 0.1000,\n",
      "         4.2250, 0.1000, 4.0469, 4.0469, 4.1279, 4.2250, 4.2250, 0.1000, 0.1000,\n",
      "         4.0469, 4.1275, 4.2250, 0.1000, 4.1275, 4.2250, 0.1000, 4.0469, 4.2250]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 5 was 86.1%\n",
      "current params: tensor([4.0469, 4.1275, 4.1279, 4.2250], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.5\n",
      "SLow rates:  tensor([[4.4375, 4.5242, 4.5217, 4.6221, 0.1000, 0.1000, 0.1000, 4.4375, 4.4375,\n",
      "         4.4375, 0.1000, 0.1000, 4.5242, 4.5242, 4.5242, 0.1000, 0.1000, 4.5242,\n",
      "         4.5242, 0.1000, 4.5217, 4.5217, 4.5217, 0.1000, 0.1000, 4.5217, 4.5217,\n",
      "         0.1000, 4.5217, 0.1000, 4.5217, 4.6221, 4.6221, 4.6221, 0.1000, 0.1000,\n",
      "         4.6221, 4.6221, 0.1000, 4.6221, 0.1000, 4.6221, 4.5242, 4.6221, 4.6221,\n",
      "         4.6221, 4.5217, 4.6221, 4.6221, 4.6221, 4.5242, 4.6221, 4.6221, 4.6221,\n",
      "         4.5242, 4.5217, 4.5242, 4.5242, 4.5242, 0.1000, 4.5242, 4.5217, 0.1000,\n",
      "         4.5217, 4.6221, 0.1000, 4.6221, 4.6221, 4.6221, 4.5242, 4.5242, 0.1000,\n",
      "         4.6221, 0.1000, 4.4375, 4.4375, 4.5242, 4.6221, 4.6221, 0.1000, 0.1000,\n",
      "         4.4375, 4.5242, 4.6221, 0.1000, 4.5242, 4.6221, 0.1000, 4.4375, 4.6221]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.2214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 6 was 87.0%\n",
      "current params: tensor([4.4375, 4.5242, 4.5217, 4.6221], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.5\n",
      "SLow rates:  tensor([[4.8018, 4.8964, 4.8860, 4.9910, 0.1000, 0.1000, 0.1000, 4.8018, 4.8018,\n",
      "         4.8018, 0.1000, 0.1000, 4.8964, 4.8964, 4.8964, 0.1000, 0.1000, 4.8964,\n",
      "         4.8964, 0.1000, 4.8860, 4.8860, 4.8860, 0.1000, 0.1000, 4.8860, 4.8860,\n",
      "         0.1000, 4.8860, 0.1000, 4.8860, 4.9910, 4.9910, 4.9910, 0.1000, 0.1000,\n",
      "         4.9910, 4.9910, 0.1000, 4.9910, 0.1000, 4.9910, 4.8964, 4.9910, 4.9910,\n",
      "         4.9910, 4.8860, 4.9910, 4.9910, 4.9910, 4.8964, 4.9910, 4.9910, 4.9910,\n",
      "         4.8964, 4.8860, 4.8964, 4.8964, 4.8964, 0.1000, 4.8964, 4.8860, 0.1000,\n",
      "         4.8860, 4.9910, 0.1000, 4.9910, 4.9910, 4.9910, 4.8964, 4.8964, 0.1000,\n",
      "         4.9910, 0.1000, 4.8018, 4.8018, 4.8964, 4.9910, 4.9910, 0.1000, 0.1000,\n",
      "         4.8018, 4.8964, 4.9910, 0.1000, 4.8964, 4.9910, 0.1000, 4.8018, 4.9910]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 7 was 87.8%\n",
      "current params: tensor([4.8018, 4.8964, 4.8860, 4.9910], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.5\n",
      "SLow rates:  tensor([[5.1451, 5.2457, 5.2290, 5.3373, 0.1000, 0.1000, 0.1000, 5.1451, 5.1451,\n",
      "         5.1451, 0.1000, 0.1000, 5.2457, 5.2457, 5.2457, 0.1000, 0.1000, 5.2457,\n",
      "         5.2457, 0.1000, 5.2290, 5.2290, 5.2290, 0.1000, 0.1000, 5.2290, 5.2290,\n",
      "         0.1000, 5.2290, 0.1000, 5.2290, 5.3373, 5.3373, 5.3373, 0.1000, 0.1000,\n",
      "         5.3373, 5.3373, 0.1000, 5.3373, 0.1000, 5.3373, 5.2457, 5.3373, 5.3373,\n",
      "         5.3373, 5.2290, 5.3373, 5.3373, 5.3373, 5.2457, 5.3373, 5.3373, 5.3373,\n",
      "         5.2457, 5.2290, 5.2457, 5.2457, 5.2457, 0.1000, 5.2457, 5.2290, 0.1000,\n",
      "         5.2290, 5.3373, 0.1000, 5.3373, 5.3373, 5.3373, 5.2457, 5.2457, 0.1000,\n",
      "         5.3373, 0.1000, 5.1451, 5.1451, 5.2457, 5.3373, 5.3373, 0.1000, 0.1000,\n",
      "         5.1451, 5.2457, 5.3373, 0.1000, 5.2457, 5.3373, 0.1000, 5.1451, 5.3373]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 8 was 88.5%\n",
      "current params: tensor([5.1451, 5.2457, 5.2290, 5.3373], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.5\n",
      "SLow rates:  tensor([[5.4712, 5.5758, 5.5539, 5.6650, 0.1000, 0.1000, 0.1000, 5.4712, 5.4712,\n",
      "         5.4712, 0.1000, 0.1000, 5.5758, 5.5758, 5.5758, 0.1000, 0.1000, 5.5758,\n",
      "         5.5758, 0.1000, 5.5539, 5.5539, 5.5539, 0.1000, 0.1000, 5.5539, 5.5539,\n",
      "         0.1000, 5.5539, 0.1000, 5.5539, 5.6650, 5.6650, 5.6650, 0.1000, 0.1000,\n",
      "         5.6650, 5.6650, 0.1000, 5.6650, 0.1000, 5.6650, 5.5758, 5.6650, 5.6650,\n",
      "         5.6650, 5.5539, 5.6650, 5.6650, 5.6650, 5.5758, 5.6650, 5.6650, 5.6650,\n",
      "         5.5758, 5.5539, 5.5758, 5.5758, 5.5758, 0.1000, 5.5758, 5.5539, 0.1000,\n",
      "         5.5539, 5.6650, 0.1000, 5.6650, 5.6650, 5.6650, 5.5758, 5.5758, 0.1000,\n",
      "         5.6650, 0.1000, 5.4712, 5.4712, 5.5758, 5.6650, 5.6650, 0.1000, 0.1000,\n",
      "         5.4712, 5.5758, 5.6650, 0.1000, 5.5758, 5.6650, 0.1000, 5.4712, 5.6650]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 9 was 89.0%\n",
      "current params: tensor([5.4712, 5.5758, 5.5539, 5.6650], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.6\n",
      "SLow rates:  tensor([[5.7820, 5.8902, 5.8642, 5.9770, 0.1000, 0.1000, 0.1000, 5.7820, 5.7820,\n",
      "         5.7820, 0.1000, 0.1000, 5.8902, 5.8902, 5.8902, 0.1000, 0.1000, 5.8902,\n",
      "         5.8902, 0.1000, 5.8642, 5.8642, 5.8642, 0.1000, 0.1000, 5.8642, 5.8642,\n",
      "         0.1000, 5.8642, 0.1000, 5.8642, 5.9770, 5.9770, 5.9770, 0.1000, 0.1000,\n",
      "         5.9770, 5.9770, 0.1000, 5.9770, 0.1000, 5.9770, 5.8902, 5.9770, 5.9770,\n",
      "         5.9770, 5.8642, 5.9770, 5.9770, 5.9770, 5.8902, 5.9770, 5.9770, 5.9770,\n",
      "         5.8902, 5.8642, 5.8902, 5.8902, 5.8902, 0.1000, 5.8902, 5.8642, 0.1000,\n",
      "         5.8642, 5.9770, 0.1000, 5.9770, 5.9770, 5.9770, 5.8902, 5.8902, 0.1000,\n",
      "         5.9770, 0.1000, 5.7820, 5.7820, 5.8902, 5.9770, 5.9770, 0.1000, 0.1000,\n",
      "         5.7820, 5.8902, 5.9770, 0.1000, 5.8902, 5.9770, 0.1000, 5.7820, 5.9770]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 10 was 89.5%\n",
      "current params: tensor([5.7820, 5.8902, 5.8642, 5.9770], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.6\n",
      "SLow rates:  tensor([[6.0798, 6.1911, 6.1615, 6.2756, 0.1000, 0.1000, 0.1000, 6.0798, 6.0798,\n",
      "         6.0798, 0.1000, 0.1000, 6.1911, 6.1911, 6.1911, 0.1000, 0.1000, 6.1911,\n",
      "         6.1911, 0.1000, 6.1615, 6.1615, 6.1615, 0.1000, 0.1000, 6.1615, 6.1615,\n",
      "         0.1000, 6.1615, 0.1000, 6.1615, 6.2756, 6.2756, 6.2756, 0.1000, 0.1000,\n",
      "         6.2756, 6.2756, 0.1000, 6.2756, 0.1000, 6.2756, 6.1911, 6.2756, 6.2756,\n",
      "         6.2756, 6.1615, 6.2756, 6.2756, 6.2756, 6.1911, 6.2756, 6.2756, 6.2756,\n",
      "         6.1911, 6.1615, 6.1911, 6.1911, 6.1911, 0.1000, 6.1911, 6.1615, 0.1000,\n",
      "         6.1615, 6.2756, 0.1000, 6.2756, 6.2756, 6.2756, 6.1911, 6.1911, 0.1000,\n",
      "         6.2756, 0.1000, 6.0798, 6.0798, 6.1911, 6.2756, 6.2756, 0.1000, 0.1000,\n",
      "         6.0798, 6.1911, 6.2756, 0.1000, 6.1911, 6.2756, 0.1000, 6.0798, 6.2756]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0816, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 11 was 89.9%\n",
      "current params: tensor([6.0798, 6.1911, 6.1615, 6.2756], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.6\n",
      "SLow rates:  tensor([[6.3664, 6.4801, 6.4476, 6.5625, 0.1000, 0.1000, 0.1000, 6.3664, 6.3664,\n",
      "         6.3664, 0.1000, 0.1000, 6.4801, 6.4801, 6.4801, 0.1000, 0.1000, 6.4801,\n",
      "         6.4801, 0.1000, 6.4476, 6.4476, 6.4476, 0.1000, 0.1000, 6.4476, 6.4476,\n",
      "         0.1000, 6.4476, 0.1000, 6.4476, 6.5625, 6.5625, 6.5625, 0.1000, 0.1000,\n",
      "         6.5625, 6.5625, 0.1000, 6.5625, 0.1000, 6.5625, 6.4801, 6.5625, 6.5625,\n",
      "         6.5625, 6.4476, 6.5625, 6.5625, 6.5625, 6.4801, 6.5625, 6.5625, 6.5625,\n",
      "         6.4801, 6.4476, 6.4801, 6.4801, 6.4801, 0.1000, 6.4801, 6.4476, 0.1000,\n",
      "         6.4476, 6.5625, 0.1000, 6.5625, 6.5625, 6.5625, 6.4801, 6.4801, 0.1000,\n",
      "         6.5625, 0.1000, 6.3664, 6.3664, 6.4801, 6.5625, 6.5625, 0.1000, 0.1000,\n",
      "         6.3664, 6.4801, 6.5625, 0.1000, 6.4801, 6.5625, 0.1000, 6.3664, 6.5625]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 12 was 90.3%\n",
      "current params: tensor([6.3664, 6.4801, 6.4476, 6.5625], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.6\n",
      "SLow rates:  tensor([[6.6431, 6.7586, 6.7236, 6.8391, 0.1000, 0.1000, 0.1000, 6.6431, 6.6431,\n",
      "         6.6431, 0.1000, 0.1000, 6.7586, 6.7586, 6.7586, 0.1000, 0.1000, 6.7586,\n",
      "         6.7586, 0.1000, 6.7236, 6.7236, 6.7236, 0.1000, 0.1000, 6.7236, 6.7236,\n",
      "         0.1000, 6.7236, 0.1000, 6.7236, 6.8391, 6.8391, 6.8391, 0.1000, 0.1000,\n",
      "         6.8391, 6.8391, 0.1000, 6.8391, 0.1000, 6.8391, 6.7586, 6.8391, 6.8391,\n",
      "         6.8391, 6.7236, 6.8391, 6.8391, 6.8391, 6.7586, 6.8391, 6.8391, 6.8391,\n",
      "         6.7586, 6.7236, 6.7586, 6.7586, 6.7586, 0.1000, 6.7586, 6.7236, 0.1000,\n",
      "         6.7236, 6.8391, 0.1000, 6.8391, 6.8391, 6.8391, 6.7586, 6.7586, 0.1000,\n",
      "         6.8391, 0.1000, 6.6431, 6.6431, 6.7586, 6.8391, 6.8391, 0.1000, 0.1000,\n",
      "         6.6431, 6.7586, 6.8391, 0.1000, 6.7586, 6.8391, 0.1000, 6.6431, 6.8391]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 13 was 90.6%\n",
      "current params: tensor([6.6431, 6.7586, 6.7236, 6.8391], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.6\n",
      "SLow rates:  tensor([[6.9107, 7.0279, 6.9906, 7.1066, 0.1000, 0.1000, 0.1000, 6.9107, 6.9107,\n",
      "         6.9107, 0.1000, 0.1000, 7.0279, 7.0279, 7.0279, 0.1000, 0.1000, 7.0279,\n",
      "         7.0279, 0.1000, 6.9906, 6.9906, 6.9906, 0.1000, 0.1000, 6.9906, 6.9906,\n",
      "         0.1000, 6.9906, 0.1000, 6.9906, 7.1066, 7.1066, 7.1066, 0.1000, 0.1000,\n",
      "         7.1066, 7.1066, 0.1000, 7.1066, 0.1000, 7.1066, 7.0279, 7.1066, 7.1066,\n",
      "         7.1066, 6.9906, 7.1066, 7.1066, 7.1066, 7.0279, 7.1066, 7.1066, 7.1066,\n",
      "         7.0279, 6.9906, 7.0279, 7.0279, 7.0279, 0.1000, 7.0279, 6.9906, 0.1000,\n",
      "         6.9906, 7.1066, 0.1000, 7.1066, 7.1066, 7.1066, 7.0279, 7.0279, 0.1000,\n",
      "         7.1066, 0.1000, 6.9107, 6.9107, 7.0279, 7.1066, 7.1066, 0.1000, 0.1000,\n",
      "         6.9107, 7.0279, 7.1066, 0.1000, 7.0279, 7.1066, 0.1000, 6.9107, 7.1066]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 14 was 90.9%\n",
      "current params: tensor([6.9107, 7.0279, 6.9906, 7.1066], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.6\n",
      "SLow rates:  tensor([[7.1704, 7.2889, 7.2497, 7.3659, 0.1000, 0.1000, 0.1000, 7.1704, 7.1704,\n",
      "         7.1704, 0.1000, 0.1000, 7.2889, 7.2889, 7.2889, 0.1000, 0.1000, 7.2889,\n",
      "         7.2889, 0.1000, 7.2497, 7.2497, 7.2497, 0.1000, 0.1000, 7.2497, 7.2497,\n",
      "         0.1000, 7.2497, 0.1000, 7.2497, 7.3659, 7.3659, 7.3659, 0.1000, 0.1000,\n",
      "         7.3659, 7.3659, 0.1000, 7.3659, 0.1000, 7.3659, 7.2889, 7.3659, 7.3659,\n",
      "         7.3659, 7.2497, 7.3659, 7.3659, 7.3659, 7.2889, 7.3659, 7.3659, 7.3659,\n",
      "         7.2889, 7.2497, 7.2889, 7.2889, 7.2889, 0.1000, 7.2889, 7.2497, 0.1000,\n",
      "         7.2497, 7.3659, 0.1000, 7.3659, 7.3659, 7.3659, 7.2889, 7.2889, 0.1000,\n",
      "         7.3659, 0.1000, 7.1704, 7.1704, 7.2889, 7.3659, 7.3659, 0.1000, 0.1000,\n",
      "         7.1704, 7.2889, 7.3659, 0.1000, 7.2889, 7.3659, 0.1000, 7.1704, 7.3659]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 15 was 91.2%\n",
      "current params: tensor([7.1704, 7.2889, 7.2497, 7.3659], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.7\n",
      "SLow rates:  tensor([[7.4229, 7.5424, 7.5015, 7.6178, 0.1000, 0.1000, 0.1000, 7.4229, 7.4229,\n",
      "         7.4229, 0.1000, 0.1000, 7.5424, 7.5424, 7.5424, 0.1000, 0.1000, 7.5424,\n",
      "         7.5424, 0.1000, 7.5015, 7.5015, 7.5015, 0.1000, 0.1000, 7.5015, 7.5015,\n",
      "         0.1000, 7.5015, 0.1000, 7.5015, 7.6178, 7.6178, 7.6178, 0.1000, 0.1000,\n",
      "         7.6178, 7.6178, 0.1000, 7.6178, 0.1000, 7.6178, 7.5424, 7.6178, 7.6178,\n",
      "         7.6178, 7.5015, 7.6178, 7.6178, 7.6178, 7.5424, 7.6178, 7.6178, 7.6178,\n",
      "         7.5424, 7.5015, 7.5424, 7.5424, 7.5424, 0.1000, 7.5424, 7.5015, 0.1000,\n",
      "         7.5015, 7.6178, 0.1000, 7.6178, 7.6178, 7.6178, 7.5424, 7.5424, 0.1000,\n",
      "         7.6178, 0.1000, 7.4229, 7.4229, 7.5424, 7.6178, 7.6178, 0.1000, 0.1000,\n",
      "         7.4229, 7.5424, 7.6178, 0.1000, 7.5424, 7.6178, 0.1000, 7.4229, 7.6178]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 16 was 91.4%\n",
      "current params: tensor([7.4229, 7.5424, 7.5015, 7.6178], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.7\n",
      "SLow rates:  tensor([[7.6687, 7.7891, 7.7467, 7.8630, 0.1000, 0.1000, 0.1000, 7.6687, 7.6687,\n",
      "         7.6687, 0.1000, 0.1000, 7.7891, 7.7891, 7.7891, 0.1000, 0.1000, 7.7891,\n",
      "         7.7891, 0.1000, 7.7467, 7.7467, 7.7467, 0.1000, 0.1000, 7.7467, 7.7467,\n",
      "         0.1000, 7.7467, 0.1000, 7.7467, 7.8630, 7.8630, 7.8630, 0.1000, 0.1000,\n",
      "         7.8630, 7.8630, 0.1000, 7.8630, 0.1000, 7.8630, 7.7891, 7.8630, 7.8630,\n",
      "         7.8630, 7.7467, 7.8630, 7.8630, 7.8630, 7.7891, 7.8630, 7.8630, 7.8630,\n",
      "         7.7891, 7.7467, 7.7891, 7.7891, 7.7891, 0.1000, 7.7891, 7.7467, 0.1000,\n",
      "         7.7467, 7.8630, 0.1000, 7.8630, 7.8630, 7.8630, 7.7891, 7.7891, 0.1000,\n",
      "         7.8630, 0.1000, 7.6687, 7.6687, 7.7891, 7.8630, 7.8630, 0.1000, 0.1000,\n",
      "         7.6687, 7.7891, 7.8630, 0.1000, 7.7891, 7.8630, 0.1000, 7.6687, 7.8630]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 17 was 91.7%\n",
      "current params: tensor([7.6687, 7.7891, 7.7467, 7.8630], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.7\n",
      "SLow rates:  tensor([[7.9084, 8.0296, 7.9859, 8.1021, 0.1000, 0.1000, 0.1000, 7.9084, 7.9084,\n",
      "         7.9084, 0.1000, 0.1000, 8.0296, 8.0296, 8.0296, 0.1000, 0.1000, 8.0296,\n",
      "         8.0296, 0.1000, 7.9859, 7.9859, 7.9859, 0.1000, 0.1000, 7.9859, 7.9859,\n",
      "         0.1000, 7.9859, 0.1000, 7.9859, 8.1021, 8.1021, 8.1021, 0.1000, 0.1000,\n",
      "         8.1021, 8.1021, 0.1000, 8.1021, 0.1000, 8.1021, 8.0296, 8.1021, 8.1021,\n",
      "         8.1021, 7.9859, 8.1021, 8.1021, 8.1021, 8.0296, 8.1021, 8.1021, 8.1021,\n",
      "         8.0296, 7.9859, 8.0296, 8.0296, 8.0296, 0.1000, 8.0296, 7.9859, 0.1000,\n",
      "         7.9859, 8.1021, 0.1000, 8.1021, 8.1021, 8.1021, 8.0296, 8.0296, 0.1000,\n",
      "         8.1021, 0.1000, 7.9084, 7.9084, 8.0296, 8.1021, 8.1021, 0.1000, 0.1000,\n",
      "         7.9084, 8.0296, 8.1021, 0.1000, 8.0296, 8.1021, 0.1000, 7.9084, 8.1021]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 18 was 91.9%\n",
      "current params: tensor([7.9084, 8.0296, 7.9859, 8.1021], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.7\n",
      "SLow rates:  tensor([[8.1426, 8.2644, 8.2195, 8.3356, 0.1000, 0.1000, 0.1000, 8.1426, 8.1426,\n",
      "         8.1426, 0.1000, 0.1000, 8.2644, 8.2644, 8.2644, 0.1000, 0.1000, 8.2644,\n",
      "         8.2644, 0.1000, 8.2195, 8.2195, 8.2195, 0.1000, 0.1000, 8.2195, 8.2195,\n",
      "         0.1000, 8.2195, 0.1000, 8.2195, 8.3356, 8.3356, 8.3356, 0.1000, 0.1000,\n",
      "         8.3356, 8.3356, 0.1000, 8.3356, 0.1000, 8.3356, 8.2644, 8.3356, 8.3356,\n",
      "         8.3356, 8.2195, 8.3356, 8.3356, 8.3356, 8.2644, 8.3356, 8.3356, 8.3356,\n",
      "         8.2644, 8.2195, 8.2644, 8.2644, 8.2644, 0.1000, 8.2644, 8.2195, 0.1000,\n",
      "         8.2195, 8.3356, 0.1000, 8.3356, 8.3356, 8.3356, 8.2644, 8.2644, 0.1000,\n",
      "         8.3356, 0.1000, 8.1426, 8.1426, 8.2644, 8.3356, 8.3356, 0.1000, 0.1000,\n",
      "         8.1426, 8.2644, 8.3356, 0.1000, 8.2644, 8.3356, 0.1000, 8.1426, 8.3356]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 19 was 92.1%\n",
      "current params: tensor([8.1426, 8.2644, 8.2195, 8.3356], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.7\n",
      "SLow rates:  tensor([[8.3717, 8.4940, 8.4479, 8.5639, 0.1000, 0.1000, 0.1000, 8.3717, 8.3717,\n",
      "         8.3717, 0.1000, 0.1000, 8.4940, 8.4940, 8.4940, 0.1000, 0.1000, 8.4940,\n",
      "         8.4940, 0.1000, 8.4479, 8.4479, 8.4479, 0.1000, 0.1000, 8.4479, 8.4479,\n",
      "         0.1000, 8.4479, 0.1000, 8.4479, 8.5639, 8.5639, 8.5639, 0.1000, 0.1000,\n",
      "         8.5639, 8.5639, 0.1000, 8.5639, 0.1000, 8.5639, 8.4940, 8.5639, 8.5639,\n",
      "         8.5639, 8.4479, 8.5639, 8.5639, 8.5639, 8.4940, 8.5639, 8.5639, 8.5639,\n",
      "         8.4940, 8.4479, 8.4940, 8.4940, 8.4940, 0.1000, 8.4940, 8.4479, 0.1000,\n",
      "         8.4479, 8.5639, 0.1000, 8.5639, 8.5639, 8.5639, 8.4940, 8.4940, 0.1000,\n",
      "         8.5639, 0.1000, 8.3717, 8.3717, 8.4940, 8.5639, 8.5639, 0.1000, 0.1000,\n",
      "         8.3717, 8.4940, 8.5639, 0.1000, 8.4940, 8.5639, 0.1000, 8.3717, 8.5639]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 20 was 92.3%\n",
      "current params: tensor([8.3717, 8.4940, 8.4479, 8.5639], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.8\n",
      "SLow rates:  tensor([[8.5965, 8.7185, 8.6715, 8.7870, 0.1000, 0.1000, 0.1000, 8.5965, 8.5965,\n",
      "         8.5965, 0.1000, 0.1000, 8.7185, 8.7185, 8.7185, 0.1000, 0.1000, 8.7185,\n",
      "         8.7185, 0.1000, 8.6715, 8.6715, 8.6715, 0.1000, 0.1000, 8.6715, 8.6715,\n",
      "         0.1000, 8.6715, 0.1000, 8.6715, 8.7870, 8.7870, 8.7870, 0.1000, 0.1000,\n",
      "         8.7870, 8.7870, 0.1000, 8.7870, 0.1000, 8.7870, 8.7185, 8.7870, 8.7870,\n",
      "         8.7870, 8.6715, 8.7870, 8.7870, 8.7870, 8.7185, 8.7870, 8.7870, 8.7870,\n",
      "         8.7185, 8.6715, 8.7185, 8.7185, 8.7185, 0.1000, 8.7185, 8.6715, 0.1000,\n",
      "         8.6715, 8.7870, 0.1000, 8.7870, 8.7870, 8.7870, 8.7185, 8.7185, 0.1000,\n",
      "         8.7870, 0.1000, 8.5965, 8.5965, 8.7185, 8.7870, 8.7870, 0.1000, 0.1000,\n",
      "         8.5965, 8.7185, 8.7870, 0.1000, 8.7185, 8.7870, 0.1000, 8.5965, 8.7870]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0492, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 21 was 92.4%\n",
      "current params: tensor([8.5965, 8.7185, 8.6715, 8.7870], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.8\n",
      "SLow rates:  tensor([[8.8164, 8.9387, 8.8908, 9.0060, 0.1000, 0.1000, 0.1000, 8.8164, 8.8164,\n",
      "         8.8164, 0.1000, 0.1000, 8.9387, 8.9387, 8.9387, 0.1000, 0.1000, 8.9387,\n",
      "         8.9387, 0.1000, 8.8908, 8.8908, 8.8908, 0.1000, 0.1000, 8.8908, 8.8908,\n",
      "         0.1000, 8.8908, 0.1000, 8.8908, 9.0060, 9.0060, 9.0060, 0.1000, 0.1000,\n",
      "         9.0060, 9.0060, 0.1000, 9.0060, 0.1000, 9.0060, 8.9387, 9.0060, 9.0060,\n",
      "         9.0060, 8.8908, 9.0060, 9.0060, 9.0060, 8.9387, 9.0060, 9.0060, 9.0060,\n",
      "         8.9387, 8.8908, 8.9387, 8.9387, 8.9387, 0.1000, 8.9387, 8.8908, 0.1000,\n",
      "         8.8908, 9.0060, 0.1000, 9.0060, 9.0060, 9.0060, 8.9387, 8.9387, 0.1000,\n",
      "         9.0060, 0.1000, 8.8164, 8.8164, 8.9387, 9.0060, 9.0060, 0.1000, 0.1000,\n",
      "         8.8164, 8.9387, 9.0060, 0.1000, 8.9387, 9.0060, 0.1000, 8.8164, 9.0060]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 22 was 92.6%\n",
      "current params: tensor([8.8164, 8.9387, 8.8908, 9.0060], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.8\n",
      "SLow rates:  tensor([[9.0320, 9.1547, 9.1060, 9.2209, 0.1000, 0.1000, 0.1000, 9.0320, 9.0320,\n",
      "         9.0320, 0.1000, 0.1000, 9.1547, 9.1547, 9.1547, 0.1000, 0.1000, 9.1547,\n",
      "         9.1547, 0.1000, 9.1060, 9.1060, 9.1060, 0.1000, 0.1000, 9.1060, 9.1060,\n",
      "         0.1000, 9.1060, 0.1000, 9.1060, 9.2209, 9.2209, 9.2209, 0.1000, 0.1000,\n",
      "         9.2209, 9.2209, 0.1000, 9.2209, 0.1000, 9.2209, 9.1547, 9.2209, 9.2209,\n",
      "         9.2209, 9.1060, 9.2209, 9.2209, 9.2209, 9.1547, 9.2209, 9.2209, 9.2209,\n",
      "         9.1547, 9.1060, 9.1547, 9.1547, 9.1547, 0.1000, 9.1547, 9.1060, 0.1000,\n",
      "         9.1060, 9.2209, 0.1000, 9.2209, 9.2209, 9.2209, 9.1547, 9.1547, 0.1000,\n",
      "         9.2209, 0.1000, 9.0320, 9.0320, 9.1547, 9.2209, 9.2209, 0.1000, 0.1000,\n",
      "         9.0320, 9.1547, 9.2209, 0.1000, 9.1547, 9.2209, 0.1000, 9.0320, 9.2209]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 23 was 92.7%\n",
      "current params: tensor([9.0320, 9.1547, 9.1060, 9.2209], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.8\n",
      "SLow rates:  tensor([[9.2438, 9.3667, 9.3173, 9.4319, 0.1000, 0.1000, 0.1000, 9.2438, 9.2438,\n",
      "         9.2438, 0.1000, 0.1000, 9.3667, 9.3667, 9.3667, 0.1000, 0.1000, 9.3667,\n",
      "         9.3667, 0.1000, 9.3173, 9.3173, 9.3173, 0.1000, 0.1000, 9.3173, 9.3173,\n",
      "         0.1000, 9.3173, 0.1000, 9.3173, 9.4319, 9.4319, 9.4319, 0.1000, 0.1000,\n",
      "         9.4319, 9.4319, 0.1000, 9.4319, 0.1000, 9.4319, 9.3667, 9.4319, 9.4319,\n",
      "         9.4319, 9.3173, 9.4319, 9.4319, 9.4319, 9.3667, 9.4319, 9.4319, 9.4319,\n",
      "         9.3667, 9.3173, 9.3667, 9.3667, 9.3667, 0.1000, 9.3667, 9.3173, 0.1000,\n",
      "         9.3173, 9.4319, 0.1000, 9.4319, 9.4319, 9.4319, 9.3667, 9.3667, 0.1000,\n",
      "         9.4319, 0.1000, 9.2438, 9.2438, 9.3667, 9.4319, 9.4319, 0.1000, 0.1000,\n",
      "         9.2438, 9.3667, 9.4319, 0.1000, 9.3667, 9.4319, 0.1000, 9.2438, 9.4319]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 24 was 92.9%\n",
      "current params: tensor([9.2438, 9.3667, 9.3173, 9.4319], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.8\n",
      "SLow rates:  tensor([[9.4520, 9.5751, 9.5250, 9.6393, 0.1000, 0.1000, 0.1000, 9.4520, 9.4520,\n",
      "         9.4520, 0.1000, 0.1000, 9.5751, 9.5751, 9.5751, 0.1000, 0.1000, 9.5751,\n",
      "         9.5751, 0.1000, 9.5250, 9.5250, 9.5250, 0.1000, 0.1000, 9.5250, 9.5250,\n",
      "         0.1000, 9.5250, 0.1000, 9.5250, 9.6393, 9.6393, 9.6393, 0.1000, 0.1000,\n",
      "         9.6393, 9.6393, 0.1000, 9.6393, 0.1000, 9.6393, 9.5751, 9.6393, 9.6393,\n",
      "         9.6393, 9.5250, 9.6393, 9.6393, 9.6393, 9.5751, 9.6393, 9.6393, 9.6393,\n",
      "         9.5751, 9.5250, 9.5751, 9.5751, 9.5751, 0.1000, 9.5751, 9.5250, 0.1000,\n",
      "         9.5250, 9.6393, 0.1000, 9.6393, 9.6393, 9.6393, 9.5751, 9.5751, 0.1000,\n",
      "         9.6393, 0.1000, 9.4520, 9.4520, 9.5751, 9.6393, 9.6393, 0.1000, 0.1000,\n",
      "         9.4520, 9.5751, 9.6393, 0.1000, 9.5751, 9.6393, 0.1000, 9.4520, 9.6393]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 25 was 93.0%\n",
      "current params: tensor([9.4520, 9.5751, 9.5250, 9.6393], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.9\n",
      "SLow rates:  tensor([[9.6568, 9.7800, 9.7292, 9.8432, 0.1000, 0.1000, 0.1000, 9.6568, 9.6568,\n",
      "         9.6568, 0.1000, 0.1000, 9.7800, 9.7800, 9.7800, 0.1000, 0.1000, 9.7800,\n",
      "         9.7800, 0.1000, 9.7292, 9.7292, 9.7292, 0.1000, 0.1000, 9.7292, 9.7292,\n",
      "         0.1000, 9.7292, 0.1000, 9.7292, 9.8432, 9.8432, 9.8432, 0.1000, 0.1000,\n",
      "         9.8432, 9.8432, 0.1000, 9.8432, 0.1000, 9.8432, 9.7800, 9.8432, 9.8432,\n",
      "         9.8432, 9.7292, 9.8432, 9.8432, 9.8432, 9.7800, 9.8432, 9.8432, 9.8432,\n",
      "         9.7800, 9.7292, 9.7800, 9.7800, 9.7800, 0.1000, 9.7800, 9.7292, 0.1000,\n",
      "         9.7292, 9.8432, 0.1000, 9.8432, 9.8432, 9.8432, 9.7800, 9.7800, 0.1000,\n",
      "         9.8432, 0.1000, 9.6568, 9.6568, 9.7800, 9.8432, 9.8432, 0.1000, 0.1000,\n",
      "         9.6568, 9.7800, 9.8432, 0.1000, 9.7800, 9.8432, 0.1000, 9.6568, 9.8432]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 26 was 93.2%\n",
      "current params: tensor([9.6568, 9.7800, 9.7292, 9.8432], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.9\n",
      "SLow rates:  tensor([[ 9.8583,  9.9816,  9.9303, 10.0440,  0.1000,  0.1000,  0.1000,  9.8583,\n",
      "          9.8583,  9.8583,  0.1000,  0.1000,  9.9816,  9.9816,  9.9816,  0.1000,\n",
      "          0.1000,  9.9816,  9.9816,  0.1000,  9.9303,  9.9303,  9.9303,  0.1000,\n",
      "          0.1000,  9.9303,  9.9303,  0.1000,  9.9303,  0.1000,  9.9303, 10.0440,\n",
      "         10.0440, 10.0440,  0.1000,  0.1000, 10.0440, 10.0440,  0.1000, 10.0440,\n",
      "          0.1000, 10.0440,  9.9816, 10.0440, 10.0440, 10.0440,  9.9303, 10.0440,\n",
      "         10.0440, 10.0440,  9.9816, 10.0440, 10.0440, 10.0440,  9.9816,  9.9303,\n",
      "          9.9816,  9.9816,  9.9816,  0.1000,  9.9816,  9.9303,  0.1000,  9.9303,\n",
      "         10.0440,  0.1000, 10.0440, 10.0440, 10.0440,  9.9816,  9.9816,  0.1000,\n",
      "         10.0440,  0.1000,  9.8583,  9.8583,  9.9816, 10.0440, 10.0440,  0.1000,\n",
      "          0.1000,  9.8583,  9.9816, 10.0440,  0.1000,  9.9816, 10.0440,  0.1000,\n",
      "          9.8583, 10.0440]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 27 was 93.3%\n",
      "current params: tensor([ 9.8583,  9.9816,  9.9303, 10.0440], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.9\n",
      "SLow rates:  tensor([[10.0568, 10.1801, 10.1283, 10.2416,  0.1000,  0.1000,  0.1000, 10.0568,\n",
      "         10.0568, 10.0568,  0.1000,  0.1000, 10.1801, 10.1801, 10.1801,  0.1000,\n",
      "          0.1000, 10.1801, 10.1801,  0.1000, 10.1283, 10.1283, 10.1283,  0.1000,\n",
      "          0.1000, 10.1283, 10.1283,  0.1000, 10.1283,  0.1000, 10.1283, 10.2416,\n",
      "         10.2416, 10.2416,  0.1000,  0.1000, 10.2416, 10.2416,  0.1000, 10.2416,\n",
      "          0.1000, 10.2416, 10.1801, 10.2416, 10.2416, 10.2416, 10.1283, 10.2416,\n",
      "         10.2416, 10.2416, 10.1801, 10.2416, 10.2416, 10.2416, 10.1801, 10.1283,\n",
      "         10.1801, 10.1801, 10.1801,  0.1000, 10.1801, 10.1283,  0.1000, 10.1283,\n",
      "         10.2416,  0.1000, 10.2416, 10.2416, 10.2416, 10.1801, 10.1801,  0.1000,\n",
      "         10.2416,  0.1000, 10.0568, 10.0568, 10.1801, 10.2416, 10.2416,  0.1000,\n",
      "          0.1000, 10.0568, 10.1801, 10.2416,  0.1000, 10.1801, 10.2416,  0.1000,\n",
      "         10.0568, 10.2416]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 28 was 93.4%\n",
      "current params: tensor([10.0568, 10.1801, 10.1283, 10.2416], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.9\n",
      "SLow rates:  tensor([[10.2524, 10.3758, 10.3235, 10.4364,  0.1000,  0.1000,  0.1000, 10.2524,\n",
      "         10.2524, 10.2524,  0.1000,  0.1000, 10.3758, 10.3758, 10.3758,  0.1000,\n",
      "          0.1000, 10.3758, 10.3758,  0.1000, 10.3235, 10.3235, 10.3235,  0.1000,\n",
      "          0.1000, 10.3235, 10.3235,  0.1000, 10.3235,  0.1000, 10.3235, 10.4364,\n",
      "         10.4364, 10.4364,  0.1000,  0.1000, 10.4364, 10.4364,  0.1000, 10.4364,\n",
      "          0.1000, 10.4364, 10.3758, 10.4364, 10.4364, 10.4364, 10.3235, 10.4364,\n",
      "         10.4364, 10.4364, 10.3758, 10.4364, 10.4364, 10.4364, 10.3758, 10.3235,\n",
      "         10.3758, 10.3758, 10.3758,  0.1000, 10.3758, 10.3235,  0.1000, 10.3235,\n",
      "         10.4364,  0.1000, 10.4364, 10.4364, 10.4364, 10.3758, 10.3758,  0.1000,\n",
      "         10.4364,  0.1000, 10.2524, 10.2524, 10.3758, 10.4364, 10.4364,  0.1000,\n",
      "          0.1000, 10.2524, 10.3758, 10.4364,  0.1000, 10.3758, 10.4364,  0.1000,\n",
      "         10.2524, 10.4364]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 29 was 93.5%\n",
      "current params: tensor([10.2524, 10.3758, 10.3235, 10.4364], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.9\n",
      "SLow rates:  tensor([[10.4453, 10.5686, 10.5159, 10.6285,  0.1000,  0.1000,  0.1000, 10.4453,\n",
      "         10.4453, 10.4453,  0.1000,  0.1000, 10.5686, 10.5686, 10.5686,  0.1000,\n",
      "          0.1000, 10.5686, 10.5686,  0.1000, 10.5159, 10.5159, 10.5159,  0.1000,\n",
      "          0.1000, 10.5159, 10.5159,  0.1000, 10.5159,  0.1000, 10.5159, 10.6285,\n",
      "         10.6285, 10.6285,  0.1000,  0.1000, 10.6285, 10.6285,  0.1000, 10.6285,\n",
      "          0.1000, 10.6285, 10.5686, 10.6285, 10.6285, 10.6285, 10.5159, 10.6285,\n",
      "         10.6285, 10.6285, 10.5686, 10.6285, 10.6285, 10.6285, 10.5686, 10.5159,\n",
      "         10.5686, 10.5686, 10.5686,  0.1000, 10.5686, 10.5159,  0.1000, 10.5159,\n",
      "         10.6285,  0.1000, 10.6285, 10.6285, 10.6285, 10.5686, 10.5686,  0.1000,\n",
      "         10.6285,  0.1000, 10.4453, 10.4453, 10.5686, 10.6285, 10.6285,  0.1000,\n",
      "          0.1000, 10.4453, 10.5686, 10.6285,  0.1000, 10.5686, 10.6285,  0.1000,\n",
      "         10.4453, 10.6285]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 30 was 93.6%\n",
      "current params: tensor([10.4453, 10.5686, 10.5159, 10.6285], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  5.9\n",
      "SLow rates:  tensor([[10.6355, 10.7589, 10.7057, 10.8180,  0.1000,  0.1000,  0.1000, 10.6355,\n",
      "         10.6355, 10.6355,  0.1000,  0.1000, 10.7589, 10.7589, 10.7589,  0.1000,\n",
      "          0.1000, 10.7589, 10.7589,  0.1000, 10.7057, 10.7057, 10.7057,  0.1000,\n",
      "          0.1000, 10.7057, 10.7057,  0.1000, 10.7057,  0.1000, 10.7057, 10.8180,\n",
      "         10.8180, 10.8180,  0.1000,  0.1000, 10.8180, 10.8180,  0.1000, 10.8180,\n",
      "          0.1000, 10.8180, 10.7589, 10.8180, 10.8180, 10.8180, 10.7057, 10.8180,\n",
      "         10.8180, 10.8180, 10.7589, 10.8180, 10.8180, 10.8180, 10.7589, 10.7057,\n",
      "         10.7589, 10.7589, 10.7589,  0.1000, 10.7589, 10.7057,  0.1000, 10.7057,\n",
      "         10.8180,  0.1000, 10.8180, 10.8180, 10.8180, 10.7589, 10.7589,  0.1000,\n",
      "         10.8180,  0.1000, 10.6355, 10.6355, 10.7589, 10.8180, 10.8180,  0.1000,\n",
      "          0.1000, 10.6355, 10.7589, 10.8180,  0.1000, 10.7589, 10.8180,  0.1000,\n",
      "         10.6355, 10.8180]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 31 was 93.7%\n",
      "current params: tensor([10.6355, 10.7589, 10.7057, 10.8180], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.0\n",
      "SLow rates:  tensor([[10.8234, 10.9467, 10.8931, 11.0050,  0.1000,  0.1000,  0.1000, 10.8234,\n",
      "         10.8234, 10.8234,  0.1000,  0.1000, 10.9467, 10.9467, 10.9467,  0.1000,\n",
      "          0.1000, 10.9467, 10.9467,  0.1000, 10.8931, 10.8931, 10.8931,  0.1000,\n",
      "          0.1000, 10.8931, 10.8931,  0.1000, 10.8931,  0.1000, 10.8931, 11.0050,\n",
      "         11.0050, 11.0050,  0.1000,  0.1000, 11.0050, 11.0050,  0.1000, 11.0050,\n",
      "          0.1000, 11.0050, 10.9467, 11.0050, 11.0050, 11.0050, 10.8931, 11.0050,\n",
      "         11.0050, 11.0050, 10.9467, 11.0050, 11.0050, 11.0050, 10.9467, 10.8931,\n",
      "         10.9467, 10.9467, 10.9467,  0.1000, 10.9467, 10.8931,  0.1000, 10.8931,\n",
      "         11.0050,  0.1000, 11.0050, 11.0050, 11.0050, 10.9467, 10.9467,  0.1000,\n",
      "         11.0050,  0.1000, 10.8234, 10.8234, 10.9467, 11.0050, 11.0050,  0.1000,\n",
      "          0.1000, 10.8234, 10.9467, 11.0050,  0.1000, 10.9467, 11.0050,  0.1000,\n",
      "         10.8234, 11.0050]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 32 was 93.8%\n",
      "current params: tensor([10.8234, 10.9467, 10.8931, 11.0050], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.0\n",
      "SLow rates:  tensor([[11.0088, 11.1321, 11.0782, 11.1897,  0.1000,  0.1000,  0.1000, 11.0088,\n",
      "         11.0088, 11.0088,  0.1000,  0.1000, 11.1321, 11.1321, 11.1321,  0.1000,\n",
      "          0.1000, 11.1321, 11.1321,  0.1000, 11.0782, 11.0782, 11.0782,  0.1000,\n",
      "          0.1000, 11.0782, 11.0782,  0.1000, 11.0782,  0.1000, 11.0782, 11.1897,\n",
      "         11.1897, 11.1897,  0.1000,  0.1000, 11.1897, 11.1897,  0.1000, 11.1897,\n",
      "          0.1000, 11.1897, 11.1321, 11.1897, 11.1897, 11.1897, 11.0782, 11.1897,\n",
      "         11.1897, 11.1897, 11.1321, 11.1897, 11.1897, 11.1897, 11.1321, 11.0782,\n",
      "         11.1321, 11.1321, 11.1321,  0.1000, 11.1321, 11.0782,  0.1000, 11.0782,\n",
      "         11.1897,  0.1000, 11.1897, 11.1897, 11.1897, 11.1321, 11.1321,  0.1000,\n",
      "         11.1897,  0.1000, 11.0088, 11.0088, 11.1321, 11.1897, 11.1897,  0.1000,\n",
      "          0.1000, 11.0088, 11.1321, 11.1897,  0.1000, 11.1321, 11.1897,  0.1000,\n",
      "         11.0088, 11.1897]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 33 was 93.9%\n",
      "current params: tensor([11.0088, 11.1321, 11.0782, 11.1897], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.0\n",
      "SLow rates:  tensor([[11.1920, 11.3152, 11.2610, 11.3721,  0.1000,  0.1000,  0.1000, 11.1920,\n",
      "         11.1920, 11.1920,  0.1000,  0.1000, 11.3152, 11.3152, 11.3152,  0.1000,\n",
      "          0.1000, 11.3152, 11.3152,  0.1000, 11.2610, 11.2610, 11.2610,  0.1000,\n",
      "          0.1000, 11.2610, 11.2610,  0.1000, 11.2610,  0.1000, 11.2610, 11.3721,\n",
      "         11.3721, 11.3721,  0.1000,  0.1000, 11.3721, 11.3721,  0.1000, 11.3721,\n",
      "          0.1000, 11.3721, 11.3152, 11.3721, 11.3721, 11.3721, 11.2610, 11.3721,\n",
      "         11.3721, 11.3721, 11.3152, 11.3721, 11.3721, 11.3721, 11.3152, 11.2610,\n",
      "         11.3152, 11.3152, 11.3152,  0.1000, 11.3152, 11.2610,  0.1000, 11.2610,\n",
      "         11.3721,  0.1000, 11.3721, 11.3721, 11.3721, 11.3152, 11.3152,  0.1000,\n",
      "         11.3721,  0.1000, 11.1920, 11.1920, 11.3152, 11.3721, 11.3721,  0.1000,\n",
      "          0.1000, 11.1920, 11.3152, 11.3721,  0.1000, 11.3152, 11.3721,  0.1000,\n",
      "         11.1920, 11.3721]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 34 was 94.0%\n",
      "current params: tensor([11.1920, 11.3152, 11.2610, 11.3721], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.0\n",
      "SLow rates:  tensor([[11.3731, 11.4962, 11.4417, 11.5525,  0.1000,  0.1000,  0.1000, 11.3731,\n",
      "         11.3731, 11.3731,  0.1000,  0.1000, 11.4962, 11.4962, 11.4962,  0.1000,\n",
      "          0.1000, 11.4962, 11.4962,  0.1000, 11.4417, 11.4417, 11.4417,  0.1000,\n",
      "          0.1000, 11.4417, 11.4417,  0.1000, 11.4417,  0.1000, 11.4417, 11.5525,\n",
      "         11.5525, 11.5525,  0.1000,  0.1000, 11.5525, 11.5525,  0.1000, 11.5525,\n",
      "          0.1000, 11.5525, 11.4962, 11.5525, 11.5525, 11.5525, 11.4417, 11.5525,\n",
      "         11.5525, 11.5525, 11.4962, 11.5525, 11.5525, 11.5525, 11.4962, 11.4417,\n",
      "         11.4962, 11.4962, 11.4962,  0.1000, 11.4962, 11.4417,  0.1000, 11.4417,\n",
      "         11.5525,  0.1000, 11.5525, 11.5525, 11.5525, 11.4962, 11.4962,  0.1000,\n",
      "         11.5525,  0.1000, 11.3731, 11.3731, 11.4962, 11.5525, 11.5525,  0.1000,\n",
      "          0.1000, 11.3731, 11.4962, 11.5525,  0.1000, 11.4962, 11.5525,  0.1000,\n",
      "         11.3731, 11.5525]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 35 was 94.1%\n",
      "current params: tensor([11.3731, 11.4962, 11.4417, 11.5525], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.0\n",
      "SLow rates:  tensor([[11.5522, 11.6752, 11.6204, 11.7307,  0.1000,  0.1000,  0.1000, 11.5522,\n",
      "         11.5522, 11.5522,  0.1000,  0.1000, 11.6752, 11.6752, 11.6752,  0.1000,\n",
      "          0.1000, 11.6752, 11.6752,  0.1000, 11.6204, 11.6204, 11.6204,  0.1000,\n",
      "          0.1000, 11.6204, 11.6204,  0.1000, 11.6204,  0.1000, 11.6204, 11.7307,\n",
      "         11.7307, 11.7307,  0.1000,  0.1000, 11.7307, 11.7307,  0.1000, 11.7307,\n",
      "          0.1000, 11.7307, 11.6752, 11.7307, 11.7307, 11.7307, 11.6204, 11.7307,\n",
      "         11.7307, 11.7307, 11.6752, 11.7307, 11.7307, 11.7307, 11.6752, 11.6204,\n",
      "         11.6752, 11.6752, 11.6752,  0.1000, 11.6752, 11.6204,  0.1000, 11.6204,\n",
      "         11.7307,  0.1000, 11.7307, 11.7307, 11.7307, 11.6752, 11.6752,  0.1000,\n",
      "         11.7307,  0.1000, 11.5522, 11.5522, 11.6752, 11.7307, 11.7307,  0.1000,\n",
      "          0.1000, 11.5522, 11.6752, 11.7307,  0.1000, 11.6752, 11.7307,  0.1000,\n",
      "         11.5522, 11.7307]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 36 was 94.1%\n",
      "current params: tensor([11.5522, 11.6752, 11.6204, 11.7307], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.1\n",
      "SLow rates:  tensor([[11.7293, 11.8521, 11.7971, 11.9070,  0.1000,  0.1000,  0.1000, 11.7293,\n",
      "         11.7293, 11.7293,  0.1000,  0.1000, 11.8521, 11.8521, 11.8521,  0.1000,\n",
      "          0.1000, 11.8521, 11.8521,  0.1000, 11.7971, 11.7971, 11.7971,  0.1000,\n",
      "          0.1000, 11.7971, 11.7971,  0.1000, 11.7971,  0.1000, 11.7971, 11.9070,\n",
      "         11.9070, 11.9070,  0.1000,  0.1000, 11.9070, 11.9070,  0.1000, 11.9070,\n",
      "          0.1000, 11.9070, 11.8521, 11.9070, 11.9070, 11.9070, 11.7971, 11.9070,\n",
      "         11.9070, 11.9070, 11.8521, 11.9070, 11.9070, 11.9070, 11.8521, 11.7971,\n",
      "         11.8521, 11.8521, 11.8521,  0.1000, 11.8521, 11.7971,  0.1000, 11.7971,\n",
      "         11.9070,  0.1000, 11.9070, 11.9070, 11.9070, 11.8521, 11.8521,  0.1000,\n",
      "         11.9070,  0.1000, 11.7293, 11.7293, 11.8521, 11.9070, 11.9070,  0.1000,\n",
      "          0.1000, 11.7293, 11.8521, 11.9070,  0.1000, 11.8521, 11.9070,  0.1000,\n",
      "         11.7293, 11.9070]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 37 was 94.2%\n",
      "current params: tensor([11.7293, 11.8521, 11.7971, 11.9070], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.1\n",
      "SLow rates:  tensor([[11.9045, 12.0272, 11.9719, 12.0815,  0.1000,  0.1000,  0.1000, 11.9045,\n",
      "         11.9045, 11.9045,  0.1000,  0.1000, 12.0272, 12.0272, 12.0272,  0.1000,\n",
      "          0.1000, 12.0272, 12.0272,  0.1000, 11.9719, 11.9719, 11.9719,  0.1000,\n",
      "          0.1000, 11.9719, 11.9719,  0.1000, 11.9719,  0.1000, 11.9719, 12.0815,\n",
      "         12.0815, 12.0815,  0.1000,  0.1000, 12.0815, 12.0815,  0.1000, 12.0815,\n",
      "          0.1000, 12.0815, 12.0272, 12.0815, 12.0815, 12.0815, 11.9719, 12.0815,\n",
      "         12.0815, 12.0815, 12.0272, 12.0815, 12.0815, 12.0815, 12.0272, 11.9719,\n",
      "         12.0272, 12.0272, 12.0272,  0.1000, 12.0272, 11.9719,  0.1000, 11.9719,\n",
      "         12.0815,  0.1000, 12.0815, 12.0815, 12.0815, 12.0272, 12.0272,  0.1000,\n",
      "         12.0815,  0.1000, 11.9045, 11.9045, 12.0272, 12.0815, 12.0815,  0.1000,\n",
      "          0.1000, 11.9045, 12.0272, 12.0815,  0.1000, 12.0272, 12.0815,  0.1000,\n",
      "         11.9045, 12.0815]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 38 was 94.3%\n",
      "current params: tensor([11.9045, 12.0272, 11.9719, 12.0815], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.1\n",
      "SLow rates:  tensor([[12.0779, 12.2005, 12.1450, 12.2542,  0.1000,  0.1000,  0.1000, 12.0779,\n",
      "         12.0779, 12.0779,  0.1000,  0.1000, 12.2005, 12.2005, 12.2005,  0.1000,\n",
      "          0.1000, 12.2005, 12.2005,  0.1000, 12.1450, 12.1450, 12.1450,  0.1000,\n",
      "          0.1000, 12.1450, 12.1450,  0.1000, 12.1450,  0.1000, 12.1450, 12.2542,\n",
      "         12.2542, 12.2542,  0.1000,  0.1000, 12.2542, 12.2542,  0.1000, 12.2542,\n",
      "          0.1000, 12.2542, 12.2005, 12.2542, 12.2542, 12.2542, 12.1450, 12.2542,\n",
      "         12.2542, 12.2542, 12.2005, 12.2542, 12.2542, 12.2542, 12.2005, 12.1450,\n",
      "         12.2005, 12.2005, 12.2005,  0.1000, 12.2005, 12.1450,  0.1000, 12.1450,\n",
      "         12.2542,  0.1000, 12.2542, 12.2542, 12.2542, 12.2005, 12.2005,  0.1000,\n",
      "         12.2542,  0.1000, 12.0779, 12.0779, 12.2005, 12.2542, 12.2542,  0.1000,\n",
      "          0.1000, 12.0779, 12.2005, 12.2542,  0.1000, 12.2005, 12.2542,  0.1000,\n",
      "         12.0779, 12.2542]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 39 was 94.4%\n",
      "current params: tensor([12.0779, 12.2005, 12.1450, 12.2542], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.1\n",
      "SLow rates:  tensor([[12.2496, 12.3721, 12.3163, 12.4251,  0.1000,  0.1000,  0.1000, 12.2496,\n",
      "         12.2496, 12.2496,  0.1000,  0.1000, 12.3721, 12.3721, 12.3721,  0.1000,\n",
      "          0.1000, 12.3721, 12.3721,  0.1000, 12.3163, 12.3163, 12.3163,  0.1000,\n",
      "          0.1000, 12.3163, 12.3163,  0.1000, 12.3163,  0.1000, 12.3163, 12.4251,\n",
      "         12.4251, 12.4251,  0.1000,  0.1000, 12.4251, 12.4251,  0.1000, 12.4251,\n",
      "          0.1000, 12.4251, 12.3721, 12.4251, 12.4251, 12.4251, 12.3163, 12.4251,\n",
      "         12.4251, 12.4251, 12.3721, 12.4251, 12.4251, 12.4251, 12.3721, 12.3163,\n",
      "         12.3721, 12.3721, 12.3721,  0.1000, 12.3721, 12.3163,  0.1000, 12.3163,\n",
      "         12.4251,  0.1000, 12.4251, 12.4251, 12.4251, 12.3721, 12.3721,  0.1000,\n",
      "         12.4251,  0.1000, 12.2496, 12.2496, 12.3721, 12.4251, 12.4251,  0.1000,\n",
      "          0.1000, 12.2496, 12.3721, 12.4251,  0.1000, 12.3721, 12.4251,  0.1000,\n",
      "         12.2496, 12.4251]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 40 was 94.4%\n",
      "current params: tensor([12.2496, 12.3721, 12.3163, 12.4251], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.1\n",
      "SLow rates:  tensor([[12.4196, 12.5419, 12.4860, 12.5945,  0.1000,  0.1000,  0.1000, 12.4196,\n",
      "         12.4196, 12.4196,  0.1000,  0.1000, 12.5419, 12.5419, 12.5419,  0.1000,\n",
      "          0.1000, 12.5419, 12.5419,  0.1000, 12.4860, 12.4860, 12.4860,  0.1000,\n",
      "          0.1000, 12.4860, 12.4860,  0.1000, 12.4860,  0.1000, 12.4860, 12.5945,\n",
      "         12.5945, 12.5945,  0.1000,  0.1000, 12.5945, 12.5945,  0.1000, 12.5945,\n",
      "          0.1000, 12.5945, 12.5419, 12.5945, 12.5945, 12.5945, 12.4860, 12.5945,\n",
      "         12.5945, 12.5945, 12.5419, 12.5945, 12.5945, 12.5945, 12.5419, 12.4860,\n",
      "         12.5419, 12.5419, 12.5419,  0.1000, 12.5419, 12.4860,  0.1000, 12.4860,\n",
      "         12.5945,  0.1000, 12.5945, 12.5945, 12.5945, 12.5419, 12.5419,  0.1000,\n",
      "         12.5945,  0.1000, 12.4196, 12.4196, 12.5419, 12.5945, 12.5945,  0.1000,\n",
      "          0.1000, 12.4196, 12.5419, 12.5945,  0.1000, 12.5419, 12.5945,  0.1000,\n",
      "         12.4196, 12.5945]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 41 was 94.5%\n",
      "current params: tensor([12.4196, 12.5419, 12.4860, 12.5945], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.2\n",
      "SLow rates:  tensor([[12.5881, 12.7102, 12.6541, 12.7622,  0.1000,  0.1000,  0.1000, 12.5881,\n",
      "         12.5881, 12.5881,  0.1000,  0.1000, 12.7102, 12.7102, 12.7102,  0.1000,\n",
      "          0.1000, 12.7102, 12.7102,  0.1000, 12.6541, 12.6541, 12.6541,  0.1000,\n",
      "          0.1000, 12.6541, 12.6541,  0.1000, 12.6541,  0.1000, 12.6541, 12.7622,\n",
      "         12.7622, 12.7622,  0.1000,  0.1000, 12.7622, 12.7622,  0.1000, 12.7622,\n",
      "          0.1000, 12.7622, 12.7102, 12.7622, 12.7622, 12.7622, 12.6541, 12.7622,\n",
      "         12.7622, 12.7622, 12.7102, 12.7622, 12.7622, 12.7622, 12.7102, 12.6541,\n",
      "         12.7102, 12.7102, 12.7102,  0.1000, 12.7102, 12.6541,  0.1000, 12.6541,\n",
      "         12.7622,  0.1000, 12.7622, 12.7622, 12.7622, 12.7102, 12.7102,  0.1000,\n",
      "         12.7622,  0.1000, 12.5881, 12.5881, 12.7102, 12.7622, 12.7622,  0.1000,\n",
      "          0.1000, 12.5881, 12.7102, 12.7622,  0.1000, 12.7102, 12.7622,  0.1000,\n",
      "         12.5881, 12.7622]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 42 was 94.6%\n",
      "current params: tensor([12.5881, 12.7102, 12.6541, 12.7622], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.2\n",
      "SLow rates:  tensor([[12.7550, 12.8769, 12.8205, 12.9284,  0.1000,  0.1000,  0.1000, 12.7550,\n",
      "         12.7550, 12.7550,  0.1000,  0.1000, 12.8769, 12.8769, 12.8769,  0.1000,\n",
      "          0.1000, 12.8769, 12.8769,  0.1000, 12.8205, 12.8205, 12.8205,  0.1000,\n",
      "          0.1000, 12.8205, 12.8205,  0.1000, 12.8205,  0.1000, 12.8205, 12.9284,\n",
      "         12.9284, 12.9284,  0.1000,  0.1000, 12.9284, 12.9284,  0.1000, 12.9284,\n",
      "          0.1000, 12.9284, 12.8769, 12.9284, 12.9284, 12.9284, 12.8205, 12.9284,\n",
      "         12.9284, 12.9284, 12.8769, 12.9284, 12.9284, 12.9284, 12.8769, 12.8205,\n",
      "         12.8769, 12.8769, 12.8769,  0.1000, 12.8769, 12.8205,  0.1000, 12.8205,\n",
      "         12.9284,  0.1000, 12.9284, 12.9284, 12.9284, 12.8769, 12.8769,  0.1000,\n",
      "         12.9284,  0.1000, 12.7550, 12.7550, 12.8769, 12.9284, 12.9284,  0.1000,\n",
      "          0.1000, 12.7550, 12.8769, 12.9284,  0.1000, 12.8769, 12.9284,  0.1000,\n",
      "         12.7550, 12.9284]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 43 was 94.6%\n",
      "current params: tensor([12.7550, 12.8769, 12.8205, 12.9284], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.2\n",
      "SLow rates:  tensor([[12.9204, 13.0421, 12.9856, 13.0931,  0.1000,  0.1000,  0.1000, 12.9204,\n",
      "         12.9204, 12.9204,  0.1000,  0.1000, 13.0421, 13.0421, 13.0421,  0.1000,\n",
      "          0.1000, 13.0421, 13.0421,  0.1000, 12.9856, 12.9856, 12.9856,  0.1000,\n",
      "          0.1000, 12.9856, 12.9856,  0.1000, 12.9856,  0.1000, 12.9856, 13.0931,\n",
      "         13.0931, 13.0931,  0.1000,  0.1000, 13.0931, 13.0931,  0.1000, 13.0931,\n",
      "          0.1000, 13.0931, 13.0421, 13.0931, 13.0931, 13.0931, 12.9856, 13.0931,\n",
      "         13.0931, 13.0931, 13.0421, 13.0931, 13.0931, 13.0931, 13.0421, 12.9856,\n",
      "         13.0421, 13.0421, 13.0421,  0.1000, 13.0421, 12.9856,  0.1000, 12.9856,\n",
      "         13.0931,  0.1000, 13.0931, 13.0931, 13.0931, 13.0421, 13.0421,  0.1000,\n",
      "         13.0931,  0.1000, 12.9204, 12.9204, 13.0421, 13.0931, 13.0931,  0.1000,\n",
      "          0.1000, 12.9204, 13.0421, 13.0931,  0.1000, 13.0421, 13.0931,  0.1000,\n",
      "         12.9204, 13.0931]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 44 was 94.7%\n",
      "current params: tensor([12.9204, 13.0421, 12.9856, 13.0931], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.2\n",
      "SLow rates:  tensor([[13.0844, 13.2060, 13.1493, 13.2564,  0.1000,  0.1000,  0.1000, 13.0844,\n",
      "         13.0844, 13.0844,  0.1000,  0.1000, 13.2060, 13.2060, 13.2060,  0.1000,\n",
      "          0.1000, 13.2060, 13.2060,  0.1000, 13.1493, 13.1493, 13.1493,  0.1000,\n",
      "          0.1000, 13.1493, 13.1493,  0.1000, 13.1493,  0.1000, 13.1493, 13.2564,\n",
      "         13.2564, 13.2564,  0.1000,  0.1000, 13.2564, 13.2564,  0.1000, 13.2564,\n",
      "          0.1000, 13.2564, 13.2060, 13.2564, 13.2564, 13.2564, 13.1493, 13.2564,\n",
      "         13.2564, 13.2564, 13.2060, 13.2564, 13.2564, 13.2564, 13.2060, 13.1493,\n",
      "         13.2060, 13.2060, 13.2060,  0.1000, 13.2060, 13.1493,  0.1000, 13.1493,\n",
      "         13.2564,  0.1000, 13.2564, 13.2564, 13.2564, 13.2060, 13.2060,  0.1000,\n",
      "         13.2564,  0.1000, 13.0844, 13.0844, 13.2060, 13.2564, 13.2564,  0.1000,\n",
      "          0.1000, 13.0844, 13.2060, 13.2564,  0.1000, 13.2060, 13.2564,  0.1000,\n",
      "         13.0844, 13.2564]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 45 was 94.7%\n",
      "current params: tensor([13.0844, 13.2060, 13.1493, 13.2564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.2\n",
      "SLow rates:  tensor([[13.2470, 13.3685, 13.3117, 13.4184,  0.1000,  0.1000,  0.1000, 13.2470,\n",
      "         13.2470, 13.2470,  0.1000,  0.1000, 13.3685, 13.3685, 13.3685,  0.1000,\n",
      "          0.1000, 13.3685, 13.3685,  0.1000, 13.3117, 13.3117, 13.3117,  0.1000,\n",
      "          0.1000, 13.3117, 13.3117,  0.1000, 13.3117,  0.1000, 13.3117, 13.4184,\n",
      "         13.4184, 13.4184,  0.1000,  0.1000, 13.4184, 13.4184,  0.1000, 13.4184,\n",
      "          0.1000, 13.4184, 13.3685, 13.4184, 13.4184, 13.4184, 13.3117, 13.4184,\n",
      "         13.4184, 13.4184, 13.3685, 13.4184, 13.4184, 13.4184, 13.3685, 13.3117,\n",
      "         13.3685, 13.3685, 13.3685,  0.1000, 13.3685, 13.3117,  0.1000, 13.3117,\n",
      "         13.4184,  0.1000, 13.4184, 13.4184, 13.4184, 13.3685, 13.3685,  0.1000,\n",
      "         13.4184,  0.1000, 13.2470, 13.2470, 13.3685, 13.4184, 13.4184,  0.1000,\n",
      "          0.1000, 13.2470, 13.3685, 13.4184,  0.1000, 13.3685, 13.4184,  0.1000,\n",
      "         13.2470, 13.4184]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 46 was 94.8%\n",
      "current params: tensor([13.2470, 13.3685, 13.3117, 13.4184], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.2\n",
      "SLow rates:  tensor([[13.4083, 13.5296, 13.4726, 13.5790,  0.1000,  0.1000,  0.1000, 13.4083,\n",
      "         13.4083, 13.4083,  0.1000,  0.1000, 13.5296, 13.5296, 13.5296,  0.1000,\n",
      "          0.1000, 13.5296, 13.5296,  0.1000, 13.4726, 13.4726, 13.4726,  0.1000,\n",
      "          0.1000, 13.4726, 13.4726,  0.1000, 13.4726,  0.1000, 13.4726, 13.5790,\n",
      "         13.5790, 13.5790,  0.1000,  0.1000, 13.5790, 13.5790,  0.1000, 13.5790,\n",
      "          0.1000, 13.5790, 13.5296, 13.5790, 13.5790, 13.5790, 13.4726, 13.5790,\n",
      "         13.5790, 13.5790, 13.5296, 13.5790, 13.5790, 13.5790, 13.5296, 13.4726,\n",
      "         13.5296, 13.5296, 13.5296,  0.1000, 13.5296, 13.4726,  0.1000, 13.4726,\n",
      "         13.5790,  0.1000, 13.5790, 13.5790, 13.5790, 13.5296, 13.5296,  0.1000,\n",
      "         13.5790,  0.1000, 13.4083, 13.4083, 13.5296, 13.5790, 13.5790,  0.1000,\n",
      "          0.1000, 13.4083, 13.5296, 13.5790,  0.1000, 13.5296, 13.5790,  0.1000,\n",
      "         13.4083, 13.5790]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 47 was 94.9%\n",
      "current params: tensor([13.4083, 13.5296, 13.4726, 13.5790], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.3\n",
      "SLow rates:  tensor([[13.5683, 13.6894, 13.6323, 13.7383,  0.1000,  0.1000,  0.1000, 13.5683,\n",
      "         13.5683, 13.5683,  0.1000,  0.1000, 13.6894, 13.6894, 13.6894,  0.1000,\n",
      "          0.1000, 13.6894, 13.6894,  0.1000, 13.6323, 13.6323, 13.6323,  0.1000,\n",
      "          0.1000, 13.6323, 13.6323,  0.1000, 13.6323,  0.1000, 13.6323, 13.7383,\n",
      "         13.7383, 13.7383,  0.1000,  0.1000, 13.7383, 13.7383,  0.1000, 13.7383,\n",
      "          0.1000, 13.7383, 13.6894, 13.7383, 13.7383, 13.7383, 13.6323, 13.7383,\n",
      "         13.7383, 13.7383, 13.6894, 13.7383, 13.7383, 13.7383, 13.6894, 13.6323,\n",
      "         13.6894, 13.6894, 13.6894,  0.1000, 13.6894, 13.6323,  0.1000, 13.6323,\n",
      "         13.7383,  0.1000, 13.7383, 13.7383, 13.7383, 13.6894, 13.6894,  0.1000,\n",
      "         13.7383,  0.1000, 13.5683, 13.5683, 13.6894, 13.7383, 13.7383,  0.1000,\n",
      "          0.1000, 13.5683, 13.6894, 13.7383,  0.1000, 13.6894, 13.7383,  0.1000,\n",
      "         13.5683, 13.7383]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 48 was 94.9%\n",
      "current params: tensor([13.5683, 13.6894, 13.6323, 13.7383], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.3\n",
      "SLow rates:  tensor([[13.7270, 13.8480, 13.7908, 13.8965,  0.1000,  0.1000,  0.1000, 13.7270,\n",
      "         13.7270, 13.7270,  0.1000,  0.1000, 13.8480, 13.8480, 13.8480,  0.1000,\n",
      "          0.1000, 13.8480, 13.8480,  0.1000, 13.7908, 13.7908, 13.7908,  0.1000,\n",
      "          0.1000, 13.7908, 13.7908,  0.1000, 13.7908,  0.1000, 13.7908, 13.8965,\n",
      "         13.8965, 13.8965,  0.1000,  0.1000, 13.8965, 13.8965,  0.1000, 13.8965,\n",
      "          0.1000, 13.8965, 13.8480, 13.8965, 13.8965, 13.8965, 13.7908, 13.8965,\n",
      "         13.8965, 13.8965, 13.8480, 13.8965, 13.8965, 13.8965, 13.8480, 13.7908,\n",
      "         13.8480, 13.8480, 13.8480,  0.1000, 13.8480, 13.7908,  0.1000, 13.7908,\n",
      "         13.8965,  0.1000, 13.8965, 13.8965, 13.8965, 13.8480, 13.8480,  0.1000,\n",
      "         13.8965,  0.1000, 13.7270, 13.7270, 13.8480, 13.8965, 13.8965,  0.1000,\n",
      "          0.1000, 13.7270, 13.8480, 13.8965,  0.1000, 13.8480, 13.8965,  0.1000,\n",
      "         13.7270, 13.8965]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 49 was 95.0%\n",
      "current params: tensor([13.7270, 13.8480, 13.7908, 13.8965], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.3\n",
      "SLow rates:  tensor([[13.8846, 14.0054, 13.9481, 14.0534,  0.1000,  0.1000,  0.1000, 13.8846,\n",
      "         13.8846, 13.8846,  0.1000,  0.1000, 14.0054, 14.0054, 14.0054,  0.1000,\n",
      "          0.1000, 14.0054, 14.0054,  0.1000, 13.9481, 13.9481, 13.9481,  0.1000,\n",
      "          0.1000, 13.9481, 13.9481,  0.1000, 13.9481,  0.1000, 13.9481, 14.0534,\n",
      "         14.0534, 14.0534,  0.1000,  0.1000, 14.0534, 14.0534,  0.1000, 14.0534,\n",
      "          0.1000, 14.0534, 14.0054, 14.0534, 14.0534, 14.0534, 13.9481, 14.0534,\n",
      "         14.0534, 14.0534, 14.0054, 14.0534, 14.0534, 14.0534, 14.0054, 13.9481,\n",
      "         14.0054, 14.0054, 14.0054,  0.1000, 14.0054, 13.9481,  0.1000, 13.9481,\n",
      "         14.0534,  0.1000, 14.0534, 14.0534, 14.0534, 14.0054, 14.0054,  0.1000,\n",
      "         14.0534,  0.1000, 13.8846, 13.8846, 14.0054, 14.0534, 14.0534,  0.1000,\n",
      "          0.1000, 13.8846, 14.0054, 14.0534,  0.1000, 14.0054, 14.0534,  0.1000,\n",
      "         13.8846, 14.0534]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1892, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 50 was 95.0%\n",
      "current params: tensor([13.8846, 14.0054, 13.9481, 14.0534], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.3\n",
      "SLow rates:  tensor([[14.0410, 14.1616, 14.1042, 14.2092,  0.1000,  0.1000,  0.1000, 14.0410,\n",
      "         14.0410, 14.0410,  0.1000,  0.1000, 14.1616, 14.1616, 14.1616,  0.1000,\n",
      "          0.1000, 14.1616, 14.1616,  0.1000, 14.1042, 14.1042, 14.1042,  0.1000,\n",
      "          0.1000, 14.1042, 14.1042,  0.1000, 14.1042,  0.1000, 14.1042, 14.2092,\n",
      "         14.2092, 14.2092,  0.1000,  0.1000, 14.2092, 14.2092,  0.1000, 14.2092,\n",
      "          0.1000, 14.2092, 14.1616, 14.2092, 14.2092, 14.2092, 14.1042, 14.2092,\n",
      "         14.2092, 14.2092, 14.1616, 14.2092, 14.2092, 14.2092, 14.1616, 14.1042,\n",
      "         14.1616, 14.1616, 14.1616,  0.1000, 14.1616, 14.1042,  0.1000, 14.1042,\n",
      "         14.2092,  0.1000, 14.2092, 14.2092, 14.2092, 14.1616, 14.1616,  0.1000,\n",
      "         14.2092,  0.1000, 14.0410, 14.0410, 14.1616, 14.2092, 14.2092,  0.1000,\n",
      "          0.1000, 14.0410, 14.1616, 14.2092,  0.1000, 14.1616, 14.2092,  0.1000,\n",
      "         14.0410, 14.2092]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 51 was 95.1%\n",
      "current params: tensor([14.0410, 14.1616, 14.1042, 14.2092], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.3\n",
      "SLow rates:  tensor([[14.1962, 14.3167, 14.2592, 14.3639,  0.1000,  0.1000,  0.1000, 14.1962,\n",
      "         14.1962, 14.1962,  0.1000,  0.1000, 14.3167, 14.3167, 14.3167,  0.1000,\n",
      "          0.1000, 14.3167, 14.3167,  0.1000, 14.2592, 14.2592, 14.2592,  0.1000,\n",
      "          0.1000, 14.2592, 14.2592,  0.1000, 14.2592,  0.1000, 14.2592, 14.3639,\n",
      "         14.3639, 14.3639,  0.1000,  0.1000, 14.3639, 14.3639,  0.1000, 14.3639,\n",
      "          0.1000, 14.3639, 14.3167, 14.3639, 14.3639, 14.3639, 14.2592, 14.3639,\n",
      "         14.3639, 14.3639, 14.3167, 14.3639, 14.3639, 14.3639, 14.3167, 14.2592,\n",
      "         14.3167, 14.3167, 14.3167,  0.1000, 14.3167, 14.2592,  0.1000, 14.2592,\n",
      "         14.3639,  0.1000, 14.3639, 14.3639, 14.3639, 14.3167, 14.3167,  0.1000,\n",
      "         14.3639,  0.1000, 14.1962, 14.1962, 14.3167, 14.3639, 14.3639,  0.1000,\n",
      "          0.1000, 14.1962, 14.3167, 14.3639,  0.1000, 14.3167, 14.3639,  0.1000,\n",
      "         14.1962, 14.3639]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1843, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 52 was 95.1%\n",
      "current params: tensor([14.1962, 14.3167, 14.2592, 14.3639], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.4\n",
      "SLow rates:  tensor([[14.3504, 14.4707, 14.4131, 14.5174,  0.1000,  0.1000,  0.1000, 14.3504,\n",
      "         14.3504, 14.3504,  0.1000,  0.1000, 14.4707, 14.4707, 14.4707,  0.1000,\n",
      "          0.1000, 14.4707, 14.4707,  0.1000, 14.4131, 14.4131, 14.4131,  0.1000,\n",
      "          0.1000, 14.4131, 14.4131,  0.1000, 14.4131,  0.1000, 14.4131, 14.5174,\n",
      "         14.5174, 14.5174,  0.1000,  0.1000, 14.5174, 14.5174,  0.1000, 14.5174,\n",
      "          0.1000, 14.5174, 14.4707, 14.5174, 14.5174, 14.5174, 14.4131, 14.5174,\n",
      "         14.5174, 14.5174, 14.4707, 14.5174, 14.5174, 14.5174, 14.4707, 14.4131,\n",
      "         14.4707, 14.4707, 14.4707,  0.1000, 14.4707, 14.4131,  0.1000, 14.4131,\n",
      "         14.5174,  0.1000, 14.5174, 14.5174, 14.5174, 14.4707, 14.4707,  0.1000,\n",
      "         14.5174,  0.1000, 14.3504, 14.3504, 14.4707, 14.5174, 14.5174,  0.1000,\n",
      "          0.1000, 14.3504, 14.4707, 14.5174,  0.1000, 14.4707, 14.5174,  0.1000,\n",
      "         14.3504, 14.5174]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1839, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 53 was 95.2%\n",
      "current params: tensor([14.3504, 14.4707, 14.4131, 14.5174], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.4\n",
      "SLow rates:  tensor([[14.5035, 14.6236, 14.5659, 14.6700,  0.1000,  0.1000,  0.1000, 14.5035,\n",
      "         14.5035, 14.5035,  0.1000,  0.1000, 14.6236, 14.6236, 14.6236,  0.1000,\n",
      "          0.1000, 14.6236, 14.6236,  0.1000, 14.5659, 14.5659, 14.5659,  0.1000,\n",
      "          0.1000, 14.5659, 14.5659,  0.1000, 14.5659,  0.1000, 14.5659, 14.6700,\n",
      "         14.6700, 14.6700,  0.1000,  0.1000, 14.6700, 14.6700,  0.1000, 14.6700,\n",
      "          0.1000, 14.6700, 14.6236, 14.6700, 14.6700, 14.6700, 14.5659, 14.6700,\n",
      "         14.6700, 14.6700, 14.6236, 14.6700, 14.6700, 14.6700, 14.6236, 14.5659,\n",
      "         14.6236, 14.6236, 14.6236,  0.1000, 14.6236, 14.5659,  0.1000, 14.5659,\n",
      "         14.6700,  0.1000, 14.6700, 14.6700, 14.6700, 14.6236, 14.6236,  0.1000,\n",
      "         14.6700,  0.1000, 14.5035, 14.5035, 14.6236, 14.6700, 14.6700,  0.1000,\n",
      "          0.1000, 14.5035, 14.6236, 14.6700,  0.1000, 14.6236, 14.6700,  0.1000,\n",
      "         14.5035, 14.6700]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 54 was 95.2%\n",
      "current params: tensor([14.5035, 14.6236, 14.5659, 14.6700], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.4\n",
      "SLow rates:  tensor([[14.6556, 14.7755, 14.7178, 14.8215,  0.1000,  0.1000,  0.1000, 14.6556,\n",
      "         14.6556, 14.6556,  0.1000,  0.1000, 14.7755, 14.7755, 14.7755,  0.1000,\n",
      "          0.1000, 14.7755, 14.7755,  0.1000, 14.7178, 14.7178, 14.7178,  0.1000,\n",
      "          0.1000, 14.7178, 14.7178,  0.1000, 14.7178,  0.1000, 14.7178, 14.8215,\n",
      "         14.8215, 14.8215,  0.1000,  0.1000, 14.8215, 14.8215,  0.1000, 14.8215,\n",
      "          0.1000, 14.8215, 14.7755, 14.8215, 14.8215, 14.8215, 14.7178, 14.8215,\n",
      "         14.8215, 14.8215, 14.7755, 14.8215, 14.8215, 14.8215, 14.7755, 14.7178,\n",
      "         14.7755, 14.7755, 14.7755,  0.1000, 14.7755, 14.7178,  0.1000, 14.7178,\n",
      "         14.8215,  0.1000, 14.8215, 14.8215, 14.8215, 14.7755, 14.7755,  0.1000,\n",
      "         14.8215,  0.1000, 14.6556, 14.6556, 14.7755, 14.8215, 14.8215,  0.1000,\n",
      "          0.1000, 14.6556, 14.7755, 14.8215,  0.1000, 14.7755, 14.8215,  0.1000,\n",
      "         14.6556, 14.8215]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 55 was 95.3%\n",
      "current params: tensor([14.6556, 14.7755, 14.7178, 14.8215], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.4\n",
      "SLow rates:  tensor([[14.8067, 14.9264, 14.8686, 14.9720,  0.1000,  0.1000,  0.1000, 14.8067,\n",
      "         14.8067, 14.8067,  0.1000,  0.1000, 14.9264, 14.9264, 14.9264,  0.1000,\n",
      "          0.1000, 14.9264, 14.9264,  0.1000, 14.8686, 14.8686, 14.8686,  0.1000,\n",
      "          0.1000, 14.8686, 14.8686,  0.1000, 14.8686,  0.1000, 14.8686, 14.9720,\n",
      "         14.9720, 14.9720,  0.1000,  0.1000, 14.9720, 14.9720,  0.1000, 14.9720,\n",
      "          0.1000, 14.9720, 14.9264, 14.9720, 14.9720, 14.9720, 14.8686, 14.9720,\n",
      "         14.9720, 14.9720, 14.9264, 14.9720, 14.9720, 14.9720, 14.9264, 14.8686,\n",
      "         14.9264, 14.9264, 14.9264,  0.1000, 14.9264, 14.8686,  0.1000, 14.8686,\n",
      "         14.9720,  0.1000, 14.9720, 14.9720, 14.9720, 14.9264, 14.9264,  0.1000,\n",
      "         14.9720,  0.1000, 14.8067, 14.8067, 14.9264, 14.9720, 14.9720,  0.1000,\n",
      "          0.1000, 14.8067, 14.9264, 14.9720,  0.1000, 14.9264, 14.9720,  0.1000,\n",
      "         14.8067, 14.9720]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 56 was 95.3%\n",
      "current params: tensor([14.8067, 14.9264, 14.8686, 14.9720], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.4\n",
      "SLow rates:  tensor([[14.9568, 15.0764, 15.0185, 15.1216,  0.1000,  0.1000,  0.1000, 14.9568,\n",
      "         14.9568, 14.9568,  0.1000,  0.1000, 15.0764, 15.0764, 15.0764,  0.1000,\n",
      "          0.1000, 15.0764, 15.0764,  0.1000, 15.0185, 15.0185, 15.0185,  0.1000,\n",
      "          0.1000, 15.0185, 15.0185,  0.1000, 15.0185,  0.1000, 15.0185, 15.1216,\n",
      "         15.1216, 15.1216,  0.1000,  0.1000, 15.1216, 15.1216,  0.1000, 15.1216,\n",
      "          0.1000, 15.1216, 15.0764, 15.1216, 15.1216, 15.1216, 15.0185, 15.1216,\n",
      "         15.1216, 15.1216, 15.0764, 15.1216, 15.1216, 15.1216, 15.0764, 15.0185,\n",
      "         15.0764, 15.0764, 15.0764,  0.1000, 15.0764, 15.0185,  0.1000, 15.0185,\n",
      "         15.1216,  0.1000, 15.1216, 15.1216, 15.1216, 15.0764, 15.0764,  0.1000,\n",
      "         15.1216,  0.1000, 14.9568, 14.9568, 15.0764, 15.1216, 15.1216,  0.1000,\n",
      "          0.1000, 14.9568, 15.0764, 15.1216,  0.1000, 15.0764, 15.1216,  0.1000,\n",
      "         14.9568, 15.1216]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 57 was 95.3%\n",
      "current params: tensor([14.9568, 15.0764, 15.0185, 15.1216], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.4\n",
      "SLow rates:  tensor([[15.1062, 15.2253, 15.1674, 15.2703,  0.1000,  0.1000,  0.1000, 15.1062,\n",
      "         15.1062, 15.1062,  0.1000,  0.1000, 15.2253, 15.2253, 15.2253,  0.1000,\n",
      "          0.1000, 15.2253, 15.2253,  0.1000, 15.1674, 15.1674, 15.1674,  0.1000,\n",
      "          0.1000, 15.1674, 15.1674,  0.1000, 15.1674,  0.1000, 15.1674, 15.2703,\n",
      "         15.2703, 15.2703,  0.1000,  0.1000, 15.2703, 15.2703,  0.1000, 15.2703,\n",
      "          0.1000, 15.2703, 15.2253, 15.2703, 15.2703, 15.2703, 15.1674, 15.2703,\n",
      "         15.2703, 15.2703, 15.2253, 15.2703, 15.2703, 15.2703, 15.2253, 15.1674,\n",
      "         15.2253, 15.2253, 15.2253,  0.1000, 15.2253, 15.1674,  0.1000, 15.1674,\n",
      "         15.2703,  0.1000, 15.2703, 15.2703, 15.2703, 15.2253, 15.2253,  0.1000,\n",
      "         15.2703,  0.1000, 15.1062, 15.1062, 15.2253, 15.2703, 15.2703,  0.1000,\n",
      "          0.1000, 15.1062, 15.2253, 15.2703,  0.1000, 15.2253, 15.2703,  0.1000,\n",
      "         15.1062, 15.2703]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 58 was 95.4%\n",
      "current params: tensor([15.1062, 15.2253, 15.1674, 15.2703], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.5\n",
      "SLow rates:  tensor([[15.2545, 15.3735, 15.3155, 15.4181,  0.1000,  0.1000,  0.1000, 15.2545,\n",
      "         15.2545, 15.2545,  0.1000,  0.1000, 15.3735, 15.3735, 15.3735,  0.1000,\n",
      "          0.1000, 15.3735, 15.3735,  0.1000, 15.3155, 15.3155, 15.3155,  0.1000,\n",
      "          0.1000, 15.3155, 15.3155,  0.1000, 15.3155,  0.1000, 15.3155, 15.4181,\n",
      "         15.4181, 15.4181,  0.1000,  0.1000, 15.4181, 15.4181,  0.1000, 15.4181,\n",
      "          0.1000, 15.4181, 15.3735, 15.4181, 15.4181, 15.4181, 15.3155, 15.4181,\n",
      "         15.4181, 15.4181, 15.3735, 15.4181, 15.4181, 15.4181, 15.3735, 15.3155,\n",
      "         15.3735, 15.3735, 15.3735,  0.1000, 15.3735, 15.3155,  0.1000, 15.3155,\n",
      "         15.4181,  0.1000, 15.4181, 15.4181, 15.4181, 15.3735, 15.3735,  0.1000,\n",
      "         15.4181,  0.1000, 15.2545, 15.2545, 15.3735, 15.4181, 15.4181,  0.1000,\n",
      "          0.1000, 15.2545, 15.3735, 15.4181,  0.1000, 15.3735, 15.4181,  0.1000,\n",
      "         15.2545, 15.4181]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 59 was 95.4%\n",
      "current params: tensor([15.2545, 15.3735, 15.3155, 15.4181], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.5\n",
      "SLow rates:  tensor([[15.4019, 15.5207, 15.4626, 15.5649,  0.1000,  0.1000,  0.1000, 15.4019,\n",
      "         15.4019, 15.4019,  0.1000,  0.1000, 15.5207, 15.5207, 15.5207,  0.1000,\n",
      "          0.1000, 15.5207, 15.5207,  0.1000, 15.4626, 15.4626, 15.4626,  0.1000,\n",
      "          0.1000, 15.4626, 15.4626,  0.1000, 15.4626,  0.1000, 15.4626, 15.5649,\n",
      "         15.5649, 15.5649,  0.1000,  0.1000, 15.5649, 15.5649,  0.1000, 15.5649,\n",
      "          0.1000, 15.5649, 15.5207, 15.5649, 15.5649, 15.5649, 15.4626, 15.5649,\n",
      "         15.5649, 15.5649, 15.5207, 15.5649, 15.5649, 15.5649, 15.5207, 15.4626,\n",
      "         15.5207, 15.5207, 15.5207,  0.1000, 15.5207, 15.4626,  0.1000, 15.4626,\n",
      "         15.5649,  0.1000, 15.5649, 15.5649, 15.5649, 15.5207, 15.5207,  0.1000,\n",
      "         15.5649,  0.1000, 15.4019, 15.4019, 15.5207, 15.5649, 15.5649,  0.1000,\n",
      "          0.1000, 15.4019, 15.5207, 15.5649,  0.1000, 15.5207, 15.5649,  0.1000,\n",
      "         15.4019, 15.5649]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 60 was 95.5%\n",
      "current params: tensor([15.4019, 15.5207, 15.4626, 15.5649], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.5\n",
      "SLow rates:  tensor([[15.5484, 15.6670, 15.6089, 15.7109,  0.1000,  0.1000,  0.1000, 15.5484,\n",
      "         15.5484, 15.5484,  0.1000,  0.1000, 15.6670, 15.6670, 15.6670,  0.1000,\n",
      "          0.1000, 15.6670, 15.6670,  0.1000, 15.6089, 15.6089, 15.6089,  0.1000,\n",
      "          0.1000, 15.6089, 15.6089,  0.1000, 15.6089,  0.1000, 15.6089, 15.7109,\n",
      "         15.7109, 15.7109,  0.1000,  0.1000, 15.7109, 15.7109,  0.1000, 15.7109,\n",
      "          0.1000, 15.7109, 15.6670, 15.7109, 15.7109, 15.7109, 15.6089, 15.7109,\n",
      "         15.7109, 15.7109, 15.6670, 15.7109, 15.7109, 15.7109, 15.6670, 15.6089,\n",
      "         15.6670, 15.6670, 15.6670,  0.1000, 15.6670, 15.6089,  0.1000, 15.6089,\n",
      "         15.7109,  0.1000, 15.7109, 15.7109, 15.7109, 15.6670, 15.6670,  0.1000,\n",
      "         15.7109,  0.1000, 15.5484, 15.5484, 15.6670, 15.7109, 15.7109,  0.1000,\n",
      "          0.1000, 15.5484, 15.6670, 15.7109,  0.1000, 15.6670, 15.7109,  0.1000,\n",
      "         15.5484, 15.7109]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 61 was 95.5%\n",
      "current params: tensor([15.5484, 15.6670, 15.6089, 15.7109], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.5\n",
      "SLow rates:  tensor([[15.6941, 15.8126, 15.7544, 15.8561,  0.1000,  0.1000,  0.1000, 15.6941,\n",
      "         15.6941, 15.6941,  0.1000,  0.1000, 15.8126, 15.8126, 15.8126,  0.1000,\n",
      "          0.1000, 15.8126, 15.8126,  0.1000, 15.7544, 15.7544, 15.7544,  0.1000,\n",
      "          0.1000, 15.7544, 15.7544,  0.1000, 15.7544,  0.1000, 15.7544, 15.8561,\n",
      "         15.8561, 15.8561,  0.1000,  0.1000, 15.8561, 15.8561,  0.1000, 15.8561,\n",
      "          0.1000, 15.8561, 15.8126, 15.8561, 15.8561, 15.8561, 15.7544, 15.8561,\n",
      "         15.8561, 15.8561, 15.8126, 15.8561, 15.8561, 15.8561, 15.8126, 15.7544,\n",
      "         15.8126, 15.8126, 15.8126,  0.1000, 15.8126, 15.7544,  0.1000, 15.7544,\n",
      "         15.8561,  0.1000, 15.8561, 15.8561, 15.8561, 15.8126, 15.8126,  0.1000,\n",
      "         15.8561,  0.1000, 15.6941, 15.6941, 15.8126, 15.8561, 15.8561,  0.1000,\n",
      "          0.1000, 15.6941, 15.8126, 15.8561,  0.1000, 15.8126, 15.8561,  0.1000,\n",
      "         15.6941, 15.8561]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 62 was 95.5%\n",
      "current params: tensor([15.6941, 15.8126, 15.7544, 15.8561], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.5\n",
      "SLow rates:  tensor([[15.8390, 15.9573, 15.8991, 16.0005,  0.1000,  0.1000,  0.1000, 15.8390,\n",
      "         15.8390, 15.8390,  0.1000,  0.1000, 15.9573, 15.9573, 15.9573,  0.1000,\n",
      "          0.1000, 15.9573, 15.9573,  0.1000, 15.8991, 15.8991, 15.8991,  0.1000,\n",
      "          0.1000, 15.8991, 15.8991,  0.1000, 15.8991,  0.1000, 15.8991, 16.0005,\n",
      "         16.0005, 16.0005,  0.1000,  0.1000, 16.0005, 16.0005,  0.1000, 16.0005,\n",
      "          0.1000, 16.0005, 15.9573, 16.0005, 16.0005, 16.0005, 15.8991, 16.0005,\n",
      "         16.0005, 16.0005, 15.9573, 16.0005, 16.0005, 16.0005, 15.9573, 15.8991,\n",
      "         15.9573, 15.9573, 15.9573,  0.1000, 15.9573, 15.8991,  0.1000, 15.8991,\n",
      "         16.0005,  0.1000, 16.0005, 16.0005, 16.0005, 15.9573, 15.9573,  0.1000,\n",
      "         16.0005,  0.1000, 15.8390, 15.8390, 15.9573, 16.0005, 16.0005,  0.1000,\n",
      "          0.1000, 15.8390, 15.9573, 16.0005,  0.1000, 15.9573, 16.0005,  0.1000,\n",
      "         15.8390, 16.0005]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0939, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 63 was 95.6%\n",
      "current params: tensor([15.8390, 15.9573, 15.8991, 16.0005], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.6\n",
      "SLow rates:  tensor([[15.9830, 16.1012, 16.0429, 16.1441,  0.1000,  0.1000,  0.1000, 15.9830,\n",
      "         15.9830, 15.9830,  0.1000,  0.1000, 16.1012, 16.1012, 16.1012,  0.1000,\n",
      "          0.1000, 16.1012, 16.1012,  0.1000, 16.0429, 16.0429, 16.0429,  0.1000,\n",
      "          0.1000, 16.0429, 16.0429,  0.1000, 16.0429,  0.1000, 16.0429, 16.1441,\n",
      "         16.1441, 16.1441,  0.1000,  0.1000, 16.1441, 16.1441,  0.1000, 16.1441,\n",
      "          0.1000, 16.1441, 16.1012, 16.1441, 16.1441, 16.1441, 16.0429, 16.1441,\n",
      "         16.1441, 16.1441, 16.1012, 16.1441, 16.1441, 16.1441, 16.1012, 16.0429,\n",
      "         16.1012, 16.1012, 16.1012,  0.1000, 16.1012, 16.0429,  0.1000, 16.0429,\n",
      "         16.1441,  0.1000, 16.1441, 16.1441, 16.1441, 16.1012, 16.1012,  0.1000,\n",
      "         16.1441,  0.1000, 15.9830, 15.9830, 16.1012, 16.1441, 16.1441,  0.1000,\n",
      "          0.1000, 15.9830, 16.1012, 16.1441,  0.1000, 16.1012, 16.1441,  0.1000,\n",
      "         15.9830, 16.1441]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 64 was 95.6%\n",
      "current params: tensor([15.9830, 16.1012, 16.0429, 16.1441], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.6\n",
      "SLow rates:  tensor([[16.1264, 16.2443, 16.1860, 16.2869,  0.1000,  0.1000,  0.1000, 16.1264,\n",
      "         16.1264, 16.1264,  0.1000,  0.1000, 16.2443, 16.2443, 16.2443,  0.1000,\n",
      "          0.1000, 16.2443, 16.2443,  0.1000, 16.1860, 16.1860, 16.1860,  0.1000,\n",
      "          0.1000, 16.1860, 16.1860,  0.1000, 16.1860,  0.1000, 16.1860, 16.2869,\n",
      "         16.2869, 16.2869,  0.1000,  0.1000, 16.2869, 16.2869,  0.1000, 16.2869,\n",
      "          0.1000, 16.2869, 16.2443, 16.2869, 16.2869, 16.2869, 16.1860, 16.2869,\n",
      "         16.2869, 16.2869, 16.2443, 16.2869, 16.2869, 16.2869, 16.2443, 16.1860,\n",
      "         16.2443, 16.2443, 16.2443,  0.1000, 16.2443, 16.1860,  0.1000, 16.1860,\n",
      "         16.2869,  0.1000, 16.2869, 16.2869, 16.2869, 16.2443, 16.2443,  0.1000,\n",
      "         16.2869,  0.1000, 16.1264, 16.1264, 16.2443, 16.2869, 16.2869,  0.1000,\n",
      "          0.1000, 16.1264, 16.2443, 16.2869,  0.1000, 16.2443, 16.2869,  0.1000,\n",
      "         16.1264, 16.2869]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 65 was 95.6%\n",
      "current params: tensor([16.1264, 16.2443, 16.1860, 16.2869], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.6\n",
      "SLow rates:  tensor([[16.2689, 16.3867, 16.3284, 16.4289,  0.1000,  0.1000,  0.1000, 16.2689,\n",
      "         16.2689, 16.2689,  0.1000,  0.1000, 16.3867, 16.3867, 16.3867,  0.1000,\n",
      "          0.1000, 16.3867, 16.3867,  0.1000, 16.3284, 16.3284, 16.3284,  0.1000,\n",
      "          0.1000, 16.3284, 16.3284,  0.1000, 16.3284,  0.1000, 16.3284, 16.4289,\n",
      "         16.4289, 16.4289,  0.1000,  0.1000, 16.4289, 16.4289,  0.1000, 16.4289,\n",
      "          0.1000, 16.4289, 16.3867, 16.4289, 16.4289, 16.4289, 16.3284, 16.4289,\n",
      "         16.4289, 16.4289, 16.3867, 16.4289, 16.4289, 16.4289, 16.3867, 16.3284,\n",
      "         16.3867, 16.3867, 16.3867,  0.1000, 16.3867, 16.3284,  0.1000, 16.3284,\n",
      "         16.4289,  0.1000, 16.4289, 16.4289, 16.4289, 16.3867, 16.3867,  0.1000,\n",
      "         16.4289,  0.1000, 16.2689, 16.2689, 16.3867, 16.4289, 16.4289,  0.1000,\n",
      "          0.1000, 16.2689, 16.3867, 16.4289,  0.1000, 16.3867, 16.4289,  0.1000,\n",
      "         16.2689, 16.4289]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 66 was 95.7%\n",
      "current params: tensor([16.2689, 16.3867, 16.3284, 16.4289], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.6\n",
      "SLow rates:  tensor([[16.4107, 16.5283, 16.4700, 16.5703,  0.1000,  0.1000,  0.1000, 16.4107,\n",
      "         16.4107, 16.4107,  0.1000,  0.1000, 16.5283, 16.5283, 16.5283,  0.1000,\n",
      "          0.1000, 16.5283, 16.5283,  0.1000, 16.4700, 16.4700, 16.4700,  0.1000,\n",
      "          0.1000, 16.4700, 16.4700,  0.1000, 16.4700,  0.1000, 16.4700, 16.5703,\n",
      "         16.5703, 16.5703,  0.1000,  0.1000, 16.5703, 16.5703,  0.1000, 16.5703,\n",
      "          0.1000, 16.5703, 16.5283, 16.5703, 16.5703, 16.5703, 16.4700, 16.5703,\n",
      "         16.5703, 16.5703, 16.5283, 16.5703, 16.5703, 16.5703, 16.5283, 16.4700,\n",
      "         16.5283, 16.5283, 16.5283,  0.1000, 16.5283, 16.4700,  0.1000, 16.4700,\n",
      "         16.5703,  0.1000, 16.5703, 16.5703, 16.5703, 16.5283, 16.5283,  0.1000,\n",
      "         16.5703,  0.1000, 16.4107, 16.4107, 16.5283, 16.5703, 16.5703,  0.1000,\n",
      "          0.1000, 16.4107, 16.5283, 16.5703,  0.1000, 16.5283, 16.5703,  0.1000,\n",
      "         16.4107, 16.5703]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 67 was 95.7%\n",
      "current params: tensor([16.4107, 16.5283, 16.4700, 16.5703], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.6\n",
      "SLow rates:  tensor([[16.5519, 16.6693, 16.6109, 16.7109,  0.1000,  0.1000,  0.1000, 16.5519,\n",
      "         16.5519, 16.5519,  0.1000,  0.1000, 16.6693, 16.6693, 16.6693,  0.1000,\n",
      "          0.1000, 16.6693, 16.6693,  0.1000, 16.6109, 16.6109, 16.6109,  0.1000,\n",
      "          0.1000, 16.6109, 16.6109,  0.1000, 16.6109,  0.1000, 16.6109, 16.7109,\n",
      "         16.7109, 16.7109,  0.1000,  0.1000, 16.7109, 16.7109,  0.1000, 16.7109,\n",
      "          0.1000, 16.7109, 16.6693, 16.7109, 16.7109, 16.7109, 16.6109, 16.7109,\n",
      "         16.7109, 16.7109, 16.6693, 16.7109, 16.7109, 16.7109, 16.6693, 16.6109,\n",
      "         16.6693, 16.6693, 16.6693,  0.1000, 16.6693, 16.6109,  0.1000, 16.6109,\n",
      "         16.7109,  0.1000, 16.7109, 16.7109, 16.7109, 16.6693, 16.6693,  0.1000,\n",
      "         16.7109,  0.1000, 16.5519, 16.5519, 16.6693, 16.7109, 16.7109,  0.1000,\n",
      "          0.1000, 16.5519, 16.6693, 16.7109,  0.1000, 16.6693, 16.7109,  0.1000,\n",
      "         16.5519, 16.7109]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 68 was 95.7%\n",
      "current params: tensor([16.5519, 16.6693, 16.6109, 16.7109], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.7\n",
      "SLow rates:  tensor([[16.6923, 16.8095, 16.7511, 16.8509,  0.1000,  0.1000,  0.1000, 16.6923,\n",
      "         16.6923, 16.6923,  0.1000,  0.1000, 16.8095, 16.8095, 16.8095,  0.1000,\n",
      "          0.1000, 16.8095, 16.8095,  0.1000, 16.7511, 16.7511, 16.7511,  0.1000,\n",
      "          0.1000, 16.7511, 16.7511,  0.1000, 16.7511,  0.1000, 16.7511, 16.8509,\n",
      "         16.8509, 16.8509,  0.1000,  0.1000, 16.8509, 16.8509,  0.1000, 16.8509,\n",
      "          0.1000, 16.8509, 16.8095, 16.8509, 16.8509, 16.8509, 16.7511, 16.8509,\n",
      "         16.8509, 16.8509, 16.8095, 16.8509, 16.8509, 16.8509, 16.8095, 16.7511,\n",
      "         16.8095, 16.8095, 16.8095,  0.1000, 16.8095, 16.7511,  0.1000, 16.7511,\n",
      "         16.8509,  0.1000, 16.8509, 16.8509, 16.8509, 16.8095, 16.8095,  0.1000,\n",
      "         16.8509,  0.1000, 16.6923, 16.6923, 16.8095, 16.8509, 16.8509,  0.1000,\n",
      "          0.1000, 16.6923, 16.8095, 16.8509,  0.1000, 16.8095, 16.8509,  0.1000,\n",
      "         16.6923, 16.8509]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 69 was 95.8%\n",
      "current params: tensor([16.6923, 16.8095, 16.7511, 16.8509], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.7\n",
      "SLow rates:  tensor([[16.8320, 16.9491, 16.8907, 16.9901,  0.1000,  0.1000,  0.1000, 16.8320,\n",
      "         16.8320, 16.8320,  0.1000,  0.1000, 16.9491, 16.9491, 16.9491,  0.1000,\n",
      "          0.1000, 16.9491, 16.9491,  0.1000, 16.8907, 16.8907, 16.8907,  0.1000,\n",
      "          0.1000, 16.8907, 16.8907,  0.1000, 16.8907,  0.1000, 16.8907, 16.9901,\n",
      "         16.9901, 16.9901,  0.1000,  0.1000, 16.9901, 16.9901,  0.1000, 16.9901,\n",
      "          0.1000, 16.9901, 16.9491, 16.9901, 16.9901, 16.9901, 16.8907, 16.9901,\n",
      "         16.9901, 16.9901, 16.9491, 16.9901, 16.9901, 16.9901, 16.9491, 16.8907,\n",
      "         16.9491, 16.9491, 16.9491,  0.1000, 16.9491, 16.8907,  0.1000, 16.8907,\n",
      "         16.9901,  0.1000, 16.9901, 16.9901, 16.9901, 16.9491, 16.9491,  0.1000,\n",
      "         16.9901,  0.1000, 16.8320, 16.8320, 16.9491, 16.9901, 16.9901,  0.1000,\n",
      "          0.1000, 16.8320, 16.9491, 16.9901,  0.1000, 16.9491, 16.9901,  0.1000,\n",
      "         16.8320, 16.9901]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 70 was 95.8%\n",
      "current params: tensor([16.8320, 16.9491, 16.8907, 16.9901], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.7\n",
      "SLow rates:  tensor([[16.9711, 17.0880, 17.0295, 17.1287,  0.1000,  0.1000,  0.1000, 16.9711,\n",
      "         16.9711, 16.9711,  0.1000,  0.1000, 17.0880, 17.0880, 17.0880,  0.1000,\n",
      "          0.1000, 17.0880, 17.0880,  0.1000, 17.0295, 17.0295, 17.0295,  0.1000,\n",
      "          0.1000, 17.0295, 17.0295,  0.1000, 17.0295,  0.1000, 17.0295, 17.1287,\n",
      "         17.1287, 17.1287,  0.1000,  0.1000, 17.1287, 17.1287,  0.1000, 17.1287,\n",
      "          0.1000, 17.1287, 17.0880, 17.1287, 17.1287, 17.1287, 17.0295, 17.1287,\n",
      "         17.1287, 17.1287, 17.0880, 17.1287, 17.1287, 17.1287, 17.0880, 17.0295,\n",
      "         17.0880, 17.0880, 17.0880,  0.1000, 17.0880, 17.0295,  0.1000, 17.0295,\n",
      "         17.1287,  0.1000, 17.1287, 17.1287, 17.1287, 17.0880, 17.0880,  0.1000,\n",
      "         17.1287,  0.1000, 16.9711, 16.9711, 17.0880, 17.1287, 17.1287,  0.1000,\n",
      "          0.1000, 16.9711, 17.0880, 17.1287,  0.1000, 17.0880, 17.1287,  0.1000,\n",
      "         16.9711, 17.1287]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 71 was 95.8%\n",
      "current params: tensor([16.9711, 17.0880, 17.0295, 17.1287], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.7\n",
      "SLow rates:  tensor([[17.1095, 17.2262, 17.1678, 17.2667,  0.1000,  0.1000,  0.1000, 17.1095,\n",
      "         17.1095, 17.1095,  0.1000,  0.1000, 17.2262, 17.2262, 17.2262,  0.1000,\n",
      "          0.1000, 17.2262, 17.2262,  0.1000, 17.1678, 17.1678, 17.1678,  0.1000,\n",
      "          0.1000, 17.1678, 17.1678,  0.1000, 17.1678,  0.1000, 17.1678, 17.2667,\n",
      "         17.2667, 17.2667,  0.1000,  0.1000, 17.2667, 17.2667,  0.1000, 17.2667,\n",
      "          0.1000, 17.2667, 17.2262, 17.2667, 17.2667, 17.2667, 17.1678, 17.2667,\n",
      "         17.2667, 17.2667, 17.2262, 17.2667, 17.2667, 17.2667, 17.2262, 17.1678,\n",
      "         17.2262, 17.2262, 17.2262,  0.1000, 17.2262, 17.1678,  0.1000, 17.1678,\n",
      "         17.2667,  0.1000, 17.2667, 17.2667, 17.2667, 17.2262, 17.2262,  0.1000,\n",
      "         17.2667,  0.1000, 17.1095, 17.1095, 17.2262, 17.2667, 17.2667,  0.1000,\n",
      "          0.1000, 17.1095, 17.2262, 17.2667,  0.1000, 17.2262, 17.2667,  0.1000,\n",
      "         17.1095, 17.2667]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 72 was 95.9%\n",
      "current params: tensor([17.1095, 17.2262, 17.1678, 17.2667], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.7\n",
      "SLow rates:  tensor([[17.2473, 17.3639, 17.3054, 17.4041,  0.1000,  0.1000,  0.1000, 17.2473,\n",
      "         17.2473, 17.2473,  0.1000,  0.1000, 17.3639, 17.3639, 17.3639,  0.1000,\n",
      "          0.1000, 17.3639, 17.3639,  0.1000, 17.3054, 17.3054, 17.3054,  0.1000,\n",
      "          0.1000, 17.3054, 17.3054,  0.1000, 17.3054,  0.1000, 17.3054, 17.4041,\n",
      "         17.4041, 17.4041,  0.1000,  0.1000, 17.4041, 17.4041,  0.1000, 17.4041,\n",
      "          0.1000, 17.4041, 17.3639, 17.4041, 17.4041, 17.4041, 17.3054, 17.4041,\n",
      "         17.4041, 17.4041, 17.3639, 17.4041, 17.4041, 17.4041, 17.3639, 17.3054,\n",
      "         17.3639, 17.3639, 17.3639,  0.1000, 17.3639, 17.3054,  0.1000, 17.3054,\n",
      "         17.4041,  0.1000, 17.4041, 17.4041, 17.4041, 17.3639, 17.3639,  0.1000,\n",
      "         17.4041,  0.1000, 17.2473, 17.2473, 17.3639, 17.4041, 17.4041,  0.1000,\n",
      "          0.1000, 17.2473, 17.3639, 17.4041,  0.1000, 17.3639, 17.4041,  0.1000,\n",
      "         17.2473, 17.4041]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 73 was 95.9%\n",
      "current params: tensor([17.2473, 17.3639, 17.3054, 17.4041], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.8\n",
      "SLow rates:  tensor([[17.3845, 17.5009, 17.4423, 17.5408,  0.1000,  0.1000,  0.1000, 17.3845,\n",
      "         17.3845, 17.3845,  0.1000,  0.1000, 17.5009, 17.5009, 17.5009,  0.1000,\n",
      "          0.1000, 17.5009, 17.5009,  0.1000, 17.4423, 17.4423, 17.4423,  0.1000,\n",
      "          0.1000, 17.4423, 17.4423,  0.1000, 17.4423,  0.1000, 17.4423, 17.5408,\n",
      "         17.5408, 17.5408,  0.1000,  0.1000, 17.5408, 17.5408,  0.1000, 17.5408,\n",
      "          0.1000, 17.5408, 17.5009, 17.5408, 17.5408, 17.5408, 17.4423, 17.5408,\n",
      "         17.5408, 17.5408, 17.5009, 17.5408, 17.5408, 17.5408, 17.5009, 17.4423,\n",
      "         17.5009, 17.5009, 17.5009,  0.1000, 17.5009, 17.4423,  0.1000, 17.4423,\n",
      "         17.5408,  0.1000, 17.5408, 17.5408, 17.5408, 17.5009, 17.5009,  0.1000,\n",
      "         17.5408,  0.1000, 17.3845, 17.3845, 17.5009, 17.5408, 17.5408,  0.1000,\n",
      "          0.1000, 17.3845, 17.5009, 17.5408,  0.1000, 17.5009, 17.5408,  0.1000,\n",
      "         17.3845, 17.5408]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 74 was 95.9%\n",
      "current params: tensor([17.3845, 17.5009, 17.4423, 17.5408], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.8\n",
      "SLow rates:  tensor([[17.5210, 17.6373, 17.5787, 17.6769,  0.1000,  0.1000,  0.1000, 17.5210,\n",
      "         17.5210, 17.5210,  0.1000,  0.1000, 17.6373, 17.6373, 17.6373,  0.1000,\n",
      "          0.1000, 17.6373, 17.6373,  0.1000, 17.5787, 17.5787, 17.5787,  0.1000,\n",
      "          0.1000, 17.5787, 17.5787,  0.1000, 17.5787,  0.1000, 17.5787, 17.6769,\n",
      "         17.6769, 17.6769,  0.1000,  0.1000, 17.6769, 17.6769,  0.1000, 17.6769,\n",
      "          0.1000, 17.6769, 17.6373, 17.6769, 17.6769, 17.6769, 17.5787, 17.6769,\n",
      "         17.6769, 17.6769, 17.6373, 17.6769, 17.6769, 17.6769, 17.6373, 17.5787,\n",
      "         17.6373, 17.6373, 17.6373,  0.1000, 17.6373, 17.5787,  0.1000, 17.5787,\n",
      "         17.6769,  0.1000, 17.6769, 17.6769, 17.6769, 17.6373, 17.6373,  0.1000,\n",
      "         17.6769,  0.1000, 17.5210, 17.5210, 17.6373, 17.6769, 17.6769,  0.1000,\n",
      "          0.1000, 17.5210, 17.6373, 17.6769,  0.1000, 17.6373, 17.6769,  0.1000,\n",
      "         17.5210, 17.6769]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 75 was 96.0%\n",
      "current params: tensor([17.5210, 17.6373, 17.5787, 17.6769], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.8\n",
      "SLow rates:  tensor([[17.6570, 17.7731, 17.7145, 17.8125,  0.1000,  0.1000,  0.1000, 17.6570,\n",
      "         17.6570, 17.6570,  0.1000,  0.1000, 17.7731, 17.7731, 17.7731,  0.1000,\n",
      "          0.1000, 17.7731, 17.7731,  0.1000, 17.7145, 17.7145, 17.7145,  0.1000,\n",
      "          0.1000, 17.7145, 17.7145,  0.1000, 17.7145,  0.1000, 17.7145, 17.8125,\n",
      "         17.8125, 17.8125,  0.1000,  0.1000, 17.8125, 17.8125,  0.1000, 17.8125,\n",
      "          0.1000, 17.8125, 17.7731, 17.8125, 17.8125, 17.8125, 17.7145, 17.8125,\n",
      "         17.8125, 17.8125, 17.7731, 17.8125, 17.8125, 17.8125, 17.7731, 17.7145,\n",
      "         17.7731, 17.7731, 17.7731,  0.1000, 17.7731, 17.7145,  0.1000, 17.7145,\n",
      "         17.8125,  0.1000, 17.8125, 17.8125, 17.8125, 17.7731, 17.7731,  0.1000,\n",
      "         17.8125,  0.1000, 17.6570, 17.6570, 17.7731, 17.8125, 17.8125,  0.1000,\n",
      "          0.1000, 17.6570, 17.7731, 17.8125,  0.1000, 17.7731, 17.8125,  0.1000,\n",
      "         17.6570, 17.8125]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 76 was 96.0%\n",
      "current params: tensor([17.6570, 17.7731, 17.7145, 17.8125], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.9\n",
      "SLow rates:  tensor([[17.7924, 17.9083, 17.8498, 17.9474,  0.1000,  0.1000,  0.1000, 17.7924,\n",
      "         17.7924, 17.7924,  0.1000,  0.1000, 17.9083, 17.9083, 17.9083,  0.1000,\n",
      "          0.1000, 17.9083, 17.9083,  0.1000, 17.8498, 17.8498, 17.8498,  0.1000,\n",
      "          0.1000, 17.8498, 17.8498,  0.1000, 17.8498,  0.1000, 17.8498, 17.9474,\n",
      "         17.9474, 17.9474,  0.1000,  0.1000, 17.9474, 17.9474,  0.1000, 17.9474,\n",
      "          0.1000, 17.9474, 17.9083, 17.9474, 17.9474, 17.9474, 17.8498, 17.9474,\n",
      "         17.9474, 17.9474, 17.9083, 17.9474, 17.9474, 17.9474, 17.9083, 17.8498,\n",
      "         17.9083, 17.9083, 17.9083,  0.1000, 17.9083, 17.8498,  0.1000, 17.8498,\n",
      "         17.9474,  0.1000, 17.9474, 17.9474, 17.9474, 17.9083, 17.9083,  0.1000,\n",
      "         17.9474,  0.1000, 17.7924, 17.7924, 17.9083, 17.9474, 17.9474,  0.1000,\n",
      "          0.1000, 17.7924, 17.9083, 17.9474,  0.1000, 17.9083, 17.9474,  0.1000,\n",
      "         17.7924, 17.9474]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 77 was 96.0%\n",
      "current params: tensor([17.7924, 17.9083, 17.8498, 17.9474], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.9\n",
      "SLow rates:  tensor([[17.9273, 18.0430, 17.9844, 18.0819,  0.1000,  0.1000,  0.1000, 17.9273,\n",
      "         17.9273, 17.9273,  0.1000,  0.1000, 18.0430, 18.0430, 18.0430,  0.1000,\n",
      "          0.1000, 18.0430, 18.0430,  0.1000, 17.9844, 17.9844, 17.9844,  0.1000,\n",
      "          0.1000, 17.9844, 17.9844,  0.1000, 17.9844,  0.1000, 17.9844, 18.0819,\n",
      "         18.0819, 18.0819,  0.1000,  0.1000, 18.0819, 18.0819,  0.1000, 18.0819,\n",
      "          0.1000, 18.0819, 18.0430, 18.0819, 18.0819, 18.0819, 17.9844, 18.0819,\n",
      "         18.0819, 18.0819, 18.0430, 18.0819, 18.0819, 18.0819, 18.0430, 17.9844,\n",
      "         18.0430, 18.0430, 18.0430,  0.1000, 18.0430, 17.9844,  0.1000, 17.9844,\n",
      "         18.0819,  0.1000, 18.0819, 18.0819, 18.0819, 18.0430, 18.0430,  0.1000,\n",
      "         18.0819,  0.1000, 17.9273, 17.9273, 18.0430, 18.0819, 18.0819,  0.1000,\n",
      "          0.1000, 17.9273, 18.0430, 18.0819,  0.1000, 18.0430, 18.0819,  0.1000,\n",
      "         17.9273, 18.0819]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 78 was 96.0%\n",
      "current params: tensor([17.9273, 18.0430, 17.9844, 18.0819], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.9\n",
      "SLow rates:  tensor([[18.0615, 18.1771, 18.1185, 18.2157,  0.1000,  0.1000,  0.1000, 18.0615,\n",
      "         18.0615, 18.0615,  0.1000,  0.1000, 18.1771, 18.1771, 18.1771,  0.1000,\n",
      "          0.1000, 18.1771, 18.1771,  0.1000, 18.1185, 18.1185, 18.1185,  0.1000,\n",
      "          0.1000, 18.1185, 18.1185,  0.1000, 18.1185,  0.1000, 18.1185, 18.2157,\n",
      "         18.2157, 18.2157,  0.1000,  0.1000, 18.2157, 18.2157,  0.1000, 18.2157,\n",
      "          0.1000, 18.2157, 18.1771, 18.2157, 18.2157, 18.2157, 18.1185, 18.2157,\n",
      "         18.2157, 18.2157, 18.1771, 18.2157, 18.2157, 18.2157, 18.1771, 18.1185,\n",
      "         18.1771, 18.1771, 18.1771,  0.1000, 18.1771, 18.1185,  0.1000, 18.1185,\n",
      "         18.2157,  0.1000, 18.2157, 18.2157, 18.2157, 18.1771, 18.1771,  0.1000,\n",
      "         18.2157,  0.1000, 18.0615, 18.0615, 18.1771, 18.2157, 18.2157,  0.1000,\n",
      "          0.1000, 18.0615, 18.1771, 18.2157,  0.1000, 18.1771, 18.2157,  0.1000,\n",
      "         18.0615, 18.2157]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 79 was 96.1%\n",
      "current params: tensor([18.0615, 18.1771, 18.1185, 18.2157], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.9\n",
      "SLow rates:  tensor([[18.1953, 18.3107, 18.2521, 18.3491,  0.1000,  0.1000,  0.1000, 18.1953,\n",
      "         18.1953, 18.1953,  0.1000,  0.1000, 18.3107, 18.3107, 18.3107,  0.1000,\n",
      "          0.1000, 18.3107, 18.3107,  0.1000, 18.2521, 18.2521, 18.2521,  0.1000,\n",
      "          0.1000, 18.2521, 18.2521,  0.1000, 18.2521,  0.1000, 18.2521, 18.3491,\n",
      "         18.3491, 18.3491,  0.1000,  0.1000, 18.3491, 18.3491,  0.1000, 18.3491,\n",
      "          0.1000, 18.3491, 18.3107, 18.3491, 18.3491, 18.3491, 18.2521, 18.3491,\n",
      "         18.3491, 18.3491, 18.3107, 18.3491, 18.3491, 18.3491, 18.3107, 18.2521,\n",
      "         18.3107, 18.3107, 18.3107,  0.1000, 18.3107, 18.2521,  0.1000, 18.2521,\n",
      "         18.3491,  0.1000, 18.3491, 18.3491, 18.3491, 18.3107, 18.3107,  0.1000,\n",
      "         18.3491,  0.1000, 18.1953, 18.1953, 18.3107, 18.3491, 18.3491,  0.1000,\n",
      "          0.1000, 18.1953, 18.3107, 18.3491,  0.1000, 18.3107, 18.3491,  0.1000,\n",
      "         18.1953, 18.3491]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 80 was 96.1%\n",
      "current params: tensor([18.1953, 18.3107, 18.2521, 18.3491], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  6.9\n",
      "SLow rates:  tensor([[18.3285, 18.4438, 18.3852, 18.4819,  0.1000,  0.1000,  0.1000, 18.3285,\n",
      "         18.3285, 18.3285,  0.1000,  0.1000, 18.4438, 18.4438, 18.4438,  0.1000,\n",
      "          0.1000, 18.4438, 18.4438,  0.1000, 18.3852, 18.3852, 18.3852,  0.1000,\n",
      "          0.1000, 18.3852, 18.3852,  0.1000, 18.3852,  0.1000, 18.3852, 18.4819,\n",
      "         18.4819, 18.4819,  0.1000,  0.1000, 18.4819, 18.4819,  0.1000, 18.4819,\n",
      "          0.1000, 18.4819, 18.4438, 18.4819, 18.4819, 18.4819, 18.3852, 18.4819,\n",
      "         18.4819, 18.4819, 18.4438, 18.4819, 18.4819, 18.4819, 18.4438, 18.3852,\n",
      "         18.4438, 18.4438, 18.4438,  0.1000, 18.4438, 18.3852,  0.1000, 18.3852,\n",
      "         18.4819,  0.1000, 18.4819, 18.4819, 18.4819, 18.4438, 18.4438,  0.1000,\n",
      "         18.4819,  0.1000, 18.3285, 18.3285, 18.4438, 18.4819, 18.4819,  0.1000,\n",
      "          0.1000, 18.3285, 18.4438, 18.4819,  0.1000, 18.4438, 18.4819,  0.1000,\n",
      "         18.3285, 18.4819]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 81 was 96.1%\n",
      "current params: tensor([18.3285, 18.4438, 18.3852, 18.4819], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.0\n",
      "SLow rates:  tensor([[18.4612, 18.5763, 18.5177, 18.6142,  0.1000,  0.1000,  0.1000, 18.4612,\n",
      "         18.4612, 18.4612,  0.1000,  0.1000, 18.5763, 18.5763, 18.5763,  0.1000,\n",
      "          0.1000, 18.5763, 18.5763,  0.1000, 18.5177, 18.5177, 18.5177,  0.1000,\n",
      "          0.1000, 18.5177, 18.5177,  0.1000, 18.5177,  0.1000, 18.5177, 18.6142,\n",
      "         18.6142, 18.6142,  0.1000,  0.1000, 18.6142, 18.6142,  0.1000, 18.6142,\n",
      "          0.1000, 18.6142, 18.5763, 18.6142, 18.6142, 18.6142, 18.5177, 18.6142,\n",
      "         18.6142, 18.6142, 18.5763, 18.6142, 18.6142, 18.6142, 18.5763, 18.5177,\n",
      "         18.5763, 18.5763, 18.5763,  0.1000, 18.5763, 18.5177,  0.1000, 18.5177,\n",
      "         18.6142,  0.1000, 18.6142, 18.6142, 18.6142, 18.5763, 18.5763,  0.1000,\n",
      "         18.6142,  0.1000, 18.4612, 18.4612, 18.5763, 18.6142, 18.6142,  0.1000,\n",
      "          0.1000, 18.4612, 18.5763, 18.6142,  0.1000, 18.5763, 18.6142,  0.1000,\n",
      "         18.4612, 18.6142]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 82 was 96.1%\n",
      "current params: tensor([18.4612, 18.5763, 18.5177, 18.6142], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.0\n",
      "SLow rates:  tensor([[18.5934, 18.7084, 18.6497, 18.7460,  0.1000,  0.1000,  0.1000, 18.5934,\n",
      "         18.5934, 18.5934,  0.1000,  0.1000, 18.7084, 18.7084, 18.7084,  0.1000,\n",
      "          0.1000, 18.7084, 18.7084,  0.1000, 18.6497, 18.6497, 18.6497,  0.1000,\n",
      "          0.1000, 18.6497, 18.6497,  0.1000, 18.6497,  0.1000, 18.6497, 18.7460,\n",
      "         18.7460, 18.7460,  0.1000,  0.1000, 18.7460, 18.7460,  0.1000, 18.7460,\n",
      "          0.1000, 18.7460, 18.7084, 18.7460, 18.7460, 18.7460, 18.6497, 18.7460,\n",
      "         18.7460, 18.7460, 18.7084, 18.7460, 18.7460, 18.7460, 18.7084, 18.6497,\n",
      "         18.7084, 18.7084, 18.7084,  0.1000, 18.7084, 18.6497,  0.1000, 18.6497,\n",
      "         18.7460,  0.1000, 18.7460, 18.7460, 18.7460, 18.7084, 18.7084,  0.1000,\n",
      "         18.7460,  0.1000, 18.5934, 18.5934, 18.7084, 18.7460, 18.7460,  0.1000,\n",
      "          0.1000, 18.5934, 18.7084, 18.7460,  0.1000, 18.7084, 18.7460,  0.1000,\n",
      "         18.5934, 18.7460]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 83 was 96.2%\n",
      "current params: tensor([18.5934, 18.7084, 18.6497, 18.7460], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.0\n",
      "SLow rates:  tensor([[18.7251, 18.8399, 18.7813, 18.8773,  0.1000,  0.1000,  0.1000, 18.7251,\n",
      "         18.7251, 18.7251,  0.1000,  0.1000, 18.8399, 18.8399, 18.8399,  0.1000,\n",
      "          0.1000, 18.8399, 18.8399,  0.1000, 18.7813, 18.7813, 18.7813,  0.1000,\n",
      "          0.1000, 18.7813, 18.7813,  0.1000, 18.7813,  0.1000, 18.7813, 18.8773,\n",
      "         18.8773, 18.8773,  0.1000,  0.1000, 18.8773, 18.8773,  0.1000, 18.8773,\n",
      "          0.1000, 18.8773, 18.8399, 18.8773, 18.8773, 18.8773, 18.7813, 18.8773,\n",
      "         18.8773, 18.8773, 18.8399, 18.8773, 18.8773, 18.8773, 18.8399, 18.7813,\n",
      "         18.8399, 18.8399, 18.8399,  0.1000, 18.8399, 18.7813,  0.1000, 18.7813,\n",
      "         18.8773,  0.1000, 18.8773, 18.8773, 18.8773, 18.8399, 18.8399,  0.1000,\n",
      "         18.8773,  0.1000, 18.7251, 18.7251, 18.8399, 18.8773, 18.8773,  0.1000,\n",
      "          0.1000, 18.7251, 18.8399, 18.8773,  0.1000, 18.8399, 18.8773,  0.1000,\n",
      "         18.7251, 18.8773]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 84 was 96.2%\n",
      "current params: tensor([18.7251, 18.8399, 18.7813, 18.8773], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.0\n",
      "SLow rates:  tensor([[18.8563, 18.9710, 18.9124, 19.0082,  0.1000,  0.1000,  0.1000, 18.8563,\n",
      "         18.8563, 18.8563,  0.1000,  0.1000, 18.9710, 18.9710, 18.9710,  0.1000,\n",
      "          0.1000, 18.9710, 18.9710,  0.1000, 18.9124, 18.9124, 18.9124,  0.1000,\n",
      "          0.1000, 18.9124, 18.9124,  0.1000, 18.9124,  0.1000, 18.9124, 19.0082,\n",
      "         19.0082, 19.0082,  0.1000,  0.1000, 19.0082, 19.0082,  0.1000, 19.0082,\n",
      "          0.1000, 19.0082, 18.9710, 19.0082, 19.0082, 19.0082, 18.9124, 19.0082,\n",
      "         19.0082, 19.0082, 18.9710, 19.0082, 19.0082, 19.0082, 18.9710, 18.9124,\n",
      "         18.9710, 18.9710, 18.9710,  0.1000, 18.9710, 18.9124,  0.1000, 18.9124,\n",
      "         19.0082,  0.1000, 19.0082, 19.0082, 19.0082, 18.9710, 18.9710,  0.1000,\n",
      "         19.0082,  0.1000, 18.8563, 18.8563, 18.9710, 19.0082, 19.0082,  0.1000,\n",
      "          0.1000, 18.8563, 18.9710, 19.0082,  0.1000, 18.9710, 19.0082,  0.1000,\n",
      "         18.8563, 19.0082]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 85 was 96.2%\n",
      "current params: tensor([18.8563, 18.9710, 18.9124, 19.0082], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.0\n",
      "SLow rates:  tensor([[18.9871, 19.1016, 19.0430, 19.1385,  0.1000,  0.1000,  0.1000, 18.9871,\n",
      "         18.9871, 18.9871,  0.1000,  0.1000, 19.1016, 19.1016, 19.1016,  0.1000,\n",
      "          0.1000, 19.1016, 19.1016,  0.1000, 19.0430, 19.0430, 19.0430,  0.1000,\n",
      "          0.1000, 19.0430, 19.0430,  0.1000, 19.0430,  0.1000, 19.0430, 19.1385,\n",
      "         19.1385, 19.1385,  0.1000,  0.1000, 19.1385, 19.1385,  0.1000, 19.1385,\n",
      "          0.1000, 19.1385, 19.1016, 19.1385, 19.1385, 19.1385, 19.0430, 19.1385,\n",
      "         19.1385, 19.1385, 19.1016, 19.1385, 19.1385, 19.1385, 19.1016, 19.0430,\n",
      "         19.1016, 19.1016, 19.1016,  0.1000, 19.1016, 19.0430,  0.1000, 19.0430,\n",
      "         19.1385,  0.1000, 19.1385, 19.1385, 19.1385, 19.1016, 19.1016,  0.1000,\n",
      "         19.1385,  0.1000, 18.9871, 18.9871, 19.1016, 19.1385, 19.1385,  0.1000,\n",
      "          0.1000, 18.9871, 19.1016, 19.1385,  0.1000, 19.1016, 19.1385,  0.1000,\n",
      "         18.9871, 19.1385]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 86 was 96.2%\n",
      "current params: tensor([18.9871, 19.1016, 19.0430, 19.1385], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.0\n",
      "SLow rates:  tensor([[19.1174, 19.2317, 19.1731, 19.2685,  0.1000,  0.1000,  0.1000, 19.1174,\n",
      "         19.1174, 19.1174,  0.1000,  0.1000, 19.2317, 19.2317, 19.2317,  0.1000,\n",
      "          0.1000, 19.2317, 19.2317,  0.1000, 19.1731, 19.1731, 19.1731,  0.1000,\n",
      "          0.1000, 19.1731, 19.1731,  0.1000, 19.1731,  0.1000, 19.1731, 19.2685,\n",
      "         19.2685, 19.2685,  0.1000,  0.1000, 19.2685, 19.2685,  0.1000, 19.2685,\n",
      "          0.1000, 19.2685, 19.2317, 19.2685, 19.2685, 19.2685, 19.1731, 19.2685,\n",
      "         19.2685, 19.2685, 19.2317, 19.2685, 19.2685, 19.2685, 19.2317, 19.1731,\n",
      "         19.2317, 19.2317, 19.2317,  0.1000, 19.2317, 19.1731,  0.1000, 19.1731,\n",
      "         19.2685,  0.1000, 19.2685, 19.2685, 19.2685, 19.2317, 19.2317,  0.1000,\n",
      "         19.2685,  0.1000, 19.1174, 19.1174, 19.2317, 19.2685, 19.2685,  0.1000,\n",
      "          0.1000, 19.1174, 19.2317, 19.2685,  0.1000, 19.2317, 19.2685,  0.1000,\n",
      "         19.1174, 19.2685]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 87 was 96.3%\n",
      "current params: tensor([19.1174, 19.2317, 19.1731, 19.2685], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.1\n",
      "SLow rates:  tensor([[19.2472, 19.3614, 19.3028, 19.3979,  0.1000,  0.1000,  0.1000, 19.2472,\n",
      "         19.2472, 19.2472,  0.1000,  0.1000, 19.3614, 19.3614, 19.3614,  0.1000,\n",
      "          0.1000, 19.3614, 19.3614,  0.1000, 19.3028, 19.3028, 19.3028,  0.1000,\n",
      "          0.1000, 19.3028, 19.3028,  0.1000, 19.3028,  0.1000, 19.3028, 19.3979,\n",
      "         19.3979, 19.3979,  0.1000,  0.1000, 19.3979, 19.3979,  0.1000, 19.3979,\n",
      "          0.1000, 19.3979, 19.3614, 19.3979, 19.3979, 19.3979, 19.3028, 19.3979,\n",
      "         19.3979, 19.3979, 19.3614, 19.3979, 19.3979, 19.3979, 19.3614, 19.3028,\n",
      "         19.3614, 19.3614, 19.3614,  0.1000, 19.3614, 19.3028,  0.1000, 19.3028,\n",
      "         19.3979,  0.1000, 19.3979, 19.3979, 19.3979, 19.3614, 19.3614,  0.1000,\n",
      "         19.3979,  0.1000, 19.2472, 19.2472, 19.3614, 19.3979, 19.3979,  0.1000,\n",
      "          0.1000, 19.2472, 19.3614, 19.3979,  0.1000, 19.3614, 19.3979,  0.1000,\n",
      "         19.2472, 19.3979]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 88 was 96.3%\n",
      "current params: tensor([19.2472, 19.3614, 19.3028, 19.3979], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.1\n",
      "SLow rates:  tensor([[19.3766, 19.4906, 19.4320, 19.5269,  0.1000,  0.1000,  0.1000, 19.3766,\n",
      "         19.3766, 19.3766,  0.1000,  0.1000, 19.4906, 19.4906, 19.4906,  0.1000,\n",
      "          0.1000, 19.4906, 19.4906,  0.1000, 19.4320, 19.4320, 19.4320,  0.1000,\n",
      "          0.1000, 19.4320, 19.4320,  0.1000, 19.4320,  0.1000, 19.4320, 19.5269,\n",
      "         19.5269, 19.5269,  0.1000,  0.1000, 19.5269, 19.5269,  0.1000, 19.5269,\n",
      "          0.1000, 19.5269, 19.4906, 19.5269, 19.5269, 19.5269, 19.4320, 19.5269,\n",
      "         19.5269, 19.5269, 19.4906, 19.5269, 19.5269, 19.5269, 19.4906, 19.4320,\n",
      "         19.4906, 19.4906, 19.4906,  0.1000, 19.4906, 19.4320,  0.1000, 19.4320,\n",
      "         19.5269,  0.1000, 19.5269, 19.5269, 19.5269, 19.4906, 19.4906,  0.1000,\n",
      "         19.5269,  0.1000, 19.3766, 19.3766, 19.4906, 19.5269, 19.5269,  0.1000,\n",
      "          0.1000, 19.3766, 19.4906, 19.5269,  0.1000, 19.4906, 19.5269,  0.1000,\n",
      "         19.3766, 19.5269]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 89 was 96.3%\n",
      "current params: tensor([19.3766, 19.4906, 19.4320, 19.5269], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.1\n",
      "SLow rates:  tensor([[19.5056, 19.6194, 19.5608, 19.6555,  0.1000,  0.1000,  0.1000, 19.5056,\n",
      "         19.5056, 19.5056,  0.1000,  0.1000, 19.6194, 19.6194, 19.6194,  0.1000,\n",
      "          0.1000, 19.6194, 19.6194,  0.1000, 19.5608, 19.5608, 19.5608,  0.1000,\n",
      "          0.1000, 19.5608, 19.5608,  0.1000, 19.5608,  0.1000, 19.5608, 19.6555,\n",
      "         19.6555, 19.6555,  0.1000,  0.1000, 19.6555, 19.6555,  0.1000, 19.6555,\n",
      "          0.1000, 19.6555, 19.6194, 19.6555, 19.6555, 19.6555, 19.5608, 19.6555,\n",
      "         19.6555, 19.6555, 19.6194, 19.6555, 19.6555, 19.6555, 19.6194, 19.5608,\n",
      "         19.6194, 19.6194, 19.6194,  0.1000, 19.6194, 19.5608,  0.1000, 19.5608,\n",
      "         19.6555,  0.1000, 19.6555, 19.6555, 19.6555, 19.6194, 19.6194,  0.1000,\n",
      "         19.6555,  0.1000, 19.5056, 19.5056, 19.6194, 19.6555, 19.6555,  0.1000,\n",
      "          0.1000, 19.5056, 19.6194, 19.6555,  0.1000, 19.6194, 19.6555,  0.1000,\n",
      "         19.5056, 19.6555]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 90 was 96.3%\n",
      "current params: tensor([19.5056, 19.6194, 19.5608, 19.6555], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.1\n",
      "SLow rates:  tensor([[19.6341, 19.7478, 19.6892, 19.7837,  0.1000,  0.1000,  0.1000, 19.6341,\n",
      "         19.6341, 19.6341,  0.1000,  0.1000, 19.7478, 19.7478, 19.7478,  0.1000,\n",
      "          0.1000, 19.7478, 19.7478,  0.1000, 19.6892, 19.6892, 19.6892,  0.1000,\n",
      "          0.1000, 19.6892, 19.6892,  0.1000, 19.6892,  0.1000, 19.6892, 19.7837,\n",
      "         19.7837, 19.7837,  0.1000,  0.1000, 19.7837, 19.7837,  0.1000, 19.7837,\n",
      "          0.1000, 19.7837, 19.7478, 19.7837, 19.7837, 19.7837, 19.6892, 19.7837,\n",
      "         19.7837, 19.7837, 19.7478, 19.7837, 19.7837, 19.7837, 19.7478, 19.6892,\n",
      "         19.7478, 19.7478, 19.7478,  0.1000, 19.7478, 19.6892,  0.1000, 19.6892,\n",
      "         19.7837,  0.1000, 19.7837, 19.7837, 19.7837, 19.7478, 19.7478,  0.1000,\n",
      "         19.7837,  0.1000, 19.6341, 19.6341, 19.7478, 19.7837, 19.7837,  0.1000,\n",
      "          0.1000, 19.6341, 19.7478, 19.7837,  0.1000, 19.7478, 19.7837,  0.1000,\n",
      "         19.6341, 19.7837]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 91 was 96.4%\n",
      "current params: tensor([19.6341, 19.7478, 19.6892, 19.7837], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.1\n",
      "SLow rates:  tensor([[19.7622, 19.8758, 19.8172, 19.9115,  0.1000,  0.1000,  0.1000, 19.7622,\n",
      "         19.7622, 19.7622,  0.1000,  0.1000, 19.8758, 19.8758, 19.8758,  0.1000,\n",
      "          0.1000, 19.8758, 19.8758,  0.1000, 19.8172, 19.8172, 19.8172,  0.1000,\n",
      "          0.1000, 19.8172, 19.8172,  0.1000, 19.8172,  0.1000, 19.8172, 19.9115,\n",
      "         19.9115, 19.9115,  0.1000,  0.1000, 19.9115, 19.9115,  0.1000, 19.9115,\n",
      "          0.1000, 19.9115, 19.8758, 19.9115, 19.9115, 19.9115, 19.8172, 19.9115,\n",
      "         19.9115, 19.9115, 19.8758, 19.9115, 19.9115, 19.9115, 19.8758, 19.8172,\n",
      "         19.8758, 19.8758, 19.8758,  0.1000, 19.8758, 19.8172,  0.1000, 19.8172,\n",
      "         19.9115,  0.1000, 19.9115, 19.9115, 19.9115, 19.8758, 19.8758,  0.1000,\n",
      "         19.9115,  0.1000, 19.7622, 19.7622, 19.8758, 19.9115, 19.9115,  0.1000,\n",
      "          0.1000, 19.7622, 19.8758, 19.9115,  0.1000, 19.8758, 19.9115,  0.1000,\n",
      "         19.7622, 19.9115]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 92 was 96.4%\n",
      "current params: tensor([19.7622, 19.8758, 19.8172, 19.9115], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.2\n",
      "SLow rates:  tensor([[19.8899, 20.0033, 19.9447, 20.0388,  0.1000,  0.1000,  0.1000, 19.8899,\n",
      "         19.8899, 19.8899,  0.1000,  0.1000, 20.0033, 20.0033, 20.0033,  0.1000,\n",
      "          0.1000, 20.0033, 20.0033,  0.1000, 19.9447, 19.9447, 19.9447,  0.1000,\n",
      "          0.1000, 19.9447, 19.9447,  0.1000, 19.9447,  0.1000, 19.9447, 20.0388,\n",
      "         20.0388, 20.0388,  0.1000,  0.1000, 20.0388, 20.0388,  0.1000, 20.0388,\n",
      "          0.1000, 20.0388, 20.0033, 20.0388, 20.0388, 20.0388, 19.9447, 20.0388,\n",
      "         20.0388, 20.0388, 20.0033, 20.0388, 20.0388, 20.0388, 20.0033, 19.9447,\n",
      "         20.0033, 20.0033, 20.0033,  0.1000, 20.0033, 19.9447,  0.1000, 19.9447,\n",
      "         20.0388,  0.1000, 20.0388, 20.0388, 20.0388, 20.0033, 20.0033,  0.1000,\n",
      "         20.0388,  0.1000, 19.8899, 19.8899, 20.0033, 20.0388, 20.0388,  0.1000,\n",
      "          0.1000, 19.8899, 20.0033, 20.0388,  0.1000, 20.0033, 20.0388,  0.1000,\n",
      "         19.8899, 20.0388]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 93 was 96.4%\n",
      "current params: tensor([19.8899, 20.0033, 19.9447, 20.0388], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.2\n",
      "SLow rates:  tensor([[20.0172, 20.1305, 20.0719, 20.1658,  0.1000,  0.1000,  0.1000, 20.0172,\n",
      "         20.0172, 20.0172,  0.1000,  0.1000, 20.1305, 20.1305, 20.1305,  0.1000,\n",
      "          0.1000, 20.1305, 20.1305,  0.1000, 20.0719, 20.0719, 20.0719,  0.1000,\n",
      "          0.1000, 20.0719, 20.0719,  0.1000, 20.0719,  0.1000, 20.0719, 20.1658,\n",
      "         20.1658, 20.1658,  0.1000,  0.1000, 20.1658, 20.1658,  0.1000, 20.1658,\n",
      "          0.1000, 20.1658, 20.1305, 20.1658, 20.1658, 20.1658, 20.0719, 20.1658,\n",
      "         20.1658, 20.1658, 20.1305, 20.1658, 20.1658, 20.1658, 20.1305, 20.0719,\n",
      "         20.1305, 20.1305, 20.1305,  0.1000, 20.1305, 20.0719,  0.1000, 20.0719,\n",
      "         20.1658,  0.1000, 20.1658, 20.1658, 20.1658, 20.1305, 20.1305,  0.1000,\n",
      "         20.1658,  0.1000, 20.0172, 20.0172, 20.1305, 20.1658, 20.1658,  0.1000,\n",
      "          0.1000, 20.0172, 20.1305, 20.1658,  0.1000, 20.1305, 20.1658,  0.1000,\n",
      "         20.0172, 20.1658]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 94 was 96.4%\n",
      "current params: tensor([20.0172, 20.1305, 20.0719, 20.1658], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.2\n",
      "SLow rates:  tensor([[20.1441, 20.2572, 20.1986, 20.2923,  0.1000,  0.1000,  0.1000, 20.1441,\n",
      "         20.1441, 20.1441,  0.1000,  0.1000, 20.2572, 20.2572, 20.2572,  0.1000,\n",
      "          0.1000, 20.2572, 20.2572,  0.1000, 20.1986, 20.1986, 20.1986,  0.1000,\n",
      "          0.1000, 20.1986, 20.1986,  0.1000, 20.1986,  0.1000, 20.1986, 20.2923,\n",
      "         20.2923, 20.2923,  0.1000,  0.1000, 20.2923, 20.2923,  0.1000, 20.2923,\n",
      "          0.1000, 20.2923, 20.2572, 20.2923, 20.2923, 20.2923, 20.1986, 20.2923,\n",
      "         20.2923, 20.2923, 20.2572, 20.2923, 20.2923, 20.2923, 20.2572, 20.1986,\n",
      "         20.2572, 20.2572, 20.2572,  0.1000, 20.2572, 20.1986,  0.1000, 20.1986,\n",
      "         20.2923,  0.1000, 20.2923, 20.2923, 20.2923, 20.2572, 20.2572,  0.1000,\n",
      "         20.2923,  0.1000, 20.1441, 20.1441, 20.2572, 20.2923, 20.2923,  0.1000,\n",
      "          0.1000, 20.1441, 20.2572, 20.2923,  0.1000, 20.2572, 20.2923,  0.1000,\n",
      "         20.1441, 20.2923]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 95 was 96.4%\n",
      "current params: tensor([20.1441, 20.2572, 20.1986, 20.2923], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.2\n",
      "SLow rates:  tensor([[20.2706, 20.3836, 20.3250, 20.4185,  0.1000,  0.1000,  0.1000, 20.2706,\n",
      "         20.2706, 20.2706,  0.1000,  0.1000, 20.3836, 20.3836, 20.3836,  0.1000,\n",
      "          0.1000, 20.3836, 20.3836,  0.1000, 20.3250, 20.3250, 20.3250,  0.1000,\n",
      "          0.1000, 20.3250, 20.3250,  0.1000, 20.3250,  0.1000, 20.3250, 20.4185,\n",
      "         20.4185, 20.4185,  0.1000,  0.1000, 20.4185, 20.4185,  0.1000, 20.4185,\n",
      "          0.1000, 20.4185, 20.3836, 20.4185, 20.4185, 20.4185, 20.3250, 20.4185,\n",
      "         20.4185, 20.4185, 20.3836, 20.4185, 20.4185, 20.4185, 20.3836, 20.3250,\n",
      "         20.3836, 20.3836, 20.3836,  0.1000, 20.3836, 20.3250,  0.1000, 20.3250,\n",
      "         20.4185,  0.1000, 20.4185, 20.4185, 20.4185, 20.3836, 20.3836,  0.1000,\n",
      "         20.4185,  0.1000, 20.2706, 20.2706, 20.3836, 20.4185, 20.4185,  0.1000,\n",
      "          0.1000, 20.2706, 20.3836, 20.4185,  0.1000, 20.3836, 20.4185,  0.1000,\n",
      "         20.2706, 20.4185]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 96 was 96.5%\n",
      "current params: tensor([20.2706, 20.3836, 20.3250, 20.4185], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.3\n",
      "SLow rates:  tensor([[20.3967, 20.5096, 20.4510, 20.5443,  0.1000,  0.1000,  0.1000, 20.3967,\n",
      "         20.3967, 20.3967,  0.1000,  0.1000, 20.5096, 20.5096, 20.5096,  0.1000,\n",
      "          0.1000, 20.5096, 20.5096,  0.1000, 20.4510, 20.4510, 20.4510,  0.1000,\n",
      "          0.1000, 20.4510, 20.4510,  0.1000, 20.4510,  0.1000, 20.4510, 20.5443,\n",
      "         20.5443, 20.5443,  0.1000,  0.1000, 20.5443, 20.5443,  0.1000, 20.5443,\n",
      "          0.1000, 20.5443, 20.5096, 20.5443, 20.5443, 20.5443, 20.4510, 20.5443,\n",
      "         20.5443, 20.5443, 20.5096, 20.5443, 20.5443, 20.5443, 20.5096, 20.4510,\n",
      "         20.5096, 20.5096, 20.5096,  0.1000, 20.5096, 20.4510,  0.1000, 20.4510,\n",
      "         20.5443,  0.1000, 20.5443, 20.5443, 20.5443, 20.5096, 20.5096,  0.1000,\n",
      "         20.5443,  0.1000, 20.3967, 20.3967, 20.5096, 20.5443, 20.5443,  0.1000,\n",
      "          0.1000, 20.3967, 20.5096, 20.5443,  0.1000, 20.5096, 20.5443,  0.1000,\n",
      "         20.3967, 20.5443]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 97 was 96.5%\n",
      "current params: tensor([20.3967, 20.5096, 20.4510, 20.5443], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.3\n",
      "SLow rates:  tensor([[20.5225, 20.6352, 20.5766, 20.6697,  0.1000,  0.1000,  0.1000, 20.5225,\n",
      "         20.5225, 20.5225,  0.1000,  0.1000, 20.6352, 20.6352, 20.6352,  0.1000,\n",
      "          0.1000, 20.6352, 20.6352,  0.1000, 20.5766, 20.5766, 20.5766,  0.1000,\n",
      "          0.1000, 20.5766, 20.5766,  0.1000, 20.5766,  0.1000, 20.5766, 20.6697,\n",
      "         20.6697, 20.6697,  0.1000,  0.1000, 20.6697, 20.6697,  0.1000, 20.6697,\n",
      "          0.1000, 20.6697, 20.6352, 20.6697, 20.6697, 20.6697, 20.5766, 20.6697,\n",
      "         20.6697, 20.6697, 20.6352, 20.6697, 20.6697, 20.6697, 20.6352, 20.5766,\n",
      "         20.6352, 20.6352, 20.6352,  0.1000, 20.6352, 20.5766,  0.1000, 20.5766,\n",
      "         20.6697,  0.1000, 20.6697, 20.6697, 20.6697, 20.6352, 20.6352,  0.1000,\n",
      "         20.6697,  0.1000, 20.5225, 20.5225, 20.6352, 20.6697, 20.6697,  0.1000,\n",
      "          0.1000, 20.5225, 20.6352, 20.6697,  0.1000, 20.6352, 20.6697,  0.1000,\n",
      "         20.5225, 20.6697]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 98 was 96.5%\n",
      "current params: tensor([20.5225, 20.6352, 20.5766, 20.6697], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.3\n",
      "SLow rates:  tensor([[20.6479, 20.7605, 20.7019, 20.7948,  0.1000,  0.1000,  0.1000, 20.6479,\n",
      "         20.6479, 20.6479,  0.1000,  0.1000, 20.7605, 20.7605, 20.7605,  0.1000,\n",
      "          0.1000, 20.7605, 20.7605,  0.1000, 20.7019, 20.7019, 20.7019,  0.1000,\n",
      "          0.1000, 20.7019, 20.7019,  0.1000, 20.7019,  0.1000, 20.7019, 20.7948,\n",
      "         20.7948, 20.7948,  0.1000,  0.1000, 20.7948, 20.7948,  0.1000, 20.7948,\n",
      "          0.1000, 20.7948, 20.7605, 20.7948, 20.7948, 20.7948, 20.7019, 20.7948,\n",
      "         20.7948, 20.7948, 20.7605, 20.7948, 20.7948, 20.7948, 20.7605, 20.7019,\n",
      "         20.7605, 20.7605, 20.7605,  0.1000, 20.7605, 20.7019,  0.1000, 20.7019,\n",
      "         20.7948,  0.1000, 20.7948, 20.7948, 20.7948, 20.7605, 20.7605,  0.1000,\n",
      "         20.7948,  0.1000, 20.6479, 20.6479, 20.7605, 20.7948, 20.7948,  0.1000,\n",
      "          0.1000, 20.6479, 20.7605, 20.7948,  0.1000, 20.7605, 20.7948,  0.1000,\n",
      "         20.6479, 20.7948]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 99 was 96.5%\n",
      "current params: tensor([20.6479, 20.7605, 20.7019, 20.7948], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.3\n",
      "SLow rates:  tensor([[20.7729, 20.8853, 20.8268, 20.9195,  0.1000,  0.1000,  0.1000, 20.7729,\n",
      "         20.7729, 20.7729,  0.1000,  0.1000, 20.8853, 20.8853, 20.8853,  0.1000,\n",
      "          0.1000, 20.8853, 20.8853,  0.1000, 20.8268, 20.8268, 20.8268,  0.1000,\n",
      "          0.1000, 20.8268, 20.8268,  0.1000, 20.8268,  0.1000, 20.8268, 20.9195,\n",
      "         20.9195, 20.9195,  0.1000,  0.1000, 20.9195, 20.9195,  0.1000, 20.9195,\n",
      "          0.1000, 20.9195, 20.8853, 20.9195, 20.9195, 20.9195, 20.8268, 20.9195,\n",
      "         20.9195, 20.9195, 20.8853, 20.9195, 20.9195, 20.9195, 20.8853, 20.8268,\n",
      "         20.8853, 20.8853, 20.8853,  0.1000, 20.8853, 20.8268,  0.1000, 20.8268,\n",
      "         20.9195,  0.1000, 20.9195, 20.9195, 20.9195, 20.8853, 20.8853,  0.1000,\n",
      "         20.9195,  0.1000, 20.7729, 20.7729, 20.8853, 20.9195, 20.9195,  0.1000,\n",
      "          0.1000, 20.7729, 20.8853, 20.9195,  0.1000, 20.8853, 20.9195,  0.1000,\n",
      "         20.7729, 20.9195]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 100 was 96.5%\n",
      "current params: tensor([20.7729, 20.8853, 20.8268, 20.9195], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.3\n",
      "SLow rates:  tensor([[20.8976, 21.0099, 20.9514, 21.0439,  0.1000,  0.1000,  0.1000, 20.8976,\n",
      "         20.8976, 20.8976,  0.1000,  0.1000, 21.0099, 21.0099, 21.0099,  0.1000,\n",
      "          0.1000, 21.0099, 21.0099,  0.1000, 20.9514, 20.9514, 20.9514,  0.1000,\n",
      "          0.1000, 20.9514, 20.9514,  0.1000, 20.9514,  0.1000, 20.9514, 21.0439,\n",
      "         21.0439, 21.0439,  0.1000,  0.1000, 21.0439, 21.0439,  0.1000, 21.0439,\n",
      "          0.1000, 21.0439, 21.0099, 21.0439, 21.0439, 21.0439, 20.9514, 21.0439,\n",
      "         21.0439, 21.0439, 21.0099, 21.0439, 21.0439, 21.0439, 21.0099, 20.9514,\n",
      "         21.0099, 21.0099, 21.0099,  0.1000, 21.0099, 20.9514,  0.1000, 20.9514,\n",
      "         21.0439,  0.1000, 21.0439, 21.0439, 21.0439, 21.0099, 21.0099,  0.1000,\n",
      "         21.0439,  0.1000, 20.8976, 20.8976, 21.0099, 21.0439, 21.0439,  0.1000,\n",
      "          0.1000, 20.8976, 21.0099, 21.0439,  0.1000, 21.0099, 21.0439,  0.1000,\n",
      "         20.8976, 21.0439]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 101 was 96.6%\n",
      "current params: tensor([20.8976, 21.0099, 20.9514, 21.0439], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.4\n",
      "SLow rates:  tensor([[21.0219, 21.1341, 21.0756, 21.1679,  0.1000,  0.1000,  0.1000, 21.0219,\n",
      "         21.0219, 21.0219,  0.1000,  0.1000, 21.1341, 21.1341, 21.1341,  0.1000,\n",
      "          0.1000, 21.1341, 21.1341,  0.1000, 21.0756, 21.0756, 21.0756,  0.1000,\n",
      "          0.1000, 21.0756, 21.0756,  0.1000, 21.0756,  0.1000, 21.0756, 21.1679,\n",
      "         21.1679, 21.1679,  0.1000,  0.1000, 21.1679, 21.1679,  0.1000, 21.1679,\n",
      "          0.1000, 21.1679, 21.1341, 21.1679, 21.1679, 21.1679, 21.0756, 21.1679,\n",
      "         21.1679, 21.1679, 21.1341, 21.1679, 21.1679, 21.1679, 21.1341, 21.0756,\n",
      "         21.1341, 21.1341, 21.1341,  0.1000, 21.1341, 21.0756,  0.1000, 21.0756,\n",
      "         21.1679,  0.1000, 21.1679, 21.1679, 21.1679, 21.1341, 21.1341,  0.1000,\n",
      "         21.1679,  0.1000, 21.0219, 21.0219, 21.1341, 21.1679, 21.1679,  0.1000,\n",
      "          0.1000, 21.0219, 21.1341, 21.1679,  0.1000, 21.1341, 21.1679,  0.1000,\n",
      "         21.0219, 21.1679]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 102 was 96.6%\n",
      "current params: tensor([21.0219, 21.1341, 21.0756, 21.1679], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.4\n",
      "SLow rates:  tensor([[21.1459, 21.2580, 21.1994, 21.2916,  0.1000,  0.1000,  0.1000, 21.1459,\n",
      "         21.1459, 21.1459,  0.1000,  0.1000, 21.2580, 21.2580, 21.2580,  0.1000,\n",
      "          0.1000, 21.2580, 21.2580,  0.1000, 21.1994, 21.1994, 21.1994,  0.1000,\n",
      "          0.1000, 21.1994, 21.1994,  0.1000, 21.1994,  0.1000, 21.1994, 21.2916,\n",
      "         21.2916, 21.2916,  0.1000,  0.1000, 21.2916, 21.2916,  0.1000, 21.2916,\n",
      "          0.1000, 21.2916, 21.2580, 21.2916, 21.2916, 21.2916, 21.1994, 21.2916,\n",
      "         21.2916, 21.2916, 21.2580, 21.2916, 21.2916, 21.2916, 21.2580, 21.1994,\n",
      "         21.2580, 21.2580, 21.2580,  0.1000, 21.2580, 21.1994,  0.1000, 21.1994,\n",
      "         21.2916,  0.1000, 21.2916, 21.2916, 21.2916, 21.2580, 21.2580,  0.1000,\n",
      "         21.2916,  0.1000, 21.1459, 21.1459, 21.2580, 21.2916, 21.2916,  0.1000,\n",
      "          0.1000, 21.1459, 21.2580, 21.2916,  0.1000, 21.2580, 21.2916,  0.1000,\n",
      "         21.1459, 21.2916]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 103 was 96.6%\n",
      "current params: tensor([21.1459, 21.2580, 21.1994, 21.2916], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.4\n",
      "SLow rates:  tensor([[21.2696, 21.3815, 21.3230, 21.4150,  0.1000,  0.1000,  0.1000, 21.2696,\n",
      "         21.2696, 21.2696,  0.1000,  0.1000, 21.3815, 21.3815, 21.3815,  0.1000,\n",
      "          0.1000, 21.3815, 21.3815,  0.1000, 21.3230, 21.3230, 21.3230,  0.1000,\n",
      "          0.1000, 21.3230, 21.3230,  0.1000, 21.3230,  0.1000, 21.3230, 21.4150,\n",
      "         21.4150, 21.4150,  0.1000,  0.1000, 21.4150, 21.4150,  0.1000, 21.4150,\n",
      "          0.1000, 21.4150, 21.3815, 21.4150, 21.4150, 21.4150, 21.3230, 21.4150,\n",
      "         21.4150, 21.4150, 21.3815, 21.4150, 21.4150, 21.4150, 21.3815, 21.3230,\n",
      "         21.3815, 21.3815, 21.3815,  0.1000, 21.3815, 21.3230,  0.1000, 21.3230,\n",
      "         21.4150,  0.1000, 21.4150, 21.4150, 21.4150, 21.3815, 21.3815,  0.1000,\n",
      "         21.4150,  0.1000, 21.2696, 21.2696, 21.3815, 21.4150, 21.4150,  0.1000,\n",
      "          0.1000, 21.2696, 21.3815, 21.4150,  0.1000, 21.3815, 21.4150,  0.1000,\n",
      "         21.2696, 21.4150]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 104 was 96.6%\n",
      "current params: tensor([21.2696, 21.3815, 21.3230, 21.4150], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.4\n",
      "SLow rates:  tensor([[21.3929, 21.5047, 21.4462, 21.5380,  0.1000,  0.1000,  0.1000, 21.3929,\n",
      "         21.3929, 21.3929,  0.1000,  0.1000, 21.5047, 21.5047, 21.5047,  0.1000,\n",
      "          0.1000, 21.5047, 21.5047,  0.1000, 21.4462, 21.4462, 21.4462,  0.1000,\n",
      "          0.1000, 21.4462, 21.4462,  0.1000, 21.4462,  0.1000, 21.4462, 21.5380,\n",
      "         21.5380, 21.5380,  0.1000,  0.1000, 21.5380, 21.5380,  0.1000, 21.5380,\n",
      "          0.1000, 21.5380, 21.5047, 21.5380, 21.5380, 21.5380, 21.4462, 21.5380,\n",
      "         21.5380, 21.5380, 21.5047, 21.5380, 21.5380, 21.5380, 21.5047, 21.4462,\n",
      "         21.5047, 21.5047, 21.5047,  0.1000, 21.5047, 21.4462,  0.1000, 21.4462,\n",
      "         21.5380,  0.1000, 21.5380, 21.5380, 21.5380, 21.5047, 21.5047,  0.1000,\n",
      "         21.5380,  0.1000, 21.3929, 21.3929, 21.5047, 21.5380, 21.5380,  0.1000,\n",
      "          0.1000, 21.3929, 21.5047, 21.5380,  0.1000, 21.5047, 21.5380,  0.1000,\n",
      "         21.3929, 21.5380]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 105 was 96.6%\n",
      "current params: tensor([21.3929, 21.5047, 21.4462, 21.5380], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.4\n",
      "SLow rates:  tensor([[21.5160, 21.6276, 21.5691, 21.6607,  0.1000,  0.1000,  0.1000, 21.5160,\n",
      "         21.5160, 21.5160,  0.1000,  0.1000, 21.6276, 21.6276, 21.6276,  0.1000,\n",
      "          0.1000, 21.6276, 21.6276,  0.1000, 21.5691, 21.5691, 21.5691,  0.1000,\n",
      "          0.1000, 21.5691, 21.5691,  0.1000, 21.5691,  0.1000, 21.5691, 21.6607,\n",
      "         21.6607, 21.6607,  0.1000,  0.1000, 21.6607, 21.6607,  0.1000, 21.6607,\n",
      "          0.1000, 21.6607, 21.6276, 21.6607, 21.6607, 21.6607, 21.5691, 21.6607,\n",
      "         21.6607, 21.6607, 21.6276, 21.6607, 21.6607, 21.6607, 21.6276, 21.5691,\n",
      "         21.6276, 21.6276, 21.6276,  0.1000, 21.6276, 21.5691,  0.1000, 21.5691,\n",
      "         21.6607,  0.1000, 21.6607, 21.6607, 21.6607, 21.6276, 21.6276,  0.1000,\n",
      "         21.6607,  0.1000, 21.5160, 21.5160, 21.6276, 21.6607, 21.6607,  0.1000,\n",
      "          0.1000, 21.5160, 21.6276, 21.6607,  0.1000, 21.6276, 21.6607,  0.1000,\n",
      "         21.5160, 21.6607]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 106 was 96.6%\n",
      "current params: tensor([21.5160, 21.6276, 21.5691, 21.6607], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.5\n",
      "SLow rates:  tensor([[21.6387, 21.7501, 21.6917, 21.7831,  0.1000,  0.1000,  0.1000, 21.6387,\n",
      "         21.6387, 21.6387,  0.1000,  0.1000, 21.7501, 21.7501, 21.7501,  0.1000,\n",
      "          0.1000, 21.7501, 21.7501,  0.1000, 21.6917, 21.6917, 21.6917,  0.1000,\n",
      "          0.1000, 21.6917, 21.6917,  0.1000, 21.6917,  0.1000, 21.6917, 21.7831,\n",
      "         21.7831, 21.7831,  0.1000,  0.1000, 21.7831, 21.7831,  0.1000, 21.7831,\n",
      "          0.1000, 21.7831, 21.7501, 21.7831, 21.7831, 21.7831, 21.6917, 21.7831,\n",
      "         21.7831, 21.7831, 21.7501, 21.7831, 21.7831, 21.7831, 21.7501, 21.6917,\n",
      "         21.7501, 21.7501, 21.7501,  0.1000, 21.7501, 21.6917,  0.1000, 21.6917,\n",
      "         21.7831,  0.1000, 21.7831, 21.7831, 21.7831, 21.7501, 21.7501,  0.1000,\n",
      "         21.7831,  0.1000, 21.6387, 21.6387, 21.7501, 21.7831, 21.7831,  0.1000,\n",
      "          0.1000, 21.6387, 21.7501, 21.7831,  0.1000, 21.7501, 21.7831,  0.1000,\n",
      "         21.6387, 21.7831]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 107 was 96.7%\n",
      "current params: tensor([21.6387, 21.7501, 21.6917, 21.7831], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.5\n",
      "SLow rates:  tensor([[21.7611, 21.8724, 21.8140, 21.9052,  0.1000,  0.1000,  0.1000, 21.7611,\n",
      "         21.7611, 21.7611,  0.1000,  0.1000, 21.8724, 21.8724, 21.8724,  0.1000,\n",
      "          0.1000, 21.8724, 21.8724,  0.1000, 21.8140, 21.8140, 21.8140,  0.1000,\n",
      "          0.1000, 21.8140, 21.8140,  0.1000, 21.8140,  0.1000, 21.8140, 21.9052,\n",
      "         21.9052, 21.9052,  0.1000,  0.1000, 21.9052, 21.9052,  0.1000, 21.9052,\n",
      "          0.1000, 21.9052, 21.8724, 21.9052, 21.9052, 21.9052, 21.8140, 21.9052,\n",
      "         21.9052, 21.9052, 21.8724, 21.9052, 21.9052, 21.9052, 21.8724, 21.8140,\n",
      "         21.8724, 21.8724, 21.8724,  0.1000, 21.8724, 21.8140,  0.1000, 21.8140,\n",
      "         21.9052,  0.1000, 21.9052, 21.9052, 21.9052, 21.8724, 21.8724,  0.1000,\n",
      "         21.9052,  0.1000, 21.7611, 21.7611, 21.8724, 21.9052, 21.9052,  0.1000,\n",
      "          0.1000, 21.7611, 21.8724, 21.9052,  0.1000, 21.8724, 21.9052,  0.1000,\n",
      "         21.7611, 21.9052]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 108 was 96.7%\n",
      "current params: tensor([21.7611, 21.8724, 21.8140, 21.9052], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.5\n",
      "SLow rates:  tensor([[21.8831, 21.9944, 21.9359, 22.0270,  0.1000,  0.1000,  0.1000, 21.8831,\n",
      "         21.8831, 21.8831,  0.1000,  0.1000, 21.9944, 21.9944, 21.9944,  0.1000,\n",
      "          0.1000, 21.9944, 21.9944,  0.1000, 21.9359, 21.9359, 21.9359,  0.1000,\n",
      "          0.1000, 21.9359, 21.9359,  0.1000, 21.9359,  0.1000, 21.9359, 22.0270,\n",
      "         22.0270, 22.0270,  0.1000,  0.1000, 22.0270, 22.0270,  0.1000, 22.0270,\n",
      "          0.1000, 22.0270, 21.9944, 22.0270, 22.0270, 22.0270, 21.9359, 22.0270,\n",
      "         22.0270, 22.0270, 21.9944, 22.0270, 22.0270, 22.0270, 21.9944, 21.9359,\n",
      "         21.9944, 21.9944, 21.9944,  0.1000, 21.9944, 21.9359,  0.1000, 21.9359,\n",
      "         22.0270,  0.1000, 22.0270, 22.0270, 22.0270, 21.9944, 21.9944,  0.1000,\n",
      "         22.0270,  0.1000, 21.8831, 21.8831, 21.9944, 22.0270, 22.0270,  0.1000,\n",
      "          0.1000, 21.8831, 21.9944, 22.0270,  0.1000, 21.9944, 22.0270,  0.1000,\n",
      "         21.8831, 22.0270]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 109 was 96.7%\n",
      "current params: tensor([21.8831, 21.9944, 21.9359, 22.0270], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.5\n",
      "SLow rates:  tensor([[22.0049, 22.1160, 22.0576, 22.1485,  0.1000,  0.1000,  0.1000, 22.0049,\n",
      "         22.0049, 22.0049,  0.1000,  0.1000, 22.1160, 22.1160, 22.1160,  0.1000,\n",
      "          0.1000, 22.1160, 22.1160,  0.1000, 22.0576, 22.0576, 22.0576,  0.1000,\n",
      "          0.1000, 22.0576, 22.0576,  0.1000, 22.0576,  0.1000, 22.0576, 22.1485,\n",
      "         22.1485, 22.1485,  0.1000,  0.1000, 22.1485, 22.1485,  0.1000, 22.1485,\n",
      "          0.1000, 22.1485, 22.1160, 22.1485, 22.1485, 22.1485, 22.0576, 22.1485,\n",
      "         22.1485, 22.1485, 22.1160, 22.1485, 22.1485, 22.1485, 22.1160, 22.0576,\n",
      "         22.1160, 22.1160, 22.1160,  0.1000, 22.1160, 22.0576,  0.1000, 22.0576,\n",
      "         22.1485,  0.1000, 22.1485, 22.1485, 22.1485, 22.1160, 22.1160,  0.1000,\n",
      "         22.1485,  0.1000, 22.0049, 22.0049, 22.1160, 22.1485, 22.1485,  0.1000,\n",
      "          0.1000, 22.0049, 22.1160, 22.1485,  0.1000, 22.1160, 22.1485,  0.1000,\n",
      "         22.0049, 22.1485]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 110 was 96.7%\n",
      "current params: tensor([22.0049, 22.1160, 22.0576, 22.1485], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.5\n",
      "SLow rates:  tensor([[22.1264, 22.2374, 22.1790, 22.2697,  0.1000,  0.1000,  0.1000, 22.1264,\n",
      "         22.1264, 22.1264,  0.1000,  0.1000, 22.2374, 22.2374, 22.2374,  0.1000,\n",
      "          0.1000, 22.2374, 22.2374,  0.1000, 22.1790, 22.1790, 22.1790,  0.1000,\n",
      "          0.1000, 22.1790, 22.1790,  0.1000, 22.1790,  0.1000, 22.1790, 22.2697,\n",
      "         22.2697, 22.2697,  0.1000,  0.1000, 22.2697, 22.2697,  0.1000, 22.2697,\n",
      "          0.1000, 22.2697, 22.2374, 22.2697, 22.2697, 22.2697, 22.1790, 22.2697,\n",
      "         22.2697, 22.2697, 22.2374, 22.2697, 22.2697, 22.2697, 22.2374, 22.1790,\n",
      "         22.2374, 22.2374, 22.2374,  0.1000, 22.2374, 22.1790,  0.1000, 22.1790,\n",
      "         22.2697,  0.1000, 22.2697, 22.2697, 22.2697, 22.2374, 22.2374,  0.1000,\n",
      "         22.2697,  0.1000, 22.1264, 22.1264, 22.2374, 22.2697, 22.2697,  0.1000,\n",
      "          0.1000, 22.1264, 22.2374, 22.2697,  0.1000, 22.2374, 22.2697,  0.1000,\n",
      "         22.1264, 22.2697]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 111 was 96.7%\n",
      "current params: tensor([22.1264, 22.2374, 22.1790, 22.2697], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.5\n",
      "SLow rates:  tensor([[22.2476, 22.3584, 22.3001, 22.3906,  0.1000,  0.1000,  0.1000, 22.2476,\n",
      "         22.2476, 22.2476,  0.1000,  0.1000, 22.3584, 22.3584, 22.3584,  0.1000,\n",
      "          0.1000, 22.3584, 22.3584,  0.1000, 22.3001, 22.3001, 22.3001,  0.1000,\n",
      "          0.1000, 22.3001, 22.3001,  0.1000, 22.3001,  0.1000, 22.3001, 22.3906,\n",
      "         22.3906, 22.3906,  0.1000,  0.1000, 22.3906, 22.3906,  0.1000, 22.3906,\n",
      "          0.1000, 22.3906, 22.3584, 22.3906, 22.3906, 22.3906, 22.3001, 22.3906,\n",
      "         22.3906, 22.3906, 22.3584, 22.3906, 22.3906, 22.3906, 22.3584, 22.3001,\n",
      "         22.3584, 22.3584, 22.3584,  0.1000, 22.3584, 22.3001,  0.1000, 22.3001,\n",
      "         22.3906,  0.1000, 22.3906, 22.3906, 22.3906, 22.3584, 22.3584,  0.1000,\n",
      "         22.3906,  0.1000, 22.2476, 22.2476, 22.3584, 22.3906, 22.3906,  0.1000,\n",
      "          0.1000, 22.2476, 22.3584, 22.3906,  0.1000, 22.3584, 22.3906,  0.1000,\n",
      "         22.2476, 22.3906]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 112 was 96.7%\n",
      "current params: tensor([22.2476, 22.3584, 22.3001, 22.3906], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.6\n",
      "SLow rates:  tensor([[22.3685, 22.4792, 22.4209, 22.5113,  0.1000,  0.1000,  0.1000, 22.3685,\n",
      "         22.3685, 22.3685,  0.1000,  0.1000, 22.4792, 22.4792, 22.4792,  0.1000,\n",
      "          0.1000, 22.4792, 22.4792,  0.1000, 22.4209, 22.4209, 22.4209,  0.1000,\n",
      "          0.1000, 22.4209, 22.4209,  0.1000, 22.4209,  0.1000, 22.4209, 22.5113,\n",
      "         22.5113, 22.5113,  0.1000,  0.1000, 22.5113, 22.5113,  0.1000, 22.5113,\n",
      "          0.1000, 22.5113, 22.4792, 22.5113, 22.5113, 22.5113, 22.4209, 22.5113,\n",
      "         22.5113, 22.5113, 22.4792, 22.5113, 22.5113, 22.5113, 22.4792, 22.4209,\n",
      "         22.4792, 22.4792, 22.4792,  0.1000, 22.4792, 22.4209,  0.1000, 22.4209,\n",
      "         22.5113,  0.1000, 22.5113, 22.5113, 22.5113, 22.4792, 22.4792,  0.1000,\n",
      "         22.5113,  0.1000, 22.3685, 22.3685, 22.4792, 22.5113, 22.5113,  0.1000,\n",
      "          0.1000, 22.3685, 22.4792, 22.5113,  0.1000, 22.4792, 22.5113,  0.1000,\n",
      "         22.3685, 22.5113]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 113 was 96.8%\n",
      "current params: tensor([22.3685, 22.4792, 22.4209, 22.5113], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.6\n",
      "SLow rates:  tensor([[22.4892, 22.5998, 22.5414, 22.6316,  0.1000,  0.1000,  0.1000, 22.4892,\n",
      "         22.4892, 22.4892,  0.1000,  0.1000, 22.5998, 22.5998, 22.5998,  0.1000,\n",
      "          0.1000, 22.5998, 22.5998,  0.1000, 22.5414, 22.5414, 22.5414,  0.1000,\n",
      "          0.1000, 22.5414, 22.5414,  0.1000, 22.5414,  0.1000, 22.5414, 22.6316,\n",
      "         22.6316, 22.6316,  0.1000,  0.1000, 22.6316, 22.6316,  0.1000, 22.6316,\n",
      "          0.1000, 22.6316, 22.5998, 22.6316, 22.6316, 22.6316, 22.5414, 22.6316,\n",
      "         22.6316, 22.6316, 22.5998, 22.6316, 22.6316, 22.6316, 22.5998, 22.5414,\n",
      "         22.5998, 22.5998, 22.5998,  0.1000, 22.5998, 22.5414,  0.1000, 22.5414,\n",
      "         22.6316,  0.1000, 22.6316, 22.6316, 22.6316, 22.5998, 22.5998,  0.1000,\n",
      "         22.6316,  0.1000, 22.4892, 22.4892, 22.5998, 22.6316, 22.6316,  0.1000,\n",
      "          0.1000, 22.4892, 22.5998, 22.6316,  0.1000, 22.5998, 22.6316,  0.1000,\n",
      "         22.4892, 22.6316]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 114 was 96.8%\n",
      "current params: tensor([22.4892, 22.5998, 22.5414, 22.6316], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.6\n",
      "SLow rates:  tensor([[22.6095, 22.7200, 22.6617, 22.7517,  0.1000,  0.1000,  0.1000, 22.6095,\n",
      "         22.6095, 22.6095,  0.1000,  0.1000, 22.7200, 22.7200, 22.7200,  0.1000,\n",
      "          0.1000, 22.7200, 22.7200,  0.1000, 22.6617, 22.6617, 22.6617,  0.1000,\n",
      "          0.1000, 22.6617, 22.6617,  0.1000, 22.6617,  0.1000, 22.6617, 22.7517,\n",
      "         22.7517, 22.7517,  0.1000,  0.1000, 22.7517, 22.7517,  0.1000, 22.7517,\n",
      "          0.1000, 22.7517, 22.7200, 22.7517, 22.7517, 22.7517, 22.6617, 22.7517,\n",
      "         22.7517, 22.7517, 22.7200, 22.7517, 22.7517, 22.7517, 22.7200, 22.6617,\n",
      "         22.7200, 22.7200, 22.7200,  0.1000, 22.7200, 22.6617,  0.1000, 22.6617,\n",
      "         22.7517,  0.1000, 22.7517, 22.7517, 22.7517, 22.7200, 22.7200,  0.1000,\n",
      "         22.7517,  0.1000, 22.6095, 22.6095, 22.7200, 22.7517, 22.7517,  0.1000,\n",
      "          0.1000, 22.6095, 22.7200, 22.7517,  0.1000, 22.7200, 22.7517,  0.1000,\n",
      "         22.6095, 22.7517]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 115 was 96.8%\n",
      "current params: tensor([22.6095, 22.7200, 22.6617, 22.7517], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.6\n",
      "SLow rates:  tensor([[22.7296, 22.8400, 22.7816, 22.8716,  0.1000,  0.1000,  0.1000, 22.7296,\n",
      "         22.7296, 22.7296,  0.1000,  0.1000, 22.8400, 22.8400, 22.8400,  0.1000,\n",
      "          0.1000, 22.8400, 22.8400,  0.1000, 22.7816, 22.7816, 22.7816,  0.1000,\n",
      "          0.1000, 22.7816, 22.7816,  0.1000, 22.7816,  0.1000, 22.7816, 22.8716,\n",
      "         22.8716, 22.8716,  0.1000,  0.1000, 22.8716, 22.8716,  0.1000, 22.8716,\n",
      "          0.1000, 22.8716, 22.8400, 22.8716, 22.8716, 22.8716, 22.7816, 22.8716,\n",
      "         22.8716, 22.8716, 22.8400, 22.8716, 22.8716, 22.8716, 22.8400, 22.7816,\n",
      "         22.8400, 22.8400, 22.8400,  0.1000, 22.8400, 22.7816,  0.1000, 22.7816,\n",
      "         22.8716,  0.1000, 22.8716, 22.8716, 22.8716, 22.8400, 22.8400,  0.1000,\n",
      "         22.8716,  0.1000, 22.7296, 22.7296, 22.8400, 22.8716, 22.8716,  0.1000,\n",
      "          0.1000, 22.7296, 22.8400, 22.8716,  0.1000, 22.8400, 22.8716,  0.1000,\n",
      "         22.7296, 22.8716]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 116 was 96.8%\n",
      "current params: tensor([22.7296, 22.8400, 22.7816, 22.8716], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.7\n",
      "SLow rates:  tensor([[22.8495, 22.9597, 22.9014, 22.9911,  0.1000,  0.1000,  0.1000, 22.8495,\n",
      "         22.8495, 22.8495,  0.1000,  0.1000, 22.9597, 22.9597, 22.9597,  0.1000,\n",
      "          0.1000, 22.9597, 22.9597,  0.1000, 22.9014, 22.9014, 22.9014,  0.1000,\n",
      "          0.1000, 22.9014, 22.9014,  0.1000, 22.9014,  0.1000, 22.9014, 22.9911,\n",
      "         22.9911, 22.9911,  0.1000,  0.1000, 22.9911, 22.9911,  0.1000, 22.9911,\n",
      "          0.1000, 22.9911, 22.9597, 22.9911, 22.9911, 22.9911, 22.9014, 22.9911,\n",
      "         22.9911, 22.9911, 22.9597, 22.9911, 22.9911, 22.9911, 22.9597, 22.9014,\n",
      "         22.9597, 22.9597, 22.9597,  0.1000, 22.9597, 22.9014,  0.1000, 22.9014,\n",
      "         22.9911,  0.1000, 22.9911, 22.9911, 22.9911, 22.9597, 22.9597,  0.1000,\n",
      "         22.9911,  0.1000, 22.8495, 22.8495, 22.9597, 22.9911, 22.9911,  0.1000,\n",
      "          0.1000, 22.8495, 22.9597, 22.9911,  0.1000, 22.9597, 22.9911,  0.1000,\n",
      "         22.8495, 22.9911]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 117 was 96.8%\n",
      "current params: tensor([22.8495, 22.9597, 22.9014, 22.9911], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.7\n",
      "SLow rates:  tensor([[22.9690, 23.0791, 23.0208, 23.1104,  0.1000,  0.1000,  0.1000, 22.9690,\n",
      "         22.9690, 22.9690,  0.1000,  0.1000, 23.0791, 23.0791, 23.0791,  0.1000,\n",
      "          0.1000, 23.0791, 23.0791,  0.1000, 23.0208, 23.0208, 23.0208,  0.1000,\n",
      "          0.1000, 23.0208, 23.0208,  0.1000, 23.0208,  0.1000, 23.0208, 23.1104,\n",
      "         23.1104, 23.1104,  0.1000,  0.1000, 23.1104, 23.1104,  0.1000, 23.1104,\n",
      "          0.1000, 23.1104, 23.0791, 23.1104, 23.1104, 23.1104, 23.0208, 23.1104,\n",
      "         23.1104, 23.1104, 23.0791, 23.1104, 23.1104, 23.1104, 23.0791, 23.0208,\n",
      "         23.0791, 23.0791, 23.0791,  0.1000, 23.0791, 23.0208,  0.1000, 23.0208,\n",
      "         23.1104,  0.1000, 23.1104, 23.1104, 23.1104, 23.0791, 23.0791,  0.1000,\n",
      "         23.1104,  0.1000, 22.9690, 22.9690, 23.0791, 23.1104, 23.1104,  0.1000,\n",
      "          0.1000, 22.9690, 23.0791, 23.1104,  0.1000, 23.0791, 23.1104,  0.1000,\n",
      "         22.9690, 23.1104]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 118 was 96.8%\n",
      "current params: tensor([22.9690, 23.0791, 23.0208, 23.1104], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.7\n",
      "SLow rates:  tensor([[23.0883, 23.1983, 23.1400, 23.2295,  0.1000,  0.1000,  0.1000, 23.0883,\n",
      "         23.0883, 23.0883,  0.1000,  0.1000, 23.1983, 23.1983, 23.1983,  0.1000,\n",
      "          0.1000, 23.1983, 23.1983,  0.1000, 23.1400, 23.1400, 23.1400,  0.1000,\n",
      "          0.1000, 23.1400, 23.1400,  0.1000, 23.1400,  0.1000, 23.1400, 23.2295,\n",
      "         23.2295, 23.2295,  0.1000,  0.1000, 23.2295, 23.2295,  0.1000, 23.2295,\n",
      "          0.1000, 23.2295, 23.1983, 23.2295, 23.2295, 23.2295, 23.1400, 23.2295,\n",
      "         23.2295, 23.2295, 23.1983, 23.2295, 23.2295, 23.2295, 23.1983, 23.1400,\n",
      "         23.1983, 23.1983, 23.1983,  0.1000, 23.1983, 23.1400,  0.1000, 23.1400,\n",
      "         23.2295,  0.1000, 23.2295, 23.2295, 23.2295, 23.1983, 23.1983,  0.1000,\n",
      "         23.2295,  0.1000, 23.0883, 23.0883, 23.1983, 23.2295, 23.2295,  0.1000,\n",
      "          0.1000, 23.0883, 23.1983, 23.2295,  0.1000, 23.1983, 23.2295,  0.1000,\n",
      "         23.0883, 23.2295]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 119 was 96.9%\n",
      "current params: tensor([23.0883, 23.1983, 23.1400, 23.2295], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.7\n",
      "SLow rates:  tensor([[23.2074, 23.3172, 23.2590, 23.3483,  0.1000,  0.1000,  0.1000, 23.2074,\n",
      "         23.2074, 23.2074,  0.1000,  0.1000, 23.3172, 23.3172, 23.3172,  0.1000,\n",
      "          0.1000, 23.3172, 23.3172,  0.1000, 23.2590, 23.2590, 23.2590,  0.1000,\n",
      "          0.1000, 23.2590, 23.2590,  0.1000, 23.2590,  0.1000, 23.2590, 23.3483,\n",
      "         23.3483, 23.3483,  0.1000,  0.1000, 23.3483, 23.3483,  0.1000, 23.3483,\n",
      "          0.1000, 23.3483, 23.3172, 23.3483, 23.3483, 23.3483, 23.2590, 23.3483,\n",
      "         23.3483, 23.3483, 23.3172, 23.3483, 23.3483, 23.3483, 23.3172, 23.2590,\n",
      "         23.3172, 23.3172, 23.3172,  0.1000, 23.3172, 23.2590,  0.1000, 23.2590,\n",
      "         23.3483,  0.1000, 23.3483, 23.3483, 23.3483, 23.3172, 23.3172,  0.1000,\n",
      "         23.3483,  0.1000, 23.2074, 23.2074, 23.3172, 23.3483, 23.3483,  0.1000,\n",
      "          0.1000, 23.2074, 23.3172, 23.3483,  0.1000, 23.3172, 23.3483,  0.1000,\n",
      "         23.2074, 23.3483]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 120 was 96.9%\n",
      "current params: tensor([23.2074, 23.3172, 23.2590, 23.3483], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.7\n",
      "SLow rates:  tensor([[23.3262, 23.4359, 23.3777, 23.4668,  0.1000,  0.1000,  0.1000, 23.3262,\n",
      "         23.3262, 23.3262,  0.1000,  0.1000, 23.4359, 23.4359, 23.4359,  0.1000,\n",
      "          0.1000, 23.4359, 23.4359,  0.1000, 23.3777, 23.3777, 23.3777,  0.1000,\n",
      "          0.1000, 23.3777, 23.3777,  0.1000, 23.3777,  0.1000, 23.3777, 23.4668,\n",
      "         23.4668, 23.4668,  0.1000,  0.1000, 23.4668, 23.4668,  0.1000, 23.4668,\n",
      "          0.1000, 23.4668, 23.4359, 23.4668, 23.4668, 23.4668, 23.3777, 23.4668,\n",
      "         23.4668, 23.4668, 23.4359, 23.4668, 23.4668, 23.4668, 23.4359, 23.3777,\n",
      "         23.4359, 23.4359, 23.4359,  0.1000, 23.4359, 23.3777,  0.1000, 23.3777,\n",
      "         23.4668,  0.1000, 23.4668, 23.4668, 23.4668, 23.4359, 23.4359,  0.1000,\n",
      "         23.4668,  0.1000, 23.3262, 23.3262, 23.4359, 23.4668, 23.4668,  0.1000,\n",
      "          0.1000, 23.3262, 23.4359, 23.4668,  0.1000, 23.4359, 23.4668,  0.1000,\n",
      "         23.3262, 23.4668]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 121 was 96.9%\n",
      "current params: tensor([23.3262, 23.4359, 23.3777, 23.4668], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.8\n",
      "SLow rates:  tensor([[23.4448, 23.5544, 23.4962, 23.5851,  0.1000,  0.1000,  0.1000, 23.4448,\n",
      "         23.4448, 23.4448,  0.1000,  0.1000, 23.5544, 23.5544, 23.5544,  0.1000,\n",
      "          0.1000, 23.5544, 23.5544,  0.1000, 23.4962, 23.4962, 23.4962,  0.1000,\n",
      "          0.1000, 23.4962, 23.4962,  0.1000, 23.4962,  0.1000, 23.4962, 23.5851,\n",
      "         23.5851, 23.5851,  0.1000,  0.1000, 23.5851, 23.5851,  0.1000, 23.5851,\n",
      "          0.1000, 23.5851, 23.5544, 23.5851, 23.5851, 23.5851, 23.4962, 23.5851,\n",
      "         23.5851, 23.5851, 23.5544, 23.5851, 23.5851, 23.5851, 23.5544, 23.4962,\n",
      "         23.5544, 23.5544, 23.5544,  0.1000, 23.5544, 23.4962,  0.1000, 23.4962,\n",
      "         23.5851,  0.1000, 23.5851, 23.5851, 23.5851, 23.5544, 23.5544,  0.1000,\n",
      "         23.5851,  0.1000, 23.4448, 23.4448, 23.5544, 23.5851, 23.5851,  0.1000,\n",
      "          0.1000, 23.4448, 23.5544, 23.5851,  0.1000, 23.5544, 23.5851,  0.1000,\n",
      "         23.4448, 23.5851]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 122 was 96.9%\n",
      "current params: tensor([23.4448, 23.5544, 23.4962, 23.5851], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.8\n",
      "SLow rates:  tensor([[23.5631, 23.6726, 23.6144, 23.7032,  0.1000,  0.1000,  0.1000, 23.5631,\n",
      "         23.5631, 23.5631,  0.1000,  0.1000, 23.6726, 23.6726, 23.6726,  0.1000,\n",
      "          0.1000, 23.6726, 23.6726,  0.1000, 23.6144, 23.6144, 23.6144,  0.1000,\n",
      "          0.1000, 23.6144, 23.6144,  0.1000, 23.6144,  0.1000, 23.6144, 23.7032,\n",
      "         23.7032, 23.7032,  0.1000,  0.1000, 23.7032, 23.7032,  0.1000, 23.7032,\n",
      "          0.1000, 23.7032, 23.6726, 23.7032, 23.7032, 23.7032, 23.6144, 23.7032,\n",
      "         23.7032, 23.7032, 23.6726, 23.7032, 23.7032, 23.7032, 23.6726, 23.6144,\n",
      "         23.6726, 23.6726, 23.6726,  0.1000, 23.6726, 23.6144,  0.1000, 23.6144,\n",
      "         23.7032,  0.1000, 23.7032, 23.7032, 23.7032, 23.6726, 23.6726,  0.1000,\n",
      "         23.7032,  0.1000, 23.5631, 23.5631, 23.6726, 23.7032, 23.7032,  0.1000,\n",
      "          0.1000, 23.5631, 23.6726, 23.7032,  0.1000, 23.6726, 23.7032,  0.1000,\n",
      "         23.5631, 23.7032]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 123 was 96.9%\n",
      "current params: tensor([23.5631, 23.6726, 23.6144, 23.7032], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.8\n",
      "SLow rates:  tensor([[23.6812, 23.7905, 23.7324, 23.8210,  0.1000,  0.1000,  0.1000, 23.6812,\n",
      "         23.6812, 23.6812,  0.1000,  0.1000, 23.7905, 23.7905, 23.7905,  0.1000,\n",
      "          0.1000, 23.7905, 23.7905,  0.1000, 23.7324, 23.7324, 23.7324,  0.1000,\n",
      "          0.1000, 23.7324, 23.7324,  0.1000, 23.7324,  0.1000, 23.7324, 23.8210,\n",
      "         23.8210, 23.8210,  0.1000,  0.1000, 23.8210, 23.8210,  0.1000, 23.8210,\n",
      "          0.1000, 23.8210, 23.7905, 23.8210, 23.8210, 23.8210, 23.7324, 23.8210,\n",
      "         23.8210, 23.8210, 23.7905, 23.8210, 23.8210, 23.8210, 23.7905, 23.7324,\n",
      "         23.7905, 23.7905, 23.7905,  0.1000, 23.7905, 23.7324,  0.1000, 23.7324,\n",
      "         23.8210,  0.1000, 23.8210, 23.8210, 23.8210, 23.7905, 23.7905,  0.1000,\n",
      "         23.8210,  0.1000, 23.6812, 23.6812, 23.7905, 23.8210, 23.8210,  0.1000,\n",
      "          0.1000, 23.6812, 23.7905, 23.8210,  0.1000, 23.7905, 23.8210,  0.1000,\n",
      "         23.6812, 23.8210]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 124 was 96.9%\n",
      "current params: tensor([23.6812, 23.7905, 23.7324, 23.8210], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.8\n",
      "SLow rates:  tensor([[23.7990, 23.9083, 23.8501, 23.9387,  0.1000,  0.1000,  0.1000, 23.7990,\n",
      "         23.7990, 23.7990,  0.1000,  0.1000, 23.9083, 23.9083, 23.9083,  0.1000,\n",
      "          0.1000, 23.9083, 23.9083,  0.1000, 23.8501, 23.8501, 23.8501,  0.1000,\n",
      "          0.1000, 23.8501, 23.8501,  0.1000, 23.8501,  0.1000, 23.8501, 23.9387,\n",
      "         23.9387, 23.9387,  0.1000,  0.1000, 23.9387, 23.9387,  0.1000, 23.9387,\n",
      "          0.1000, 23.9387, 23.9083, 23.9387, 23.9387, 23.9387, 23.8501, 23.9387,\n",
      "         23.9387, 23.9387, 23.9083, 23.9387, 23.9387, 23.9387, 23.9083, 23.8501,\n",
      "         23.9083, 23.9083, 23.9083,  0.1000, 23.9083, 23.8501,  0.1000, 23.8501,\n",
      "         23.9387,  0.1000, 23.9387, 23.9387, 23.9387, 23.9083, 23.9083,  0.1000,\n",
      "         23.9387,  0.1000, 23.7990, 23.7990, 23.9083, 23.9387, 23.9387,  0.1000,\n",
      "          0.1000, 23.7990, 23.9083, 23.9387,  0.1000, 23.9083, 23.9387,  0.1000,\n",
      "         23.7990, 23.9387]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 125 was 96.9%\n",
      "current params: tensor([23.7990, 23.9083, 23.8501, 23.9387], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.8\n",
      "SLow rates:  tensor([[23.9166, 24.0258, 23.9676, 24.0560,  0.1000,  0.1000,  0.1000, 23.9166,\n",
      "         23.9166, 23.9166,  0.1000,  0.1000, 24.0258, 24.0258, 24.0258,  0.1000,\n",
      "          0.1000, 24.0258, 24.0258,  0.1000, 23.9676, 23.9676, 23.9676,  0.1000,\n",
      "          0.1000, 23.9676, 23.9676,  0.1000, 23.9676,  0.1000, 23.9676, 24.0560,\n",
      "         24.0560, 24.0560,  0.1000,  0.1000, 24.0560, 24.0560,  0.1000, 24.0560,\n",
      "          0.1000, 24.0560, 24.0258, 24.0560, 24.0560, 24.0560, 23.9676, 24.0560,\n",
      "         24.0560, 24.0560, 24.0258, 24.0560, 24.0560, 24.0560, 24.0258, 23.9676,\n",
      "         24.0258, 24.0258, 24.0258,  0.1000, 24.0258, 23.9676,  0.1000, 23.9676,\n",
      "         24.0560,  0.1000, 24.0560, 24.0560, 24.0560, 24.0258, 24.0258,  0.1000,\n",
      "         24.0560,  0.1000, 23.9166, 23.9166, 24.0258, 24.0560, 24.0560,  0.1000,\n",
      "          0.1000, 23.9166, 24.0258, 24.0560,  0.1000, 24.0258, 24.0560,  0.1000,\n",
      "         23.9166, 24.0560]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 126 was 97.0%\n",
      "current params: tensor([23.9166, 24.0258, 23.9676, 24.0560], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.9\n",
      "SLow rates:  tensor([[24.0340, 24.1431, 24.0849, 24.1732,  0.1000,  0.1000,  0.1000, 24.0340,\n",
      "         24.0340, 24.0340,  0.1000,  0.1000, 24.1431, 24.1431, 24.1431,  0.1000,\n",
      "          0.1000, 24.1431, 24.1431,  0.1000, 24.0849, 24.0849, 24.0849,  0.1000,\n",
      "          0.1000, 24.0849, 24.0849,  0.1000, 24.0849,  0.1000, 24.0849, 24.1732,\n",
      "         24.1732, 24.1732,  0.1000,  0.1000, 24.1732, 24.1732,  0.1000, 24.1732,\n",
      "          0.1000, 24.1732, 24.1431, 24.1732, 24.1732, 24.1732, 24.0849, 24.1732,\n",
      "         24.1732, 24.1732, 24.1431, 24.1732, 24.1732, 24.1732, 24.1431, 24.0849,\n",
      "         24.1431, 24.1431, 24.1431,  0.1000, 24.1431, 24.0849,  0.1000, 24.0849,\n",
      "         24.1732,  0.1000, 24.1732, 24.1732, 24.1732, 24.1431, 24.1431,  0.1000,\n",
      "         24.1732,  0.1000, 24.0340, 24.0340, 24.1431, 24.1732, 24.1732,  0.1000,\n",
      "          0.1000, 24.0340, 24.1431, 24.1732,  0.1000, 24.1431, 24.1732,  0.1000,\n",
      "         24.0340, 24.1732]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 127 was 97.0%\n",
      "current params: tensor([24.0340, 24.1431, 24.0849, 24.1732], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.9\n",
      "SLow rates:  tensor([[24.1512, 24.2601, 24.2020, 24.2901,  0.1000,  0.1000,  0.1000, 24.1512,\n",
      "         24.1512, 24.1512,  0.1000,  0.1000, 24.2601, 24.2601, 24.2601,  0.1000,\n",
      "          0.1000, 24.2601, 24.2601,  0.1000, 24.2020, 24.2020, 24.2020,  0.1000,\n",
      "          0.1000, 24.2020, 24.2020,  0.1000, 24.2020,  0.1000, 24.2020, 24.2901,\n",
      "         24.2901, 24.2901,  0.1000,  0.1000, 24.2901, 24.2901,  0.1000, 24.2901,\n",
      "          0.1000, 24.2901, 24.2601, 24.2901, 24.2901, 24.2901, 24.2020, 24.2901,\n",
      "         24.2901, 24.2901, 24.2601, 24.2901, 24.2901, 24.2901, 24.2601, 24.2020,\n",
      "         24.2601, 24.2601, 24.2601,  0.1000, 24.2601, 24.2020,  0.1000, 24.2020,\n",
      "         24.2901,  0.1000, 24.2901, 24.2901, 24.2901, 24.2601, 24.2601,  0.1000,\n",
      "         24.2901,  0.1000, 24.1512, 24.1512, 24.2601, 24.2901, 24.2901,  0.1000,\n",
      "          0.1000, 24.1512, 24.2601, 24.2901,  0.1000, 24.2601, 24.2901,  0.1000,\n",
      "         24.1512, 24.2901]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 128 was 97.0%\n",
      "current params: tensor([24.1512, 24.2601, 24.2020, 24.2901], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.9\n",
      "SLow rates:  tensor([[24.2682, 24.3770, 24.3189, 24.4069,  0.1000,  0.1000,  0.1000, 24.2682,\n",
      "         24.2682, 24.2682,  0.1000,  0.1000, 24.3770, 24.3770, 24.3770,  0.1000,\n",
      "          0.1000, 24.3770, 24.3770,  0.1000, 24.3189, 24.3189, 24.3189,  0.1000,\n",
      "          0.1000, 24.3189, 24.3189,  0.1000, 24.3189,  0.1000, 24.3189, 24.4069,\n",
      "         24.4069, 24.4069,  0.1000,  0.1000, 24.4069, 24.4069,  0.1000, 24.4069,\n",
      "          0.1000, 24.4069, 24.3770, 24.4069, 24.4069, 24.4069, 24.3189, 24.4069,\n",
      "         24.4069, 24.4069, 24.3770, 24.4069, 24.4069, 24.4069, 24.3770, 24.3189,\n",
      "         24.3770, 24.3770, 24.3770,  0.1000, 24.3770, 24.3189,  0.1000, 24.3189,\n",
      "         24.4069,  0.1000, 24.4069, 24.4069, 24.4069, 24.3770, 24.3770,  0.1000,\n",
      "         24.4069,  0.1000, 24.2682, 24.2682, 24.3770, 24.4069, 24.4069,  0.1000,\n",
      "          0.1000, 24.2682, 24.3770, 24.4069,  0.1000, 24.3770, 24.4069,  0.1000,\n",
      "         24.2682, 24.4069]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0746, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 129 was 97.0%\n",
      "current params: tensor([24.2682, 24.3770, 24.3189, 24.4069], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.9\n",
      "SLow rates:  tensor([[24.3849, 24.4936, 24.4355, 24.5234,  0.1000,  0.1000,  0.1000, 24.3849,\n",
      "         24.3849, 24.3849,  0.1000,  0.1000, 24.4936, 24.4936, 24.4936,  0.1000,\n",
      "          0.1000, 24.4936, 24.4936,  0.1000, 24.4355, 24.4355, 24.4355,  0.1000,\n",
      "          0.1000, 24.4355, 24.4355,  0.1000, 24.4355,  0.1000, 24.4355, 24.5234,\n",
      "         24.5234, 24.5234,  0.1000,  0.1000, 24.5234, 24.5234,  0.1000, 24.5234,\n",
      "          0.1000, 24.5234, 24.4936, 24.5234, 24.5234, 24.5234, 24.4355, 24.5234,\n",
      "         24.5234, 24.5234, 24.4936, 24.5234, 24.5234, 24.5234, 24.4936, 24.4355,\n",
      "         24.4936, 24.4936, 24.4936,  0.1000, 24.4936, 24.4355,  0.1000, 24.4355,\n",
      "         24.5234,  0.1000, 24.5234, 24.5234, 24.5234, 24.4936, 24.4936,  0.1000,\n",
      "         24.5234,  0.1000, 24.3849, 24.3849, 24.4936, 24.5234, 24.5234,  0.1000,\n",
      "          0.1000, 24.3849, 24.4936, 24.5234,  0.1000, 24.4936, 24.5234,  0.1000,\n",
      "         24.3849, 24.5234]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 130 was 97.0%\n",
      "current params: tensor([24.3849, 24.4936, 24.4355, 24.5234], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  7.9\n",
      "SLow rates:  tensor([[24.5014, 24.6100, 24.5520, 24.6397,  0.1000,  0.1000,  0.1000, 24.5014,\n",
      "         24.5014, 24.5014,  0.1000,  0.1000, 24.6100, 24.6100, 24.6100,  0.1000,\n",
      "          0.1000, 24.6100, 24.6100,  0.1000, 24.5520, 24.5520, 24.5520,  0.1000,\n",
      "          0.1000, 24.5520, 24.5520,  0.1000, 24.5520,  0.1000, 24.5520, 24.6397,\n",
      "         24.6397, 24.6397,  0.1000,  0.1000, 24.6397, 24.6397,  0.1000, 24.6397,\n",
      "          0.1000, 24.6397, 24.6100, 24.6397, 24.6397, 24.6397, 24.5520, 24.6397,\n",
      "         24.6397, 24.6397, 24.6100, 24.6397, 24.6397, 24.6397, 24.6100, 24.5520,\n",
      "         24.6100, 24.6100, 24.6100,  0.1000, 24.6100, 24.5520,  0.1000, 24.5520,\n",
      "         24.6397,  0.1000, 24.6397, 24.6397, 24.6397, 24.6100, 24.6100,  0.1000,\n",
      "         24.6397,  0.1000, 24.5014, 24.5014, 24.6100, 24.6397, 24.6397,  0.1000,\n",
      "          0.1000, 24.5014, 24.6100, 24.6397,  0.1000, 24.6100, 24.6397,  0.1000,\n",
      "         24.5014, 24.6397]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 131 was 97.0%\n",
      "current params: tensor([24.5014, 24.6100, 24.5520, 24.6397], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.0\n",
      "SLow rates:  tensor([[24.6178, 24.7262, 24.6682, 24.7558,  0.1000,  0.1000,  0.1000, 24.6178,\n",
      "         24.6178, 24.6178,  0.1000,  0.1000, 24.7262, 24.7262, 24.7262,  0.1000,\n",
      "          0.1000, 24.7262, 24.7262,  0.1000, 24.6682, 24.6682, 24.6682,  0.1000,\n",
      "          0.1000, 24.6682, 24.6682,  0.1000, 24.6682,  0.1000, 24.6682, 24.7558,\n",
      "         24.7558, 24.7558,  0.1000,  0.1000, 24.7558, 24.7558,  0.1000, 24.7558,\n",
      "          0.1000, 24.7558, 24.7262, 24.7558, 24.7558, 24.7558, 24.6682, 24.7558,\n",
      "         24.7558, 24.7558, 24.7262, 24.7558, 24.7558, 24.7558, 24.7262, 24.6682,\n",
      "         24.7262, 24.7262, 24.7262,  0.1000, 24.7262, 24.6682,  0.1000, 24.6682,\n",
      "         24.7558,  0.1000, 24.7558, 24.7558, 24.7558, 24.7262, 24.7262,  0.1000,\n",
      "         24.7558,  0.1000, 24.6178, 24.6178, 24.7262, 24.7558, 24.7558,  0.1000,\n",
      "          0.1000, 24.6178, 24.7262, 24.7558,  0.1000, 24.7262, 24.7558,  0.1000,\n",
      "         24.6178, 24.7558]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 132 was 97.0%\n",
      "current params: tensor([24.6178, 24.7262, 24.6682, 24.7558], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.0\n",
      "SLow rates:  tensor([[24.7340, 24.8423, 24.7841, 24.8717,  0.1000,  0.1000,  0.1000, 24.7340,\n",
      "         24.7340, 24.7340,  0.1000,  0.1000, 24.8423, 24.8423, 24.8423,  0.1000,\n",
      "          0.1000, 24.8423, 24.8423,  0.1000, 24.7841, 24.7841, 24.7841,  0.1000,\n",
      "          0.1000, 24.7841, 24.7841,  0.1000, 24.7841,  0.1000, 24.7841, 24.8717,\n",
      "         24.8717, 24.8717,  0.1000,  0.1000, 24.8717, 24.8717,  0.1000, 24.8717,\n",
      "          0.1000, 24.8717, 24.8423, 24.8717, 24.8717, 24.8717, 24.7841, 24.8717,\n",
      "         24.8717, 24.8717, 24.8423, 24.8717, 24.8717, 24.8717, 24.8423, 24.7841,\n",
      "         24.8423, 24.8423, 24.8423,  0.1000, 24.8423, 24.7841,  0.1000, 24.7841,\n",
      "         24.8717,  0.1000, 24.8717, 24.8717, 24.8717, 24.8423, 24.8423,  0.1000,\n",
      "         24.8717,  0.1000, 24.7340, 24.7340, 24.8423, 24.8717, 24.8717,  0.1000,\n",
      "          0.1000, 24.7340, 24.8423, 24.8717,  0.1000, 24.8423, 24.8717,  0.1000,\n",
      "         24.7340, 24.8717]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 133 was 97.1%\n",
      "current params: tensor([24.7340, 24.8423, 24.7841, 24.8717], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.0\n",
      "SLow rates:  tensor([[24.8499, 24.9581, 24.8999, 24.9874,  0.1000,  0.1000,  0.1000, 24.8499,\n",
      "         24.8499, 24.8499,  0.1000,  0.1000, 24.9581, 24.9581, 24.9581,  0.1000,\n",
      "          0.1000, 24.9581, 24.9581,  0.1000, 24.8999, 24.8999, 24.8999,  0.1000,\n",
      "          0.1000, 24.8999, 24.8999,  0.1000, 24.8999,  0.1000, 24.8999, 24.9874,\n",
      "         24.9874, 24.9874,  0.1000,  0.1000, 24.9874, 24.9874,  0.1000, 24.9874,\n",
      "          0.1000, 24.9874, 24.9581, 24.9874, 24.9874, 24.9874, 24.8999, 24.9874,\n",
      "         24.9874, 24.9874, 24.9581, 24.9874, 24.9874, 24.9874, 24.9581, 24.8999,\n",
      "         24.9581, 24.9581, 24.9581,  0.1000, 24.9581, 24.8999,  0.1000, 24.8999,\n",
      "         24.9874,  0.1000, 24.9874, 24.9874, 24.9874, 24.9581, 24.9581,  0.1000,\n",
      "         24.9874,  0.1000, 24.8499, 24.8499, 24.9581, 24.9874, 24.9874,  0.1000,\n",
      "          0.1000, 24.8499, 24.9581, 24.9874,  0.1000, 24.9581, 24.9874,  0.1000,\n",
      "         24.8499, 24.9874]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 134 was 97.1%\n",
      "current params: tensor([24.8499, 24.9581, 24.8999, 24.9874], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.0\n",
      "SLow rates:  tensor([[24.9656, 25.0737, 25.0156, 25.1029,  0.1000,  0.1000,  0.1000, 24.9656,\n",
      "         24.9656, 24.9656,  0.1000,  0.1000, 25.0737, 25.0737, 25.0737,  0.1000,\n",
      "          0.1000, 25.0737, 25.0737,  0.1000, 25.0156, 25.0156, 25.0156,  0.1000,\n",
      "          0.1000, 25.0156, 25.0156,  0.1000, 25.0156,  0.1000, 25.0156, 25.1029,\n",
      "         25.1029, 25.1029,  0.1000,  0.1000, 25.1029, 25.1029,  0.1000, 25.1029,\n",
      "          0.1000, 25.1029, 25.0737, 25.1029, 25.1029, 25.1029, 25.0156, 25.1029,\n",
      "         25.1029, 25.1029, 25.0737, 25.1029, 25.1029, 25.1029, 25.0737, 25.0156,\n",
      "         25.0737, 25.0737, 25.0737,  0.1000, 25.0737, 25.0156,  0.1000, 25.0156,\n",
      "         25.1029,  0.1000, 25.1029, 25.1029, 25.1029, 25.0737, 25.0737,  0.1000,\n",
      "         25.1029,  0.1000, 24.9656, 24.9656, 25.0737, 25.1029, 25.1029,  0.1000,\n",
      "          0.1000, 24.9656, 25.0737, 25.1029,  0.1000, 25.0737, 25.1029,  0.1000,\n",
      "         24.9656, 25.1029]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 135 was 97.1%\n",
      "current params: tensor([24.9656, 25.0737, 25.0156, 25.1029], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.1\n",
      "SLow rates:  tensor([[25.0811, 25.1891, 25.1310, 25.2182,  0.1000,  0.1000,  0.1000, 25.0811,\n",
      "         25.0811, 25.0811,  0.1000,  0.1000, 25.1891, 25.1891, 25.1891,  0.1000,\n",
      "          0.1000, 25.1891, 25.1891,  0.1000, 25.1310, 25.1310, 25.1310,  0.1000,\n",
      "          0.1000, 25.1310, 25.1310,  0.1000, 25.1310,  0.1000, 25.1310, 25.2182,\n",
      "         25.2182, 25.2182,  0.1000,  0.1000, 25.2182, 25.2182,  0.1000, 25.2182,\n",
      "          0.1000, 25.2182, 25.1891, 25.2182, 25.2182, 25.2182, 25.1310, 25.2182,\n",
      "         25.2182, 25.2182, 25.1891, 25.2182, 25.2182, 25.2182, 25.1891, 25.1310,\n",
      "         25.1891, 25.1891, 25.1891,  0.1000, 25.1891, 25.1310,  0.1000, 25.1310,\n",
      "         25.2182,  0.1000, 25.2182, 25.2182, 25.2182, 25.1891, 25.1891,  0.1000,\n",
      "         25.2182,  0.1000, 25.0811, 25.0811, 25.1891, 25.2182, 25.2182,  0.1000,\n",
      "          0.1000, 25.0811, 25.1891, 25.2182,  0.1000, 25.1891, 25.2182,  0.1000,\n",
      "         25.0811, 25.2182]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 136 was 97.1%\n",
      "current params: tensor([25.0811, 25.1891, 25.1310, 25.2182], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.1\n",
      "SLow rates:  tensor([[25.1964, 25.3043, 25.2462, 25.3333,  0.1000,  0.1000,  0.1000, 25.1964,\n",
      "         25.1964, 25.1964,  0.1000,  0.1000, 25.3043, 25.3043, 25.3043,  0.1000,\n",
      "          0.1000, 25.3043, 25.3043,  0.1000, 25.2462, 25.2462, 25.2462,  0.1000,\n",
      "          0.1000, 25.2462, 25.2462,  0.1000, 25.2462,  0.1000, 25.2462, 25.3333,\n",
      "         25.3333, 25.3333,  0.1000,  0.1000, 25.3333, 25.3333,  0.1000, 25.3333,\n",
      "          0.1000, 25.3333, 25.3043, 25.3333, 25.3333, 25.3333, 25.2462, 25.3333,\n",
      "         25.3333, 25.3333, 25.3043, 25.3333, 25.3333, 25.3333, 25.3043, 25.2462,\n",
      "         25.3043, 25.3043, 25.3043,  0.1000, 25.3043, 25.2462,  0.1000, 25.2462,\n",
      "         25.3333,  0.1000, 25.3333, 25.3333, 25.3333, 25.3043, 25.3043,  0.1000,\n",
      "         25.3333,  0.1000, 25.1964, 25.1964, 25.3043, 25.3333, 25.3333,  0.1000,\n",
      "          0.1000, 25.1964, 25.3043, 25.3333,  0.1000, 25.3043, 25.3333,  0.1000,\n",
      "         25.1964, 25.3333]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 137 was 97.1%\n",
      "current params: tensor([25.1964, 25.3043, 25.2462, 25.3333], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.1\n",
      "SLow rates:  tensor([[25.3116, 25.4194, 25.3613, 25.4482,  0.1000,  0.1000,  0.1000, 25.3116,\n",
      "         25.3116, 25.3116,  0.1000,  0.1000, 25.4194, 25.4194, 25.4194,  0.1000,\n",
      "          0.1000, 25.4194, 25.4194,  0.1000, 25.3613, 25.3613, 25.3613,  0.1000,\n",
      "          0.1000, 25.3613, 25.3613,  0.1000, 25.3613,  0.1000, 25.3613, 25.4482,\n",
      "         25.4482, 25.4482,  0.1000,  0.1000, 25.4482, 25.4482,  0.1000, 25.4482,\n",
      "          0.1000, 25.4482, 25.4194, 25.4482, 25.4482, 25.4482, 25.3613, 25.4482,\n",
      "         25.4482, 25.4482, 25.4194, 25.4482, 25.4482, 25.4482, 25.4194, 25.3613,\n",
      "         25.4194, 25.4194, 25.4194,  0.1000, 25.4194, 25.3613,  0.1000, 25.3613,\n",
      "         25.4482,  0.1000, 25.4482, 25.4482, 25.4482, 25.4194, 25.4194,  0.1000,\n",
      "         25.4482,  0.1000, 25.3116, 25.3116, 25.4194, 25.4482, 25.4482,  0.1000,\n",
      "          0.1000, 25.3116, 25.4194, 25.4482,  0.1000, 25.4194, 25.4482,  0.1000,\n",
      "         25.3116, 25.4482]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 138 was 97.1%\n",
      "current params: tensor([25.3116, 25.4194, 25.3613, 25.4482], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.1\n",
      "SLow rates:  tensor([[25.4265, 25.5342, 25.4761, 25.5629,  0.1000,  0.1000,  0.1000, 25.4265,\n",
      "         25.4265, 25.4265,  0.1000,  0.1000, 25.5342, 25.5342, 25.5342,  0.1000,\n",
      "          0.1000, 25.5342, 25.5342,  0.1000, 25.4761, 25.4761, 25.4761,  0.1000,\n",
      "          0.1000, 25.4761, 25.4761,  0.1000, 25.4761,  0.1000, 25.4761, 25.5629,\n",
      "         25.5629, 25.5629,  0.1000,  0.1000, 25.5629, 25.5629,  0.1000, 25.5629,\n",
      "          0.1000, 25.5629, 25.5342, 25.5629, 25.5629, 25.5629, 25.4761, 25.5629,\n",
      "         25.5629, 25.5629, 25.5342, 25.5629, 25.5629, 25.5629, 25.5342, 25.4761,\n",
      "         25.5342, 25.5342, 25.5342,  0.1000, 25.5342, 25.4761,  0.1000, 25.4761,\n",
      "         25.5629,  0.1000, 25.5629, 25.5629, 25.5629, 25.5342, 25.5342,  0.1000,\n",
      "         25.5629,  0.1000, 25.4265, 25.4265, 25.5342, 25.5629, 25.5629,  0.1000,\n",
      "          0.1000, 25.4265, 25.5342, 25.5629,  0.1000, 25.5342, 25.5629,  0.1000,\n",
      "         25.4265, 25.5629]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 139 was 97.1%\n",
      "current params: tensor([25.4265, 25.5342, 25.4761, 25.5629], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.1\n",
      "SLow rates:  tensor([[25.5413, 25.6489, 25.5908, 25.6775,  0.1000,  0.1000,  0.1000, 25.5413,\n",
      "         25.5413, 25.5413,  0.1000,  0.1000, 25.6489, 25.6489, 25.6489,  0.1000,\n",
      "          0.1000, 25.6489, 25.6489,  0.1000, 25.5908, 25.5908, 25.5908,  0.1000,\n",
      "          0.1000, 25.5908, 25.5908,  0.1000, 25.5908,  0.1000, 25.5908, 25.6775,\n",
      "         25.6775, 25.6775,  0.1000,  0.1000, 25.6775, 25.6775,  0.1000, 25.6775,\n",
      "          0.1000, 25.6775, 25.6489, 25.6775, 25.6775, 25.6775, 25.5908, 25.6775,\n",
      "         25.6775, 25.6775, 25.6489, 25.6775, 25.6775, 25.6775, 25.6489, 25.5908,\n",
      "         25.6489, 25.6489, 25.6489,  0.1000, 25.6489, 25.5908,  0.1000, 25.5908,\n",
      "         25.6775,  0.1000, 25.6775, 25.6775, 25.6775, 25.6489, 25.6489,  0.1000,\n",
      "         25.6775,  0.1000, 25.5413, 25.5413, 25.6489, 25.6775, 25.6775,  0.1000,\n",
      "          0.1000, 25.5413, 25.6489, 25.6775,  0.1000, 25.6489, 25.6775,  0.1000,\n",
      "         25.5413, 25.6775]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 140 was 97.1%\n",
      "current params: tensor([25.5413, 25.6489, 25.5908, 25.6775], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.2\n",
      "SLow rates:  tensor([[25.6558, 25.7633, 25.7053, 25.7918,  0.1000,  0.1000,  0.1000, 25.6558,\n",
      "         25.6558, 25.6558,  0.1000,  0.1000, 25.7633, 25.7633, 25.7633,  0.1000,\n",
      "          0.1000, 25.7633, 25.7633,  0.1000, 25.7053, 25.7053, 25.7053,  0.1000,\n",
      "          0.1000, 25.7053, 25.7053,  0.1000, 25.7053,  0.1000, 25.7053, 25.7918,\n",
      "         25.7918, 25.7918,  0.1000,  0.1000, 25.7918, 25.7918,  0.1000, 25.7918,\n",
      "          0.1000, 25.7918, 25.7633, 25.7918, 25.7918, 25.7918, 25.7053, 25.7918,\n",
      "         25.7918, 25.7918, 25.7633, 25.7918, 25.7918, 25.7918, 25.7633, 25.7053,\n",
      "         25.7633, 25.7633, 25.7633,  0.1000, 25.7633, 25.7053,  0.1000, 25.7053,\n",
      "         25.7918,  0.1000, 25.7918, 25.7918, 25.7918, 25.7633, 25.7633,  0.1000,\n",
      "         25.7918,  0.1000, 25.6558, 25.6558, 25.7633, 25.7918, 25.7918,  0.1000,\n",
      "          0.1000, 25.6558, 25.7633, 25.7918,  0.1000, 25.7633, 25.7918,  0.1000,\n",
      "         25.6558, 25.7918]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 141 was 97.1%\n",
      "current params: tensor([25.6558, 25.7633, 25.7053, 25.7918], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.2\n",
      "SLow rates:  tensor([[25.7702, 25.8776, 25.8196, 25.9060,  0.1000,  0.1000,  0.1000, 25.7702,\n",
      "         25.7702, 25.7702,  0.1000,  0.1000, 25.8776, 25.8776, 25.8776,  0.1000,\n",
      "          0.1000, 25.8776, 25.8776,  0.1000, 25.8196, 25.8196, 25.8196,  0.1000,\n",
      "          0.1000, 25.8196, 25.8196,  0.1000, 25.8196,  0.1000, 25.8196, 25.9060,\n",
      "         25.9060, 25.9060,  0.1000,  0.1000, 25.9060, 25.9060,  0.1000, 25.9060,\n",
      "          0.1000, 25.9060, 25.8776, 25.9060, 25.9060, 25.9060, 25.8196, 25.9060,\n",
      "         25.9060, 25.9060, 25.8776, 25.9060, 25.9060, 25.9060, 25.8776, 25.8196,\n",
      "         25.8776, 25.8776, 25.8776,  0.1000, 25.8776, 25.8196,  0.1000, 25.8196,\n",
      "         25.9060,  0.1000, 25.9060, 25.9060, 25.9060, 25.8776, 25.8776,  0.1000,\n",
      "         25.9060,  0.1000, 25.7702, 25.7702, 25.8776, 25.9060, 25.9060,  0.1000,\n",
      "          0.1000, 25.7702, 25.8776, 25.9060,  0.1000, 25.8776, 25.9060,  0.1000,\n",
      "         25.7702, 25.9060]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 142 was 97.2%\n",
      "current params: tensor([25.7702, 25.8776, 25.8196, 25.9060], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.2\n",
      "SLow rates:  tensor([[25.8845, 25.9917, 25.9338, 26.0200,  0.1000,  0.1000,  0.1000, 25.8845,\n",
      "         25.8845, 25.8845,  0.1000,  0.1000, 25.9917, 25.9917, 25.9917,  0.1000,\n",
      "          0.1000, 25.9917, 25.9917,  0.1000, 25.9338, 25.9338, 25.9338,  0.1000,\n",
      "          0.1000, 25.9338, 25.9338,  0.1000, 25.9338,  0.1000, 25.9338, 26.0200,\n",
      "         26.0200, 26.0200,  0.1000,  0.1000, 26.0200, 26.0200,  0.1000, 26.0200,\n",
      "          0.1000, 26.0200, 25.9917, 26.0200, 26.0200, 26.0200, 25.9338, 26.0200,\n",
      "         26.0200, 26.0200, 25.9917, 26.0200, 26.0200, 26.0200, 25.9917, 25.9338,\n",
      "         25.9917, 25.9917, 25.9917,  0.1000, 25.9917, 25.9338,  0.1000, 25.9338,\n",
      "         26.0200,  0.1000, 26.0200, 26.0200, 26.0200, 25.9917, 25.9917,  0.1000,\n",
      "         26.0200,  0.1000, 25.8845, 25.8845, 25.9917, 26.0200, 26.0200,  0.1000,\n",
      "          0.1000, 25.8845, 25.9917, 26.0200,  0.1000, 25.9917, 26.0200,  0.1000,\n",
      "         25.8845, 26.0200]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 143 was 97.2%\n",
      "current params: tensor([25.8845, 25.9917, 25.9338, 26.0200], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.2\n",
      "SLow rates:  tensor([[25.9985, 26.1057, 26.0478, 26.1339,  0.1000,  0.1000,  0.1000, 25.9985,\n",
      "         25.9985, 25.9985,  0.1000,  0.1000, 26.1057, 26.1057, 26.1057,  0.1000,\n",
      "          0.1000, 26.1057, 26.1057,  0.1000, 26.0478, 26.0478, 26.0478,  0.1000,\n",
      "          0.1000, 26.0478, 26.0478,  0.1000, 26.0478,  0.1000, 26.0478, 26.1339,\n",
      "         26.1339, 26.1339,  0.1000,  0.1000, 26.1339, 26.1339,  0.1000, 26.1339,\n",
      "          0.1000, 26.1339, 26.1057, 26.1339, 26.1339, 26.1339, 26.0478, 26.1339,\n",
      "         26.1339, 26.1339, 26.1057, 26.1339, 26.1339, 26.1339, 26.1057, 26.0478,\n",
      "         26.1057, 26.1057, 26.1057,  0.1000, 26.1057, 26.0478,  0.1000, 26.0478,\n",
      "         26.1339,  0.1000, 26.1339, 26.1339, 26.1339, 26.1057, 26.1057,  0.1000,\n",
      "         26.1339,  0.1000, 25.9985, 25.9985, 26.1057, 26.1339, 26.1339,  0.1000,\n",
      "          0.1000, 25.9985, 26.1057, 26.1339,  0.1000, 26.1057, 26.1339,  0.1000,\n",
      "         25.9985, 26.1339]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 144 was 97.2%\n",
      "current params: tensor([25.9985, 26.1057, 26.0478, 26.1339], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.2\n",
      "SLow rates:  tensor([[26.1124, 26.2195, 26.1616, 26.2476,  0.1000,  0.1000,  0.1000, 26.1124,\n",
      "         26.1124, 26.1124,  0.1000,  0.1000, 26.2195, 26.2195, 26.2195,  0.1000,\n",
      "          0.1000, 26.2195, 26.2195,  0.1000, 26.1616, 26.1616, 26.1616,  0.1000,\n",
      "          0.1000, 26.1616, 26.1616,  0.1000, 26.1616,  0.1000, 26.1616, 26.2476,\n",
      "         26.2476, 26.2476,  0.1000,  0.1000, 26.2476, 26.2476,  0.1000, 26.2476,\n",
      "          0.1000, 26.2476, 26.2195, 26.2476, 26.2476, 26.2476, 26.1616, 26.2476,\n",
      "         26.2476, 26.2476, 26.2195, 26.2476, 26.2476, 26.2476, 26.2195, 26.1616,\n",
      "         26.2195, 26.2195, 26.2195,  0.1000, 26.2195, 26.1616,  0.1000, 26.1616,\n",
      "         26.2476,  0.1000, 26.2476, 26.2476, 26.2476, 26.2195, 26.2195,  0.1000,\n",
      "         26.2476,  0.1000, 26.1124, 26.1124, 26.2195, 26.2476, 26.2476,  0.1000,\n",
      "          0.1000, 26.1124, 26.2195, 26.2476,  0.1000, 26.2195, 26.2476,  0.1000,\n",
      "         26.1124, 26.2476]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 145 was 97.2%\n",
      "current params: tensor([26.1124, 26.2195, 26.1616, 26.2476], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.3\n",
      "SLow rates:  tensor([[26.2261, 26.3331, 26.2752, 26.3611,  0.1000,  0.1000,  0.1000, 26.2261,\n",
      "         26.2261, 26.2261,  0.1000,  0.1000, 26.3331, 26.3331, 26.3331,  0.1000,\n",
      "          0.1000, 26.3331, 26.3331,  0.1000, 26.2752, 26.2752, 26.2752,  0.1000,\n",
      "          0.1000, 26.2752, 26.2752,  0.1000, 26.2752,  0.1000, 26.2752, 26.3611,\n",
      "         26.3611, 26.3611,  0.1000,  0.1000, 26.3611, 26.3611,  0.1000, 26.3611,\n",
      "          0.1000, 26.3611, 26.3331, 26.3611, 26.3611, 26.3611, 26.2752, 26.3611,\n",
      "         26.3611, 26.3611, 26.3331, 26.3611, 26.3611, 26.3611, 26.3331, 26.2752,\n",
      "         26.3331, 26.3331, 26.3331,  0.1000, 26.3331, 26.2752,  0.1000, 26.2752,\n",
      "         26.3611,  0.1000, 26.3611, 26.3611, 26.3611, 26.3331, 26.3331,  0.1000,\n",
      "         26.3611,  0.1000, 26.2261, 26.2261, 26.3331, 26.3611, 26.3611,  0.1000,\n",
      "          0.1000, 26.2261, 26.3331, 26.3611,  0.1000, 26.3331, 26.3611,  0.1000,\n",
      "         26.2261, 26.3611]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 146 was 97.2%\n",
      "current params: tensor([26.2261, 26.3331, 26.2752, 26.3611], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.3\n",
      "SLow rates:  tensor([[26.3396, 26.4465, 26.3886, 26.4744,  0.1000,  0.1000,  0.1000, 26.3396,\n",
      "         26.3396, 26.3396,  0.1000,  0.1000, 26.4465, 26.4465, 26.4465,  0.1000,\n",
      "          0.1000, 26.4465, 26.4465,  0.1000, 26.3886, 26.3886, 26.3886,  0.1000,\n",
      "          0.1000, 26.3886, 26.3886,  0.1000, 26.3886,  0.1000, 26.3886, 26.4744,\n",
      "         26.4744, 26.4744,  0.1000,  0.1000, 26.4744, 26.4744,  0.1000, 26.4744,\n",
      "          0.1000, 26.4744, 26.4465, 26.4744, 26.4744, 26.4744, 26.3886, 26.4744,\n",
      "         26.4744, 26.4744, 26.4465, 26.4744, 26.4744, 26.4744, 26.4465, 26.3886,\n",
      "         26.4465, 26.4465, 26.4465,  0.1000, 26.4465, 26.3886,  0.1000, 26.3886,\n",
      "         26.4744,  0.1000, 26.4744, 26.4744, 26.4744, 26.4465, 26.4465,  0.1000,\n",
      "         26.4744,  0.1000, 26.3396, 26.3396, 26.4465, 26.4744, 26.4744,  0.1000,\n",
      "          0.1000, 26.3396, 26.4465, 26.4744,  0.1000, 26.4465, 26.4744,  0.1000,\n",
      "         26.3396, 26.4744]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 147 was 97.2%\n",
      "current params: tensor([26.3396, 26.4465, 26.3886, 26.4744], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.3\n",
      "SLow rates:  tensor([[26.4530, 26.5598, 26.5020, 26.5876,  0.1000,  0.1000,  0.1000, 26.4530,\n",
      "         26.4530, 26.4530,  0.1000,  0.1000, 26.5598, 26.5598, 26.5598,  0.1000,\n",
      "          0.1000, 26.5598, 26.5598,  0.1000, 26.5020, 26.5020, 26.5020,  0.1000,\n",
      "          0.1000, 26.5020, 26.5020,  0.1000, 26.5020,  0.1000, 26.5020, 26.5876,\n",
      "         26.5876, 26.5876,  0.1000,  0.1000, 26.5876, 26.5876,  0.1000, 26.5876,\n",
      "          0.1000, 26.5876, 26.5598, 26.5876, 26.5876, 26.5876, 26.5020, 26.5876,\n",
      "         26.5876, 26.5876, 26.5598, 26.5876, 26.5876, 26.5876, 26.5598, 26.5020,\n",
      "         26.5598, 26.5598, 26.5598,  0.1000, 26.5598, 26.5020,  0.1000, 26.5020,\n",
      "         26.5876,  0.1000, 26.5876, 26.5876, 26.5876, 26.5598, 26.5598,  0.1000,\n",
      "         26.5876,  0.1000, 26.4530, 26.4530, 26.5598, 26.5876, 26.5876,  0.1000,\n",
      "          0.1000, 26.4530, 26.5598, 26.5876,  0.1000, 26.5598, 26.5876,  0.1000,\n",
      "         26.4530, 26.5876]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 148 was 97.2%\n",
      "current params: tensor([26.4530, 26.5598, 26.5020, 26.5876], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.3\n",
      "SLow rates:  tensor([[26.5662, 26.6729, 26.6151, 26.7006,  0.1000,  0.1000,  0.1000, 26.5662,\n",
      "         26.5662, 26.5662,  0.1000,  0.1000, 26.6729, 26.6729, 26.6729,  0.1000,\n",
      "          0.1000, 26.6729, 26.6729,  0.1000, 26.6151, 26.6151, 26.6151,  0.1000,\n",
      "          0.1000, 26.6151, 26.6151,  0.1000, 26.6151,  0.1000, 26.6151, 26.7006,\n",
      "         26.7006, 26.7006,  0.1000,  0.1000, 26.7006, 26.7006,  0.1000, 26.7006,\n",
      "          0.1000, 26.7006, 26.6729, 26.7006, 26.7006, 26.7006, 26.6151, 26.7006,\n",
      "         26.7006, 26.7006, 26.6729, 26.7006, 26.7006, 26.7006, 26.6729, 26.6151,\n",
      "         26.6729, 26.6729, 26.6729,  0.1000, 26.6729, 26.6151,  0.1000, 26.6151,\n",
      "         26.7006,  0.1000, 26.7006, 26.7006, 26.7006, 26.6729, 26.6729,  0.1000,\n",
      "         26.7006,  0.1000, 26.5662, 26.5662, 26.6729, 26.7006, 26.7006,  0.1000,\n",
      "          0.1000, 26.5662, 26.6729, 26.7006,  0.1000, 26.6729, 26.7006,  0.1000,\n",
      "         26.5662, 26.7006]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 149 was 97.2%\n",
      "current params: tensor([26.5662, 26.6729, 26.6151, 26.7006], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.3\n",
      "SLow rates:  tensor([[26.6793, 26.7859, 26.7281, 26.8135,  0.1000,  0.1000,  0.1000, 26.6793,\n",
      "         26.6793, 26.6793,  0.1000,  0.1000, 26.7859, 26.7859, 26.7859,  0.1000,\n",
      "          0.1000, 26.7859, 26.7859,  0.1000, 26.7281, 26.7281, 26.7281,  0.1000,\n",
      "          0.1000, 26.7281, 26.7281,  0.1000, 26.7281,  0.1000, 26.7281, 26.8135,\n",
      "         26.8135, 26.8135,  0.1000,  0.1000, 26.8135, 26.8135,  0.1000, 26.8135,\n",
      "          0.1000, 26.8135, 26.7859, 26.8135, 26.8135, 26.8135, 26.7281, 26.8135,\n",
      "         26.8135, 26.8135, 26.7859, 26.8135, 26.8135, 26.8135, 26.7859, 26.7281,\n",
      "         26.7859, 26.7859, 26.7859,  0.1000, 26.7859, 26.7281,  0.1000, 26.7281,\n",
      "         26.8135,  0.1000, 26.8135, 26.8135, 26.8135, 26.7859, 26.7859,  0.1000,\n",
      "         26.8135,  0.1000, 26.6793, 26.6793, 26.7859, 26.8135, 26.8135,  0.1000,\n",
      "          0.1000, 26.6793, 26.7859, 26.8135,  0.1000, 26.7859, 26.8135,  0.1000,\n",
      "         26.6793, 26.8135]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 150 was 97.3%\n",
      "current params: tensor([26.6793, 26.7859, 26.7281, 26.8135], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.4\n",
      "SLow rates:  tensor([[26.7922, 26.8987, 26.8409, 26.9262,  0.1000,  0.1000,  0.1000, 26.7922,\n",
      "         26.7922, 26.7922,  0.1000,  0.1000, 26.8987, 26.8987, 26.8987,  0.1000,\n",
      "          0.1000, 26.8987, 26.8987,  0.1000, 26.8409, 26.8409, 26.8409,  0.1000,\n",
      "          0.1000, 26.8409, 26.8409,  0.1000, 26.8409,  0.1000, 26.8409, 26.9262,\n",
      "         26.9262, 26.9262,  0.1000,  0.1000, 26.9262, 26.9262,  0.1000, 26.9262,\n",
      "          0.1000, 26.9262, 26.8987, 26.9262, 26.9262, 26.9262, 26.8409, 26.9262,\n",
      "         26.9262, 26.9262, 26.8987, 26.9262, 26.9262, 26.9262, 26.8987, 26.8409,\n",
      "         26.8987, 26.8987, 26.8987,  0.1000, 26.8987, 26.8409,  0.1000, 26.8409,\n",
      "         26.9262,  0.1000, 26.9262, 26.9262, 26.9262, 26.8987, 26.8987,  0.1000,\n",
      "         26.9262,  0.1000, 26.7922, 26.7922, 26.8987, 26.9262, 26.9262,  0.1000,\n",
      "          0.1000, 26.7922, 26.8987, 26.9262,  0.1000, 26.8987, 26.9262,  0.1000,\n",
      "         26.7922, 26.9262]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 151 was 97.3%\n",
      "current params: tensor([26.7922, 26.8987, 26.8409, 26.9262], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.4\n",
      "SLow rates:  tensor([[26.9049, 27.0113, 26.9536, 27.0387,  0.1000,  0.1000,  0.1000, 26.9049,\n",
      "         26.9049, 26.9049,  0.1000,  0.1000, 27.0113, 27.0113, 27.0113,  0.1000,\n",
      "          0.1000, 27.0113, 27.0113,  0.1000, 26.9536, 26.9536, 26.9536,  0.1000,\n",
      "          0.1000, 26.9536, 26.9536,  0.1000, 26.9536,  0.1000, 26.9536, 27.0387,\n",
      "         27.0387, 27.0387,  0.1000,  0.1000, 27.0387, 27.0387,  0.1000, 27.0387,\n",
      "          0.1000, 27.0387, 27.0113, 27.0387, 27.0387, 27.0387, 26.9536, 27.0387,\n",
      "         27.0387, 27.0387, 27.0113, 27.0387, 27.0387, 27.0387, 27.0113, 26.9536,\n",
      "         27.0113, 27.0113, 27.0113,  0.1000, 27.0113, 26.9536,  0.1000, 26.9536,\n",
      "         27.0387,  0.1000, 27.0387, 27.0387, 27.0387, 27.0113, 27.0113,  0.1000,\n",
      "         27.0387,  0.1000, 26.9049, 26.9049, 27.0113, 27.0387, 27.0387,  0.1000,\n",
      "          0.1000, 26.9049, 27.0113, 27.0387,  0.1000, 27.0113, 27.0387,  0.1000,\n",
      "         26.9049, 27.0387]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 152 was 97.3%\n",
      "current params: tensor([26.9049, 27.0113, 26.9536, 27.0387], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.4\n",
      "SLow rates:  tensor([[27.0175, 27.1238, 27.0661, 27.1511,  0.1000,  0.1000,  0.1000, 27.0175,\n",
      "         27.0175, 27.0175,  0.1000,  0.1000, 27.1238, 27.1238, 27.1238,  0.1000,\n",
      "          0.1000, 27.1238, 27.1238,  0.1000, 27.0661, 27.0661, 27.0661,  0.1000,\n",
      "          0.1000, 27.0661, 27.0661,  0.1000, 27.0661,  0.1000, 27.0661, 27.1511,\n",
      "         27.1511, 27.1511,  0.1000,  0.1000, 27.1511, 27.1511,  0.1000, 27.1511,\n",
      "          0.1000, 27.1511, 27.1238, 27.1511, 27.1511, 27.1511, 27.0661, 27.1511,\n",
      "         27.1511, 27.1511, 27.1238, 27.1511, 27.1511, 27.1511, 27.1238, 27.0661,\n",
      "         27.1238, 27.1238, 27.1238,  0.1000, 27.1238, 27.0661,  0.1000, 27.0661,\n",
      "         27.1511,  0.1000, 27.1511, 27.1511, 27.1511, 27.1238, 27.1238,  0.1000,\n",
      "         27.1511,  0.1000, 27.0175, 27.0175, 27.1238, 27.1511, 27.1511,  0.1000,\n",
      "          0.1000, 27.0175, 27.1238, 27.1511,  0.1000, 27.1238, 27.1511,  0.1000,\n",
      "         27.0175, 27.1511]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 153 was 97.3%\n",
      "current params: tensor([27.0175, 27.1238, 27.0661, 27.1511], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.4\n",
      "SLow rates:  tensor([[27.1299, 27.2362, 27.1785, 27.2634,  0.1000,  0.1000,  0.1000, 27.1299,\n",
      "         27.1299, 27.1299,  0.1000,  0.1000, 27.2362, 27.2362, 27.2362,  0.1000,\n",
      "          0.1000, 27.2362, 27.2362,  0.1000, 27.1785, 27.1785, 27.1785,  0.1000,\n",
      "          0.1000, 27.1785, 27.1785,  0.1000, 27.1785,  0.1000, 27.1785, 27.2634,\n",
      "         27.2634, 27.2634,  0.1000,  0.1000, 27.2634, 27.2634,  0.1000, 27.2634,\n",
      "          0.1000, 27.2634, 27.2362, 27.2634, 27.2634, 27.2634, 27.1785, 27.2634,\n",
      "         27.2634, 27.2634, 27.2362, 27.2634, 27.2634, 27.2634, 27.2362, 27.1785,\n",
      "         27.2362, 27.2362, 27.2362,  0.1000, 27.2362, 27.1785,  0.1000, 27.1785,\n",
      "         27.2634,  0.1000, 27.2634, 27.2634, 27.2634, 27.2362, 27.2362,  0.1000,\n",
      "         27.2634,  0.1000, 27.1299, 27.1299, 27.2362, 27.2634, 27.2634,  0.1000,\n",
      "          0.1000, 27.1299, 27.2362, 27.2634,  0.1000, 27.2362, 27.2634,  0.1000,\n",
      "         27.1299, 27.2634]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 154 was 97.3%\n",
      "current params: tensor([27.1299, 27.2362, 27.1785, 27.2634], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.4\n",
      "SLow rates:  tensor([[27.2422, 27.3484, 27.2907, 27.3755,  0.1000,  0.1000,  0.1000, 27.2422,\n",
      "         27.2422, 27.2422,  0.1000,  0.1000, 27.3484, 27.3484, 27.3484,  0.1000,\n",
      "          0.1000, 27.3484, 27.3484,  0.1000, 27.2907, 27.2907, 27.2907,  0.1000,\n",
      "          0.1000, 27.2907, 27.2907,  0.1000, 27.2907,  0.1000, 27.2907, 27.3755,\n",
      "         27.3755, 27.3755,  0.1000,  0.1000, 27.3755, 27.3755,  0.1000, 27.3755,\n",
      "          0.1000, 27.3755, 27.3484, 27.3755, 27.3755, 27.3755, 27.2907, 27.3755,\n",
      "         27.3755, 27.3755, 27.3484, 27.3755, 27.3755, 27.3755, 27.3484, 27.2907,\n",
      "         27.3484, 27.3484, 27.3484,  0.1000, 27.3484, 27.2907,  0.1000, 27.2907,\n",
      "         27.3755,  0.1000, 27.3755, 27.3755, 27.3755, 27.3484, 27.3484,  0.1000,\n",
      "         27.3755,  0.1000, 27.2422, 27.2422, 27.3484, 27.3755, 27.3755,  0.1000,\n",
      "          0.1000, 27.2422, 27.3484, 27.3755,  0.1000, 27.3484, 27.3755,  0.1000,\n",
      "         27.2422, 27.3755]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 155 was 97.3%\n",
      "current params: tensor([27.2422, 27.3484, 27.2907, 27.3755], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.5\n",
      "SLow rates:  tensor([[27.3543, 27.4604, 27.4027, 27.4875,  0.1000,  0.1000,  0.1000, 27.3543,\n",
      "         27.3543, 27.3543,  0.1000,  0.1000, 27.4604, 27.4604, 27.4604,  0.1000,\n",
      "          0.1000, 27.4604, 27.4604,  0.1000, 27.4027, 27.4027, 27.4027,  0.1000,\n",
      "          0.1000, 27.4027, 27.4027,  0.1000, 27.4027,  0.1000, 27.4027, 27.4875,\n",
      "         27.4875, 27.4875,  0.1000,  0.1000, 27.4875, 27.4875,  0.1000, 27.4875,\n",
      "          0.1000, 27.4875, 27.4604, 27.4875, 27.4875, 27.4875, 27.4027, 27.4875,\n",
      "         27.4875, 27.4875, 27.4604, 27.4875, 27.4875, 27.4875, 27.4604, 27.4027,\n",
      "         27.4604, 27.4604, 27.4604,  0.1000, 27.4604, 27.4027,  0.1000, 27.4027,\n",
      "         27.4875,  0.1000, 27.4875, 27.4875, 27.4875, 27.4604, 27.4604,  0.1000,\n",
      "         27.4875,  0.1000, 27.3543, 27.3543, 27.4604, 27.4875, 27.4875,  0.1000,\n",
      "          0.1000, 27.3543, 27.4604, 27.4875,  0.1000, 27.4604, 27.4875,  0.1000,\n",
      "         27.3543, 27.4875]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 156 was 97.3%\n",
      "current params: tensor([27.3543, 27.4604, 27.4027, 27.4875], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.5\n",
      "SLow rates:  tensor([[27.4663, 27.5723, 27.5147, 27.5993,  0.1000,  0.1000,  0.1000, 27.4663,\n",
      "         27.4663, 27.4663,  0.1000,  0.1000, 27.5723, 27.5723, 27.5723,  0.1000,\n",
      "          0.1000, 27.5723, 27.5723,  0.1000, 27.5147, 27.5147, 27.5147,  0.1000,\n",
      "          0.1000, 27.5147, 27.5147,  0.1000, 27.5147,  0.1000, 27.5147, 27.5993,\n",
      "         27.5993, 27.5993,  0.1000,  0.1000, 27.5993, 27.5993,  0.1000, 27.5993,\n",
      "          0.1000, 27.5993, 27.5723, 27.5993, 27.5993, 27.5993, 27.5147, 27.5993,\n",
      "         27.5993, 27.5993, 27.5723, 27.5993, 27.5993, 27.5993, 27.5723, 27.5147,\n",
      "         27.5723, 27.5723, 27.5723,  0.1000, 27.5723, 27.5147,  0.1000, 27.5147,\n",
      "         27.5993,  0.1000, 27.5993, 27.5993, 27.5993, 27.5723, 27.5723,  0.1000,\n",
      "         27.5993,  0.1000, 27.4663, 27.4663, 27.5723, 27.5993, 27.5993,  0.1000,\n",
      "          0.1000, 27.4663, 27.5723, 27.5993,  0.1000, 27.5723, 27.5993,  0.1000,\n",
      "         27.4663, 27.5993]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 157 was 97.3%\n",
      "current params: tensor([27.4663, 27.5723, 27.5147, 27.5993], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.5\n",
      "SLow rates:  tensor([[27.5782, 27.6841, 27.6265, 27.7110,  0.1000,  0.1000,  0.1000, 27.5782,\n",
      "         27.5782, 27.5782,  0.1000,  0.1000, 27.6841, 27.6841, 27.6841,  0.1000,\n",
      "          0.1000, 27.6841, 27.6841,  0.1000, 27.6265, 27.6265, 27.6265,  0.1000,\n",
      "          0.1000, 27.6265, 27.6265,  0.1000, 27.6265,  0.1000, 27.6265, 27.7110,\n",
      "         27.7110, 27.7110,  0.1000,  0.1000, 27.7110, 27.7110,  0.1000, 27.7110,\n",
      "          0.1000, 27.7110, 27.6841, 27.7110, 27.7110, 27.7110, 27.6265, 27.7110,\n",
      "         27.7110, 27.7110, 27.6841, 27.7110, 27.7110, 27.7110, 27.6841, 27.6265,\n",
      "         27.6841, 27.6841, 27.6841,  0.1000, 27.6841, 27.6265,  0.1000, 27.6265,\n",
      "         27.7110,  0.1000, 27.7110, 27.7110, 27.7110, 27.6841, 27.6841,  0.1000,\n",
      "         27.7110,  0.1000, 27.5782, 27.5782, 27.6841, 27.7110, 27.7110,  0.1000,\n",
      "          0.1000, 27.5782, 27.6841, 27.7110,  0.1000, 27.6841, 27.7110,  0.1000,\n",
      "         27.5782, 27.7110]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 158 was 97.3%\n",
      "current params: tensor([27.5782, 27.6841, 27.6265, 27.7110], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.5\n",
      "SLow rates:  tensor([[27.6899, 27.7957, 27.7381, 27.8225,  0.1000,  0.1000,  0.1000, 27.6899,\n",
      "         27.6899, 27.6899,  0.1000,  0.1000, 27.7957, 27.7957, 27.7957,  0.1000,\n",
      "          0.1000, 27.7957, 27.7957,  0.1000, 27.7381, 27.7381, 27.7381,  0.1000,\n",
      "          0.1000, 27.7381, 27.7381,  0.1000, 27.7381,  0.1000, 27.7381, 27.8225,\n",
      "         27.8225, 27.8225,  0.1000,  0.1000, 27.8225, 27.8225,  0.1000, 27.8225,\n",
      "          0.1000, 27.8225, 27.7957, 27.8225, 27.8225, 27.8225, 27.7381, 27.8225,\n",
      "         27.8225, 27.8225, 27.7957, 27.8225, 27.8225, 27.8225, 27.7957, 27.7381,\n",
      "         27.7957, 27.7957, 27.7957,  0.1000, 27.7957, 27.7381,  0.1000, 27.7381,\n",
      "         27.8225,  0.1000, 27.8225, 27.8225, 27.8225, 27.7957, 27.7957,  0.1000,\n",
      "         27.8225,  0.1000, 27.6899, 27.6899, 27.7957, 27.8225, 27.8225,  0.1000,\n",
      "          0.1000, 27.6899, 27.7957, 27.8225,  0.1000, 27.7957, 27.8225,  0.1000,\n",
      "         27.6899, 27.8225]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 159 was 97.3%\n",
      "current params: tensor([27.6899, 27.7957, 27.7381, 27.8225], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.5\n",
      "SLow rates:  tensor([[27.8015, 27.9072, 27.8496, 27.9339,  0.1000,  0.1000,  0.1000, 27.8015,\n",
      "         27.8015, 27.8015,  0.1000,  0.1000, 27.9072, 27.9072, 27.9072,  0.1000,\n",
      "          0.1000, 27.9072, 27.9072,  0.1000, 27.8496, 27.8496, 27.8496,  0.1000,\n",
      "          0.1000, 27.8496, 27.8496,  0.1000, 27.8496,  0.1000, 27.8496, 27.9339,\n",
      "         27.9339, 27.9339,  0.1000,  0.1000, 27.9339, 27.9339,  0.1000, 27.9339,\n",
      "          0.1000, 27.9339, 27.9072, 27.9339, 27.9339, 27.9339, 27.8496, 27.9339,\n",
      "         27.9339, 27.9339, 27.9072, 27.9339, 27.9339, 27.9339, 27.9072, 27.8496,\n",
      "         27.9072, 27.9072, 27.9072,  0.1000, 27.9072, 27.8496,  0.1000, 27.8496,\n",
      "         27.9339,  0.1000, 27.9339, 27.9339, 27.9339, 27.9072, 27.9072,  0.1000,\n",
      "         27.9339,  0.1000, 27.8015, 27.8015, 27.9072, 27.9339, 27.9339,  0.1000,\n",
      "          0.1000, 27.8015, 27.9072, 27.9339,  0.1000, 27.9072, 27.9339,  0.1000,\n",
      "         27.8015, 27.9339]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 160 was 97.4%\n",
      "current params: tensor([27.8015, 27.9072, 27.8496, 27.9339], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.6\n",
      "SLow rates:  tensor([[27.9129, 28.0186, 27.9610, 28.0452,  0.1000,  0.1000,  0.1000, 27.9129,\n",
      "         27.9129, 27.9129,  0.1000,  0.1000, 28.0186, 28.0186, 28.0186,  0.1000,\n",
      "          0.1000, 28.0186, 28.0186,  0.1000, 27.9610, 27.9610, 27.9610,  0.1000,\n",
      "          0.1000, 27.9610, 27.9610,  0.1000, 27.9610,  0.1000, 27.9610, 28.0452,\n",
      "         28.0452, 28.0452,  0.1000,  0.1000, 28.0452, 28.0452,  0.1000, 28.0452,\n",
      "          0.1000, 28.0452, 28.0186, 28.0452, 28.0452, 28.0452, 27.9610, 28.0452,\n",
      "         28.0452, 28.0452, 28.0186, 28.0452, 28.0452, 28.0452, 28.0186, 27.9610,\n",
      "         28.0186, 28.0186, 28.0186,  0.1000, 28.0186, 27.9610,  0.1000, 27.9610,\n",
      "         28.0452,  0.1000, 28.0452, 28.0452, 28.0452, 28.0186, 28.0186,  0.1000,\n",
      "         28.0452,  0.1000, 27.9129, 27.9129, 28.0186, 28.0452, 28.0452,  0.1000,\n",
      "          0.1000, 27.9129, 28.0186, 28.0452,  0.1000, 28.0186, 28.0452,  0.1000,\n",
      "         27.9129, 28.0452]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 161 was 97.4%\n",
      "current params: tensor([27.9129, 28.0186, 27.9610, 28.0452], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.6\n",
      "SLow rates:  tensor([[28.0242, 28.1298, 28.0722, 28.1563,  0.1000,  0.1000,  0.1000, 28.0242,\n",
      "         28.0242, 28.0242,  0.1000,  0.1000, 28.1298, 28.1298, 28.1298,  0.1000,\n",
      "          0.1000, 28.1298, 28.1298,  0.1000, 28.0722, 28.0722, 28.0722,  0.1000,\n",
      "          0.1000, 28.0722, 28.0722,  0.1000, 28.0722,  0.1000, 28.0722, 28.1563,\n",
      "         28.1563, 28.1563,  0.1000,  0.1000, 28.1563, 28.1563,  0.1000, 28.1563,\n",
      "          0.1000, 28.1563, 28.1298, 28.1563, 28.1563, 28.1563, 28.0722, 28.1563,\n",
      "         28.1563, 28.1563, 28.1298, 28.1563, 28.1563, 28.1563, 28.1298, 28.0722,\n",
      "         28.1298, 28.1298, 28.1298,  0.1000, 28.1298, 28.0722,  0.1000, 28.0722,\n",
      "         28.1563,  0.1000, 28.1563, 28.1563, 28.1563, 28.1298, 28.1298,  0.1000,\n",
      "         28.1563,  0.1000, 28.0242, 28.0242, 28.1298, 28.1563, 28.1563,  0.1000,\n",
      "          0.1000, 28.0242, 28.1298, 28.1563,  0.1000, 28.1298, 28.1563,  0.1000,\n",
      "         28.0242, 28.1563]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 162 was 97.4%\n",
      "current params: tensor([28.0242, 28.1298, 28.0722, 28.1563], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.6\n",
      "SLow rates:  tensor([[28.1354, 28.2409, 28.1833, 28.2673,  0.1000,  0.1000,  0.1000, 28.1354,\n",
      "         28.1354, 28.1354,  0.1000,  0.1000, 28.2409, 28.2409, 28.2409,  0.1000,\n",
      "          0.1000, 28.2409, 28.2409,  0.1000, 28.1833, 28.1833, 28.1833,  0.1000,\n",
      "          0.1000, 28.1833, 28.1833,  0.1000, 28.1833,  0.1000, 28.1833, 28.2673,\n",
      "         28.2673, 28.2673,  0.1000,  0.1000, 28.2673, 28.2673,  0.1000, 28.2673,\n",
      "          0.1000, 28.2673, 28.2409, 28.2673, 28.2673, 28.2673, 28.1833, 28.2673,\n",
      "         28.2673, 28.2673, 28.2409, 28.2673, 28.2673, 28.2673, 28.2409, 28.1833,\n",
      "         28.2409, 28.2409, 28.2409,  0.1000, 28.2409, 28.1833,  0.1000, 28.1833,\n",
      "         28.2673,  0.1000, 28.2673, 28.2673, 28.2673, 28.2409, 28.2409,  0.1000,\n",
      "         28.2673,  0.1000, 28.1354, 28.1354, 28.2409, 28.2673, 28.2673,  0.1000,\n",
      "          0.1000, 28.1354, 28.2409, 28.2673,  0.1000, 28.2409, 28.2673,  0.1000,\n",
      "         28.1354, 28.2673]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 163 was 97.4%\n",
      "current params: tensor([28.1354, 28.2409, 28.1833, 28.2673], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.6\n",
      "SLow rates:  tensor([[28.2464, 28.3518, 28.2943, 28.3782,  0.1000,  0.1000,  0.1000, 28.2464,\n",
      "         28.2464, 28.2464,  0.1000,  0.1000, 28.3518, 28.3518, 28.3518,  0.1000,\n",
      "          0.1000, 28.3518, 28.3518,  0.1000, 28.2943, 28.2943, 28.2943,  0.1000,\n",
      "          0.1000, 28.2943, 28.2943,  0.1000, 28.2943,  0.1000, 28.2943, 28.3782,\n",
      "         28.3782, 28.3782,  0.1000,  0.1000, 28.3782, 28.3782,  0.1000, 28.3782,\n",
      "          0.1000, 28.3782, 28.3518, 28.3782, 28.3782, 28.3782, 28.2943, 28.3782,\n",
      "         28.3782, 28.3782, 28.3518, 28.3782, 28.3782, 28.3782, 28.3518, 28.2943,\n",
      "         28.3518, 28.3518, 28.3518,  0.1000, 28.3518, 28.2943,  0.1000, 28.2943,\n",
      "         28.3782,  0.1000, 28.3782, 28.3782, 28.3782, 28.3518, 28.3518,  0.1000,\n",
      "         28.3782,  0.1000, 28.2464, 28.2464, 28.3518, 28.3782, 28.3782,  0.1000,\n",
      "          0.1000, 28.2464, 28.3518, 28.3782,  0.1000, 28.3518, 28.3782,  0.1000,\n",
      "         28.2464, 28.3782]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 164 was 97.4%\n",
      "current params: tensor([28.2464, 28.3518, 28.2943, 28.3782], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.6\n",
      "SLow rates:  tensor([[28.3573, 28.4626, 28.4052, 28.4889,  0.1000,  0.1000,  0.1000, 28.3573,\n",
      "         28.3573, 28.3573,  0.1000,  0.1000, 28.4626, 28.4626, 28.4626,  0.1000,\n",
      "          0.1000, 28.4626, 28.4626,  0.1000, 28.4052, 28.4052, 28.4052,  0.1000,\n",
      "          0.1000, 28.4052, 28.4052,  0.1000, 28.4052,  0.1000, 28.4052, 28.4889,\n",
      "         28.4889, 28.4889,  0.1000,  0.1000, 28.4889, 28.4889,  0.1000, 28.4889,\n",
      "          0.1000, 28.4889, 28.4626, 28.4889, 28.4889, 28.4889, 28.4052, 28.4889,\n",
      "         28.4889, 28.4889, 28.4626, 28.4889, 28.4889, 28.4889, 28.4626, 28.4052,\n",
      "         28.4626, 28.4626, 28.4626,  0.1000, 28.4626, 28.4052,  0.1000, 28.4052,\n",
      "         28.4889,  0.1000, 28.4889, 28.4889, 28.4889, 28.4626, 28.4626,  0.1000,\n",
      "         28.4889,  0.1000, 28.3573, 28.3573, 28.4626, 28.4889, 28.4889,  0.1000,\n",
      "          0.1000, 28.3573, 28.4626, 28.4889,  0.1000, 28.4626, 28.4889,  0.1000,\n",
      "         28.3573, 28.4889]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 165 was 97.4%\n",
      "current params: tensor([28.3573, 28.4626, 28.4052, 28.4889], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.7\n",
      "SLow rates:  tensor([[28.4681, 28.5733, 28.5159, 28.5995,  0.1000,  0.1000,  0.1000, 28.4681,\n",
      "         28.4681, 28.4681,  0.1000,  0.1000, 28.5733, 28.5733, 28.5733,  0.1000,\n",
      "          0.1000, 28.5733, 28.5733,  0.1000, 28.5159, 28.5159, 28.5159,  0.1000,\n",
      "          0.1000, 28.5159, 28.5159,  0.1000, 28.5159,  0.1000, 28.5159, 28.5995,\n",
      "         28.5995, 28.5995,  0.1000,  0.1000, 28.5995, 28.5995,  0.1000, 28.5995,\n",
      "          0.1000, 28.5995, 28.5733, 28.5995, 28.5995, 28.5995, 28.5159, 28.5995,\n",
      "         28.5995, 28.5995, 28.5733, 28.5995, 28.5995, 28.5995, 28.5733, 28.5159,\n",
      "         28.5733, 28.5733, 28.5733,  0.1000, 28.5733, 28.5159,  0.1000, 28.5159,\n",
      "         28.5995,  0.1000, 28.5995, 28.5995, 28.5995, 28.5733, 28.5733,  0.1000,\n",
      "         28.5995,  0.1000, 28.4681, 28.4681, 28.5733, 28.5995, 28.5995,  0.1000,\n",
      "          0.1000, 28.4681, 28.5733, 28.5995,  0.1000, 28.5733, 28.5995,  0.1000,\n",
      "         28.4681, 28.5995]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 166 was 97.4%\n",
      "current params: tensor([28.4681, 28.5733, 28.5159, 28.5995], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.7\n",
      "SLow rates:  tensor([[28.5788, 28.6839, 28.6265, 28.7100,  0.1000,  0.1000,  0.1000, 28.5788,\n",
      "         28.5788, 28.5788,  0.1000,  0.1000, 28.6839, 28.6839, 28.6839,  0.1000,\n",
      "          0.1000, 28.6839, 28.6839,  0.1000, 28.6265, 28.6265, 28.6265,  0.1000,\n",
      "          0.1000, 28.6265, 28.6265,  0.1000, 28.6265,  0.1000, 28.6265, 28.7100,\n",
      "         28.7100, 28.7100,  0.1000,  0.1000, 28.7100, 28.7100,  0.1000, 28.7100,\n",
      "          0.1000, 28.7100, 28.6839, 28.7100, 28.7100, 28.7100, 28.6265, 28.7100,\n",
      "         28.7100, 28.7100, 28.6839, 28.7100, 28.7100, 28.7100, 28.6839, 28.6265,\n",
      "         28.6839, 28.6839, 28.6839,  0.1000, 28.6839, 28.6265,  0.1000, 28.6265,\n",
      "         28.7100,  0.1000, 28.7100, 28.7100, 28.7100, 28.6839, 28.6839,  0.1000,\n",
      "         28.7100,  0.1000, 28.5788, 28.5788, 28.6839, 28.7100, 28.7100,  0.1000,\n",
      "          0.1000, 28.5788, 28.6839, 28.7100,  0.1000, 28.6839, 28.7100,  0.1000,\n",
      "         28.5788, 28.7100]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 167 was 97.4%\n",
      "current params: tensor([28.5788, 28.6839, 28.6265, 28.7100], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.7\n",
      "SLow rates:  tensor([[28.6893, 28.7944, 28.7369, 28.8204,  0.1000,  0.1000,  0.1000, 28.6893,\n",
      "         28.6893, 28.6893,  0.1000,  0.1000, 28.7944, 28.7944, 28.7944,  0.1000,\n",
      "          0.1000, 28.7944, 28.7944,  0.1000, 28.7369, 28.7369, 28.7369,  0.1000,\n",
      "          0.1000, 28.7369, 28.7369,  0.1000, 28.7369,  0.1000, 28.7369, 28.8204,\n",
      "         28.8204, 28.8204,  0.1000,  0.1000, 28.8204, 28.8204,  0.1000, 28.8204,\n",
      "          0.1000, 28.8204, 28.7944, 28.8204, 28.8204, 28.8204, 28.7369, 28.8204,\n",
      "         28.8204, 28.8204, 28.7944, 28.8204, 28.8204, 28.8204, 28.7944, 28.7369,\n",
      "         28.7944, 28.7944, 28.7944,  0.1000, 28.7944, 28.7369,  0.1000, 28.7369,\n",
      "         28.8204,  0.1000, 28.8204, 28.8204, 28.8204, 28.7944, 28.7944,  0.1000,\n",
      "         28.8204,  0.1000, 28.6893, 28.6893, 28.7944, 28.8204, 28.8204,  0.1000,\n",
      "          0.1000, 28.6893, 28.7944, 28.8204,  0.1000, 28.7944, 28.8204,  0.1000,\n",
      "         28.6893, 28.8204]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 168 was 97.4%\n",
      "current params: tensor([28.6893, 28.7944, 28.7369, 28.8204], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.7\n",
      "SLow rates:  tensor([[28.7997, 28.9047, 28.8473, 28.9306,  0.1000,  0.1000,  0.1000, 28.7997,\n",
      "         28.7997, 28.7997,  0.1000,  0.1000, 28.9047, 28.9047, 28.9047,  0.1000,\n",
      "          0.1000, 28.9047, 28.9047,  0.1000, 28.8473, 28.8473, 28.8473,  0.1000,\n",
      "          0.1000, 28.8473, 28.8473,  0.1000, 28.8473,  0.1000, 28.8473, 28.9306,\n",
      "         28.9306, 28.9306,  0.1000,  0.1000, 28.9306, 28.9306,  0.1000, 28.9306,\n",
      "          0.1000, 28.9306, 28.9047, 28.9306, 28.9306, 28.9306, 28.8473, 28.9306,\n",
      "         28.9306, 28.9306, 28.9047, 28.9306, 28.9306, 28.9306, 28.9047, 28.8473,\n",
      "         28.9047, 28.9047, 28.9047,  0.1000, 28.9047, 28.8473,  0.1000, 28.8473,\n",
      "         28.9306,  0.1000, 28.9306, 28.9306, 28.9306, 28.9047, 28.9047,  0.1000,\n",
      "         28.9306,  0.1000, 28.7997, 28.7997, 28.9047, 28.9306, 28.9306,  0.1000,\n",
      "          0.1000, 28.7997, 28.9047, 28.9306,  0.1000, 28.9047, 28.9306,  0.1000,\n",
      "         28.7997, 28.9306]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 169 was 97.4%\n",
      "current params: tensor([28.7997, 28.9047, 28.8473, 28.9306], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.7\n",
      "SLow rates:  tensor([[28.9100, 29.0149, 28.9575, 29.0407,  0.1000,  0.1000,  0.1000, 28.9100,\n",
      "         28.9100, 28.9100,  0.1000,  0.1000, 29.0149, 29.0149, 29.0149,  0.1000,\n",
      "          0.1000, 29.0149, 29.0149,  0.1000, 28.9575, 28.9575, 28.9575,  0.1000,\n",
      "          0.1000, 28.9575, 28.9575,  0.1000, 28.9575,  0.1000, 28.9575, 29.0407,\n",
      "         29.0407, 29.0407,  0.1000,  0.1000, 29.0407, 29.0407,  0.1000, 29.0407,\n",
      "          0.1000, 29.0407, 29.0149, 29.0407, 29.0407, 29.0407, 28.9575, 29.0407,\n",
      "         29.0407, 29.0407, 29.0149, 29.0407, 29.0407, 29.0407, 29.0149, 28.9575,\n",
      "         29.0149, 29.0149, 29.0149,  0.1000, 29.0149, 28.9575,  0.1000, 28.9575,\n",
      "         29.0407,  0.1000, 29.0407, 29.0407, 29.0407, 29.0149, 29.0149,  0.1000,\n",
      "         29.0407,  0.1000, 28.9100, 28.9100, 29.0149, 29.0407, 29.0407,  0.1000,\n",
      "          0.1000, 28.9100, 29.0149, 29.0407,  0.1000, 29.0149, 29.0407,  0.1000,\n",
      "         28.9100, 29.0407]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 170 was 97.4%\n",
      "current params: tensor([28.9100, 29.0149, 28.9575, 29.0407], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.8\n",
      "SLow rates:  tensor([[29.0201, 29.1250, 29.0676, 29.1508,  0.1000,  0.1000,  0.1000, 29.0201,\n",
      "         29.0201, 29.0201,  0.1000,  0.1000, 29.1250, 29.1250, 29.1250,  0.1000,\n",
      "          0.1000, 29.1250, 29.1250,  0.1000, 29.0676, 29.0676, 29.0676,  0.1000,\n",
      "          0.1000, 29.0676, 29.0676,  0.1000, 29.0676,  0.1000, 29.0676, 29.1508,\n",
      "         29.1508, 29.1508,  0.1000,  0.1000, 29.1508, 29.1508,  0.1000, 29.1508,\n",
      "          0.1000, 29.1508, 29.1250, 29.1508, 29.1508, 29.1508, 29.0676, 29.1508,\n",
      "         29.1508, 29.1508, 29.1250, 29.1508, 29.1508, 29.1508, 29.1250, 29.0676,\n",
      "         29.1250, 29.1250, 29.1250,  0.1000, 29.1250, 29.0676,  0.1000, 29.0676,\n",
      "         29.1508,  0.1000, 29.1508, 29.1508, 29.1508, 29.1250, 29.1250,  0.1000,\n",
      "         29.1508,  0.1000, 29.0201, 29.0201, 29.1250, 29.1508, 29.1508,  0.1000,\n",
      "          0.1000, 29.0201, 29.1250, 29.1508,  0.1000, 29.1250, 29.1508,  0.1000,\n",
      "         29.0201, 29.1508]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 171 was 97.5%\n",
      "current params: tensor([29.0201, 29.1250, 29.0676, 29.1508], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.8\n",
      "SLow rates:  tensor([[29.1302, 29.2349, 29.1776, 29.2607,  0.1000,  0.1000,  0.1000, 29.1302,\n",
      "         29.1302, 29.1302,  0.1000,  0.1000, 29.2349, 29.2349, 29.2349,  0.1000,\n",
      "          0.1000, 29.2349, 29.2349,  0.1000, 29.1776, 29.1776, 29.1776,  0.1000,\n",
      "          0.1000, 29.1776, 29.1776,  0.1000, 29.1776,  0.1000, 29.1776, 29.2607,\n",
      "         29.2607, 29.2607,  0.1000,  0.1000, 29.2607, 29.2607,  0.1000, 29.2607,\n",
      "          0.1000, 29.2607, 29.2349, 29.2607, 29.2607, 29.2607, 29.1776, 29.2607,\n",
      "         29.2607, 29.2607, 29.2349, 29.2607, 29.2607, 29.2607, 29.2349, 29.1776,\n",
      "         29.2349, 29.2349, 29.2349,  0.1000, 29.2349, 29.1776,  0.1000, 29.1776,\n",
      "         29.2607,  0.1000, 29.2607, 29.2607, 29.2607, 29.2349, 29.2349,  0.1000,\n",
      "         29.2607,  0.1000, 29.1302, 29.1302, 29.2349, 29.2607, 29.2607,  0.1000,\n",
      "          0.1000, 29.1302, 29.2349, 29.2607,  0.1000, 29.2349, 29.2607,  0.1000,\n",
      "         29.1302, 29.2607]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 172 was 97.5%\n",
      "current params: tensor([29.1302, 29.2349, 29.1776, 29.2607], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.8\n",
      "SLow rates:  tensor([[29.2401, 29.3448, 29.2875, 29.3704,  0.1000,  0.1000,  0.1000, 29.2401,\n",
      "         29.2401, 29.2401,  0.1000,  0.1000, 29.3448, 29.3448, 29.3448,  0.1000,\n",
      "          0.1000, 29.3448, 29.3448,  0.1000, 29.2875, 29.2875, 29.2875,  0.1000,\n",
      "          0.1000, 29.2875, 29.2875,  0.1000, 29.2875,  0.1000, 29.2875, 29.3704,\n",
      "         29.3704, 29.3704,  0.1000,  0.1000, 29.3704, 29.3704,  0.1000, 29.3704,\n",
      "          0.1000, 29.3704, 29.3448, 29.3704, 29.3704, 29.3704, 29.2875, 29.3704,\n",
      "         29.3704, 29.3704, 29.3448, 29.3704, 29.3704, 29.3704, 29.3448, 29.2875,\n",
      "         29.3448, 29.3448, 29.3448,  0.1000, 29.3448, 29.2875,  0.1000, 29.2875,\n",
      "         29.3704,  0.1000, 29.3704, 29.3704, 29.3704, 29.3448, 29.3448,  0.1000,\n",
      "         29.3704,  0.1000, 29.2401, 29.2401, 29.3448, 29.3704, 29.3704,  0.1000,\n",
      "          0.1000, 29.2401, 29.3448, 29.3704,  0.1000, 29.3448, 29.3704,  0.1000,\n",
      "         29.2401, 29.3704]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 173 was 97.5%\n",
      "current params: tensor([29.2401, 29.3448, 29.2875, 29.3704], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.8\n",
      "SLow rates:  tensor([[29.3499, 29.4545, 29.3972, 29.4801,  0.1000,  0.1000,  0.1000, 29.3499,\n",
      "         29.3499, 29.3499,  0.1000,  0.1000, 29.4545, 29.4545, 29.4545,  0.1000,\n",
      "          0.1000, 29.4545, 29.4545,  0.1000, 29.3972, 29.3972, 29.3972,  0.1000,\n",
      "          0.1000, 29.3972, 29.3972,  0.1000, 29.3972,  0.1000, 29.3972, 29.4801,\n",
      "         29.4801, 29.4801,  0.1000,  0.1000, 29.4801, 29.4801,  0.1000, 29.4801,\n",
      "          0.1000, 29.4801, 29.4545, 29.4801, 29.4801, 29.4801, 29.3972, 29.4801,\n",
      "         29.4801, 29.4801, 29.4545, 29.4801, 29.4801, 29.4801, 29.4545, 29.3972,\n",
      "         29.4545, 29.4545, 29.4545,  0.1000, 29.4545, 29.3972,  0.1000, 29.3972,\n",
      "         29.4801,  0.1000, 29.4801, 29.4801, 29.4801, 29.4545, 29.4545,  0.1000,\n",
      "         29.4801,  0.1000, 29.3499, 29.3499, 29.4545, 29.4801, 29.4801,  0.1000,\n",
      "          0.1000, 29.3499, 29.4545, 29.4801,  0.1000, 29.4545, 29.4801,  0.1000,\n",
      "         29.3499, 29.4801]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 174 was 97.5%\n",
      "current params: tensor([29.3499, 29.4545, 29.3972, 29.4801], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.8\n",
      "SLow rates:  tensor([[29.4596, 29.5642, 29.5069, 29.5896,  0.1000,  0.1000,  0.1000, 29.4596,\n",
      "         29.4596, 29.4596,  0.1000,  0.1000, 29.5642, 29.5642, 29.5642,  0.1000,\n",
      "          0.1000, 29.5642, 29.5642,  0.1000, 29.5069, 29.5069, 29.5069,  0.1000,\n",
      "          0.1000, 29.5069, 29.5069,  0.1000, 29.5069,  0.1000, 29.5069, 29.5896,\n",
      "         29.5896, 29.5896,  0.1000,  0.1000, 29.5896, 29.5896,  0.1000, 29.5896,\n",
      "          0.1000, 29.5896, 29.5642, 29.5896, 29.5896, 29.5896, 29.5069, 29.5896,\n",
      "         29.5896, 29.5896, 29.5642, 29.5896, 29.5896, 29.5896, 29.5642, 29.5069,\n",
      "         29.5642, 29.5642, 29.5642,  0.1000, 29.5642, 29.5069,  0.1000, 29.5069,\n",
      "         29.5896,  0.1000, 29.5896, 29.5896, 29.5896, 29.5642, 29.5642,  0.1000,\n",
      "         29.5896,  0.1000, 29.4596, 29.4596, 29.5642, 29.5896, 29.5896,  0.1000,\n",
      "          0.1000, 29.4596, 29.5642, 29.5896,  0.1000, 29.5642, 29.5896,  0.1000,\n",
      "         29.4596, 29.5896]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 175 was 97.5%\n",
      "current params: tensor([29.4596, 29.5642, 29.5069, 29.5896], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.9\n",
      "SLow rates:  tensor([[29.5692, 29.6737, 29.6164, 29.6991,  0.1000,  0.1000,  0.1000, 29.5692,\n",
      "         29.5692, 29.5692,  0.1000,  0.1000, 29.6737, 29.6737, 29.6737,  0.1000,\n",
      "          0.1000, 29.6737, 29.6737,  0.1000, 29.6164, 29.6164, 29.6164,  0.1000,\n",
      "          0.1000, 29.6164, 29.6164,  0.1000, 29.6164,  0.1000, 29.6164, 29.6991,\n",
      "         29.6991, 29.6991,  0.1000,  0.1000, 29.6991, 29.6991,  0.1000, 29.6991,\n",
      "          0.1000, 29.6991, 29.6737, 29.6991, 29.6991, 29.6991, 29.6164, 29.6991,\n",
      "         29.6991, 29.6991, 29.6737, 29.6991, 29.6991, 29.6991, 29.6737, 29.6164,\n",
      "         29.6737, 29.6737, 29.6737,  0.1000, 29.6737, 29.6164,  0.1000, 29.6164,\n",
      "         29.6991,  0.1000, 29.6991, 29.6991, 29.6991, 29.6737, 29.6737,  0.1000,\n",
      "         29.6991,  0.1000, 29.5692, 29.5692, 29.6737, 29.6991, 29.6991,  0.1000,\n",
      "          0.1000, 29.5692, 29.6737, 29.6991,  0.1000, 29.6737, 29.6991,  0.1000,\n",
      "         29.5692, 29.6991]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 176 was 97.5%\n",
      "current params: tensor([29.5692, 29.6737, 29.6164, 29.6991], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.9\n",
      "SLow rates:  tensor([[29.6787, 29.7831, 29.7258, 29.8084,  0.1000,  0.1000,  0.1000, 29.6787,\n",
      "         29.6787, 29.6787,  0.1000,  0.1000, 29.7831, 29.7831, 29.7831,  0.1000,\n",
      "          0.1000, 29.7831, 29.7831,  0.1000, 29.7258, 29.7258, 29.7258,  0.1000,\n",
      "          0.1000, 29.7258, 29.7258,  0.1000, 29.7258,  0.1000, 29.7258, 29.8084,\n",
      "         29.8084, 29.8084,  0.1000,  0.1000, 29.8084, 29.8084,  0.1000, 29.8084,\n",
      "          0.1000, 29.8084, 29.7831, 29.8084, 29.8084, 29.8084, 29.7258, 29.8084,\n",
      "         29.8084, 29.8084, 29.7831, 29.8084, 29.8084, 29.8084, 29.7831, 29.7258,\n",
      "         29.7831, 29.7831, 29.7831,  0.1000, 29.7831, 29.7258,  0.1000, 29.7258,\n",
      "         29.8084,  0.1000, 29.8084, 29.8084, 29.8084, 29.7831, 29.7831,  0.1000,\n",
      "         29.8084,  0.1000, 29.6787, 29.6787, 29.7831, 29.8084, 29.8084,  0.1000,\n",
      "          0.1000, 29.6787, 29.7831, 29.8084,  0.1000, 29.7831, 29.8084,  0.1000,\n",
      "         29.6787, 29.8084]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 177 was 97.5%\n",
      "current params: tensor([29.6787, 29.7831, 29.7258, 29.8084], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.9\n",
      "SLow rates:  tensor([[29.7881, 29.8924, 29.8352, 29.9176,  0.1000,  0.1000,  0.1000, 29.7881,\n",
      "         29.7881, 29.7881,  0.1000,  0.1000, 29.8924, 29.8924, 29.8924,  0.1000,\n",
      "          0.1000, 29.8924, 29.8924,  0.1000, 29.8352, 29.8352, 29.8352,  0.1000,\n",
      "          0.1000, 29.8352, 29.8352,  0.1000, 29.8352,  0.1000, 29.8352, 29.9176,\n",
      "         29.9176, 29.9176,  0.1000,  0.1000, 29.9176, 29.9176,  0.1000, 29.9176,\n",
      "          0.1000, 29.9176, 29.8924, 29.9176, 29.9176, 29.9176, 29.8352, 29.9176,\n",
      "         29.9176, 29.9176, 29.8924, 29.9176, 29.9176, 29.9176, 29.8924, 29.8352,\n",
      "         29.8924, 29.8924, 29.8924,  0.1000, 29.8924, 29.8352,  0.1000, 29.8352,\n",
      "         29.9176,  0.1000, 29.9176, 29.9176, 29.9176, 29.8924, 29.8924,  0.1000,\n",
      "         29.9176,  0.1000, 29.7881, 29.7881, 29.8924, 29.9176, 29.9176,  0.1000,\n",
      "          0.1000, 29.7881, 29.8924, 29.9176,  0.1000, 29.8924, 29.9176,  0.1000,\n",
      "         29.7881, 29.9176]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 178 was 97.5%\n",
      "current params: tensor([29.7881, 29.8924, 29.8352, 29.9176], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.9\n",
      "SLow rates:  tensor([[29.8973, 30.0016, 29.9444, 30.0268,  0.1000,  0.1000,  0.1000, 29.8973,\n",
      "         29.8973, 29.8973,  0.1000,  0.1000, 30.0016, 30.0016, 30.0016,  0.1000,\n",
      "          0.1000, 30.0016, 30.0016,  0.1000, 29.9444, 29.9444, 29.9444,  0.1000,\n",
      "          0.1000, 29.9444, 29.9444,  0.1000, 29.9444,  0.1000, 29.9444, 30.0268,\n",
      "         30.0268, 30.0268,  0.1000,  0.1000, 30.0268, 30.0268,  0.1000, 30.0268,\n",
      "          0.1000, 30.0268, 30.0016, 30.0268, 30.0268, 30.0268, 29.9444, 30.0268,\n",
      "         30.0268, 30.0268, 30.0016, 30.0268, 30.0268, 30.0268, 30.0016, 29.9444,\n",
      "         30.0016, 30.0016, 30.0016,  0.1000, 30.0016, 29.9444,  0.1000, 29.9444,\n",
      "         30.0268,  0.1000, 30.0268, 30.0268, 30.0268, 30.0016, 30.0016,  0.1000,\n",
      "         30.0268,  0.1000, 29.8973, 29.8973, 30.0016, 30.0268, 30.0268,  0.1000,\n",
      "          0.1000, 29.8973, 30.0016, 30.0268,  0.1000, 30.0016, 30.0268,  0.1000,\n",
      "         29.8973, 30.0268]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 179 was 97.5%\n",
      "current params: tensor([29.8973, 30.0016, 29.9444, 30.0268], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  8.9\n",
      "SLow rates:  tensor([[30.0065, 30.1106, 30.0535, 30.1358,  0.1000,  0.1000,  0.1000, 30.0065,\n",
      "         30.0065, 30.0065,  0.1000,  0.1000, 30.1106, 30.1106, 30.1106,  0.1000,\n",
      "          0.1000, 30.1106, 30.1106,  0.1000, 30.0535, 30.0535, 30.0535,  0.1000,\n",
      "          0.1000, 30.0535, 30.0535,  0.1000, 30.0535,  0.1000, 30.0535, 30.1358,\n",
      "         30.1358, 30.1358,  0.1000,  0.1000, 30.1358, 30.1358,  0.1000, 30.1358,\n",
      "          0.1000, 30.1358, 30.1106, 30.1358, 30.1358, 30.1358, 30.0535, 30.1358,\n",
      "         30.1358, 30.1358, 30.1106, 30.1358, 30.1358, 30.1358, 30.1106, 30.0535,\n",
      "         30.1106, 30.1106, 30.1106,  0.1000, 30.1106, 30.0535,  0.1000, 30.0535,\n",
      "         30.1358,  0.1000, 30.1358, 30.1358, 30.1358, 30.1106, 30.1106,  0.1000,\n",
      "         30.1358,  0.1000, 30.0065, 30.0065, 30.1106, 30.1358, 30.1358,  0.1000,\n",
      "          0.1000, 30.0065, 30.1106, 30.1358,  0.1000, 30.1106, 30.1358,  0.1000,\n",
      "         30.0065, 30.1358]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 180 was 97.5%\n",
      "current params: tensor([30.0065, 30.1106, 30.0535, 30.1358], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.0\n",
      "SLow rates:  tensor([[30.1155, 30.2196, 30.1625, 30.2447,  0.1000,  0.1000,  0.1000, 30.1155,\n",
      "         30.1155, 30.1155,  0.1000,  0.1000, 30.2196, 30.2196, 30.2196,  0.1000,\n",
      "          0.1000, 30.2196, 30.2196,  0.1000, 30.1625, 30.1625, 30.1625,  0.1000,\n",
      "          0.1000, 30.1625, 30.1625,  0.1000, 30.1625,  0.1000, 30.1625, 30.2447,\n",
      "         30.2447, 30.2447,  0.1000,  0.1000, 30.2447, 30.2447,  0.1000, 30.2447,\n",
      "          0.1000, 30.2447, 30.2196, 30.2447, 30.2447, 30.2447, 30.1625, 30.2447,\n",
      "         30.2447, 30.2447, 30.2196, 30.2447, 30.2447, 30.2447, 30.2196, 30.1625,\n",
      "         30.2196, 30.2196, 30.2196,  0.1000, 30.2196, 30.1625,  0.1000, 30.1625,\n",
      "         30.2447,  0.1000, 30.2447, 30.2447, 30.2447, 30.2196, 30.2196,  0.1000,\n",
      "         30.2447,  0.1000, 30.1155, 30.1155, 30.2196, 30.2447, 30.2447,  0.1000,\n",
      "          0.1000, 30.1155, 30.2196, 30.2447,  0.1000, 30.2196, 30.2447,  0.1000,\n",
      "         30.1155, 30.2447]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 181 was 97.5%\n",
      "current params: tensor([30.1155, 30.2196, 30.1625, 30.2447], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.0\n",
      "SLow rates:  tensor([[30.2245, 30.3285, 30.2714, 30.3535,  0.1000,  0.1000,  0.1000, 30.2245,\n",
      "         30.2245, 30.2245,  0.1000,  0.1000, 30.3285, 30.3285, 30.3285,  0.1000,\n",
      "          0.1000, 30.3285, 30.3285,  0.1000, 30.2714, 30.2714, 30.2714,  0.1000,\n",
      "          0.1000, 30.2714, 30.2714,  0.1000, 30.2714,  0.1000, 30.2714, 30.3535,\n",
      "         30.3535, 30.3535,  0.1000,  0.1000, 30.3535, 30.3535,  0.1000, 30.3535,\n",
      "          0.1000, 30.3535, 30.3285, 30.3535, 30.3535, 30.3535, 30.2714, 30.3535,\n",
      "         30.3535, 30.3535, 30.3285, 30.3535, 30.3535, 30.3535, 30.3285, 30.2714,\n",
      "         30.3285, 30.3285, 30.3285,  0.1000, 30.3285, 30.2714,  0.1000, 30.2714,\n",
      "         30.3535,  0.1000, 30.3535, 30.3535, 30.3535, 30.3285, 30.3285,  0.1000,\n",
      "         30.3535,  0.1000, 30.2245, 30.2245, 30.3285, 30.3535, 30.3535,  0.1000,\n",
      "          0.1000, 30.2245, 30.3285, 30.3535,  0.1000, 30.3285, 30.3535,  0.1000,\n",
      "         30.2245, 30.3535]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 182 was 97.6%\n",
      "current params: tensor([30.2245, 30.3285, 30.2714, 30.3535], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.0\n",
      "SLow rates:  tensor([[30.3333, 30.4373, 30.3802, 30.4622,  0.1000,  0.1000,  0.1000, 30.3333,\n",
      "         30.3333, 30.3333,  0.1000,  0.1000, 30.4373, 30.4373, 30.4373,  0.1000,\n",
      "          0.1000, 30.4373, 30.4373,  0.1000, 30.3802, 30.3802, 30.3802,  0.1000,\n",
      "          0.1000, 30.3802, 30.3802,  0.1000, 30.3802,  0.1000, 30.3802, 30.4622,\n",
      "         30.4622, 30.4622,  0.1000,  0.1000, 30.4622, 30.4622,  0.1000, 30.4622,\n",
      "          0.1000, 30.4622, 30.4373, 30.4622, 30.4622, 30.4622, 30.3802, 30.4622,\n",
      "         30.4622, 30.4622, 30.4373, 30.4622, 30.4622, 30.4622, 30.4373, 30.3802,\n",
      "         30.4373, 30.4373, 30.4373,  0.1000, 30.4373, 30.3802,  0.1000, 30.3802,\n",
      "         30.4622,  0.1000, 30.4622, 30.4622, 30.4622, 30.4373, 30.4373,  0.1000,\n",
      "         30.4622,  0.1000, 30.3333, 30.3333, 30.4373, 30.4622, 30.4622,  0.1000,\n",
      "          0.1000, 30.3333, 30.4373, 30.4622,  0.1000, 30.4373, 30.4622,  0.1000,\n",
      "         30.3333, 30.4622]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 183 was 97.6%\n",
      "current params: tensor([30.3333, 30.4373, 30.3802, 30.4622], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.0\n",
      "SLow rates:  tensor([[30.4421, 30.5460, 30.4889, 30.5708,  0.1000,  0.1000,  0.1000, 30.4421,\n",
      "         30.4421, 30.4421,  0.1000,  0.1000, 30.5460, 30.5460, 30.5460,  0.1000,\n",
      "          0.1000, 30.5460, 30.5460,  0.1000, 30.4889, 30.4889, 30.4889,  0.1000,\n",
      "          0.1000, 30.4889, 30.4889,  0.1000, 30.4889,  0.1000, 30.4889, 30.5708,\n",
      "         30.5708, 30.5708,  0.1000,  0.1000, 30.5708, 30.5708,  0.1000, 30.5708,\n",
      "          0.1000, 30.5708, 30.5460, 30.5708, 30.5708, 30.5708, 30.4889, 30.5708,\n",
      "         30.5708, 30.5708, 30.5460, 30.5708, 30.5708, 30.5708, 30.5460, 30.4889,\n",
      "         30.5460, 30.5460, 30.5460,  0.1000, 30.5460, 30.4889,  0.1000, 30.4889,\n",
      "         30.5708,  0.1000, 30.5708, 30.5708, 30.5708, 30.5460, 30.5460,  0.1000,\n",
      "         30.5708,  0.1000, 30.4421, 30.4421, 30.5460, 30.5708, 30.5708,  0.1000,\n",
      "          0.1000, 30.4421, 30.5460, 30.5708,  0.1000, 30.5460, 30.5708,  0.1000,\n",
      "         30.4421, 30.5708]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 184 was 97.6%\n",
      "current params: tensor([30.4421, 30.5460, 30.4889, 30.5708], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.0\n",
      "SLow rates:  tensor([[30.5507, 30.6545, 30.5975, 30.6793,  0.1000,  0.1000,  0.1000, 30.5507,\n",
      "         30.5507, 30.5507,  0.1000,  0.1000, 30.6545, 30.6545, 30.6545,  0.1000,\n",
      "          0.1000, 30.6545, 30.6545,  0.1000, 30.5975, 30.5975, 30.5975,  0.1000,\n",
      "          0.1000, 30.5975, 30.5975,  0.1000, 30.5975,  0.1000, 30.5975, 30.6793,\n",
      "         30.6793, 30.6793,  0.1000,  0.1000, 30.6793, 30.6793,  0.1000, 30.6793,\n",
      "          0.1000, 30.6793, 30.6545, 30.6793, 30.6793, 30.6793, 30.5975, 30.6793,\n",
      "         30.6793, 30.6793, 30.6545, 30.6793, 30.6793, 30.6793, 30.6545, 30.5975,\n",
      "         30.6545, 30.6545, 30.6545,  0.1000, 30.6545, 30.5975,  0.1000, 30.5975,\n",
      "         30.6793,  0.1000, 30.6793, 30.6793, 30.6793, 30.6545, 30.6545,  0.1000,\n",
      "         30.6793,  0.1000, 30.5507, 30.5507, 30.6545, 30.6793, 30.6793,  0.1000,\n",
      "          0.1000, 30.5507, 30.6545, 30.6793,  0.1000, 30.6545, 30.6793,  0.1000,\n",
      "         30.5507, 30.6793]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 185 was 97.6%\n",
      "current params: tensor([30.5507, 30.6545, 30.5975, 30.6793], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.0\n",
      "SLow rates:  tensor([[30.6593, 30.7630, 30.7060, 30.7877,  0.1000,  0.1000,  0.1000, 30.6593,\n",
      "         30.6593, 30.6593,  0.1000,  0.1000, 30.7630, 30.7630, 30.7630,  0.1000,\n",
      "          0.1000, 30.7630, 30.7630,  0.1000, 30.7060, 30.7060, 30.7060,  0.1000,\n",
      "          0.1000, 30.7060, 30.7060,  0.1000, 30.7060,  0.1000, 30.7060, 30.7877,\n",
      "         30.7877, 30.7877,  0.1000,  0.1000, 30.7877, 30.7877,  0.1000, 30.7877,\n",
      "          0.1000, 30.7877, 30.7630, 30.7877, 30.7877, 30.7877, 30.7060, 30.7877,\n",
      "         30.7877, 30.7877, 30.7630, 30.7877, 30.7877, 30.7877, 30.7630, 30.7060,\n",
      "         30.7630, 30.7630, 30.7630,  0.1000, 30.7630, 30.7060,  0.1000, 30.7060,\n",
      "         30.7877,  0.1000, 30.7877, 30.7877, 30.7877, 30.7630, 30.7630,  0.1000,\n",
      "         30.7877,  0.1000, 30.6593, 30.6593, 30.7630, 30.7877, 30.7877,  0.1000,\n",
      "          0.1000, 30.6593, 30.7630, 30.7877,  0.1000, 30.7630, 30.7877,  0.1000,\n",
      "         30.6593, 30.7877]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 186 was 97.6%\n",
      "current params: tensor([30.6593, 30.7630, 30.7060, 30.7877], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.1\n",
      "SLow rates:  tensor([[30.7677, 30.8714, 30.8144, 30.8960,  0.1000,  0.1000,  0.1000, 30.7677,\n",
      "         30.7677, 30.7677,  0.1000,  0.1000, 30.8714, 30.8714, 30.8714,  0.1000,\n",
      "          0.1000, 30.8714, 30.8714,  0.1000, 30.8144, 30.8144, 30.8144,  0.1000,\n",
      "          0.1000, 30.8144, 30.8144,  0.1000, 30.8144,  0.1000, 30.8144, 30.8960,\n",
      "         30.8960, 30.8960,  0.1000,  0.1000, 30.8960, 30.8960,  0.1000, 30.8960,\n",
      "          0.1000, 30.8960, 30.8714, 30.8960, 30.8960, 30.8960, 30.8144, 30.8960,\n",
      "         30.8960, 30.8960, 30.8714, 30.8960, 30.8960, 30.8960, 30.8714, 30.8144,\n",
      "         30.8714, 30.8714, 30.8714,  0.1000, 30.8714, 30.8144,  0.1000, 30.8144,\n",
      "         30.8960,  0.1000, 30.8960, 30.8960, 30.8960, 30.8714, 30.8714,  0.1000,\n",
      "         30.8960,  0.1000, 30.7677, 30.7677, 30.8714, 30.8960, 30.8960,  0.1000,\n",
      "          0.1000, 30.7677, 30.8714, 30.8960,  0.1000, 30.8714, 30.8960,  0.1000,\n",
      "         30.7677, 30.8960]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 187 was 97.6%\n",
      "current params: tensor([30.7677, 30.8714, 30.8144, 30.8960], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.1\n",
      "SLow rates:  tensor([[30.8761, 30.9797, 30.9227, 31.0043,  0.1000,  0.1000,  0.1000, 30.8761,\n",
      "         30.8761, 30.8761,  0.1000,  0.1000, 30.9797, 30.9797, 30.9797,  0.1000,\n",
      "          0.1000, 30.9797, 30.9797,  0.1000, 30.9227, 30.9227, 30.9227,  0.1000,\n",
      "          0.1000, 30.9227, 30.9227,  0.1000, 30.9227,  0.1000, 30.9227, 31.0043,\n",
      "         31.0043, 31.0043,  0.1000,  0.1000, 31.0043, 31.0043,  0.1000, 31.0043,\n",
      "          0.1000, 31.0043, 30.9797, 31.0043, 31.0043, 31.0043, 30.9227, 31.0043,\n",
      "         31.0043, 31.0043, 30.9797, 31.0043, 31.0043, 31.0043, 30.9797, 30.9227,\n",
      "         30.9797, 30.9797, 30.9797,  0.1000, 30.9797, 30.9227,  0.1000, 30.9227,\n",
      "         31.0043,  0.1000, 31.0043, 31.0043, 31.0043, 30.9797, 30.9797,  0.1000,\n",
      "         31.0043,  0.1000, 30.8761, 30.8761, 30.9797, 31.0043, 31.0043,  0.1000,\n",
      "          0.1000, 30.8761, 30.9797, 31.0043,  0.1000, 30.9797, 31.0043,  0.1000,\n",
      "         30.8761, 31.0043]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 188 was 97.6%\n",
      "current params: tensor([30.8761, 30.9797, 30.9227, 31.0043], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.1\n",
      "SLow rates:  tensor([[30.9844, 31.0879, 31.0309, 31.1124,  0.1000,  0.1000,  0.1000, 30.9844,\n",
      "         30.9844, 30.9844,  0.1000,  0.1000, 31.0879, 31.0879, 31.0879,  0.1000,\n",
      "          0.1000, 31.0879, 31.0879,  0.1000, 31.0309, 31.0309, 31.0309,  0.1000,\n",
      "          0.1000, 31.0309, 31.0309,  0.1000, 31.0309,  0.1000, 31.0309, 31.1124,\n",
      "         31.1124, 31.1124,  0.1000,  0.1000, 31.1124, 31.1124,  0.1000, 31.1124,\n",
      "          0.1000, 31.1124, 31.0879, 31.1124, 31.1124, 31.1124, 31.0309, 31.1124,\n",
      "         31.1124, 31.1124, 31.0879, 31.1124, 31.1124, 31.1124, 31.0879, 31.0309,\n",
      "         31.0879, 31.0879, 31.0879,  0.1000, 31.0879, 31.0309,  0.1000, 31.0309,\n",
      "         31.1124,  0.1000, 31.1124, 31.1124, 31.1124, 31.0879, 31.0879,  0.1000,\n",
      "         31.1124,  0.1000, 30.9844, 30.9844, 31.0879, 31.1124, 31.1124,  0.1000,\n",
      "          0.1000, 30.9844, 31.0879, 31.1124,  0.1000, 31.0879, 31.1124,  0.1000,\n",
      "         30.9844, 31.1124]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 189 was 97.6%\n",
      "current params: tensor([30.9844, 31.0879, 31.0309, 31.1124], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.1\n",
      "SLow rates:  tensor([[31.0925, 31.1960, 31.1390, 31.2204,  0.1000,  0.1000,  0.1000, 31.0925,\n",
      "         31.0925, 31.0925,  0.1000,  0.1000, 31.1960, 31.1960, 31.1960,  0.1000,\n",
      "          0.1000, 31.1960, 31.1960,  0.1000, 31.1390, 31.1390, 31.1390,  0.1000,\n",
      "          0.1000, 31.1390, 31.1390,  0.1000, 31.1390,  0.1000, 31.1390, 31.2204,\n",
      "         31.2204, 31.2204,  0.1000,  0.1000, 31.2204, 31.2204,  0.1000, 31.2204,\n",
      "          0.1000, 31.2204, 31.1960, 31.2204, 31.2204, 31.2204, 31.1390, 31.2204,\n",
      "         31.2204, 31.2204, 31.1960, 31.2204, 31.2204, 31.2204, 31.1960, 31.1390,\n",
      "         31.1960, 31.1960, 31.1960,  0.1000, 31.1960, 31.1390,  0.1000, 31.1390,\n",
      "         31.2204,  0.1000, 31.2204, 31.2204, 31.2204, 31.1960, 31.1960,  0.1000,\n",
      "         31.2204,  0.1000, 31.0925, 31.0925, 31.1960, 31.2204, 31.2204,  0.1000,\n",
      "          0.1000, 31.0925, 31.1960, 31.2204,  0.1000, 31.1960, 31.2204,  0.1000,\n",
      "         31.0925, 31.2204]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 190 was 97.6%\n",
      "current params: tensor([31.0925, 31.1960, 31.1390, 31.2204], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.1\n",
      "SLow rates:  tensor([[31.2006, 31.3040, 31.2470, 31.3284,  0.1000,  0.1000,  0.1000, 31.2006,\n",
      "         31.2006, 31.2006,  0.1000,  0.1000, 31.3040, 31.3040, 31.3040,  0.1000,\n",
      "          0.1000, 31.3040, 31.3040,  0.1000, 31.2470, 31.2470, 31.2470,  0.1000,\n",
      "          0.1000, 31.2470, 31.2470,  0.1000, 31.2470,  0.1000, 31.2470, 31.3284,\n",
      "         31.3284, 31.3284,  0.1000,  0.1000, 31.3284, 31.3284,  0.1000, 31.3284,\n",
      "          0.1000, 31.3284, 31.3040, 31.3284, 31.3284, 31.3284, 31.2470, 31.3284,\n",
      "         31.3284, 31.3284, 31.3040, 31.3284, 31.3284, 31.3284, 31.3040, 31.2470,\n",
      "         31.3040, 31.3040, 31.3040,  0.1000, 31.3040, 31.2470,  0.1000, 31.2470,\n",
      "         31.3284,  0.1000, 31.3284, 31.3284, 31.3284, 31.3040, 31.3040,  0.1000,\n",
      "         31.3284,  0.1000, 31.2006, 31.2006, 31.3040, 31.3284, 31.3284,  0.1000,\n",
      "          0.1000, 31.2006, 31.3040, 31.3284,  0.1000, 31.3040, 31.3284,  0.1000,\n",
      "         31.2006, 31.3284]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 191 was 97.6%\n",
      "current params: tensor([31.2006, 31.3040, 31.2470, 31.3284], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.2\n",
      "SLow rates:  tensor([[31.3086, 31.4119, 31.3550, 31.4362,  0.1000,  0.1000,  0.1000, 31.3086,\n",
      "         31.3086, 31.3086,  0.1000,  0.1000, 31.4119, 31.4119, 31.4119,  0.1000,\n",
      "          0.1000, 31.4119, 31.4119,  0.1000, 31.3550, 31.3550, 31.3550,  0.1000,\n",
      "          0.1000, 31.3550, 31.3550,  0.1000, 31.3550,  0.1000, 31.3550, 31.4362,\n",
      "         31.4362, 31.4362,  0.1000,  0.1000, 31.4362, 31.4362,  0.1000, 31.4362,\n",
      "          0.1000, 31.4362, 31.4119, 31.4362, 31.4362, 31.4362, 31.3550, 31.4362,\n",
      "         31.4362, 31.4362, 31.4119, 31.4362, 31.4362, 31.4362, 31.4119, 31.3550,\n",
      "         31.4119, 31.4119, 31.4119,  0.1000, 31.4119, 31.3550,  0.1000, 31.3550,\n",
      "         31.4362,  0.1000, 31.4362, 31.4362, 31.4362, 31.4119, 31.4119,  0.1000,\n",
      "         31.4362,  0.1000, 31.3086, 31.3086, 31.4119, 31.4362, 31.4362,  0.1000,\n",
      "          0.1000, 31.3086, 31.4119, 31.4362,  0.1000, 31.4119, 31.4362,  0.1000,\n",
      "         31.3086, 31.4362]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 192 was 97.6%\n",
      "current params: tensor([31.3086, 31.4119, 31.3550, 31.4362], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.2\n",
      "SLow rates:  tensor([[31.4165, 31.5197, 31.4628, 31.5440,  0.1000,  0.1000,  0.1000, 31.4165,\n",
      "         31.4165, 31.4165,  0.1000,  0.1000, 31.5197, 31.5197, 31.5197,  0.1000,\n",
      "          0.1000, 31.5197, 31.5197,  0.1000, 31.4628, 31.4628, 31.4628,  0.1000,\n",
      "          0.1000, 31.4628, 31.4628,  0.1000, 31.4628,  0.1000, 31.4628, 31.5440,\n",
      "         31.5440, 31.5440,  0.1000,  0.1000, 31.5440, 31.5440,  0.1000, 31.5440,\n",
      "          0.1000, 31.5440, 31.5197, 31.5440, 31.5440, 31.5440, 31.4628, 31.5440,\n",
      "         31.5440, 31.5440, 31.5197, 31.5440, 31.5440, 31.5440, 31.5197, 31.4628,\n",
      "         31.5197, 31.5197, 31.5197,  0.1000, 31.5197, 31.4628,  0.1000, 31.4628,\n",
      "         31.5440,  0.1000, 31.5440, 31.5440, 31.5440, 31.5197, 31.5197,  0.1000,\n",
      "         31.5440,  0.1000, 31.4165, 31.4165, 31.5197, 31.5440, 31.5440,  0.1000,\n",
      "          0.1000, 31.4165, 31.5197, 31.5440,  0.1000, 31.5197, 31.5440,  0.1000,\n",
      "         31.4165, 31.5440]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1614, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 193 was 97.6%\n",
      "current params: tensor([31.4165, 31.5197, 31.4628, 31.5440], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.2\n",
      "SLow rates:  tensor([[31.5243, 31.6275, 31.5706, 31.6517,  0.1000,  0.1000,  0.1000, 31.5243,\n",
      "         31.5243, 31.5243,  0.1000,  0.1000, 31.6275, 31.6275, 31.6275,  0.1000,\n",
      "          0.1000, 31.6275, 31.6275,  0.1000, 31.5706, 31.5706, 31.5706,  0.1000,\n",
      "          0.1000, 31.5706, 31.5706,  0.1000, 31.5706,  0.1000, 31.5706, 31.6517,\n",
      "         31.6517, 31.6517,  0.1000,  0.1000, 31.6517, 31.6517,  0.1000, 31.6517,\n",
      "          0.1000, 31.6517, 31.6275, 31.6517, 31.6517, 31.6517, 31.5706, 31.6517,\n",
      "         31.6517, 31.6517, 31.6275, 31.6517, 31.6517, 31.6517, 31.6275, 31.5706,\n",
      "         31.6275, 31.6275, 31.6275,  0.1000, 31.6275, 31.5706,  0.1000, 31.5706,\n",
      "         31.6517,  0.1000, 31.6517, 31.6517, 31.6517, 31.6275, 31.6275,  0.1000,\n",
      "         31.6517,  0.1000, 31.5243, 31.5243, 31.6275, 31.6517, 31.6517,  0.1000,\n",
      "          0.1000, 31.5243, 31.6275, 31.6517,  0.1000, 31.6275, 31.6517,  0.1000,\n",
      "         31.5243, 31.6517]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 194 was 97.6%\n",
      "current params: tensor([31.5243, 31.6275, 31.5706, 31.6517], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.2\n",
      "SLow rates:  tensor([[31.6320, 31.7351, 31.6783, 31.7593,  0.1000,  0.1000,  0.1000, 31.6320,\n",
      "         31.6320, 31.6320,  0.1000,  0.1000, 31.7351, 31.7351, 31.7351,  0.1000,\n",
      "          0.1000, 31.7351, 31.7351,  0.1000, 31.6783, 31.6783, 31.6783,  0.1000,\n",
      "          0.1000, 31.6783, 31.6783,  0.1000, 31.6783,  0.1000, 31.6783, 31.7593,\n",
      "         31.7593, 31.7593,  0.1000,  0.1000, 31.7593, 31.7593,  0.1000, 31.7593,\n",
      "          0.1000, 31.7593, 31.7351, 31.7593, 31.7593, 31.7593, 31.6783, 31.7593,\n",
      "         31.7593, 31.7593, 31.7351, 31.7593, 31.7593, 31.7593, 31.7351, 31.6783,\n",
      "         31.7351, 31.7351, 31.7351,  0.1000, 31.7351, 31.6783,  0.1000, 31.6783,\n",
      "         31.7593,  0.1000, 31.7593, 31.7593, 31.7593, 31.7351, 31.7351,  0.1000,\n",
      "         31.7593,  0.1000, 31.6320, 31.6320, 31.7351, 31.7593, 31.7593,  0.1000,\n",
      "          0.1000, 31.6320, 31.7351, 31.7593,  0.1000, 31.7351, 31.7593,  0.1000,\n",
      "         31.6320, 31.7593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 195 was 97.7%\n",
      "current params: tensor([31.6320, 31.7351, 31.6783, 31.7593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.2\n",
      "SLow rates:  tensor([[31.7396, 31.8427, 31.7858, 31.8668,  0.1000,  0.1000,  0.1000, 31.7396,\n",
      "         31.7396, 31.7396,  0.1000,  0.1000, 31.8427, 31.8427, 31.8427,  0.1000,\n",
      "          0.1000, 31.8427, 31.8427,  0.1000, 31.7858, 31.7858, 31.7858,  0.1000,\n",
      "          0.1000, 31.7858, 31.7858,  0.1000, 31.7858,  0.1000, 31.7858, 31.8668,\n",
      "         31.8668, 31.8668,  0.1000,  0.1000, 31.8668, 31.8668,  0.1000, 31.8668,\n",
      "          0.1000, 31.8668, 31.8427, 31.8668, 31.8668, 31.8668, 31.7858, 31.8668,\n",
      "         31.8668, 31.8668, 31.8427, 31.8668, 31.8668, 31.8668, 31.8427, 31.7858,\n",
      "         31.8427, 31.8427, 31.8427,  0.1000, 31.8427, 31.7858,  0.1000, 31.7858,\n",
      "         31.8668,  0.1000, 31.8668, 31.8668, 31.8668, 31.8427, 31.8427,  0.1000,\n",
      "         31.8668,  0.1000, 31.7396, 31.7396, 31.8427, 31.8668, 31.8668,  0.1000,\n",
      "          0.1000, 31.7396, 31.8427, 31.8668,  0.1000, 31.8427, 31.8668,  0.1000,\n",
      "         31.7396, 31.8668]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 196 was 97.7%\n",
      "current params: tensor([31.7396, 31.8427, 31.7858, 31.8668], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.3\n",
      "SLow rates:  tensor([[31.8472, 31.9502, 31.8933, 31.9742,  0.1000,  0.1000,  0.1000, 31.8472,\n",
      "         31.8472, 31.8472,  0.1000,  0.1000, 31.9502, 31.9502, 31.9502,  0.1000,\n",
      "          0.1000, 31.9502, 31.9502,  0.1000, 31.8933, 31.8933, 31.8933,  0.1000,\n",
      "          0.1000, 31.8933, 31.8933,  0.1000, 31.8933,  0.1000, 31.8933, 31.9742,\n",
      "         31.9742, 31.9742,  0.1000,  0.1000, 31.9742, 31.9742,  0.1000, 31.9742,\n",
      "          0.1000, 31.9742, 31.9502, 31.9742, 31.9742, 31.9742, 31.8933, 31.9742,\n",
      "         31.9742, 31.9742, 31.9502, 31.9742, 31.9742, 31.9742, 31.9502, 31.8933,\n",
      "         31.9502, 31.9502, 31.9502,  0.1000, 31.9502, 31.8933,  0.1000, 31.8933,\n",
      "         31.9742,  0.1000, 31.9742, 31.9742, 31.9742, 31.9502, 31.9502,  0.1000,\n",
      "         31.9742,  0.1000, 31.8472, 31.8472, 31.9502, 31.9742, 31.9742,  0.1000,\n",
      "          0.1000, 31.8472, 31.9502, 31.9742,  0.1000, 31.9502, 31.9742,  0.1000,\n",
      "         31.8472, 31.9742]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 197 was 97.7%\n",
      "current params: tensor([31.8472, 31.9502, 31.8933, 31.9742], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.3\n",
      "SLow rates:  tensor([[31.9546, 32.0576, 32.0008, 32.0815,  0.1000,  0.1000,  0.1000, 31.9546,\n",
      "         31.9546, 31.9546,  0.1000,  0.1000, 32.0576, 32.0576, 32.0576,  0.1000,\n",
      "          0.1000, 32.0576, 32.0576,  0.1000, 32.0008, 32.0008, 32.0008,  0.1000,\n",
      "          0.1000, 32.0008, 32.0008,  0.1000, 32.0008,  0.1000, 32.0008, 32.0815,\n",
      "         32.0815, 32.0815,  0.1000,  0.1000, 32.0815, 32.0815,  0.1000, 32.0815,\n",
      "          0.1000, 32.0815, 32.0576, 32.0815, 32.0815, 32.0815, 32.0008, 32.0815,\n",
      "         32.0815, 32.0815, 32.0576, 32.0815, 32.0815, 32.0815, 32.0576, 32.0008,\n",
      "         32.0576, 32.0576, 32.0576,  0.1000, 32.0576, 32.0008,  0.1000, 32.0008,\n",
      "         32.0815,  0.1000, 32.0815, 32.0815, 32.0815, 32.0576, 32.0576,  0.1000,\n",
      "         32.0815,  0.1000, 31.9546, 31.9546, 32.0576, 32.0815, 32.0815,  0.1000,\n",
      "          0.1000, 31.9546, 32.0576, 32.0815,  0.1000, 32.0576, 32.0815,  0.1000,\n",
      "         31.9546, 32.0815]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 198 was 97.7%\n",
      "current params: tensor([31.9546, 32.0576, 32.0008, 32.0815], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.3\n",
      "SLow rates:  tensor([[32.0620, 32.1649, 32.1081, 32.1888,  0.1000,  0.1000,  0.1000, 32.0620,\n",
      "         32.0620, 32.0620,  0.1000,  0.1000, 32.1649, 32.1649, 32.1649,  0.1000,\n",
      "          0.1000, 32.1649, 32.1649,  0.1000, 32.1081, 32.1081, 32.1081,  0.1000,\n",
      "          0.1000, 32.1081, 32.1081,  0.1000, 32.1081,  0.1000, 32.1081, 32.1888,\n",
      "         32.1888, 32.1888,  0.1000,  0.1000, 32.1888, 32.1888,  0.1000, 32.1888,\n",
      "          0.1000, 32.1888, 32.1649, 32.1888, 32.1888, 32.1888, 32.1081, 32.1888,\n",
      "         32.1888, 32.1888, 32.1649, 32.1888, 32.1888, 32.1888, 32.1649, 32.1081,\n",
      "         32.1649, 32.1649, 32.1649,  0.1000, 32.1649, 32.1081,  0.1000, 32.1081,\n",
      "         32.1888,  0.1000, 32.1888, 32.1888, 32.1888, 32.1649, 32.1649,  0.1000,\n",
      "         32.1888,  0.1000, 32.0620, 32.0620, 32.1649, 32.1888, 32.1888,  0.1000,\n",
      "          0.1000, 32.0620, 32.1649, 32.1888,  0.1000, 32.1649, 32.1888,  0.1000,\n",
      "         32.0620, 32.1888]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 199 was 97.7%\n",
      "current params: tensor([32.0620, 32.1649, 32.1081, 32.1888], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.3\n",
      "SLow rates:  tensor([[32.1693, 32.2721, 32.2153, 32.2960,  0.1000,  0.1000,  0.1000, 32.1693,\n",
      "         32.1693, 32.1693,  0.1000,  0.1000, 32.2721, 32.2721, 32.2721,  0.1000,\n",
      "          0.1000, 32.2721, 32.2721,  0.1000, 32.2153, 32.2153, 32.2153,  0.1000,\n",
      "          0.1000, 32.2153, 32.2153,  0.1000, 32.2153,  0.1000, 32.2153, 32.2960,\n",
      "         32.2960, 32.2960,  0.1000,  0.1000, 32.2960, 32.2960,  0.1000, 32.2960,\n",
      "          0.1000, 32.2960, 32.2721, 32.2960, 32.2960, 32.2960, 32.2153, 32.2960,\n",
      "         32.2960, 32.2960, 32.2721, 32.2960, 32.2960, 32.2960, 32.2721, 32.2153,\n",
      "         32.2721, 32.2721, 32.2721,  0.1000, 32.2721, 32.2153,  0.1000, 32.2153,\n",
      "         32.2960,  0.1000, 32.2960, 32.2960, 32.2960, 32.2721, 32.2721,  0.1000,\n",
      "         32.2960,  0.1000, 32.1693, 32.1693, 32.2721, 32.2960, 32.2960,  0.1000,\n",
      "          0.1000, 32.1693, 32.2721, 32.2960,  0.1000, 32.2721, 32.2960,  0.1000,\n",
      "         32.1693, 32.2960]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 200 was 97.7%\n",
      "current params: tensor([32.1693, 32.2721, 32.2153, 32.2960], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.3\n",
      "SLow rates:  tensor([[32.2765, 32.3793, 32.3225, 32.4031,  0.1000,  0.1000,  0.1000, 32.2765,\n",
      "         32.2765, 32.2765,  0.1000,  0.1000, 32.3793, 32.3793, 32.3793,  0.1000,\n",
      "          0.1000, 32.3793, 32.3793,  0.1000, 32.3225, 32.3225, 32.3225,  0.1000,\n",
      "          0.1000, 32.3225, 32.3225,  0.1000, 32.3225,  0.1000, 32.3225, 32.4031,\n",
      "         32.4031, 32.4031,  0.1000,  0.1000, 32.4031, 32.4031,  0.1000, 32.4031,\n",
      "          0.1000, 32.4031, 32.3793, 32.4031, 32.4031, 32.4031, 32.3225, 32.4031,\n",
      "         32.4031, 32.4031, 32.3793, 32.4031, 32.4031, 32.4031, 32.3793, 32.3225,\n",
      "         32.3793, 32.3793, 32.3793,  0.1000, 32.3793, 32.3225,  0.1000, 32.3225,\n",
      "         32.4031,  0.1000, 32.4031, 32.4031, 32.4031, 32.3793, 32.3793,  0.1000,\n",
      "         32.4031,  0.1000, 32.2765, 32.2765, 32.3793, 32.4031, 32.4031,  0.1000,\n",
      "          0.1000, 32.2765, 32.3793, 32.4031,  0.1000, 32.3793, 32.4031,  0.1000,\n",
      "         32.2765, 32.4031]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 201 was 97.7%\n",
      "current params: tensor([32.2765, 32.3793, 32.3225, 32.4031], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.4\n",
      "SLow rates:  tensor([[32.3837, 32.4863, 32.4296, 32.5101,  0.1000,  0.1000,  0.1000, 32.3837,\n",
      "         32.3837, 32.3837,  0.1000,  0.1000, 32.4863, 32.4863, 32.4863,  0.1000,\n",
      "          0.1000, 32.4863, 32.4863,  0.1000, 32.4296, 32.4296, 32.4296,  0.1000,\n",
      "          0.1000, 32.4296, 32.4296,  0.1000, 32.4296,  0.1000, 32.4296, 32.5101,\n",
      "         32.5101, 32.5101,  0.1000,  0.1000, 32.5101, 32.5101,  0.1000, 32.5101,\n",
      "          0.1000, 32.5101, 32.4863, 32.5101, 32.5101, 32.5101, 32.4296, 32.5101,\n",
      "         32.5101, 32.5101, 32.4863, 32.5101, 32.5101, 32.5101, 32.4863, 32.4296,\n",
      "         32.4863, 32.4863, 32.4863,  0.1000, 32.4863, 32.4296,  0.1000, 32.4296,\n",
      "         32.5101,  0.1000, 32.5101, 32.5101, 32.5101, 32.4863, 32.4863,  0.1000,\n",
      "         32.5101,  0.1000, 32.3837, 32.3837, 32.4863, 32.5101, 32.5101,  0.1000,\n",
      "          0.1000, 32.3837, 32.4863, 32.5101,  0.1000, 32.4863, 32.5101,  0.1000,\n",
      "         32.3837, 32.5101]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 202 was 97.7%\n",
      "current params: tensor([32.3837, 32.4863, 32.4296, 32.5101], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.4\n",
      "SLow rates:  tensor([[32.4907, 32.5933, 32.5366, 32.6170,  0.1000,  0.1000,  0.1000, 32.4907,\n",
      "         32.4907, 32.4907,  0.1000,  0.1000, 32.5933, 32.5933, 32.5933,  0.1000,\n",
      "          0.1000, 32.5933, 32.5933,  0.1000, 32.5366, 32.5366, 32.5366,  0.1000,\n",
      "          0.1000, 32.5366, 32.5366,  0.1000, 32.5366,  0.1000, 32.5366, 32.6170,\n",
      "         32.6170, 32.6170,  0.1000,  0.1000, 32.6170, 32.6170,  0.1000, 32.6170,\n",
      "          0.1000, 32.6170, 32.5933, 32.6170, 32.6170, 32.6170, 32.5366, 32.6170,\n",
      "         32.6170, 32.6170, 32.5933, 32.6170, 32.6170, 32.6170, 32.5933, 32.5366,\n",
      "         32.5933, 32.5933, 32.5933,  0.1000, 32.5933, 32.5366,  0.1000, 32.5366,\n",
      "         32.6170,  0.1000, 32.6170, 32.6170, 32.6170, 32.5933, 32.5933,  0.1000,\n",
      "         32.6170,  0.1000, 32.4907, 32.4907, 32.5933, 32.6170, 32.6170,  0.1000,\n",
      "          0.1000, 32.4907, 32.5933, 32.6170,  0.1000, 32.5933, 32.6170,  0.1000,\n",
      "         32.4907, 32.6170]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 203 was 97.7%\n",
      "current params: tensor([32.4907, 32.5933, 32.5366, 32.6170], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.4\n",
      "SLow rates:  tensor([[32.5977, 32.7002, 32.6435, 32.7239,  0.1000,  0.1000,  0.1000, 32.5977,\n",
      "         32.5977, 32.5977,  0.1000,  0.1000, 32.7002, 32.7002, 32.7002,  0.1000,\n",
      "          0.1000, 32.7002, 32.7002,  0.1000, 32.6435, 32.6435, 32.6435,  0.1000,\n",
      "          0.1000, 32.6435, 32.6435,  0.1000, 32.6435,  0.1000, 32.6435, 32.7239,\n",
      "         32.7239, 32.7239,  0.1000,  0.1000, 32.7239, 32.7239,  0.1000, 32.7239,\n",
      "          0.1000, 32.7239, 32.7002, 32.7239, 32.7239, 32.7239, 32.6435, 32.7239,\n",
      "         32.7239, 32.7239, 32.7002, 32.7239, 32.7239, 32.7239, 32.7002, 32.6435,\n",
      "         32.7002, 32.7002, 32.7002,  0.1000, 32.7002, 32.6435,  0.1000, 32.6435,\n",
      "         32.7239,  0.1000, 32.7239, 32.7239, 32.7239, 32.7002, 32.7002,  0.1000,\n",
      "         32.7239,  0.1000, 32.5977, 32.5977, 32.7002, 32.7239, 32.7239,  0.1000,\n",
      "          0.1000, 32.5977, 32.7002, 32.7239,  0.1000, 32.7002, 32.7239,  0.1000,\n",
      "         32.5977, 32.7239]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 204 was 97.7%\n",
      "current params: tensor([32.5977, 32.7002, 32.6435, 32.7239], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.4\n",
      "SLow rates:  tensor([[32.7046, 32.8071, 32.7504, 32.8307,  0.1000,  0.1000,  0.1000, 32.7046,\n",
      "         32.7046, 32.7046,  0.1000,  0.1000, 32.8071, 32.8071, 32.8071,  0.1000,\n",
      "          0.1000, 32.8071, 32.8071,  0.1000, 32.7504, 32.7504, 32.7504,  0.1000,\n",
      "          0.1000, 32.7504, 32.7504,  0.1000, 32.7504,  0.1000, 32.7504, 32.8307,\n",
      "         32.8307, 32.8307,  0.1000,  0.1000, 32.8307, 32.8307,  0.1000, 32.8307,\n",
      "          0.1000, 32.8307, 32.8071, 32.8307, 32.8307, 32.8307, 32.7504, 32.8307,\n",
      "         32.8307, 32.8307, 32.8071, 32.8307, 32.8307, 32.8307, 32.8071, 32.7504,\n",
      "         32.8071, 32.8071, 32.8071,  0.1000, 32.8071, 32.7504,  0.1000, 32.7504,\n",
      "         32.8307,  0.1000, 32.8307, 32.8307, 32.8307, 32.8071, 32.8071,  0.1000,\n",
      "         32.8307,  0.1000, 32.7046, 32.7046, 32.8071, 32.8307, 32.8307,  0.1000,\n",
      "          0.1000, 32.7046, 32.8071, 32.8307,  0.1000, 32.8071, 32.8307,  0.1000,\n",
      "         32.7046, 32.8307]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 205 was 97.7%\n",
      "current params: tensor([32.7046, 32.8071, 32.7504, 32.8307], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.4\n",
      "SLow rates:  tensor([[32.8114, 32.9138, 32.8572, 32.9374,  0.1000,  0.1000,  0.1000, 32.8114,\n",
      "         32.8114, 32.8114,  0.1000,  0.1000, 32.9138, 32.9138, 32.9138,  0.1000,\n",
      "          0.1000, 32.9138, 32.9138,  0.1000, 32.8572, 32.8572, 32.8572,  0.1000,\n",
      "          0.1000, 32.8572, 32.8572,  0.1000, 32.8572,  0.1000, 32.8572, 32.9374,\n",
      "         32.9374, 32.9374,  0.1000,  0.1000, 32.9374, 32.9374,  0.1000, 32.9374,\n",
      "          0.1000, 32.9374, 32.9138, 32.9374, 32.9374, 32.9374, 32.8572, 32.9374,\n",
      "         32.9374, 32.9374, 32.9138, 32.9374, 32.9374, 32.9374, 32.9138, 32.8572,\n",
      "         32.9138, 32.9138, 32.9138,  0.1000, 32.9138, 32.8572,  0.1000, 32.8572,\n",
      "         32.9374,  0.1000, 32.9374, 32.9374, 32.9374, 32.9138, 32.9138,  0.1000,\n",
      "         32.9374,  0.1000, 32.8114, 32.8114, 32.9138, 32.9374, 32.9374,  0.1000,\n",
      "          0.1000, 32.8114, 32.9138, 32.9374,  0.1000, 32.9138, 32.9374,  0.1000,\n",
      "         32.8114, 32.9374]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 206 was 97.7%\n",
      "current params: tensor([32.8114, 32.9138, 32.8572, 32.9374], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.4\n",
      "SLow rates:  tensor([[32.9182, 33.0205, 32.9639, 33.0440,  0.1000,  0.1000,  0.1000, 32.9182,\n",
      "         32.9182, 32.9182,  0.1000,  0.1000, 33.0205, 33.0205, 33.0205,  0.1000,\n",
      "          0.1000, 33.0205, 33.0205,  0.1000, 32.9639, 32.9639, 32.9639,  0.1000,\n",
      "          0.1000, 32.9639, 32.9639,  0.1000, 32.9639,  0.1000, 32.9639, 33.0440,\n",
      "         33.0440, 33.0440,  0.1000,  0.1000, 33.0440, 33.0440,  0.1000, 33.0440,\n",
      "          0.1000, 33.0440, 33.0205, 33.0440, 33.0440, 33.0440, 32.9639, 33.0440,\n",
      "         33.0440, 33.0440, 33.0205, 33.0440, 33.0440, 33.0440, 33.0205, 32.9639,\n",
      "         33.0205, 33.0205, 33.0205,  0.1000, 33.0205, 32.9639,  0.1000, 32.9639,\n",
      "         33.0440,  0.1000, 33.0440, 33.0440, 33.0440, 33.0205, 33.0205,  0.1000,\n",
      "         33.0440,  0.1000, 32.9182, 32.9182, 33.0205, 33.0440, 33.0440,  0.1000,\n",
      "          0.1000, 32.9182, 33.0205, 33.0440,  0.1000, 33.0205, 33.0440,  0.1000,\n",
      "         32.9182, 33.0440]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 207 was 97.7%\n",
      "current params: tensor([32.9182, 33.0205, 32.9639, 33.0440], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.5\n",
      "SLow rates:  tensor([[33.0248, 33.1271, 33.0705, 33.1506,  0.1000,  0.1000,  0.1000, 33.0248,\n",
      "         33.0248, 33.0248,  0.1000,  0.1000, 33.1271, 33.1271, 33.1271,  0.1000,\n",
      "          0.1000, 33.1271, 33.1271,  0.1000, 33.0705, 33.0705, 33.0705,  0.1000,\n",
      "          0.1000, 33.0705, 33.0705,  0.1000, 33.0705,  0.1000, 33.0705, 33.1506,\n",
      "         33.1506, 33.1506,  0.1000,  0.1000, 33.1506, 33.1506,  0.1000, 33.1506,\n",
      "          0.1000, 33.1506, 33.1271, 33.1506, 33.1506, 33.1506, 33.0705, 33.1506,\n",
      "         33.1506, 33.1506, 33.1271, 33.1506, 33.1506, 33.1506, 33.1271, 33.0705,\n",
      "         33.1271, 33.1271, 33.1271,  0.1000, 33.1271, 33.0705,  0.1000, 33.0705,\n",
      "         33.1506,  0.1000, 33.1506, 33.1506, 33.1506, 33.1271, 33.1271,  0.1000,\n",
      "         33.1506,  0.1000, 33.0248, 33.0248, 33.1271, 33.1506, 33.1506,  0.1000,\n",
      "          0.1000, 33.0248, 33.1271, 33.1506,  0.1000, 33.1271, 33.1506,  0.1000,\n",
      "         33.0248, 33.1506]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 208 was 97.7%\n",
      "current params: tensor([33.0248, 33.1271, 33.0705, 33.1506], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.5\n",
      "SLow rates:  tensor([[33.1314, 33.2337, 33.1771, 33.2570,  0.1000,  0.1000,  0.1000, 33.1314,\n",
      "         33.1314, 33.1314,  0.1000,  0.1000, 33.2337, 33.2337, 33.2337,  0.1000,\n",
      "          0.1000, 33.2337, 33.2337,  0.1000, 33.1771, 33.1771, 33.1771,  0.1000,\n",
      "          0.1000, 33.1771, 33.1771,  0.1000, 33.1771,  0.1000, 33.1771, 33.2570,\n",
      "         33.2570, 33.2570,  0.1000,  0.1000, 33.2570, 33.2570,  0.1000, 33.2570,\n",
      "          0.1000, 33.2570, 33.2337, 33.2570, 33.2570, 33.2570, 33.1771, 33.2570,\n",
      "         33.2570, 33.2570, 33.2337, 33.2570, 33.2570, 33.2570, 33.2337, 33.1771,\n",
      "         33.2337, 33.2337, 33.2337,  0.1000, 33.2337, 33.1771,  0.1000, 33.1771,\n",
      "         33.2570,  0.1000, 33.2570, 33.2570, 33.2570, 33.2337, 33.2337,  0.1000,\n",
      "         33.2570,  0.1000, 33.1314, 33.1314, 33.2337, 33.2570, 33.2570,  0.1000,\n",
      "          0.1000, 33.1314, 33.2337, 33.2570,  0.1000, 33.2337, 33.2570,  0.1000,\n",
      "         33.1314, 33.2570]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 209 was 97.8%\n",
      "current params: tensor([33.1314, 33.2337, 33.1771, 33.2570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.5\n",
      "SLow rates:  tensor([[33.2380, 33.3401, 33.2836, 33.3635,  0.1000,  0.1000,  0.1000, 33.2380,\n",
      "         33.2380, 33.2380,  0.1000,  0.1000, 33.3401, 33.3401, 33.3401,  0.1000,\n",
      "          0.1000, 33.3401, 33.3401,  0.1000, 33.2836, 33.2836, 33.2836,  0.1000,\n",
      "          0.1000, 33.2836, 33.2836,  0.1000, 33.2836,  0.1000, 33.2836, 33.3635,\n",
      "         33.3635, 33.3635,  0.1000,  0.1000, 33.3635, 33.3635,  0.1000, 33.3635,\n",
      "          0.1000, 33.3635, 33.3401, 33.3635, 33.3635, 33.3635, 33.2836, 33.3635,\n",
      "         33.3635, 33.3635, 33.3401, 33.3635, 33.3635, 33.3635, 33.3401, 33.2836,\n",
      "         33.3401, 33.3401, 33.3401,  0.1000, 33.3401, 33.2836,  0.1000, 33.2836,\n",
      "         33.3635,  0.1000, 33.3635, 33.3635, 33.3635, 33.3401, 33.3401,  0.1000,\n",
      "         33.3635,  0.1000, 33.2380, 33.2380, 33.3401, 33.3635, 33.3635,  0.1000,\n",
      "          0.1000, 33.2380, 33.3401, 33.3635,  0.1000, 33.3401, 33.3635,  0.1000,\n",
      "         33.2380, 33.3635]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 210 was 97.8%\n",
      "current params: tensor([33.2380, 33.3401, 33.2836, 33.3635], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.5\n",
      "SLow rates:  tensor([[33.3444, 33.4465, 33.3900, 33.4698,  0.1000,  0.1000,  0.1000, 33.3444,\n",
      "         33.3444, 33.3444,  0.1000,  0.1000, 33.4465, 33.4465, 33.4465,  0.1000,\n",
      "          0.1000, 33.4465, 33.4465,  0.1000, 33.3900, 33.3900, 33.3900,  0.1000,\n",
      "          0.1000, 33.3900, 33.3900,  0.1000, 33.3900,  0.1000, 33.3900, 33.4698,\n",
      "         33.4698, 33.4698,  0.1000,  0.1000, 33.4698, 33.4698,  0.1000, 33.4698,\n",
      "          0.1000, 33.4698, 33.4465, 33.4698, 33.4698, 33.4698, 33.3900, 33.4698,\n",
      "         33.4698, 33.4698, 33.4465, 33.4698, 33.4698, 33.4698, 33.4465, 33.3900,\n",
      "         33.4465, 33.4465, 33.4465,  0.1000, 33.4465, 33.3900,  0.1000, 33.3900,\n",
      "         33.4698,  0.1000, 33.4698, 33.4698, 33.4698, 33.4465, 33.4465,  0.1000,\n",
      "         33.4698,  0.1000, 33.3444, 33.3444, 33.4465, 33.4698, 33.4698,  0.1000,\n",
      "          0.1000, 33.3444, 33.4465, 33.4698,  0.1000, 33.4465, 33.4698,  0.1000,\n",
      "         33.3444, 33.4698]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 211 was 97.8%\n",
      "current params: tensor([33.3444, 33.4465, 33.3900, 33.4698], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.5\n",
      "SLow rates:  tensor([[33.4508, 33.5529, 33.4963, 33.5761,  0.1000,  0.1000,  0.1000, 33.4508,\n",
      "         33.4508, 33.4508,  0.1000,  0.1000, 33.5529, 33.5529, 33.5529,  0.1000,\n",
      "          0.1000, 33.5529, 33.5529,  0.1000, 33.4963, 33.4963, 33.4963,  0.1000,\n",
      "          0.1000, 33.4963, 33.4963,  0.1000, 33.4963,  0.1000, 33.4963, 33.5761,\n",
      "         33.5761, 33.5761,  0.1000,  0.1000, 33.5761, 33.5761,  0.1000, 33.5761,\n",
      "          0.1000, 33.5761, 33.5529, 33.5761, 33.5761, 33.5761, 33.4963, 33.5761,\n",
      "         33.5761, 33.5761, 33.5529, 33.5761, 33.5761, 33.5761, 33.5529, 33.4963,\n",
      "         33.5529, 33.5529, 33.5529,  0.1000, 33.5529, 33.4963,  0.1000, 33.4963,\n",
      "         33.5761,  0.1000, 33.5761, 33.5761, 33.5761, 33.5529, 33.5529,  0.1000,\n",
      "         33.5761,  0.1000, 33.4508, 33.4508, 33.5529, 33.5761, 33.5761,  0.1000,\n",
      "          0.1000, 33.4508, 33.5529, 33.5761,  0.1000, 33.5529, 33.5761,  0.1000,\n",
      "         33.4508, 33.5761]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 212 was 97.8%\n",
      "current params: tensor([33.4508, 33.5529, 33.4963, 33.5761], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.6\n",
      "SLow rates:  tensor([[33.5571, 33.6591, 33.6026, 33.6823,  0.1000,  0.1000,  0.1000, 33.5571,\n",
      "         33.5571, 33.5571,  0.1000,  0.1000, 33.6591, 33.6591, 33.6591,  0.1000,\n",
      "          0.1000, 33.6591, 33.6591,  0.1000, 33.6026, 33.6026, 33.6026,  0.1000,\n",
      "          0.1000, 33.6026, 33.6026,  0.1000, 33.6026,  0.1000, 33.6026, 33.6823,\n",
      "         33.6823, 33.6823,  0.1000,  0.1000, 33.6823, 33.6823,  0.1000, 33.6823,\n",
      "          0.1000, 33.6823, 33.6591, 33.6823, 33.6823, 33.6823, 33.6026, 33.6823,\n",
      "         33.6823, 33.6823, 33.6591, 33.6823, 33.6823, 33.6823, 33.6591, 33.6026,\n",
      "         33.6591, 33.6591, 33.6591,  0.1000, 33.6591, 33.6026,  0.1000, 33.6026,\n",
      "         33.6823,  0.1000, 33.6823, 33.6823, 33.6823, 33.6591, 33.6591,  0.1000,\n",
      "         33.6823,  0.1000, 33.5571, 33.5571, 33.6591, 33.6823, 33.6823,  0.1000,\n",
      "          0.1000, 33.5571, 33.6591, 33.6823,  0.1000, 33.6591, 33.6823,  0.1000,\n",
      "         33.5571, 33.6823]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 213 was 97.8%\n",
      "current params: tensor([33.5571, 33.6591, 33.6026, 33.6823], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.6\n",
      "SLow rates:  tensor([[33.6633, 33.7653, 33.7088, 33.7884,  0.1000,  0.1000,  0.1000, 33.6633,\n",
      "         33.6633, 33.6633,  0.1000,  0.1000, 33.7653, 33.7653, 33.7653,  0.1000,\n",
      "          0.1000, 33.7653, 33.7653,  0.1000, 33.7088, 33.7088, 33.7088,  0.1000,\n",
      "          0.1000, 33.7088, 33.7088,  0.1000, 33.7088,  0.1000, 33.7088, 33.7884,\n",
      "         33.7884, 33.7884,  0.1000,  0.1000, 33.7884, 33.7884,  0.1000, 33.7884,\n",
      "          0.1000, 33.7884, 33.7653, 33.7884, 33.7884, 33.7884, 33.7088, 33.7884,\n",
      "         33.7884, 33.7884, 33.7653, 33.7884, 33.7884, 33.7884, 33.7653, 33.7088,\n",
      "         33.7653, 33.7653, 33.7653,  0.1000, 33.7653, 33.7088,  0.1000, 33.7088,\n",
      "         33.7884,  0.1000, 33.7884, 33.7884, 33.7884, 33.7653, 33.7653,  0.1000,\n",
      "         33.7884,  0.1000, 33.6633, 33.6633, 33.7653, 33.7884, 33.7884,  0.1000,\n",
      "          0.1000, 33.6633, 33.7653, 33.7884,  0.1000, 33.7653, 33.7884,  0.1000,\n",
      "         33.6633, 33.7884]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 214 was 97.8%\n",
      "current params: tensor([33.6633, 33.7653, 33.7088, 33.7884], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.6\n",
      "SLow rates:  tensor([[33.7695, 33.8714, 33.8149, 33.8945,  0.1000,  0.1000,  0.1000, 33.7695,\n",
      "         33.7695, 33.7695,  0.1000,  0.1000, 33.8714, 33.8714, 33.8714,  0.1000,\n",
      "          0.1000, 33.8714, 33.8714,  0.1000, 33.8149, 33.8149, 33.8149,  0.1000,\n",
      "          0.1000, 33.8149, 33.8149,  0.1000, 33.8149,  0.1000, 33.8149, 33.8945,\n",
      "         33.8945, 33.8945,  0.1000,  0.1000, 33.8945, 33.8945,  0.1000, 33.8945,\n",
      "          0.1000, 33.8945, 33.8714, 33.8945, 33.8945, 33.8945, 33.8149, 33.8945,\n",
      "         33.8945, 33.8945, 33.8714, 33.8945, 33.8945, 33.8945, 33.8714, 33.8149,\n",
      "         33.8714, 33.8714, 33.8714,  0.1000, 33.8714, 33.8149,  0.1000, 33.8149,\n",
      "         33.8945,  0.1000, 33.8945, 33.8945, 33.8945, 33.8714, 33.8714,  0.1000,\n",
      "         33.8945,  0.1000, 33.7695, 33.7695, 33.8714, 33.8945, 33.8945,  0.1000,\n",
      "          0.1000, 33.7695, 33.8714, 33.8945,  0.1000, 33.8714, 33.8945,  0.1000,\n",
      "         33.7695, 33.8945]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 215 was 97.8%\n",
      "current params: tensor([33.7695, 33.8714, 33.8149, 33.8945], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.6\n",
      "SLow rates:  tensor([[33.8756, 33.9775, 33.9210, 34.0005,  0.1000,  0.1000,  0.1000, 33.8756,\n",
      "         33.8756, 33.8756,  0.1000,  0.1000, 33.9775, 33.9775, 33.9775,  0.1000,\n",
      "          0.1000, 33.9775, 33.9775,  0.1000, 33.9210, 33.9210, 33.9210,  0.1000,\n",
      "          0.1000, 33.9210, 33.9210,  0.1000, 33.9210,  0.1000, 33.9210, 34.0005,\n",
      "         34.0005, 34.0005,  0.1000,  0.1000, 34.0005, 34.0005,  0.1000, 34.0005,\n",
      "          0.1000, 34.0005, 33.9775, 34.0005, 34.0005, 34.0005, 33.9210, 34.0005,\n",
      "         34.0005, 34.0005, 33.9775, 34.0005, 34.0005, 34.0005, 33.9775, 33.9210,\n",
      "         33.9775, 33.9775, 33.9775,  0.1000, 33.9775, 33.9210,  0.1000, 33.9210,\n",
      "         34.0005,  0.1000, 34.0005, 34.0005, 34.0005, 33.9775, 33.9775,  0.1000,\n",
      "         34.0005,  0.1000, 33.8756, 33.8756, 33.9775, 34.0005, 34.0005,  0.1000,\n",
      "          0.1000, 33.8756, 33.9775, 34.0005,  0.1000, 33.9775, 34.0005,  0.1000,\n",
      "         33.8756, 34.0005]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 216 was 97.8%\n",
      "current params: tensor([33.8756, 33.9775, 33.9210, 34.0005], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.6\n",
      "SLow rates:  tensor([[33.9817, 34.0835, 34.0270, 34.1064,  0.1000,  0.1000,  0.1000, 33.9817,\n",
      "         33.9817, 33.9817,  0.1000,  0.1000, 34.0835, 34.0835, 34.0835,  0.1000,\n",
      "          0.1000, 34.0835, 34.0835,  0.1000, 34.0270, 34.0270, 34.0270,  0.1000,\n",
      "          0.1000, 34.0270, 34.0270,  0.1000, 34.0270,  0.1000, 34.0270, 34.1064,\n",
      "         34.1064, 34.1064,  0.1000,  0.1000, 34.1064, 34.1064,  0.1000, 34.1064,\n",
      "          0.1000, 34.1064, 34.0835, 34.1064, 34.1064, 34.1064, 34.0270, 34.1064,\n",
      "         34.1064, 34.1064, 34.0835, 34.1064, 34.1064, 34.1064, 34.0835, 34.0270,\n",
      "         34.0835, 34.0835, 34.0835,  0.1000, 34.0835, 34.0270,  0.1000, 34.0270,\n",
      "         34.1064,  0.1000, 34.1064, 34.1064, 34.1064, 34.0835, 34.0835,  0.1000,\n",
      "         34.1064,  0.1000, 33.9817, 33.9817, 34.0835, 34.1064, 34.1064,  0.1000,\n",
      "          0.1000, 33.9817, 34.0835, 34.1064,  0.1000, 34.0835, 34.1064,  0.1000,\n",
      "         33.9817, 34.1064]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 217 was 97.8%\n",
      "current params: tensor([33.9817, 34.0835, 34.0270, 34.1064], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.7\n",
      "SLow rates:  tensor([[34.0876, 34.1894, 34.1329, 34.2123,  0.1000,  0.1000,  0.1000, 34.0876,\n",
      "         34.0876, 34.0876,  0.1000,  0.1000, 34.1894, 34.1894, 34.1894,  0.1000,\n",
      "          0.1000, 34.1894, 34.1894,  0.1000, 34.1329, 34.1329, 34.1329,  0.1000,\n",
      "          0.1000, 34.1329, 34.1329,  0.1000, 34.1329,  0.1000, 34.1329, 34.2123,\n",
      "         34.2123, 34.2123,  0.1000,  0.1000, 34.2123, 34.2123,  0.1000, 34.2123,\n",
      "          0.1000, 34.2123, 34.1894, 34.2123, 34.2123, 34.2123, 34.1329, 34.2123,\n",
      "         34.2123, 34.2123, 34.1894, 34.2123, 34.2123, 34.2123, 34.1894, 34.1329,\n",
      "         34.1894, 34.1894, 34.1894,  0.1000, 34.1894, 34.1329,  0.1000, 34.1329,\n",
      "         34.2123,  0.1000, 34.2123, 34.2123, 34.2123, 34.1894, 34.1894,  0.1000,\n",
      "         34.2123,  0.1000, 34.0876, 34.0876, 34.1894, 34.2123, 34.2123,  0.1000,\n",
      "          0.1000, 34.0876, 34.1894, 34.2123,  0.1000, 34.1894, 34.2123,  0.1000,\n",
      "         34.0876, 34.2123]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 218 was 97.8%\n",
      "current params: tensor([34.0876, 34.1894, 34.1329, 34.2123], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.7\n",
      "SLow rates:  tensor([[34.1936, 34.2952, 34.2388, 34.3181,  0.1000,  0.1000,  0.1000, 34.1936,\n",
      "         34.1936, 34.1936,  0.1000,  0.1000, 34.2952, 34.2952, 34.2952,  0.1000,\n",
      "          0.1000, 34.2952, 34.2952,  0.1000, 34.2388, 34.2388, 34.2388,  0.1000,\n",
      "          0.1000, 34.2388, 34.2388,  0.1000, 34.2388,  0.1000, 34.2388, 34.3181,\n",
      "         34.3181, 34.3181,  0.1000,  0.1000, 34.3181, 34.3181,  0.1000, 34.3181,\n",
      "          0.1000, 34.3181, 34.2952, 34.3181, 34.3181, 34.3181, 34.2388, 34.3181,\n",
      "         34.3181, 34.3181, 34.2952, 34.3181, 34.3181, 34.3181, 34.2952, 34.2388,\n",
      "         34.2952, 34.2952, 34.2952,  0.1000, 34.2952, 34.2388,  0.1000, 34.2388,\n",
      "         34.3181,  0.1000, 34.3181, 34.3181, 34.3181, 34.2952, 34.2952,  0.1000,\n",
      "         34.3181,  0.1000, 34.1936, 34.1936, 34.2952, 34.3181, 34.3181,  0.1000,\n",
      "          0.1000, 34.1936, 34.2952, 34.3181,  0.1000, 34.2952, 34.3181,  0.1000,\n",
      "         34.1936, 34.3181]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 219 was 97.8%\n",
      "current params: tensor([34.1936, 34.2952, 34.2388, 34.3181], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.7\n",
      "SLow rates:  tensor([[34.2994, 34.4010, 34.3446, 34.4238,  0.1000,  0.1000,  0.1000, 34.2994,\n",
      "         34.2994, 34.2994,  0.1000,  0.1000, 34.4010, 34.4010, 34.4010,  0.1000,\n",
      "          0.1000, 34.4010, 34.4010,  0.1000, 34.3446, 34.3446, 34.3446,  0.1000,\n",
      "          0.1000, 34.3446, 34.3446,  0.1000, 34.3446,  0.1000, 34.3446, 34.4238,\n",
      "         34.4238, 34.4238,  0.1000,  0.1000, 34.4238, 34.4238,  0.1000, 34.4238,\n",
      "          0.1000, 34.4238, 34.4010, 34.4238, 34.4238, 34.4238, 34.3446, 34.4238,\n",
      "         34.4238, 34.4238, 34.4010, 34.4238, 34.4238, 34.4238, 34.4010, 34.3446,\n",
      "         34.4010, 34.4010, 34.4010,  0.1000, 34.4010, 34.3446,  0.1000, 34.3446,\n",
      "         34.4238,  0.1000, 34.4238, 34.4238, 34.4238, 34.4010, 34.4010,  0.1000,\n",
      "         34.4238,  0.1000, 34.2994, 34.2994, 34.4010, 34.4238, 34.4238,  0.1000,\n",
      "          0.1000, 34.2994, 34.4010, 34.4238,  0.1000, 34.4010, 34.4238,  0.1000,\n",
      "         34.2994, 34.4238]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 220 was 97.8%\n",
      "current params: tensor([34.2994, 34.4010, 34.3446, 34.4238], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.7\n",
      "SLow rates:  tensor([[34.4052, 34.5067, 34.4503, 34.5295,  0.1000,  0.1000,  0.1000, 34.4052,\n",
      "         34.4052, 34.4052,  0.1000,  0.1000, 34.5067, 34.5067, 34.5067,  0.1000,\n",
      "          0.1000, 34.5067, 34.5067,  0.1000, 34.4503, 34.4503, 34.4503,  0.1000,\n",
      "          0.1000, 34.4503, 34.4503,  0.1000, 34.4503,  0.1000, 34.4503, 34.5295,\n",
      "         34.5295, 34.5295,  0.1000,  0.1000, 34.5295, 34.5295,  0.1000, 34.5295,\n",
      "          0.1000, 34.5295, 34.5067, 34.5295, 34.5295, 34.5295, 34.4503, 34.5295,\n",
      "         34.5295, 34.5295, 34.5067, 34.5295, 34.5295, 34.5295, 34.5067, 34.4503,\n",
      "         34.5067, 34.5067, 34.5067,  0.1000, 34.5067, 34.4503,  0.1000, 34.4503,\n",
      "         34.5295,  0.1000, 34.5295, 34.5295, 34.5295, 34.5067, 34.5067,  0.1000,\n",
      "         34.5295,  0.1000, 34.4052, 34.4052, 34.5067, 34.5295, 34.5295,  0.1000,\n",
      "          0.1000, 34.4052, 34.5067, 34.5295,  0.1000, 34.5067, 34.5295,  0.1000,\n",
      "         34.4052, 34.5295]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 221 was 97.8%\n",
      "current params: tensor([34.4052, 34.5067, 34.4503, 34.5295], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.7\n",
      "SLow rates:  tensor([[34.5109, 34.6124, 34.5560, 34.6351,  0.1000,  0.1000,  0.1000, 34.5109,\n",
      "         34.5109, 34.5109,  0.1000,  0.1000, 34.6124, 34.6124, 34.6124,  0.1000,\n",
      "          0.1000, 34.6124, 34.6124,  0.1000, 34.5560, 34.5560, 34.5560,  0.1000,\n",
      "          0.1000, 34.5560, 34.5560,  0.1000, 34.5560,  0.1000, 34.5560, 34.6351,\n",
      "         34.6351, 34.6351,  0.1000,  0.1000, 34.6351, 34.6351,  0.1000, 34.6351,\n",
      "          0.1000, 34.6351, 34.6124, 34.6351, 34.6351, 34.6351, 34.5560, 34.6351,\n",
      "         34.6351, 34.6351, 34.6124, 34.6351, 34.6351, 34.6351, 34.6124, 34.5560,\n",
      "         34.6124, 34.6124, 34.6124,  0.1000, 34.6124, 34.5560,  0.1000, 34.5560,\n",
      "         34.6351,  0.1000, 34.6351, 34.6351, 34.6351, 34.6124, 34.6124,  0.1000,\n",
      "         34.6351,  0.1000, 34.5109, 34.5109, 34.6124, 34.6351, 34.6351,  0.1000,\n",
      "          0.1000, 34.5109, 34.6124, 34.6351,  0.1000, 34.6124, 34.6351,  0.1000,\n",
      "         34.5109, 34.6351]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 222 was 97.8%\n",
      "current params: tensor([34.5109, 34.6124, 34.5560, 34.6351], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.7\n",
      "SLow rates:  tensor([[34.6165, 34.7180, 34.6616, 34.7407,  0.1000,  0.1000,  0.1000, 34.6165,\n",
      "         34.6165, 34.6165,  0.1000,  0.1000, 34.7180, 34.7180, 34.7180,  0.1000,\n",
      "          0.1000, 34.7180, 34.7180,  0.1000, 34.6616, 34.6616, 34.6616,  0.1000,\n",
      "          0.1000, 34.6616, 34.6616,  0.1000, 34.6616,  0.1000, 34.6616, 34.7407,\n",
      "         34.7407, 34.7407,  0.1000,  0.1000, 34.7407, 34.7407,  0.1000, 34.7407,\n",
      "          0.1000, 34.7407, 34.7180, 34.7407, 34.7407, 34.7407, 34.6616, 34.7407,\n",
      "         34.7407, 34.7407, 34.7180, 34.7407, 34.7407, 34.7407, 34.7180, 34.6616,\n",
      "         34.7180, 34.7180, 34.7180,  0.1000, 34.7180, 34.6616,  0.1000, 34.6616,\n",
      "         34.7407,  0.1000, 34.7407, 34.7407, 34.7407, 34.7180, 34.7180,  0.1000,\n",
      "         34.7407,  0.1000, 34.6165, 34.6165, 34.7180, 34.7407, 34.7407,  0.1000,\n",
      "          0.1000, 34.6165, 34.7180, 34.7407,  0.1000, 34.7180, 34.7407,  0.1000,\n",
      "         34.6165, 34.7407]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 223 was 97.8%\n",
      "current params: tensor([34.6165, 34.7180, 34.6616, 34.7407], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.8\n",
      "SLow rates:  tensor([[34.7221, 34.8235, 34.7672, 34.8462,  0.1000,  0.1000,  0.1000, 34.7221,\n",
      "         34.7221, 34.7221,  0.1000,  0.1000, 34.8235, 34.8235, 34.8235,  0.1000,\n",
      "          0.1000, 34.8235, 34.8235,  0.1000, 34.7672, 34.7672, 34.7672,  0.1000,\n",
      "          0.1000, 34.7672, 34.7672,  0.1000, 34.7672,  0.1000, 34.7672, 34.8462,\n",
      "         34.8462, 34.8462,  0.1000,  0.1000, 34.8462, 34.8462,  0.1000, 34.8462,\n",
      "          0.1000, 34.8462, 34.8235, 34.8462, 34.8462, 34.8462, 34.7672, 34.8462,\n",
      "         34.8462, 34.8462, 34.8235, 34.8462, 34.8462, 34.8462, 34.8235, 34.7672,\n",
      "         34.8235, 34.8235, 34.8235,  0.1000, 34.8235, 34.7672,  0.1000, 34.7672,\n",
      "         34.8462,  0.1000, 34.8462, 34.8462, 34.8462, 34.8235, 34.8235,  0.1000,\n",
      "         34.8462,  0.1000, 34.7221, 34.7221, 34.8235, 34.8462, 34.8462,  0.1000,\n",
      "          0.1000, 34.7221, 34.8235, 34.8462,  0.1000, 34.8235, 34.8462,  0.1000,\n",
      "         34.7221, 34.8462]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 224 was 97.8%\n",
      "current params: tensor([34.7221, 34.8235, 34.7672, 34.8462], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.8\n",
      "SLow rates:  tensor([[34.8277, 34.9290, 34.8727, 34.9516,  0.1000,  0.1000,  0.1000, 34.8277,\n",
      "         34.8277, 34.8277,  0.1000,  0.1000, 34.9290, 34.9290, 34.9290,  0.1000,\n",
      "          0.1000, 34.9290, 34.9290,  0.1000, 34.8727, 34.8727, 34.8727,  0.1000,\n",
      "          0.1000, 34.8727, 34.8727,  0.1000, 34.8727,  0.1000, 34.8727, 34.9516,\n",
      "         34.9516, 34.9516,  0.1000,  0.1000, 34.9516, 34.9516,  0.1000, 34.9516,\n",
      "          0.1000, 34.9516, 34.9290, 34.9516, 34.9516, 34.9516, 34.8727, 34.9516,\n",
      "         34.9516, 34.9516, 34.9290, 34.9516, 34.9516, 34.9516, 34.9290, 34.8727,\n",
      "         34.9290, 34.9290, 34.9290,  0.1000, 34.9290, 34.8727,  0.1000, 34.8727,\n",
      "         34.9516,  0.1000, 34.9516, 34.9516, 34.9516, 34.9290, 34.9290,  0.1000,\n",
      "         34.9516,  0.1000, 34.8277, 34.8277, 34.9290, 34.9516, 34.9516,  0.1000,\n",
      "          0.1000, 34.8277, 34.9290, 34.9516,  0.1000, 34.9290, 34.9516,  0.1000,\n",
      "         34.8277, 34.9516]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 225 was 97.9%\n",
      "current params: tensor([34.8277, 34.9290, 34.8727, 34.9516], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.8\n",
      "SLow rates:  tensor([[34.9331, 35.0344, 34.9781, 35.0570,  0.1000,  0.1000,  0.1000, 34.9331,\n",
      "         34.9331, 34.9331,  0.1000,  0.1000, 35.0344, 35.0344, 35.0344,  0.1000,\n",
      "          0.1000, 35.0344, 35.0344,  0.1000, 34.9781, 34.9781, 34.9781,  0.1000,\n",
      "          0.1000, 34.9781, 34.9781,  0.1000, 34.9781,  0.1000, 34.9781, 35.0570,\n",
      "         35.0570, 35.0570,  0.1000,  0.1000, 35.0570, 35.0570,  0.1000, 35.0570,\n",
      "          0.1000, 35.0570, 35.0344, 35.0570, 35.0570, 35.0570, 34.9781, 35.0570,\n",
      "         35.0570, 35.0570, 35.0344, 35.0570, 35.0570, 35.0570, 35.0344, 34.9781,\n",
      "         35.0344, 35.0344, 35.0344,  0.1000, 35.0344, 34.9781,  0.1000, 34.9781,\n",
      "         35.0570,  0.1000, 35.0570, 35.0570, 35.0570, 35.0344, 35.0344,  0.1000,\n",
      "         35.0570,  0.1000, 34.9331, 34.9331, 35.0344, 35.0570, 35.0570,  0.1000,\n",
      "          0.1000, 34.9331, 35.0344, 35.0570,  0.1000, 35.0344, 35.0570,  0.1000,\n",
      "         34.9331, 35.0570]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 226 was 97.9%\n",
      "current params: tensor([34.9331, 35.0344, 34.9781, 35.0570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.8\n",
      "SLow rates:  tensor([[35.0386, 35.1398, 35.0835, 35.1623,  0.1000,  0.1000,  0.1000, 35.0386,\n",
      "         35.0386, 35.0386,  0.1000,  0.1000, 35.1398, 35.1398, 35.1398,  0.1000,\n",
      "          0.1000, 35.1398, 35.1398,  0.1000, 35.0835, 35.0835, 35.0835,  0.1000,\n",
      "          0.1000, 35.0835, 35.0835,  0.1000, 35.0835,  0.1000, 35.0835, 35.1623,\n",
      "         35.1623, 35.1623,  0.1000,  0.1000, 35.1623, 35.1623,  0.1000, 35.1623,\n",
      "          0.1000, 35.1623, 35.1398, 35.1623, 35.1623, 35.1623, 35.0835, 35.1623,\n",
      "         35.1623, 35.1623, 35.1398, 35.1623, 35.1623, 35.1623, 35.1398, 35.0835,\n",
      "         35.1398, 35.1398, 35.1398,  0.1000, 35.1398, 35.0835,  0.1000, 35.0835,\n",
      "         35.1623,  0.1000, 35.1623, 35.1623, 35.1623, 35.1398, 35.1398,  0.1000,\n",
      "         35.1623,  0.1000, 35.0386, 35.0386, 35.1398, 35.1623, 35.1623,  0.1000,\n",
      "          0.1000, 35.0386, 35.1398, 35.1623,  0.1000, 35.1398, 35.1623,  0.1000,\n",
      "         35.0386, 35.1623]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 227 was 97.9%\n",
      "current params: tensor([35.0386, 35.1398, 35.0835, 35.1623], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.8\n",
      "SLow rates:  tensor([[35.1439, 35.2451, 35.1888, 35.2675,  0.1000,  0.1000,  0.1000, 35.1439,\n",
      "         35.1439, 35.1439,  0.1000,  0.1000, 35.2451, 35.2451, 35.2451,  0.1000,\n",
      "          0.1000, 35.2451, 35.2451,  0.1000, 35.1888, 35.1888, 35.1888,  0.1000,\n",
      "          0.1000, 35.1888, 35.1888,  0.1000, 35.1888,  0.1000, 35.1888, 35.2675,\n",
      "         35.2675, 35.2675,  0.1000,  0.1000, 35.2675, 35.2675,  0.1000, 35.2675,\n",
      "          0.1000, 35.2675, 35.2451, 35.2675, 35.2675, 35.2675, 35.1888, 35.2675,\n",
      "         35.2675, 35.2675, 35.2451, 35.2675, 35.2675, 35.2675, 35.2451, 35.1888,\n",
      "         35.2451, 35.2451, 35.2451,  0.1000, 35.2451, 35.1888,  0.1000, 35.1888,\n",
      "         35.2675,  0.1000, 35.2675, 35.2675, 35.2675, 35.2451, 35.2451,  0.1000,\n",
      "         35.2675,  0.1000, 35.1439, 35.1439, 35.2451, 35.2675, 35.2675,  0.1000,\n",
      "          0.1000, 35.1439, 35.2451, 35.2675,  0.1000, 35.2451, 35.2675,  0.1000,\n",
      "         35.1439, 35.2675]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 228 was 97.9%\n",
      "current params: tensor([35.1439, 35.2451, 35.1888, 35.2675], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.9\n",
      "SLow rates:  tensor([[35.2492, 35.3503, 35.2941, 35.3727,  0.1000,  0.1000,  0.1000, 35.2492,\n",
      "         35.2492, 35.2492,  0.1000,  0.1000, 35.3503, 35.3503, 35.3503,  0.1000,\n",
      "          0.1000, 35.3503, 35.3503,  0.1000, 35.2941, 35.2941, 35.2941,  0.1000,\n",
      "          0.1000, 35.2941, 35.2941,  0.1000, 35.2941,  0.1000, 35.2941, 35.3727,\n",
      "         35.3727, 35.3727,  0.1000,  0.1000, 35.3727, 35.3727,  0.1000, 35.3727,\n",
      "          0.1000, 35.3727, 35.3503, 35.3727, 35.3727, 35.3727, 35.2941, 35.3727,\n",
      "         35.3727, 35.3727, 35.3503, 35.3727, 35.3727, 35.3727, 35.3503, 35.2941,\n",
      "         35.3503, 35.3503, 35.3503,  0.1000, 35.3503, 35.2941,  0.1000, 35.2941,\n",
      "         35.3727,  0.1000, 35.3727, 35.3727, 35.3727, 35.3503, 35.3503,  0.1000,\n",
      "         35.3727,  0.1000, 35.2492, 35.2492, 35.3503, 35.3727, 35.3727,  0.1000,\n",
      "          0.1000, 35.2492, 35.3503, 35.3727,  0.1000, 35.3503, 35.3727,  0.1000,\n",
      "         35.2492, 35.3727]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 229 was 97.9%\n",
      "current params: tensor([35.2492, 35.3503, 35.2941, 35.3727], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.9\n",
      "SLow rates:  tensor([[35.3544, 35.4555, 35.3993, 35.4779,  0.1000,  0.1000,  0.1000, 35.3544,\n",
      "         35.3544, 35.3544,  0.1000,  0.1000, 35.4555, 35.4555, 35.4555,  0.1000,\n",
      "          0.1000, 35.4555, 35.4555,  0.1000, 35.3993, 35.3993, 35.3993,  0.1000,\n",
      "          0.1000, 35.3993, 35.3993,  0.1000, 35.3993,  0.1000, 35.3993, 35.4779,\n",
      "         35.4779, 35.4779,  0.1000,  0.1000, 35.4779, 35.4779,  0.1000, 35.4779,\n",
      "          0.1000, 35.4779, 35.4555, 35.4779, 35.4779, 35.4779, 35.3993, 35.4779,\n",
      "         35.4779, 35.4779, 35.4555, 35.4779, 35.4779, 35.4779, 35.4555, 35.3993,\n",
      "         35.4555, 35.4555, 35.4555,  0.1000, 35.4555, 35.3993,  0.1000, 35.3993,\n",
      "         35.4779,  0.1000, 35.4779, 35.4779, 35.4779, 35.4555, 35.4555,  0.1000,\n",
      "         35.4779,  0.1000, 35.3544, 35.3544, 35.4555, 35.4779, 35.4779,  0.1000,\n",
      "          0.1000, 35.3544, 35.4555, 35.4779,  0.1000, 35.4555, 35.4779,  0.1000,\n",
      "         35.3544, 35.4779]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 230 was 97.9%\n",
      "current params: tensor([35.3544, 35.4555, 35.3993, 35.4779], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.9\n",
      "SLow rates:  tensor([[35.4596, 35.5607, 35.5044, 35.5830,  0.1000,  0.1000,  0.1000, 35.4596,\n",
      "         35.4596, 35.4596,  0.1000,  0.1000, 35.5607, 35.5607, 35.5607,  0.1000,\n",
      "          0.1000, 35.5607, 35.5607,  0.1000, 35.5044, 35.5044, 35.5044,  0.1000,\n",
      "          0.1000, 35.5044, 35.5044,  0.1000, 35.5044,  0.1000, 35.5044, 35.5830,\n",
      "         35.5830, 35.5830,  0.1000,  0.1000, 35.5830, 35.5830,  0.1000, 35.5830,\n",
      "          0.1000, 35.5830, 35.5607, 35.5830, 35.5830, 35.5830, 35.5044, 35.5830,\n",
      "         35.5830, 35.5830, 35.5607, 35.5830, 35.5830, 35.5830, 35.5607, 35.5044,\n",
      "         35.5607, 35.5607, 35.5607,  0.1000, 35.5607, 35.5044,  0.1000, 35.5044,\n",
      "         35.5830,  0.1000, 35.5830, 35.5830, 35.5830, 35.5607, 35.5607,  0.1000,\n",
      "         35.5830,  0.1000, 35.4596, 35.4596, 35.5607, 35.5830, 35.5830,  0.1000,\n",
      "          0.1000, 35.4596, 35.5607, 35.5830,  0.1000, 35.5607, 35.5830,  0.1000,\n",
      "         35.4596, 35.5830]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 231 was 97.9%\n",
      "current params: tensor([35.4596, 35.5607, 35.5044, 35.5830], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.9\n",
      "SLow rates:  tensor([[35.5647, 35.6657, 35.6095, 35.6880,  0.1000,  0.1000,  0.1000, 35.5647,\n",
      "         35.5647, 35.5647,  0.1000,  0.1000, 35.6657, 35.6657, 35.6657,  0.1000,\n",
      "          0.1000, 35.6657, 35.6657,  0.1000, 35.6095, 35.6095, 35.6095,  0.1000,\n",
      "          0.1000, 35.6095, 35.6095,  0.1000, 35.6095,  0.1000, 35.6095, 35.6880,\n",
      "         35.6880, 35.6880,  0.1000,  0.1000, 35.6880, 35.6880,  0.1000, 35.6880,\n",
      "          0.1000, 35.6880, 35.6657, 35.6880, 35.6880, 35.6880, 35.6095, 35.6880,\n",
      "         35.6880, 35.6880, 35.6657, 35.6880, 35.6880, 35.6880, 35.6657, 35.6095,\n",
      "         35.6657, 35.6657, 35.6657,  0.1000, 35.6657, 35.6095,  0.1000, 35.6095,\n",
      "         35.6880,  0.1000, 35.6880, 35.6880, 35.6880, 35.6657, 35.6657,  0.1000,\n",
      "         35.6880,  0.1000, 35.5647, 35.5647, 35.6657, 35.6880, 35.6880,  0.1000,\n",
      "          0.1000, 35.5647, 35.6657, 35.6880,  0.1000, 35.6657, 35.6880,  0.1000,\n",
      "         35.5647, 35.6880]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 232 was 97.9%\n",
      "current params: tensor([35.5647, 35.6657, 35.6095, 35.6880], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  9.9\n",
      "SLow rates:  tensor([[35.6698, 35.7708, 35.7146, 35.7930,  0.1000,  0.1000,  0.1000, 35.6698,\n",
      "         35.6698, 35.6698,  0.1000,  0.1000, 35.7708, 35.7708, 35.7708,  0.1000,\n",
      "          0.1000, 35.7708, 35.7708,  0.1000, 35.7146, 35.7146, 35.7146,  0.1000,\n",
      "          0.1000, 35.7146, 35.7146,  0.1000, 35.7146,  0.1000, 35.7146, 35.7930,\n",
      "         35.7930, 35.7930,  0.1000,  0.1000, 35.7930, 35.7930,  0.1000, 35.7930,\n",
      "          0.1000, 35.7930, 35.7708, 35.7930, 35.7930, 35.7930, 35.7146, 35.7930,\n",
      "         35.7930, 35.7930, 35.7708, 35.7930, 35.7930, 35.7930, 35.7708, 35.7146,\n",
      "         35.7708, 35.7708, 35.7708,  0.1000, 35.7708, 35.7146,  0.1000, 35.7146,\n",
      "         35.7930,  0.1000, 35.7930, 35.7930, 35.7930, 35.7708, 35.7708,  0.1000,\n",
      "         35.7930,  0.1000, 35.6698, 35.6698, 35.7708, 35.7930, 35.7930,  0.1000,\n",
      "          0.1000, 35.6698, 35.7708, 35.7930,  0.1000, 35.7708, 35.7930,  0.1000,\n",
      "         35.6698, 35.7930]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 233 was 97.9%\n",
      "current params: tensor([35.6698, 35.7708, 35.7146, 35.7930], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.0\n",
      "SLow rates:  tensor([[35.7748, 35.8757, 35.8195, 35.8979,  0.1000,  0.1000,  0.1000, 35.7748,\n",
      "         35.7748, 35.7748,  0.1000,  0.1000, 35.8757, 35.8757, 35.8757,  0.1000,\n",
      "          0.1000, 35.8757, 35.8757,  0.1000, 35.8195, 35.8195, 35.8195,  0.1000,\n",
      "          0.1000, 35.8195, 35.8195,  0.1000, 35.8195,  0.1000, 35.8195, 35.8979,\n",
      "         35.8979, 35.8979,  0.1000,  0.1000, 35.8979, 35.8979,  0.1000, 35.8979,\n",
      "          0.1000, 35.8979, 35.8757, 35.8979, 35.8979, 35.8979, 35.8195, 35.8979,\n",
      "         35.8979, 35.8979, 35.8757, 35.8979, 35.8979, 35.8979, 35.8757, 35.8195,\n",
      "         35.8757, 35.8757, 35.8757,  0.1000, 35.8757, 35.8195,  0.1000, 35.8195,\n",
      "         35.8979,  0.1000, 35.8979, 35.8979, 35.8979, 35.8757, 35.8757,  0.1000,\n",
      "         35.8979,  0.1000, 35.7748, 35.7748, 35.8757, 35.8979, 35.8979,  0.1000,\n",
      "          0.1000, 35.7748, 35.8757, 35.8979,  0.1000, 35.8757, 35.8979,  0.1000,\n",
      "         35.7748, 35.8979]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 234 was 97.9%\n",
      "current params: tensor([35.7748, 35.8757, 35.8195, 35.8979], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.0\n",
      "SLow rates:  tensor([[35.8798, 35.9806, 35.9245, 36.0028,  0.1000,  0.1000,  0.1000, 35.8798,\n",
      "         35.8798, 35.8798,  0.1000,  0.1000, 35.9806, 35.9806, 35.9806,  0.1000,\n",
      "          0.1000, 35.9806, 35.9806,  0.1000, 35.9245, 35.9245, 35.9245,  0.1000,\n",
      "          0.1000, 35.9245, 35.9245,  0.1000, 35.9245,  0.1000, 35.9245, 36.0028,\n",
      "         36.0028, 36.0028,  0.1000,  0.1000, 36.0028, 36.0028,  0.1000, 36.0028,\n",
      "          0.1000, 36.0028, 35.9806, 36.0028, 36.0028, 36.0028, 35.9245, 36.0028,\n",
      "         36.0028, 36.0028, 35.9806, 36.0028, 36.0028, 36.0028, 35.9806, 35.9245,\n",
      "         35.9806, 35.9806, 35.9806,  0.1000, 35.9806, 35.9245,  0.1000, 35.9245,\n",
      "         36.0028,  0.1000, 36.0028, 36.0028, 36.0028, 35.9806, 35.9806,  0.1000,\n",
      "         36.0028,  0.1000, 35.8798, 35.8798, 35.9806, 36.0028, 36.0028,  0.1000,\n",
      "          0.1000, 35.8798, 35.9806, 36.0028,  0.1000, 35.9806, 36.0028,  0.1000,\n",
      "         35.8798, 36.0028]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 235 was 97.9%\n",
      "current params: tensor([35.8798, 35.9806, 35.9245, 36.0028], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.0\n",
      "SLow rates:  tensor([[35.9847, 36.0855, 36.0293, 36.1076,  0.1000,  0.1000,  0.1000, 35.9847,\n",
      "         35.9847, 35.9847,  0.1000,  0.1000, 36.0855, 36.0855, 36.0855,  0.1000,\n",
      "          0.1000, 36.0855, 36.0855,  0.1000, 36.0293, 36.0293, 36.0293,  0.1000,\n",
      "          0.1000, 36.0293, 36.0293,  0.1000, 36.0293,  0.1000, 36.0293, 36.1076,\n",
      "         36.1076, 36.1076,  0.1000,  0.1000, 36.1076, 36.1076,  0.1000, 36.1076,\n",
      "          0.1000, 36.1076, 36.0855, 36.1076, 36.1076, 36.1076, 36.0293, 36.1076,\n",
      "         36.1076, 36.1076, 36.0855, 36.1076, 36.1076, 36.1076, 36.0855, 36.0293,\n",
      "         36.0855, 36.0855, 36.0855,  0.1000, 36.0855, 36.0293,  0.1000, 36.0293,\n",
      "         36.1076,  0.1000, 36.1076, 36.1076, 36.1076, 36.0855, 36.0855,  0.1000,\n",
      "         36.1076,  0.1000, 35.9847, 35.9847, 36.0855, 36.1076, 36.1076,  0.1000,\n",
      "          0.1000, 35.9847, 36.0855, 36.1076,  0.1000, 36.0855, 36.1076,  0.1000,\n",
      "         35.9847, 36.1076]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 236 was 97.9%\n",
      "current params: tensor([35.9847, 36.0855, 36.0293, 36.1076], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.0\n",
      "SLow rates:  tensor([[36.0896, 36.1903, 36.1342, 36.2124,  0.1000,  0.1000,  0.1000, 36.0896,\n",
      "         36.0896, 36.0896,  0.1000,  0.1000, 36.1903, 36.1903, 36.1903,  0.1000,\n",
      "          0.1000, 36.1903, 36.1903,  0.1000, 36.1342, 36.1342, 36.1342,  0.1000,\n",
      "          0.1000, 36.1342, 36.1342,  0.1000, 36.1342,  0.1000, 36.1342, 36.2124,\n",
      "         36.2124, 36.2124,  0.1000,  0.1000, 36.2124, 36.2124,  0.1000, 36.2124,\n",
      "          0.1000, 36.2124, 36.1903, 36.2124, 36.2124, 36.2124, 36.1342, 36.2124,\n",
      "         36.2124, 36.2124, 36.1903, 36.2124, 36.2124, 36.2124, 36.1903, 36.1342,\n",
      "         36.1903, 36.1903, 36.1903,  0.1000, 36.1903, 36.1342,  0.1000, 36.1342,\n",
      "         36.2124,  0.1000, 36.2124, 36.2124, 36.2124, 36.1903, 36.1903,  0.1000,\n",
      "         36.2124,  0.1000, 36.0896, 36.0896, 36.1903, 36.2124, 36.2124,  0.1000,\n",
      "          0.1000, 36.0896, 36.1903, 36.2124,  0.1000, 36.1903, 36.2124,  0.1000,\n",
      "         36.0896, 36.2124]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 237 was 97.9%\n",
      "current params: tensor([36.0896, 36.1903, 36.1342, 36.2124], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.0\n",
      "SLow rates:  tensor([[36.1944, 36.2950, 36.2389, 36.3171,  0.1000,  0.1000,  0.1000, 36.1944,\n",
      "         36.1944, 36.1944,  0.1000,  0.1000, 36.2950, 36.2950, 36.2950,  0.1000,\n",
      "          0.1000, 36.2950, 36.2950,  0.1000, 36.2389, 36.2389, 36.2389,  0.1000,\n",
      "          0.1000, 36.2389, 36.2389,  0.1000, 36.2389,  0.1000, 36.2389, 36.3171,\n",
      "         36.3171, 36.3171,  0.1000,  0.1000, 36.3171, 36.3171,  0.1000, 36.3171,\n",
      "          0.1000, 36.3171, 36.2950, 36.3171, 36.3171, 36.3171, 36.2389, 36.3171,\n",
      "         36.3171, 36.3171, 36.2950, 36.3171, 36.3171, 36.3171, 36.2950, 36.2389,\n",
      "         36.2950, 36.2950, 36.2950,  0.1000, 36.2950, 36.2389,  0.1000, 36.2389,\n",
      "         36.3171,  0.1000, 36.3171, 36.3171, 36.3171, 36.2950, 36.2950,  0.1000,\n",
      "         36.3171,  0.1000, 36.1944, 36.1944, 36.2950, 36.3171, 36.3171,  0.1000,\n",
      "          0.1000, 36.1944, 36.2950, 36.3171,  0.1000, 36.2950, 36.3171,  0.1000,\n",
      "         36.1944, 36.3171]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 238 was 97.9%\n",
      "current params: tensor([36.1944, 36.2950, 36.2389, 36.3171], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.0\n",
      "SLow rates:  tensor([[36.2991, 36.3997, 36.3437, 36.4217,  0.1000,  0.1000,  0.1000, 36.2991,\n",
      "         36.2991, 36.2991,  0.1000,  0.1000, 36.3997, 36.3997, 36.3997,  0.1000,\n",
      "          0.1000, 36.3997, 36.3997,  0.1000, 36.3437, 36.3437, 36.3437,  0.1000,\n",
      "          0.1000, 36.3437, 36.3437,  0.1000, 36.3437,  0.1000, 36.3437, 36.4217,\n",
      "         36.4217, 36.4217,  0.1000,  0.1000, 36.4217, 36.4217,  0.1000, 36.4217,\n",
      "          0.1000, 36.4217, 36.3997, 36.4217, 36.4217, 36.4217, 36.3437, 36.4217,\n",
      "         36.4217, 36.4217, 36.3997, 36.4217, 36.4217, 36.4217, 36.3997, 36.3437,\n",
      "         36.3997, 36.3997, 36.3997,  0.1000, 36.3997, 36.3437,  0.1000, 36.3437,\n",
      "         36.4217,  0.1000, 36.4217, 36.4217, 36.4217, 36.3997, 36.3997,  0.1000,\n",
      "         36.4217,  0.1000, 36.2991, 36.2991, 36.3997, 36.4217, 36.4217,  0.1000,\n",
      "          0.1000, 36.2991, 36.3997, 36.4217,  0.1000, 36.3997, 36.4217,  0.1000,\n",
      "         36.2991, 36.4217]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 239 was 97.9%\n",
      "current params: tensor([36.2991, 36.3997, 36.3437, 36.4217], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.1\n",
      "SLow rates:  tensor([[36.4038, 36.5044, 36.4483, 36.5263,  0.1000,  0.1000,  0.1000, 36.4038,\n",
      "         36.4038, 36.4038,  0.1000,  0.1000, 36.5044, 36.5044, 36.5044,  0.1000,\n",
      "          0.1000, 36.5044, 36.5044,  0.1000, 36.4483, 36.4483, 36.4483,  0.1000,\n",
      "          0.1000, 36.4483, 36.4483,  0.1000, 36.4483,  0.1000, 36.4483, 36.5263,\n",
      "         36.5263, 36.5263,  0.1000,  0.1000, 36.5263, 36.5263,  0.1000, 36.5263,\n",
      "          0.1000, 36.5263, 36.5044, 36.5263, 36.5263, 36.5263, 36.4483, 36.5263,\n",
      "         36.5263, 36.5263, 36.5044, 36.5263, 36.5263, 36.5263, 36.5044, 36.4483,\n",
      "         36.5044, 36.5044, 36.5044,  0.1000, 36.5044, 36.4483,  0.1000, 36.4483,\n",
      "         36.5263,  0.1000, 36.5263, 36.5263, 36.5263, 36.5044, 36.5044,  0.1000,\n",
      "         36.5263,  0.1000, 36.4038, 36.4038, 36.5044, 36.5263, 36.5263,  0.1000,\n",
      "          0.1000, 36.4038, 36.5044, 36.5263,  0.1000, 36.5044, 36.5263,  0.1000,\n",
      "         36.4038, 36.5263]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 240 was 97.9%\n",
      "current params: tensor([36.4038, 36.5044, 36.4483, 36.5263], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.1\n",
      "SLow rates:  tensor([[36.5085, 36.6090, 36.5529, 36.6309,  0.1000,  0.1000,  0.1000, 36.5085,\n",
      "         36.5085, 36.5085,  0.1000,  0.1000, 36.6090, 36.6090, 36.6090,  0.1000,\n",
      "          0.1000, 36.6090, 36.6090,  0.1000, 36.5529, 36.5529, 36.5529,  0.1000,\n",
      "          0.1000, 36.5529, 36.5529,  0.1000, 36.5529,  0.1000, 36.5529, 36.6309,\n",
      "         36.6309, 36.6309,  0.1000,  0.1000, 36.6309, 36.6309,  0.1000, 36.6309,\n",
      "          0.1000, 36.6309, 36.6090, 36.6309, 36.6309, 36.6309, 36.5529, 36.6309,\n",
      "         36.6309, 36.6309, 36.6090, 36.6309, 36.6309, 36.6309, 36.6090, 36.5529,\n",
      "         36.6090, 36.6090, 36.6090,  0.1000, 36.6090, 36.5529,  0.1000, 36.5529,\n",
      "         36.6309,  0.1000, 36.6309, 36.6309, 36.6309, 36.6090, 36.6090,  0.1000,\n",
      "         36.6309,  0.1000, 36.5085, 36.5085, 36.6090, 36.6309, 36.6309,  0.1000,\n",
      "          0.1000, 36.5085, 36.6090, 36.6309,  0.1000, 36.6090, 36.6309,  0.1000,\n",
      "         36.5085, 36.6309]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 241 was 97.9%\n",
      "current params: tensor([36.5085, 36.6090, 36.5529, 36.6309], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.1\n",
      "SLow rates:  tensor([[36.6131, 36.7136, 36.6575, 36.7354,  0.1000,  0.1000,  0.1000, 36.6131,\n",
      "         36.6131, 36.6131,  0.1000,  0.1000, 36.7136, 36.7136, 36.7136,  0.1000,\n",
      "          0.1000, 36.7136, 36.7136,  0.1000, 36.6575, 36.6575, 36.6575,  0.1000,\n",
      "          0.1000, 36.6575, 36.6575,  0.1000, 36.6575,  0.1000, 36.6575, 36.7354,\n",
      "         36.7354, 36.7354,  0.1000,  0.1000, 36.7354, 36.7354,  0.1000, 36.7354,\n",
      "          0.1000, 36.7354, 36.7136, 36.7354, 36.7354, 36.7354, 36.6575, 36.7354,\n",
      "         36.7354, 36.7354, 36.7136, 36.7354, 36.7354, 36.7354, 36.7136, 36.6575,\n",
      "         36.7136, 36.7136, 36.7136,  0.1000, 36.7136, 36.6575,  0.1000, 36.6575,\n",
      "         36.7354,  0.1000, 36.7354, 36.7354, 36.7354, 36.7136, 36.7136,  0.1000,\n",
      "         36.7354,  0.1000, 36.6131, 36.6131, 36.7136, 36.7354, 36.7354,  0.1000,\n",
      "          0.1000, 36.6131, 36.7136, 36.7354,  0.1000, 36.7136, 36.7354,  0.1000,\n",
      "         36.6131, 36.7354]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 242 was 98.0%\n",
      "current params: tensor([36.6131, 36.7136, 36.6575, 36.7354], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.1\n",
      "SLow rates:  tensor([[36.7176, 36.8181, 36.7620, 36.8399,  0.1000,  0.1000,  0.1000, 36.7176,\n",
      "         36.7176, 36.7176,  0.1000,  0.1000, 36.8181, 36.8181, 36.8181,  0.1000,\n",
      "          0.1000, 36.8181, 36.8181,  0.1000, 36.7620, 36.7620, 36.7620,  0.1000,\n",
      "          0.1000, 36.7620, 36.7620,  0.1000, 36.7620,  0.1000, 36.7620, 36.8399,\n",
      "         36.8399, 36.8399,  0.1000,  0.1000, 36.8399, 36.8399,  0.1000, 36.8399,\n",
      "          0.1000, 36.8399, 36.8181, 36.8399, 36.8399, 36.8399, 36.7620, 36.8399,\n",
      "         36.8399, 36.8399, 36.8181, 36.8399, 36.8399, 36.8399, 36.8181, 36.7620,\n",
      "         36.8181, 36.8181, 36.8181,  0.1000, 36.8181, 36.7620,  0.1000, 36.7620,\n",
      "         36.8399,  0.1000, 36.8399, 36.8399, 36.8399, 36.8181, 36.8181,  0.1000,\n",
      "         36.8399,  0.1000, 36.7176, 36.7176, 36.8181, 36.8399, 36.8399,  0.1000,\n",
      "          0.1000, 36.7176, 36.8181, 36.8399,  0.1000, 36.8181, 36.8399,  0.1000,\n",
      "         36.7176, 36.8399]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 243 was 98.0%\n",
      "current params: tensor([36.7176, 36.8181, 36.7620, 36.8399], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.1\n",
      "SLow rates:  tensor([[36.8221, 36.9225, 36.8665, 36.9443,  0.1000,  0.1000,  0.1000, 36.8221,\n",
      "         36.8221, 36.8221,  0.1000,  0.1000, 36.9225, 36.9225, 36.9225,  0.1000,\n",
      "          0.1000, 36.9225, 36.9225,  0.1000, 36.8665, 36.8665, 36.8665,  0.1000,\n",
      "          0.1000, 36.8665, 36.8665,  0.1000, 36.8665,  0.1000, 36.8665, 36.9443,\n",
      "         36.9443, 36.9443,  0.1000,  0.1000, 36.9443, 36.9443,  0.1000, 36.9443,\n",
      "          0.1000, 36.9443, 36.9225, 36.9443, 36.9443, 36.9443, 36.8665, 36.9443,\n",
      "         36.9443, 36.9443, 36.9225, 36.9443, 36.9443, 36.9443, 36.9225, 36.8665,\n",
      "         36.9225, 36.9225, 36.9225,  0.1000, 36.9225, 36.8665,  0.1000, 36.8665,\n",
      "         36.9443,  0.1000, 36.9443, 36.9443, 36.9443, 36.9225, 36.9225,  0.1000,\n",
      "         36.9443,  0.1000, 36.8221, 36.8221, 36.9225, 36.9443, 36.9443,  0.1000,\n",
      "          0.1000, 36.8221, 36.9225, 36.9443,  0.1000, 36.9225, 36.9443,  0.1000,\n",
      "         36.8221, 36.9443]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 244 was 98.0%\n",
      "current params: tensor([36.8221, 36.9225, 36.8665, 36.9443], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.2\n",
      "SLow rates:  tensor([[36.9266, 37.0269, 36.9709, 37.0487,  0.1000,  0.1000,  0.1000, 36.9266,\n",
      "         36.9266, 36.9266,  0.1000,  0.1000, 37.0269, 37.0269, 37.0269,  0.1000,\n",
      "          0.1000, 37.0269, 37.0269,  0.1000, 36.9709, 36.9709, 36.9709,  0.1000,\n",
      "          0.1000, 36.9709, 36.9709,  0.1000, 36.9709,  0.1000, 36.9709, 37.0487,\n",
      "         37.0487, 37.0487,  0.1000,  0.1000, 37.0487, 37.0487,  0.1000, 37.0487,\n",
      "          0.1000, 37.0487, 37.0269, 37.0487, 37.0487, 37.0487, 36.9709, 37.0487,\n",
      "         37.0487, 37.0487, 37.0269, 37.0487, 37.0487, 37.0487, 37.0269, 36.9709,\n",
      "         37.0269, 37.0269, 37.0269,  0.1000, 37.0269, 36.9709,  0.1000, 36.9709,\n",
      "         37.0487,  0.1000, 37.0487, 37.0487, 37.0487, 37.0269, 37.0269,  0.1000,\n",
      "         37.0487,  0.1000, 36.9266, 36.9266, 37.0269, 37.0487, 37.0487,  0.1000,\n",
      "          0.1000, 36.9266, 37.0269, 37.0487,  0.1000, 37.0269, 37.0487,  0.1000,\n",
      "         36.9266, 37.0487]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 245 was 98.0%\n",
      "current params: tensor([36.9266, 37.0269, 36.9709, 37.0487], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.2\n",
      "SLow rates:  tensor([[37.0310, 37.1313, 37.0753, 37.1530,  0.1000,  0.1000,  0.1000, 37.0310,\n",
      "         37.0310, 37.0310,  0.1000,  0.1000, 37.1313, 37.1313, 37.1313,  0.1000,\n",
      "          0.1000, 37.1313, 37.1313,  0.1000, 37.0753, 37.0753, 37.0753,  0.1000,\n",
      "          0.1000, 37.0753, 37.0753,  0.1000, 37.0753,  0.1000, 37.0753, 37.1530,\n",
      "         37.1530, 37.1530,  0.1000,  0.1000, 37.1530, 37.1530,  0.1000, 37.1530,\n",
      "          0.1000, 37.1530, 37.1313, 37.1530, 37.1530, 37.1530, 37.0753, 37.1530,\n",
      "         37.1530, 37.1530, 37.1313, 37.1530, 37.1530, 37.1530, 37.1313, 37.0753,\n",
      "         37.1313, 37.1313, 37.1313,  0.1000, 37.1313, 37.0753,  0.1000, 37.0753,\n",
      "         37.1530,  0.1000, 37.1530, 37.1530, 37.1530, 37.1313, 37.1313,  0.1000,\n",
      "         37.1530,  0.1000, 37.0310, 37.0310, 37.1313, 37.1530, 37.1530,  0.1000,\n",
      "          0.1000, 37.0310, 37.1313, 37.1530,  0.1000, 37.1313, 37.1530,  0.1000,\n",
      "         37.0310, 37.1530]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 246 was 98.0%\n",
      "current params: tensor([37.0310, 37.1313, 37.0753, 37.1530], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.2\n",
      "SLow rates:  tensor([[37.1353, 37.2356, 37.1796, 37.2573,  0.1000,  0.1000,  0.1000, 37.1353,\n",
      "         37.1353, 37.1353,  0.1000,  0.1000, 37.2356, 37.2356, 37.2356,  0.1000,\n",
      "          0.1000, 37.2356, 37.2356,  0.1000, 37.1796, 37.1796, 37.1796,  0.1000,\n",
      "          0.1000, 37.1796, 37.1796,  0.1000, 37.1796,  0.1000, 37.1796, 37.2573,\n",
      "         37.2573, 37.2573,  0.1000,  0.1000, 37.2573, 37.2573,  0.1000, 37.2573,\n",
      "          0.1000, 37.2573, 37.2356, 37.2573, 37.2573, 37.2573, 37.1796, 37.2573,\n",
      "         37.2573, 37.2573, 37.2356, 37.2573, 37.2573, 37.2573, 37.2356, 37.1796,\n",
      "         37.2356, 37.2356, 37.2356,  0.1000, 37.2356, 37.1796,  0.1000, 37.1796,\n",
      "         37.2573,  0.1000, 37.2573, 37.2573, 37.2573, 37.2356, 37.2356,  0.1000,\n",
      "         37.2573,  0.1000, 37.1353, 37.1353, 37.2356, 37.2573, 37.2573,  0.1000,\n",
      "          0.1000, 37.1353, 37.2356, 37.2573,  0.1000, 37.2356, 37.2573,  0.1000,\n",
      "         37.1353, 37.2573]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 247 was 98.0%\n",
      "current params: tensor([37.1353, 37.2356, 37.1796, 37.2573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.2\n",
      "SLow rates:  tensor([[37.2396, 37.3399, 37.2839, 37.3615,  0.1000,  0.1000,  0.1000, 37.2396,\n",
      "         37.2396, 37.2396,  0.1000,  0.1000, 37.3399, 37.3399, 37.3399,  0.1000,\n",
      "          0.1000, 37.3399, 37.3399,  0.1000, 37.2839, 37.2839, 37.2839,  0.1000,\n",
      "          0.1000, 37.2839, 37.2839,  0.1000, 37.2839,  0.1000, 37.2839, 37.3615,\n",
      "         37.3615, 37.3615,  0.1000,  0.1000, 37.3615, 37.3615,  0.1000, 37.3615,\n",
      "          0.1000, 37.3615, 37.3399, 37.3615, 37.3615, 37.3615, 37.2839, 37.3615,\n",
      "         37.3615, 37.3615, 37.3399, 37.3615, 37.3615, 37.3615, 37.3399, 37.2839,\n",
      "         37.3399, 37.3399, 37.3399,  0.1000, 37.3399, 37.2839,  0.1000, 37.2839,\n",
      "         37.3615,  0.1000, 37.3615, 37.3615, 37.3615, 37.3399, 37.3399,  0.1000,\n",
      "         37.3615,  0.1000, 37.2396, 37.2396, 37.3399, 37.3615, 37.3615,  0.1000,\n",
      "          0.1000, 37.2396, 37.3399, 37.3615,  0.1000, 37.3399, 37.3615,  0.1000,\n",
      "         37.2396, 37.3615]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 248 was 98.0%\n",
      "current params: tensor([37.2396, 37.3399, 37.2839, 37.3615], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.2\n",
      "SLow rates:  tensor([[37.3439, 37.4441, 37.3881, 37.4657,  0.1000,  0.1000,  0.1000, 37.3439,\n",
      "         37.3439, 37.3439,  0.1000,  0.1000, 37.4441, 37.4441, 37.4441,  0.1000,\n",
      "          0.1000, 37.4441, 37.4441,  0.1000, 37.3881, 37.3881, 37.3881,  0.1000,\n",
      "          0.1000, 37.3881, 37.3881,  0.1000, 37.3881,  0.1000, 37.3881, 37.4657,\n",
      "         37.4657, 37.4657,  0.1000,  0.1000, 37.4657, 37.4657,  0.1000, 37.4657,\n",
      "          0.1000, 37.4657, 37.4441, 37.4657, 37.4657, 37.4657, 37.3881, 37.4657,\n",
      "         37.4657, 37.4657, 37.4441, 37.4657, 37.4657, 37.4657, 37.4441, 37.3881,\n",
      "         37.4441, 37.4441, 37.4441,  0.1000, 37.4441, 37.3881,  0.1000, 37.3881,\n",
      "         37.4657,  0.1000, 37.4657, 37.4657, 37.4657, 37.4441, 37.4441,  0.1000,\n",
      "         37.4657,  0.1000, 37.3439, 37.3439, 37.4441, 37.4657, 37.4657,  0.1000,\n",
      "          0.1000, 37.3439, 37.4441, 37.4657,  0.1000, 37.4441, 37.4657,  0.1000,\n",
      "         37.3439, 37.4657]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 249 was 98.0%\n",
      "current params: tensor([37.3439, 37.4441, 37.3881, 37.4657], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.3\n",
      "SLow rates:  tensor([[37.4481, 37.5482, 37.4923, 37.5698,  0.1000,  0.1000,  0.1000, 37.4481,\n",
      "         37.4481, 37.4481,  0.1000,  0.1000, 37.5482, 37.5482, 37.5482,  0.1000,\n",
      "          0.1000, 37.5482, 37.5482,  0.1000, 37.4923, 37.4923, 37.4923,  0.1000,\n",
      "          0.1000, 37.4923, 37.4923,  0.1000, 37.4923,  0.1000, 37.4923, 37.5698,\n",
      "         37.5698, 37.5698,  0.1000,  0.1000, 37.5698, 37.5698,  0.1000, 37.5698,\n",
      "          0.1000, 37.5698, 37.5482, 37.5698, 37.5698, 37.5698, 37.4923, 37.5698,\n",
      "         37.5698, 37.5698, 37.5482, 37.5698, 37.5698, 37.5698, 37.5482, 37.4923,\n",
      "         37.5482, 37.5482, 37.5482,  0.1000, 37.5482, 37.4923,  0.1000, 37.4923,\n",
      "         37.5698,  0.1000, 37.5698, 37.5698, 37.5698, 37.5482, 37.5482,  0.1000,\n",
      "         37.5698,  0.1000, 37.4481, 37.4481, 37.5482, 37.5698, 37.5698,  0.1000,\n",
      "          0.1000, 37.4481, 37.5482, 37.5698,  0.1000, 37.5482, 37.5698,  0.1000,\n",
      "         37.4481, 37.5698]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 250 was 98.0%\n",
      "current params: tensor([37.4481, 37.5482, 37.4923, 37.5698], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.3\n",
      "SLow rates:  tensor([[37.5523, 37.6524, 37.5965, 37.6739,  0.1000,  0.1000,  0.1000, 37.5523,\n",
      "         37.5523, 37.5523,  0.1000,  0.1000, 37.6524, 37.6524, 37.6524,  0.1000,\n",
      "          0.1000, 37.6524, 37.6524,  0.1000, 37.5965, 37.5965, 37.5965,  0.1000,\n",
      "          0.1000, 37.5965, 37.5965,  0.1000, 37.5965,  0.1000, 37.5965, 37.6739,\n",
      "         37.6739, 37.6739,  0.1000,  0.1000, 37.6739, 37.6739,  0.1000, 37.6739,\n",
      "          0.1000, 37.6739, 37.6524, 37.6739, 37.6739, 37.6739, 37.5965, 37.6739,\n",
      "         37.6739, 37.6739, 37.6524, 37.6739, 37.6739, 37.6739, 37.6524, 37.5965,\n",
      "         37.6524, 37.6524, 37.6524,  0.1000, 37.6524, 37.5965,  0.1000, 37.5965,\n",
      "         37.6739,  0.1000, 37.6739, 37.6739, 37.6739, 37.6524, 37.6524,  0.1000,\n",
      "         37.6739,  0.1000, 37.5523, 37.5523, 37.6524, 37.6739, 37.6739,  0.1000,\n",
      "          0.1000, 37.5523, 37.6524, 37.6739,  0.1000, 37.6524, 37.6739,  0.1000,\n",
      "         37.5523, 37.6739]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 251 was 98.0%\n",
      "current params: tensor([37.5523, 37.6524, 37.5965, 37.6739], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.3\n",
      "SLow rates:  tensor([[37.6564, 37.7565, 37.7006, 37.7779,  0.1000,  0.1000,  0.1000, 37.6564,\n",
      "         37.6564, 37.6564,  0.1000,  0.1000, 37.7565, 37.7565, 37.7565,  0.1000,\n",
      "          0.1000, 37.7565, 37.7565,  0.1000, 37.7006, 37.7006, 37.7006,  0.1000,\n",
      "          0.1000, 37.7006, 37.7006,  0.1000, 37.7006,  0.1000, 37.7006, 37.7779,\n",
      "         37.7779, 37.7779,  0.1000,  0.1000, 37.7779, 37.7779,  0.1000, 37.7779,\n",
      "          0.1000, 37.7779, 37.7565, 37.7779, 37.7779, 37.7779, 37.7006, 37.7779,\n",
      "         37.7779, 37.7779, 37.7565, 37.7779, 37.7779, 37.7779, 37.7565, 37.7006,\n",
      "         37.7565, 37.7565, 37.7565,  0.1000, 37.7565, 37.7006,  0.1000, 37.7006,\n",
      "         37.7779,  0.1000, 37.7779, 37.7779, 37.7779, 37.7565, 37.7565,  0.1000,\n",
      "         37.7779,  0.1000, 37.6564, 37.6564, 37.7565, 37.7779, 37.7779,  0.1000,\n",
      "          0.1000, 37.6564, 37.7565, 37.7779,  0.1000, 37.7565, 37.7779,  0.1000,\n",
      "         37.6564, 37.7779]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 252 was 98.0%\n",
      "current params: tensor([37.6564, 37.7565, 37.7006, 37.7779], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.3\n",
      "SLow rates:  tensor([[37.7605, 37.8605, 37.8046, 37.8820,  0.1000,  0.1000,  0.1000, 37.7605,\n",
      "         37.7605, 37.7605,  0.1000,  0.1000, 37.8605, 37.8605, 37.8605,  0.1000,\n",
      "          0.1000, 37.8605, 37.8605,  0.1000, 37.8046, 37.8046, 37.8046,  0.1000,\n",
      "          0.1000, 37.8046, 37.8046,  0.1000, 37.8046,  0.1000, 37.8046, 37.8820,\n",
      "         37.8820, 37.8820,  0.1000,  0.1000, 37.8820, 37.8820,  0.1000, 37.8820,\n",
      "          0.1000, 37.8820, 37.8605, 37.8820, 37.8820, 37.8820, 37.8046, 37.8820,\n",
      "         37.8820, 37.8820, 37.8605, 37.8820, 37.8820, 37.8820, 37.8605, 37.8046,\n",
      "         37.8605, 37.8605, 37.8605,  0.1000, 37.8605, 37.8046,  0.1000, 37.8046,\n",
      "         37.8820,  0.1000, 37.8820, 37.8820, 37.8820, 37.8605, 37.8605,  0.1000,\n",
      "         37.8820,  0.1000, 37.7605, 37.7605, 37.8605, 37.8820, 37.8820,  0.1000,\n",
      "          0.1000, 37.7605, 37.8605, 37.8820,  0.1000, 37.8605, 37.8820,  0.1000,\n",
      "         37.7605, 37.8820]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 253 was 98.0%\n",
      "current params: tensor([37.7605, 37.8605, 37.8046, 37.8820], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.3\n",
      "SLow rates:  tensor([[37.8645, 37.9645, 37.9086, 37.9859,  0.1000,  0.1000,  0.1000, 37.8645,\n",
      "         37.8645, 37.8645,  0.1000,  0.1000, 37.9645, 37.9645, 37.9645,  0.1000,\n",
      "          0.1000, 37.9645, 37.9645,  0.1000, 37.9086, 37.9086, 37.9086,  0.1000,\n",
      "          0.1000, 37.9086, 37.9086,  0.1000, 37.9086,  0.1000, 37.9086, 37.9859,\n",
      "         37.9859, 37.9859,  0.1000,  0.1000, 37.9859, 37.9859,  0.1000, 37.9859,\n",
      "          0.1000, 37.9859, 37.9645, 37.9859, 37.9859, 37.9859, 37.9086, 37.9859,\n",
      "         37.9859, 37.9859, 37.9645, 37.9859, 37.9859, 37.9859, 37.9645, 37.9086,\n",
      "         37.9645, 37.9645, 37.9645,  0.1000, 37.9645, 37.9086,  0.1000, 37.9086,\n",
      "         37.9859,  0.1000, 37.9859, 37.9859, 37.9859, 37.9645, 37.9645,  0.1000,\n",
      "         37.9859,  0.1000, 37.8645, 37.8645, 37.9645, 37.9859, 37.9859,  0.1000,\n",
      "          0.1000, 37.8645, 37.9645, 37.9859,  0.1000, 37.9645, 37.9859,  0.1000,\n",
      "         37.8645, 37.9859]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 254 was 98.0%\n",
      "current params: tensor([37.8645, 37.9645, 37.9086, 37.9859], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.4\n",
      "SLow rates:  tensor([[37.9685, 38.0685, 38.0126, 38.0898,  0.1000,  0.1000,  0.1000, 37.9685,\n",
      "         37.9685, 37.9685,  0.1000,  0.1000, 38.0685, 38.0685, 38.0685,  0.1000,\n",
      "          0.1000, 38.0685, 38.0685,  0.1000, 38.0126, 38.0126, 38.0126,  0.1000,\n",
      "          0.1000, 38.0126, 38.0126,  0.1000, 38.0126,  0.1000, 38.0126, 38.0898,\n",
      "         38.0898, 38.0898,  0.1000,  0.1000, 38.0898, 38.0898,  0.1000, 38.0898,\n",
      "          0.1000, 38.0898, 38.0685, 38.0898, 38.0898, 38.0898, 38.0126, 38.0898,\n",
      "         38.0898, 38.0898, 38.0685, 38.0898, 38.0898, 38.0898, 38.0685, 38.0126,\n",
      "         38.0685, 38.0685, 38.0685,  0.1000, 38.0685, 38.0126,  0.1000, 38.0126,\n",
      "         38.0898,  0.1000, 38.0898, 38.0898, 38.0898, 38.0685, 38.0685,  0.1000,\n",
      "         38.0898,  0.1000, 37.9685, 37.9685, 38.0685, 38.0898, 38.0898,  0.1000,\n",
      "          0.1000, 37.9685, 38.0685, 38.0898,  0.1000, 38.0685, 38.0898,  0.1000,\n",
      "         37.9685, 38.0898]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 255 was 98.0%\n",
      "current params: tensor([37.9685, 38.0685, 38.0126, 38.0898], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.4\n",
      "SLow rates:  tensor([[38.0725, 38.1724, 38.1165, 38.1937,  0.1000,  0.1000,  0.1000, 38.0725,\n",
      "         38.0725, 38.0725,  0.1000,  0.1000, 38.1724, 38.1724, 38.1724,  0.1000,\n",
      "          0.1000, 38.1724, 38.1724,  0.1000, 38.1165, 38.1165, 38.1165,  0.1000,\n",
      "          0.1000, 38.1165, 38.1165,  0.1000, 38.1165,  0.1000, 38.1165, 38.1937,\n",
      "         38.1937, 38.1937,  0.1000,  0.1000, 38.1937, 38.1937,  0.1000, 38.1937,\n",
      "          0.1000, 38.1937, 38.1724, 38.1937, 38.1937, 38.1937, 38.1165, 38.1937,\n",
      "         38.1937, 38.1937, 38.1724, 38.1937, 38.1937, 38.1937, 38.1724, 38.1165,\n",
      "         38.1724, 38.1724, 38.1724,  0.1000, 38.1724, 38.1165,  0.1000, 38.1165,\n",
      "         38.1937,  0.1000, 38.1937, 38.1937, 38.1937, 38.1724, 38.1724,  0.1000,\n",
      "         38.1937,  0.1000, 38.0725, 38.0725, 38.1724, 38.1937, 38.1937,  0.1000,\n",
      "          0.1000, 38.0725, 38.1724, 38.1937,  0.1000, 38.1724, 38.1937,  0.1000,\n",
      "         38.0725, 38.1937]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 256 was 98.0%\n",
      "current params: tensor([38.0725, 38.1724, 38.1165, 38.1937], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.4\n",
      "SLow rates:  tensor([[38.1764, 38.2762, 38.2204, 38.2976,  0.1000,  0.1000,  0.1000, 38.1764,\n",
      "         38.1764, 38.1764,  0.1000,  0.1000, 38.2762, 38.2762, 38.2762,  0.1000,\n",
      "          0.1000, 38.2762, 38.2762,  0.1000, 38.2204, 38.2204, 38.2204,  0.1000,\n",
      "          0.1000, 38.2204, 38.2204,  0.1000, 38.2204,  0.1000, 38.2204, 38.2976,\n",
      "         38.2976, 38.2976,  0.1000,  0.1000, 38.2976, 38.2976,  0.1000, 38.2976,\n",
      "          0.1000, 38.2976, 38.2762, 38.2976, 38.2976, 38.2976, 38.2204, 38.2976,\n",
      "         38.2976, 38.2976, 38.2762, 38.2976, 38.2976, 38.2976, 38.2762, 38.2204,\n",
      "         38.2762, 38.2762, 38.2762,  0.1000, 38.2762, 38.2204,  0.1000, 38.2204,\n",
      "         38.2976,  0.1000, 38.2976, 38.2976, 38.2976, 38.2762, 38.2762,  0.1000,\n",
      "         38.2976,  0.1000, 38.1764, 38.1764, 38.2762, 38.2976, 38.2976,  0.1000,\n",
      "          0.1000, 38.1764, 38.2762, 38.2976,  0.1000, 38.2762, 38.2976,  0.1000,\n",
      "         38.1764, 38.2976]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 257 was 98.0%\n",
      "current params: tensor([38.1764, 38.2762, 38.2204, 38.2976], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.4\n",
      "SLow rates:  tensor([[38.2803, 38.3801, 38.3243, 38.4014,  0.1000,  0.1000,  0.1000, 38.2803,\n",
      "         38.2803, 38.2803,  0.1000,  0.1000, 38.3801, 38.3801, 38.3801,  0.1000,\n",
      "          0.1000, 38.3801, 38.3801,  0.1000, 38.3243, 38.3243, 38.3243,  0.1000,\n",
      "          0.1000, 38.3243, 38.3243,  0.1000, 38.3243,  0.1000, 38.3243, 38.4014,\n",
      "         38.4014, 38.4014,  0.1000,  0.1000, 38.4014, 38.4014,  0.1000, 38.4014,\n",
      "          0.1000, 38.4014, 38.3801, 38.4014, 38.4014, 38.4014, 38.3243, 38.4014,\n",
      "         38.4014, 38.4014, 38.3801, 38.4014, 38.4014, 38.4014, 38.3801, 38.3243,\n",
      "         38.3801, 38.3801, 38.3801,  0.1000, 38.3801, 38.3243,  0.1000, 38.3243,\n",
      "         38.4014,  0.1000, 38.4014, 38.4014, 38.4014, 38.3801, 38.3801,  0.1000,\n",
      "         38.4014,  0.1000, 38.2803, 38.2803, 38.3801, 38.4014, 38.4014,  0.1000,\n",
      "          0.1000, 38.2803, 38.3801, 38.4014,  0.1000, 38.3801, 38.4014,  0.1000,\n",
      "         38.2803, 38.4014]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 258 was 98.0%\n",
      "current params: tensor([38.2803, 38.3801, 38.3243, 38.4014], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.4\n",
      "SLow rates:  tensor([[38.3841, 38.4839, 38.4281, 38.5051,  0.1000,  0.1000,  0.1000, 38.3841,\n",
      "         38.3841, 38.3841,  0.1000,  0.1000, 38.4839, 38.4839, 38.4839,  0.1000,\n",
      "          0.1000, 38.4839, 38.4839,  0.1000, 38.4281, 38.4281, 38.4281,  0.1000,\n",
      "          0.1000, 38.4281, 38.4281,  0.1000, 38.4281,  0.1000, 38.4281, 38.5051,\n",
      "         38.5051, 38.5051,  0.1000,  0.1000, 38.5051, 38.5051,  0.1000, 38.5051,\n",
      "          0.1000, 38.5051, 38.4839, 38.5051, 38.5051, 38.5051, 38.4281, 38.5051,\n",
      "         38.5051, 38.5051, 38.4839, 38.5051, 38.5051, 38.5051, 38.4839, 38.4281,\n",
      "         38.4839, 38.4839, 38.4839,  0.1000, 38.4839, 38.4281,  0.1000, 38.4281,\n",
      "         38.5051,  0.1000, 38.5051, 38.5051, 38.5051, 38.4839, 38.4839,  0.1000,\n",
      "         38.5051,  0.1000, 38.3841, 38.3841, 38.4839, 38.5051, 38.5051,  0.1000,\n",
      "          0.1000, 38.3841, 38.4839, 38.5051,  0.1000, 38.4839, 38.5051,  0.1000,\n",
      "         38.3841, 38.5051]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 259 was 98.0%\n",
      "current params: tensor([38.3841, 38.4839, 38.4281, 38.5051], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.4\n",
      "SLow rates:  tensor([[38.4879, 38.5876, 38.5318, 38.6088,  0.1000,  0.1000,  0.1000, 38.4879,\n",
      "         38.4879, 38.4879,  0.1000,  0.1000, 38.5876, 38.5876, 38.5876,  0.1000,\n",
      "          0.1000, 38.5876, 38.5876,  0.1000, 38.5318, 38.5318, 38.5318,  0.1000,\n",
      "          0.1000, 38.5318, 38.5318,  0.1000, 38.5318,  0.1000, 38.5318, 38.6088,\n",
      "         38.6088, 38.6088,  0.1000,  0.1000, 38.6088, 38.6088,  0.1000, 38.6088,\n",
      "          0.1000, 38.6088, 38.5876, 38.6088, 38.6088, 38.6088, 38.5318, 38.6088,\n",
      "         38.6088, 38.6088, 38.5876, 38.6088, 38.6088, 38.6088, 38.5876, 38.5318,\n",
      "         38.5876, 38.5876, 38.5876,  0.1000, 38.5876, 38.5318,  0.1000, 38.5318,\n",
      "         38.6088,  0.1000, 38.6088, 38.6088, 38.6088, 38.5876, 38.5876,  0.1000,\n",
      "         38.6088,  0.1000, 38.4879, 38.4879, 38.5876, 38.6088, 38.6088,  0.1000,\n",
      "          0.1000, 38.4879, 38.5876, 38.6088,  0.1000, 38.5876, 38.6088,  0.1000,\n",
      "         38.4879, 38.6088]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 260 was 98.0%\n",
      "current params: tensor([38.4879, 38.5876, 38.5318, 38.6088], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.5\n",
      "SLow rates:  tensor([[38.5916, 38.6913, 38.6356, 38.7125,  0.1000,  0.1000,  0.1000, 38.5916,\n",
      "         38.5916, 38.5916,  0.1000,  0.1000, 38.6913, 38.6913, 38.6913,  0.1000,\n",
      "          0.1000, 38.6913, 38.6913,  0.1000, 38.6356, 38.6356, 38.6356,  0.1000,\n",
      "          0.1000, 38.6356, 38.6356,  0.1000, 38.6356,  0.1000, 38.6356, 38.7125,\n",
      "         38.7125, 38.7125,  0.1000,  0.1000, 38.7125, 38.7125,  0.1000, 38.7125,\n",
      "          0.1000, 38.7125, 38.6913, 38.7125, 38.7125, 38.7125, 38.6356, 38.7125,\n",
      "         38.7125, 38.7125, 38.6913, 38.7125, 38.7125, 38.7125, 38.6913, 38.6356,\n",
      "         38.6913, 38.6913, 38.6913,  0.1000, 38.6913, 38.6356,  0.1000, 38.6356,\n",
      "         38.7125,  0.1000, 38.7125, 38.7125, 38.7125, 38.6913, 38.6913,  0.1000,\n",
      "         38.7125,  0.1000, 38.5916, 38.5916, 38.6913, 38.7125, 38.7125,  0.1000,\n",
      "          0.1000, 38.5916, 38.6913, 38.7125,  0.1000, 38.6913, 38.7125,  0.1000,\n",
      "         38.5916, 38.7125]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 261 was 98.0%\n",
      "current params: tensor([38.5916, 38.6913, 38.6356, 38.7125], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.5\n",
      "SLow rates:  tensor([[38.6954, 38.7950, 38.7392, 38.8161,  0.1000,  0.1000,  0.1000, 38.6954,\n",
      "         38.6954, 38.6954,  0.1000,  0.1000, 38.7950, 38.7950, 38.7950,  0.1000,\n",
      "          0.1000, 38.7950, 38.7950,  0.1000, 38.7392, 38.7392, 38.7392,  0.1000,\n",
      "          0.1000, 38.7392, 38.7392,  0.1000, 38.7392,  0.1000, 38.7392, 38.8161,\n",
      "         38.8161, 38.8161,  0.1000,  0.1000, 38.8161, 38.8161,  0.1000, 38.8161,\n",
      "          0.1000, 38.8161, 38.7950, 38.8161, 38.8161, 38.8161, 38.7392, 38.8161,\n",
      "         38.8161, 38.8161, 38.7950, 38.8161, 38.8161, 38.8161, 38.7950, 38.7392,\n",
      "         38.7950, 38.7950, 38.7950,  0.1000, 38.7950, 38.7392,  0.1000, 38.7392,\n",
      "         38.8161,  0.1000, 38.8161, 38.8161, 38.8161, 38.7950, 38.7950,  0.1000,\n",
      "         38.8161,  0.1000, 38.6954, 38.6954, 38.7950, 38.8161, 38.8161,  0.1000,\n",
      "          0.1000, 38.6954, 38.7950, 38.8161,  0.1000, 38.7950, 38.8161,  0.1000,\n",
      "         38.6954, 38.8161]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 262 was 98.1%\n",
      "current params: tensor([38.6954, 38.7950, 38.7392, 38.8161], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.5\n",
      "SLow rates:  tensor([[38.7990, 38.8986, 38.8429, 38.9197,  0.1000,  0.1000,  0.1000, 38.7990,\n",
      "         38.7990, 38.7990,  0.1000,  0.1000, 38.8986, 38.8986, 38.8986,  0.1000,\n",
      "          0.1000, 38.8986, 38.8986,  0.1000, 38.8429, 38.8429, 38.8429,  0.1000,\n",
      "          0.1000, 38.8429, 38.8429,  0.1000, 38.8429,  0.1000, 38.8429, 38.9197,\n",
      "         38.9197, 38.9197,  0.1000,  0.1000, 38.9197, 38.9197,  0.1000, 38.9197,\n",
      "          0.1000, 38.9197, 38.8986, 38.9197, 38.9197, 38.9197, 38.8429, 38.9197,\n",
      "         38.9197, 38.9197, 38.8986, 38.9197, 38.9197, 38.9197, 38.8986, 38.8429,\n",
      "         38.8986, 38.8986, 38.8986,  0.1000, 38.8986, 38.8429,  0.1000, 38.8429,\n",
      "         38.9197,  0.1000, 38.9197, 38.9197, 38.9197, 38.8986, 38.8986,  0.1000,\n",
      "         38.9197,  0.1000, 38.7990, 38.7990, 38.8986, 38.9197, 38.9197,  0.1000,\n",
      "          0.1000, 38.7990, 38.8986, 38.9197,  0.1000, 38.8986, 38.9197,  0.1000,\n",
      "         38.7990, 38.9197]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 263 was 98.1%\n",
      "current params: tensor([38.7990, 38.8986, 38.8429, 38.9197], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.5\n",
      "SLow rates:  tensor([[38.9027, 39.0022, 38.9465, 39.0233,  0.1000,  0.1000,  0.1000, 38.9027,\n",
      "         38.9027, 38.9027,  0.1000,  0.1000, 39.0022, 39.0022, 39.0022,  0.1000,\n",
      "          0.1000, 39.0022, 39.0022,  0.1000, 38.9465, 38.9465, 38.9465,  0.1000,\n",
      "          0.1000, 38.9465, 38.9465,  0.1000, 38.9465,  0.1000, 38.9465, 39.0233,\n",
      "         39.0233, 39.0233,  0.1000,  0.1000, 39.0233, 39.0233,  0.1000, 39.0233,\n",
      "          0.1000, 39.0233, 39.0022, 39.0233, 39.0233, 39.0233, 38.9465, 39.0233,\n",
      "         39.0233, 39.0233, 39.0022, 39.0233, 39.0233, 39.0233, 39.0022, 38.9465,\n",
      "         39.0022, 39.0022, 39.0022,  0.1000, 39.0022, 38.9465,  0.1000, 38.9465,\n",
      "         39.0233,  0.1000, 39.0233, 39.0233, 39.0233, 39.0022, 39.0022,  0.1000,\n",
      "         39.0233,  0.1000, 38.9027, 38.9027, 39.0022, 39.0233, 39.0233,  0.1000,\n",
      "          0.1000, 38.9027, 39.0022, 39.0233,  0.1000, 39.0022, 39.0233,  0.1000,\n",
      "         38.9027, 39.0233]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 264 was 98.1%\n",
      "current params: tensor([38.9027, 39.0022, 38.9465, 39.0233], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.5\n",
      "SLow rates:  tensor([[39.0063, 39.1058, 39.0501, 39.1268,  0.1000,  0.1000,  0.1000, 39.0063,\n",
      "         39.0063, 39.0063,  0.1000,  0.1000, 39.1058, 39.1058, 39.1058,  0.1000,\n",
      "          0.1000, 39.1058, 39.1058,  0.1000, 39.0501, 39.0501, 39.0501,  0.1000,\n",
      "          0.1000, 39.0501, 39.0501,  0.1000, 39.0501,  0.1000, 39.0501, 39.1268,\n",
      "         39.1268, 39.1268,  0.1000,  0.1000, 39.1268, 39.1268,  0.1000, 39.1268,\n",
      "          0.1000, 39.1268, 39.1058, 39.1268, 39.1268, 39.1268, 39.0501, 39.1268,\n",
      "         39.1268, 39.1268, 39.1058, 39.1268, 39.1268, 39.1268, 39.1058, 39.0501,\n",
      "         39.1058, 39.1058, 39.1058,  0.1000, 39.1058, 39.0501,  0.1000, 39.0501,\n",
      "         39.1268,  0.1000, 39.1268, 39.1268, 39.1268, 39.1058, 39.1058,  0.1000,\n",
      "         39.1268,  0.1000, 39.0063, 39.0063, 39.1058, 39.1268, 39.1268,  0.1000,\n",
      "          0.1000, 39.0063, 39.1058, 39.1268,  0.1000, 39.1058, 39.1268,  0.1000,\n",
      "         39.0063, 39.1268]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 265 was 98.1%\n",
      "current params: tensor([39.0063, 39.1058, 39.0501, 39.1268], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.6\n",
      "SLow rates:  tensor([[39.1098, 39.2093, 39.1536, 39.2303,  0.1000,  0.1000,  0.1000, 39.1098,\n",
      "         39.1098, 39.1098,  0.1000,  0.1000, 39.2093, 39.2093, 39.2093,  0.1000,\n",
      "          0.1000, 39.2093, 39.2093,  0.1000, 39.1536, 39.1536, 39.1536,  0.1000,\n",
      "          0.1000, 39.1536, 39.1536,  0.1000, 39.1536,  0.1000, 39.1536, 39.2303,\n",
      "         39.2303, 39.2303,  0.1000,  0.1000, 39.2303, 39.2303,  0.1000, 39.2303,\n",
      "          0.1000, 39.2303, 39.2093, 39.2303, 39.2303, 39.2303, 39.1536, 39.2303,\n",
      "         39.2303, 39.2303, 39.2093, 39.2303, 39.2303, 39.2303, 39.2093, 39.1536,\n",
      "         39.2093, 39.2093, 39.2093,  0.1000, 39.2093, 39.1536,  0.1000, 39.1536,\n",
      "         39.2303,  0.1000, 39.2303, 39.2303, 39.2303, 39.2093, 39.2093,  0.1000,\n",
      "         39.2303,  0.1000, 39.1098, 39.1098, 39.2093, 39.2303, 39.2303,  0.1000,\n",
      "          0.1000, 39.1098, 39.2093, 39.2303,  0.1000, 39.2093, 39.2303,  0.1000,\n",
      "         39.1098, 39.2303]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 266 was 98.1%\n",
      "current params: tensor([39.1098, 39.2093, 39.1536, 39.2303], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.6\n",
      "SLow rates:  tensor([[39.2133, 39.3128, 39.2571, 39.3337,  0.1000,  0.1000,  0.1000, 39.2133,\n",
      "         39.2133, 39.2133,  0.1000,  0.1000, 39.3128, 39.3128, 39.3128,  0.1000,\n",
      "          0.1000, 39.3128, 39.3128,  0.1000, 39.2571, 39.2571, 39.2571,  0.1000,\n",
      "          0.1000, 39.2571, 39.2571,  0.1000, 39.2571,  0.1000, 39.2571, 39.3337,\n",
      "         39.3337, 39.3337,  0.1000,  0.1000, 39.3337, 39.3337,  0.1000, 39.3337,\n",
      "          0.1000, 39.3337, 39.3128, 39.3337, 39.3337, 39.3337, 39.2571, 39.3337,\n",
      "         39.3337, 39.3337, 39.3128, 39.3337, 39.3337, 39.3337, 39.3128, 39.2571,\n",
      "         39.3128, 39.3128, 39.3128,  0.1000, 39.3128, 39.2571,  0.1000, 39.2571,\n",
      "         39.3337,  0.1000, 39.3337, 39.3337, 39.3337, 39.3128, 39.3128,  0.1000,\n",
      "         39.3337,  0.1000, 39.2133, 39.2133, 39.3128, 39.3337, 39.3337,  0.1000,\n",
      "          0.1000, 39.2133, 39.3128, 39.3337,  0.1000, 39.3128, 39.3337,  0.1000,\n",
      "         39.2133, 39.3337]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 267 was 98.1%\n",
      "current params: tensor([39.2133, 39.3128, 39.2571, 39.3337], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.6\n",
      "SLow rates:  tensor([[39.3168, 39.4162, 39.3605, 39.4372,  0.1000,  0.1000,  0.1000, 39.3168,\n",
      "         39.3168, 39.3168,  0.1000,  0.1000, 39.4162, 39.4162, 39.4162,  0.1000,\n",
      "          0.1000, 39.4162, 39.4162,  0.1000, 39.3605, 39.3605, 39.3605,  0.1000,\n",
      "          0.1000, 39.3605, 39.3605,  0.1000, 39.3605,  0.1000, 39.3605, 39.4372,\n",
      "         39.4372, 39.4372,  0.1000,  0.1000, 39.4372, 39.4372,  0.1000, 39.4372,\n",
      "          0.1000, 39.4372, 39.4162, 39.4372, 39.4372, 39.4372, 39.3605, 39.4372,\n",
      "         39.4372, 39.4372, 39.4162, 39.4372, 39.4372, 39.4372, 39.4162, 39.3605,\n",
      "         39.4162, 39.4162, 39.4162,  0.1000, 39.4162, 39.3605,  0.1000, 39.3605,\n",
      "         39.4372,  0.1000, 39.4372, 39.4372, 39.4372, 39.4162, 39.4162,  0.1000,\n",
      "         39.4372,  0.1000, 39.3168, 39.3168, 39.4162, 39.4372, 39.4372,  0.1000,\n",
      "          0.1000, 39.3168, 39.4162, 39.4372,  0.1000, 39.4162, 39.4372,  0.1000,\n",
      "         39.3168, 39.4372]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 268 was 98.1%\n",
      "current params: tensor([39.3168, 39.4162, 39.3605, 39.4372], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.6\n",
      "SLow rates:  tensor([[39.4203, 39.5196, 39.4640, 39.5405,  0.1000,  0.1000,  0.1000, 39.4203,\n",
      "         39.4203, 39.4203,  0.1000,  0.1000, 39.5196, 39.5196, 39.5196,  0.1000,\n",
      "          0.1000, 39.5196, 39.5196,  0.1000, 39.4640, 39.4640, 39.4640,  0.1000,\n",
      "          0.1000, 39.4640, 39.4640,  0.1000, 39.4640,  0.1000, 39.4640, 39.5405,\n",
      "         39.5405, 39.5405,  0.1000,  0.1000, 39.5405, 39.5405,  0.1000, 39.5405,\n",
      "          0.1000, 39.5405, 39.5196, 39.5405, 39.5405, 39.5405, 39.4640, 39.5405,\n",
      "         39.5405, 39.5405, 39.5196, 39.5405, 39.5405, 39.5405, 39.5196, 39.4640,\n",
      "         39.5196, 39.5196, 39.5196,  0.1000, 39.5196, 39.4640,  0.1000, 39.4640,\n",
      "         39.5405,  0.1000, 39.5405, 39.5405, 39.5405, 39.5196, 39.5196,  0.1000,\n",
      "         39.5405,  0.1000, 39.4203, 39.4203, 39.5196, 39.5405, 39.5405,  0.1000,\n",
      "          0.1000, 39.4203, 39.5196, 39.5405,  0.1000, 39.5196, 39.5405,  0.1000,\n",
      "         39.4203, 39.5405]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 269 was 98.1%\n",
      "current params: tensor([39.4203, 39.5196, 39.4640, 39.5405], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.6\n",
      "SLow rates:  tensor([[39.5237, 39.6230, 39.5673, 39.6439,  0.1000,  0.1000,  0.1000, 39.5237,\n",
      "         39.5237, 39.5237,  0.1000,  0.1000, 39.6230, 39.6230, 39.6230,  0.1000,\n",
      "          0.1000, 39.6230, 39.6230,  0.1000, 39.5673, 39.5673, 39.5673,  0.1000,\n",
      "          0.1000, 39.5673, 39.5673,  0.1000, 39.5673,  0.1000, 39.5673, 39.6439,\n",
      "         39.6439, 39.6439,  0.1000,  0.1000, 39.6439, 39.6439,  0.1000, 39.6439,\n",
      "          0.1000, 39.6439, 39.6230, 39.6439, 39.6439, 39.6439, 39.5673, 39.6439,\n",
      "         39.6439, 39.6439, 39.6230, 39.6439, 39.6439, 39.6439, 39.6230, 39.5673,\n",
      "         39.6230, 39.6230, 39.6230,  0.1000, 39.6230, 39.5673,  0.1000, 39.5673,\n",
      "         39.6439,  0.1000, 39.6439, 39.6439, 39.6439, 39.6230, 39.6230,  0.1000,\n",
      "         39.6439,  0.1000, 39.5237, 39.5237, 39.6230, 39.6439, 39.6439,  0.1000,\n",
      "          0.1000, 39.5237, 39.6230, 39.6439,  0.1000, 39.6230, 39.6439,  0.1000,\n",
      "         39.5237, 39.6439]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 270 was 98.1%\n",
      "current params: tensor([39.5237, 39.6230, 39.5673, 39.6439], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.7\n",
      "SLow rates:  tensor([[39.6270, 39.7263, 39.6707, 39.7472,  0.1000,  0.1000,  0.1000, 39.6270,\n",
      "         39.6270, 39.6270,  0.1000,  0.1000, 39.7263, 39.7263, 39.7263,  0.1000,\n",
      "          0.1000, 39.7263, 39.7263,  0.1000, 39.6707, 39.6707, 39.6707,  0.1000,\n",
      "          0.1000, 39.6707, 39.6707,  0.1000, 39.6707,  0.1000, 39.6707, 39.7472,\n",
      "         39.7472, 39.7472,  0.1000,  0.1000, 39.7472, 39.7472,  0.1000, 39.7472,\n",
      "          0.1000, 39.7472, 39.7263, 39.7472, 39.7472, 39.7472, 39.6707, 39.7472,\n",
      "         39.7472, 39.7472, 39.7263, 39.7472, 39.7472, 39.7472, 39.7263, 39.6707,\n",
      "         39.7263, 39.7263, 39.7263,  0.1000, 39.7263, 39.6707,  0.1000, 39.6707,\n",
      "         39.7472,  0.1000, 39.7472, 39.7472, 39.7472, 39.7263, 39.7263,  0.1000,\n",
      "         39.7472,  0.1000, 39.6270, 39.6270, 39.7263, 39.7472, 39.7472,  0.1000,\n",
      "          0.1000, 39.6270, 39.7263, 39.7472,  0.1000, 39.7263, 39.7472,  0.1000,\n",
      "         39.6270, 39.7472]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 271 was 98.1%\n",
      "current params: tensor([39.6270, 39.7263, 39.6707, 39.7472], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.7\n",
      "SLow rates:  tensor([[39.7304, 39.8296, 39.7740, 39.8504,  0.1000,  0.1000,  0.1000, 39.7304,\n",
      "         39.7304, 39.7304,  0.1000,  0.1000, 39.8296, 39.8296, 39.8296,  0.1000,\n",
      "          0.1000, 39.8296, 39.8296,  0.1000, 39.7740, 39.7740, 39.7740,  0.1000,\n",
      "          0.1000, 39.7740, 39.7740,  0.1000, 39.7740,  0.1000, 39.7740, 39.8504,\n",
      "         39.8504, 39.8504,  0.1000,  0.1000, 39.8504, 39.8504,  0.1000, 39.8504,\n",
      "          0.1000, 39.8504, 39.8296, 39.8504, 39.8504, 39.8504, 39.7740, 39.8504,\n",
      "         39.8504, 39.8504, 39.8296, 39.8504, 39.8504, 39.8504, 39.8296, 39.7740,\n",
      "         39.8296, 39.8296, 39.8296,  0.1000, 39.8296, 39.7740,  0.1000, 39.7740,\n",
      "         39.8504,  0.1000, 39.8504, 39.8504, 39.8504, 39.8296, 39.8296,  0.1000,\n",
      "         39.8504,  0.1000, 39.7304, 39.7304, 39.8296, 39.8504, 39.8504,  0.1000,\n",
      "          0.1000, 39.7304, 39.8296, 39.8504,  0.1000, 39.8296, 39.8504,  0.1000,\n",
      "         39.7304, 39.8504]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 272 was 98.1%\n",
      "current params: tensor([39.7304, 39.8296, 39.7740, 39.8504], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.7\n",
      "SLow rates:  tensor([[39.8337, 39.9329, 39.8773, 39.9537,  0.1000,  0.1000,  0.1000, 39.8337,\n",
      "         39.8337, 39.8337,  0.1000,  0.1000, 39.9329, 39.9329, 39.9329,  0.1000,\n",
      "          0.1000, 39.9329, 39.9329,  0.1000, 39.8773, 39.8773, 39.8773,  0.1000,\n",
      "          0.1000, 39.8773, 39.8773,  0.1000, 39.8773,  0.1000, 39.8773, 39.9537,\n",
      "         39.9537, 39.9537,  0.1000,  0.1000, 39.9537, 39.9537,  0.1000, 39.9537,\n",
      "          0.1000, 39.9537, 39.9329, 39.9537, 39.9537, 39.9537, 39.8773, 39.9537,\n",
      "         39.9537, 39.9537, 39.9329, 39.9537, 39.9537, 39.9537, 39.9329, 39.8773,\n",
      "         39.9329, 39.9329, 39.9329,  0.1000, 39.9329, 39.8773,  0.1000, 39.8773,\n",
      "         39.9537,  0.1000, 39.9537, 39.9537, 39.9537, 39.9329, 39.9329,  0.1000,\n",
      "         39.9537,  0.1000, 39.8337, 39.8337, 39.9329, 39.9537, 39.9537,  0.1000,\n",
      "          0.1000, 39.8337, 39.9329, 39.9537,  0.1000, 39.9329, 39.9537,  0.1000,\n",
      "         39.8337, 39.9537]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 273 was 98.1%\n",
      "current params: tensor([39.8337, 39.9329, 39.8773, 39.9537], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.7\n",
      "SLow rates:  tensor([[39.9369, 40.0361, 39.9805, 40.0569,  0.1000,  0.1000,  0.1000, 39.9369,\n",
      "         39.9369, 39.9369,  0.1000,  0.1000, 40.0361, 40.0361, 40.0361,  0.1000,\n",
      "          0.1000, 40.0361, 40.0361,  0.1000, 39.9805, 39.9805, 39.9805,  0.1000,\n",
      "          0.1000, 39.9805, 39.9805,  0.1000, 39.9805,  0.1000, 39.9805, 40.0569,\n",
      "         40.0569, 40.0569,  0.1000,  0.1000, 40.0569, 40.0569,  0.1000, 40.0569,\n",
      "          0.1000, 40.0569, 40.0361, 40.0569, 40.0569, 40.0569, 39.9805, 40.0569,\n",
      "         40.0569, 40.0569, 40.0361, 40.0569, 40.0569, 40.0569, 40.0361, 39.9805,\n",
      "         40.0361, 40.0361, 40.0361,  0.1000, 40.0361, 39.9805,  0.1000, 39.9805,\n",
      "         40.0569,  0.1000, 40.0569, 40.0569, 40.0569, 40.0361, 40.0361,  0.1000,\n",
      "         40.0569,  0.1000, 39.9369, 39.9369, 40.0361, 40.0569, 40.0569,  0.1000,\n",
      "          0.1000, 39.9369, 40.0361, 40.0569,  0.1000, 40.0361, 40.0569,  0.1000,\n",
      "         39.9369, 40.0569]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 274 was 98.1%\n",
      "current params: tensor([39.9369, 40.0361, 39.9805, 40.0569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.7\n",
      "SLow rates:  tensor([[40.0402, 40.1393, 40.0837, 40.1600,  0.1000,  0.1000,  0.1000, 40.0402,\n",
      "         40.0402, 40.0402,  0.1000,  0.1000, 40.1393, 40.1393, 40.1393,  0.1000,\n",
      "          0.1000, 40.1393, 40.1393,  0.1000, 40.0837, 40.0837, 40.0837,  0.1000,\n",
      "          0.1000, 40.0837, 40.0837,  0.1000, 40.0837,  0.1000, 40.0837, 40.1600,\n",
      "         40.1600, 40.1600,  0.1000,  0.1000, 40.1600, 40.1600,  0.1000, 40.1600,\n",
      "          0.1000, 40.1600, 40.1393, 40.1600, 40.1600, 40.1600, 40.0837, 40.1600,\n",
      "         40.1600, 40.1600, 40.1393, 40.1600, 40.1600, 40.1600, 40.1393, 40.0837,\n",
      "         40.1393, 40.1393, 40.1393,  0.1000, 40.1393, 40.0837,  0.1000, 40.0837,\n",
      "         40.1600,  0.1000, 40.1600, 40.1600, 40.1600, 40.1393, 40.1393,  0.1000,\n",
      "         40.1600,  0.1000, 40.0402, 40.0402, 40.1393, 40.1600, 40.1600,  0.1000,\n",
      "          0.1000, 40.0402, 40.1393, 40.1600,  0.1000, 40.1393, 40.1600,  0.1000,\n",
      "         40.0402, 40.1600]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 275 was 98.1%\n",
      "current params: tensor([40.0402, 40.1393, 40.0837, 40.1600], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.7\n",
      "SLow rates:  tensor([[40.1434, 40.2425, 40.1869, 40.2632,  0.1000,  0.1000,  0.1000, 40.1434,\n",
      "         40.1434, 40.1434,  0.1000,  0.1000, 40.2425, 40.2425, 40.2425,  0.1000,\n",
      "          0.1000, 40.2425, 40.2425,  0.1000, 40.1869, 40.1869, 40.1869,  0.1000,\n",
      "          0.1000, 40.1869, 40.1869,  0.1000, 40.1869,  0.1000, 40.1869, 40.2632,\n",
      "         40.2632, 40.2632,  0.1000,  0.1000, 40.2632, 40.2632,  0.1000, 40.2632,\n",
      "          0.1000, 40.2632, 40.2425, 40.2632, 40.2632, 40.2632, 40.1869, 40.2632,\n",
      "         40.2632, 40.2632, 40.2425, 40.2632, 40.2632, 40.2632, 40.2425, 40.1869,\n",
      "         40.2425, 40.2425, 40.2425,  0.1000, 40.2425, 40.1869,  0.1000, 40.1869,\n",
      "         40.2632,  0.1000, 40.2632, 40.2632, 40.2632, 40.2425, 40.2425,  0.1000,\n",
      "         40.2632,  0.1000, 40.1434, 40.1434, 40.2425, 40.2632, 40.2632,  0.1000,\n",
      "          0.1000, 40.1434, 40.2425, 40.2632,  0.1000, 40.2425, 40.2632,  0.1000,\n",
      "         40.1434, 40.2632]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 276 was 98.1%\n",
      "current params: tensor([40.1434, 40.2425, 40.1869, 40.2632], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.8\n",
      "SLow rates:  tensor([[40.2465, 40.3456, 40.2900, 40.3663,  0.1000,  0.1000,  0.1000, 40.2465,\n",
      "         40.2465, 40.2465,  0.1000,  0.1000, 40.3456, 40.3456, 40.3456,  0.1000,\n",
      "          0.1000, 40.3456, 40.3456,  0.1000, 40.2900, 40.2900, 40.2900,  0.1000,\n",
      "          0.1000, 40.2900, 40.2900,  0.1000, 40.2900,  0.1000, 40.2900, 40.3663,\n",
      "         40.3663, 40.3663,  0.1000,  0.1000, 40.3663, 40.3663,  0.1000, 40.3663,\n",
      "          0.1000, 40.3663, 40.3456, 40.3663, 40.3663, 40.3663, 40.2900, 40.3663,\n",
      "         40.3663, 40.3663, 40.3456, 40.3663, 40.3663, 40.3663, 40.3456, 40.2900,\n",
      "         40.3456, 40.3456, 40.3456,  0.1000, 40.3456, 40.2900,  0.1000, 40.2900,\n",
      "         40.3663,  0.1000, 40.3663, 40.3663, 40.3663, 40.3456, 40.3456,  0.1000,\n",
      "         40.3663,  0.1000, 40.2465, 40.2465, 40.3456, 40.3663, 40.3663,  0.1000,\n",
      "          0.1000, 40.2465, 40.3456, 40.3663,  0.1000, 40.3456, 40.3663,  0.1000,\n",
      "         40.2465, 40.3663]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 277 was 98.1%\n",
      "current params: tensor([40.2465, 40.3456, 40.2900, 40.3663], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.8\n",
      "SLow rates:  tensor([[40.3497, 40.4487, 40.3931, 40.4693,  0.1000,  0.1000,  0.1000, 40.3497,\n",
      "         40.3497, 40.3497,  0.1000,  0.1000, 40.4487, 40.4487, 40.4487,  0.1000,\n",
      "          0.1000, 40.4487, 40.4487,  0.1000, 40.3931, 40.3931, 40.3931,  0.1000,\n",
      "          0.1000, 40.3931, 40.3931,  0.1000, 40.3931,  0.1000, 40.3931, 40.4693,\n",
      "         40.4693, 40.4693,  0.1000,  0.1000, 40.4693, 40.4693,  0.1000, 40.4693,\n",
      "          0.1000, 40.4693, 40.4487, 40.4693, 40.4693, 40.4693, 40.3931, 40.4693,\n",
      "         40.4693, 40.4693, 40.4487, 40.4693, 40.4693, 40.4693, 40.4487, 40.3931,\n",
      "         40.4487, 40.4487, 40.4487,  0.1000, 40.4487, 40.3931,  0.1000, 40.3931,\n",
      "         40.4693,  0.1000, 40.4693, 40.4693, 40.4693, 40.4487, 40.4487,  0.1000,\n",
      "         40.4693,  0.1000, 40.3497, 40.3497, 40.4487, 40.4693, 40.4693,  0.1000,\n",
      "          0.1000, 40.3497, 40.4487, 40.4693,  0.1000, 40.4487, 40.4693,  0.1000,\n",
      "         40.3497, 40.4693]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 278 was 98.1%\n",
      "current params: tensor([40.3497, 40.4487, 40.3931, 40.4693], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.8\n",
      "SLow rates:  tensor([[40.4528, 40.5517, 40.4962, 40.5724,  0.1000,  0.1000,  0.1000, 40.4528,\n",
      "         40.4528, 40.4528,  0.1000,  0.1000, 40.5517, 40.5517, 40.5517,  0.1000,\n",
      "          0.1000, 40.5517, 40.5517,  0.1000, 40.4962, 40.4962, 40.4962,  0.1000,\n",
      "          0.1000, 40.4962, 40.4962,  0.1000, 40.4962,  0.1000, 40.4962, 40.5724,\n",
      "         40.5724, 40.5724,  0.1000,  0.1000, 40.5724, 40.5724,  0.1000, 40.5724,\n",
      "          0.1000, 40.5724, 40.5517, 40.5724, 40.5724, 40.5724, 40.4962, 40.5724,\n",
      "         40.5724, 40.5724, 40.5517, 40.5724, 40.5724, 40.5724, 40.5517, 40.4962,\n",
      "         40.5517, 40.5517, 40.5517,  0.1000, 40.5517, 40.4962,  0.1000, 40.4962,\n",
      "         40.5724,  0.1000, 40.5724, 40.5724, 40.5724, 40.5517, 40.5517,  0.1000,\n",
      "         40.5724,  0.1000, 40.4528, 40.4528, 40.5517, 40.5724, 40.5724,  0.1000,\n",
      "          0.1000, 40.4528, 40.5517, 40.5724,  0.1000, 40.5517, 40.5724,  0.1000,\n",
      "         40.4528, 40.5724]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 279 was 98.1%\n",
      "current params: tensor([40.4528, 40.5517, 40.4962, 40.5724], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.8\n",
      "SLow rates:  tensor([[40.5558, 40.6548, 40.5993, 40.6754,  0.1000,  0.1000,  0.1000, 40.5558,\n",
      "         40.5558, 40.5558,  0.1000,  0.1000, 40.6548, 40.6548, 40.6548,  0.1000,\n",
      "          0.1000, 40.6548, 40.6548,  0.1000, 40.5993, 40.5993, 40.5993,  0.1000,\n",
      "          0.1000, 40.5993, 40.5993,  0.1000, 40.5993,  0.1000, 40.5993, 40.6754,\n",
      "         40.6754, 40.6754,  0.1000,  0.1000, 40.6754, 40.6754,  0.1000, 40.6754,\n",
      "          0.1000, 40.6754, 40.6548, 40.6754, 40.6754, 40.6754, 40.5993, 40.6754,\n",
      "         40.6754, 40.6754, 40.6548, 40.6754, 40.6754, 40.6754, 40.6548, 40.5993,\n",
      "         40.6548, 40.6548, 40.6548,  0.1000, 40.6548, 40.5993,  0.1000, 40.5993,\n",
      "         40.6754,  0.1000, 40.6754, 40.6754, 40.6754, 40.6548, 40.6548,  0.1000,\n",
      "         40.6754,  0.1000, 40.5558, 40.5558, 40.6548, 40.6754, 40.6754,  0.1000,\n",
      "          0.1000, 40.5558, 40.6548, 40.6754,  0.1000, 40.6548, 40.6754,  0.1000,\n",
      "         40.5558, 40.6754]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 280 was 98.1%\n",
      "current params: tensor([40.5558, 40.6548, 40.5993, 40.6754], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.8\n",
      "SLow rates:  tensor([[40.6589, 40.7578, 40.7023, 40.7783,  0.1000,  0.1000,  0.1000, 40.6589,\n",
      "         40.6589, 40.6589,  0.1000,  0.1000, 40.7578, 40.7578, 40.7578,  0.1000,\n",
      "          0.1000, 40.7578, 40.7578,  0.1000, 40.7023, 40.7023, 40.7023,  0.1000,\n",
      "          0.1000, 40.7023, 40.7023,  0.1000, 40.7023,  0.1000, 40.7023, 40.7783,\n",
      "         40.7783, 40.7783,  0.1000,  0.1000, 40.7783, 40.7783,  0.1000, 40.7783,\n",
      "          0.1000, 40.7783, 40.7578, 40.7783, 40.7783, 40.7783, 40.7023, 40.7783,\n",
      "         40.7783, 40.7783, 40.7578, 40.7783, 40.7783, 40.7783, 40.7578, 40.7023,\n",
      "         40.7578, 40.7578, 40.7578,  0.1000, 40.7578, 40.7023,  0.1000, 40.7023,\n",
      "         40.7783,  0.1000, 40.7783, 40.7783, 40.7783, 40.7578, 40.7578,  0.1000,\n",
      "         40.7783,  0.1000, 40.6589, 40.6589, 40.7578, 40.7783, 40.7783,  0.1000,\n",
      "          0.1000, 40.6589, 40.7578, 40.7783,  0.1000, 40.7578, 40.7783,  0.1000,\n",
      "         40.6589, 40.7783]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 281 was 98.1%\n",
      "current params: tensor([40.6589, 40.7578, 40.7023, 40.7783], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.9\n",
      "SLow rates:  tensor([[40.7619, 40.8607, 40.8053, 40.8813,  0.1000,  0.1000,  0.1000, 40.7619,\n",
      "         40.7619, 40.7619,  0.1000,  0.1000, 40.8607, 40.8607, 40.8607,  0.1000,\n",
      "          0.1000, 40.8607, 40.8607,  0.1000, 40.8053, 40.8053, 40.8053,  0.1000,\n",
      "          0.1000, 40.8053, 40.8053,  0.1000, 40.8053,  0.1000, 40.8053, 40.8813,\n",
      "         40.8813, 40.8813,  0.1000,  0.1000, 40.8813, 40.8813,  0.1000, 40.8813,\n",
      "          0.1000, 40.8813, 40.8607, 40.8813, 40.8813, 40.8813, 40.8053, 40.8813,\n",
      "         40.8813, 40.8813, 40.8607, 40.8813, 40.8813, 40.8813, 40.8607, 40.8053,\n",
      "         40.8607, 40.8607, 40.8607,  0.1000, 40.8607, 40.8053,  0.1000, 40.8053,\n",
      "         40.8813,  0.1000, 40.8813, 40.8813, 40.8813, 40.8607, 40.8607,  0.1000,\n",
      "         40.8813,  0.1000, 40.7619, 40.7619, 40.8607, 40.8813, 40.8813,  0.1000,\n",
      "          0.1000, 40.7619, 40.8607, 40.8813,  0.1000, 40.8607, 40.8813,  0.1000,\n",
      "         40.7619, 40.8813]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 282 was 98.1%\n",
      "current params: tensor([40.7619, 40.8607, 40.8053, 40.8813], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.9\n",
      "SLow rates:  tensor([[40.8648, 40.9637, 40.9082, 40.9842,  0.1000,  0.1000,  0.1000, 40.8648,\n",
      "         40.8648, 40.8648,  0.1000,  0.1000, 40.9637, 40.9637, 40.9637,  0.1000,\n",
      "          0.1000, 40.9637, 40.9637,  0.1000, 40.9082, 40.9082, 40.9082,  0.1000,\n",
      "          0.1000, 40.9082, 40.9082,  0.1000, 40.9082,  0.1000, 40.9082, 40.9842,\n",
      "         40.9842, 40.9842,  0.1000,  0.1000, 40.9842, 40.9842,  0.1000, 40.9842,\n",
      "          0.1000, 40.9842, 40.9637, 40.9842, 40.9842, 40.9842, 40.9082, 40.9842,\n",
      "         40.9842, 40.9842, 40.9637, 40.9842, 40.9842, 40.9842, 40.9637, 40.9082,\n",
      "         40.9637, 40.9637, 40.9637,  0.1000, 40.9637, 40.9082,  0.1000, 40.9082,\n",
      "         40.9842,  0.1000, 40.9842, 40.9842, 40.9842, 40.9637, 40.9637,  0.1000,\n",
      "         40.9842,  0.1000, 40.8648, 40.8648, 40.9637, 40.9842, 40.9842,  0.1000,\n",
      "          0.1000, 40.8648, 40.9637, 40.9842,  0.1000, 40.9637, 40.9842,  0.1000,\n",
      "         40.8648, 40.9842]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 283 was 98.2%\n",
      "current params: tensor([40.8648, 40.9637, 40.9082, 40.9842], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.9\n",
      "SLow rates:  tensor([[40.9678, 41.0666, 41.0111, 41.0871,  0.1000,  0.1000,  0.1000, 40.9678,\n",
      "         40.9678, 40.9678,  0.1000,  0.1000, 41.0666, 41.0666, 41.0666,  0.1000,\n",
      "          0.1000, 41.0666, 41.0666,  0.1000, 41.0111, 41.0111, 41.0111,  0.1000,\n",
      "          0.1000, 41.0111, 41.0111,  0.1000, 41.0111,  0.1000, 41.0111, 41.0871,\n",
      "         41.0871, 41.0871,  0.1000,  0.1000, 41.0871, 41.0871,  0.1000, 41.0871,\n",
      "          0.1000, 41.0871, 41.0666, 41.0871, 41.0871, 41.0871, 41.0111, 41.0871,\n",
      "         41.0871, 41.0871, 41.0666, 41.0871, 41.0871, 41.0871, 41.0666, 41.0111,\n",
      "         41.0666, 41.0666, 41.0666,  0.1000, 41.0666, 41.0111,  0.1000, 41.0111,\n",
      "         41.0871,  0.1000, 41.0871, 41.0871, 41.0871, 41.0666, 41.0666,  0.1000,\n",
      "         41.0871,  0.1000, 40.9678, 40.9678, 41.0666, 41.0871, 41.0871,  0.1000,\n",
      "          0.1000, 40.9678, 41.0666, 41.0871,  0.1000, 41.0666, 41.0871,  0.1000,\n",
      "         40.9678, 41.0871]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 284 was 98.2%\n",
      "current params: tensor([40.9678, 41.0666, 41.0111, 41.0871], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.9\n",
      "SLow rates:  tensor([[41.0707, 41.1694, 41.1140, 41.1899,  0.1000,  0.1000,  0.1000, 41.0707,\n",
      "         41.0707, 41.0707,  0.1000,  0.1000, 41.1694, 41.1694, 41.1694,  0.1000,\n",
      "          0.1000, 41.1694, 41.1694,  0.1000, 41.1140, 41.1140, 41.1140,  0.1000,\n",
      "          0.1000, 41.1140, 41.1140,  0.1000, 41.1140,  0.1000, 41.1140, 41.1899,\n",
      "         41.1899, 41.1899,  0.1000,  0.1000, 41.1899, 41.1899,  0.1000, 41.1899,\n",
      "          0.1000, 41.1899, 41.1694, 41.1899, 41.1899, 41.1899, 41.1140, 41.1899,\n",
      "         41.1899, 41.1899, 41.1694, 41.1899, 41.1899, 41.1899, 41.1694, 41.1140,\n",
      "         41.1694, 41.1694, 41.1694,  0.1000, 41.1694, 41.1140,  0.1000, 41.1140,\n",
      "         41.1899,  0.1000, 41.1899, 41.1899, 41.1899, 41.1694, 41.1694,  0.1000,\n",
      "         41.1899,  0.1000, 41.0707, 41.0707, 41.1694, 41.1899, 41.1899,  0.1000,\n",
      "          0.1000, 41.0707, 41.1694, 41.1899,  0.1000, 41.1694, 41.1899,  0.1000,\n",
      "         41.0707, 41.1899]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 285 was 98.2%\n",
      "current params: tensor([41.0707, 41.1694, 41.1140, 41.1899], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  10.9\n",
      "SLow rates:  tensor([[41.1735, 41.2723, 41.2169, 41.2927,  0.1000,  0.1000,  0.1000, 41.1735,\n",
      "         41.1735, 41.1735,  0.1000,  0.1000, 41.2723, 41.2723, 41.2723,  0.1000,\n",
      "          0.1000, 41.2723, 41.2723,  0.1000, 41.2169, 41.2169, 41.2169,  0.1000,\n",
      "          0.1000, 41.2169, 41.2169,  0.1000, 41.2169,  0.1000, 41.2169, 41.2927,\n",
      "         41.2927, 41.2927,  0.1000,  0.1000, 41.2927, 41.2927,  0.1000, 41.2927,\n",
      "          0.1000, 41.2927, 41.2723, 41.2927, 41.2927, 41.2927, 41.2169, 41.2927,\n",
      "         41.2927, 41.2927, 41.2723, 41.2927, 41.2927, 41.2927, 41.2723, 41.2169,\n",
      "         41.2723, 41.2723, 41.2723,  0.1000, 41.2723, 41.2169,  0.1000, 41.2169,\n",
      "         41.2927,  0.1000, 41.2927, 41.2927, 41.2927, 41.2723, 41.2723,  0.1000,\n",
      "         41.2927,  0.1000, 41.1735, 41.1735, 41.2723, 41.2927, 41.2927,  0.1000,\n",
      "          0.1000, 41.1735, 41.2723, 41.2927,  0.1000, 41.2723, 41.2927,  0.1000,\n",
      "         41.1735, 41.2927]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 286 was 98.2%\n",
      "current params: tensor([41.1735, 41.2723, 41.2169, 41.2927], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.0\n",
      "SLow rates:  tensor([[41.2764, 41.3751, 41.3197, 41.3955,  0.1000,  0.1000,  0.1000, 41.2764,\n",
      "         41.2764, 41.2764,  0.1000,  0.1000, 41.3751, 41.3751, 41.3751,  0.1000,\n",
      "          0.1000, 41.3751, 41.3751,  0.1000, 41.3197, 41.3197, 41.3197,  0.1000,\n",
      "          0.1000, 41.3197, 41.3197,  0.1000, 41.3197,  0.1000, 41.3197, 41.3955,\n",
      "         41.3955, 41.3955,  0.1000,  0.1000, 41.3955, 41.3955,  0.1000, 41.3955,\n",
      "          0.1000, 41.3955, 41.3751, 41.3955, 41.3955, 41.3955, 41.3197, 41.3955,\n",
      "         41.3955, 41.3955, 41.3751, 41.3955, 41.3955, 41.3955, 41.3751, 41.3197,\n",
      "         41.3751, 41.3751, 41.3751,  0.1000, 41.3751, 41.3197,  0.1000, 41.3197,\n",
      "         41.3955,  0.1000, 41.3955, 41.3955, 41.3955, 41.3751, 41.3751,  0.1000,\n",
      "         41.3955,  0.1000, 41.2764, 41.2764, 41.3751, 41.3955, 41.3955,  0.1000,\n",
      "          0.1000, 41.2764, 41.3751, 41.3955,  0.1000, 41.3751, 41.3955,  0.1000,\n",
      "         41.2764, 41.3955]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 287 was 98.2%\n",
      "current params: tensor([41.2764, 41.3751, 41.3197, 41.3955], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.0\n",
      "SLow rates:  tensor([[41.3792, 41.4779, 41.4225, 41.4983,  0.1000,  0.1000,  0.1000, 41.3792,\n",
      "         41.3792, 41.3792,  0.1000,  0.1000, 41.4779, 41.4779, 41.4779,  0.1000,\n",
      "          0.1000, 41.4779, 41.4779,  0.1000, 41.4225, 41.4225, 41.4225,  0.1000,\n",
      "          0.1000, 41.4225, 41.4225,  0.1000, 41.4225,  0.1000, 41.4225, 41.4983,\n",
      "         41.4983, 41.4983,  0.1000,  0.1000, 41.4983, 41.4983,  0.1000, 41.4983,\n",
      "          0.1000, 41.4983, 41.4779, 41.4983, 41.4983, 41.4983, 41.4225, 41.4983,\n",
      "         41.4983, 41.4983, 41.4779, 41.4983, 41.4983, 41.4983, 41.4779, 41.4225,\n",
      "         41.4779, 41.4779, 41.4779,  0.1000, 41.4779, 41.4225,  0.1000, 41.4225,\n",
      "         41.4983,  0.1000, 41.4983, 41.4983, 41.4983, 41.4779, 41.4779,  0.1000,\n",
      "         41.4983,  0.1000, 41.3792, 41.3792, 41.4779, 41.4983, 41.4983,  0.1000,\n",
      "          0.1000, 41.3792, 41.4779, 41.4983,  0.1000, 41.4779, 41.4983,  0.1000,\n",
      "         41.3792, 41.4983]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 288 was 98.2%\n",
      "current params: tensor([41.3792, 41.4779, 41.4225, 41.4983], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.0\n",
      "SLow rates:  tensor([[41.4820, 41.5806, 41.5252, 41.6010,  0.1000,  0.1000,  0.1000, 41.4820,\n",
      "         41.4820, 41.4820,  0.1000,  0.1000, 41.5806, 41.5806, 41.5806,  0.1000,\n",
      "          0.1000, 41.5806, 41.5806,  0.1000, 41.5252, 41.5252, 41.5252,  0.1000,\n",
      "          0.1000, 41.5252, 41.5252,  0.1000, 41.5252,  0.1000, 41.5252, 41.6010,\n",
      "         41.6010, 41.6010,  0.1000,  0.1000, 41.6010, 41.6010,  0.1000, 41.6010,\n",
      "          0.1000, 41.6010, 41.5806, 41.6010, 41.6010, 41.6010, 41.5252, 41.6010,\n",
      "         41.6010, 41.6010, 41.5806, 41.6010, 41.6010, 41.6010, 41.5806, 41.5252,\n",
      "         41.5806, 41.5806, 41.5806,  0.1000, 41.5806, 41.5252,  0.1000, 41.5252,\n",
      "         41.6010,  0.1000, 41.6010, 41.6010, 41.6010, 41.5806, 41.5806,  0.1000,\n",
      "         41.6010,  0.1000, 41.4820, 41.4820, 41.5806, 41.6010, 41.6010,  0.1000,\n",
      "          0.1000, 41.4820, 41.5806, 41.6010,  0.1000, 41.5806, 41.6010,  0.1000,\n",
      "         41.4820, 41.6010]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 289 was 98.2%\n",
      "current params: tensor([41.4820, 41.5806, 41.5252, 41.6010], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.0\n",
      "SLow rates:  tensor([[41.5848, 41.6834, 41.6280, 41.7037,  0.1000,  0.1000,  0.1000, 41.5848,\n",
      "         41.5848, 41.5848,  0.1000,  0.1000, 41.6834, 41.6834, 41.6834,  0.1000,\n",
      "          0.1000, 41.6834, 41.6834,  0.1000, 41.6280, 41.6280, 41.6280,  0.1000,\n",
      "          0.1000, 41.6280, 41.6280,  0.1000, 41.6280,  0.1000, 41.6280, 41.7037,\n",
      "         41.7037, 41.7037,  0.1000,  0.1000, 41.7037, 41.7037,  0.1000, 41.7037,\n",
      "          0.1000, 41.7037, 41.6834, 41.7037, 41.7037, 41.7037, 41.6280, 41.7037,\n",
      "         41.7037, 41.7037, 41.6834, 41.7037, 41.7037, 41.7037, 41.6834, 41.6280,\n",
      "         41.6834, 41.6834, 41.6834,  0.1000, 41.6834, 41.6280,  0.1000, 41.6280,\n",
      "         41.7037,  0.1000, 41.7037, 41.7037, 41.7037, 41.6834, 41.6834,  0.1000,\n",
      "         41.7037,  0.1000, 41.5848, 41.5848, 41.6834, 41.7037, 41.7037,  0.1000,\n",
      "          0.1000, 41.5848, 41.6834, 41.7037,  0.1000, 41.6834, 41.7037,  0.1000,\n",
      "         41.5848, 41.7037]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 290 was 98.2%\n",
      "current params: tensor([41.5848, 41.6834, 41.6280, 41.7037], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.0\n",
      "SLow rates:  tensor([[41.6875, 41.7861, 41.7307, 41.8064,  0.1000,  0.1000,  0.1000, 41.6875,\n",
      "         41.6875, 41.6875,  0.1000,  0.1000, 41.7861, 41.7861, 41.7861,  0.1000,\n",
      "          0.1000, 41.7861, 41.7861,  0.1000, 41.7307, 41.7307, 41.7307,  0.1000,\n",
      "          0.1000, 41.7307, 41.7307,  0.1000, 41.7307,  0.1000, 41.7307, 41.8064,\n",
      "         41.8064, 41.8064,  0.1000,  0.1000, 41.8064, 41.8064,  0.1000, 41.8064,\n",
      "          0.1000, 41.8064, 41.7861, 41.8064, 41.8064, 41.8064, 41.7307, 41.8064,\n",
      "         41.8064, 41.8064, 41.7861, 41.8064, 41.8064, 41.8064, 41.7861, 41.7307,\n",
      "         41.7861, 41.7861, 41.7861,  0.1000, 41.7861, 41.7307,  0.1000, 41.7307,\n",
      "         41.8064,  0.1000, 41.8064, 41.8064, 41.8064, 41.7861, 41.7861,  0.1000,\n",
      "         41.8064,  0.1000, 41.6875, 41.6875, 41.7861, 41.8064, 41.8064,  0.1000,\n",
      "          0.1000, 41.6875, 41.7861, 41.8064,  0.1000, 41.7861, 41.8064,  0.1000,\n",
      "         41.6875, 41.8064]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 291 was 98.2%\n",
      "current params: tensor([41.6875, 41.7861, 41.7307, 41.8064], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.0\n",
      "SLow rates:  tensor([[41.7902, 41.8887, 41.8334, 41.9090,  0.1000,  0.1000,  0.1000, 41.7902,\n",
      "         41.7902, 41.7902,  0.1000,  0.1000, 41.8887, 41.8887, 41.8887,  0.1000,\n",
      "          0.1000, 41.8887, 41.8887,  0.1000, 41.8334, 41.8334, 41.8334,  0.1000,\n",
      "          0.1000, 41.8334, 41.8334,  0.1000, 41.8334,  0.1000, 41.8334, 41.9090,\n",
      "         41.9090, 41.9090,  0.1000,  0.1000, 41.9090, 41.9090,  0.1000, 41.9090,\n",
      "          0.1000, 41.9090, 41.8887, 41.9090, 41.9090, 41.9090, 41.8334, 41.9090,\n",
      "         41.9090, 41.9090, 41.8887, 41.9090, 41.9090, 41.9090, 41.8887, 41.8334,\n",
      "         41.8887, 41.8887, 41.8887,  0.1000, 41.8887, 41.8334,  0.1000, 41.8334,\n",
      "         41.9090,  0.1000, 41.9090, 41.9090, 41.9090, 41.8887, 41.8887,  0.1000,\n",
      "         41.9090,  0.1000, 41.7902, 41.7902, 41.8887, 41.9090, 41.9090,  0.1000,\n",
      "          0.1000, 41.7902, 41.8887, 41.9090,  0.1000, 41.8887, 41.9090,  0.1000,\n",
      "         41.7902, 41.9090]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 292 was 98.2%\n",
      "current params: tensor([41.7902, 41.8887, 41.8334, 41.9090], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.1\n",
      "SLow rates:  tensor([[41.8929, 41.9914, 41.9360, 42.0116,  0.1000,  0.1000,  0.1000, 41.8929,\n",
      "         41.8929, 41.8929,  0.1000,  0.1000, 41.9914, 41.9914, 41.9914,  0.1000,\n",
      "          0.1000, 41.9914, 41.9914,  0.1000, 41.9360, 41.9360, 41.9360,  0.1000,\n",
      "          0.1000, 41.9360, 41.9360,  0.1000, 41.9360,  0.1000, 41.9360, 42.0116,\n",
      "         42.0116, 42.0116,  0.1000,  0.1000, 42.0116, 42.0116,  0.1000, 42.0116,\n",
      "          0.1000, 42.0116, 41.9914, 42.0116, 42.0116, 42.0116, 41.9360, 42.0116,\n",
      "         42.0116, 42.0116, 41.9914, 42.0116, 42.0116, 42.0116, 41.9914, 41.9360,\n",
      "         41.9914, 41.9914, 41.9914,  0.1000, 41.9914, 41.9360,  0.1000, 41.9360,\n",
      "         42.0116,  0.1000, 42.0116, 42.0116, 42.0116, 41.9914, 41.9914,  0.1000,\n",
      "         42.0116,  0.1000, 41.8929, 41.8929, 41.9914, 42.0116, 42.0116,  0.1000,\n",
      "          0.1000, 41.8929, 41.9914, 42.0116,  0.1000, 41.9914, 42.0116,  0.1000,\n",
      "         41.8929, 42.0116]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 293 was 98.2%\n",
      "current params: tensor([41.8929, 41.9914, 41.9360, 42.0116], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.1\n",
      "SLow rates:  tensor([[41.9955, 42.0940, 42.0386, 42.1142,  0.1000,  0.1000,  0.1000, 41.9955,\n",
      "         41.9955, 41.9955,  0.1000,  0.1000, 42.0940, 42.0940, 42.0940,  0.1000,\n",
      "          0.1000, 42.0940, 42.0940,  0.1000, 42.0386, 42.0386, 42.0386,  0.1000,\n",
      "          0.1000, 42.0386, 42.0386,  0.1000, 42.0386,  0.1000, 42.0386, 42.1142,\n",
      "         42.1142, 42.1142,  0.1000,  0.1000, 42.1142, 42.1142,  0.1000, 42.1142,\n",
      "          0.1000, 42.1142, 42.0940, 42.1142, 42.1142, 42.1142, 42.0386, 42.1142,\n",
      "         42.1142, 42.1142, 42.0940, 42.1142, 42.1142, 42.1142, 42.0940, 42.0386,\n",
      "         42.0940, 42.0940, 42.0940,  0.1000, 42.0940, 42.0386,  0.1000, 42.0386,\n",
      "         42.1142,  0.1000, 42.1142, 42.1142, 42.1142, 42.0940, 42.0940,  0.1000,\n",
      "         42.1142,  0.1000, 41.9955, 41.9955, 42.0940, 42.1142, 42.1142,  0.1000,\n",
      "          0.1000, 41.9955, 42.0940, 42.1142,  0.1000, 42.0940, 42.1142,  0.1000,\n",
      "         41.9955, 42.1142]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 294 was 98.2%\n",
      "current params: tensor([41.9955, 42.0940, 42.0386, 42.1142], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.1\n",
      "SLow rates:  tensor([[42.0981, 42.1966, 42.1412, 42.2168,  0.1000,  0.1000,  0.1000, 42.0981,\n",
      "         42.0981, 42.0981,  0.1000,  0.1000, 42.1966, 42.1966, 42.1966,  0.1000,\n",
      "          0.1000, 42.1966, 42.1966,  0.1000, 42.1412, 42.1412, 42.1412,  0.1000,\n",
      "          0.1000, 42.1412, 42.1412,  0.1000, 42.1412,  0.1000, 42.1412, 42.2168,\n",
      "         42.2168, 42.2168,  0.1000,  0.1000, 42.2168, 42.2168,  0.1000, 42.2168,\n",
      "          0.1000, 42.2168, 42.1966, 42.2168, 42.2168, 42.2168, 42.1412, 42.2168,\n",
      "         42.2168, 42.2168, 42.1966, 42.2168, 42.2168, 42.2168, 42.1966, 42.1412,\n",
      "         42.1966, 42.1966, 42.1966,  0.1000, 42.1966, 42.1412,  0.1000, 42.1412,\n",
      "         42.2168,  0.1000, 42.2168, 42.2168, 42.2168, 42.1966, 42.1966,  0.1000,\n",
      "         42.2168,  0.1000, 42.0981, 42.0981, 42.1966, 42.2168, 42.2168,  0.1000,\n",
      "          0.1000, 42.0981, 42.1966, 42.2168,  0.1000, 42.1966, 42.2168,  0.1000,\n",
      "         42.0981, 42.2168]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 295 was 98.2%\n",
      "current params: tensor([42.0981, 42.1966, 42.1412, 42.2168], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.1\n",
      "SLow rates:  tensor([[42.2007, 42.2991, 42.2438, 42.3193,  0.1000,  0.1000,  0.1000, 42.2007,\n",
      "         42.2007, 42.2007,  0.1000,  0.1000, 42.2991, 42.2991, 42.2991,  0.1000,\n",
      "          0.1000, 42.2991, 42.2991,  0.1000, 42.2438, 42.2438, 42.2438,  0.1000,\n",
      "          0.1000, 42.2438, 42.2438,  0.1000, 42.2438,  0.1000, 42.2438, 42.3193,\n",
      "         42.3193, 42.3193,  0.1000,  0.1000, 42.3193, 42.3193,  0.1000, 42.3193,\n",
      "          0.1000, 42.3193, 42.2991, 42.3193, 42.3193, 42.3193, 42.2438, 42.3193,\n",
      "         42.3193, 42.3193, 42.2991, 42.3193, 42.3193, 42.3193, 42.2991, 42.2438,\n",
      "         42.2991, 42.2991, 42.2991,  0.1000, 42.2991, 42.2438,  0.1000, 42.2438,\n",
      "         42.3193,  0.1000, 42.3193, 42.3193, 42.3193, 42.2991, 42.2991,  0.1000,\n",
      "         42.3193,  0.1000, 42.2007, 42.2007, 42.2991, 42.3193, 42.3193,  0.1000,\n",
      "          0.1000, 42.2007, 42.2991, 42.3193,  0.1000, 42.2991, 42.3193,  0.1000,\n",
      "         42.2007, 42.3193]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 296 was 98.2%\n",
      "current params: tensor([42.2007, 42.2991, 42.2438, 42.3193], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.1\n",
      "SLow rates:  tensor([[42.3033, 42.4016, 42.3464, 42.4218,  0.1000,  0.1000,  0.1000, 42.3033,\n",
      "         42.3033, 42.3033,  0.1000,  0.1000, 42.4016, 42.4016, 42.4016,  0.1000,\n",
      "          0.1000, 42.4016, 42.4016,  0.1000, 42.3464, 42.3464, 42.3464,  0.1000,\n",
      "          0.1000, 42.3464, 42.3464,  0.1000, 42.3464,  0.1000, 42.3464, 42.4218,\n",
      "         42.4218, 42.4218,  0.1000,  0.1000, 42.4218, 42.4218,  0.1000, 42.4218,\n",
      "          0.1000, 42.4218, 42.4016, 42.4218, 42.4218, 42.4218, 42.3464, 42.4218,\n",
      "         42.4218, 42.4218, 42.4016, 42.4218, 42.4218, 42.4218, 42.4016, 42.3464,\n",
      "         42.4016, 42.4016, 42.4016,  0.1000, 42.4016, 42.3464,  0.1000, 42.3464,\n",
      "         42.4218,  0.1000, 42.4218, 42.4218, 42.4218, 42.4016, 42.4016,  0.1000,\n",
      "         42.4218,  0.1000, 42.3033, 42.3033, 42.4016, 42.4218, 42.4218,  0.1000,\n",
      "          0.1000, 42.3033, 42.4016, 42.4218,  0.1000, 42.4016, 42.4218,  0.1000,\n",
      "         42.3033, 42.4218]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 297 was 98.2%\n",
      "current params: tensor([42.3033, 42.4016, 42.3464, 42.4218], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.2\n",
      "SLow rates:  tensor([[42.4058, 42.5041, 42.4489, 42.5243,  0.1000,  0.1000,  0.1000, 42.4058,\n",
      "         42.4058, 42.4058,  0.1000,  0.1000, 42.5041, 42.5041, 42.5041,  0.1000,\n",
      "          0.1000, 42.5041, 42.5041,  0.1000, 42.4489, 42.4489, 42.4489,  0.1000,\n",
      "          0.1000, 42.4489, 42.4489,  0.1000, 42.4489,  0.1000, 42.4489, 42.5243,\n",
      "         42.5243, 42.5243,  0.1000,  0.1000, 42.5243, 42.5243,  0.1000, 42.5243,\n",
      "          0.1000, 42.5243, 42.5041, 42.5243, 42.5243, 42.5243, 42.4489, 42.5243,\n",
      "         42.5243, 42.5243, 42.5041, 42.5243, 42.5243, 42.5243, 42.5041, 42.4489,\n",
      "         42.5041, 42.5041, 42.5041,  0.1000, 42.5041, 42.4489,  0.1000, 42.4489,\n",
      "         42.5243,  0.1000, 42.5243, 42.5243, 42.5243, 42.5041, 42.5041,  0.1000,\n",
      "         42.5243,  0.1000, 42.4058, 42.4058, 42.5041, 42.5243, 42.5243,  0.1000,\n",
      "          0.1000, 42.4058, 42.5041, 42.5243,  0.1000, 42.5041, 42.5243,  0.1000,\n",
      "         42.4058, 42.5243]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 298 was 98.2%\n",
      "current params: tensor([42.4058, 42.5041, 42.4489, 42.5243], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.2\n",
      "SLow rates:  tensor([[42.5083, 42.6066, 42.5514, 42.6267,  0.1000,  0.1000,  0.1000, 42.5083,\n",
      "         42.5083, 42.5083,  0.1000,  0.1000, 42.6066, 42.6066, 42.6066,  0.1000,\n",
      "          0.1000, 42.6066, 42.6066,  0.1000, 42.5514, 42.5514, 42.5514,  0.1000,\n",
      "          0.1000, 42.5514, 42.5514,  0.1000, 42.5514,  0.1000, 42.5514, 42.6267,\n",
      "         42.6267, 42.6267,  0.1000,  0.1000, 42.6267, 42.6267,  0.1000, 42.6267,\n",
      "          0.1000, 42.6267, 42.6066, 42.6267, 42.6267, 42.6267, 42.5514, 42.6267,\n",
      "         42.6267, 42.6267, 42.6066, 42.6267, 42.6267, 42.6267, 42.6066, 42.5514,\n",
      "         42.6066, 42.6066, 42.6066,  0.1000, 42.6066, 42.5514,  0.1000, 42.5514,\n",
      "         42.6267,  0.1000, 42.6267, 42.6267, 42.6267, 42.6066, 42.6066,  0.1000,\n",
      "         42.6267,  0.1000, 42.5083, 42.5083, 42.6066, 42.6267, 42.6267,  0.1000,\n",
      "          0.1000, 42.5083, 42.6066, 42.6267,  0.1000, 42.6066, 42.6267,  0.1000,\n",
      "         42.5083, 42.6267]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 299 was 98.2%\n",
      "current params: tensor([42.5083, 42.6066, 42.5514, 42.6267], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.2\n",
      "SLow rates:  tensor([[42.6108, 42.7091, 42.6538, 42.7292,  0.1000,  0.1000,  0.1000, 42.6108,\n",
      "         42.6108, 42.6108,  0.1000,  0.1000, 42.7091, 42.7091, 42.7091,  0.1000,\n",
      "          0.1000, 42.7091, 42.7091,  0.1000, 42.6538, 42.6538, 42.6538,  0.1000,\n",
      "          0.1000, 42.6538, 42.6538,  0.1000, 42.6538,  0.1000, 42.6538, 42.7292,\n",
      "         42.7292, 42.7292,  0.1000,  0.1000, 42.7292, 42.7292,  0.1000, 42.7292,\n",
      "          0.1000, 42.7292, 42.7091, 42.7292, 42.7292, 42.7292, 42.6538, 42.7292,\n",
      "         42.7292, 42.7292, 42.7091, 42.7292, 42.7292, 42.7292, 42.7091, 42.6538,\n",
      "         42.7091, 42.7091, 42.7091,  0.1000, 42.7091, 42.6538,  0.1000, 42.6538,\n",
      "         42.7292,  0.1000, 42.7292, 42.7292, 42.7292, 42.7091, 42.7091,  0.1000,\n",
      "         42.7292,  0.1000, 42.6108, 42.6108, 42.7091, 42.7292, 42.7292,  0.1000,\n",
      "          0.1000, 42.6108, 42.7091, 42.7292,  0.1000, 42.7091, 42.7292,  0.1000,\n",
      "         42.6108, 42.7292]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 300 was 98.2%\n",
      "current params: tensor([42.6108, 42.7091, 42.6538, 42.7292], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.2\n",
      "SLow rates:  tensor([[42.7133, 42.8115, 42.7563, 42.8316,  0.1000,  0.1000,  0.1000, 42.7133,\n",
      "         42.7133, 42.7133,  0.1000,  0.1000, 42.8115, 42.8115, 42.8115,  0.1000,\n",
      "          0.1000, 42.8115, 42.8115,  0.1000, 42.7563, 42.7563, 42.7563,  0.1000,\n",
      "          0.1000, 42.7563, 42.7563,  0.1000, 42.7563,  0.1000, 42.7563, 42.8316,\n",
      "         42.8316, 42.8316,  0.1000,  0.1000, 42.8316, 42.8316,  0.1000, 42.8316,\n",
      "          0.1000, 42.8316, 42.8115, 42.8316, 42.8316, 42.8316, 42.7563, 42.8316,\n",
      "         42.8316, 42.8316, 42.8115, 42.8316, 42.8316, 42.8316, 42.8115, 42.7563,\n",
      "         42.8115, 42.8115, 42.8115,  0.1000, 42.8115, 42.7563,  0.1000, 42.7563,\n",
      "         42.8316,  0.1000, 42.8316, 42.8316, 42.8316, 42.8115, 42.8115,  0.1000,\n",
      "         42.8316,  0.1000, 42.7133, 42.7133, 42.8115, 42.8316, 42.8316,  0.1000,\n",
      "          0.1000, 42.7133, 42.8115, 42.8316,  0.1000, 42.8115, 42.8316,  0.1000,\n",
      "         42.7133, 42.8316]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 301 was 98.2%\n",
      "current params: tensor([42.7133, 42.8115, 42.7563, 42.8316], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.2\n",
      "SLow rates:  tensor([[42.8157, 42.9139, 42.8587, 42.9339,  0.1000,  0.1000,  0.1000, 42.8157,\n",
      "         42.8157, 42.8157,  0.1000,  0.1000, 42.9139, 42.9139, 42.9139,  0.1000,\n",
      "          0.1000, 42.9139, 42.9139,  0.1000, 42.8587, 42.8587, 42.8587,  0.1000,\n",
      "          0.1000, 42.8587, 42.8587,  0.1000, 42.8587,  0.1000, 42.8587, 42.9339,\n",
      "         42.9339, 42.9339,  0.1000,  0.1000, 42.9339, 42.9339,  0.1000, 42.9339,\n",
      "          0.1000, 42.9339, 42.9139, 42.9339, 42.9339, 42.9339, 42.8587, 42.9339,\n",
      "         42.9339, 42.9339, 42.9139, 42.9339, 42.9339, 42.9339, 42.9139, 42.8587,\n",
      "         42.9139, 42.9139, 42.9139,  0.1000, 42.9139, 42.8587,  0.1000, 42.8587,\n",
      "         42.9339,  0.1000, 42.9339, 42.9339, 42.9339, 42.9139, 42.9139,  0.1000,\n",
      "         42.9339,  0.1000, 42.8157, 42.8157, 42.9139, 42.9339, 42.9339,  0.1000,\n",
      "          0.1000, 42.8157, 42.9139, 42.9339,  0.1000, 42.9139, 42.9339,  0.1000,\n",
      "         42.8157, 42.9339]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 302 was 98.2%\n",
      "current params: tensor([42.8157, 42.9139, 42.8587, 42.9339], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.3\n",
      "SLow rates:  tensor([[42.9181, 43.0163, 42.9611, 43.0363,  0.1000,  0.1000,  0.1000, 42.9181,\n",
      "         42.9181, 42.9181,  0.1000,  0.1000, 43.0163, 43.0163, 43.0163,  0.1000,\n",
      "          0.1000, 43.0163, 43.0163,  0.1000, 42.9611, 42.9611, 42.9611,  0.1000,\n",
      "          0.1000, 42.9611, 42.9611,  0.1000, 42.9611,  0.1000, 42.9611, 43.0363,\n",
      "         43.0363, 43.0363,  0.1000,  0.1000, 43.0363, 43.0363,  0.1000, 43.0363,\n",
      "          0.1000, 43.0363, 43.0163, 43.0363, 43.0363, 43.0363, 42.9611, 43.0363,\n",
      "         43.0363, 43.0363, 43.0163, 43.0363, 43.0363, 43.0363, 43.0163, 42.9611,\n",
      "         43.0163, 43.0163, 43.0163,  0.1000, 43.0163, 42.9611,  0.1000, 42.9611,\n",
      "         43.0363,  0.1000, 43.0363, 43.0363, 43.0363, 43.0163, 43.0163,  0.1000,\n",
      "         43.0363,  0.1000, 42.9181, 42.9181, 43.0163, 43.0363, 43.0363,  0.1000,\n",
      "          0.1000, 42.9181, 43.0163, 43.0363,  0.1000, 43.0163, 43.0363,  0.1000,\n",
      "         42.9181, 43.0363]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 303 was 98.2%\n",
      "current params: tensor([42.9181, 43.0163, 42.9611, 43.0363], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.3\n",
      "SLow rates:  tensor([[43.0205, 43.1186, 43.0634, 43.1386,  0.1000,  0.1000,  0.1000, 43.0205,\n",
      "         43.0205, 43.0205,  0.1000,  0.1000, 43.1186, 43.1186, 43.1186,  0.1000,\n",
      "          0.1000, 43.1186, 43.1186,  0.1000, 43.0634, 43.0634, 43.0634,  0.1000,\n",
      "          0.1000, 43.0634, 43.0634,  0.1000, 43.0634,  0.1000, 43.0634, 43.1386,\n",
      "         43.1386, 43.1386,  0.1000,  0.1000, 43.1386, 43.1386,  0.1000, 43.1386,\n",
      "          0.1000, 43.1386, 43.1186, 43.1386, 43.1386, 43.1386, 43.0634, 43.1386,\n",
      "         43.1386, 43.1386, 43.1186, 43.1386, 43.1386, 43.1386, 43.1186, 43.0634,\n",
      "         43.1186, 43.1186, 43.1186,  0.1000, 43.1186, 43.0634,  0.1000, 43.0634,\n",
      "         43.1386,  0.1000, 43.1386, 43.1386, 43.1386, 43.1186, 43.1186,  0.1000,\n",
      "         43.1386,  0.1000, 43.0205, 43.0205, 43.1186, 43.1386, 43.1386,  0.1000,\n",
      "          0.1000, 43.0205, 43.1186, 43.1386,  0.1000, 43.1186, 43.1386,  0.1000,\n",
      "         43.0205, 43.1386]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 304 was 98.2%\n",
      "current params: tensor([43.0205, 43.1186, 43.0634, 43.1386], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.3\n",
      "SLow rates:  tensor([[43.1228, 43.2210, 43.1658, 43.2409,  0.1000,  0.1000,  0.1000, 43.1228,\n",
      "         43.1228, 43.1228,  0.1000,  0.1000, 43.2210, 43.2210, 43.2210,  0.1000,\n",
      "          0.1000, 43.2210, 43.2210,  0.1000, 43.1658, 43.1658, 43.1658,  0.1000,\n",
      "          0.1000, 43.1658, 43.1658,  0.1000, 43.1658,  0.1000, 43.1658, 43.2409,\n",
      "         43.2409, 43.2409,  0.1000,  0.1000, 43.2409, 43.2409,  0.1000, 43.2409,\n",
      "          0.1000, 43.2409, 43.2210, 43.2409, 43.2409, 43.2409, 43.1658, 43.2409,\n",
      "         43.2409, 43.2409, 43.2210, 43.2409, 43.2409, 43.2409, 43.2210, 43.1658,\n",
      "         43.2210, 43.2210, 43.2210,  0.1000, 43.2210, 43.1658,  0.1000, 43.1658,\n",
      "         43.2409,  0.1000, 43.2409, 43.2409, 43.2409, 43.2210, 43.2210,  0.1000,\n",
      "         43.2409,  0.1000, 43.1228, 43.1228, 43.2210, 43.2409, 43.2409,  0.1000,\n",
      "          0.1000, 43.1228, 43.2210, 43.2409,  0.1000, 43.2210, 43.2409,  0.1000,\n",
      "         43.1228, 43.2409]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 305 was 98.2%\n",
      "current params: tensor([43.1228, 43.2210, 43.1658, 43.2409], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.3\n",
      "SLow rates:  tensor([[43.2252, 43.3233, 43.2681, 43.3432,  0.1000,  0.1000,  0.1000, 43.2252,\n",
      "         43.2252, 43.2252,  0.1000,  0.1000, 43.3233, 43.3233, 43.3233,  0.1000,\n",
      "          0.1000, 43.3233, 43.3233,  0.1000, 43.2681, 43.2681, 43.2681,  0.1000,\n",
      "          0.1000, 43.2681, 43.2681,  0.1000, 43.2681,  0.1000, 43.2681, 43.3432,\n",
      "         43.3432, 43.3432,  0.1000,  0.1000, 43.3432, 43.3432,  0.1000, 43.3432,\n",
      "          0.1000, 43.3432, 43.3233, 43.3432, 43.3432, 43.3432, 43.2681, 43.3432,\n",
      "         43.3432, 43.3432, 43.3233, 43.3432, 43.3432, 43.3432, 43.3233, 43.2681,\n",
      "         43.3233, 43.3233, 43.3233,  0.1000, 43.3233, 43.2681,  0.1000, 43.2681,\n",
      "         43.3432,  0.1000, 43.3432, 43.3432, 43.3432, 43.3233, 43.3233,  0.1000,\n",
      "         43.3432,  0.1000, 43.2252, 43.2252, 43.3233, 43.3432, 43.3432,  0.1000,\n",
      "          0.1000, 43.2252, 43.3233, 43.3432,  0.1000, 43.3233, 43.3432,  0.1000,\n",
      "         43.2252, 43.3432]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 306 was 98.2%\n",
      "current params: tensor([43.2252, 43.3233, 43.2681, 43.3432], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.3\n",
      "SLow rates:  tensor([[43.3275, 43.4255, 43.3704, 43.4455,  0.1000,  0.1000,  0.1000, 43.3275,\n",
      "         43.3275, 43.3275,  0.1000,  0.1000, 43.4255, 43.4255, 43.4255,  0.1000,\n",
      "          0.1000, 43.4255, 43.4255,  0.1000, 43.3704, 43.3704, 43.3704,  0.1000,\n",
      "          0.1000, 43.3704, 43.3704,  0.1000, 43.3704,  0.1000, 43.3704, 43.4455,\n",
      "         43.4455, 43.4455,  0.1000,  0.1000, 43.4455, 43.4455,  0.1000, 43.4455,\n",
      "          0.1000, 43.4455, 43.4255, 43.4455, 43.4455, 43.4455, 43.3704, 43.4455,\n",
      "         43.4455, 43.4455, 43.4255, 43.4455, 43.4455, 43.4455, 43.4255, 43.3704,\n",
      "         43.4255, 43.4255, 43.4255,  0.1000, 43.4255, 43.3704,  0.1000, 43.3704,\n",
      "         43.4455,  0.1000, 43.4455, 43.4455, 43.4455, 43.4255, 43.4255,  0.1000,\n",
      "         43.4455,  0.1000, 43.3275, 43.3275, 43.4255, 43.4455, 43.4455,  0.1000,\n",
      "          0.1000, 43.3275, 43.4255, 43.4455,  0.1000, 43.4255, 43.4455,  0.1000,\n",
      "         43.3275, 43.4455]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 307 was 98.2%\n",
      "current params: tensor([43.3275, 43.4255, 43.3704, 43.4455], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.4\n",
      "SLow rates:  tensor([[43.4298, 43.5278, 43.4726, 43.5477,  0.1000,  0.1000,  0.1000, 43.4298,\n",
      "         43.4298, 43.4298,  0.1000,  0.1000, 43.5278, 43.5278, 43.5278,  0.1000,\n",
      "          0.1000, 43.5278, 43.5278,  0.1000, 43.4726, 43.4726, 43.4726,  0.1000,\n",
      "          0.1000, 43.4726, 43.4726,  0.1000, 43.4726,  0.1000, 43.4726, 43.5477,\n",
      "         43.5477, 43.5477,  0.1000,  0.1000, 43.5477, 43.5477,  0.1000, 43.5477,\n",
      "          0.1000, 43.5477, 43.5278, 43.5477, 43.5477, 43.5477, 43.4726, 43.5477,\n",
      "         43.5477, 43.5477, 43.5278, 43.5477, 43.5477, 43.5477, 43.5278, 43.4726,\n",
      "         43.5278, 43.5278, 43.5278,  0.1000, 43.5278, 43.4726,  0.1000, 43.4726,\n",
      "         43.5477,  0.1000, 43.5477, 43.5477, 43.5477, 43.5278, 43.5278,  0.1000,\n",
      "         43.5477,  0.1000, 43.4298, 43.4298, 43.5278, 43.5477, 43.5477,  0.1000,\n",
      "          0.1000, 43.4298, 43.5278, 43.5477,  0.1000, 43.5278, 43.5477,  0.1000,\n",
      "         43.4298, 43.5477]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 308 was 98.3%\n",
      "current params: tensor([43.4298, 43.5278, 43.4726, 43.5477], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.4\n",
      "SLow rates:  tensor([[43.5320, 43.6300, 43.5749, 43.6499,  0.1000,  0.1000,  0.1000, 43.5320,\n",
      "         43.5320, 43.5320,  0.1000,  0.1000, 43.6300, 43.6300, 43.6300,  0.1000,\n",
      "          0.1000, 43.6300, 43.6300,  0.1000, 43.5749, 43.5749, 43.5749,  0.1000,\n",
      "          0.1000, 43.5749, 43.5749,  0.1000, 43.5749,  0.1000, 43.5749, 43.6499,\n",
      "         43.6499, 43.6499,  0.1000,  0.1000, 43.6499, 43.6499,  0.1000, 43.6499,\n",
      "          0.1000, 43.6499, 43.6300, 43.6499, 43.6499, 43.6499, 43.5749, 43.6499,\n",
      "         43.6499, 43.6499, 43.6300, 43.6499, 43.6499, 43.6499, 43.6300, 43.5749,\n",
      "         43.6300, 43.6300, 43.6300,  0.1000, 43.6300, 43.5749,  0.1000, 43.5749,\n",
      "         43.6499,  0.1000, 43.6499, 43.6499, 43.6499, 43.6300, 43.6300,  0.1000,\n",
      "         43.6499,  0.1000, 43.5320, 43.5320, 43.6300, 43.6499, 43.6499,  0.1000,\n",
      "          0.1000, 43.5320, 43.6300, 43.6499,  0.1000, 43.6300, 43.6499,  0.1000,\n",
      "         43.5320, 43.6499]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 309 was 98.3%\n",
      "current params: tensor([43.5320, 43.6300, 43.5749, 43.6499], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.4\n",
      "SLow rates:  tensor([[43.6343, 43.7322, 43.6771, 43.7521,  0.1000,  0.1000,  0.1000, 43.6343,\n",
      "         43.6343, 43.6343,  0.1000,  0.1000, 43.7322, 43.7322, 43.7322,  0.1000,\n",
      "          0.1000, 43.7322, 43.7322,  0.1000, 43.6771, 43.6771, 43.6771,  0.1000,\n",
      "          0.1000, 43.6771, 43.6771,  0.1000, 43.6771,  0.1000, 43.6771, 43.7521,\n",
      "         43.7521, 43.7521,  0.1000,  0.1000, 43.7521, 43.7521,  0.1000, 43.7521,\n",
      "          0.1000, 43.7521, 43.7322, 43.7521, 43.7521, 43.7521, 43.6771, 43.7521,\n",
      "         43.7521, 43.7521, 43.7322, 43.7521, 43.7521, 43.7521, 43.7322, 43.6771,\n",
      "         43.7322, 43.7322, 43.7322,  0.1000, 43.7322, 43.6771,  0.1000, 43.6771,\n",
      "         43.7521,  0.1000, 43.7521, 43.7521, 43.7521, 43.7322, 43.7322,  0.1000,\n",
      "         43.7521,  0.1000, 43.6343, 43.6343, 43.7322, 43.7521, 43.7521,  0.1000,\n",
      "          0.1000, 43.6343, 43.7322, 43.7521,  0.1000, 43.7322, 43.7521,  0.1000,\n",
      "         43.6343, 43.7521]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 310 was 98.3%\n",
      "current params: tensor([43.6343, 43.7322, 43.6771, 43.7521], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.4\n",
      "SLow rates:  tensor([[43.7365, 43.8344, 43.7793, 43.8542,  0.1000,  0.1000,  0.1000, 43.7365,\n",
      "         43.7365, 43.7365,  0.1000,  0.1000, 43.8344, 43.8344, 43.8344,  0.1000,\n",
      "          0.1000, 43.8344, 43.8344,  0.1000, 43.7793, 43.7793, 43.7793,  0.1000,\n",
      "          0.1000, 43.7793, 43.7793,  0.1000, 43.7793,  0.1000, 43.7793, 43.8542,\n",
      "         43.8542, 43.8542,  0.1000,  0.1000, 43.8542, 43.8542,  0.1000, 43.8542,\n",
      "          0.1000, 43.8542, 43.8344, 43.8542, 43.8542, 43.8542, 43.7793, 43.8542,\n",
      "         43.8542, 43.8542, 43.8344, 43.8542, 43.8542, 43.8542, 43.8344, 43.7793,\n",
      "         43.8344, 43.8344, 43.8344,  0.1000, 43.8344, 43.7793,  0.1000, 43.7793,\n",
      "         43.8542,  0.1000, 43.8542, 43.8542, 43.8542, 43.8344, 43.8344,  0.1000,\n",
      "         43.8542,  0.1000, 43.7365, 43.7365, 43.8344, 43.8542, 43.8542,  0.1000,\n",
      "          0.1000, 43.7365, 43.8344, 43.8542,  0.1000, 43.8344, 43.8542,  0.1000,\n",
      "         43.7365, 43.8542]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 311 was 98.3%\n",
      "current params: tensor([43.7365, 43.8344, 43.7793, 43.8542], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.4\n",
      "SLow rates:  tensor([[43.8387, 43.9366, 43.8815, 43.9564,  0.1000,  0.1000,  0.1000, 43.8387,\n",
      "         43.8387, 43.8387,  0.1000,  0.1000, 43.9366, 43.9366, 43.9366,  0.1000,\n",
      "          0.1000, 43.9366, 43.9366,  0.1000, 43.8815, 43.8815, 43.8815,  0.1000,\n",
      "          0.1000, 43.8815, 43.8815,  0.1000, 43.8815,  0.1000, 43.8815, 43.9564,\n",
      "         43.9564, 43.9564,  0.1000,  0.1000, 43.9564, 43.9564,  0.1000, 43.9564,\n",
      "          0.1000, 43.9564, 43.9366, 43.9564, 43.9564, 43.9564, 43.8815, 43.9564,\n",
      "         43.9564, 43.9564, 43.9366, 43.9564, 43.9564, 43.9564, 43.9366, 43.8815,\n",
      "         43.9366, 43.9366, 43.9366,  0.1000, 43.9366, 43.8815,  0.1000, 43.8815,\n",
      "         43.9564,  0.1000, 43.9564, 43.9564, 43.9564, 43.9366, 43.9366,  0.1000,\n",
      "         43.9564,  0.1000, 43.8387, 43.8387, 43.9366, 43.9564, 43.9564,  0.1000,\n",
      "          0.1000, 43.8387, 43.9366, 43.9564,  0.1000, 43.9366, 43.9564,  0.1000,\n",
      "         43.8387, 43.9564]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 312 was 98.3%\n",
      "current params: tensor([43.8387, 43.9366, 43.8815, 43.9564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.4\n",
      "SLow rates:  tensor([[43.9408, 44.0387, 43.9836, 44.0585,  0.1000,  0.1000,  0.1000, 43.9408,\n",
      "         43.9408, 43.9408,  0.1000,  0.1000, 44.0387, 44.0387, 44.0387,  0.1000,\n",
      "          0.1000, 44.0387, 44.0387,  0.1000, 43.9836, 43.9836, 43.9836,  0.1000,\n",
      "          0.1000, 43.9836, 43.9836,  0.1000, 43.9836,  0.1000, 43.9836, 44.0585,\n",
      "         44.0585, 44.0585,  0.1000,  0.1000, 44.0585, 44.0585,  0.1000, 44.0585,\n",
      "          0.1000, 44.0585, 44.0387, 44.0585, 44.0585, 44.0585, 43.9836, 44.0585,\n",
      "         44.0585, 44.0585, 44.0387, 44.0585, 44.0585, 44.0585, 44.0387, 43.9836,\n",
      "         44.0387, 44.0387, 44.0387,  0.1000, 44.0387, 43.9836,  0.1000, 43.9836,\n",
      "         44.0585,  0.1000, 44.0585, 44.0585, 44.0585, 44.0387, 44.0387,  0.1000,\n",
      "         44.0585,  0.1000, 43.9408, 43.9408, 44.0387, 44.0585, 44.0585,  0.1000,\n",
      "          0.1000, 43.9408, 44.0387, 44.0585,  0.1000, 44.0387, 44.0585,  0.1000,\n",
      "         43.9408, 44.0585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 313 was 98.3%\n",
      "current params: tensor([43.9408, 44.0387, 43.9836, 44.0585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.5\n",
      "SLow rates:  tensor([[44.0430, 44.1408, 44.0857, 44.1606,  0.1000,  0.1000,  0.1000, 44.0430,\n",
      "         44.0430, 44.0430,  0.1000,  0.1000, 44.1408, 44.1408, 44.1408,  0.1000,\n",
      "          0.1000, 44.1408, 44.1408,  0.1000, 44.0857, 44.0857, 44.0857,  0.1000,\n",
      "          0.1000, 44.0857, 44.0857,  0.1000, 44.0857,  0.1000, 44.0857, 44.1606,\n",
      "         44.1606, 44.1606,  0.1000,  0.1000, 44.1606, 44.1606,  0.1000, 44.1606,\n",
      "          0.1000, 44.1606, 44.1408, 44.1606, 44.1606, 44.1606, 44.0857, 44.1606,\n",
      "         44.1606, 44.1606, 44.1408, 44.1606, 44.1606, 44.1606, 44.1408, 44.0857,\n",
      "         44.1408, 44.1408, 44.1408,  0.1000, 44.1408, 44.0857,  0.1000, 44.0857,\n",
      "         44.1606,  0.1000, 44.1606, 44.1606, 44.1606, 44.1408, 44.1408,  0.1000,\n",
      "         44.1606,  0.1000, 44.0430, 44.0430, 44.1408, 44.1606, 44.1606,  0.1000,\n",
      "          0.1000, 44.0430, 44.1408, 44.1606,  0.1000, 44.1408, 44.1606,  0.1000,\n",
      "         44.0430, 44.1606]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 314 was 98.3%\n",
      "current params: tensor([44.0430, 44.1408, 44.0857, 44.1606], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.5\n",
      "SLow rates:  tensor([[44.1451, 44.2429, 44.1878, 44.2627,  0.1000,  0.1000,  0.1000, 44.1451,\n",
      "         44.1451, 44.1451,  0.1000,  0.1000, 44.2429, 44.2429, 44.2429,  0.1000,\n",
      "          0.1000, 44.2429, 44.2429,  0.1000, 44.1878, 44.1878, 44.1878,  0.1000,\n",
      "          0.1000, 44.1878, 44.1878,  0.1000, 44.1878,  0.1000, 44.1878, 44.2627,\n",
      "         44.2627, 44.2627,  0.1000,  0.1000, 44.2627, 44.2627,  0.1000, 44.2627,\n",
      "          0.1000, 44.2627, 44.2429, 44.2627, 44.2627, 44.2627, 44.1878, 44.2627,\n",
      "         44.2627, 44.2627, 44.2429, 44.2627, 44.2627, 44.2627, 44.2429, 44.1878,\n",
      "         44.2429, 44.2429, 44.2429,  0.1000, 44.2429, 44.1878,  0.1000, 44.1878,\n",
      "         44.2627,  0.1000, 44.2627, 44.2627, 44.2627, 44.2429, 44.2429,  0.1000,\n",
      "         44.2627,  0.1000, 44.1451, 44.1451, 44.2429, 44.2627, 44.2627,  0.1000,\n",
      "          0.1000, 44.1451, 44.2429, 44.2627,  0.1000, 44.2429, 44.2627,  0.1000,\n",
      "         44.1451, 44.2627]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 315 was 98.3%\n",
      "current params: tensor([44.1451, 44.2429, 44.1878, 44.2627], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.5\n",
      "SLow rates:  tensor([[44.2472, 44.3450, 44.2899, 44.3647,  0.1000,  0.1000,  0.1000, 44.2472,\n",
      "         44.2472, 44.2472,  0.1000,  0.1000, 44.3450, 44.3450, 44.3450,  0.1000,\n",
      "          0.1000, 44.3450, 44.3450,  0.1000, 44.2899, 44.2899, 44.2899,  0.1000,\n",
      "          0.1000, 44.2899, 44.2899,  0.1000, 44.2899,  0.1000, 44.2899, 44.3647,\n",
      "         44.3647, 44.3647,  0.1000,  0.1000, 44.3647, 44.3647,  0.1000, 44.3647,\n",
      "          0.1000, 44.3647, 44.3450, 44.3647, 44.3647, 44.3647, 44.2899, 44.3647,\n",
      "         44.3647, 44.3647, 44.3450, 44.3647, 44.3647, 44.3647, 44.3450, 44.2899,\n",
      "         44.3450, 44.3450, 44.3450,  0.1000, 44.3450, 44.2899,  0.1000, 44.2899,\n",
      "         44.3647,  0.1000, 44.3647, 44.3647, 44.3647, 44.3450, 44.3450,  0.1000,\n",
      "         44.3647,  0.1000, 44.2472, 44.2472, 44.3450, 44.3647, 44.3647,  0.1000,\n",
      "          0.1000, 44.2472, 44.3450, 44.3647,  0.1000, 44.3450, 44.3647,  0.1000,\n",
      "         44.2472, 44.3647]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 316 was 98.3%\n",
      "current params: tensor([44.2472, 44.3450, 44.2899, 44.3647], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.5\n",
      "SLow rates:  tensor([[44.3493, 44.4471, 44.3920, 44.4667,  0.1000,  0.1000,  0.1000, 44.3493,\n",
      "         44.3493, 44.3493,  0.1000,  0.1000, 44.4471, 44.4471, 44.4471,  0.1000,\n",
      "          0.1000, 44.4471, 44.4471,  0.1000, 44.3920, 44.3920, 44.3920,  0.1000,\n",
      "          0.1000, 44.3920, 44.3920,  0.1000, 44.3920,  0.1000, 44.3920, 44.4667,\n",
      "         44.4667, 44.4667,  0.1000,  0.1000, 44.4667, 44.4667,  0.1000, 44.4667,\n",
      "          0.1000, 44.4667, 44.4471, 44.4667, 44.4667, 44.4667, 44.3920, 44.4667,\n",
      "         44.4667, 44.4667, 44.4471, 44.4667, 44.4667, 44.4667, 44.4471, 44.3920,\n",
      "         44.4471, 44.4471, 44.4471,  0.1000, 44.4471, 44.3920,  0.1000, 44.3920,\n",
      "         44.4667,  0.1000, 44.4667, 44.4667, 44.4667, 44.4471, 44.4471,  0.1000,\n",
      "         44.4667,  0.1000, 44.3493, 44.3493, 44.4471, 44.4667, 44.4667,  0.1000,\n",
      "          0.1000, 44.3493, 44.4471, 44.4667,  0.1000, 44.4471, 44.4667,  0.1000,\n",
      "         44.3493, 44.4667]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 317 was 98.3%\n",
      "current params: tensor([44.3493, 44.4471, 44.3920, 44.4667], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.5\n",
      "SLow rates:  tensor([[44.4513, 44.5491, 44.4940, 44.5688,  0.1000,  0.1000,  0.1000, 44.4513,\n",
      "         44.4513, 44.4513,  0.1000,  0.1000, 44.5491, 44.5491, 44.5491,  0.1000,\n",
      "          0.1000, 44.5491, 44.5491,  0.1000, 44.4940, 44.4940, 44.4940,  0.1000,\n",
      "          0.1000, 44.4940, 44.4940,  0.1000, 44.4940,  0.1000, 44.4940, 44.5688,\n",
      "         44.5688, 44.5688,  0.1000,  0.1000, 44.5688, 44.5688,  0.1000, 44.5688,\n",
      "          0.1000, 44.5688, 44.5491, 44.5688, 44.5688, 44.5688, 44.4940, 44.5688,\n",
      "         44.5688, 44.5688, 44.5491, 44.5688, 44.5688, 44.5688, 44.5491, 44.4940,\n",
      "         44.5491, 44.5491, 44.5491,  0.1000, 44.5491, 44.4940,  0.1000, 44.4940,\n",
      "         44.5688,  0.1000, 44.5688, 44.5688, 44.5688, 44.5491, 44.5491,  0.1000,\n",
      "         44.5688,  0.1000, 44.4513, 44.4513, 44.5491, 44.5688, 44.5688,  0.1000,\n",
      "          0.1000, 44.4513, 44.5491, 44.5688,  0.1000, 44.5491, 44.5688,  0.1000,\n",
      "         44.4513, 44.5688]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 318 was 98.3%\n",
      "current params: tensor([44.4513, 44.5491, 44.4940, 44.5688], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.6\n",
      "SLow rates:  tensor([[44.5534, 44.6511, 44.5960, 44.6707,  0.1000,  0.1000,  0.1000, 44.5534,\n",
      "         44.5534, 44.5534,  0.1000,  0.1000, 44.6511, 44.6511, 44.6511,  0.1000,\n",
      "          0.1000, 44.6511, 44.6511,  0.1000, 44.5960, 44.5960, 44.5960,  0.1000,\n",
      "          0.1000, 44.5960, 44.5960,  0.1000, 44.5960,  0.1000, 44.5960, 44.6707,\n",
      "         44.6707, 44.6707,  0.1000,  0.1000, 44.6707, 44.6707,  0.1000, 44.6707,\n",
      "          0.1000, 44.6707, 44.6511, 44.6707, 44.6707, 44.6707, 44.5960, 44.6707,\n",
      "         44.6707, 44.6707, 44.6511, 44.6707, 44.6707, 44.6707, 44.6511, 44.5960,\n",
      "         44.6511, 44.6511, 44.6511,  0.1000, 44.6511, 44.5960,  0.1000, 44.5960,\n",
      "         44.6707,  0.1000, 44.6707, 44.6707, 44.6707, 44.6511, 44.6511,  0.1000,\n",
      "         44.6707,  0.1000, 44.5534, 44.5534, 44.6511, 44.6707, 44.6707,  0.1000,\n",
      "          0.1000, 44.5534, 44.6511, 44.6707,  0.1000, 44.6511, 44.6707,  0.1000,\n",
      "         44.5534, 44.6707]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 319 was 98.3%\n",
      "current params: tensor([44.5534, 44.6511, 44.5960, 44.6707], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.6\n",
      "SLow rates:  tensor([[44.6554, 44.7531, 44.6980, 44.7727,  0.1000,  0.1000,  0.1000, 44.6554,\n",
      "         44.6554, 44.6554,  0.1000,  0.1000, 44.7531, 44.7531, 44.7531,  0.1000,\n",
      "          0.1000, 44.7531, 44.7531,  0.1000, 44.6980, 44.6980, 44.6980,  0.1000,\n",
      "          0.1000, 44.6980, 44.6980,  0.1000, 44.6980,  0.1000, 44.6980, 44.7727,\n",
      "         44.7727, 44.7727,  0.1000,  0.1000, 44.7727, 44.7727,  0.1000, 44.7727,\n",
      "          0.1000, 44.7727, 44.7531, 44.7727, 44.7727, 44.7727, 44.6980, 44.7727,\n",
      "         44.7727, 44.7727, 44.7531, 44.7727, 44.7727, 44.7727, 44.7531, 44.6980,\n",
      "         44.7531, 44.7531, 44.7531,  0.1000, 44.7531, 44.6980,  0.1000, 44.6980,\n",
      "         44.7727,  0.1000, 44.7727, 44.7727, 44.7727, 44.7531, 44.7531,  0.1000,\n",
      "         44.7727,  0.1000, 44.6554, 44.6554, 44.7531, 44.7727, 44.7727,  0.1000,\n",
      "          0.1000, 44.6554, 44.7531, 44.7727,  0.1000, 44.7531, 44.7727,  0.1000,\n",
      "         44.6554, 44.7727]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 320 was 98.3%\n",
      "current params: tensor([44.6554, 44.7531, 44.6980, 44.7727], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.6\n",
      "SLow rates:  tensor([[44.7574, 44.8550, 44.8000, 44.8747,  0.1000,  0.1000,  0.1000, 44.7574,\n",
      "         44.7574, 44.7574,  0.1000,  0.1000, 44.8550, 44.8550, 44.8550,  0.1000,\n",
      "          0.1000, 44.8550, 44.8550,  0.1000, 44.8000, 44.8000, 44.8000,  0.1000,\n",
      "          0.1000, 44.8000, 44.8000,  0.1000, 44.8000,  0.1000, 44.8000, 44.8747,\n",
      "         44.8747, 44.8747,  0.1000,  0.1000, 44.8747, 44.8747,  0.1000, 44.8747,\n",
      "          0.1000, 44.8747, 44.8550, 44.8747, 44.8747, 44.8747, 44.8000, 44.8747,\n",
      "         44.8747, 44.8747, 44.8550, 44.8747, 44.8747, 44.8747, 44.8550, 44.8000,\n",
      "         44.8550, 44.8550, 44.8550,  0.1000, 44.8550, 44.8000,  0.1000, 44.8000,\n",
      "         44.8747,  0.1000, 44.8747, 44.8747, 44.8747, 44.8550, 44.8550,  0.1000,\n",
      "         44.8747,  0.1000, 44.7574, 44.7574, 44.8550, 44.8747, 44.8747,  0.1000,\n",
      "          0.1000, 44.7574, 44.8550, 44.8747,  0.1000, 44.8550, 44.8747,  0.1000,\n",
      "         44.7574, 44.8747]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 321 was 98.3%\n",
      "current params: tensor([44.7574, 44.8550, 44.8000, 44.8747], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.6\n",
      "SLow rates:  tensor([[44.8594, 44.9570, 44.9020, 44.9766,  0.1000,  0.1000,  0.1000, 44.8594,\n",
      "         44.8594, 44.8594,  0.1000,  0.1000, 44.9570, 44.9570, 44.9570,  0.1000,\n",
      "          0.1000, 44.9570, 44.9570,  0.1000, 44.9020, 44.9020, 44.9020,  0.1000,\n",
      "          0.1000, 44.9020, 44.9020,  0.1000, 44.9020,  0.1000, 44.9020, 44.9766,\n",
      "         44.9766, 44.9766,  0.1000,  0.1000, 44.9766, 44.9766,  0.1000, 44.9766,\n",
      "          0.1000, 44.9766, 44.9570, 44.9766, 44.9766, 44.9766, 44.9020, 44.9766,\n",
      "         44.9766, 44.9766, 44.9570, 44.9766, 44.9766, 44.9766, 44.9570, 44.9020,\n",
      "         44.9570, 44.9570, 44.9570,  0.1000, 44.9570, 44.9020,  0.1000, 44.9020,\n",
      "         44.9766,  0.1000, 44.9766, 44.9766, 44.9766, 44.9570, 44.9570,  0.1000,\n",
      "         44.9766,  0.1000, 44.8594, 44.8594, 44.9570, 44.9766, 44.9766,  0.1000,\n",
      "          0.1000, 44.8594, 44.9570, 44.9766,  0.1000, 44.9570, 44.9766,  0.1000,\n",
      "         44.8594, 44.9766]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 322 was 98.3%\n",
      "current params: tensor([44.8594, 44.9570, 44.9020, 44.9766], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.6\n",
      "SLow rates:  tensor([[44.9613, 45.0589, 45.0039, 45.0785,  0.1000,  0.1000,  0.1000, 44.9613,\n",
      "         44.9613, 44.9613,  0.1000,  0.1000, 45.0589, 45.0589, 45.0589,  0.1000,\n",
      "          0.1000, 45.0589, 45.0589,  0.1000, 45.0039, 45.0039, 45.0039,  0.1000,\n",
      "          0.1000, 45.0039, 45.0039,  0.1000, 45.0039,  0.1000, 45.0039, 45.0785,\n",
      "         45.0785, 45.0785,  0.1000,  0.1000, 45.0785, 45.0785,  0.1000, 45.0785,\n",
      "          0.1000, 45.0785, 45.0589, 45.0785, 45.0785, 45.0785, 45.0039, 45.0785,\n",
      "         45.0785, 45.0785, 45.0589, 45.0785, 45.0785, 45.0785, 45.0589, 45.0039,\n",
      "         45.0589, 45.0589, 45.0589,  0.1000, 45.0589, 45.0039,  0.1000, 45.0039,\n",
      "         45.0785,  0.1000, 45.0785, 45.0785, 45.0785, 45.0589, 45.0589,  0.1000,\n",
      "         45.0785,  0.1000, 44.9613, 44.9613, 45.0589, 45.0785, 45.0785,  0.1000,\n",
      "          0.1000, 44.9613, 45.0589, 45.0785,  0.1000, 45.0589, 45.0785,  0.1000,\n",
      "         44.9613, 45.0785]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 323 was 98.3%\n",
      "current params: tensor([44.9613, 45.0589, 45.0039, 45.0785], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.7\n",
      "SLow rates:  tensor([[45.0632, 45.1608, 45.1058, 45.1804,  0.1000,  0.1000,  0.1000, 45.0632,\n",
      "         45.0632, 45.0632,  0.1000,  0.1000, 45.1608, 45.1608, 45.1608,  0.1000,\n",
      "          0.1000, 45.1608, 45.1608,  0.1000, 45.1058, 45.1058, 45.1058,  0.1000,\n",
      "          0.1000, 45.1058, 45.1058,  0.1000, 45.1058,  0.1000, 45.1058, 45.1804,\n",
      "         45.1804, 45.1804,  0.1000,  0.1000, 45.1804, 45.1804,  0.1000, 45.1804,\n",
      "          0.1000, 45.1804, 45.1608, 45.1804, 45.1804, 45.1804, 45.1058, 45.1804,\n",
      "         45.1804, 45.1804, 45.1608, 45.1804, 45.1804, 45.1804, 45.1608, 45.1058,\n",
      "         45.1608, 45.1608, 45.1608,  0.1000, 45.1608, 45.1058,  0.1000, 45.1058,\n",
      "         45.1804,  0.1000, 45.1804, 45.1804, 45.1804, 45.1608, 45.1608,  0.1000,\n",
      "         45.1804,  0.1000, 45.0632, 45.0632, 45.1608, 45.1804, 45.1804,  0.1000,\n",
      "          0.1000, 45.0632, 45.1608, 45.1804,  0.1000, 45.1608, 45.1804,  0.1000,\n",
      "         45.0632, 45.1804]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 324 was 98.3%\n",
      "current params: tensor([45.0632, 45.1608, 45.1058, 45.1804], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.7\n",
      "SLow rates:  tensor([[45.1652, 45.2627, 45.2077, 45.2822,  0.1000,  0.1000,  0.1000, 45.1652,\n",
      "         45.1652, 45.1652,  0.1000,  0.1000, 45.2627, 45.2627, 45.2627,  0.1000,\n",
      "          0.1000, 45.2627, 45.2627,  0.1000, 45.2077, 45.2077, 45.2077,  0.1000,\n",
      "          0.1000, 45.2077, 45.2077,  0.1000, 45.2077,  0.1000, 45.2077, 45.2822,\n",
      "         45.2822, 45.2822,  0.1000,  0.1000, 45.2822, 45.2822,  0.1000, 45.2822,\n",
      "          0.1000, 45.2822, 45.2627, 45.2822, 45.2822, 45.2822, 45.2077, 45.2822,\n",
      "         45.2822, 45.2822, 45.2627, 45.2822, 45.2822, 45.2822, 45.2627, 45.2077,\n",
      "         45.2627, 45.2627, 45.2627,  0.1000, 45.2627, 45.2077,  0.1000, 45.2077,\n",
      "         45.2822,  0.1000, 45.2822, 45.2822, 45.2822, 45.2627, 45.2627,  0.1000,\n",
      "         45.2822,  0.1000, 45.1652, 45.1652, 45.2627, 45.2822, 45.2822,  0.1000,\n",
      "          0.1000, 45.1652, 45.2627, 45.2822,  0.1000, 45.2627, 45.2822,  0.1000,\n",
      "         45.1652, 45.2822]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 325 was 98.3%\n",
      "current params: tensor([45.1652, 45.2627, 45.2077, 45.2822], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.7\n",
      "SLow rates:  tensor([[45.2671, 45.3646, 45.3096, 45.3841,  0.1000,  0.1000,  0.1000, 45.2671,\n",
      "         45.2671, 45.2671,  0.1000,  0.1000, 45.3646, 45.3646, 45.3646,  0.1000,\n",
      "          0.1000, 45.3646, 45.3646,  0.1000, 45.3096, 45.3096, 45.3096,  0.1000,\n",
      "          0.1000, 45.3096, 45.3096,  0.1000, 45.3096,  0.1000, 45.3096, 45.3841,\n",
      "         45.3841, 45.3841,  0.1000,  0.1000, 45.3841, 45.3841,  0.1000, 45.3841,\n",
      "          0.1000, 45.3841, 45.3646, 45.3841, 45.3841, 45.3841, 45.3096, 45.3841,\n",
      "         45.3841, 45.3841, 45.3646, 45.3841, 45.3841, 45.3841, 45.3646, 45.3096,\n",
      "         45.3646, 45.3646, 45.3646,  0.1000, 45.3646, 45.3096,  0.1000, 45.3096,\n",
      "         45.3841,  0.1000, 45.3841, 45.3841, 45.3841, 45.3646, 45.3646,  0.1000,\n",
      "         45.3841,  0.1000, 45.2671, 45.2671, 45.3646, 45.3841, 45.3841,  0.1000,\n",
      "          0.1000, 45.2671, 45.3646, 45.3841,  0.1000, 45.3646, 45.3841,  0.1000,\n",
      "         45.2671, 45.3841]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 326 was 98.3%\n",
      "current params: tensor([45.2671, 45.3646, 45.3096, 45.3841], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.7\n",
      "SLow rates:  tensor([[45.3689, 45.4664, 45.4115, 45.4859,  0.1000,  0.1000,  0.1000, 45.3689,\n",
      "         45.3689, 45.3689,  0.1000,  0.1000, 45.4664, 45.4664, 45.4664,  0.1000,\n",
      "          0.1000, 45.4664, 45.4664,  0.1000, 45.4115, 45.4115, 45.4115,  0.1000,\n",
      "          0.1000, 45.4115, 45.4115,  0.1000, 45.4115,  0.1000, 45.4115, 45.4859,\n",
      "         45.4859, 45.4859,  0.1000,  0.1000, 45.4859, 45.4859,  0.1000, 45.4859,\n",
      "          0.1000, 45.4859, 45.4664, 45.4859, 45.4859, 45.4859, 45.4115, 45.4859,\n",
      "         45.4859, 45.4859, 45.4664, 45.4859, 45.4859, 45.4859, 45.4664, 45.4115,\n",
      "         45.4664, 45.4664, 45.4664,  0.1000, 45.4664, 45.4115,  0.1000, 45.4115,\n",
      "         45.4859,  0.1000, 45.4859, 45.4859, 45.4859, 45.4664, 45.4664,  0.1000,\n",
      "         45.4859,  0.1000, 45.3689, 45.3689, 45.4664, 45.4859, 45.4859,  0.1000,\n",
      "          0.1000, 45.3689, 45.4664, 45.4859,  0.1000, 45.4664, 45.4859,  0.1000,\n",
      "         45.3689, 45.4859]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 327 was 98.3%\n",
      "current params: tensor([45.3689, 45.4664, 45.4115, 45.4859], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.7\n",
      "SLow rates:  tensor([[45.4708, 45.5683, 45.5133, 45.5877,  0.1000,  0.1000,  0.1000, 45.4708,\n",
      "         45.4708, 45.4708,  0.1000,  0.1000, 45.5683, 45.5683, 45.5683,  0.1000,\n",
      "          0.1000, 45.5683, 45.5683,  0.1000, 45.5133, 45.5133, 45.5133,  0.1000,\n",
      "          0.1000, 45.5133, 45.5133,  0.1000, 45.5133,  0.1000, 45.5133, 45.5877,\n",
      "         45.5877, 45.5877,  0.1000,  0.1000, 45.5877, 45.5877,  0.1000, 45.5877,\n",
      "          0.1000, 45.5877, 45.5683, 45.5877, 45.5877, 45.5877, 45.5133, 45.5877,\n",
      "         45.5877, 45.5877, 45.5683, 45.5877, 45.5877, 45.5877, 45.5683, 45.5133,\n",
      "         45.5683, 45.5683, 45.5683,  0.1000, 45.5683, 45.5133,  0.1000, 45.5133,\n",
      "         45.5877,  0.1000, 45.5877, 45.5877, 45.5877, 45.5683, 45.5683,  0.1000,\n",
      "         45.5877,  0.1000, 45.4708, 45.4708, 45.5683, 45.5877, 45.5877,  0.1000,\n",
      "          0.1000, 45.4708, 45.5683, 45.5877,  0.1000, 45.5683, 45.5877,  0.1000,\n",
      "         45.4708, 45.5877]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 328 was 98.3%\n",
      "current params: tensor([45.4708, 45.5683, 45.5133, 45.5877], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.7\n",
      "SLow rates:  tensor([[45.5726, 45.6701, 45.6151, 45.6895,  0.1000,  0.1000,  0.1000, 45.5726,\n",
      "         45.5726, 45.5726,  0.1000,  0.1000, 45.6701, 45.6701, 45.6701,  0.1000,\n",
      "          0.1000, 45.6701, 45.6701,  0.1000, 45.6151, 45.6151, 45.6151,  0.1000,\n",
      "          0.1000, 45.6151, 45.6151,  0.1000, 45.6151,  0.1000, 45.6151, 45.6895,\n",
      "         45.6895, 45.6895,  0.1000,  0.1000, 45.6895, 45.6895,  0.1000, 45.6895,\n",
      "          0.1000, 45.6895, 45.6701, 45.6895, 45.6895, 45.6895, 45.6151, 45.6895,\n",
      "         45.6895, 45.6895, 45.6701, 45.6895, 45.6895, 45.6895, 45.6701, 45.6151,\n",
      "         45.6701, 45.6701, 45.6701,  0.1000, 45.6701, 45.6151,  0.1000, 45.6151,\n",
      "         45.6895,  0.1000, 45.6895, 45.6895, 45.6895, 45.6701, 45.6701,  0.1000,\n",
      "         45.6895,  0.1000, 45.5726, 45.5726, 45.6701, 45.6895, 45.6895,  0.1000,\n",
      "          0.1000, 45.5726, 45.6701, 45.6895,  0.1000, 45.6701, 45.6895,  0.1000,\n",
      "         45.5726, 45.6895]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 329 was 98.3%\n",
      "current params: tensor([45.5726, 45.6701, 45.6151, 45.6895], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.8\n",
      "SLow rates:  tensor([[45.6744, 45.7719, 45.7169, 45.7913,  0.1000,  0.1000,  0.1000, 45.6744,\n",
      "         45.6744, 45.6744,  0.1000,  0.1000, 45.7719, 45.7719, 45.7719,  0.1000,\n",
      "          0.1000, 45.7719, 45.7719,  0.1000, 45.7169, 45.7169, 45.7169,  0.1000,\n",
      "          0.1000, 45.7169, 45.7169,  0.1000, 45.7169,  0.1000, 45.7169, 45.7913,\n",
      "         45.7913, 45.7913,  0.1000,  0.1000, 45.7913, 45.7913,  0.1000, 45.7913,\n",
      "          0.1000, 45.7913, 45.7719, 45.7913, 45.7913, 45.7913, 45.7169, 45.7913,\n",
      "         45.7913, 45.7913, 45.7719, 45.7913, 45.7913, 45.7913, 45.7719, 45.7169,\n",
      "         45.7719, 45.7719, 45.7719,  0.1000, 45.7719, 45.7169,  0.1000, 45.7169,\n",
      "         45.7913,  0.1000, 45.7913, 45.7913, 45.7913, 45.7719, 45.7719,  0.1000,\n",
      "         45.7913,  0.1000, 45.6744, 45.6744, 45.7719, 45.7913, 45.7913,  0.1000,\n",
      "          0.1000, 45.6744, 45.7719, 45.7913,  0.1000, 45.7719, 45.7913,  0.1000,\n",
      "         45.6744, 45.7913]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 330 was 98.3%\n",
      "current params: tensor([45.6744, 45.7719, 45.7169, 45.7913], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.8\n",
      "SLow rates:  tensor([[45.7762, 45.8736, 45.8187, 45.8930,  0.1000,  0.1000,  0.1000, 45.7762,\n",
      "         45.7762, 45.7762,  0.1000,  0.1000, 45.8736, 45.8736, 45.8736,  0.1000,\n",
      "          0.1000, 45.8736, 45.8736,  0.1000, 45.8187, 45.8187, 45.8187,  0.1000,\n",
      "          0.1000, 45.8187, 45.8187,  0.1000, 45.8187,  0.1000, 45.8187, 45.8930,\n",
      "         45.8930, 45.8930,  0.1000,  0.1000, 45.8930, 45.8930,  0.1000, 45.8930,\n",
      "          0.1000, 45.8930, 45.8736, 45.8930, 45.8930, 45.8930, 45.8187, 45.8930,\n",
      "         45.8930, 45.8930, 45.8736, 45.8930, 45.8930, 45.8930, 45.8736, 45.8187,\n",
      "         45.8736, 45.8736, 45.8736,  0.1000, 45.8736, 45.8187,  0.1000, 45.8187,\n",
      "         45.8930,  0.1000, 45.8930, 45.8930, 45.8930, 45.8736, 45.8736,  0.1000,\n",
      "         45.8930,  0.1000, 45.7762, 45.7762, 45.8736, 45.8930, 45.8930,  0.1000,\n",
      "          0.1000, 45.7762, 45.8736, 45.8930,  0.1000, 45.8736, 45.8930,  0.1000,\n",
      "         45.7762, 45.8930]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1639, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 331 was 98.3%\n",
      "current params: tensor([45.7762, 45.8736, 45.8187, 45.8930], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.8\n",
      "SLow rates:  tensor([[45.8780, 45.9754, 45.9205, 45.9948,  0.1000,  0.1000,  0.1000, 45.8780,\n",
      "         45.8780, 45.8780,  0.1000,  0.1000, 45.9754, 45.9754, 45.9754,  0.1000,\n",
      "          0.1000, 45.9754, 45.9754,  0.1000, 45.9205, 45.9205, 45.9205,  0.1000,\n",
      "          0.1000, 45.9205, 45.9205,  0.1000, 45.9205,  0.1000, 45.9205, 45.9948,\n",
      "         45.9948, 45.9948,  0.1000,  0.1000, 45.9948, 45.9948,  0.1000, 45.9948,\n",
      "          0.1000, 45.9948, 45.9754, 45.9948, 45.9948, 45.9948, 45.9205, 45.9948,\n",
      "         45.9948, 45.9948, 45.9754, 45.9948, 45.9948, 45.9948, 45.9754, 45.9205,\n",
      "         45.9754, 45.9754, 45.9754,  0.1000, 45.9754, 45.9205,  0.1000, 45.9205,\n",
      "         45.9948,  0.1000, 45.9948, 45.9948, 45.9948, 45.9754, 45.9754,  0.1000,\n",
      "         45.9948,  0.1000, 45.8780, 45.8780, 45.9754, 45.9948, 45.9948,  0.1000,\n",
      "          0.1000, 45.8780, 45.9754, 45.9948,  0.1000, 45.9754, 45.9948,  0.1000,\n",
      "         45.8780, 45.9948]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 332 was 98.3%\n",
      "current params: tensor([45.8780, 45.9754, 45.9205, 45.9948], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.8\n",
      "SLow rates:  tensor([[45.9798, 46.0771, 46.0222, 46.0965,  0.1000,  0.1000,  0.1000, 45.9798,\n",
      "         45.9798, 45.9798,  0.1000,  0.1000, 46.0771, 46.0771, 46.0771,  0.1000,\n",
      "          0.1000, 46.0771, 46.0771,  0.1000, 46.0222, 46.0222, 46.0222,  0.1000,\n",
      "          0.1000, 46.0222, 46.0222,  0.1000, 46.0222,  0.1000, 46.0222, 46.0965,\n",
      "         46.0965, 46.0965,  0.1000,  0.1000, 46.0965, 46.0965,  0.1000, 46.0965,\n",
      "          0.1000, 46.0965, 46.0771, 46.0965, 46.0965, 46.0965, 46.0222, 46.0965,\n",
      "         46.0965, 46.0965, 46.0771, 46.0965, 46.0965, 46.0965, 46.0771, 46.0222,\n",
      "         46.0771, 46.0771, 46.0771,  0.1000, 46.0771, 46.0222,  0.1000, 46.0222,\n",
      "         46.0965,  0.1000, 46.0965, 46.0965, 46.0965, 46.0771, 46.0771,  0.1000,\n",
      "         46.0965,  0.1000, 45.9798, 45.9798, 46.0771, 46.0965, 46.0965,  0.1000,\n",
      "          0.1000, 45.9798, 46.0771, 46.0965,  0.1000, 46.0771, 46.0965,  0.1000,\n",
      "         45.9798, 46.0965]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 333 was 98.3%\n",
      "current params: tensor([45.9798, 46.0771, 46.0222, 46.0965], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.8\n",
      "SLow rates:  tensor([[46.0815, 46.1788, 46.1239, 46.1982,  0.1000,  0.1000,  0.1000, 46.0815,\n",
      "         46.0815, 46.0815,  0.1000,  0.1000, 46.1788, 46.1788, 46.1788,  0.1000,\n",
      "          0.1000, 46.1788, 46.1788,  0.1000, 46.1239, 46.1239, 46.1239,  0.1000,\n",
      "          0.1000, 46.1239, 46.1239,  0.1000, 46.1239,  0.1000, 46.1239, 46.1982,\n",
      "         46.1982, 46.1982,  0.1000,  0.1000, 46.1982, 46.1982,  0.1000, 46.1982,\n",
      "          0.1000, 46.1982, 46.1788, 46.1982, 46.1982, 46.1982, 46.1239, 46.1982,\n",
      "         46.1982, 46.1982, 46.1788, 46.1982, 46.1982, 46.1982, 46.1788, 46.1239,\n",
      "         46.1788, 46.1788, 46.1788,  0.1000, 46.1788, 46.1239,  0.1000, 46.1239,\n",
      "         46.1982,  0.1000, 46.1982, 46.1982, 46.1982, 46.1788, 46.1788,  0.1000,\n",
      "         46.1982,  0.1000, 46.0815, 46.0815, 46.1788, 46.1982, 46.1982,  0.1000,\n",
      "          0.1000, 46.0815, 46.1788, 46.1982,  0.1000, 46.1788, 46.1982,  0.1000,\n",
      "         46.0815, 46.1982]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 334 was 98.3%\n",
      "current params: tensor([46.0815, 46.1788, 46.1239, 46.1982], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.9\n",
      "SLow rates:  tensor([[46.1832, 46.2805, 46.2256, 46.2999,  0.1000,  0.1000,  0.1000, 46.1832,\n",
      "         46.1832, 46.1832,  0.1000,  0.1000, 46.2805, 46.2805, 46.2805,  0.1000,\n",
      "          0.1000, 46.2805, 46.2805,  0.1000, 46.2256, 46.2256, 46.2256,  0.1000,\n",
      "          0.1000, 46.2256, 46.2256,  0.1000, 46.2256,  0.1000, 46.2256, 46.2999,\n",
      "         46.2999, 46.2999,  0.1000,  0.1000, 46.2999, 46.2999,  0.1000, 46.2999,\n",
      "          0.1000, 46.2999, 46.2805, 46.2999, 46.2999, 46.2999, 46.2256, 46.2999,\n",
      "         46.2999, 46.2999, 46.2805, 46.2999, 46.2999, 46.2999, 46.2805, 46.2256,\n",
      "         46.2805, 46.2805, 46.2805,  0.1000, 46.2805, 46.2256,  0.1000, 46.2256,\n",
      "         46.2999,  0.1000, 46.2999, 46.2999, 46.2999, 46.2805, 46.2805,  0.1000,\n",
      "         46.2999,  0.1000, 46.1832, 46.1832, 46.2805, 46.2999, 46.2999,  0.1000,\n",
      "          0.1000, 46.1832, 46.2805, 46.2999,  0.1000, 46.2805, 46.2999,  0.1000,\n",
      "         46.1832, 46.2999]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 335 was 98.4%\n",
      "current params: tensor([46.1832, 46.2805, 46.2256, 46.2999], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.9\n",
      "SLow rates:  tensor([[46.2849, 46.3822, 46.3273, 46.4015,  0.1000,  0.1000,  0.1000, 46.2849,\n",
      "         46.2849, 46.2849,  0.1000,  0.1000, 46.3822, 46.3822, 46.3822,  0.1000,\n",
      "          0.1000, 46.3822, 46.3822,  0.1000, 46.3273, 46.3273, 46.3273,  0.1000,\n",
      "          0.1000, 46.3273, 46.3273,  0.1000, 46.3273,  0.1000, 46.3273, 46.4015,\n",
      "         46.4015, 46.4015,  0.1000,  0.1000, 46.4015, 46.4015,  0.1000, 46.4015,\n",
      "          0.1000, 46.4015, 46.3822, 46.4015, 46.4015, 46.4015, 46.3273, 46.4015,\n",
      "         46.4015, 46.4015, 46.3822, 46.4015, 46.4015, 46.4015, 46.3822, 46.3273,\n",
      "         46.3822, 46.3822, 46.3822,  0.1000, 46.3822, 46.3273,  0.1000, 46.3273,\n",
      "         46.4015,  0.1000, 46.4015, 46.4015, 46.4015, 46.3822, 46.3822,  0.1000,\n",
      "         46.4015,  0.1000, 46.2849, 46.2849, 46.3822, 46.4015, 46.4015,  0.1000,\n",
      "          0.1000, 46.2849, 46.3822, 46.4015,  0.1000, 46.3822, 46.4015,  0.1000,\n",
      "         46.2849, 46.4015]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 336 was 98.4%\n",
      "current params: tensor([46.2849, 46.3822, 46.3273, 46.4015], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.9\n",
      "SLow rates:  tensor([[46.3866, 46.4839, 46.4290, 46.5032,  0.1000,  0.1000,  0.1000, 46.3866,\n",
      "         46.3866, 46.3866,  0.1000,  0.1000, 46.4839, 46.4839, 46.4839,  0.1000,\n",
      "          0.1000, 46.4839, 46.4839,  0.1000, 46.4290, 46.4290, 46.4290,  0.1000,\n",
      "          0.1000, 46.4290, 46.4290,  0.1000, 46.4290,  0.1000, 46.4290, 46.5032,\n",
      "         46.5032, 46.5032,  0.1000,  0.1000, 46.5032, 46.5032,  0.1000, 46.5032,\n",
      "          0.1000, 46.5032, 46.4839, 46.5032, 46.5032, 46.5032, 46.4290, 46.5032,\n",
      "         46.5032, 46.5032, 46.4839, 46.5032, 46.5032, 46.5032, 46.4839, 46.4290,\n",
      "         46.4839, 46.4839, 46.4839,  0.1000, 46.4839, 46.4290,  0.1000, 46.4290,\n",
      "         46.5032,  0.1000, 46.5032, 46.5032, 46.5032, 46.4839, 46.4839,  0.1000,\n",
      "         46.5032,  0.1000, 46.3866, 46.3866, 46.4839, 46.5032, 46.5032,  0.1000,\n",
      "          0.1000, 46.3866, 46.4839, 46.5032,  0.1000, 46.4839, 46.5032,  0.1000,\n",
      "         46.3866, 46.5032]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 337 was 98.4%\n",
      "current params: tensor([46.3866, 46.4839, 46.4290, 46.5032], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.9\n",
      "SLow rates:  tensor([[46.4883, 46.5855, 46.5307, 46.6048,  0.1000,  0.1000,  0.1000, 46.4883,\n",
      "         46.4883, 46.4883,  0.1000,  0.1000, 46.5855, 46.5855, 46.5855,  0.1000,\n",
      "          0.1000, 46.5855, 46.5855,  0.1000, 46.5307, 46.5307, 46.5307,  0.1000,\n",
      "          0.1000, 46.5307, 46.5307,  0.1000, 46.5307,  0.1000, 46.5307, 46.6048,\n",
      "         46.6048, 46.6048,  0.1000,  0.1000, 46.6048, 46.6048,  0.1000, 46.6048,\n",
      "          0.1000, 46.6048, 46.5855, 46.6048, 46.6048, 46.6048, 46.5307, 46.6048,\n",
      "         46.6048, 46.6048, 46.5855, 46.6048, 46.6048, 46.6048, 46.5855, 46.5307,\n",
      "         46.5855, 46.5855, 46.5855,  0.1000, 46.5855, 46.5307,  0.1000, 46.5307,\n",
      "         46.6048,  0.1000, 46.6048, 46.6048, 46.6048, 46.5855, 46.5855,  0.1000,\n",
      "         46.6048,  0.1000, 46.4883, 46.4883, 46.5855, 46.6048, 46.6048,  0.1000,\n",
      "          0.1000, 46.4883, 46.5855, 46.6048,  0.1000, 46.5855, 46.6048,  0.1000,\n",
      "         46.4883, 46.6048]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 338 was 98.4%\n",
      "current params: tensor([46.4883, 46.5855, 46.5307, 46.6048], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  11.9\n",
      "SLow rates:  tensor([[46.5900, 46.6872, 46.6323, 46.7064,  0.1000,  0.1000,  0.1000, 46.5900,\n",
      "         46.5900, 46.5900,  0.1000,  0.1000, 46.6872, 46.6872, 46.6872,  0.1000,\n",
      "          0.1000, 46.6872, 46.6872,  0.1000, 46.6323, 46.6323, 46.6323,  0.1000,\n",
      "          0.1000, 46.6323, 46.6323,  0.1000, 46.6323,  0.1000, 46.6323, 46.7064,\n",
      "         46.7064, 46.7064,  0.1000,  0.1000, 46.7064, 46.7064,  0.1000, 46.7064,\n",
      "          0.1000, 46.7064, 46.6872, 46.7064, 46.7064, 46.7064, 46.6323, 46.7064,\n",
      "         46.7064, 46.7064, 46.6872, 46.7064, 46.7064, 46.7064, 46.6872, 46.6323,\n",
      "         46.6872, 46.6872, 46.6872,  0.1000, 46.6872, 46.6323,  0.1000, 46.6323,\n",
      "         46.7064,  0.1000, 46.7064, 46.7064, 46.7064, 46.6872, 46.6872,  0.1000,\n",
      "         46.7064,  0.1000, 46.5900, 46.5900, 46.6872, 46.7064, 46.7064,  0.1000,\n",
      "          0.1000, 46.5900, 46.6872, 46.7064,  0.1000, 46.6872, 46.7064,  0.1000,\n",
      "         46.5900, 46.7064]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1617, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 339 was 98.4%\n",
      "current params: tensor([46.5900, 46.6872, 46.6323, 46.7064], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.0\n",
      "SLow rates:  tensor([[46.6916, 46.7888, 46.7339, 46.8080,  0.1000,  0.1000,  0.1000, 46.6916,\n",
      "         46.6916, 46.6916,  0.1000,  0.1000, 46.7888, 46.7888, 46.7888,  0.1000,\n",
      "          0.1000, 46.7888, 46.7888,  0.1000, 46.7339, 46.7339, 46.7339,  0.1000,\n",
      "          0.1000, 46.7339, 46.7339,  0.1000, 46.7339,  0.1000, 46.7339, 46.8080,\n",
      "         46.8080, 46.8080,  0.1000,  0.1000, 46.8080, 46.8080,  0.1000, 46.8080,\n",
      "          0.1000, 46.8080, 46.7888, 46.8080, 46.8080, 46.8080, 46.7339, 46.8080,\n",
      "         46.8080, 46.8080, 46.7888, 46.8080, 46.8080, 46.8080, 46.7888, 46.7339,\n",
      "         46.7888, 46.7888, 46.7888,  0.1000, 46.7888, 46.7339,  0.1000, 46.7339,\n",
      "         46.8080,  0.1000, 46.8080, 46.8080, 46.8080, 46.7888, 46.7888,  0.1000,\n",
      "         46.8080,  0.1000, 46.6916, 46.6916, 46.7888, 46.8080, 46.8080,  0.1000,\n",
      "          0.1000, 46.6916, 46.7888, 46.8080,  0.1000, 46.7888, 46.8080,  0.1000,\n",
      "         46.6916, 46.8080]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 340 was 98.4%\n",
      "current params: tensor([46.6916, 46.7888, 46.7339, 46.8080], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.0\n",
      "SLow rates:  tensor([[46.7932, 46.8904, 46.8355, 46.9096,  0.1000,  0.1000,  0.1000, 46.7932,\n",
      "         46.7932, 46.7932,  0.1000,  0.1000, 46.8904, 46.8904, 46.8904,  0.1000,\n",
      "          0.1000, 46.8904, 46.8904,  0.1000, 46.8355, 46.8355, 46.8355,  0.1000,\n",
      "          0.1000, 46.8355, 46.8355,  0.1000, 46.8355,  0.1000, 46.8355, 46.9096,\n",
      "         46.9096, 46.9096,  0.1000,  0.1000, 46.9096, 46.9096,  0.1000, 46.9096,\n",
      "          0.1000, 46.9096, 46.8904, 46.9096, 46.9096, 46.9096, 46.8355, 46.9096,\n",
      "         46.9096, 46.9096, 46.8904, 46.9096, 46.9096, 46.9096, 46.8904, 46.8355,\n",
      "         46.8904, 46.8904, 46.8904,  0.1000, 46.8904, 46.8355,  0.1000, 46.8355,\n",
      "         46.9096,  0.1000, 46.9096, 46.9096, 46.9096, 46.8904, 46.8904,  0.1000,\n",
      "         46.9096,  0.1000, 46.7932, 46.7932, 46.8904, 46.9096, 46.9096,  0.1000,\n",
      "          0.1000, 46.7932, 46.8904, 46.9096,  0.1000, 46.8904, 46.9096,  0.1000,\n",
      "         46.7932, 46.9096]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 341 was 98.4%\n",
      "current params: tensor([46.7932, 46.8904, 46.8355, 46.9096], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.0\n",
      "SLow rates:  tensor([[46.8948, 46.9919, 46.9371, 47.0112,  0.1000,  0.1000,  0.1000, 46.8948,\n",
      "         46.8948, 46.8948,  0.1000,  0.1000, 46.9919, 46.9919, 46.9919,  0.1000,\n",
      "          0.1000, 46.9919, 46.9919,  0.1000, 46.9371, 46.9371, 46.9371,  0.1000,\n",
      "          0.1000, 46.9371, 46.9371,  0.1000, 46.9371,  0.1000, 46.9371, 47.0112,\n",
      "         47.0112, 47.0112,  0.1000,  0.1000, 47.0112, 47.0112,  0.1000, 47.0112,\n",
      "          0.1000, 47.0112, 46.9919, 47.0112, 47.0112, 47.0112, 46.9371, 47.0112,\n",
      "         47.0112, 47.0112, 46.9919, 47.0112, 47.0112, 47.0112, 46.9919, 46.9371,\n",
      "         46.9919, 46.9919, 46.9919,  0.1000, 46.9919, 46.9371,  0.1000, 46.9371,\n",
      "         47.0112,  0.1000, 47.0112, 47.0112, 47.0112, 46.9919, 46.9919,  0.1000,\n",
      "         47.0112,  0.1000, 46.8948, 46.8948, 46.9919, 47.0112, 47.0112,  0.1000,\n",
      "          0.1000, 46.8948, 46.9919, 47.0112,  0.1000, 46.9919, 47.0112,  0.1000,\n",
      "         46.8948, 47.0112]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 342 was 98.4%\n",
      "current params: tensor([46.8948, 46.9919, 46.9371, 47.0112], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.0\n",
      "SLow rates:  tensor([[46.9964, 47.0935, 47.0387, 47.1127,  0.1000,  0.1000,  0.1000, 46.9964,\n",
      "         46.9964, 46.9964,  0.1000,  0.1000, 47.0935, 47.0935, 47.0935,  0.1000,\n",
      "          0.1000, 47.0935, 47.0935,  0.1000, 47.0387, 47.0387, 47.0387,  0.1000,\n",
      "          0.1000, 47.0387, 47.0387,  0.1000, 47.0387,  0.1000, 47.0387, 47.1127,\n",
      "         47.1127, 47.1127,  0.1000,  0.1000, 47.1127, 47.1127,  0.1000, 47.1127,\n",
      "          0.1000, 47.1127, 47.0935, 47.1127, 47.1127, 47.1127, 47.0387, 47.1127,\n",
      "         47.1127, 47.1127, 47.0935, 47.1127, 47.1127, 47.1127, 47.0935, 47.0387,\n",
      "         47.0935, 47.0935, 47.0935,  0.1000, 47.0935, 47.0387,  0.1000, 47.0387,\n",
      "         47.1127,  0.1000, 47.1127, 47.1127, 47.1127, 47.0935, 47.0935,  0.1000,\n",
      "         47.1127,  0.1000, 46.9964, 46.9964, 47.0935, 47.1127, 47.1127,  0.1000,\n",
      "          0.1000, 46.9964, 47.0935, 47.1127,  0.1000, 47.0935, 47.1127,  0.1000,\n",
      "         46.9964, 47.1127]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 343 was 98.4%\n",
      "current params: tensor([46.9964, 47.0935, 47.0387, 47.1127], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.0\n",
      "SLow rates:  tensor([[47.0980, 47.1951, 47.1403, 47.2142,  0.1000,  0.1000,  0.1000, 47.0980,\n",
      "         47.0980, 47.0980,  0.1000,  0.1000, 47.1951, 47.1951, 47.1951,  0.1000,\n",
      "          0.1000, 47.1951, 47.1951,  0.1000, 47.1403, 47.1403, 47.1403,  0.1000,\n",
      "          0.1000, 47.1403, 47.1403,  0.1000, 47.1403,  0.1000, 47.1403, 47.2142,\n",
      "         47.2142, 47.2142,  0.1000,  0.1000, 47.2142, 47.2142,  0.1000, 47.2142,\n",
      "          0.1000, 47.2142, 47.1951, 47.2142, 47.2142, 47.2142, 47.1403, 47.2142,\n",
      "         47.2142, 47.2142, 47.1951, 47.2142, 47.2142, 47.2142, 47.1951, 47.1403,\n",
      "         47.1951, 47.1951, 47.1951,  0.1000, 47.1951, 47.1403,  0.1000, 47.1403,\n",
      "         47.2142,  0.1000, 47.2142, 47.2142, 47.2142, 47.1951, 47.1951,  0.1000,\n",
      "         47.2142,  0.1000, 47.0980, 47.0980, 47.1951, 47.2142, 47.2142,  0.1000,\n",
      "          0.1000, 47.0980, 47.1951, 47.2142,  0.1000, 47.1951, 47.2142,  0.1000,\n",
      "         47.0980, 47.2142]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 344 was 98.4%\n",
      "current params: tensor([47.0980, 47.1951, 47.1403, 47.2142], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.1\n",
      "SLow rates:  tensor([[47.1995, 47.2966, 47.2418, 47.3158,  0.1000,  0.1000,  0.1000, 47.1995,\n",
      "         47.1995, 47.1995,  0.1000,  0.1000, 47.2966, 47.2966, 47.2966,  0.1000,\n",
      "          0.1000, 47.2966, 47.2966,  0.1000, 47.2418, 47.2418, 47.2418,  0.1000,\n",
      "          0.1000, 47.2418, 47.2418,  0.1000, 47.2418,  0.1000, 47.2418, 47.3158,\n",
      "         47.3158, 47.3158,  0.1000,  0.1000, 47.3158, 47.3158,  0.1000, 47.3158,\n",
      "          0.1000, 47.3158, 47.2966, 47.3158, 47.3158, 47.3158, 47.2418, 47.3158,\n",
      "         47.3158, 47.3158, 47.2966, 47.3158, 47.3158, 47.3158, 47.2966, 47.2418,\n",
      "         47.2966, 47.2966, 47.2966,  0.1000, 47.2966, 47.2418,  0.1000, 47.2418,\n",
      "         47.3158,  0.1000, 47.3158, 47.3158, 47.3158, 47.2966, 47.2966,  0.1000,\n",
      "         47.3158,  0.1000, 47.1995, 47.1995, 47.2966, 47.3158, 47.3158,  0.1000,\n",
      "          0.1000, 47.1995, 47.2966, 47.3158,  0.1000, 47.2966, 47.3158,  0.1000,\n",
      "         47.1995, 47.3158]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 345 was 98.4%\n",
      "current params: tensor([47.1995, 47.2966, 47.2418, 47.3158], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.1\n",
      "SLow rates:  tensor([[47.3011, 47.3981, 47.3433, 47.4173,  0.1000,  0.1000,  0.1000, 47.3011,\n",
      "         47.3011, 47.3011,  0.1000,  0.1000, 47.3981, 47.3981, 47.3981,  0.1000,\n",
      "          0.1000, 47.3981, 47.3981,  0.1000, 47.3433, 47.3433, 47.3433,  0.1000,\n",
      "          0.1000, 47.3433, 47.3433,  0.1000, 47.3433,  0.1000, 47.3433, 47.4173,\n",
      "         47.4173, 47.4173,  0.1000,  0.1000, 47.4173, 47.4173,  0.1000, 47.4173,\n",
      "          0.1000, 47.4173, 47.3981, 47.4173, 47.4173, 47.4173, 47.3433, 47.4173,\n",
      "         47.4173, 47.4173, 47.3981, 47.4173, 47.4173, 47.4173, 47.3981, 47.3433,\n",
      "         47.3981, 47.3981, 47.3981,  0.1000, 47.3981, 47.3433,  0.1000, 47.3433,\n",
      "         47.4173,  0.1000, 47.4173, 47.4173, 47.4173, 47.3981, 47.3981,  0.1000,\n",
      "         47.4173,  0.1000, 47.3011, 47.3011, 47.3981, 47.4173, 47.4173,  0.1000,\n",
      "          0.1000, 47.3011, 47.3981, 47.4173,  0.1000, 47.3981, 47.4173,  0.1000,\n",
      "         47.3011, 47.4173]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 346 was 98.4%\n",
      "current params: tensor([47.3011, 47.3981, 47.3433, 47.4173], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.1\n",
      "SLow rates:  tensor([[47.4026, 47.4996, 47.4448, 47.5187,  0.1000,  0.1000,  0.1000, 47.4026,\n",
      "         47.4026, 47.4026,  0.1000,  0.1000, 47.4996, 47.4996, 47.4996,  0.1000,\n",
      "          0.1000, 47.4996, 47.4996,  0.1000, 47.4448, 47.4448, 47.4448,  0.1000,\n",
      "          0.1000, 47.4448, 47.4448,  0.1000, 47.4448,  0.1000, 47.4448, 47.5187,\n",
      "         47.5187, 47.5187,  0.1000,  0.1000, 47.5187, 47.5187,  0.1000, 47.5187,\n",
      "          0.1000, 47.5187, 47.4996, 47.5187, 47.5187, 47.5187, 47.4448, 47.5187,\n",
      "         47.5187, 47.5187, 47.4996, 47.5187, 47.5187, 47.5187, 47.4996, 47.4448,\n",
      "         47.4996, 47.4996, 47.4996,  0.1000, 47.4996, 47.4448,  0.1000, 47.4448,\n",
      "         47.5187,  0.1000, 47.5187, 47.5187, 47.5187, 47.4996, 47.4996,  0.1000,\n",
      "         47.5187,  0.1000, 47.4026, 47.4026, 47.4996, 47.5187, 47.5187,  0.1000,\n",
      "          0.1000, 47.4026, 47.4996, 47.5187,  0.1000, 47.4996, 47.5187,  0.1000,\n",
      "         47.4026, 47.5187]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 347 was 98.4%\n",
      "current params: tensor([47.4026, 47.4996, 47.4448, 47.5187], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.1\n",
      "SLow rates:  tensor([[47.5041, 47.6011, 47.5463, 47.6202,  0.1000,  0.1000,  0.1000, 47.5041,\n",
      "         47.5041, 47.5041,  0.1000,  0.1000, 47.6011, 47.6011, 47.6011,  0.1000,\n",
      "          0.1000, 47.6011, 47.6011,  0.1000, 47.5463, 47.5463, 47.5463,  0.1000,\n",
      "          0.1000, 47.5463, 47.5463,  0.1000, 47.5463,  0.1000, 47.5463, 47.6202,\n",
      "         47.6202, 47.6202,  0.1000,  0.1000, 47.6202, 47.6202,  0.1000, 47.6202,\n",
      "          0.1000, 47.6202, 47.6011, 47.6202, 47.6202, 47.6202, 47.5463, 47.6202,\n",
      "         47.6202, 47.6202, 47.6011, 47.6202, 47.6202, 47.6202, 47.6011, 47.5463,\n",
      "         47.6011, 47.6011, 47.6011,  0.1000, 47.6011, 47.5463,  0.1000, 47.5463,\n",
      "         47.6202,  0.1000, 47.6202, 47.6202, 47.6202, 47.6011, 47.6011,  0.1000,\n",
      "         47.6202,  0.1000, 47.5041, 47.5041, 47.6011, 47.6202, 47.6202,  0.1000,\n",
      "          0.1000, 47.5041, 47.6011, 47.6202,  0.1000, 47.6011, 47.6202,  0.1000,\n",
      "         47.5041, 47.6202]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 348 was 98.4%\n",
      "current params: tensor([47.5041, 47.6011, 47.5463, 47.6202], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.1\n",
      "SLow rates:  tensor([[47.6056, 47.7026, 47.6478, 47.7217,  0.1000,  0.1000,  0.1000, 47.6056,\n",
      "         47.6056, 47.6056,  0.1000,  0.1000, 47.7026, 47.7026, 47.7026,  0.1000,\n",
      "          0.1000, 47.7026, 47.7026,  0.1000, 47.6478, 47.6478, 47.6478,  0.1000,\n",
      "          0.1000, 47.6478, 47.6478,  0.1000, 47.6478,  0.1000, 47.6478, 47.7217,\n",
      "         47.7217, 47.7217,  0.1000,  0.1000, 47.7217, 47.7217,  0.1000, 47.7217,\n",
      "          0.1000, 47.7217, 47.7026, 47.7217, 47.7217, 47.7217, 47.6478, 47.7217,\n",
      "         47.7217, 47.7217, 47.7026, 47.7217, 47.7217, 47.7217, 47.7026, 47.6478,\n",
      "         47.7026, 47.7026, 47.7026,  0.1000, 47.7026, 47.6478,  0.1000, 47.6478,\n",
      "         47.7217,  0.1000, 47.7217, 47.7217, 47.7217, 47.7026, 47.7026,  0.1000,\n",
      "         47.7217,  0.1000, 47.6056, 47.6056, 47.7026, 47.7217, 47.7217,  0.1000,\n",
      "          0.1000, 47.6056, 47.7026, 47.7217,  0.1000, 47.7026, 47.7217,  0.1000,\n",
      "         47.6056, 47.7217]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 349 was 98.4%\n",
      "current params: tensor([47.6056, 47.7026, 47.6478, 47.7217], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.1\n",
      "SLow rates:  tensor([[47.7071, 47.8040, 47.7493, 47.8231,  0.1000,  0.1000,  0.1000, 47.7071,\n",
      "         47.7071, 47.7071,  0.1000,  0.1000, 47.8040, 47.8040, 47.8040,  0.1000,\n",
      "          0.1000, 47.8040, 47.8040,  0.1000, 47.7493, 47.7493, 47.7493,  0.1000,\n",
      "          0.1000, 47.7493, 47.7493,  0.1000, 47.7493,  0.1000, 47.7493, 47.8231,\n",
      "         47.8231, 47.8231,  0.1000,  0.1000, 47.8231, 47.8231,  0.1000, 47.8231,\n",
      "          0.1000, 47.8231, 47.8040, 47.8231, 47.8231, 47.8231, 47.7493, 47.8231,\n",
      "         47.8231, 47.8231, 47.8040, 47.8231, 47.8231, 47.8231, 47.8040, 47.7493,\n",
      "         47.8040, 47.8040, 47.8040,  0.1000, 47.8040, 47.7493,  0.1000, 47.7493,\n",
      "         47.8231,  0.1000, 47.8231, 47.8231, 47.8231, 47.8040, 47.8040,  0.1000,\n",
      "         47.8231,  0.1000, 47.7071, 47.7071, 47.8040, 47.8231, 47.8231,  0.1000,\n",
      "          0.1000, 47.7071, 47.8040, 47.8231,  0.1000, 47.8040, 47.8231,  0.1000,\n",
      "         47.7071, 47.8231]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 350 was 98.4%\n",
      "current params: tensor([47.7071, 47.8040, 47.7493, 47.8231], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.2\n",
      "SLow rates:  tensor([[47.8085, 47.9055, 47.8507, 47.9245,  0.1000,  0.1000,  0.1000, 47.8085,\n",
      "         47.8085, 47.8085,  0.1000,  0.1000, 47.9055, 47.9055, 47.9055,  0.1000,\n",
      "          0.1000, 47.9055, 47.9055,  0.1000, 47.8507, 47.8507, 47.8507,  0.1000,\n",
      "          0.1000, 47.8507, 47.8507,  0.1000, 47.8507,  0.1000, 47.8507, 47.9245,\n",
      "         47.9245, 47.9245,  0.1000,  0.1000, 47.9245, 47.9245,  0.1000, 47.9245,\n",
      "          0.1000, 47.9245, 47.9055, 47.9245, 47.9245, 47.9245, 47.8507, 47.9245,\n",
      "         47.9245, 47.9245, 47.9055, 47.9245, 47.9245, 47.9245, 47.9055, 47.8507,\n",
      "         47.9055, 47.9055, 47.9055,  0.1000, 47.9055, 47.8507,  0.1000, 47.8507,\n",
      "         47.9245,  0.1000, 47.9245, 47.9245, 47.9245, 47.9055, 47.9055,  0.1000,\n",
      "         47.9245,  0.1000, 47.8085, 47.8085, 47.9055, 47.9245, 47.9245,  0.1000,\n",
      "          0.1000, 47.8085, 47.9055, 47.9245,  0.1000, 47.9055, 47.9245,  0.1000,\n",
      "         47.8085, 47.9245]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 351 was 98.4%\n",
      "current params: tensor([47.8085, 47.9055, 47.8507, 47.9245], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.2\n",
      "SLow rates:  tensor([[47.9100, 48.0069, 47.9521, 48.0259,  0.1000,  0.1000,  0.1000, 47.9100,\n",
      "         47.9100, 47.9100,  0.1000,  0.1000, 48.0069, 48.0069, 48.0069,  0.1000,\n",
      "          0.1000, 48.0069, 48.0069,  0.1000, 47.9521, 47.9521, 47.9521,  0.1000,\n",
      "          0.1000, 47.9521, 47.9521,  0.1000, 47.9521,  0.1000, 47.9521, 48.0259,\n",
      "         48.0259, 48.0259,  0.1000,  0.1000, 48.0259, 48.0259,  0.1000, 48.0259,\n",
      "          0.1000, 48.0259, 48.0069, 48.0259, 48.0259, 48.0259, 47.9521, 48.0259,\n",
      "         48.0259, 48.0259, 48.0069, 48.0259, 48.0259, 48.0259, 48.0069, 47.9521,\n",
      "         48.0069, 48.0069, 48.0069,  0.1000, 48.0069, 47.9521,  0.1000, 47.9521,\n",
      "         48.0259,  0.1000, 48.0259, 48.0259, 48.0259, 48.0069, 48.0069,  0.1000,\n",
      "         48.0259,  0.1000, 47.9100, 47.9100, 48.0069, 48.0259, 48.0259,  0.1000,\n",
      "          0.1000, 47.9100, 48.0069, 48.0259,  0.1000, 48.0069, 48.0259,  0.1000,\n",
      "         47.9100, 48.0259]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 352 was 98.4%\n",
      "current params: tensor([47.9100, 48.0069, 47.9521, 48.0259], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.2\n",
      "SLow rates:  tensor([[48.0114, 48.1083, 48.0536, 48.1273,  0.1000,  0.1000,  0.1000, 48.0114,\n",
      "         48.0114, 48.0114,  0.1000,  0.1000, 48.1083, 48.1083, 48.1083,  0.1000,\n",
      "          0.1000, 48.1083, 48.1083,  0.1000, 48.0536, 48.0536, 48.0536,  0.1000,\n",
      "          0.1000, 48.0536, 48.0536,  0.1000, 48.0536,  0.1000, 48.0536, 48.1273,\n",
      "         48.1273, 48.1273,  0.1000,  0.1000, 48.1273, 48.1273,  0.1000, 48.1273,\n",
      "          0.1000, 48.1273, 48.1083, 48.1273, 48.1273, 48.1273, 48.0536, 48.1273,\n",
      "         48.1273, 48.1273, 48.1083, 48.1273, 48.1273, 48.1273, 48.1083, 48.0536,\n",
      "         48.1083, 48.1083, 48.1083,  0.1000, 48.1083, 48.0536,  0.1000, 48.0536,\n",
      "         48.1273,  0.1000, 48.1273, 48.1273, 48.1273, 48.1083, 48.1083,  0.1000,\n",
      "         48.1273,  0.1000, 48.0114, 48.0114, 48.1083, 48.1273, 48.1273,  0.1000,\n",
      "          0.1000, 48.0114, 48.1083, 48.1273,  0.1000, 48.1083, 48.1273,  0.1000,\n",
      "         48.0114, 48.1273]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1571, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 353 was 98.4%\n",
      "current params: tensor([48.0114, 48.1083, 48.0536, 48.1273], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.2\n",
      "SLow rates:  tensor([[48.1128, 48.2097, 48.1550, 48.2287,  0.1000,  0.1000,  0.1000, 48.1128,\n",
      "         48.1128, 48.1128,  0.1000,  0.1000, 48.2097, 48.2097, 48.2097,  0.1000,\n",
      "          0.1000, 48.2097, 48.2097,  0.1000, 48.1550, 48.1550, 48.1550,  0.1000,\n",
      "          0.1000, 48.1550, 48.1550,  0.1000, 48.1550,  0.1000, 48.1550, 48.2287,\n",
      "         48.2287, 48.2287,  0.1000,  0.1000, 48.2287, 48.2287,  0.1000, 48.2287,\n",
      "          0.1000, 48.2287, 48.2097, 48.2287, 48.2287, 48.2287, 48.1550, 48.2287,\n",
      "         48.2287, 48.2287, 48.2097, 48.2287, 48.2287, 48.2287, 48.2097, 48.1550,\n",
      "         48.2097, 48.2097, 48.2097,  0.1000, 48.2097, 48.1550,  0.1000, 48.1550,\n",
      "         48.2287,  0.1000, 48.2287, 48.2287, 48.2287, 48.2097, 48.2097,  0.1000,\n",
      "         48.2287,  0.1000, 48.1128, 48.1128, 48.2097, 48.2287, 48.2287,  0.1000,\n",
      "          0.1000, 48.1128, 48.2097, 48.2287,  0.1000, 48.2097, 48.2287,  0.1000,\n",
      "         48.1128, 48.2287]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1566, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 354 was 98.4%\n",
      "current params: tensor([48.1128, 48.2097, 48.1550, 48.2287], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.2\n",
      "SLow rates:  tensor([[48.2142, 48.3111, 48.2564, 48.3301,  0.1000,  0.1000,  0.1000, 48.2142,\n",
      "         48.2142, 48.2142,  0.1000,  0.1000, 48.3111, 48.3111, 48.3111,  0.1000,\n",
      "          0.1000, 48.3111, 48.3111,  0.1000, 48.2564, 48.2564, 48.2564,  0.1000,\n",
      "          0.1000, 48.2564, 48.2564,  0.1000, 48.2564,  0.1000, 48.2564, 48.3301,\n",
      "         48.3301, 48.3301,  0.1000,  0.1000, 48.3301, 48.3301,  0.1000, 48.3301,\n",
      "          0.1000, 48.3301, 48.3111, 48.3301, 48.3301, 48.3301, 48.2564, 48.3301,\n",
      "         48.3301, 48.3301, 48.3111, 48.3301, 48.3301, 48.3301, 48.3111, 48.2564,\n",
      "         48.3111, 48.3111, 48.3111,  0.1000, 48.3111, 48.2564,  0.1000, 48.2564,\n",
      "         48.3301,  0.1000, 48.3301, 48.3301, 48.3301, 48.3111, 48.3111,  0.1000,\n",
      "         48.3301,  0.1000, 48.2142, 48.2142, 48.3111, 48.3301, 48.3301,  0.1000,\n",
      "          0.1000, 48.2142, 48.3111, 48.3301,  0.1000, 48.3111, 48.3301,  0.1000,\n",
      "         48.2142, 48.3301]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 355 was 98.4%\n",
      "current params: tensor([48.2142, 48.3111, 48.2564, 48.3301], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.3\n",
      "SLow rates:  tensor([[48.3156, 48.4124, 48.3577, 48.4314,  0.1000,  0.1000,  0.1000, 48.3156,\n",
      "         48.3156, 48.3156,  0.1000,  0.1000, 48.4124, 48.4124, 48.4124,  0.1000,\n",
      "          0.1000, 48.4124, 48.4124,  0.1000, 48.3577, 48.3577, 48.3577,  0.1000,\n",
      "          0.1000, 48.3577, 48.3577,  0.1000, 48.3577,  0.1000, 48.3577, 48.4314,\n",
      "         48.4314, 48.4314,  0.1000,  0.1000, 48.4314, 48.4314,  0.1000, 48.4314,\n",
      "          0.1000, 48.4314, 48.4124, 48.4314, 48.4314, 48.4314, 48.3577, 48.4314,\n",
      "         48.4314, 48.4314, 48.4124, 48.4314, 48.4314, 48.4314, 48.4124, 48.3577,\n",
      "         48.4124, 48.4124, 48.4124,  0.1000, 48.4124, 48.3577,  0.1000, 48.3577,\n",
      "         48.4314,  0.1000, 48.4314, 48.4314, 48.4314, 48.4124, 48.4124,  0.1000,\n",
      "         48.4314,  0.1000, 48.3156, 48.3156, 48.4124, 48.4314, 48.4314,  0.1000,\n",
      "          0.1000, 48.3156, 48.4124, 48.4314,  0.1000, 48.4124, 48.4314,  0.1000,\n",
      "         48.3156, 48.4314]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 356 was 98.4%\n",
      "current params: tensor([48.3156, 48.4124, 48.3577, 48.4314], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.3\n",
      "SLow rates:  tensor([[48.4170, 48.5138, 48.4591, 48.5328,  0.1000,  0.1000,  0.1000, 48.4170,\n",
      "         48.4170, 48.4170,  0.1000,  0.1000, 48.5138, 48.5138, 48.5138,  0.1000,\n",
      "          0.1000, 48.5138, 48.5138,  0.1000, 48.4591, 48.4591, 48.4591,  0.1000,\n",
      "          0.1000, 48.4591, 48.4591,  0.1000, 48.4591,  0.1000, 48.4591, 48.5328,\n",
      "         48.5328, 48.5328,  0.1000,  0.1000, 48.5328, 48.5328,  0.1000, 48.5328,\n",
      "          0.1000, 48.5328, 48.5138, 48.5328, 48.5328, 48.5328, 48.4591, 48.5328,\n",
      "         48.5328, 48.5328, 48.5138, 48.5328, 48.5328, 48.5328, 48.5138, 48.4591,\n",
      "         48.5138, 48.5138, 48.5138,  0.1000, 48.5138, 48.4591,  0.1000, 48.4591,\n",
      "         48.5328,  0.1000, 48.5328, 48.5328, 48.5328, 48.5138, 48.5138,  0.1000,\n",
      "         48.5328,  0.1000, 48.4170, 48.4170, 48.5138, 48.5328, 48.5328,  0.1000,\n",
      "          0.1000, 48.4170, 48.5138, 48.5328,  0.1000, 48.5138, 48.5328,  0.1000,\n",
      "         48.4170, 48.5328]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 357 was 98.4%\n",
      "current params: tensor([48.4170, 48.5138, 48.4591, 48.5328], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.3\n",
      "SLow rates:  tensor([[48.5183, 48.6151, 48.5604, 48.6341,  0.1000,  0.1000,  0.1000, 48.5183,\n",
      "         48.5183, 48.5183,  0.1000,  0.1000, 48.6151, 48.6151, 48.6151,  0.1000,\n",
      "          0.1000, 48.6151, 48.6151,  0.1000, 48.5604, 48.5604, 48.5604,  0.1000,\n",
      "          0.1000, 48.5604, 48.5604,  0.1000, 48.5604,  0.1000, 48.5604, 48.6341,\n",
      "         48.6341, 48.6341,  0.1000,  0.1000, 48.6341, 48.6341,  0.1000, 48.6341,\n",
      "          0.1000, 48.6341, 48.6151, 48.6341, 48.6341, 48.6341, 48.5604, 48.6341,\n",
      "         48.6341, 48.6341, 48.6151, 48.6341, 48.6341, 48.6341, 48.6151, 48.5604,\n",
      "         48.6151, 48.6151, 48.6151,  0.1000, 48.6151, 48.5604,  0.1000, 48.5604,\n",
      "         48.6341,  0.1000, 48.6341, 48.6341, 48.6341, 48.6151, 48.6151,  0.1000,\n",
      "         48.6341,  0.1000, 48.5183, 48.5183, 48.6151, 48.6341, 48.6341,  0.1000,\n",
      "          0.1000, 48.5183, 48.6151, 48.6341,  0.1000, 48.6151, 48.6341,  0.1000,\n",
      "         48.5183, 48.6341]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 358 was 98.4%\n",
      "current params: tensor([48.5183, 48.6151, 48.5604, 48.6341], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.3\n",
      "SLow rates:  tensor([[48.6197, 48.7164, 48.6618, 48.7354,  0.1000,  0.1000,  0.1000, 48.6197,\n",
      "         48.6197, 48.6197,  0.1000,  0.1000, 48.7164, 48.7164, 48.7164,  0.1000,\n",
      "          0.1000, 48.7164, 48.7164,  0.1000, 48.6618, 48.6618, 48.6618,  0.1000,\n",
      "          0.1000, 48.6618, 48.6618,  0.1000, 48.6618,  0.1000, 48.6618, 48.7354,\n",
      "         48.7354, 48.7354,  0.1000,  0.1000, 48.7354, 48.7354,  0.1000, 48.7354,\n",
      "          0.1000, 48.7354, 48.7164, 48.7354, 48.7354, 48.7354, 48.6618, 48.7354,\n",
      "         48.7354, 48.7354, 48.7164, 48.7354, 48.7354, 48.7354, 48.7164, 48.6618,\n",
      "         48.7164, 48.7164, 48.7164,  0.1000, 48.7164, 48.6618,  0.1000, 48.6618,\n",
      "         48.7354,  0.1000, 48.7354, 48.7354, 48.7354, 48.7164, 48.7164,  0.1000,\n",
      "         48.7354,  0.1000, 48.6197, 48.6197, 48.7164, 48.7354, 48.7354,  0.1000,\n",
      "          0.1000, 48.6197, 48.7164, 48.7354,  0.1000, 48.7164, 48.7354,  0.1000,\n",
      "         48.6197, 48.7354]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 359 was 98.4%\n",
      "current params: tensor([48.6197, 48.7164, 48.6618, 48.7354], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.3\n",
      "SLow rates:  tensor([[48.7210, 48.8177, 48.7631, 48.8367,  0.1000,  0.1000,  0.1000, 48.7210,\n",
      "         48.7210, 48.7210,  0.1000,  0.1000, 48.8177, 48.8177, 48.8177,  0.1000,\n",
      "          0.1000, 48.8177, 48.8177,  0.1000, 48.7631, 48.7631, 48.7631,  0.1000,\n",
      "          0.1000, 48.7631, 48.7631,  0.1000, 48.7631,  0.1000, 48.7631, 48.8367,\n",
      "         48.8367, 48.8367,  0.1000,  0.1000, 48.8367, 48.8367,  0.1000, 48.8367,\n",
      "          0.1000, 48.8367, 48.8177, 48.8367, 48.8367, 48.8367, 48.7631, 48.8367,\n",
      "         48.8367, 48.8367, 48.8177, 48.8367, 48.8367, 48.8367, 48.8177, 48.7631,\n",
      "         48.8177, 48.8177, 48.8177,  0.1000, 48.8177, 48.7631,  0.1000, 48.7631,\n",
      "         48.8367,  0.1000, 48.8367, 48.8367, 48.8367, 48.8177, 48.8177,  0.1000,\n",
      "         48.8367,  0.1000, 48.7210, 48.7210, 48.8177, 48.8367, 48.8367,  0.1000,\n",
      "          0.1000, 48.7210, 48.8177, 48.8367,  0.1000, 48.8177, 48.8367,  0.1000,\n",
      "         48.7210, 48.8367]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 360 was 98.4%\n",
      "current params: tensor([48.7210, 48.8177, 48.7631, 48.8367], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.4\n",
      "SLow rates:  tensor([[48.8223, 48.9190, 48.8644, 48.9380,  0.1000,  0.1000,  0.1000, 48.8223,\n",
      "         48.8223, 48.8223,  0.1000,  0.1000, 48.9190, 48.9190, 48.9190,  0.1000,\n",
      "          0.1000, 48.9190, 48.9190,  0.1000, 48.8644, 48.8644, 48.8644,  0.1000,\n",
      "          0.1000, 48.8644, 48.8644,  0.1000, 48.8644,  0.1000, 48.8644, 48.9380,\n",
      "         48.9380, 48.9380,  0.1000,  0.1000, 48.9380, 48.9380,  0.1000, 48.9380,\n",
      "          0.1000, 48.9380, 48.9190, 48.9380, 48.9380, 48.9380, 48.8644, 48.9380,\n",
      "         48.9380, 48.9380, 48.9190, 48.9380, 48.9380, 48.9380, 48.9190, 48.8644,\n",
      "         48.9190, 48.9190, 48.9190,  0.1000, 48.9190, 48.8644,  0.1000, 48.8644,\n",
      "         48.9380,  0.1000, 48.9380, 48.9380, 48.9380, 48.9190, 48.9190,  0.1000,\n",
      "         48.9380,  0.1000, 48.8223, 48.8223, 48.9190, 48.9380, 48.9380,  0.1000,\n",
      "          0.1000, 48.8223, 48.9190, 48.9380,  0.1000, 48.9190, 48.9380,  0.1000,\n",
      "         48.8223, 48.9380]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 361 was 98.4%\n",
      "current params: tensor([48.8223, 48.9190, 48.8644, 48.9380], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.4\n",
      "SLow rates:  tensor([[48.9236, 49.0203, 48.9657, 49.0392,  0.1000,  0.1000,  0.1000, 48.9236,\n",
      "         48.9236, 48.9236,  0.1000,  0.1000, 49.0203, 49.0203, 49.0203,  0.1000,\n",
      "          0.1000, 49.0203, 49.0203,  0.1000, 48.9657, 48.9657, 48.9657,  0.1000,\n",
      "          0.1000, 48.9657, 48.9657,  0.1000, 48.9657,  0.1000, 48.9657, 49.0392,\n",
      "         49.0392, 49.0392,  0.1000,  0.1000, 49.0392, 49.0392,  0.1000, 49.0392,\n",
      "          0.1000, 49.0392, 49.0203, 49.0392, 49.0392, 49.0392, 48.9657, 49.0392,\n",
      "         49.0392, 49.0392, 49.0203, 49.0392, 49.0392, 49.0392, 49.0203, 48.9657,\n",
      "         49.0203, 49.0203, 49.0203,  0.1000, 49.0203, 48.9657,  0.1000, 48.9657,\n",
      "         49.0392,  0.1000, 49.0392, 49.0392, 49.0392, 49.0203, 49.0203,  0.1000,\n",
      "         49.0392,  0.1000, 48.9236, 48.9236, 49.0203, 49.0392, 49.0392,  0.1000,\n",
      "          0.1000, 48.9236, 49.0203, 49.0392,  0.1000, 49.0203, 49.0392,  0.1000,\n",
      "         48.9236, 49.0392]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 362 was 98.4%\n",
      "current params: tensor([48.9236, 49.0203, 48.9657, 49.0392], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.4\n",
      "SLow rates:  tensor([[49.0249, 49.1216, 49.0670, 49.1405,  0.1000,  0.1000,  0.1000, 49.0249,\n",
      "         49.0249, 49.0249,  0.1000,  0.1000, 49.1216, 49.1216, 49.1216,  0.1000,\n",
      "          0.1000, 49.1216, 49.1216,  0.1000, 49.0670, 49.0670, 49.0670,  0.1000,\n",
      "          0.1000, 49.0670, 49.0670,  0.1000, 49.0670,  0.1000, 49.0670, 49.1405,\n",
      "         49.1405, 49.1405,  0.1000,  0.1000, 49.1405, 49.1405,  0.1000, 49.1405,\n",
      "          0.1000, 49.1405, 49.1216, 49.1405, 49.1405, 49.1405, 49.0670, 49.1405,\n",
      "         49.1405, 49.1405, 49.1216, 49.1405, 49.1405, 49.1405, 49.1216, 49.0670,\n",
      "         49.1216, 49.1216, 49.1216,  0.1000, 49.1216, 49.0670,  0.1000, 49.0670,\n",
      "         49.1405,  0.1000, 49.1405, 49.1405, 49.1405, 49.1216, 49.1216,  0.1000,\n",
      "         49.1405,  0.1000, 49.0249, 49.0249, 49.1216, 49.1405, 49.1405,  0.1000,\n",
      "          0.1000, 49.0249, 49.1216, 49.1405,  0.1000, 49.1216, 49.1405,  0.1000,\n",
      "         49.0249, 49.1405]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 363 was 98.4%\n",
      "current params: tensor([49.0249, 49.1216, 49.0670, 49.1405], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.4\n",
      "SLow rates:  tensor([[49.1262, 49.2229, 49.1682, 49.2417,  0.1000,  0.1000,  0.1000, 49.1262,\n",
      "         49.1262, 49.1262,  0.1000,  0.1000, 49.2229, 49.2229, 49.2229,  0.1000,\n",
      "          0.1000, 49.2229, 49.2229,  0.1000, 49.1682, 49.1682, 49.1682,  0.1000,\n",
      "          0.1000, 49.1682, 49.1682,  0.1000, 49.1682,  0.1000, 49.1682, 49.2417,\n",
      "         49.2417, 49.2417,  0.1000,  0.1000, 49.2417, 49.2417,  0.1000, 49.2417,\n",
      "          0.1000, 49.2417, 49.2229, 49.2417, 49.2417, 49.2417, 49.1682, 49.2417,\n",
      "         49.2417, 49.2417, 49.2229, 49.2417, 49.2417, 49.2417, 49.2229, 49.1682,\n",
      "         49.2229, 49.2229, 49.2229,  0.1000, 49.2229, 49.1682,  0.1000, 49.1682,\n",
      "         49.2417,  0.1000, 49.2417, 49.2417, 49.2417, 49.2229, 49.2229,  0.1000,\n",
      "         49.2417,  0.1000, 49.1262, 49.1262, 49.2229, 49.2417, 49.2417,  0.1000,\n",
      "          0.1000, 49.1262, 49.2229, 49.2417,  0.1000, 49.2229, 49.2417,  0.1000,\n",
      "         49.1262, 49.2417]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 364 was 98.4%\n",
      "current params: tensor([49.1262, 49.2229, 49.1682, 49.2417], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.4\n",
      "SLow rates:  tensor([[49.2275, 49.3241, 49.2695, 49.3430,  0.1000,  0.1000,  0.1000, 49.2275,\n",
      "         49.2275, 49.2275,  0.1000,  0.1000, 49.3241, 49.3241, 49.3241,  0.1000,\n",
      "          0.1000, 49.3241, 49.3241,  0.1000, 49.2695, 49.2695, 49.2695,  0.1000,\n",
      "          0.1000, 49.2695, 49.2695,  0.1000, 49.2695,  0.1000, 49.2695, 49.3430,\n",
      "         49.3430, 49.3430,  0.1000,  0.1000, 49.3430, 49.3430,  0.1000, 49.3430,\n",
      "          0.1000, 49.3430, 49.3241, 49.3430, 49.3430, 49.3430, 49.2695, 49.3430,\n",
      "         49.3430, 49.3430, 49.3241, 49.3430, 49.3430, 49.3430, 49.3241, 49.2695,\n",
      "         49.3241, 49.3241, 49.3241,  0.1000, 49.3241, 49.2695,  0.1000, 49.2695,\n",
      "         49.3430,  0.1000, 49.3430, 49.3430, 49.3430, 49.3241, 49.3241,  0.1000,\n",
      "         49.3430,  0.1000, 49.2275, 49.2275, 49.3241, 49.3430, 49.3430,  0.1000,\n",
      "          0.1000, 49.2275, 49.3241, 49.3430,  0.1000, 49.3241, 49.3430,  0.1000,\n",
      "         49.2275, 49.3430]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 365 was 98.4%\n",
      "current params: tensor([49.2275, 49.3241, 49.2695, 49.3430], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.5\n",
      "SLow rates:  tensor([[49.3287, 49.4253, 49.3707, 49.4442,  0.1000,  0.1000,  0.1000, 49.3287,\n",
      "         49.3287, 49.3287,  0.1000,  0.1000, 49.4253, 49.4253, 49.4253,  0.1000,\n",
      "          0.1000, 49.4253, 49.4253,  0.1000, 49.3707, 49.3707, 49.3707,  0.1000,\n",
      "          0.1000, 49.3707, 49.3707,  0.1000, 49.3707,  0.1000, 49.3707, 49.4442,\n",
      "         49.4442, 49.4442,  0.1000,  0.1000, 49.4442, 49.4442,  0.1000, 49.4442,\n",
      "          0.1000, 49.4442, 49.4253, 49.4442, 49.4442, 49.4442, 49.3707, 49.4442,\n",
      "         49.4442, 49.4442, 49.4253, 49.4442, 49.4442, 49.4442, 49.4253, 49.3707,\n",
      "         49.4253, 49.4253, 49.4253,  0.1000, 49.4253, 49.3707,  0.1000, 49.3707,\n",
      "         49.4442,  0.1000, 49.4442, 49.4442, 49.4442, 49.4253, 49.4253,  0.1000,\n",
      "         49.4442,  0.1000, 49.3287, 49.3287, 49.4253, 49.4442, 49.4442,  0.1000,\n",
      "          0.1000, 49.3287, 49.4253, 49.4442,  0.1000, 49.4253, 49.4442,  0.1000,\n",
      "         49.3287, 49.4442]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 366 was 98.4%\n",
      "current params: tensor([49.3287, 49.4253, 49.3707, 49.4442], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.5\n",
      "SLow rates:  tensor([[49.4300, 49.5266, 49.4719, 49.5454,  0.1000,  0.1000,  0.1000, 49.4300,\n",
      "         49.4300, 49.4300,  0.1000,  0.1000, 49.5266, 49.5266, 49.5266,  0.1000,\n",
      "          0.1000, 49.5266, 49.5266,  0.1000, 49.4719, 49.4719, 49.4719,  0.1000,\n",
      "          0.1000, 49.4719, 49.4719,  0.1000, 49.4719,  0.1000, 49.4719, 49.5454,\n",
      "         49.5454, 49.5454,  0.1000,  0.1000, 49.5454, 49.5454,  0.1000, 49.5454,\n",
      "          0.1000, 49.5454, 49.5266, 49.5454, 49.5454, 49.5454, 49.4719, 49.5454,\n",
      "         49.5454, 49.5454, 49.5266, 49.5454, 49.5454, 49.5454, 49.5266, 49.4719,\n",
      "         49.5266, 49.5266, 49.5266,  0.1000, 49.5266, 49.4719,  0.1000, 49.4719,\n",
      "         49.5454,  0.1000, 49.5454, 49.5454, 49.5454, 49.5266, 49.5266,  0.1000,\n",
      "         49.5454,  0.1000, 49.4300, 49.4300, 49.5266, 49.5454, 49.5454,  0.1000,\n",
      "          0.1000, 49.4300, 49.5266, 49.5454,  0.1000, 49.5266, 49.5454,  0.1000,\n",
      "         49.4300, 49.5454]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 367 was 98.5%\n",
      "current params: tensor([49.4300, 49.5266, 49.4719, 49.5454], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.5\n",
      "SLow rates:  tensor([[49.5312, 49.6278, 49.5732, 49.6466,  0.1000,  0.1000,  0.1000, 49.5312,\n",
      "         49.5312, 49.5312,  0.1000,  0.1000, 49.6278, 49.6278, 49.6278,  0.1000,\n",
      "          0.1000, 49.6278, 49.6278,  0.1000, 49.5732, 49.5732, 49.5732,  0.1000,\n",
      "          0.1000, 49.5732, 49.5732,  0.1000, 49.5732,  0.1000, 49.5732, 49.6466,\n",
      "         49.6466, 49.6466,  0.1000,  0.1000, 49.6466, 49.6466,  0.1000, 49.6466,\n",
      "          0.1000, 49.6466, 49.6278, 49.6466, 49.6466, 49.6466, 49.5732, 49.6466,\n",
      "         49.6466, 49.6466, 49.6278, 49.6466, 49.6466, 49.6466, 49.6278, 49.5732,\n",
      "         49.6278, 49.6278, 49.6278,  0.1000, 49.6278, 49.5732,  0.1000, 49.5732,\n",
      "         49.6466,  0.1000, 49.6466, 49.6466, 49.6466, 49.6278, 49.6278,  0.1000,\n",
      "         49.6466,  0.1000, 49.5312, 49.5312, 49.6278, 49.6466, 49.6466,  0.1000,\n",
      "          0.1000, 49.5312, 49.6278, 49.6466,  0.1000, 49.6278, 49.6466,  0.1000,\n",
      "         49.5312, 49.6466]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 368 was 98.5%\n",
      "current params: tensor([49.5312, 49.6278, 49.5732, 49.6466], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.5\n",
      "SLow rates:  tensor([[49.6324, 49.7290, 49.6744, 49.7478,  0.1000,  0.1000,  0.1000, 49.6324,\n",
      "         49.6324, 49.6324,  0.1000,  0.1000, 49.7290, 49.7290, 49.7290,  0.1000,\n",
      "          0.1000, 49.7290, 49.7290,  0.1000, 49.6744, 49.6744, 49.6744,  0.1000,\n",
      "          0.1000, 49.6744, 49.6744,  0.1000, 49.6744,  0.1000, 49.6744, 49.7478,\n",
      "         49.7478, 49.7478,  0.1000,  0.1000, 49.7478, 49.7478,  0.1000, 49.7478,\n",
      "          0.1000, 49.7478, 49.7290, 49.7478, 49.7478, 49.7478, 49.6744, 49.7478,\n",
      "         49.7478, 49.7478, 49.7290, 49.7478, 49.7478, 49.7478, 49.7290, 49.6744,\n",
      "         49.7290, 49.7290, 49.7290,  0.1000, 49.7290, 49.6744,  0.1000, 49.6744,\n",
      "         49.7478,  0.1000, 49.7478, 49.7478, 49.7478, 49.7290, 49.7290,  0.1000,\n",
      "         49.7478,  0.1000, 49.6324, 49.6324, 49.7290, 49.7478, 49.7478,  0.1000,\n",
      "          0.1000, 49.6324, 49.7290, 49.7478,  0.1000, 49.7290, 49.7478,  0.1000,\n",
      "         49.6324, 49.7478]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 369 was 98.5%\n",
      "current params: tensor([49.6324, 49.7290, 49.6744, 49.7478], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.5\n",
      "SLow rates:  tensor([[49.7336, 49.8301, 49.7756, 49.8489,  0.1000,  0.1000,  0.1000, 49.7336,\n",
      "         49.7336, 49.7336,  0.1000,  0.1000, 49.8301, 49.8301, 49.8301,  0.1000,\n",
      "          0.1000, 49.8301, 49.8301,  0.1000, 49.7756, 49.7756, 49.7756,  0.1000,\n",
      "          0.1000, 49.7756, 49.7756,  0.1000, 49.7756,  0.1000, 49.7756, 49.8489,\n",
      "         49.8489, 49.8489,  0.1000,  0.1000, 49.8489, 49.8489,  0.1000, 49.8489,\n",
      "          0.1000, 49.8489, 49.8301, 49.8489, 49.8489, 49.8489, 49.7756, 49.8489,\n",
      "         49.8489, 49.8489, 49.8301, 49.8489, 49.8489, 49.8489, 49.8301, 49.7756,\n",
      "         49.8301, 49.8301, 49.8301,  0.1000, 49.8301, 49.7756,  0.1000, 49.7756,\n",
      "         49.8489,  0.1000, 49.8489, 49.8489, 49.8489, 49.8301, 49.8301,  0.1000,\n",
      "         49.8489,  0.1000, 49.7336, 49.7336, 49.8301, 49.8489, 49.8489,  0.1000,\n",
      "          0.1000, 49.7336, 49.8301, 49.8489,  0.1000, 49.8301, 49.8489,  0.1000,\n",
      "         49.7336, 49.8489]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 370 was 98.5%\n",
      "current params: tensor([49.7336, 49.8301, 49.7756, 49.8489], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.6\n",
      "SLow rates:  tensor([[49.8348, 49.9313, 49.8767, 49.9501,  0.1000,  0.1000,  0.1000, 49.8348,\n",
      "         49.8348, 49.8348,  0.1000,  0.1000, 49.9313, 49.9313, 49.9313,  0.1000,\n",
      "          0.1000, 49.9313, 49.9313,  0.1000, 49.8767, 49.8767, 49.8767,  0.1000,\n",
      "          0.1000, 49.8767, 49.8767,  0.1000, 49.8767,  0.1000, 49.8767, 49.9501,\n",
      "         49.9501, 49.9501,  0.1000,  0.1000, 49.9501, 49.9501,  0.1000, 49.9501,\n",
      "          0.1000, 49.9501, 49.9313, 49.9501, 49.9501, 49.9501, 49.8767, 49.9501,\n",
      "         49.9501, 49.9501, 49.9313, 49.9501, 49.9501, 49.9501, 49.9313, 49.8767,\n",
      "         49.9313, 49.9313, 49.9313,  0.1000, 49.9313, 49.8767,  0.1000, 49.8767,\n",
      "         49.9501,  0.1000, 49.9501, 49.9501, 49.9501, 49.9313, 49.9313,  0.1000,\n",
      "         49.9501,  0.1000, 49.8348, 49.8348, 49.9313, 49.9501, 49.9501,  0.1000,\n",
      "          0.1000, 49.8348, 49.9313, 49.9501,  0.1000, 49.9313, 49.9501,  0.1000,\n",
      "         49.8348, 49.9501]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 371 was 98.5%\n",
      "current params: tensor([49.8348, 49.9313, 49.8767, 49.9501], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.6\n",
      "SLow rates:  tensor([[49.9360, 50.0325, 49.9779, 50.0512,  0.1000,  0.1000,  0.1000, 49.9360,\n",
      "         49.9360, 49.9360,  0.1000,  0.1000, 50.0325, 50.0325, 50.0325,  0.1000,\n",
      "          0.1000, 50.0325, 50.0325,  0.1000, 49.9779, 49.9779, 49.9779,  0.1000,\n",
      "          0.1000, 49.9779, 49.9779,  0.1000, 49.9779,  0.1000, 49.9779, 50.0512,\n",
      "         50.0512, 50.0512,  0.1000,  0.1000, 50.0512, 50.0512,  0.1000, 50.0512,\n",
      "          0.1000, 50.0512, 50.0325, 50.0512, 50.0512, 50.0512, 49.9779, 50.0512,\n",
      "         50.0512, 50.0512, 50.0325, 50.0512, 50.0512, 50.0512, 50.0325, 49.9779,\n",
      "         50.0325, 50.0325, 50.0325,  0.1000, 50.0325, 49.9779,  0.1000, 49.9779,\n",
      "         50.0512,  0.1000, 50.0512, 50.0512, 50.0512, 50.0325, 50.0325,  0.1000,\n",
      "         50.0512,  0.1000, 49.9360, 49.9360, 50.0325, 50.0512, 50.0512,  0.1000,\n",
      "          0.1000, 49.9360, 50.0325, 50.0512,  0.1000, 50.0325, 50.0512,  0.1000,\n",
      "         49.9360, 50.0512]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 372 was 98.5%\n",
      "current params: tensor([49.9360, 50.0325, 49.9779, 50.0512], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.6\n",
      "SLow rates:  tensor([[50.0371, 50.1336, 50.0790, 50.1524,  0.1000,  0.1000,  0.1000, 50.0371,\n",
      "         50.0371, 50.0371,  0.1000,  0.1000, 50.1336, 50.1336, 50.1336,  0.1000,\n",
      "          0.1000, 50.1336, 50.1336,  0.1000, 50.0790, 50.0790, 50.0790,  0.1000,\n",
      "          0.1000, 50.0790, 50.0790,  0.1000, 50.0790,  0.1000, 50.0790, 50.1524,\n",
      "         50.1524, 50.1524,  0.1000,  0.1000, 50.1524, 50.1524,  0.1000, 50.1524,\n",
      "          0.1000, 50.1524, 50.1336, 50.1524, 50.1524, 50.1524, 50.0790, 50.1524,\n",
      "         50.1524, 50.1524, 50.1336, 50.1524, 50.1524, 50.1524, 50.1336, 50.0790,\n",
      "         50.1336, 50.1336, 50.1336,  0.1000, 50.1336, 50.0790,  0.1000, 50.0790,\n",
      "         50.1524,  0.1000, 50.1524, 50.1524, 50.1524, 50.1336, 50.1336,  0.1000,\n",
      "         50.1524,  0.1000, 50.0371, 50.0371, 50.1336, 50.1524, 50.1524,  0.1000,\n",
      "          0.1000, 50.0371, 50.1336, 50.1524,  0.1000, 50.1336, 50.1524,  0.1000,\n",
      "         50.0371, 50.1524]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 373 was 98.5%\n",
      "current params: tensor([50.0371, 50.1336, 50.0790, 50.1524], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.6\n",
      "SLow rates:  tensor([[50.1383, 50.2347, 50.1802, 50.2535,  0.1000,  0.1000,  0.1000, 50.1383,\n",
      "         50.1383, 50.1383,  0.1000,  0.1000, 50.2347, 50.2347, 50.2347,  0.1000,\n",
      "          0.1000, 50.2347, 50.2347,  0.1000, 50.1802, 50.1802, 50.1802,  0.1000,\n",
      "          0.1000, 50.1802, 50.1802,  0.1000, 50.1802,  0.1000, 50.1802, 50.2535,\n",
      "         50.2535, 50.2535,  0.1000,  0.1000, 50.2535, 50.2535,  0.1000, 50.2535,\n",
      "          0.1000, 50.2535, 50.2347, 50.2535, 50.2535, 50.2535, 50.1802, 50.2535,\n",
      "         50.2535, 50.2535, 50.2347, 50.2535, 50.2535, 50.2535, 50.2347, 50.1802,\n",
      "         50.2347, 50.2347, 50.2347,  0.1000, 50.2347, 50.1802,  0.1000, 50.1802,\n",
      "         50.2535,  0.1000, 50.2535, 50.2535, 50.2535, 50.2347, 50.2347,  0.1000,\n",
      "         50.2535,  0.1000, 50.1383, 50.1383, 50.2347, 50.2535, 50.2535,  0.1000,\n",
      "          0.1000, 50.1383, 50.2347, 50.2535,  0.1000, 50.2347, 50.2535,  0.1000,\n",
      "         50.1383, 50.2535]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 374 was 98.5%\n",
      "current params: tensor([50.1383, 50.2347, 50.1802, 50.2535], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.6\n",
      "SLow rates:  tensor([[50.2394, 50.3359, 50.2813, 50.3546,  0.1000,  0.1000,  0.1000, 50.2394,\n",
      "         50.2394, 50.2394,  0.1000,  0.1000, 50.3359, 50.3359, 50.3359,  0.1000,\n",
      "          0.1000, 50.3359, 50.3359,  0.1000, 50.2813, 50.2813, 50.2813,  0.1000,\n",
      "          0.1000, 50.2813, 50.2813,  0.1000, 50.2813,  0.1000, 50.2813, 50.3546,\n",
      "         50.3546, 50.3546,  0.1000,  0.1000, 50.3546, 50.3546,  0.1000, 50.3546,\n",
      "          0.1000, 50.3546, 50.3359, 50.3546, 50.3546, 50.3546, 50.2813, 50.3546,\n",
      "         50.3546, 50.3546, 50.3359, 50.3546, 50.3546, 50.3546, 50.3359, 50.2813,\n",
      "         50.3359, 50.3359, 50.3359,  0.1000, 50.3359, 50.2813,  0.1000, 50.2813,\n",
      "         50.3546,  0.1000, 50.3546, 50.3546, 50.3546, 50.3359, 50.3359,  0.1000,\n",
      "         50.3546,  0.1000, 50.2394, 50.2394, 50.3359, 50.3546, 50.3546,  0.1000,\n",
      "          0.1000, 50.2394, 50.3359, 50.3546,  0.1000, 50.3359, 50.3546,  0.1000,\n",
      "         50.2394, 50.3546]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 375 was 98.5%\n",
      "current params: tensor([50.2394, 50.3359, 50.2813, 50.3546], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.6\n",
      "SLow rates:  tensor([[50.3406, 50.4370, 50.3824, 50.4557,  0.1000,  0.1000,  0.1000, 50.3406,\n",
      "         50.3406, 50.3406,  0.1000,  0.1000, 50.4370, 50.4370, 50.4370,  0.1000,\n",
      "          0.1000, 50.4370, 50.4370,  0.1000, 50.3824, 50.3824, 50.3824,  0.1000,\n",
      "          0.1000, 50.3824, 50.3824,  0.1000, 50.3824,  0.1000, 50.3824, 50.4557,\n",
      "         50.4557, 50.4557,  0.1000,  0.1000, 50.4557, 50.4557,  0.1000, 50.4557,\n",
      "          0.1000, 50.4557, 50.4370, 50.4557, 50.4557, 50.4557, 50.3824, 50.4557,\n",
      "         50.4557, 50.4557, 50.4370, 50.4557, 50.4557, 50.4557, 50.4370, 50.3824,\n",
      "         50.4370, 50.4370, 50.4370,  0.1000, 50.4370, 50.3824,  0.1000, 50.3824,\n",
      "         50.4557,  0.1000, 50.4557, 50.4557, 50.4557, 50.4370, 50.4370,  0.1000,\n",
      "         50.4557,  0.1000, 50.3406, 50.3406, 50.4370, 50.4557, 50.4557,  0.1000,\n",
      "          0.1000, 50.3406, 50.4370, 50.4557,  0.1000, 50.4370, 50.4557,  0.1000,\n",
      "         50.3406, 50.4557]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 376 was 98.5%\n",
      "current params: tensor([50.3406, 50.4370, 50.3824, 50.4557], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.7\n",
      "SLow rates:  tensor([[50.4417, 50.5381, 50.4835, 50.5568,  0.1000,  0.1000,  0.1000, 50.4417,\n",
      "         50.4417, 50.4417,  0.1000,  0.1000, 50.5381, 50.5381, 50.5381,  0.1000,\n",
      "          0.1000, 50.5381, 50.5381,  0.1000, 50.4835, 50.4835, 50.4835,  0.1000,\n",
      "          0.1000, 50.4835, 50.4835,  0.1000, 50.4835,  0.1000, 50.4835, 50.5568,\n",
      "         50.5568, 50.5568,  0.1000,  0.1000, 50.5568, 50.5568,  0.1000, 50.5568,\n",
      "          0.1000, 50.5568, 50.5381, 50.5568, 50.5568, 50.5568, 50.4835, 50.5568,\n",
      "         50.5568, 50.5568, 50.5381, 50.5568, 50.5568, 50.5568, 50.5381, 50.4835,\n",
      "         50.5381, 50.5381, 50.5381,  0.1000, 50.5381, 50.4835,  0.1000, 50.4835,\n",
      "         50.5568,  0.1000, 50.5568, 50.5568, 50.5568, 50.5381, 50.5381,  0.1000,\n",
      "         50.5568,  0.1000, 50.4417, 50.4417, 50.5381, 50.5568, 50.5568,  0.1000,\n",
      "          0.1000, 50.4417, 50.5381, 50.5568,  0.1000, 50.5381, 50.5568,  0.1000,\n",
      "         50.4417, 50.5568]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 377 was 98.5%\n",
      "current params: tensor([50.4417, 50.5381, 50.4835, 50.5568], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.7\n",
      "SLow rates:  tensor([[50.5428, 50.6392, 50.5846, 50.6578,  0.1000,  0.1000,  0.1000, 50.5428,\n",
      "         50.5428, 50.5428,  0.1000,  0.1000, 50.6392, 50.6392, 50.6392,  0.1000,\n",
      "          0.1000, 50.6392, 50.6392,  0.1000, 50.5846, 50.5846, 50.5846,  0.1000,\n",
      "          0.1000, 50.5846, 50.5846,  0.1000, 50.5846,  0.1000, 50.5846, 50.6578,\n",
      "         50.6578, 50.6578,  0.1000,  0.1000, 50.6578, 50.6578,  0.1000, 50.6578,\n",
      "          0.1000, 50.6578, 50.6392, 50.6578, 50.6578, 50.6578, 50.5846, 50.6578,\n",
      "         50.6578, 50.6578, 50.6392, 50.6578, 50.6578, 50.6578, 50.6392, 50.5846,\n",
      "         50.6392, 50.6392, 50.6392,  0.1000, 50.6392, 50.5846,  0.1000, 50.5846,\n",
      "         50.6578,  0.1000, 50.6578, 50.6578, 50.6578, 50.6392, 50.6392,  0.1000,\n",
      "         50.6578,  0.1000, 50.5428, 50.5428, 50.6392, 50.6578, 50.6578,  0.1000,\n",
      "          0.1000, 50.5428, 50.6392, 50.6578,  0.1000, 50.6392, 50.6578,  0.1000,\n",
      "         50.5428, 50.6578]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 378 was 98.5%\n",
      "current params: tensor([50.5428, 50.6392, 50.5846, 50.6578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.7\n",
      "SLow rates:  tensor([[50.6439, 50.7402, 50.6857, 50.7589,  0.1000,  0.1000,  0.1000, 50.6439,\n",
      "         50.6439, 50.6439,  0.1000,  0.1000, 50.7402, 50.7402, 50.7402,  0.1000,\n",
      "          0.1000, 50.7402, 50.7402,  0.1000, 50.6857, 50.6857, 50.6857,  0.1000,\n",
      "          0.1000, 50.6857, 50.6857,  0.1000, 50.6857,  0.1000, 50.6857, 50.7589,\n",
      "         50.7589, 50.7589,  0.1000,  0.1000, 50.7589, 50.7589,  0.1000, 50.7589,\n",
      "          0.1000, 50.7589, 50.7402, 50.7589, 50.7589, 50.7589, 50.6857, 50.7589,\n",
      "         50.7589, 50.7589, 50.7402, 50.7589, 50.7589, 50.7589, 50.7402, 50.6857,\n",
      "         50.7402, 50.7402, 50.7402,  0.1000, 50.7402, 50.6857,  0.1000, 50.6857,\n",
      "         50.7589,  0.1000, 50.7589, 50.7589, 50.7589, 50.7402, 50.7402,  0.1000,\n",
      "         50.7589,  0.1000, 50.6439, 50.6439, 50.7402, 50.7589, 50.7589,  0.1000,\n",
      "          0.1000, 50.6439, 50.7402, 50.7589,  0.1000, 50.7402, 50.7589,  0.1000,\n",
      "         50.6439, 50.7589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 379 was 98.5%\n",
      "current params: tensor([50.6439, 50.7402, 50.6857, 50.7589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.7\n",
      "SLow rates:  tensor([[50.7450, 50.8413, 50.7868, 50.8600,  0.1000,  0.1000,  0.1000, 50.7450,\n",
      "         50.7450, 50.7450,  0.1000,  0.1000, 50.8413, 50.8413, 50.8413,  0.1000,\n",
      "          0.1000, 50.8413, 50.8413,  0.1000, 50.7868, 50.7868, 50.7868,  0.1000,\n",
      "          0.1000, 50.7868, 50.7868,  0.1000, 50.7868,  0.1000, 50.7868, 50.8600,\n",
      "         50.8600, 50.8600,  0.1000,  0.1000, 50.8600, 50.8600,  0.1000, 50.8600,\n",
      "          0.1000, 50.8600, 50.8413, 50.8600, 50.8600, 50.8600, 50.7868, 50.8600,\n",
      "         50.8600, 50.8600, 50.8413, 50.8600, 50.8600, 50.8600, 50.8413, 50.7868,\n",
      "         50.8413, 50.8413, 50.8413,  0.1000, 50.8413, 50.7868,  0.1000, 50.7868,\n",
      "         50.8600,  0.1000, 50.8600, 50.8600, 50.8600, 50.8413, 50.8413,  0.1000,\n",
      "         50.8600,  0.1000, 50.7450, 50.7450, 50.8413, 50.8600, 50.8600,  0.1000,\n",
      "          0.1000, 50.7450, 50.8413, 50.8600,  0.1000, 50.8413, 50.8600,  0.1000,\n",
      "         50.7450, 50.8600]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 380 was 98.5%\n",
      "current params: tensor([50.7450, 50.8413, 50.7868, 50.8600], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.7\n",
      "SLow rates:  tensor([[50.8460, 50.9424, 50.8879, 50.9610,  0.1000,  0.1000,  0.1000, 50.8460,\n",
      "         50.8460, 50.8460,  0.1000,  0.1000, 50.9424, 50.9424, 50.9424,  0.1000,\n",
      "          0.1000, 50.9424, 50.9424,  0.1000, 50.8879, 50.8879, 50.8879,  0.1000,\n",
      "          0.1000, 50.8879, 50.8879,  0.1000, 50.8879,  0.1000, 50.8879, 50.9610,\n",
      "         50.9610, 50.9610,  0.1000,  0.1000, 50.9610, 50.9610,  0.1000, 50.9610,\n",
      "          0.1000, 50.9610, 50.9424, 50.9610, 50.9610, 50.9610, 50.8879, 50.9610,\n",
      "         50.9610, 50.9610, 50.9424, 50.9610, 50.9610, 50.9610, 50.9424, 50.8879,\n",
      "         50.9424, 50.9424, 50.9424,  0.1000, 50.9424, 50.8879,  0.1000, 50.8879,\n",
      "         50.9610,  0.1000, 50.9610, 50.9610, 50.9610, 50.9424, 50.9424,  0.1000,\n",
      "         50.9610,  0.1000, 50.8460, 50.8460, 50.9424, 50.9610, 50.9610,  0.1000,\n",
      "          0.1000, 50.8460, 50.9424, 50.9610,  0.1000, 50.9424, 50.9610,  0.1000,\n",
      "         50.8460, 50.9610]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 381 was 98.5%\n",
      "current params: tensor([50.8460, 50.9424, 50.8879, 50.9610], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.8\n",
      "SLow rates:  tensor([[50.9471, 51.0434, 50.9889, 51.0620,  0.1000,  0.1000,  0.1000, 50.9471,\n",
      "         50.9471, 50.9471,  0.1000,  0.1000, 51.0434, 51.0434, 51.0434,  0.1000,\n",
      "          0.1000, 51.0434, 51.0434,  0.1000, 50.9889, 50.9889, 50.9889,  0.1000,\n",
      "          0.1000, 50.9889, 50.9889,  0.1000, 50.9889,  0.1000, 50.9889, 51.0620,\n",
      "         51.0620, 51.0620,  0.1000,  0.1000, 51.0620, 51.0620,  0.1000, 51.0620,\n",
      "          0.1000, 51.0620, 51.0434, 51.0620, 51.0620, 51.0620, 50.9889, 51.0620,\n",
      "         51.0620, 51.0620, 51.0434, 51.0620, 51.0620, 51.0620, 51.0434, 50.9889,\n",
      "         51.0434, 51.0434, 51.0434,  0.1000, 51.0434, 50.9889,  0.1000, 50.9889,\n",
      "         51.0620,  0.1000, 51.0620, 51.0620, 51.0620, 51.0434, 51.0434,  0.1000,\n",
      "         51.0620,  0.1000, 50.9471, 50.9471, 51.0434, 51.0620, 51.0620,  0.1000,\n",
      "          0.1000, 50.9471, 51.0434, 51.0620,  0.1000, 51.0434, 51.0620,  0.1000,\n",
      "         50.9471, 51.0620]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 382 was 98.5%\n",
      "current params: tensor([50.9471, 51.0434, 50.9889, 51.0620], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.8\n",
      "SLow rates:  tensor([[51.0481, 51.1444, 51.0899, 51.1630,  0.1000,  0.1000,  0.1000, 51.0481,\n",
      "         51.0481, 51.0481,  0.1000,  0.1000, 51.1444, 51.1444, 51.1444,  0.1000,\n",
      "          0.1000, 51.1444, 51.1444,  0.1000, 51.0899, 51.0899, 51.0899,  0.1000,\n",
      "          0.1000, 51.0899, 51.0899,  0.1000, 51.0899,  0.1000, 51.0899, 51.1630,\n",
      "         51.1630, 51.1630,  0.1000,  0.1000, 51.1630, 51.1630,  0.1000, 51.1630,\n",
      "          0.1000, 51.1630, 51.1444, 51.1630, 51.1630, 51.1630, 51.0899, 51.1630,\n",
      "         51.1630, 51.1630, 51.1444, 51.1630, 51.1630, 51.1630, 51.1444, 51.0899,\n",
      "         51.1444, 51.1444, 51.1444,  0.1000, 51.1444, 51.0899,  0.1000, 51.0899,\n",
      "         51.1630,  0.1000, 51.1630, 51.1630, 51.1630, 51.1444, 51.1444,  0.1000,\n",
      "         51.1630,  0.1000, 51.0481, 51.0481, 51.1444, 51.1630, 51.1630,  0.1000,\n",
      "          0.1000, 51.0481, 51.1444, 51.1630,  0.1000, 51.1444, 51.1630,  0.1000,\n",
      "         51.0481, 51.1630]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 383 was 98.5%\n",
      "current params: tensor([51.0481, 51.1444, 51.0899, 51.1630], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.8\n",
      "SLow rates:  tensor([[51.1492, 51.2454, 51.1910, 51.2641,  0.1000,  0.1000,  0.1000, 51.1492,\n",
      "         51.1492, 51.1492,  0.1000,  0.1000, 51.2454, 51.2454, 51.2454,  0.1000,\n",
      "          0.1000, 51.2454, 51.2454,  0.1000, 51.1910, 51.1910, 51.1910,  0.1000,\n",
      "          0.1000, 51.1910, 51.1910,  0.1000, 51.1910,  0.1000, 51.1910, 51.2641,\n",
      "         51.2641, 51.2641,  0.1000,  0.1000, 51.2641, 51.2641,  0.1000, 51.2641,\n",
      "          0.1000, 51.2641, 51.2454, 51.2641, 51.2641, 51.2641, 51.1910, 51.2641,\n",
      "         51.2641, 51.2641, 51.2454, 51.2641, 51.2641, 51.2641, 51.2454, 51.1910,\n",
      "         51.2454, 51.2454, 51.2454,  0.1000, 51.2454, 51.1910,  0.1000, 51.1910,\n",
      "         51.2641,  0.1000, 51.2641, 51.2641, 51.2641, 51.2454, 51.2454,  0.1000,\n",
      "         51.2641,  0.1000, 51.1492, 51.1492, 51.2454, 51.2641, 51.2641,  0.1000,\n",
      "          0.1000, 51.1492, 51.2454, 51.2641,  0.1000, 51.2454, 51.2641,  0.1000,\n",
      "         51.1492, 51.2641]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 384 was 98.5%\n",
      "current params: tensor([51.1492, 51.2454, 51.1910, 51.2641], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.8\n",
      "SLow rates:  tensor([[51.2502, 51.3465, 51.2920, 51.3651,  0.1000,  0.1000,  0.1000, 51.2502,\n",
      "         51.2502, 51.2502,  0.1000,  0.1000, 51.3465, 51.3465, 51.3465,  0.1000,\n",
      "          0.1000, 51.3465, 51.3465,  0.1000, 51.2920, 51.2920, 51.2920,  0.1000,\n",
      "          0.1000, 51.2920, 51.2920,  0.1000, 51.2920,  0.1000, 51.2920, 51.3651,\n",
      "         51.3651, 51.3651,  0.1000,  0.1000, 51.3651, 51.3651,  0.1000, 51.3651,\n",
      "          0.1000, 51.3651, 51.3465, 51.3651, 51.3651, 51.3651, 51.2920, 51.3651,\n",
      "         51.3651, 51.3651, 51.3465, 51.3651, 51.3651, 51.3651, 51.3465, 51.2920,\n",
      "         51.3465, 51.3465, 51.3465,  0.1000, 51.3465, 51.2920,  0.1000, 51.2920,\n",
      "         51.3651,  0.1000, 51.3651, 51.3651, 51.3651, 51.3465, 51.3465,  0.1000,\n",
      "         51.3651,  0.1000, 51.2502, 51.2502, 51.3465, 51.3651, 51.3651,  0.1000,\n",
      "          0.1000, 51.2502, 51.3465, 51.3651,  0.1000, 51.3465, 51.3651,  0.1000,\n",
      "         51.2502, 51.3651]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 385 was 98.5%\n",
      "current params: tensor([51.2502, 51.3465, 51.2920, 51.3651], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.8\n",
      "SLow rates:  tensor([[51.3512, 51.4475, 51.3930, 51.4660,  0.1000,  0.1000,  0.1000, 51.3512,\n",
      "         51.3512, 51.3512,  0.1000,  0.1000, 51.4475, 51.4475, 51.4475,  0.1000,\n",
      "          0.1000, 51.4475, 51.4475,  0.1000, 51.3930, 51.3930, 51.3930,  0.1000,\n",
      "          0.1000, 51.3930, 51.3930,  0.1000, 51.3930,  0.1000, 51.3930, 51.4660,\n",
      "         51.4660, 51.4660,  0.1000,  0.1000, 51.4660, 51.4660,  0.1000, 51.4660,\n",
      "          0.1000, 51.4660, 51.4475, 51.4660, 51.4660, 51.4660, 51.3930, 51.4660,\n",
      "         51.4660, 51.4660, 51.4475, 51.4660, 51.4660, 51.4660, 51.4475, 51.3930,\n",
      "         51.4475, 51.4475, 51.4475,  0.1000, 51.4475, 51.3930,  0.1000, 51.3930,\n",
      "         51.4660,  0.1000, 51.4660, 51.4660, 51.4660, 51.4475, 51.4475,  0.1000,\n",
      "         51.4660,  0.1000, 51.3512, 51.3512, 51.4475, 51.4660, 51.4660,  0.1000,\n",
      "          0.1000, 51.3512, 51.4475, 51.4660,  0.1000, 51.4475, 51.4660,  0.1000,\n",
      "         51.3512, 51.4660]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 386 was 98.5%\n",
      "current params: tensor([51.3512, 51.4475, 51.3930, 51.4660], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.8\n",
      "SLow rates:  tensor([[51.4522, 51.5485, 51.4940, 51.5670,  0.1000,  0.1000,  0.1000, 51.4522,\n",
      "         51.4522, 51.4522,  0.1000,  0.1000, 51.5485, 51.5485, 51.5485,  0.1000,\n",
      "          0.1000, 51.5485, 51.5485,  0.1000, 51.4940, 51.4940, 51.4940,  0.1000,\n",
      "          0.1000, 51.4940, 51.4940,  0.1000, 51.4940,  0.1000, 51.4940, 51.5670,\n",
      "         51.5670, 51.5670,  0.1000,  0.1000, 51.5670, 51.5670,  0.1000, 51.5670,\n",
      "          0.1000, 51.5670, 51.5485, 51.5670, 51.5670, 51.5670, 51.4940, 51.5670,\n",
      "         51.5670, 51.5670, 51.5485, 51.5670, 51.5670, 51.5670, 51.5485, 51.4940,\n",
      "         51.5485, 51.5485, 51.5485,  0.1000, 51.5485, 51.4940,  0.1000, 51.4940,\n",
      "         51.5670,  0.1000, 51.5670, 51.5670, 51.5670, 51.5485, 51.5485,  0.1000,\n",
      "         51.5670,  0.1000, 51.4522, 51.4522, 51.5485, 51.5670, 51.5670,  0.1000,\n",
      "          0.1000, 51.4522, 51.5485, 51.5670,  0.1000, 51.5485, 51.5670,  0.1000,\n",
      "         51.4522, 51.5670]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 387 was 98.5%\n",
      "current params: tensor([51.4522, 51.5485, 51.4940, 51.5670], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.9\n",
      "SLow rates:  tensor([[51.5532, 51.6494, 51.5950, 51.6680,  0.1000,  0.1000,  0.1000, 51.5532,\n",
      "         51.5532, 51.5532,  0.1000,  0.1000, 51.6494, 51.6494, 51.6494,  0.1000,\n",
      "          0.1000, 51.6494, 51.6494,  0.1000, 51.5950, 51.5950, 51.5950,  0.1000,\n",
      "          0.1000, 51.5950, 51.5950,  0.1000, 51.5950,  0.1000, 51.5950, 51.6680,\n",
      "         51.6680, 51.6680,  0.1000,  0.1000, 51.6680, 51.6680,  0.1000, 51.6680,\n",
      "          0.1000, 51.6680, 51.6494, 51.6680, 51.6680, 51.6680, 51.5950, 51.6680,\n",
      "         51.6680, 51.6680, 51.6494, 51.6680, 51.6680, 51.6680, 51.6494, 51.5950,\n",
      "         51.6494, 51.6494, 51.6494,  0.1000, 51.6494, 51.5950,  0.1000, 51.5950,\n",
      "         51.6680,  0.1000, 51.6680, 51.6680, 51.6680, 51.6494, 51.6494,  0.1000,\n",
      "         51.6680,  0.1000, 51.5532, 51.5532, 51.6494, 51.6680, 51.6680,  0.1000,\n",
      "          0.1000, 51.5532, 51.6494, 51.6680,  0.1000, 51.6494, 51.6680,  0.1000,\n",
      "         51.5532, 51.6680]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 388 was 98.5%\n",
      "current params: tensor([51.5532, 51.6494, 51.5950, 51.6680], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.9\n",
      "SLow rates:  tensor([[51.6542, 51.7504, 51.6960, 51.7689,  0.1000,  0.1000,  0.1000, 51.6542,\n",
      "         51.6542, 51.6542,  0.1000,  0.1000, 51.7504, 51.7504, 51.7504,  0.1000,\n",
      "          0.1000, 51.7504, 51.7504,  0.1000, 51.6960, 51.6960, 51.6960,  0.1000,\n",
      "          0.1000, 51.6960, 51.6960,  0.1000, 51.6960,  0.1000, 51.6960, 51.7689,\n",
      "         51.7689, 51.7689,  0.1000,  0.1000, 51.7689, 51.7689,  0.1000, 51.7689,\n",
      "          0.1000, 51.7689, 51.7504, 51.7689, 51.7689, 51.7689, 51.6960, 51.7689,\n",
      "         51.7689, 51.7689, 51.7504, 51.7689, 51.7689, 51.7689, 51.7504, 51.6960,\n",
      "         51.7504, 51.7504, 51.7504,  0.1000, 51.7504, 51.6960,  0.1000, 51.6960,\n",
      "         51.7689,  0.1000, 51.7689, 51.7689, 51.7689, 51.7504, 51.7504,  0.1000,\n",
      "         51.7689,  0.1000, 51.6542, 51.6542, 51.7504, 51.7689, 51.7689,  0.1000,\n",
      "          0.1000, 51.6542, 51.7504, 51.7689,  0.1000, 51.7504, 51.7689,  0.1000,\n",
      "         51.6542, 51.7689]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 389 was 98.5%\n",
      "current params: tensor([51.6542, 51.7504, 51.6960, 51.7689], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.9\n",
      "SLow rates:  tensor([[51.7552, 51.8514, 51.7969, 51.8699,  0.1000,  0.1000,  0.1000, 51.7552,\n",
      "         51.7552, 51.7552,  0.1000,  0.1000, 51.8514, 51.8514, 51.8514,  0.1000,\n",
      "          0.1000, 51.8514, 51.8514,  0.1000, 51.7969, 51.7969, 51.7969,  0.1000,\n",
      "          0.1000, 51.7969, 51.7969,  0.1000, 51.7969,  0.1000, 51.7969, 51.8699,\n",
      "         51.8699, 51.8699,  0.1000,  0.1000, 51.8699, 51.8699,  0.1000, 51.8699,\n",
      "          0.1000, 51.8699, 51.8514, 51.8699, 51.8699, 51.8699, 51.7969, 51.8699,\n",
      "         51.8699, 51.8699, 51.8514, 51.8699, 51.8699, 51.8699, 51.8514, 51.7969,\n",
      "         51.8514, 51.8514, 51.8514,  0.1000, 51.8514, 51.7969,  0.1000, 51.7969,\n",
      "         51.8699,  0.1000, 51.8699, 51.8699, 51.8699, 51.8514, 51.8514,  0.1000,\n",
      "         51.8699,  0.1000, 51.7552, 51.7552, 51.8514, 51.8699, 51.8699,  0.1000,\n",
      "          0.1000, 51.7552, 51.8514, 51.8699,  0.1000, 51.8514, 51.8699,  0.1000,\n",
      "         51.7552, 51.8699]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 390 was 98.5%\n",
      "current params: tensor([51.7552, 51.8514, 51.7969, 51.8699], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.9\n",
      "SLow rates:  tensor([[51.8562, 51.9523, 51.8979, 51.9708,  0.1000,  0.1000,  0.1000, 51.8562,\n",
      "         51.8562, 51.8562,  0.1000,  0.1000, 51.9523, 51.9523, 51.9523,  0.1000,\n",
      "          0.1000, 51.9523, 51.9523,  0.1000, 51.8979, 51.8979, 51.8979,  0.1000,\n",
      "          0.1000, 51.8979, 51.8979,  0.1000, 51.8979,  0.1000, 51.8979, 51.9708,\n",
      "         51.9708, 51.9708,  0.1000,  0.1000, 51.9708, 51.9708,  0.1000, 51.9708,\n",
      "          0.1000, 51.9708, 51.9523, 51.9708, 51.9708, 51.9708, 51.8979, 51.9708,\n",
      "         51.9708, 51.9708, 51.9523, 51.9708, 51.9708, 51.9708, 51.9523, 51.8979,\n",
      "         51.9523, 51.9523, 51.9523,  0.1000, 51.9523, 51.8979,  0.1000, 51.8979,\n",
      "         51.9708,  0.1000, 51.9708, 51.9708, 51.9708, 51.9523, 51.9523,  0.1000,\n",
      "         51.9708,  0.1000, 51.8562, 51.8562, 51.9523, 51.9708, 51.9708,  0.1000,\n",
      "          0.1000, 51.8562, 51.9523, 51.9708,  0.1000, 51.9523, 51.9708,  0.1000,\n",
      "         51.8562, 51.9708]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 391 was 98.5%\n",
      "current params: tensor([51.8562, 51.9523, 51.8979, 51.9708], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  12.9\n",
      "SLow rates:  tensor([[51.9571, 52.0533, 51.9988, 52.0718,  0.1000,  0.1000,  0.1000, 51.9571,\n",
      "         51.9571, 51.9571,  0.1000,  0.1000, 52.0533, 52.0533, 52.0533,  0.1000,\n",
      "          0.1000, 52.0533, 52.0533,  0.1000, 51.9988, 51.9988, 51.9988,  0.1000,\n",
      "          0.1000, 51.9988, 51.9988,  0.1000, 51.9988,  0.1000, 51.9988, 52.0718,\n",
      "         52.0718, 52.0718,  0.1000,  0.1000, 52.0718, 52.0718,  0.1000, 52.0718,\n",
      "          0.1000, 52.0718, 52.0533, 52.0718, 52.0718, 52.0718, 51.9988, 52.0718,\n",
      "         52.0718, 52.0718, 52.0533, 52.0718, 52.0718, 52.0718, 52.0533, 51.9988,\n",
      "         52.0533, 52.0533, 52.0533,  0.1000, 52.0533, 51.9988,  0.1000, 51.9988,\n",
      "         52.0718,  0.1000, 52.0718, 52.0718, 52.0718, 52.0533, 52.0533,  0.1000,\n",
      "         52.0718,  0.1000, 51.9571, 51.9571, 52.0533, 52.0718, 52.0718,  0.1000,\n",
      "          0.1000, 51.9571, 52.0533, 52.0718,  0.1000, 52.0533, 52.0718,  0.1000,\n",
      "         51.9571, 52.0718]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 392 was 98.5%\n",
      "current params: tensor([51.9571, 52.0533, 51.9988, 52.0718], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.0\n",
      "SLow rates:  tensor([[52.0581, 52.1542, 52.0998, 52.1727,  0.1000,  0.1000,  0.1000, 52.0581,\n",
      "         52.0581, 52.0581,  0.1000,  0.1000, 52.1542, 52.1542, 52.1542,  0.1000,\n",
      "          0.1000, 52.1542, 52.1542,  0.1000, 52.0998, 52.0998, 52.0998,  0.1000,\n",
      "          0.1000, 52.0998, 52.0998,  0.1000, 52.0998,  0.1000, 52.0998, 52.1727,\n",
      "         52.1727, 52.1727,  0.1000,  0.1000, 52.1727, 52.1727,  0.1000, 52.1727,\n",
      "          0.1000, 52.1727, 52.1542, 52.1727, 52.1727, 52.1727, 52.0998, 52.1727,\n",
      "         52.1727, 52.1727, 52.1542, 52.1727, 52.1727, 52.1727, 52.1542, 52.0998,\n",
      "         52.1542, 52.1542, 52.1542,  0.1000, 52.1542, 52.0998,  0.1000, 52.0998,\n",
      "         52.1727,  0.1000, 52.1727, 52.1727, 52.1727, 52.1542, 52.1542,  0.1000,\n",
      "         52.1727,  0.1000, 52.0581, 52.0581, 52.1542, 52.1727, 52.1727,  0.1000,\n",
      "          0.1000, 52.0581, 52.1542, 52.1727,  0.1000, 52.1542, 52.1727,  0.1000,\n",
      "         52.0581, 52.1727]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 393 was 98.5%\n",
      "current params: tensor([52.0581, 52.1542, 52.0998, 52.1727], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.0\n",
      "SLow rates:  tensor([[52.1590, 52.2551, 52.2007, 52.2736,  0.1000,  0.1000,  0.1000, 52.1590,\n",
      "         52.1590, 52.1590,  0.1000,  0.1000, 52.2551, 52.2551, 52.2551,  0.1000,\n",
      "          0.1000, 52.2551, 52.2551,  0.1000, 52.2007, 52.2007, 52.2007,  0.1000,\n",
      "          0.1000, 52.2007, 52.2007,  0.1000, 52.2007,  0.1000, 52.2007, 52.2736,\n",
      "         52.2736, 52.2736,  0.1000,  0.1000, 52.2736, 52.2736,  0.1000, 52.2736,\n",
      "          0.1000, 52.2736, 52.2551, 52.2736, 52.2736, 52.2736, 52.2007, 52.2736,\n",
      "         52.2736, 52.2736, 52.2551, 52.2736, 52.2736, 52.2736, 52.2551, 52.2007,\n",
      "         52.2551, 52.2551, 52.2551,  0.1000, 52.2551, 52.2007,  0.1000, 52.2007,\n",
      "         52.2736,  0.1000, 52.2736, 52.2736, 52.2736, 52.2551, 52.2551,  0.1000,\n",
      "         52.2736,  0.1000, 52.1590, 52.1590, 52.2551, 52.2736, 52.2736,  0.1000,\n",
      "          0.1000, 52.1590, 52.2551, 52.2736,  0.1000, 52.2551, 52.2736,  0.1000,\n",
      "         52.1590, 52.2736]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 394 was 98.5%\n",
      "current params: tensor([52.1590, 52.2551, 52.2007, 52.2736], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.0\n",
      "SLow rates:  tensor([[52.2599, 52.3560, 52.3016, 52.3745,  0.1000,  0.1000,  0.1000, 52.2599,\n",
      "         52.2599, 52.2599,  0.1000,  0.1000, 52.3560, 52.3560, 52.3560,  0.1000,\n",
      "          0.1000, 52.3560, 52.3560,  0.1000, 52.3016, 52.3016, 52.3016,  0.1000,\n",
      "          0.1000, 52.3016, 52.3016,  0.1000, 52.3016,  0.1000, 52.3016, 52.3745,\n",
      "         52.3745, 52.3745,  0.1000,  0.1000, 52.3745, 52.3745,  0.1000, 52.3745,\n",
      "          0.1000, 52.3745, 52.3560, 52.3745, 52.3745, 52.3745, 52.3016, 52.3745,\n",
      "         52.3745, 52.3745, 52.3560, 52.3745, 52.3745, 52.3745, 52.3560, 52.3016,\n",
      "         52.3560, 52.3560, 52.3560,  0.1000, 52.3560, 52.3016,  0.1000, 52.3016,\n",
      "         52.3745,  0.1000, 52.3745, 52.3745, 52.3745, 52.3560, 52.3560,  0.1000,\n",
      "         52.3745,  0.1000, 52.2599, 52.2599, 52.3560, 52.3745, 52.3745,  0.1000,\n",
      "          0.1000, 52.2599, 52.3560, 52.3745,  0.1000, 52.3560, 52.3745,  0.1000,\n",
      "         52.2599, 52.3745]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 395 was 98.5%\n",
      "current params: tensor([52.2599, 52.3560, 52.3016, 52.3745], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.0\n",
      "SLow rates:  tensor([[52.3609, 52.4569, 52.4025, 52.4754,  0.1000,  0.1000,  0.1000, 52.3609,\n",
      "         52.3609, 52.3609,  0.1000,  0.1000, 52.4569, 52.4569, 52.4569,  0.1000,\n",
      "          0.1000, 52.4569, 52.4569,  0.1000, 52.4025, 52.4025, 52.4025,  0.1000,\n",
      "          0.1000, 52.4025, 52.4025,  0.1000, 52.4025,  0.1000, 52.4025, 52.4754,\n",
      "         52.4754, 52.4754,  0.1000,  0.1000, 52.4754, 52.4754,  0.1000, 52.4754,\n",
      "          0.1000, 52.4754, 52.4569, 52.4754, 52.4754, 52.4754, 52.4025, 52.4754,\n",
      "         52.4754, 52.4754, 52.4569, 52.4754, 52.4754, 52.4754, 52.4569, 52.4025,\n",
      "         52.4569, 52.4569, 52.4569,  0.1000, 52.4569, 52.4025,  0.1000, 52.4025,\n",
      "         52.4754,  0.1000, 52.4754, 52.4754, 52.4754, 52.4569, 52.4569,  0.1000,\n",
      "         52.4754,  0.1000, 52.3609, 52.3609, 52.4569, 52.4754, 52.4754,  0.1000,\n",
      "          0.1000, 52.3609, 52.4569, 52.4754,  0.1000, 52.4569, 52.4754,  0.1000,\n",
      "         52.3609, 52.4754]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 396 was 98.5%\n",
      "current params: tensor([52.3609, 52.4569, 52.4025, 52.4754], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.0\n",
      "SLow rates:  tensor([[52.4618, 52.5578, 52.5034, 52.5763,  0.1000,  0.1000,  0.1000, 52.4618,\n",
      "         52.4618, 52.4618,  0.1000,  0.1000, 52.5578, 52.5578, 52.5578,  0.1000,\n",
      "          0.1000, 52.5578, 52.5578,  0.1000, 52.5034, 52.5034, 52.5034,  0.1000,\n",
      "          0.1000, 52.5034, 52.5034,  0.1000, 52.5034,  0.1000, 52.5034, 52.5763,\n",
      "         52.5763, 52.5763,  0.1000,  0.1000, 52.5763, 52.5763,  0.1000, 52.5763,\n",
      "          0.1000, 52.5763, 52.5578, 52.5763, 52.5763, 52.5763, 52.5034, 52.5763,\n",
      "         52.5763, 52.5763, 52.5578, 52.5763, 52.5763, 52.5763, 52.5578, 52.5034,\n",
      "         52.5578, 52.5578, 52.5578,  0.1000, 52.5578, 52.5034,  0.1000, 52.5034,\n",
      "         52.5763,  0.1000, 52.5763, 52.5763, 52.5763, 52.5578, 52.5578,  0.1000,\n",
      "         52.5763,  0.1000, 52.4618, 52.4618, 52.5578, 52.5763, 52.5763,  0.1000,\n",
      "          0.1000, 52.4618, 52.5578, 52.5763,  0.1000, 52.5578, 52.5763,  0.1000,\n",
      "         52.4618, 52.5763]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1397, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 397 was 98.5%\n",
      "current params: tensor([52.4618, 52.5578, 52.5034, 52.5763], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.1\n",
      "SLow rates:  tensor([[52.5627, 52.6587, 52.6043, 52.6771,  0.1000,  0.1000,  0.1000, 52.5627,\n",
      "         52.5627, 52.5627,  0.1000,  0.1000, 52.6587, 52.6587, 52.6587,  0.1000,\n",
      "          0.1000, 52.6587, 52.6587,  0.1000, 52.6043, 52.6043, 52.6043,  0.1000,\n",
      "          0.1000, 52.6043, 52.6043,  0.1000, 52.6043,  0.1000, 52.6043, 52.6771,\n",
      "         52.6771, 52.6771,  0.1000,  0.1000, 52.6771, 52.6771,  0.1000, 52.6771,\n",
      "          0.1000, 52.6771, 52.6587, 52.6771, 52.6771, 52.6771, 52.6043, 52.6771,\n",
      "         52.6771, 52.6771, 52.6587, 52.6771, 52.6771, 52.6771, 52.6587, 52.6043,\n",
      "         52.6587, 52.6587, 52.6587,  0.1000, 52.6587, 52.6043,  0.1000, 52.6043,\n",
      "         52.6771,  0.1000, 52.6771, 52.6771, 52.6771, 52.6587, 52.6587,  0.1000,\n",
      "         52.6771,  0.1000, 52.5627, 52.5627, 52.6587, 52.6771, 52.6771,  0.1000,\n",
      "          0.1000, 52.5627, 52.6587, 52.6771,  0.1000, 52.6587, 52.6771,  0.1000,\n",
      "         52.5627, 52.6771]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 398 was 98.5%\n",
      "current params: tensor([52.5627, 52.6587, 52.6043, 52.6771], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.1\n",
      "SLow rates:  tensor([[52.6636, 52.7596, 52.7052, 52.7780,  0.1000,  0.1000,  0.1000, 52.6636,\n",
      "         52.6636, 52.6636,  0.1000,  0.1000, 52.7596, 52.7596, 52.7596,  0.1000,\n",
      "          0.1000, 52.7596, 52.7596,  0.1000, 52.7052, 52.7052, 52.7052,  0.1000,\n",
      "          0.1000, 52.7052, 52.7052,  0.1000, 52.7052,  0.1000, 52.7052, 52.7780,\n",
      "         52.7780, 52.7780,  0.1000,  0.1000, 52.7780, 52.7780,  0.1000, 52.7780,\n",
      "          0.1000, 52.7780, 52.7596, 52.7780, 52.7780, 52.7780, 52.7052, 52.7780,\n",
      "         52.7780, 52.7780, 52.7596, 52.7780, 52.7780, 52.7780, 52.7596, 52.7052,\n",
      "         52.7596, 52.7596, 52.7596,  0.1000, 52.7596, 52.7052,  0.1000, 52.7052,\n",
      "         52.7780,  0.1000, 52.7780, 52.7780, 52.7780, 52.7596, 52.7596,  0.1000,\n",
      "         52.7780,  0.1000, 52.6636, 52.6636, 52.7596, 52.7780, 52.7780,  0.1000,\n",
      "          0.1000, 52.6636, 52.7596, 52.7780,  0.1000, 52.7596, 52.7780,  0.1000,\n",
      "         52.6636, 52.7780]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 399 was 98.5%\n",
      "current params: tensor([52.6636, 52.7596, 52.7052, 52.7780], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.1\n",
      "SLow rates:  tensor([[52.7645, 52.8604, 52.8061, 52.8789,  0.1000,  0.1000,  0.1000, 52.7645,\n",
      "         52.7645, 52.7645,  0.1000,  0.1000, 52.8604, 52.8604, 52.8604,  0.1000,\n",
      "          0.1000, 52.8604, 52.8604,  0.1000, 52.8061, 52.8061, 52.8061,  0.1000,\n",
      "          0.1000, 52.8061, 52.8061,  0.1000, 52.8061,  0.1000, 52.8061, 52.8789,\n",
      "         52.8789, 52.8789,  0.1000,  0.1000, 52.8789, 52.8789,  0.1000, 52.8789,\n",
      "          0.1000, 52.8789, 52.8604, 52.8789, 52.8789, 52.8789, 52.8061, 52.8789,\n",
      "         52.8789, 52.8789, 52.8604, 52.8789, 52.8789, 52.8789, 52.8604, 52.8061,\n",
      "         52.8604, 52.8604, 52.8604,  0.1000, 52.8604, 52.8061,  0.1000, 52.8061,\n",
      "         52.8789,  0.1000, 52.8789, 52.8789, 52.8789, 52.8604, 52.8604,  0.1000,\n",
      "         52.8789,  0.1000, 52.7645, 52.7645, 52.8604, 52.8789, 52.8789,  0.1000,\n",
      "          0.1000, 52.7645, 52.8604, 52.8789,  0.1000, 52.8604, 52.8789,  0.1000,\n",
      "         52.7645, 52.8789]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 400 was 98.5%\n",
      "current params: tensor([52.7645, 52.8604, 52.8061, 52.8789], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.1\n",
      "SLow rates:  tensor([[52.8653, 52.9613, 52.9069, 52.9797,  0.1000,  0.1000,  0.1000, 52.8653,\n",
      "         52.8653, 52.8653,  0.1000,  0.1000, 52.9613, 52.9613, 52.9613,  0.1000,\n",
      "          0.1000, 52.9613, 52.9613,  0.1000, 52.9069, 52.9069, 52.9069,  0.1000,\n",
      "          0.1000, 52.9069, 52.9069,  0.1000, 52.9069,  0.1000, 52.9069, 52.9797,\n",
      "         52.9797, 52.9797,  0.1000,  0.1000, 52.9797, 52.9797,  0.1000, 52.9797,\n",
      "          0.1000, 52.9797, 52.9613, 52.9797, 52.9797, 52.9797, 52.9069, 52.9797,\n",
      "         52.9797, 52.9797, 52.9613, 52.9797, 52.9797, 52.9797, 52.9613, 52.9069,\n",
      "         52.9613, 52.9613, 52.9613,  0.1000, 52.9613, 52.9069,  0.1000, 52.9069,\n",
      "         52.9797,  0.1000, 52.9797, 52.9797, 52.9797, 52.9613, 52.9613,  0.1000,\n",
      "         52.9797,  0.1000, 52.8653, 52.8653, 52.9613, 52.9797, 52.9797,  0.1000,\n",
      "          0.1000, 52.8653, 52.9613, 52.9797,  0.1000, 52.9613, 52.9797,  0.1000,\n",
      "         52.8653, 52.9797]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 401 was 98.5%\n",
      "current params: tensor([52.8653, 52.9613, 52.9069, 52.9797], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.1\n",
      "SLow rates:  tensor([[52.9662, 53.0621, 53.0078, 53.0805,  0.1000,  0.1000,  0.1000, 52.9662,\n",
      "         52.9662, 52.9662,  0.1000,  0.1000, 53.0621, 53.0621, 53.0621,  0.1000,\n",
      "          0.1000, 53.0621, 53.0621,  0.1000, 53.0078, 53.0078, 53.0078,  0.1000,\n",
      "          0.1000, 53.0078, 53.0078,  0.1000, 53.0078,  0.1000, 53.0078, 53.0805,\n",
      "         53.0805, 53.0805,  0.1000,  0.1000, 53.0805, 53.0805,  0.1000, 53.0805,\n",
      "          0.1000, 53.0805, 53.0621, 53.0805, 53.0805, 53.0805, 53.0078, 53.0805,\n",
      "         53.0805, 53.0805, 53.0621, 53.0805, 53.0805, 53.0805, 53.0621, 53.0078,\n",
      "         53.0621, 53.0621, 53.0621,  0.1000, 53.0621, 53.0078,  0.1000, 53.0078,\n",
      "         53.0805,  0.1000, 53.0805, 53.0805, 53.0805, 53.0621, 53.0621,  0.1000,\n",
      "         53.0805,  0.1000, 52.9662, 52.9662, 53.0621, 53.0805, 53.0805,  0.1000,\n",
      "          0.1000, 52.9662, 53.0621, 53.0805,  0.1000, 53.0621, 53.0805,  0.1000,\n",
      "         52.9662, 53.0805]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 402 was 98.5%\n",
      "current params: tensor([52.9662, 53.0621, 53.0078, 53.0805], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.2\n",
      "SLow rates:  tensor([[53.0670, 53.1630, 53.1086, 53.1814,  0.1000,  0.1000,  0.1000, 53.0670,\n",
      "         53.0670, 53.0670,  0.1000,  0.1000, 53.1630, 53.1630, 53.1630,  0.1000,\n",
      "          0.1000, 53.1630, 53.1630,  0.1000, 53.1086, 53.1086, 53.1086,  0.1000,\n",
      "          0.1000, 53.1086, 53.1086,  0.1000, 53.1086,  0.1000, 53.1086, 53.1814,\n",
      "         53.1814, 53.1814,  0.1000,  0.1000, 53.1814, 53.1814,  0.1000, 53.1814,\n",
      "          0.1000, 53.1814, 53.1630, 53.1814, 53.1814, 53.1814, 53.1086, 53.1814,\n",
      "         53.1814, 53.1814, 53.1630, 53.1814, 53.1814, 53.1814, 53.1630, 53.1086,\n",
      "         53.1630, 53.1630, 53.1630,  0.1000, 53.1630, 53.1086,  0.1000, 53.1086,\n",
      "         53.1814,  0.1000, 53.1814, 53.1814, 53.1814, 53.1630, 53.1630,  0.1000,\n",
      "         53.1814,  0.1000, 53.0670, 53.0670, 53.1630, 53.1814, 53.1814,  0.1000,\n",
      "          0.1000, 53.0670, 53.1630, 53.1814,  0.1000, 53.1630, 53.1814,  0.1000,\n",
      "         53.0670, 53.1814]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 403 was 98.6%\n",
      "current params: tensor([53.0670, 53.1630, 53.1086, 53.1814], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.2\n",
      "SLow rates:  tensor([[53.1679, 53.2638, 53.2095, 53.2822,  0.1000,  0.1000,  0.1000, 53.1679,\n",
      "         53.1679, 53.1679,  0.1000,  0.1000, 53.2638, 53.2638, 53.2638,  0.1000,\n",
      "          0.1000, 53.2638, 53.2638,  0.1000, 53.2095, 53.2095, 53.2095,  0.1000,\n",
      "          0.1000, 53.2095, 53.2095,  0.1000, 53.2095,  0.1000, 53.2095, 53.2822,\n",
      "         53.2822, 53.2822,  0.1000,  0.1000, 53.2822, 53.2822,  0.1000, 53.2822,\n",
      "          0.1000, 53.2822, 53.2638, 53.2822, 53.2822, 53.2822, 53.2095, 53.2822,\n",
      "         53.2822, 53.2822, 53.2638, 53.2822, 53.2822, 53.2822, 53.2638, 53.2095,\n",
      "         53.2638, 53.2638, 53.2638,  0.1000, 53.2638, 53.2095,  0.1000, 53.2095,\n",
      "         53.2822,  0.1000, 53.2822, 53.2822, 53.2822, 53.2638, 53.2638,  0.1000,\n",
      "         53.2822,  0.1000, 53.1679, 53.1679, 53.2638, 53.2822, 53.2822,  0.1000,\n",
      "          0.1000, 53.1679, 53.2638, 53.2822,  0.1000, 53.2638, 53.2822,  0.1000,\n",
      "         53.1679, 53.2822]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 404 was 98.6%\n",
      "current params: tensor([53.1679, 53.2638, 53.2095, 53.2822], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.2\n",
      "SLow rates:  tensor([[53.2687, 53.3646, 53.3103, 53.3830,  0.1000,  0.1000,  0.1000, 53.2687,\n",
      "         53.2687, 53.2687,  0.1000,  0.1000, 53.3646, 53.3646, 53.3646,  0.1000,\n",
      "          0.1000, 53.3646, 53.3646,  0.1000, 53.3103, 53.3103, 53.3103,  0.1000,\n",
      "          0.1000, 53.3103, 53.3103,  0.1000, 53.3103,  0.1000, 53.3103, 53.3830,\n",
      "         53.3830, 53.3830,  0.1000,  0.1000, 53.3830, 53.3830,  0.1000, 53.3830,\n",
      "          0.1000, 53.3830, 53.3646, 53.3830, 53.3830, 53.3830, 53.3103, 53.3830,\n",
      "         53.3830, 53.3830, 53.3646, 53.3830, 53.3830, 53.3830, 53.3646, 53.3103,\n",
      "         53.3646, 53.3646, 53.3646,  0.1000, 53.3646, 53.3103,  0.1000, 53.3103,\n",
      "         53.3830,  0.1000, 53.3830, 53.3830, 53.3830, 53.3646, 53.3646,  0.1000,\n",
      "         53.3830,  0.1000, 53.2687, 53.2687, 53.3646, 53.3830, 53.3830,  0.1000,\n",
      "          0.1000, 53.2687, 53.3646, 53.3830,  0.1000, 53.3646, 53.3830,  0.1000,\n",
      "         53.2687, 53.3830]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 405 was 98.6%\n",
      "current params: tensor([53.2687, 53.3646, 53.3103, 53.3830], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.2\n",
      "SLow rates:  tensor([[53.3696, 53.4655, 53.4111, 53.4838,  0.1000,  0.1000,  0.1000, 53.3696,\n",
      "         53.3696, 53.3696,  0.1000,  0.1000, 53.4655, 53.4655, 53.4655,  0.1000,\n",
      "          0.1000, 53.4655, 53.4655,  0.1000, 53.4111, 53.4111, 53.4111,  0.1000,\n",
      "          0.1000, 53.4111, 53.4111,  0.1000, 53.4111,  0.1000, 53.4111, 53.4838,\n",
      "         53.4838, 53.4838,  0.1000,  0.1000, 53.4838, 53.4838,  0.1000, 53.4838,\n",
      "          0.1000, 53.4838, 53.4655, 53.4838, 53.4838, 53.4838, 53.4111, 53.4838,\n",
      "         53.4838, 53.4838, 53.4655, 53.4838, 53.4838, 53.4838, 53.4655, 53.4111,\n",
      "         53.4655, 53.4655, 53.4655,  0.1000, 53.4655, 53.4111,  0.1000, 53.4111,\n",
      "         53.4838,  0.1000, 53.4838, 53.4838, 53.4838, 53.4655, 53.4655,  0.1000,\n",
      "         53.4838,  0.1000, 53.3696, 53.3696, 53.4655, 53.4838, 53.4838,  0.1000,\n",
      "          0.1000, 53.3696, 53.4655, 53.4838,  0.1000, 53.4655, 53.4838,  0.1000,\n",
      "         53.3696, 53.4838]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 406 was 98.6%\n",
      "current params: tensor([53.3696, 53.4655, 53.4111, 53.4838], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.2\n",
      "SLow rates:  tensor([[53.4704, 53.5663, 53.5119, 53.5846,  0.1000,  0.1000,  0.1000, 53.4704,\n",
      "         53.4704, 53.4704,  0.1000,  0.1000, 53.5663, 53.5663, 53.5663,  0.1000,\n",
      "          0.1000, 53.5663, 53.5663,  0.1000, 53.5119, 53.5119, 53.5119,  0.1000,\n",
      "          0.1000, 53.5119, 53.5119,  0.1000, 53.5119,  0.1000, 53.5119, 53.5846,\n",
      "         53.5846, 53.5846,  0.1000,  0.1000, 53.5846, 53.5846,  0.1000, 53.5846,\n",
      "          0.1000, 53.5846, 53.5663, 53.5846, 53.5846, 53.5846, 53.5119, 53.5846,\n",
      "         53.5846, 53.5846, 53.5663, 53.5846, 53.5846, 53.5846, 53.5663, 53.5119,\n",
      "         53.5663, 53.5663, 53.5663,  0.1000, 53.5663, 53.5119,  0.1000, 53.5119,\n",
      "         53.5846,  0.1000, 53.5846, 53.5846, 53.5846, 53.5663, 53.5663,  0.1000,\n",
      "         53.5846,  0.1000, 53.4704, 53.4704, 53.5663, 53.5846, 53.5846,  0.1000,\n",
      "          0.1000, 53.4704, 53.5663, 53.5846,  0.1000, 53.5663, 53.5846,  0.1000,\n",
      "         53.4704, 53.5846]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 407 was 98.6%\n",
      "current params: tensor([53.4704, 53.5663, 53.5119, 53.5846], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.2\n",
      "SLow rates:  tensor([[53.5712, 53.6671, 53.6127, 53.6854,  0.1000,  0.1000,  0.1000, 53.5712,\n",
      "         53.5712, 53.5712,  0.1000,  0.1000, 53.6671, 53.6671, 53.6671,  0.1000,\n",
      "          0.1000, 53.6671, 53.6671,  0.1000, 53.6127, 53.6127, 53.6127,  0.1000,\n",
      "          0.1000, 53.6127, 53.6127,  0.1000, 53.6127,  0.1000, 53.6127, 53.6854,\n",
      "         53.6854, 53.6854,  0.1000,  0.1000, 53.6854, 53.6854,  0.1000, 53.6854,\n",
      "          0.1000, 53.6854, 53.6671, 53.6854, 53.6854, 53.6854, 53.6127, 53.6854,\n",
      "         53.6854, 53.6854, 53.6671, 53.6854, 53.6854, 53.6854, 53.6671, 53.6127,\n",
      "         53.6671, 53.6671, 53.6671,  0.1000, 53.6671, 53.6127,  0.1000, 53.6127,\n",
      "         53.6854,  0.1000, 53.6854, 53.6854, 53.6854, 53.6671, 53.6671,  0.1000,\n",
      "         53.6854,  0.1000, 53.5712, 53.5712, 53.6671, 53.6854, 53.6854,  0.1000,\n",
      "          0.1000, 53.5712, 53.6671, 53.6854,  0.1000, 53.6671, 53.6854,  0.1000,\n",
      "         53.5712, 53.6854]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 408 was 98.6%\n",
      "current params: tensor([53.5712, 53.6671, 53.6127, 53.6854], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.3\n",
      "SLow rates:  tensor([[53.6720, 53.7678, 53.7135, 53.7862,  0.1000,  0.1000,  0.1000, 53.6720,\n",
      "         53.6720, 53.6720,  0.1000,  0.1000, 53.7678, 53.7678, 53.7678,  0.1000,\n",
      "          0.1000, 53.7678, 53.7678,  0.1000, 53.7135, 53.7135, 53.7135,  0.1000,\n",
      "          0.1000, 53.7135, 53.7135,  0.1000, 53.7135,  0.1000, 53.7135, 53.7862,\n",
      "         53.7862, 53.7862,  0.1000,  0.1000, 53.7862, 53.7862,  0.1000, 53.7862,\n",
      "          0.1000, 53.7862, 53.7678, 53.7862, 53.7862, 53.7862, 53.7135, 53.7862,\n",
      "         53.7862, 53.7862, 53.7678, 53.7862, 53.7862, 53.7862, 53.7678, 53.7135,\n",
      "         53.7678, 53.7678, 53.7678,  0.1000, 53.7678, 53.7135,  0.1000, 53.7135,\n",
      "         53.7862,  0.1000, 53.7862, 53.7862, 53.7862, 53.7678, 53.7678,  0.1000,\n",
      "         53.7862,  0.1000, 53.6720, 53.6720, 53.7678, 53.7862, 53.7862,  0.1000,\n",
      "          0.1000, 53.6720, 53.7678, 53.7862,  0.1000, 53.7678, 53.7862,  0.1000,\n",
      "         53.6720, 53.7862]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 409 was 98.6%\n",
      "current params: tensor([53.6720, 53.7678, 53.7135, 53.7862], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.3\n",
      "SLow rates:  tensor([[53.7728, 53.8686, 53.8143, 53.8869,  0.1000,  0.1000,  0.1000, 53.7728,\n",
      "         53.7728, 53.7728,  0.1000,  0.1000, 53.8686, 53.8686, 53.8686,  0.1000,\n",
      "          0.1000, 53.8686, 53.8686,  0.1000, 53.8143, 53.8143, 53.8143,  0.1000,\n",
      "          0.1000, 53.8143, 53.8143,  0.1000, 53.8143,  0.1000, 53.8143, 53.8869,\n",
      "         53.8869, 53.8869,  0.1000,  0.1000, 53.8869, 53.8869,  0.1000, 53.8869,\n",
      "          0.1000, 53.8869, 53.8686, 53.8869, 53.8869, 53.8869, 53.8143, 53.8869,\n",
      "         53.8869, 53.8869, 53.8686, 53.8869, 53.8869, 53.8869, 53.8686, 53.8143,\n",
      "         53.8686, 53.8686, 53.8686,  0.1000, 53.8686, 53.8143,  0.1000, 53.8143,\n",
      "         53.8869,  0.1000, 53.8869, 53.8869, 53.8869, 53.8686, 53.8686,  0.1000,\n",
      "         53.8869,  0.1000, 53.7728, 53.7728, 53.8686, 53.8869, 53.8869,  0.1000,\n",
      "          0.1000, 53.7728, 53.8686, 53.8869,  0.1000, 53.8686, 53.8869,  0.1000,\n",
      "         53.7728, 53.8869]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 410 was 98.6%\n",
      "current params: tensor([53.7728, 53.8686, 53.8143, 53.8869], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.3\n",
      "SLow rates:  tensor([[53.8736, 53.9694, 53.9151, 53.9877,  0.1000,  0.1000,  0.1000, 53.8736,\n",
      "         53.8736, 53.8736,  0.1000,  0.1000, 53.9694, 53.9694, 53.9694,  0.1000,\n",
      "          0.1000, 53.9694, 53.9694,  0.1000, 53.9151, 53.9151, 53.9151,  0.1000,\n",
      "          0.1000, 53.9151, 53.9151,  0.1000, 53.9151,  0.1000, 53.9151, 53.9877,\n",
      "         53.9877, 53.9877,  0.1000,  0.1000, 53.9877, 53.9877,  0.1000, 53.9877,\n",
      "          0.1000, 53.9877, 53.9694, 53.9877, 53.9877, 53.9877, 53.9151, 53.9877,\n",
      "         53.9877, 53.9877, 53.9694, 53.9877, 53.9877, 53.9877, 53.9694, 53.9151,\n",
      "         53.9694, 53.9694, 53.9694,  0.1000, 53.9694, 53.9151,  0.1000, 53.9151,\n",
      "         53.9877,  0.1000, 53.9877, 53.9877, 53.9877, 53.9694, 53.9694,  0.1000,\n",
      "         53.9877,  0.1000, 53.8736, 53.8736, 53.9694, 53.9877, 53.9877,  0.1000,\n",
      "          0.1000, 53.8736, 53.9694, 53.9877,  0.1000, 53.9694, 53.9877,  0.1000,\n",
      "         53.8736, 53.9877]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 411 was 98.6%\n",
      "current params: tensor([53.8736, 53.9694, 53.9151, 53.9877], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.3\n",
      "SLow rates:  tensor([[53.9744, 54.0702, 54.0159, 54.0885,  0.1000,  0.1000,  0.1000, 53.9744,\n",
      "         53.9744, 53.9744,  0.1000,  0.1000, 54.0702, 54.0702, 54.0702,  0.1000,\n",
      "          0.1000, 54.0702, 54.0702,  0.1000, 54.0159, 54.0159, 54.0159,  0.1000,\n",
      "          0.1000, 54.0159, 54.0159,  0.1000, 54.0159,  0.1000, 54.0159, 54.0885,\n",
      "         54.0885, 54.0885,  0.1000,  0.1000, 54.0885, 54.0885,  0.1000, 54.0885,\n",
      "          0.1000, 54.0885, 54.0702, 54.0885, 54.0885, 54.0885, 54.0159, 54.0885,\n",
      "         54.0885, 54.0885, 54.0702, 54.0885, 54.0885, 54.0885, 54.0702, 54.0159,\n",
      "         54.0702, 54.0702, 54.0702,  0.1000, 54.0702, 54.0159,  0.1000, 54.0159,\n",
      "         54.0885,  0.1000, 54.0885, 54.0885, 54.0885, 54.0702, 54.0702,  0.1000,\n",
      "         54.0885,  0.1000, 53.9744, 53.9744, 54.0702, 54.0885, 54.0885,  0.1000,\n",
      "          0.1000, 53.9744, 54.0702, 54.0885,  0.1000, 54.0702, 54.0885,  0.1000,\n",
      "         53.9744, 54.0885]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 412 was 98.6%\n",
      "current params: tensor([53.9744, 54.0702, 54.0159, 54.0885], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.3\n",
      "SLow rates:  tensor([[54.0751, 54.1709, 54.1166, 54.1892,  0.1000,  0.1000,  0.1000, 54.0751,\n",
      "         54.0751, 54.0751,  0.1000,  0.1000, 54.1709, 54.1709, 54.1709,  0.1000,\n",
      "          0.1000, 54.1709, 54.1709,  0.1000, 54.1166, 54.1166, 54.1166,  0.1000,\n",
      "          0.1000, 54.1166, 54.1166,  0.1000, 54.1166,  0.1000, 54.1166, 54.1892,\n",
      "         54.1892, 54.1892,  0.1000,  0.1000, 54.1892, 54.1892,  0.1000, 54.1892,\n",
      "          0.1000, 54.1892, 54.1709, 54.1892, 54.1892, 54.1892, 54.1166, 54.1892,\n",
      "         54.1892, 54.1892, 54.1709, 54.1892, 54.1892, 54.1892, 54.1709, 54.1166,\n",
      "         54.1709, 54.1709, 54.1709,  0.1000, 54.1709, 54.1166,  0.1000, 54.1166,\n",
      "         54.1892,  0.1000, 54.1892, 54.1892, 54.1892, 54.1709, 54.1709,  0.1000,\n",
      "         54.1892,  0.1000, 54.0751, 54.0751, 54.1709, 54.1892, 54.1892,  0.1000,\n",
      "          0.1000, 54.0751, 54.1709, 54.1892,  0.1000, 54.1709, 54.1892,  0.1000,\n",
      "         54.0751, 54.1892]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 413 was 98.6%\n",
      "current params: tensor([54.0751, 54.1709, 54.1166, 54.1892], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.4\n",
      "SLow rates:  tensor([[54.1759, 54.2717, 54.2174, 54.2899,  0.1000,  0.1000,  0.1000, 54.1759,\n",
      "         54.1759, 54.1759,  0.1000,  0.1000, 54.2717, 54.2717, 54.2717,  0.1000,\n",
      "          0.1000, 54.2717, 54.2717,  0.1000, 54.2174, 54.2174, 54.2174,  0.1000,\n",
      "          0.1000, 54.2174, 54.2174,  0.1000, 54.2174,  0.1000, 54.2174, 54.2899,\n",
      "         54.2899, 54.2899,  0.1000,  0.1000, 54.2899, 54.2899,  0.1000, 54.2899,\n",
      "          0.1000, 54.2899, 54.2717, 54.2899, 54.2899, 54.2899, 54.2174, 54.2899,\n",
      "         54.2899, 54.2899, 54.2717, 54.2899, 54.2899, 54.2899, 54.2717, 54.2174,\n",
      "         54.2717, 54.2717, 54.2717,  0.1000, 54.2717, 54.2174,  0.1000, 54.2174,\n",
      "         54.2899,  0.1000, 54.2899, 54.2899, 54.2899, 54.2717, 54.2717,  0.1000,\n",
      "         54.2899,  0.1000, 54.1759, 54.1759, 54.2717, 54.2899, 54.2899,  0.1000,\n",
      "          0.1000, 54.1759, 54.2717, 54.2899,  0.1000, 54.2717, 54.2899,  0.1000,\n",
      "         54.1759, 54.2899]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 414 was 98.6%\n",
      "current params: tensor([54.1759, 54.2717, 54.2174, 54.2899], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.4\n",
      "SLow rates:  tensor([[54.2767, 54.3724, 54.3181, 54.3907,  0.1000,  0.1000,  0.1000, 54.2767,\n",
      "         54.2767, 54.2767,  0.1000,  0.1000, 54.3724, 54.3724, 54.3724,  0.1000,\n",
      "          0.1000, 54.3724, 54.3724,  0.1000, 54.3181, 54.3181, 54.3181,  0.1000,\n",
      "          0.1000, 54.3181, 54.3181,  0.1000, 54.3181,  0.1000, 54.3181, 54.3907,\n",
      "         54.3907, 54.3907,  0.1000,  0.1000, 54.3907, 54.3907,  0.1000, 54.3907,\n",
      "          0.1000, 54.3907, 54.3724, 54.3907, 54.3907, 54.3907, 54.3181, 54.3907,\n",
      "         54.3907, 54.3907, 54.3724, 54.3907, 54.3907, 54.3907, 54.3724, 54.3181,\n",
      "         54.3724, 54.3724, 54.3724,  0.1000, 54.3724, 54.3181,  0.1000, 54.3181,\n",
      "         54.3907,  0.1000, 54.3907, 54.3907, 54.3907, 54.3724, 54.3724,  0.1000,\n",
      "         54.3907,  0.1000, 54.2767, 54.2767, 54.3724, 54.3907, 54.3907,  0.1000,\n",
      "          0.1000, 54.2767, 54.3724, 54.3907,  0.1000, 54.3724, 54.3907,  0.1000,\n",
      "         54.2767, 54.3907]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 415 was 98.6%\n",
      "current params: tensor([54.2767, 54.3724, 54.3181, 54.3907], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.4\n",
      "SLow rates:  tensor([[54.3774, 54.4731, 54.4189, 54.4914,  0.1000,  0.1000,  0.1000, 54.3774,\n",
      "         54.3774, 54.3774,  0.1000,  0.1000, 54.4731, 54.4731, 54.4731,  0.1000,\n",
      "          0.1000, 54.4731, 54.4731,  0.1000, 54.4189, 54.4189, 54.4189,  0.1000,\n",
      "          0.1000, 54.4189, 54.4189,  0.1000, 54.4189,  0.1000, 54.4189, 54.4914,\n",
      "         54.4914, 54.4914,  0.1000,  0.1000, 54.4914, 54.4914,  0.1000, 54.4914,\n",
      "          0.1000, 54.4914, 54.4731, 54.4914, 54.4914, 54.4914, 54.4189, 54.4914,\n",
      "         54.4914, 54.4914, 54.4731, 54.4914, 54.4914, 54.4914, 54.4731, 54.4189,\n",
      "         54.4731, 54.4731, 54.4731,  0.1000, 54.4731, 54.4189,  0.1000, 54.4189,\n",
      "         54.4914,  0.1000, 54.4914, 54.4914, 54.4914, 54.4731, 54.4731,  0.1000,\n",
      "         54.4914,  0.1000, 54.3774, 54.3774, 54.4731, 54.4914, 54.4914,  0.1000,\n",
      "          0.1000, 54.3774, 54.4731, 54.4914,  0.1000, 54.4731, 54.4914,  0.1000,\n",
      "         54.3774, 54.4914]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 416 was 98.6%\n",
      "current params: tensor([54.3774, 54.4731, 54.4189, 54.4914], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.4\n",
      "SLow rates:  tensor([[54.4781, 54.5739, 54.5196, 54.5921,  0.1000,  0.1000,  0.1000, 54.4781,\n",
      "         54.4781, 54.4781,  0.1000,  0.1000, 54.5739, 54.5739, 54.5739,  0.1000,\n",
      "          0.1000, 54.5739, 54.5739,  0.1000, 54.5196, 54.5196, 54.5196,  0.1000,\n",
      "          0.1000, 54.5196, 54.5196,  0.1000, 54.5196,  0.1000, 54.5196, 54.5921,\n",
      "         54.5921, 54.5921,  0.1000,  0.1000, 54.5921, 54.5921,  0.1000, 54.5921,\n",
      "          0.1000, 54.5921, 54.5739, 54.5921, 54.5921, 54.5921, 54.5196, 54.5921,\n",
      "         54.5921, 54.5921, 54.5739, 54.5921, 54.5921, 54.5921, 54.5739, 54.5196,\n",
      "         54.5739, 54.5739, 54.5739,  0.1000, 54.5739, 54.5196,  0.1000, 54.5196,\n",
      "         54.5921,  0.1000, 54.5921, 54.5921, 54.5921, 54.5739, 54.5739,  0.1000,\n",
      "         54.5921,  0.1000, 54.4781, 54.4781, 54.5739, 54.5921, 54.5921,  0.1000,\n",
      "          0.1000, 54.4781, 54.5739, 54.5921,  0.1000, 54.5739, 54.5921,  0.1000,\n",
      "         54.4781, 54.5921]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 417 was 98.6%\n",
      "current params: tensor([54.4781, 54.5739, 54.5196, 54.5921], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.4\n",
      "SLow rates:  tensor([[54.5789, 54.6746, 54.6203, 54.6928,  0.1000,  0.1000,  0.1000, 54.5789,\n",
      "         54.5789, 54.5789,  0.1000,  0.1000, 54.6746, 54.6746, 54.6746,  0.1000,\n",
      "          0.1000, 54.6746, 54.6746,  0.1000, 54.6203, 54.6203, 54.6203,  0.1000,\n",
      "          0.1000, 54.6203, 54.6203,  0.1000, 54.6203,  0.1000, 54.6203, 54.6928,\n",
      "         54.6928, 54.6928,  0.1000,  0.1000, 54.6928, 54.6928,  0.1000, 54.6928,\n",
      "          0.1000, 54.6928, 54.6746, 54.6928, 54.6928, 54.6928, 54.6203, 54.6928,\n",
      "         54.6928, 54.6928, 54.6746, 54.6928, 54.6928, 54.6928, 54.6746, 54.6203,\n",
      "         54.6746, 54.6746, 54.6746,  0.1000, 54.6746, 54.6203,  0.1000, 54.6203,\n",
      "         54.6928,  0.1000, 54.6928, 54.6928, 54.6928, 54.6746, 54.6746,  0.1000,\n",
      "         54.6928,  0.1000, 54.5789, 54.5789, 54.6746, 54.6928, 54.6928,  0.1000,\n",
      "          0.1000, 54.5789, 54.6746, 54.6928,  0.1000, 54.6746, 54.6928,  0.1000,\n",
      "         54.5789, 54.6928]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 418 was 98.6%\n",
      "current params: tensor([54.5789, 54.6746, 54.6203, 54.6928], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.5\n",
      "SLow rates:  tensor([[54.6796, 54.7753, 54.7211, 54.7935,  0.1000,  0.1000,  0.1000, 54.6796,\n",
      "         54.6796, 54.6796,  0.1000,  0.1000, 54.7753, 54.7753, 54.7753,  0.1000,\n",
      "          0.1000, 54.7753, 54.7753,  0.1000, 54.7211, 54.7211, 54.7211,  0.1000,\n",
      "          0.1000, 54.7211, 54.7211,  0.1000, 54.7211,  0.1000, 54.7211, 54.7935,\n",
      "         54.7935, 54.7935,  0.1000,  0.1000, 54.7935, 54.7935,  0.1000, 54.7935,\n",
      "          0.1000, 54.7935, 54.7753, 54.7935, 54.7935, 54.7935, 54.7211, 54.7935,\n",
      "         54.7935, 54.7935, 54.7753, 54.7935, 54.7935, 54.7935, 54.7753, 54.7211,\n",
      "         54.7753, 54.7753, 54.7753,  0.1000, 54.7753, 54.7211,  0.1000, 54.7211,\n",
      "         54.7935,  0.1000, 54.7935, 54.7935, 54.7935, 54.7753, 54.7753,  0.1000,\n",
      "         54.7935,  0.1000, 54.6796, 54.6796, 54.7753, 54.7935, 54.7935,  0.1000,\n",
      "          0.1000, 54.6796, 54.7753, 54.7935,  0.1000, 54.7753, 54.7935,  0.1000,\n",
      "         54.6796, 54.7935]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 419 was 98.6%\n",
      "current params: tensor([54.6796, 54.7753, 54.7211, 54.7935], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.5\n",
      "SLow rates:  tensor([[54.7803, 54.8760, 54.8218, 54.8942,  0.1000,  0.1000,  0.1000, 54.7803,\n",
      "         54.7803, 54.7803,  0.1000,  0.1000, 54.8760, 54.8760, 54.8760,  0.1000,\n",
      "          0.1000, 54.8760, 54.8760,  0.1000, 54.8218, 54.8218, 54.8218,  0.1000,\n",
      "          0.1000, 54.8218, 54.8218,  0.1000, 54.8218,  0.1000, 54.8218, 54.8942,\n",
      "         54.8942, 54.8942,  0.1000,  0.1000, 54.8942, 54.8942,  0.1000, 54.8942,\n",
      "          0.1000, 54.8942, 54.8760, 54.8942, 54.8942, 54.8942, 54.8218, 54.8942,\n",
      "         54.8942, 54.8942, 54.8760, 54.8942, 54.8942, 54.8942, 54.8760, 54.8218,\n",
      "         54.8760, 54.8760, 54.8760,  0.1000, 54.8760, 54.8218,  0.1000, 54.8218,\n",
      "         54.8942,  0.1000, 54.8942, 54.8942, 54.8942, 54.8760, 54.8760,  0.1000,\n",
      "         54.8942,  0.1000, 54.7803, 54.7803, 54.8760, 54.8942, 54.8942,  0.1000,\n",
      "          0.1000, 54.7803, 54.8760, 54.8942,  0.1000, 54.8760, 54.8942,  0.1000,\n",
      "         54.7803, 54.8942]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 420 was 98.6%\n",
      "current params: tensor([54.7803, 54.8760, 54.8218, 54.8942], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.5\n",
      "SLow rates:  tensor([[54.8810, 54.9767, 54.9225, 54.9949,  0.1000,  0.1000,  0.1000, 54.8810,\n",
      "         54.8810, 54.8810,  0.1000,  0.1000, 54.9767, 54.9767, 54.9767,  0.1000,\n",
      "          0.1000, 54.9767, 54.9767,  0.1000, 54.9225, 54.9225, 54.9225,  0.1000,\n",
      "          0.1000, 54.9225, 54.9225,  0.1000, 54.9225,  0.1000, 54.9225, 54.9949,\n",
      "         54.9949, 54.9949,  0.1000,  0.1000, 54.9949, 54.9949,  0.1000, 54.9949,\n",
      "          0.1000, 54.9949, 54.9767, 54.9949, 54.9949, 54.9949, 54.9225, 54.9949,\n",
      "         54.9949, 54.9949, 54.9767, 54.9949, 54.9949, 54.9949, 54.9767, 54.9225,\n",
      "         54.9767, 54.9767, 54.9767,  0.1000, 54.9767, 54.9225,  0.1000, 54.9225,\n",
      "         54.9949,  0.1000, 54.9949, 54.9949, 54.9949, 54.9767, 54.9767,  0.1000,\n",
      "         54.9949,  0.1000, 54.8810, 54.8810, 54.9767, 54.9949, 54.9949,  0.1000,\n",
      "          0.1000, 54.8810, 54.9767, 54.9949,  0.1000, 54.9767, 54.9949,  0.1000,\n",
      "         54.8810, 54.9949]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 421 was 98.6%\n",
      "current params: tensor([54.8810, 54.9767, 54.9225, 54.9949], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.5\n",
      "SLow rates:  tensor([[54.9817, 55.0774, 55.0232, 55.0956,  0.1000,  0.1000,  0.1000, 54.9817,\n",
      "         54.9817, 54.9817,  0.1000,  0.1000, 55.0774, 55.0774, 55.0774,  0.1000,\n",
      "          0.1000, 55.0774, 55.0774,  0.1000, 55.0232, 55.0232, 55.0232,  0.1000,\n",
      "          0.1000, 55.0232, 55.0232,  0.1000, 55.0232,  0.1000, 55.0232, 55.0956,\n",
      "         55.0956, 55.0956,  0.1000,  0.1000, 55.0956, 55.0956,  0.1000, 55.0956,\n",
      "          0.1000, 55.0956, 55.0774, 55.0956, 55.0956, 55.0956, 55.0232, 55.0956,\n",
      "         55.0956, 55.0956, 55.0774, 55.0956, 55.0956, 55.0956, 55.0774, 55.0232,\n",
      "         55.0774, 55.0774, 55.0774,  0.1000, 55.0774, 55.0232,  0.1000, 55.0232,\n",
      "         55.0956,  0.1000, 55.0956, 55.0956, 55.0956, 55.0774, 55.0774,  0.1000,\n",
      "         55.0956,  0.1000, 54.9817, 54.9817, 55.0774, 55.0956, 55.0956,  0.1000,\n",
      "          0.1000, 54.9817, 55.0774, 55.0956,  0.1000, 55.0774, 55.0956,  0.1000,\n",
      "         54.9817, 55.0956]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 422 was 98.6%\n",
      "current params: tensor([54.9817, 55.0774, 55.0232, 55.0956], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.5\n",
      "SLow rates:  tensor([[55.0824, 55.1781, 55.1239, 55.1963,  0.1000,  0.1000,  0.1000, 55.0824,\n",
      "         55.0824, 55.0824,  0.1000,  0.1000, 55.1781, 55.1781, 55.1781,  0.1000,\n",
      "          0.1000, 55.1781, 55.1781,  0.1000, 55.1239, 55.1239, 55.1239,  0.1000,\n",
      "          0.1000, 55.1239, 55.1239,  0.1000, 55.1239,  0.1000, 55.1239, 55.1963,\n",
      "         55.1963, 55.1963,  0.1000,  0.1000, 55.1963, 55.1963,  0.1000, 55.1963,\n",
      "          0.1000, 55.1963, 55.1781, 55.1963, 55.1963, 55.1963, 55.1239, 55.1963,\n",
      "         55.1963, 55.1963, 55.1781, 55.1963, 55.1963, 55.1963, 55.1781, 55.1239,\n",
      "         55.1781, 55.1781, 55.1781,  0.1000, 55.1781, 55.1239,  0.1000, 55.1239,\n",
      "         55.1963,  0.1000, 55.1963, 55.1963, 55.1963, 55.1781, 55.1781,  0.1000,\n",
      "         55.1963,  0.1000, 55.0824, 55.0824, 55.1781, 55.1963, 55.1963,  0.1000,\n",
      "          0.1000, 55.0824, 55.1781, 55.1963,  0.1000, 55.1781, 55.1963,  0.1000,\n",
      "         55.0824, 55.1963]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 423 was 98.6%\n",
      "current params: tensor([55.0824, 55.1781, 55.1239, 55.1963], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.5\n",
      "SLow rates:  tensor([[55.1831, 55.2788, 55.2245, 55.2969,  0.1000,  0.1000,  0.1000, 55.1831,\n",
      "         55.1831, 55.1831,  0.1000,  0.1000, 55.2788, 55.2788, 55.2788,  0.1000,\n",
      "          0.1000, 55.2788, 55.2788,  0.1000, 55.2245, 55.2245, 55.2245,  0.1000,\n",
      "          0.1000, 55.2245, 55.2245,  0.1000, 55.2245,  0.1000, 55.2245, 55.2969,\n",
      "         55.2969, 55.2969,  0.1000,  0.1000, 55.2969, 55.2969,  0.1000, 55.2969,\n",
      "          0.1000, 55.2969, 55.2788, 55.2969, 55.2969, 55.2969, 55.2245, 55.2969,\n",
      "         55.2969, 55.2969, 55.2788, 55.2969, 55.2969, 55.2969, 55.2788, 55.2245,\n",
      "         55.2788, 55.2788, 55.2788,  0.1000, 55.2788, 55.2245,  0.1000, 55.2245,\n",
      "         55.2969,  0.1000, 55.2969, 55.2969, 55.2969, 55.2788, 55.2788,  0.1000,\n",
      "         55.2969,  0.1000, 55.1831, 55.1831, 55.2788, 55.2969, 55.2969,  0.1000,\n",
      "          0.1000, 55.1831, 55.2788, 55.2969,  0.1000, 55.2788, 55.2969,  0.1000,\n",
      "         55.1831, 55.2969]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 424 was 98.6%\n",
      "current params: tensor([55.1831, 55.2788, 55.2245, 55.2969], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.6\n",
      "SLow rates:  tensor([[55.2838, 55.3794, 55.3252, 55.3976,  0.1000,  0.1000,  0.1000, 55.2838,\n",
      "         55.2838, 55.2838,  0.1000,  0.1000, 55.3794, 55.3794, 55.3794,  0.1000,\n",
      "          0.1000, 55.3794, 55.3794,  0.1000, 55.3252, 55.3252, 55.3252,  0.1000,\n",
      "          0.1000, 55.3252, 55.3252,  0.1000, 55.3252,  0.1000, 55.3252, 55.3976,\n",
      "         55.3976, 55.3976,  0.1000,  0.1000, 55.3976, 55.3976,  0.1000, 55.3976,\n",
      "          0.1000, 55.3976, 55.3794, 55.3976, 55.3976, 55.3976, 55.3252, 55.3976,\n",
      "         55.3976, 55.3976, 55.3794, 55.3976, 55.3976, 55.3976, 55.3794, 55.3252,\n",
      "         55.3794, 55.3794, 55.3794,  0.1000, 55.3794, 55.3252,  0.1000, 55.3252,\n",
      "         55.3976,  0.1000, 55.3976, 55.3976, 55.3976, 55.3794, 55.3794,  0.1000,\n",
      "         55.3976,  0.1000, 55.2838, 55.2838, 55.3794, 55.3976, 55.3976,  0.1000,\n",
      "          0.1000, 55.2838, 55.3794, 55.3976,  0.1000, 55.3794, 55.3976,  0.1000,\n",
      "         55.2838, 55.3976]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 425 was 98.6%\n",
      "current params: tensor([55.2838, 55.3794, 55.3252, 55.3976], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.6\n",
      "SLow rates:  tensor([[55.3845, 55.4801, 55.4259, 55.4982,  0.1000,  0.1000,  0.1000, 55.3845,\n",
      "         55.3845, 55.3845,  0.1000,  0.1000, 55.4801, 55.4801, 55.4801,  0.1000,\n",
      "          0.1000, 55.4801, 55.4801,  0.1000, 55.4259, 55.4259, 55.4259,  0.1000,\n",
      "          0.1000, 55.4259, 55.4259,  0.1000, 55.4259,  0.1000, 55.4259, 55.4982,\n",
      "         55.4982, 55.4982,  0.1000,  0.1000, 55.4982, 55.4982,  0.1000, 55.4982,\n",
      "          0.1000, 55.4982, 55.4801, 55.4982, 55.4982, 55.4982, 55.4259, 55.4982,\n",
      "         55.4982, 55.4982, 55.4801, 55.4982, 55.4982, 55.4982, 55.4801, 55.4259,\n",
      "         55.4801, 55.4801, 55.4801,  0.1000, 55.4801, 55.4259,  0.1000, 55.4259,\n",
      "         55.4982,  0.1000, 55.4982, 55.4982, 55.4982, 55.4801, 55.4801,  0.1000,\n",
      "         55.4982,  0.1000, 55.3845, 55.3845, 55.4801, 55.4982, 55.4982,  0.1000,\n",
      "          0.1000, 55.3845, 55.4801, 55.4982,  0.1000, 55.4801, 55.4982,  0.1000,\n",
      "         55.3845, 55.4982]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 426 was 98.6%\n",
      "current params: tensor([55.3845, 55.4801, 55.4259, 55.4982], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.6\n",
      "SLow rates:  tensor([[55.4852, 55.5807, 55.5265, 55.5989,  0.1000,  0.1000,  0.1000, 55.4852,\n",
      "         55.4852, 55.4852,  0.1000,  0.1000, 55.5807, 55.5807, 55.5807,  0.1000,\n",
      "          0.1000, 55.5807, 55.5807,  0.1000, 55.5265, 55.5265, 55.5265,  0.1000,\n",
      "          0.1000, 55.5265, 55.5265,  0.1000, 55.5265,  0.1000, 55.5265, 55.5989,\n",
      "         55.5989, 55.5989,  0.1000,  0.1000, 55.5989, 55.5989,  0.1000, 55.5989,\n",
      "          0.1000, 55.5989, 55.5807, 55.5989, 55.5989, 55.5989, 55.5265, 55.5989,\n",
      "         55.5989, 55.5989, 55.5807, 55.5989, 55.5989, 55.5989, 55.5807, 55.5265,\n",
      "         55.5807, 55.5807, 55.5807,  0.1000, 55.5807, 55.5265,  0.1000, 55.5265,\n",
      "         55.5989,  0.1000, 55.5989, 55.5989, 55.5989, 55.5807, 55.5807,  0.1000,\n",
      "         55.5989,  0.1000, 55.4852, 55.4852, 55.5807, 55.5989, 55.5989,  0.1000,\n",
      "          0.1000, 55.4852, 55.5807, 55.5989,  0.1000, 55.5807, 55.5989,  0.1000,\n",
      "         55.4852, 55.5989]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 427 was 98.6%\n",
      "current params: tensor([55.4852, 55.5807, 55.5265, 55.5989], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.6\n",
      "SLow rates:  tensor([[55.5858, 55.6814, 55.6272, 55.6995,  0.1000,  0.1000,  0.1000, 55.5858,\n",
      "         55.5858, 55.5858,  0.1000,  0.1000, 55.6814, 55.6814, 55.6814,  0.1000,\n",
      "          0.1000, 55.6814, 55.6814,  0.1000, 55.6272, 55.6272, 55.6272,  0.1000,\n",
      "          0.1000, 55.6272, 55.6272,  0.1000, 55.6272,  0.1000, 55.6272, 55.6995,\n",
      "         55.6995, 55.6995,  0.1000,  0.1000, 55.6995, 55.6995,  0.1000, 55.6995,\n",
      "          0.1000, 55.6995, 55.6814, 55.6995, 55.6995, 55.6995, 55.6272, 55.6995,\n",
      "         55.6995, 55.6995, 55.6814, 55.6995, 55.6995, 55.6995, 55.6814, 55.6272,\n",
      "         55.6814, 55.6814, 55.6814,  0.1000, 55.6814, 55.6272,  0.1000, 55.6272,\n",
      "         55.6995,  0.1000, 55.6995, 55.6995, 55.6995, 55.6814, 55.6814,  0.1000,\n",
      "         55.6995,  0.1000, 55.5858, 55.5858, 55.6814, 55.6995, 55.6995,  0.1000,\n",
      "          0.1000, 55.5858, 55.6814, 55.6995,  0.1000, 55.6814, 55.6995,  0.1000,\n",
      "         55.5858, 55.6995]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 428 was 98.6%\n",
      "current params: tensor([55.5858, 55.6814, 55.6272, 55.6995], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.6\n",
      "SLow rates:  tensor([[55.6865, 55.7820, 55.7279, 55.8002,  0.1000,  0.1000,  0.1000, 55.6865,\n",
      "         55.6865, 55.6865,  0.1000,  0.1000, 55.7820, 55.7820, 55.7820,  0.1000,\n",
      "          0.1000, 55.7820, 55.7820,  0.1000, 55.7279, 55.7279, 55.7279,  0.1000,\n",
      "          0.1000, 55.7279, 55.7279,  0.1000, 55.7279,  0.1000, 55.7279, 55.8002,\n",
      "         55.8002, 55.8002,  0.1000,  0.1000, 55.8002, 55.8002,  0.1000, 55.8002,\n",
      "          0.1000, 55.8002, 55.7820, 55.8002, 55.8002, 55.8002, 55.7279, 55.8002,\n",
      "         55.8002, 55.8002, 55.7820, 55.8002, 55.8002, 55.8002, 55.7820, 55.7279,\n",
      "         55.7820, 55.7820, 55.7820,  0.1000, 55.7820, 55.7279,  0.1000, 55.7279,\n",
      "         55.8002,  0.1000, 55.8002, 55.8002, 55.8002, 55.7820, 55.7820,  0.1000,\n",
      "         55.8002,  0.1000, 55.6865, 55.6865, 55.7820, 55.8002, 55.8002,  0.1000,\n",
      "          0.1000, 55.6865, 55.7820, 55.8002,  0.1000, 55.7820, 55.8002,  0.1000,\n",
      "         55.6865, 55.8002]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 429 was 98.6%\n",
      "current params: tensor([55.6865, 55.7820, 55.7279, 55.8002], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.7\n",
      "SLow rates:  tensor([[55.7871, 55.8827, 55.8285, 55.9008,  0.1000,  0.1000,  0.1000, 55.7871,\n",
      "         55.7871, 55.7871,  0.1000,  0.1000, 55.8827, 55.8827, 55.8827,  0.1000,\n",
      "          0.1000, 55.8827, 55.8827,  0.1000, 55.8285, 55.8285, 55.8285,  0.1000,\n",
      "          0.1000, 55.8285, 55.8285,  0.1000, 55.8285,  0.1000, 55.8285, 55.9008,\n",
      "         55.9008, 55.9008,  0.1000,  0.1000, 55.9008, 55.9008,  0.1000, 55.9008,\n",
      "          0.1000, 55.9008, 55.8827, 55.9008, 55.9008, 55.9008, 55.8285, 55.9008,\n",
      "         55.9008, 55.9008, 55.8827, 55.9008, 55.9008, 55.9008, 55.8827, 55.8285,\n",
      "         55.8827, 55.8827, 55.8827,  0.1000, 55.8827, 55.8285,  0.1000, 55.8285,\n",
      "         55.9008,  0.1000, 55.9008, 55.9008, 55.9008, 55.8827, 55.8827,  0.1000,\n",
      "         55.9008,  0.1000, 55.7871, 55.7871, 55.8827, 55.9008, 55.9008,  0.1000,\n",
      "          0.1000, 55.7871, 55.8827, 55.9008,  0.1000, 55.8827, 55.9008,  0.1000,\n",
      "         55.7871, 55.9008]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 430 was 98.6%\n",
      "current params: tensor([55.7871, 55.8827, 55.8285, 55.9008], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.7\n",
      "SLow rates:  tensor([[55.8878, 55.9833, 55.9291, 56.0014,  0.1000,  0.1000,  0.1000, 55.8878,\n",
      "         55.8878, 55.8878,  0.1000,  0.1000, 55.9833, 55.9833, 55.9833,  0.1000,\n",
      "          0.1000, 55.9833, 55.9833,  0.1000, 55.9291, 55.9291, 55.9291,  0.1000,\n",
      "          0.1000, 55.9291, 55.9291,  0.1000, 55.9291,  0.1000, 55.9291, 56.0014,\n",
      "         56.0014, 56.0014,  0.1000,  0.1000, 56.0014, 56.0014,  0.1000, 56.0014,\n",
      "          0.1000, 56.0014, 55.9833, 56.0014, 56.0014, 56.0014, 55.9291, 56.0014,\n",
      "         56.0014, 56.0014, 55.9833, 56.0014, 56.0014, 56.0014, 55.9833, 55.9291,\n",
      "         55.9833, 55.9833, 55.9833,  0.1000, 55.9833, 55.9291,  0.1000, 55.9291,\n",
      "         56.0014,  0.1000, 56.0014, 56.0014, 56.0014, 55.9833, 55.9833,  0.1000,\n",
      "         56.0014,  0.1000, 55.8878, 55.8878, 55.9833, 56.0014, 56.0014,  0.1000,\n",
      "          0.1000, 55.8878, 55.9833, 56.0014,  0.1000, 55.9833, 56.0014,  0.1000,\n",
      "         55.8878, 56.0014]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 431 was 98.6%\n",
      "current params: tensor([55.8878, 55.9833, 55.9291, 56.0014], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.7\n",
      "SLow rates:  tensor([[55.9884, 56.0839, 56.0298, 56.1020,  0.1000,  0.1000,  0.1000, 55.9884,\n",
      "         55.9884, 55.9884,  0.1000,  0.1000, 56.0839, 56.0839, 56.0839,  0.1000,\n",
      "          0.1000, 56.0839, 56.0839,  0.1000, 56.0298, 56.0298, 56.0298,  0.1000,\n",
      "          0.1000, 56.0298, 56.0298,  0.1000, 56.0298,  0.1000, 56.0298, 56.1020,\n",
      "         56.1020, 56.1020,  0.1000,  0.1000, 56.1020, 56.1020,  0.1000, 56.1020,\n",
      "          0.1000, 56.1020, 56.0839, 56.1020, 56.1020, 56.1020, 56.0298, 56.1020,\n",
      "         56.1020, 56.1020, 56.0839, 56.1020, 56.1020, 56.1020, 56.0839, 56.0298,\n",
      "         56.0839, 56.0839, 56.0839,  0.1000, 56.0839, 56.0298,  0.1000, 56.0298,\n",
      "         56.1020,  0.1000, 56.1020, 56.1020, 56.1020, 56.0839, 56.0839,  0.1000,\n",
      "         56.1020,  0.1000, 55.9884, 55.9884, 56.0839, 56.1020, 56.1020,  0.1000,\n",
      "          0.1000, 55.9884, 56.0839, 56.1020,  0.1000, 56.0839, 56.1020,  0.1000,\n",
      "         55.9884, 56.1020]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 432 was 98.6%\n",
      "current params: tensor([55.9884, 56.0839, 56.0298, 56.1020], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.7\n",
      "SLow rates:  tensor([[56.0890, 56.1845, 56.1304, 56.2026,  0.1000,  0.1000,  0.1000, 56.0890,\n",
      "         56.0890, 56.0890,  0.1000,  0.1000, 56.1845, 56.1845, 56.1845,  0.1000,\n",
      "          0.1000, 56.1845, 56.1845,  0.1000, 56.1304, 56.1304, 56.1304,  0.1000,\n",
      "          0.1000, 56.1304, 56.1304,  0.1000, 56.1304,  0.1000, 56.1304, 56.2026,\n",
      "         56.2026, 56.2026,  0.1000,  0.1000, 56.2026, 56.2026,  0.1000, 56.2026,\n",
      "          0.1000, 56.2026, 56.1845, 56.2026, 56.2026, 56.2026, 56.1304, 56.2026,\n",
      "         56.2026, 56.2026, 56.1845, 56.2026, 56.2026, 56.2026, 56.1845, 56.1304,\n",
      "         56.1845, 56.1845, 56.1845,  0.1000, 56.1845, 56.1304,  0.1000, 56.1304,\n",
      "         56.2026,  0.1000, 56.2026, 56.2026, 56.2026, 56.1845, 56.1845,  0.1000,\n",
      "         56.2026,  0.1000, 56.0890, 56.0890, 56.1845, 56.2026, 56.2026,  0.1000,\n",
      "          0.1000, 56.0890, 56.1845, 56.2026,  0.1000, 56.1845, 56.2026,  0.1000,\n",
      "         56.0890, 56.2026]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 433 was 98.6%\n",
      "current params: tensor([56.0890, 56.1845, 56.1304, 56.2026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.7\n",
      "SLow rates:  tensor([[56.1897, 56.2851, 56.2310, 56.3032,  0.1000,  0.1000,  0.1000, 56.1897,\n",
      "         56.1897, 56.1897,  0.1000,  0.1000, 56.2851, 56.2851, 56.2851,  0.1000,\n",
      "          0.1000, 56.2851, 56.2851,  0.1000, 56.2310, 56.2310, 56.2310,  0.1000,\n",
      "          0.1000, 56.2310, 56.2310,  0.1000, 56.2310,  0.1000, 56.2310, 56.3032,\n",
      "         56.3032, 56.3032,  0.1000,  0.1000, 56.3032, 56.3032,  0.1000, 56.3032,\n",
      "          0.1000, 56.3032, 56.2851, 56.3032, 56.3032, 56.3032, 56.2310, 56.3032,\n",
      "         56.3032, 56.3032, 56.2851, 56.3032, 56.3032, 56.3032, 56.2851, 56.2310,\n",
      "         56.2851, 56.2851, 56.2851,  0.1000, 56.2851, 56.2310,  0.1000, 56.2310,\n",
      "         56.3032,  0.1000, 56.3032, 56.3032, 56.3032, 56.2851, 56.2851,  0.1000,\n",
      "         56.3032,  0.1000, 56.1897, 56.1897, 56.2851, 56.3032, 56.3032,  0.1000,\n",
      "          0.1000, 56.1897, 56.2851, 56.3032,  0.1000, 56.2851, 56.3032,  0.1000,\n",
      "         56.1897, 56.3032]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 434 was 98.6%\n",
      "current params: tensor([56.1897, 56.2851, 56.2310, 56.3032], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.8\n",
      "SLow rates:  tensor([[56.2903, 56.3857, 56.3316, 56.4038,  0.1000,  0.1000,  0.1000, 56.2903,\n",
      "         56.2903, 56.2903,  0.1000,  0.1000, 56.3857, 56.3857, 56.3857,  0.1000,\n",
      "          0.1000, 56.3857, 56.3857,  0.1000, 56.3316, 56.3316, 56.3316,  0.1000,\n",
      "          0.1000, 56.3316, 56.3316,  0.1000, 56.3316,  0.1000, 56.3316, 56.4038,\n",
      "         56.4038, 56.4038,  0.1000,  0.1000, 56.4038, 56.4038,  0.1000, 56.4038,\n",
      "          0.1000, 56.4038, 56.3857, 56.4038, 56.4038, 56.4038, 56.3316, 56.4038,\n",
      "         56.4038, 56.4038, 56.3857, 56.4038, 56.4038, 56.4038, 56.3857, 56.3316,\n",
      "         56.3857, 56.3857, 56.3857,  0.1000, 56.3857, 56.3316,  0.1000, 56.3316,\n",
      "         56.4038,  0.1000, 56.4038, 56.4038, 56.4038, 56.3857, 56.3857,  0.1000,\n",
      "         56.4038,  0.1000, 56.2903, 56.2903, 56.3857, 56.4038, 56.4038,  0.1000,\n",
      "          0.1000, 56.2903, 56.3857, 56.4038,  0.1000, 56.3857, 56.4038,  0.1000,\n",
      "         56.2903, 56.4038]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 435 was 98.6%\n",
      "current params: tensor([56.2903, 56.3857, 56.3316, 56.4038], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.8\n",
      "SLow rates:  tensor([[56.3909, 56.4863, 56.4322, 56.5044,  0.1000,  0.1000,  0.1000, 56.3909,\n",
      "         56.3909, 56.3909,  0.1000,  0.1000, 56.4863, 56.4863, 56.4863,  0.1000,\n",
      "          0.1000, 56.4863, 56.4863,  0.1000, 56.4322, 56.4322, 56.4322,  0.1000,\n",
      "          0.1000, 56.4322, 56.4322,  0.1000, 56.4322,  0.1000, 56.4322, 56.5044,\n",
      "         56.5044, 56.5044,  0.1000,  0.1000, 56.5044, 56.5044,  0.1000, 56.5044,\n",
      "          0.1000, 56.5044, 56.4863, 56.5044, 56.5044, 56.5044, 56.4322, 56.5044,\n",
      "         56.5044, 56.5044, 56.4863, 56.5044, 56.5044, 56.5044, 56.4863, 56.4322,\n",
      "         56.4863, 56.4863, 56.4863,  0.1000, 56.4863, 56.4322,  0.1000, 56.4322,\n",
      "         56.5044,  0.1000, 56.5044, 56.5044, 56.5044, 56.4863, 56.4863,  0.1000,\n",
      "         56.5044,  0.1000, 56.3909, 56.3909, 56.4863, 56.5044, 56.5044,  0.1000,\n",
      "          0.1000, 56.3909, 56.4863, 56.5044,  0.1000, 56.4863, 56.5044,  0.1000,\n",
      "         56.3909, 56.5044]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 436 was 98.6%\n",
      "current params: tensor([56.3909, 56.4863, 56.4322, 56.5044], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.8\n",
      "SLow rates:  tensor([[56.4915, 56.5869, 56.5328, 56.6050,  0.1000,  0.1000,  0.1000, 56.4915,\n",
      "         56.4915, 56.4915,  0.1000,  0.1000, 56.5869, 56.5869, 56.5869,  0.1000,\n",
      "          0.1000, 56.5869, 56.5869,  0.1000, 56.5328, 56.5328, 56.5328,  0.1000,\n",
      "          0.1000, 56.5328, 56.5328,  0.1000, 56.5328,  0.1000, 56.5328, 56.6050,\n",
      "         56.6050, 56.6050,  0.1000,  0.1000, 56.6050, 56.6050,  0.1000, 56.6050,\n",
      "          0.1000, 56.6050, 56.5869, 56.6050, 56.6050, 56.6050, 56.5328, 56.6050,\n",
      "         56.6050, 56.6050, 56.5869, 56.6050, 56.6050, 56.6050, 56.5869, 56.5328,\n",
      "         56.5869, 56.5869, 56.5869,  0.1000, 56.5869, 56.5328,  0.1000, 56.5328,\n",
      "         56.6050,  0.1000, 56.6050, 56.6050, 56.6050, 56.5869, 56.5869,  0.1000,\n",
      "         56.6050,  0.1000, 56.4915, 56.4915, 56.5869, 56.6050, 56.6050,  0.1000,\n",
      "          0.1000, 56.4915, 56.5869, 56.6050,  0.1000, 56.5869, 56.6050,  0.1000,\n",
      "         56.4915, 56.6050]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 437 was 98.6%\n",
      "current params: tensor([56.4915, 56.5869, 56.5328, 56.6050], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.8\n",
      "SLow rates:  tensor([[56.5921, 56.6875, 56.6334, 56.7056,  0.1000,  0.1000,  0.1000, 56.5921,\n",
      "         56.5921, 56.5921,  0.1000,  0.1000, 56.6875, 56.6875, 56.6875,  0.1000,\n",
      "          0.1000, 56.6875, 56.6875,  0.1000, 56.6334, 56.6334, 56.6334,  0.1000,\n",
      "          0.1000, 56.6334, 56.6334,  0.1000, 56.6334,  0.1000, 56.6334, 56.7056,\n",
      "         56.7056, 56.7056,  0.1000,  0.1000, 56.7056, 56.7056,  0.1000, 56.7056,\n",
      "          0.1000, 56.7056, 56.6875, 56.7056, 56.7056, 56.7056, 56.6334, 56.7056,\n",
      "         56.7056, 56.7056, 56.6875, 56.7056, 56.7056, 56.7056, 56.6875, 56.6334,\n",
      "         56.6875, 56.6875, 56.6875,  0.1000, 56.6875, 56.6334,  0.1000, 56.6334,\n",
      "         56.7056,  0.1000, 56.7056, 56.7056, 56.7056, 56.6875, 56.6875,  0.1000,\n",
      "         56.7056,  0.1000, 56.5921, 56.5921, 56.6875, 56.7056, 56.7056,  0.1000,\n",
      "          0.1000, 56.5921, 56.6875, 56.7056,  0.1000, 56.6875, 56.7056,  0.1000,\n",
      "         56.5921, 56.7056]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 438 was 98.6%\n",
      "current params: tensor([56.5921, 56.6875, 56.6334, 56.7056], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.8\n",
      "SLow rates:  tensor([[56.6927, 56.7881, 56.7340, 56.8061,  0.1000,  0.1000,  0.1000, 56.6927,\n",
      "         56.6927, 56.6927,  0.1000,  0.1000, 56.7881, 56.7881, 56.7881,  0.1000,\n",
      "          0.1000, 56.7881, 56.7881,  0.1000, 56.7340, 56.7340, 56.7340,  0.1000,\n",
      "          0.1000, 56.7340, 56.7340,  0.1000, 56.7340,  0.1000, 56.7340, 56.8061,\n",
      "         56.8061, 56.8061,  0.1000,  0.1000, 56.8061, 56.8061,  0.1000, 56.8061,\n",
      "          0.1000, 56.8061, 56.7881, 56.8061, 56.8061, 56.8061, 56.7340, 56.8061,\n",
      "         56.8061, 56.8061, 56.7881, 56.8061, 56.8061, 56.8061, 56.7881, 56.7340,\n",
      "         56.7881, 56.7881, 56.7881,  0.1000, 56.7881, 56.7340,  0.1000, 56.7340,\n",
      "         56.8061,  0.1000, 56.8061, 56.8061, 56.8061, 56.7881, 56.7881,  0.1000,\n",
      "         56.8061,  0.1000, 56.6927, 56.6927, 56.7881, 56.8061, 56.8061,  0.1000,\n",
      "          0.1000, 56.6927, 56.7881, 56.8061,  0.1000, 56.7881, 56.8061,  0.1000,\n",
      "         56.6927, 56.8061]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 439 was 98.6%\n",
      "current params: tensor([56.6927, 56.7881, 56.7340, 56.8061], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.8\n",
      "SLow rates:  tensor([[56.7933, 56.8887, 56.8346, 56.9067,  0.1000,  0.1000,  0.1000, 56.7933,\n",
      "         56.7933, 56.7933,  0.1000,  0.1000, 56.8887, 56.8887, 56.8887,  0.1000,\n",
      "          0.1000, 56.8887, 56.8887,  0.1000, 56.8346, 56.8346, 56.8346,  0.1000,\n",
      "          0.1000, 56.8346, 56.8346,  0.1000, 56.8346,  0.1000, 56.8346, 56.9067,\n",
      "         56.9067, 56.9067,  0.1000,  0.1000, 56.9067, 56.9067,  0.1000, 56.9067,\n",
      "          0.1000, 56.9067, 56.8887, 56.9067, 56.9067, 56.9067, 56.8346, 56.9067,\n",
      "         56.9067, 56.9067, 56.8887, 56.9067, 56.9067, 56.9067, 56.8887, 56.8346,\n",
      "         56.8887, 56.8887, 56.8887,  0.1000, 56.8887, 56.8346,  0.1000, 56.8346,\n",
      "         56.9067,  0.1000, 56.9067, 56.9067, 56.9067, 56.8887, 56.8887,  0.1000,\n",
      "         56.9067,  0.1000, 56.7933, 56.7933, 56.8887, 56.9067, 56.9067,  0.1000,\n",
      "          0.1000, 56.7933, 56.8887, 56.9067,  0.1000, 56.8887, 56.9067,  0.1000,\n",
      "         56.7933, 56.9067]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 440 was 98.6%\n",
      "current params: tensor([56.7933, 56.8887, 56.8346, 56.9067], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.9\n",
      "SLow rates:  tensor([[56.8938, 56.9892, 56.9351, 57.0073,  0.1000,  0.1000,  0.1000, 56.8938,\n",
      "         56.8938, 56.8938,  0.1000,  0.1000, 56.9892, 56.9892, 56.9892,  0.1000,\n",
      "          0.1000, 56.9892, 56.9892,  0.1000, 56.9351, 56.9351, 56.9351,  0.1000,\n",
      "          0.1000, 56.9351, 56.9351,  0.1000, 56.9351,  0.1000, 56.9351, 57.0073,\n",
      "         57.0073, 57.0073,  0.1000,  0.1000, 57.0073, 57.0073,  0.1000, 57.0073,\n",
      "          0.1000, 57.0073, 56.9892, 57.0073, 57.0073, 57.0073, 56.9351, 57.0073,\n",
      "         57.0073, 57.0073, 56.9892, 57.0073, 57.0073, 57.0073, 56.9892, 56.9351,\n",
      "         56.9892, 56.9892, 56.9892,  0.1000, 56.9892, 56.9351,  0.1000, 56.9351,\n",
      "         57.0073,  0.1000, 57.0073, 57.0073, 57.0073, 56.9892, 56.9892,  0.1000,\n",
      "         57.0073,  0.1000, 56.8938, 56.8938, 56.9892, 57.0073, 57.0073,  0.1000,\n",
      "          0.1000, 56.8938, 56.9892, 57.0073,  0.1000, 56.9892, 57.0073,  0.1000,\n",
      "         56.8938, 57.0073]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 441 was 98.6%\n",
      "current params: tensor([56.8938, 56.9892, 56.9351, 57.0073], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.9\n",
      "SLow rates:  tensor([[56.9944, 57.0898, 57.0357, 57.1078,  0.1000,  0.1000,  0.1000, 56.9944,\n",
      "         56.9944, 56.9944,  0.1000,  0.1000, 57.0898, 57.0898, 57.0898,  0.1000,\n",
      "          0.1000, 57.0898, 57.0898,  0.1000, 57.0357, 57.0357, 57.0357,  0.1000,\n",
      "          0.1000, 57.0357, 57.0357,  0.1000, 57.0357,  0.1000, 57.0357, 57.1078,\n",
      "         57.1078, 57.1078,  0.1000,  0.1000, 57.1078, 57.1078,  0.1000, 57.1078,\n",
      "          0.1000, 57.1078, 57.0898, 57.1078, 57.1078, 57.1078, 57.0357, 57.1078,\n",
      "         57.1078, 57.1078, 57.0898, 57.1078, 57.1078, 57.1078, 57.0898, 57.0357,\n",
      "         57.0898, 57.0898, 57.0898,  0.1000, 57.0898, 57.0357,  0.1000, 57.0357,\n",
      "         57.1078,  0.1000, 57.1078, 57.1078, 57.1078, 57.0898, 57.0898,  0.1000,\n",
      "         57.1078,  0.1000, 56.9944, 56.9944, 57.0898, 57.1078, 57.1078,  0.1000,\n",
      "          0.1000, 56.9944, 57.0898, 57.1078,  0.1000, 57.0898, 57.1078,  0.1000,\n",
      "         56.9944, 57.1078]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 442 was 98.6%\n",
      "current params: tensor([56.9944, 57.0898, 57.0357, 57.1078], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.9\n",
      "SLow rates:  tensor([[57.0950, 57.1904, 57.1363, 57.2084,  0.1000,  0.1000,  0.1000, 57.0950,\n",
      "         57.0950, 57.0950,  0.1000,  0.1000, 57.1904, 57.1904, 57.1904,  0.1000,\n",
      "          0.1000, 57.1904, 57.1904,  0.1000, 57.1363, 57.1363, 57.1363,  0.1000,\n",
      "          0.1000, 57.1363, 57.1363,  0.1000, 57.1363,  0.1000, 57.1363, 57.2084,\n",
      "         57.2084, 57.2084,  0.1000,  0.1000, 57.2084, 57.2084,  0.1000, 57.2084,\n",
      "          0.1000, 57.2084, 57.1904, 57.2084, 57.2084, 57.2084, 57.1363, 57.2084,\n",
      "         57.2084, 57.2084, 57.1904, 57.2084, 57.2084, 57.2084, 57.1904, 57.1363,\n",
      "         57.1904, 57.1904, 57.1904,  0.1000, 57.1904, 57.1363,  0.1000, 57.1363,\n",
      "         57.2084,  0.1000, 57.2084, 57.2084, 57.2084, 57.1904, 57.1904,  0.1000,\n",
      "         57.2084,  0.1000, 57.0950, 57.0950, 57.1904, 57.2084, 57.2084,  0.1000,\n",
      "          0.1000, 57.0950, 57.1904, 57.2084,  0.1000, 57.1904, 57.2084,  0.1000,\n",
      "         57.0950, 57.2084]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 443 was 98.6%\n",
      "current params: tensor([57.0950, 57.1904, 57.1363, 57.2084], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.9\n",
      "SLow rates:  tensor([[57.1955, 57.2909, 57.2368, 57.3089,  0.1000,  0.1000,  0.1000, 57.1955,\n",
      "         57.1955, 57.1955,  0.1000,  0.1000, 57.2909, 57.2909, 57.2909,  0.1000,\n",
      "          0.1000, 57.2909, 57.2909,  0.1000, 57.2368, 57.2368, 57.2368,  0.1000,\n",
      "          0.1000, 57.2368, 57.2368,  0.1000, 57.2368,  0.1000, 57.2368, 57.3089,\n",
      "         57.3089, 57.3089,  0.1000,  0.1000, 57.3089, 57.3089,  0.1000, 57.3089,\n",
      "          0.1000, 57.3089, 57.2909, 57.3089, 57.3089, 57.3089, 57.2368, 57.3089,\n",
      "         57.3089, 57.3089, 57.2909, 57.3089, 57.3089, 57.3089, 57.2909, 57.2368,\n",
      "         57.2909, 57.2909, 57.2909,  0.1000, 57.2909, 57.2368,  0.1000, 57.2368,\n",
      "         57.3089,  0.1000, 57.3089, 57.3089, 57.3089, 57.2909, 57.2909,  0.1000,\n",
      "         57.3089,  0.1000, 57.1955, 57.1955, 57.2909, 57.3089, 57.3089,  0.1000,\n",
      "          0.1000, 57.1955, 57.2909, 57.3089,  0.1000, 57.2909, 57.3089,  0.1000,\n",
      "         57.1955, 57.3089]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 444 was 98.6%\n",
      "current params: tensor([57.1955, 57.2909, 57.2368, 57.3089], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  13.9\n",
      "SLow rates:  tensor([[57.2961, 57.3914, 57.3374, 57.4094,  0.1000,  0.1000,  0.1000, 57.2961,\n",
      "         57.2961, 57.2961,  0.1000,  0.1000, 57.3914, 57.3914, 57.3914,  0.1000,\n",
      "          0.1000, 57.3914, 57.3914,  0.1000, 57.3374, 57.3374, 57.3374,  0.1000,\n",
      "          0.1000, 57.3374, 57.3374,  0.1000, 57.3374,  0.1000, 57.3374, 57.4094,\n",
      "         57.4094, 57.4094,  0.1000,  0.1000, 57.4094, 57.4094,  0.1000, 57.4094,\n",
      "          0.1000, 57.4094, 57.3914, 57.4094, 57.4094, 57.4094, 57.3374, 57.4094,\n",
      "         57.4094, 57.4094, 57.3914, 57.4094, 57.4094, 57.4094, 57.3914, 57.3374,\n",
      "         57.3914, 57.3914, 57.3914,  0.1000, 57.3914, 57.3374,  0.1000, 57.3374,\n",
      "         57.4094,  0.1000, 57.4094, 57.4094, 57.4094, 57.3914, 57.3914,  0.1000,\n",
      "         57.4094,  0.1000, 57.2961, 57.2961, 57.3914, 57.4094, 57.4094,  0.1000,\n",
      "          0.1000, 57.2961, 57.3914, 57.4094,  0.1000, 57.3914, 57.4094,  0.1000,\n",
      "         57.2961, 57.4094]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 445 was 98.7%\n",
      "current params: tensor([57.2961, 57.3914, 57.3374, 57.4094], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.0\n",
      "SLow rates:  tensor([[57.3967, 57.4920, 57.4379, 57.5100,  0.1000,  0.1000,  0.1000, 57.3967,\n",
      "         57.3967, 57.3967,  0.1000,  0.1000, 57.4920, 57.4920, 57.4920,  0.1000,\n",
      "          0.1000, 57.4920, 57.4920,  0.1000, 57.4379, 57.4379, 57.4379,  0.1000,\n",
      "          0.1000, 57.4379, 57.4379,  0.1000, 57.4379,  0.1000, 57.4379, 57.5100,\n",
      "         57.5100, 57.5100,  0.1000,  0.1000, 57.5100, 57.5100,  0.1000, 57.5100,\n",
      "          0.1000, 57.5100, 57.4920, 57.5100, 57.5100, 57.5100, 57.4379, 57.5100,\n",
      "         57.5100, 57.5100, 57.4920, 57.5100, 57.5100, 57.5100, 57.4920, 57.4379,\n",
      "         57.4920, 57.4920, 57.4920,  0.1000, 57.4920, 57.4379,  0.1000, 57.4379,\n",
      "         57.5100,  0.1000, 57.5100, 57.5100, 57.5100, 57.4920, 57.4920,  0.1000,\n",
      "         57.5100,  0.1000, 57.3967, 57.3967, 57.4920, 57.5100, 57.5100,  0.1000,\n",
      "          0.1000, 57.3967, 57.4920, 57.5100,  0.1000, 57.4920, 57.5100,  0.1000,\n",
      "         57.3967, 57.5100]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 446 was 98.7%\n",
      "current params: tensor([57.3967, 57.4920, 57.4379, 57.5100], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.0\n",
      "SLow rates:  tensor([[57.4972, 57.5925, 57.5384, 57.6105,  0.1000,  0.1000,  0.1000, 57.4972,\n",
      "         57.4972, 57.4972,  0.1000,  0.1000, 57.5925, 57.5925, 57.5925,  0.1000,\n",
      "          0.1000, 57.5925, 57.5925,  0.1000, 57.5384, 57.5384, 57.5384,  0.1000,\n",
      "          0.1000, 57.5384, 57.5384,  0.1000, 57.5384,  0.1000, 57.5384, 57.6105,\n",
      "         57.6105, 57.6105,  0.1000,  0.1000, 57.6105, 57.6105,  0.1000, 57.6105,\n",
      "          0.1000, 57.6105, 57.5925, 57.6105, 57.6105, 57.6105, 57.5384, 57.6105,\n",
      "         57.6105, 57.6105, 57.5925, 57.6105, 57.6105, 57.6105, 57.5925, 57.5384,\n",
      "         57.5925, 57.5925, 57.5925,  0.1000, 57.5925, 57.5384,  0.1000, 57.5384,\n",
      "         57.6105,  0.1000, 57.6105, 57.6105, 57.6105, 57.5925, 57.5925,  0.1000,\n",
      "         57.6105,  0.1000, 57.4972, 57.4972, 57.5925, 57.6105, 57.6105,  0.1000,\n",
      "          0.1000, 57.4972, 57.5925, 57.6105,  0.1000, 57.5925, 57.6105,  0.1000,\n",
      "         57.4972, 57.6105]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 447 was 98.7%\n",
      "current params: tensor([57.4972, 57.5925, 57.5384, 57.6105], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.0\n",
      "SLow rates:  tensor([[57.5977, 57.6930, 57.6390, 57.7110,  0.1000,  0.1000,  0.1000, 57.5977,\n",
      "         57.5977, 57.5977,  0.1000,  0.1000, 57.6930, 57.6930, 57.6930,  0.1000,\n",
      "          0.1000, 57.6930, 57.6930,  0.1000, 57.6390, 57.6390, 57.6390,  0.1000,\n",
      "          0.1000, 57.6390, 57.6390,  0.1000, 57.6390,  0.1000, 57.6390, 57.7110,\n",
      "         57.7110, 57.7110,  0.1000,  0.1000, 57.7110, 57.7110,  0.1000, 57.7110,\n",
      "          0.1000, 57.7110, 57.6930, 57.7110, 57.7110, 57.7110, 57.6390, 57.7110,\n",
      "         57.7110, 57.7110, 57.6930, 57.7110, 57.7110, 57.7110, 57.6930, 57.6390,\n",
      "         57.6930, 57.6930, 57.6930,  0.1000, 57.6930, 57.6390,  0.1000, 57.6390,\n",
      "         57.7110,  0.1000, 57.7110, 57.7110, 57.7110, 57.6930, 57.6930,  0.1000,\n",
      "         57.7110,  0.1000, 57.5977, 57.5977, 57.6930, 57.7110, 57.7110,  0.1000,\n",
      "          0.1000, 57.5977, 57.6930, 57.7110,  0.1000, 57.6930, 57.7110,  0.1000,\n",
      "         57.5977, 57.7110]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 448 was 98.7%\n",
      "current params: tensor([57.5977, 57.6930, 57.6390, 57.7110], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.0\n",
      "SLow rates:  tensor([[57.6983, 57.7936, 57.7395, 57.8115,  0.1000,  0.1000,  0.1000, 57.6983,\n",
      "         57.6983, 57.6983,  0.1000,  0.1000, 57.7936, 57.7936, 57.7936,  0.1000,\n",
      "          0.1000, 57.7936, 57.7936,  0.1000, 57.7395, 57.7395, 57.7395,  0.1000,\n",
      "          0.1000, 57.7395, 57.7395,  0.1000, 57.7395,  0.1000, 57.7395, 57.8115,\n",
      "         57.8115, 57.8115,  0.1000,  0.1000, 57.8115, 57.8115,  0.1000, 57.8115,\n",
      "          0.1000, 57.8115, 57.7936, 57.8115, 57.8115, 57.8115, 57.7395, 57.8115,\n",
      "         57.8115, 57.8115, 57.7936, 57.8115, 57.8115, 57.8115, 57.7936, 57.7395,\n",
      "         57.7936, 57.7936, 57.7936,  0.1000, 57.7936, 57.7395,  0.1000, 57.7395,\n",
      "         57.8115,  0.1000, 57.8115, 57.8115, 57.8115, 57.7936, 57.7936,  0.1000,\n",
      "         57.8115,  0.1000, 57.6983, 57.6983, 57.7936, 57.8115, 57.8115,  0.1000,\n",
      "          0.1000, 57.6983, 57.7936, 57.8115,  0.1000, 57.7936, 57.8115,  0.1000,\n",
      "         57.6983, 57.8115]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 449 was 98.7%\n",
      "current params: tensor([57.6983, 57.7936, 57.7395, 57.8115], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.0\n",
      "SLow rates:  tensor([[57.7988, 57.8941, 57.8400, 57.9120,  0.1000,  0.1000,  0.1000, 57.7988,\n",
      "         57.7988, 57.7988,  0.1000,  0.1000, 57.8941, 57.8941, 57.8941,  0.1000,\n",
      "          0.1000, 57.8941, 57.8941,  0.1000, 57.8400, 57.8400, 57.8400,  0.1000,\n",
      "          0.1000, 57.8400, 57.8400,  0.1000, 57.8400,  0.1000, 57.8400, 57.9120,\n",
      "         57.9120, 57.9120,  0.1000,  0.1000, 57.9120, 57.9120,  0.1000, 57.9120,\n",
      "          0.1000, 57.9120, 57.8941, 57.9120, 57.9120, 57.9120, 57.8400, 57.9120,\n",
      "         57.9120, 57.9120, 57.8941, 57.9120, 57.9120, 57.9120, 57.8941, 57.8400,\n",
      "         57.8941, 57.8941, 57.8941,  0.1000, 57.8941, 57.8400,  0.1000, 57.8400,\n",
      "         57.9120,  0.1000, 57.9120, 57.9120, 57.9120, 57.8941, 57.8941,  0.1000,\n",
      "         57.9120,  0.1000, 57.7988, 57.7988, 57.8941, 57.9120, 57.9120,  0.1000,\n",
      "          0.1000, 57.7988, 57.8941, 57.9120,  0.1000, 57.8941, 57.9120,  0.1000,\n",
      "         57.7988, 57.9120]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 450 was 98.7%\n",
      "current params: tensor([57.7988, 57.8941, 57.8400, 57.9120], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.1\n",
      "SLow rates:  tensor([[57.8993, 57.9946, 57.9405, 58.0125,  0.1000,  0.1000,  0.1000, 57.8993,\n",
      "         57.8993, 57.8993,  0.1000,  0.1000, 57.9946, 57.9946, 57.9946,  0.1000,\n",
      "          0.1000, 57.9946, 57.9946,  0.1000, 57.9405, 57.9405, 57.9405,  0.1000,\n",
      "          0.1000, 57.9405, 57.9405,  0.1000, 57.9405,  0.1000, 57.9405, 58.0125,\n",
      "         58.0125, 58.0125,  0.1000,  0.1000, 58.0125, 58.0125,  0.1000, 58.0125,\n",
      "          0.1000, 58.0125, 57.9946, 58.0125, 58.0125, 58.0125, 57.9405, 58.0125,\n",
      "         58.0125, 58.0125, 57.9946, 58.0125, 58.0125, 58.0125, 57.9946, 57.9405,\n",
      "         57.9946, 57.9946, 57.9946,  0.1000, 57.9946, 57.9405,  0.1000, 57.9405,\n",
      "         58.0125,  0.1000, 58.0125, 58.0125, 58.0125, 57.9946, 57.9946,  0.1000,\n",
      "         58.0125,  0.1000, 57.8993, 57.8993, 57.9946, 58.0125, 58.0125,  0.1000,\n",
      "          0.1000, 57.8993, 57.9946, 58.0125,  0.1000, 57.9946, 58.0125,  0.1000,\n",
      "         57.8993, 58.0125]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 451 was 98.7%\n",
      "current params: tensor([57.8993, 57.9946, 57.9405, 58.0125], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.1\n",
      "SLow rates:  tensor([[57.9998, 58.0951, 58.0410, 58.1130,  0.1000,  0.1000,  0.1000, 57.9998,\n",
      "         57.9998, 57.9998,  0.1000,  0.1000, 58.0951, 58.0951, 58.0951,  0.1000,\n",
      "          0.1000, 58.0951, 58.0951,  0.1000, 58.0410, 58.0410, 58.0410,  0.1000,\n",
      "          0.1000, 58.0410, 58.0410,  0.1000, 58.0410,  0.1000, 58.0410, 58.1130,\n",
      "         58.1130, 58.1130,  0.1000,  0.1000, 58.1130, 58.1130,  0.1000, 58.1130,\n",
      "          0.1000, 58.1130, 58.0951, 58.1130, 58.1130, 58.1130, 58.0410, 58.1130,\n",
      "         58.1130, 58.1130, 58.0951, 58.1130, 58.1130, 58.1130, 58.0951, 58.0410,\n",
      "         58.0951, 58.0951, 58.0951,  0.1000, 58.0951, 58.0410,  0.1000, 58.0410,\n",
      "         58.1130,  0.1000, 58.1130, 58.1130, 58.1130, 58.0951, 58.0951,  0.1000,\n",
      "         58.1130,  0.1000, 57.9998, 57.9998, 58.0951, 58.1130, 58.1130,  0.1000,\n",
      "          0.1000, 57.9998, 58.0951, 58.1130,  0.1000, 58.0951, 58.1130,  0.1000,\n",
      "         57.9998, 58.1130]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 452 was 98.7%\n",
      "current params: tensor([57.9998, 58.0951, 58.0410, 58.1130], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.1\n",
      "SLow rates:  tensor([[58.1004, 58.1956, 58.1416, 58.2135,  0.1000,  0.1000,  0.1000, 58.1004,\n",
      "         58.1004, 58.1004,  0.1000,  0.1000, 58.1956, 58.1956, 58.1956,  0.1000,\n",
      "          0.1000, 58.1956, 58.1956,  0.1000, 58.1416, 58.1416, 58.1416,  0.1000,\n",
      "          0.1000, 58.1416, 58.1416,  0.1000, 58.1416,  0.1000, 58.1416, 58.2135,\n",
      "         58.2135, 58.2135,  0.1000,  0.1000, 58.2135, 58.2135,  0.1000, 58.2135,\n",
      "          0.1000, 58.2135, 58.1956, 58.2135, 58.2135, 58.2135, 58.1416, 58.2135,\n",
      "         58.2135, 58.2135, 58.1956, 58.2135, 58.2135, 58.2135, 58.1956, 58.1416,\n",
      "         58.1956, 58.1956, 58.1956,  0.1000, 58.1956, 58.1416,  0.1000, 58.1416,\n",
      "         58.2135,  0.1000, 58.2135, 58.2135, 58.2135, 58.1956, 58.1956,  0.1000,\n",
      "         58.2135,  0.1000, 58.1004, 58.1004, 58.1956, 58.2135, 58.2135,  0.1000,\n",
      "          0.1000, 58.1004, 58.1956, 58.2135,  0.1000, 58.1956, 58.2135,  0.1000,\n",
      "         58.1004, 58.2135]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 453 was 98.7%\n",
      "current params: tensor([58.1004, 58.1956, 58.1416, 58.2135], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.1\n",
      "SLow rates:  tensor([[58.2009, 58.2961, 58.2421, 58.3140,  0.1000,  0.1000,  0.1000, 58.2009,\n",
      "         58.2009, 58.2009,  0.1000,  0.1000, 58.2961, 58.2961, 58.2961,  0.1000,\n",
      "          0.1000, 58.2961, 58.2961,  0.1000, 58.2421, 58.2421, 58.2421,  0.1000,\n",
      "          0.1000, 58.2421, 58.2421,  0.1000, 58.2421,  0.1000, 58.2421, 58.3140,\n",
      "         58.3140, 58.3140,  0.1000,  0.1000, 58.3140, 58.3140,  0.1000, 58.3140,\n",
      "          0.1000, 58.3140, 58.2961, 58.3140, 58.3140, 58.3140, 58.2421, 58.3140,\n",
      "         58.3140, 58.3140, 58.2961, 58.3140, 58.3140, 58.3140, 58.2961, 58.2421,\n",
      "         58.2961, 58.2961, 58.2961,  0.1000, 58.2961, 58.2421,  0.1000, 58.2421,\n",
      "         58.3140,  0.1000, 58.3140, 58.3140, 58.3140, 58.2961, 58.2961,  0.1000,\n",
      "         58.3140,  0.1000, 58.2009, 58.2009, 58.2961, 58.3140, 58.3140,  0.1000,\n",
      "          0.1000, 58.2009, 58.2961, 58.3140,  0.1000, 58.2961, 58.3140,  0.1000,\n",
      "         58.2009, 58.3140]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 454 was 98.7%\n",
      "current params: tensor([58.2009, 58.2961, 58.2421, 58.3140], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.1\n",
      "SLow rates:  tensor([[58.3014, 58.3966, 58.3426, 58.4145,  0.1000,  0.1000,  0.1000, 58.3014,\n",
      "         58.3014, 58.3014,  0.1000,  0.1000, 58.3966, 58.3966, 58.3966,  0.1000,\n",
      "          0.1000, 58.3966, 58.3966,  0.1000, 58.3426, 58.3426, 58.3426,  0.1000,\n",
      "          0.1000, 58.3426, 58.3426,  0.1000, 58.3426,  0.1000, 58.3426, 58.4145,\n",
      "         58.4145, 58.4145,  0.1000,  0.1000, 58.4145, 58.4145,  0.1000, 58.4145,\n",
      "          0.1000, 58.4145, 58.3966, 58.4145, 58.4145, 58.4145, 58.3426, 58.4145,\n",
      "         58.4145, 58.4145, 58.3966, 58.4145, 58.4145, 58.4145, 58.3966, 58.3426,\n",
      "         58.3966, 58.3966, 58.3966,  0.1000, 58.3966, 58.3426,  0.1000, 58.3426,\n",
      "         58.4145,  0.1000, 58.4145, 58.4145, 58.4145, 58.3966, 58.3966,  0.1000,\n",
      "         58.4145,  0.1000, 58.3014, 58.3014, 58.3966, 58.4145, 58.4145,  0.1000,\n",
      "          0.1000, 58.3014, 58.3966, 58.4145,  0.1000, 58.3966, 58.4145,  0.1000,\n",
      "         58.3014, 58.4145]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 455 was 98.7%\n",
      "current params: tensor([58.3014, 58.3966, 58.3426, 58.4145], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.2\n",
      "SLow rates:  tensor([[58.4019, 58.4971, 58.4430, 58.5150,  0.1000,  0.1000,  0.1000, 58.4019,\n",
      "         58.4019, 58.4019,  0.1000,  0.1000, 58.4971, 58.4971, 58.4971,  0.1000,\n",
      "          0.1000, 58.4971, 58.4971,  0.1000, 58.4430, 58.4430, 58.4430,  0.1000,\n",
      "          0.1000, 58.4430, 58.4430,  0.1000, 58.4430,  0.1000, 58.4430, 58.5150,\n",
      "         58.5150, 58.5150,  0.1000,  0.1000, 58.5150, 58.5150,  0.1000, 58.5150,\n",
      "          0.1000, 58.5150, 58.4971, 58.5150, 58.5150, 58.5150, 58.4430, 58.5150,\n",
      "         58.5150, 58.5150, 58.4971, 58.5150, 58.5150, 58.5150, 58.4971, 58.4430,\n",
      "         58.4971, 58.4971, 58.4971,  0.1000, 58.4971, 58.4430,  0.1000, 58.4430,\n",
      "         58.5150,  0.1000, 58.5150, 58.5150, 58.5150, 58.4971, 58.4971,  0.1000,\n",
      "         58.5150,  0.1000, 58.4019, 58.4019, 58.4971, 58.5150, 58.5150,  0.1000,\n",
      "          0.1000, 58.4019, 58.4971, 58.5150,  0.1000, 58.4971, 58.5150,  0.1000,\n",
      "         58.4019, 58.5150]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 456 was 98.7%\n",
      "current params: tensor([58.4019, 58.4971, 58.4430, 58.5150], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.2\n",
      "SLow rates:  tensor([[58.5024, 58.5976, 58.5435, 58.6155,  0.1000,  0.1000,  0.1000, 58.5024,\n",
      "         58.5024, 58.5024,  0.1000,  0.1000, 58.5976, 58.5976, 58.5976,  0.1000,\n",
      "          0.1000, 58.5976, 58.5976,  0.1000, 58.5435, 58.5435, 58.5435,  0.1000,\n",
      "          0.1000, 58.5435, 58.5435,  0.1000, 58.5435,  0.1000, 58.5435, 58.6155,\n",
      "         58.6155, 58.6155,  0.1000,  0.1000, 58.6155, 58.6155,  0.1000, 58.6155,\n",
      "          0.1000, 58.6155, 58.5976, 58.6155, 58.6155, 58.6155, 58.5435, 58.6155,\n",
      "         58.6155, 58.6155, 58.5976, 58.6155, 58.6155, 58.6155, 58.5976, 58.5435,\n",
      "         58.5976, 58.5976, 58.5976,  0.1000, 58.5976, 58.5435,  0.1000, 58.5435,\n",
      "         58.6155,  0.1000, 58.6155, 58.6155, 58.6155, 58.5976, 58.5976,  0.1000,\n",
      "         58.6155,  0.1000, 58.5024, 58.5024, 58.5976, 58.6155, 58.6155,  0.1000,\n",
      "          0.1000, 58.5024, 58.5976, 58.6155,  0.1000, 58.5976, 58.6155,  0.1000,\n",
      "         58.5024, 58.6155]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 457 was 98.7%\n",
      "current params: tensor([58.5024, 58.5976, 58.5435, 58.6155], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.2\n",
      "SLow rates:  tensor([[58.6028, 58.6980, 58.6440, 58.7159,  0.1000,  0.1000,  0.1000, 58.6028,\n",
      "         58.6028, 58.6028,  0.1000,  0.1000, 58.6980, 58.6980, 58.6980,  0.1000,\n",
      "          0.1000, 58.6980, 58.6980,  0.1000, 58.6440, 58.6440, 58.6440,  0.1000,\n",
      "          0.1000, 58.6440, 58.6440,  0.1000, 58.6440,  0.1000, 58.6440, 58.7159,\n",
      "         58.7159, 58.7159,  0.1000,  0.1000, 58.7159, 58.7159,  0.1000, 58.7159,\n",
      "          0.1000, 58.7159, 58.6980, 58.7159, 58.7159, 58.7159, 58.6440, 58.7159,\n",
      "         58.7159, 58.7159, 58.6980, 58.7159, 58.7159, 58.7159, 58.6980, 58.6440,\n",
      "         58.6980, 58.6980, 58.6980,  0.1000, 58.6980, 58.6440,  0.1000, 58.6440,\n",
      "         58.7159,  0.1000, 58.7159, 58.7159, 58.7159, 58.6980, 58.6980,  0.1000,\n",
      "         58.7159,  0.1000, 58.6028, 58.6028, 58.6980, 58.7159, 58.7159,  0.1000,\n",
      "          0.1000, 58.6028, 58.6980, 58.7159,  0.1000, 58.6980, 58.7159,  0.1000,\n",
      "         58.6028, 58.7159]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 458 was 98.7%\n",
      "current params: tensor([58.6028, 58.6980, 58.6440, 58.7159], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.2\n",
      "SLow rates:  tensor([[58.7033, 58.7985, 58.7445, 58.8164,  0.1000,  0.1000,  0.1000, 58.7033,\n",
      "         58.7033, 58.7033,  0.1000,  0.1000, 58.7985, 58.7985, 58.7985,  0.1000,\n",
      "          0.1000, 58.7985, 58.7985,  0.1000, 58.7445, 58.7445, 58.7445,  0.1000,\n",
      "          0.1000, 58.7445, 58.7445,  0.1000, 58.7445,  0.1000, 58.7445, 58.8164,\n",
      "         58.8164, 58.8164,  0.1000,  0.1000, 58.8164, 58.8164,  0.1000, 58.8164,\n",
      "          0.1000, 58.8164, 58.7985, 58.8164, 58.8164, 58.8164, 58.7445, 58.8164,\n",
      "         58.8164, 58.8164, 58.7985, 58.8164, 58.8164, 58.8164, 58.7985, 58.7445,\n",
      "         58.7985, 58.7985, 58.7985,  0.1000, 58.7985, 58.7445,  0.1000, 58.7445,\n",
      "         58.8164,  0.1000, 58.8164, 58.8164, 58.8164, 58.7985, 58.7985,  0.1000,\n",
      "         58.8164,  0.1000, 58.7033, 58.7033, 58.7985, 58.8164, 58.8164,  0.1000,\n",
      "          0.1000, 58.7033, 58.7985, 58.8164,  0.1000, 58.7985, 58.8164,  0.1000,\n",
      "         58.7033, 58.8164]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 459 was 98.7%\n",
      "current params: tensor([58.7033, 58.7985, 58.7445, 58.8164], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.2\n",
      "SLow rates:  tensor([[58.8038, 58.8990, 58.8450, 58.9169,  0.1000,  0.1000,  0.1000, 58.8038,\n",
      "         58.8038, 58.8038,  0.1000,  0.1000, 58.8990, 58.8990, 58.8990,  0.1000,\n",
      "          0.1000, 58.8990, 58.8990,  0.1000, 58.8450, 58.8450, 58.8450,  0.1000,\n",
      "          0.1000, 58.8450, 58.8450,  0.1000, 58.8450,  0.1000, 58.8450, 58.9169,\n",
      "         58.9169, 58.9169,  0.1000,  0.1000, 58.9169, 58.9169,  0.1000, 58.9169,\n",
      "          0.1000, 58.9169, 58.8990, 58.9169, 58.9169, 58.9169, 58.8450, 58.9169,\n",
      "         58.9169, 58.9169, 58.8990, 58.9169, 58.9169, 58.9169, 58.8990, 58.8450,\n",
      "         58.8990, 58.8990, 58.8990,  0.1000, 58.8990, 58.8450,  0.1000, 58.8450,\n",
      "         58.9169,  0.1000, 58.9169, 58.9169, 58.9169, 58.8990, 58.8990,  0.1000,\n",
      "         58.9169,  0.1000, 58.8038, 58.8038, 58.8990, 58.9169, 58.9169,  0.1000,\n",
      "          0.1000, 58.8038, 58.8990, 58.9169,  0.1000, 58.8990, 58.9169,  0.1000,\n",
      "         58.8038, 58.9169]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 460 was 98.7%\n",
      "current params: tensor([58.8038, 58.8990, 58.8450, 58.9169], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.2\n",
      "SLow rates:  tensor([[58.9043, 58.9994, 58.9454, 59.0173,  0.1000,  0.1000,  0.1000, 58.9043,\n",
      "         58.9043, 58.9043,  0.1000,  0.1000, 58.9994, 58.9994, 58.9994,  0.1000,\n",
      "          0.1000, 58.9994, 58.9994,  0.1000, 58.9454, 58.9454, 58.9454,  0.1000,\n",
      "          0.1000, 58.9454, 58.9454,  0.1000, 58.9454,  0.1000, 58.9454, 59.0173,\n",
      "         59.0173, 59.0173,  0.1000,  0.1000, 59.0173, 59.0173,  0.1000, 59.0173,\n",
      "          0.1000, 59.0173, 58.9994, 59.0173, 59.0173, 59.0173, 58.9454, 59.0173,\n",
      "         59.0173, 59.0173, 58.9994, 59.0173, 59.0173, 59.0173, 58.9994, 58.9454,\n",
      "         58.9994, 58.9994, 58.9994,  0.1000, 58.9994, 58.9454,  0.1000, 58.9454,\n",
      "         59.0173,  0.1000, 59.0173, 59.0173, 59.0173, 58.9994, 58.9994,  0.1000,\n",
      "         59.0173,  0.1000, 58.9043, 58.9043, 58.9994, 59.0173, 59.0173,  0.1000,\n",
      "          0.1000, 58.9043, 58.9994, 59.0173,  0.1000, 58.9994, 59.0173,  0.1000,\n",
      "         58.9043, 59.0173]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 461 was 98.7%\n",
      "current params: tensor([58.9043, 58.9994, 58.9454, 59.0173], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.3\n",
      "SLow rates:  tensor([[59.0047, 59.0999, 59.0459, 59.1178,  0.1000,  0.1000,  0.1000, 59.0047,\n",
      "         59.0047, 59.0047,  0.1000,  0.1000, 59.0999, 59.0999, 59.0999,  0.1000,\n",
      "          0.1000, 59.0999, 59.0999,  0.1000, 59.0459, 59.0459, 59.0459,  0.1000,\n",
      "          0.1000, 59.0459, 59.0459,  0.1000, 59.0459,  0.1000, 59.0459, 59.1178,\n",
      "         59.1178, 59.1178,  0.1000,  0.1000, 59.1178, 59.1178,  0.1000, 59.1178,\n",
      "          0.1000, 59.1178, 59.0999, 59.1178, 59.1178, 59.1178, 59.0459, 59.1178,\n",
      "         59.1178, 59.1178, 59.0999, 59.1178, 59.1178, 59.1178, 59.0999, 59.0459,\n",
      "         59.0999, 59.0999, 59.0999,  0.1000, 59.0999, 59.0459,  0.1000, 59.0459,\n",
      "         59.1178,  0.1000, 59.1178, 59.1178, 59.1178, 59.0999, 59.0999,  0.1000,\n",
      "         59.1178,  0.1000, 59.0047, 59.0047, 59.0999, 59.1178, 59.1178,  0.1000,\n",
      "          0.1000, 59.0047, 59.0999, 59.1178,  0.1000, 59.0999, 59.1178,  0.1000,\n",
      "         59.0047, 59.1178]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 462 was 98.7%\n",
      "current params: tensor([59.0047, 59.0999, 59.0459, 59.1178], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.3\n",
      "SLow rates:  tensor([[59.1052, 59.2003, 59.1463, 59.2182,  0.1000,  0.1000,  0.1000, 59.1052,\n",
      "         59.1052, 59.1052,  0.1000,  0.1000, 59.2003, 59.2003, 59.2003,  0.1000,\n",
      "          0.1000, 59.2003, 59.2003,  0.1000, 59.1463, 59.1463, 59.1463,  0.1000,\n",
      "          0.1000, 59.1463, 59.1463,  0.1000, 59.1463,  0.1000, 59.1463, 59.2182,\n",
      "         59.2182, 59.2182,  0.1000,  0.1000, 59.2182, 59.2182,  0.1000, 59.2182,\n",
      "          0.1000, 59.2182, 59.2003, 59.2182, 59.2182, 59.2182, 59.1463, 59.2182,\n",
      "         59.2182, 59.2182, 59.2003, 59.2182, 59.2182, 59.2182, 59.2003, 59.1463,\n",
      "         59.2003, 59.2003, 59.2003,  0.1000, 59.2003, 59.1463,  0.1000, 59.1463,\n",
      "         59.2182,  0.1000, 59.2182, 59.2182, 59.2182, 59.2003, 59.2003,  0.1000,\n",
      "         59.2182,  0.1000, 59.1052, 59.1052, 59.2003, 59.2182, 59.2182,  0.1000,\n",
      "          0.1000, 59.1052, 59.2003, 59.2182,  0.1000, 59.2003, 59.2182,  0.1000,\n",
      "         59.1052, 59.2182]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 463 was 98.7%\n",
      "current params: tensor([59.1052, 59.2003, 59.1463, 59.2182], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.3\n",
      "SLow rates:  tensor([[59.2057, 59.3008, 59.2468, 59.3186,  0.1000,  0.1000,  0.1000, 59.2057,\n",
      "         59.2057, 59.2057,  0.1000,  0.1000, 59.3008, 59.3008, 59.3008,  0.1000,\n",
      "          0.1000, 59.3008, 59.3008,  0.1000, 59.2468, 59.2468, 59.2468,  0.1000,\n",
      "          0.1000, 59.2468, 59.2468,  0.1000, 59.2468,  0.1000, 59.2468, 59.3186,\n",
      "         59.3186, 59.3186,  0.1000,  0.1000, 59.3186, 59.3186,  0.1000, 59.3186,\n",
      "          0.1000, 59.3186, 59.3008, 59.3186, 59.3186, 59.3186, 59.2468, 59.3186,\n",
      "         59.3186, 59.3186, 59.3008, 59.3186, 59.3186, 59.3186, 59.3008, 59.2468,\n",
      "         59.3008, 59.3008, 59.3008,  0.1000, 59.3008, 59.2468,  0.1000, 59.2468,\n",
      "         59.3186,  0.1000, 59.3186, 59.3186, 59.3186, 59.3008, 59.3008,  0.1000,\n",
      "         59.3186,  0.1000, 59.2057, 59.2057, 59.3008, 59.3186, 59.3186,  0.1000,\n",
      "          0.1000, 59.2057, 59.3008, 59.3186,  0.1000, 59.3008, 59.3186,  0.1000,\n",
      "         59.2057, 59.3186]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 464 was 98.7%\n",
      "current params: tensor([59.2057, 59.3008, 59.2468, 59.3186], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.3\n",
      "SLow rates:  tensor([[59.3061, 59.4012, 59.3472, 59.4191,  0.1000,  0.1000,  0.1000, 59.3061,\n",
      "         59.3061, 59.3061,  0.1000,  0.1000, 59.4012, 59.4012, 59.4012,  0.1000,\n",
      "          0.1000, 59.4012, 59.4012,  0.1000, 59.3472, 59.3472, 59.3472,  0.1000,\n",
      "          0.1000, 59.3472, 59.3472,  0.1000, 59.3472,  0.1000, 59.3472, 59.4191,\n",
      "         59.4191, 59.4191,  0.1000,  0.1000, 59.4191, 59.4191,  0.1000, 59.4191,\n",
      "          0.1000, 59.4191, 59.4012, 59.4191, 59.4191, 59.4191, 59.3472, 59.4191,\n",
      "         59.4191, 59.4191, 59.4012, 59.4191, 59.4191, 59.4191, 59.4012, 59.3472,\n",
      "         59.4012, 59.4012, 59.4012,  0.1000, 59.4012, 59.3472,  0.1000, 59.3472,\n",
      "         59.4191,  0.1000, 59.4191, 59.4191, 59.4191, 59.4012, 59.4012,  0.1000,\n",
      "         59.4191,  0.1000, 59.3061, 59.3061, 59.4012, 59.4191, 59.4191,  0.1000,\n",
      "          0.1000, 59.3061, 59.4012, 59.4191,  0.1000, 59.4012, 59.4191,  0.1000,\n",
      "         59.3061, 59.4191]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 465 was 98.7%\n",
      "current params: tensor([59.3061, 59.4012, 59.3472, 59.4191], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.3\n",
      "SLow rates:  tensor([[59.4066, 59.5017, 59.4477, 59.5195,  0.1000,  0.1000,  0.1000, 59.4066,\n",
      "         59.4066, 59.4066,  0.1000,  0.1000, 59.5017, 59.5017, 59.5017,  0.1000,\n",
      "          0.1000, 59.5017, 59.5017,  0.1000, 59.4477, 59.4477, 59.4477,  0.1000,\n",
      "          0.1000, 59.4477, 59.4477,  0.1000, 59.4477,  0.1000, 59.4477, 59.5195,\n",
      "         59.5195, 59.5195,  0.1000,  0.1000, 59.5195, 59.5195,  0.1000, 59.5195,\n",
      "          0.1000, 59.5195, 59.5017, 59.5195, 59.5195, 59.5195, 59.4477, 59.5195,\n",
      "         59.5195, 59.5195, 59.5017, 59.5195, 59.5195, 59.5195, 59.5017, 59.4477,\n",
      "         59.5017, 59.5017, 59.5017,  0.1000, 59.5017, 59.4477,  0.1000, 59.4477,\n",
      "         59.5195,  0.1000, 59.5195, 59.5195, 59.5195, 59.5017, 59.5017,  0.1000,\n",
      "         59.5195,  0.1000, 59.4066, 59.4066, 59.5017, 59.5195, 59.5195,  0.1000,\n",
      "          0.1000, 59.4066, 59.5017, 59.5195,  0.1000, 59.5017, 59.5195,  0.1000,\n",
      "         59.4066, 59.5195]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 466 was 98.7%\n",
      "current params: tensor([59.4066, 59.5017, 59.4477, 59.5195], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.4\n",
      "SLow rates:  tensor([[59.5070, 59.6021, 59.5481, 59.6199,  0.1000,  0.1000,  0.1000, 59.5070,\n",
      "         59.5070, 59.5070,  0.1000,  0.1000, 59.6021, 59.6021, 59.6021,  0.1000,\n",
      "          0.1000, 59.6021, 59.6021,  0.1000, 59.5481, 59.5481, 59.5481,  0.1000,\n",
      "          0.1000, 59.5481, 59.5481,  0.1000, 59.5481,  0.1000, 59.5481, 59.6199,\n",
      "         59.6199, 59.6199,  0.1000,  0.1000, 59.6199, 59.6199,  0.1000, 59.6199,\n",
      "          0.1000, 59.6199, 59.6021, 59.6199, 59.6199, 59.6199, 59.5481, 59.6199,\n",
      "         59.6199, 59.6199, 59.6021, 59.6199, 59.6199, 59.6199, 59.6021, 59.5481,\n",
      "         59.6021, 59.6021, 59.6021,  0.1000, 59.6021, 59.5481,  0.1000, 59.5481,\n",
      "         59.6199,  0.1000, 59.6199, 59.6199, 59.6199, 59.6021, 59.6021,  0.1000,\n",
      "         59.6199,  0.1000, 59.5070, 59.5070, 59.6021, 59.6199, 59.6199,  0.1000,\n",
      "          0.1000, 59.5070, 59.6021, 59.6199,  0.1000, 59.6021, 59.6199,  0.1000,\n",
      "         59.5070, 59.6199]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 467 was 98.7%\n",
      "current params: tensor([59.5070, 59.6021, 59.5481, 59.6199], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.4\n",
      "SLow rates:  tensor([[59.6074, 59.7025, 59.6486, 59.7204,  0.1000,  0.1000,  0.1000, 59.6074,\n",
      "         59.6074, 59.6074,  0.1000,  0.1000, 59.7025, 59.7025, 59.7025,  0.1000,\n",
      "          0.1000, 59.7025, 59.7025,  0.1000, 59.6486, 59.6486, 59.6486,  0.1000,\n",
      "          0.1000, 59.6486, 59.6486,  0.1000, 59.6486,  0.1000, 59.6486, 59.7204,\n",
      "         59.7204, 59.7204,  0.1000,  0.1000, 59.7204, 59.7204,  0.1000, 59.7204,\n",
      "          0.1000, 59.7204, 59.7025, 59.7204, 59.7204, 59.7204, 59.6486, 59.7204,\n",
      "         59.7204, 59.7204, 59.7025, 59.7204, 59.7204, 59.7204, 59.7025, 59.6486,\n",
      "         59.7025, 59.7025, 59.7025,  0.1000, 59.7025, 59.6486,  0.1000, 59.6486,\n",
      "         59.7204,  0.1000, 59.7204, 59.7204, 59.7204, 59.7025, 59.7025,  0.1000,\n",
      "         59.7204,  0.1000, 59.6074, 59.6074, 59.7025, 59.7204, 59.7204,  0.1000,\n",
      "          0.1000, 59.6074, 59.7025, 59.7204,  0.1000, 59.7025, 59.7204,  0.1000,\n",
      "         59.6074, 59.7204]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 468 was 98.7%\n",
      "current params: tensor([59.6074, 59.7025, 59.6486, 59.7204], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.4\n",
      "SLow rates:  tensor([[59.7079, 59.8030, 59.7490, 59.8208,  0.1000,  0.1000,  0.1000, 59.7079,\n",
      "         59.7079, 59.7079,  0.1000,  0.1000, 59.8030, 59.8030, 59.8030,  0.1000,\n",
      "          0.1000, 59.8030, 59.8030,  0.1000, 59.7490, 59.7490, 59.7490,  0.1000,\n",
      "          0.1000, 59.7490, 59.7490,  0.1000, 59.7490,  0.1000, 59.7490, 59.8208,\n",
      "         59.8208, 59.8208,  0.1000,  0.1000, 59.8208, 59.8208,  0.1000, 59.8208,\n",
      "          0.1000, 59.8208, 59.8030, 59.8208, 59.8208, 59.8208, 59.7490, 59.8208,\n",
      "         59.8208, 59.8208, 59.8030, 59.8208, 59.8208, 59.8208, 59.8030, 59.7490,\n",
      "         59.8030, 59.8030, 59.8030,  0.1000, 59.8030, 59.7490,  0.1000, 59.7490,\n",
      "         59.8208,  0.1000, 59.8208, 59.8208, 59.8208, 59.8030, 59.8030,  0.1000,\n",
      "         59.8208,  0.1000, 59.7079, 59.7079, 59.8030, 59.8208, 59.8208,  0.1000,\n",
      "          0.1000, 59.7079, 59.8030, 59.8208,  0.1000, 59.8030, 59.8208,  0.1000,\n",
      "         59.7079, 59.8208]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1641, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 469 was 98.7%\n",
      "current params: tensor([59.7079, 59.8030, 59.7490, 59.8208], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.4\n",
      "SLow rates:  tensor([[59.8083, 59.9034, 59.8494, 59.9212,  0.1000,  0.1000,  0.1000, 59.8083,\n",
      "         59.8083, 59.8083,  0.1000,  0.1000, 59.9034, 59.9034, 59.9034,  0.1000,\n",
      "          0.1000, 59.9034, 59.9034,  0.1000, 59.8494, 59.8494, 59.8494,  0.1000,\n",
      "          0.1000, 59.8494, 59.8494,  0.1000, 59.8494,  0.1000, 59.8494, 59.9212,\n",
      "         59.9212, 59.9212,  0.1000,  0.1000, 59.9212, 59.9212,  0.1000, 59.9212,\n",
      "          0.1000, 59.9212, 59.9034, 59.9212, 59.9212, 59.9212, 59.8494, 59.9212,\n",
      "         59.9212, 59.9212, 59.9034, 59.9212, 59.9212, 59.9212, 59.9034, 59.8494,\n",
      "         59.9034, 59.9034, 59.9034,  0.1000, 59.9034, 59.8494,  0.1000, 59.8494,\n",
      "         59.9212,  0.1000, 59.9212, 59.9212, 59.9212, 59.9034, 59.9034,  0.1000,\n",
      "         59.9212,  0.1000, 59.8083, 59.8083, 59.9034, 59.9212, 59.9212,  0.1000,\n",
      "          0.1000, 59.8083, 59.9034, 59.9212,  0.1000, 59.9034, 59.9212,  0.1000,\n",
      "         59.8083, 59.9212]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 470 was 98.7%\n",
      "current params: tensor([59.8083, 59.9034, 59.8494, 59.9212], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.4\n",
      "SLow rates:  tensor([[59.9087, 60.0038, 59.9498, 60.0216,  0.1000,  0.1000,  0.1000, 59.9087,\n",
      "         59.9087, 59.9087,  0.1000,  0.1000, 60.0038, 60.0038, 60.0038,  0.1000,\n",
      "          0.1000, 60.0038, 60.0038,  0.1000, 59.9498, 59.9498, 59.9498,  0.1000,\n",
      "          0.1000, 59.9498, 59.9498,  0.1000, 59.9498,  0.1000, 59.9498, 60.0216,\n",
      "         60.0216, 60.0216,  0.1000,  0.1000, 60.0216, 60.0216,  0.1000, 60.0216,\n",
      "          0.1000, 60.0216, 60.0038, 60.0216, 60.0216, 60.0216, 59.9498, 60.0216,\n",
      "         60.0216, 60.0216, 60.0038, 60.0216, 60.0216, 60.0216, 60.0038, 59.9498,\n",
      "         60.0038, 60.0038, 60.0038,  0.1000, 60.0038, 59.9498,  0.1000, 59.9498,\n",
      "         60.0216,  0.1000, 60.0216, 60.0216, 60.0216, 60.0038, 60.0038,  0.1000,\n",
      "         60.0216,  0.1000, 59.9087, 59.9087, 60.0038, 60.0216, 60.0216,  0.1000,\n",
      "          0.1000, 59.9087, 60.0038, 60.0216,  0.1000, 60.0038, 60.0216,  0.1000,\n",
      "         59.9087, 60.0216]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 471 was 98.7%\n",
      "current params: tensor([59.9087, 60.0038, 59.9498, 60.0216], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.5\n",
      "SLow rates:  tensor([[60.0092, 60.1042, 60.0502, 60.1220,  0.1000,  0.1000,  0.1000, 60.0092,\n",
      "         60.0092, 60.0092,  0.1000,  0.1000, 60.1042, 60.1042, 60.1042,  0.1000,\n",
      "          0.1000, 60.1042, 60.1042,  0.1000, 60.0502, 60.0502, 60.0502,  0.1000,\n",
      "          0.1000, 60.0502, 60.0502,  0.1000, 60.0502,  0.1000, 60.0502, 60.1220,\n",
      "         60.1220, 60.1220,  0.1000,  0.1000, 60.1220, 60.1220,  0.1000, 60.1220,\n",
      "          0.1000, 60.1220, 60.1042, 60.1220, 60.1220, 60.1220, 60.0502, 60.1220,\n",
      "         60.1220, 60.1220, 60.1042, 60.1220, 60.1220, 60.1220, 60.1042, 60.0502,\n",
      "         60.1042, 60.1042, 60.1042,  0.1000, 60.1042, 60.0502,  0.1000, 60.0502,\n",
      "         60.1220,  0.1000, 60.1220, 60.1220, 60.1220, 60.1042, 60.1042,  0.1000,\n",
      "         60.1220,  0.1000, 60.0092, 60.0092, 60.1042, 60.1220, 60.1220,  0.1000,\n",
      "          0.1000, 60.0092, 60.1042, 60.1220,  0.1000, 60.1042, 60.1220,  0.1000,\n",
      "         60.0092, 60.1220]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 472 was 98.7%\n",
      "current params: tensor([60.0092, 60.1042, 60.0502, 60.1220], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.5\n",
      "SLow rates:  tensor([[60.1096, 60.2046, 60.1507, 60.2224,  0.1000,  0.1000,  0.1000, 60.1096,\n",
      "         60.1096, 60.1096,  0.1000,  0.1000, 60.2046, 60.2046, 60.2046,  0.1000,\n",
      "          0.1000, 60.2046, 60.2046,  0.1000, 60.1507, 60.1507, 60.1507,  0.1000,\n",
      "          0.1000, 60.1507, 60.1507,  0.1000, 60.1507,  0.1000, 60.1507, 60.2224,\n",
      "         60.2224, 60.2224,  0.1000,  0.1000, 60.2224, 60.2224,  0.1000, 60.2224,\n",
      "          0.1000, 60.2224, 60.2046, 60.2224, 60.2224, 60.2224, 60.1507, 60.2224,\n",
      "         60.2224, 60.2224, 60.2046, 60.2224, 60.2224, 60.2224, 60.2046, 60.1507,\n",
      "         60.2046, 60.2046, 60.2046,  0.1000, 60.2046, 60.1507,  0.1000, 60.1507,\n",
      "         60.2224,  0.1000, 60.2224, 60.2224, 60.2224, 60.2046, 60.2046,  0.1000,\n",
      "         60.2224,  0.1000, 60.1096, 60.1096, 60.2046, 60.2224, 60.2224,  0.1000,\n",
      "          0.1000, 60.1096, 60.2046, 60.2224,  0.1000, 60.2046, 60.2224,  0.1000,\n",
      "         60.1096, 60.2224]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 473 was 98.7%\n",
      "current params: tensor([60.1096, 60.2046, 60.1507, 60.2224], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.5\n",
      "SLow rates:  tensor([[60.2100, 60.3050, 60.2511, 60.3228,  0.1000,  0.1000,  0.1000, 60.2100,\n",
      "         60.2100, 60.2100,  0.1000,  0.1000, 60.3050, 60.3050, 60.3050,  0.1000,\n",
      "          0.1000, 60.3050, 60.3050,  0.1000, 60.2511, 60.2511, 60.2511,  0.1000,\n",
      "          0.1000, 60.2511, 60.2511,  0.1000, 60.2511,  0.1000, 60.2511, 60.3228,\n",
      "         60.3228, 60.3228,  0.1000,  0.1000, 60.3228, 60.3228,  0.1000, 60.3228,\n",
      "          0.1000, 60.3228, 60.3050, 60.3228, 60.3228, 60.3228, 60.2511, 60.3228,\n",
      "         60.3228, 60.3228, 60.3050, 60.3228, 60.3228, 60.3228, 60.3050, 60.2511,\n",
      "         60.3050, 60.3050, 60.3050,  0.1000, 60.3050, 60.2511,  0.1000, 60.2511,\n",
      "         60.3228,  0.1000, 60.3228, 60.3228, 60.3228, 60.3050, 60.3050,  0.1000,\n",
      "         60.3228,  0.1000, 60.2100, 60.2100, 60.3050, 60.3228, 60.3228,  0.1000,\n",
      "          0.1000, 60.2100, 60.3050, 60.3228,  0.1000, 60.3050, 60.3228,  0.1000,\n",
      "         60.2100, 60.3228]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 474 was 98.7%\n",
      "current params: tensor([60.2100, 60.3050, 60.2511, 60.3228], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.5\n",
      "SLow rates:  tensor([[60.3104, 60.4054, 60.3515, 60.4232,  0.1000,  0.1000,  0.1000, 60.3104,\n",
      "         60.3104, 60.3104,  0.1000,  0.1000, 60.4054, 60.4054, 60.4054,  0.1000,\n",
      "          0.1000, 60.4054, 60.4054,  0.1000, 60.3515, 60.3515, 60.3515,  0.1000,\n",
      "          0.1000, 60.3515, 60.3515,  0.1000, 60.3515,  0.1000, 60.3515, 60.4232,\n",
      "         60.4232, 60.4232,  0.1000,  0.1000, 60.4232, 60.4232,  0.1000, 60.4232,\n",
      "          0.1000, 60.4232, 60.4054, 60.4232, 60.4232, 60.4232, 60.3515, 60.4232,\n",
      "         60.4232, 60.4232, 60.4054, 60.4232, 60.4232, 60.4232, 60.4054, 60.3515,\n",
      "         60.4054, 60.4054, 60.4054,  0.1000, 60.4054, 60.3515,  0.1000, 60.3515,\n",
      "         60.4232,  0.1000, 60.4232, 60.4232, 60.4232, 60.4054, 60.4054,  0.1000,\n",
      "         60.4232,  0.1000, 60.3104, 60.3104, 60.4054, 60.4232, 60.4232,  0.1000,\n",
      "          0.1000, 60.3104, 60.4054, 60.4232,  0.1000, 60.4054, 60.4232,  0.1000,\n",
      "         60.3104, 60.4232]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 475 was 98.7%\n",
      "current params: tensor([60.3104, 60.4054, 60.3515, 60.4232], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.5\n",
      "SLow rates:  tensor([[60.4108, 60.5058, 60.4519, 60.5236,  0.1000,  0.1000,  0.1000, 60.4108,\n",
      "         60.4108, 60.4108,  0.1000,  0.1000, 60.5058, 60.5058, 60.5058,  0.1000,\n",
      "          0.1000, 60.5058, 60.5058,  0.1000, 60.4519, 60.4519, 60.4519,  0.1000,\n",
      "          0.1000, 60.4519, 60.4519,  0.1000, 60.4519,  0.1000, 60.4519, 60.5236,\n",
      "         60.5236, 60.5236,  0.1000,  0.1000, 60.5236, 60.5236,  0.1000, 60.5236,\n",
      "          0.1000, 60.5236, 60.5058, 60.5236, 60.5236, 60.5236, 60.4519, 60.5236,\n",
      "         60.5236, 60.5236, 60.5058, 60.5236, 60.5236, 60.5236, 60.5058, 60.4519,\n",
      "         60.5058, 60.5058, 60.5058,  0.1000, 60.5058, 60.4519,  0.1000, 60.4519,\n",
      "         60.5236,  0.1000, 60.5236, 60.5236, 60.5236, 60.5058, 60.5058,  0.1000,\n",
      "         60.5236,  0.1000, 60.4108, 60.4108, 60.5058, 60.5236, 60.5236,  0.1000,\n",
      "          0.1000, 60.4108, 60.5058, 60.5236,  0.1000, 60.5058, 60.5236,  0.1000,\n",
      "         60.4108, 60.5236]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 476 was 98.7%\n",
      "current params: tensor([60.4108, 60.5058, 60.4519, 60.5236], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.5\n",
      "SLow rates:  tensor([[60.5112, 60.6062, 60.5523, 60.6240,  0.1000,  0.1000,  0.1000, 60.5112,\n",
      "         60.5112, 60.5112,  0.1000,  0.1000, 60.6062, 60.6062, 60.6062,  0.1000,\n",
      "          0.1000, 60.6062, 60.6062,  0.1000, 60.5523, 60.5523, 60.5523,  0.1000,\n",
      "          0.1000, 60.5523, 60.5523,  0.1000, 60.5523,  0.1000, 60.5523, 60.6240,\n",
      "         60.6240, 60.6240,  0.1000,  0.1000, 60.6240, 60.6240,  0.1000, 60.6240,\n",
      "          0.1000, 60.6240, 60.6062, 60.6240, 60.6240, 60.6240, 60.5523, 60.6240,\n",
      "         60.6240, 60.6240, 60.6062, 60.6240, 60.6240, 60.6240, 60.6062, 60.5523,\n",
      "         60.6062, 60.6062, 60.6062,  0.1000, 60.6062, 60.5523,  0.1000, 60.5523,\n",
      "         60.6240,  0.1000, 60.6240, 60.6240, 60.6240, 60.6062, 60.6062,  0.1000,\n",
      "         60.6240,  0.1000, 60.5112, 60.5112, 60.6062, 60.6240, 60.6240,  0.1000,\n",
      "          0.1000, 60.5112, 60.6062, 60.6240,  0.1000, 60.6062, 60.6240,  0.1000,\n",
      "         60.5112, 60.6240]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 477 was 98.7%\n",
      "current params: tensor([60.5112, 60.6062, 60.5523, 60.6240], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.6\n",
      "SLow rates:  tensor([[60.6116, 60.7066, 60.6527, 60.7244,  0.1000,  0.1000,  0.1000, 60.6116,\n",
      "         60.6116, 60.6116,  0.1000,  0.1000, 60.7066, 60.7066, 60.7066,  0.1000,\n",
      "          0.1000, 60.7066, 60.7066,  0.1000, 60.6527, 60.6527, 60.6527,  0.1000,\n",
      "          0.1000, 60.6527, 60.6527,  0.1000, 60.6527,  0.1000, 60.6527, 60.7244,\n",
      "         60.7244, 60.7244,  0.1000,  0.1000, 60.7244, 60.7244,  0.1000, 60.7244,\n",
      "          0.1000, 60.7244, 60.7066, 60.7244, 60.7244, 60.7244, 60.6527, 60.7244,\n",
      "         60.7244, 60.7244, 60.7066, 60.7244, 60.7244, 60.7244, 60.7066, 60.6527,\n",
      "         60.7066, 60.7066, 60.7066,  0.1000, 60.7066, 60.6527,  0.1000, 60.6527,\n",
      "         60.7244,  0.1000, 60.7244, 60.7244, 60.7244, 60.7066, 60.7066,  0.1000,\n",
      "         60.7244,  0.1000, 60.6116, 60.6116, 60.7066, 60.7244, 60.7244,  0.1000,\n",
      "          0.1000, 60.6116, 60.7066, 60.7244,  0.1000, 60.7066, 60.7244,  0.1000,\n",
      "         60.6116, 60.7244]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 478 was 98.7%\n",
      "current params: tensor([60.6116, 60.7066, 60.6527, 60.7244], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.6\n",
      "SLow rates:  tensor([[60.7120, 60.8070, 60.7530, 60.8247,  0.1000,  0.1000,  0.1000, 60.7120,\n",
      "         60.7120, 60.7120,  0.1000,  0.1000, 60.8070, 60.8070, 60.8070,  0.1000,\n",
      "          0.1000, 60.8070, 60.8070,  0.1000, 60.7530, 60.7530, 60.7530,  0.1000,\n",
      "          0.1000, 60.7530, 60.7530,  0.1000, 60.7530,  0.1000, 60.7530, 60.8247,\n",
      "         60.8247, 60.8247,  0.1000,  0.1000, 60.8247, 60.8247,  0.1000, 60.8247,\n",
      "          0.1000, 60.8247, 60.8070, 60.8247, 60.8247, 60.8247, 60.7530, 60.8247,\n",
      "         60.8247, 60.8247, 60.8070, 60.8247, 60.8247, 60.8247, 60.8070, 60.7530,\n",
      "         60.8070, 60.8070, 60.8070,  0.1000, 60.8070, 60.7530,  0.1000, 60.7530,\n",
      "         60.8247,  0.1000, 60.8247, 60.8247, 60.8247, 60.8070, 60.8070,  0.1000,\n",
      "         60.8247,  0.1000, 60.7120, 60.7120, 60.8070, 60.8247, 60.8247,  0.1000,\n",
      "          0.1000, 60.7120, 60.8070, 60.8247,  0.1000, 60.8070, 60.8247,  0.1000,\n",
      "         60.7120, 60.8247]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0840, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 479 was 98.7%\n",
      "current params: tensor([60.7120, 60.8070, 60.7530, 60.8247], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.6\n",
      "SLow rates:  tensor([[60.8124, 60.9074, 60.8534, 60.9251,  0.1000,  0.1000,  0.1000, 60.8124,\n",
      "         60.8124, 60.8124,  0.1000,  0.1000, 60.9074, 60.9074, 60.9074,  0.1000,\n",
      "          0.1000, 60.9074, 60.9074,  0.1000, 60.8534, 60.8534, 60.8534,  0.1000,\n",
      "          0.1000, 60.8534, 60.8534,  0.1000, 60.8534,  0.1000, 60.8534, 60.9251,\n",
      "         60.9251, 60.9251,  0.1000,  0.1000, 60.9251, 60.9251,  0.1000, 60.9251,\n",
      "          0.1000, 60.9251, 60.9074, 60.9251, 60.9251, 60.9251, 60.8534, 60.9251,\n",
      "         60.9251, 60.9251, 60.9074, 60.9251, 60.9251, 60.9251, 60.9074, 60.8534,\n",
      "         60.9074, 60.9074, 60.9074,  0.1000, 60.9074, 60.8534,  0.1000, 60.8534,\n",
      "         60.9251,  0.1000, 60.9251, 60.9251, 60.9251, 60.9074, 60.9074,  0.1000,\n",
      "         60.9251,  0.1000, 60.8124, 60.8124, 60.9074, 60.9251, 60.9251,  0.1000,\n",
      "          0.1000, 60.8124, 60.9074, 60.9251,  0.1000, 60.9074, 60.9251,  0.1000,\n",
      "         60.8124, 60.9251]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 480 was 98.7%\n",
      "current params: tensor([60.8124, 60.9074, 60.8534, 60.9251], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.6\n",
      "SLow rates:  tensor([[60.9128, 61.0077, 60.9538, 61.0255,  0.1000,  0.1000,  0.1000, 60.9128,\n",
      "         60.9128, 60.9128,  0.1000,  0.1000, 61.0077, 61.0077, 61.0077,  0.1000,\n",
      "          0.1000, 61.0077, 61.0077,  0.1000, 60.9538, 60.9538, 60.9538,  0.1000,\n",
      "          0.1000, 60.9538, 60.9538,  0.1000, 60.9538,  0.1000, 60.9538, 61.0255,\n",
      "         61.0255, 61.0255,  0.1000,  0.1000, 61.0255, 61.0255,  0.1000, 61.0255,\n",
      "          0.1000, 61.0255, 61.0077, 61.0255, 61.0255, 61.0255, 60.9538, 61.0255,\n",
      "         61.0255, 61.0255, 61.0077, 61.0255, 61.0255, 61.0255, 61.0077, 60.9538,\n",
      "         61.0077, 61.0077, 61.0077,  0.1000, 61.0077, 60.9538,  0.1000, 60.9538,\n",
      "         61.0255,  0.1000, 61.0255, 61.0255, 61.0255, 61.0077, 61.0077,  0.1000,\n",
      "         61.0255,  0.1000, 60.9128, 60.9128, 61.0077, 61.0255, 61.0255,  0.1000,\n",
      "          0.1000, 60.9128, 61.0077, 61.0255,  0.1000, 61.0077, 61.0255,  0.1000,\n",
      "         60.9128, 61.0255]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 481 was 98.7%\n",
      "current params: tensor([60.9128, 61.0077, 60.9538, 61.0255], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.6\n",
      "SLow rates:  tensor([[61.0132, 61.1081, 61.0542, 61.1258,  0.1000,  0.1000,  0.1000, 61.0132,\n",
      "         61.0132, 61.0132,  0.1000,  0.1000, 61.1081, 61.1081, 61.1081,  0.1000,\n",
      "          0.1000, 61.1081, 61.1081,  0.1000, 61.0542, 61.0542, 61.0542,  0.1000,\n",
      "          0.1000, 61.0542, 61.0542,  0.1000, 61.0542,  0.1000, 61.0542, 61.1258,\n",
      "         61.1258, 61.1258,  0.1000,  0.1000, 61.1258, 61.1258,  0.1000, 61.1258,\n",
      "          0.1000, 61.1258, 61.1081, 61.1258, 61.1258, 61.1258, 61.0542, 61.1258,\n",
      "         61.1258, 61.1258, 61.1081, 61.1258, 61.1258, 61.1258, 61.1081, 61.0542,\n",
      "         61.1081, 61.1081, 61.1081,  0.1000, 61.1081, 61.0542,  0.1000, 61.0542,\n",
      "         61.1258,  0.1000, 61.1258, 61.1258, 61.1258, 61.1081, 61.1081,  0.1000,\n",
      "         61.1258,  0.1000, 61.0132, 61.0132, 61.1081, 61.1258, 61.1258,  0.1000,\n",
      "          0.1000, 61.0132, 61.1081, 61.1258,  0.1000, 61.1081, 61.1258,  0.1000,\n",
      "         61.0132, 61.1258]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 482 was 98.7%\n",
      "current params: tensor([61.0132, 61.1081, 61.0542, 61.1258], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.7\n",
      "SLow rates:  tensor([[61.1135, 61.2085, 61.1546, 61.2262,  0.1000,  0.1000,  0.1000, 61.1135,\n",
      "         61.1135, 61.1135,  0.1000,  0.1000, 61.2085, 61.2085, 61.2085,  0.1000,\n",
      "          0.1000, 61.2085, 61.2085,  0.1000, 61.1546, 61.1546, 61.1546,  0.1000,\n",
      "          0.1000, 61.1546, 61.1546,  0.1000, 61.1546,  0.1000, 61.1546, 61.2262,\n",
      "         61.2262, 61.2262,  0.1000,  0.1000, 61.2262, 61.2262,  0.1000, 61.2262,\n",
      "          0.1000, 61.2262, 61.2085, 61.2262, 61.2262, 61.2262, 61.1546, 61.2262,\n",
      "         61.2262, 61.2262, 61.2085, 61.2262, 61.2262, 61.2262, 61.2085, 61.1546,\n",
      "         61.2085, 61.2085, 61.2085,  0.1000, 61.2085, 61.1546,  0.1000, 61.1546,\n",
      "         61.2262,  0.1000, 61.2262, 61.2262, 61.2262, 61.2085, 61.2085,  0.1000,\n",
      "         61.2262,  0.1000, 61.1135, 61.1135, 61.2085, 61.2262, 61.2262,  0.1000,\n",
      "          0.1000, 61.1135, 61.2085, 61.2262,  0.1000, 61.2085, 61.2262,  0.1000,\n",
      "         61.1135, 61.2262]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 483 was 98.7%\n",
      "current params: tensor([61.1135, 61.2085, 61.1546, 61.2262], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.7\n",
      "SLow rates:  tensor([[61.2139, 61.3088, 61.2549, 61.3266,  0.1000,  0.1000,  0.1000, 61.2139,\n",
      "         61.2139, 61.2139,  0.1000,  0.1000, 61.3088, 61.3088, 61.3088,  0.1000,\n",
      "          0.1000, 61.3088, 61.3088,  0.1000, 61.2549, 61.2549, 61.2549,  0.1000,\n",
      "          0.1000, 61.2549, 61.2549,  0.1000, 61.2549,  0.1000, 61.2549, 61.3266,\n",
      "         61.3266, 61.3266,  0.1000,  0.1000, 61.3266, 61.3266,  0.1000, 61.3266,\n",
      "          0.1000, 61.3266, 61.3088, 61.3266, 61.3266, 61.3266, 61.2549, 61.3266,\n",
      "         61.3266, 61.3266, 61.3088, 61.3266, 61.3266, 61.3266, 61.3088, 61.2549,\n",
      "         61.3088, 61.3088, 61.3088,  0.1000, 61.3088, 61.2549,  0.1000, 61.2549,\n",
      "         61.3266,  0.1000, 61.3266, 61.3266, 61.3266, 61.3088, 61.3088,  0.1000,\n",
      "         61.3266,  0.1000, 61.2139, 61.2139, 61.3088, 61.3266, 61.3266,  0.1000,\n",
      "          0.1000, 61.2139, 61.3088, 61.3266,  0.1000, 61.3088, 61.3266,  0.1000,\n",
      "         61.2139, 61.3266]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 484 was 98.7%\n",
      "current params: tensor([61.2139, 61.3088, 61.2549, 61.3266], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.7\n",
      "SLow rates:  tensor([[61.3143, 61.4092, 61.3553, 61.4269,  0.1000,  0.1000,  0.1000, 61.3143,\n",
      "         61.3143, 61.3143,  0.1000,  0.1000, 61.4092, 61.4092, 61.4092,  0.1000,\n",
      "          0.1000, 61.4092, 61.4092,  0.1000, 61.3553, 61.3553, 61.3553,  0.1000,\n",
      "          0.1000, 61.3553, 61.3553,  0.1000, 61.3553,  0.1000, 61.3553, 61.4269,\n",
      "         61.4269, 61.4269,  0.1000,  0.1000, 61.4269, 61.4269,  0.1000, 61.4269,\n",
      "          0.1000, 61.4269, 61.4092, 61.4269, 61.4269, 61.4269, 61.3553, 61.4269,\n",
      "         61.4269, 61.4269, 61.4092, 61.4269, 61.4269, 61.4269, 61.4092, 61.3553,\n",
      "         61.4092, 61.4092, 61.4092,  0.1000, 61.4092, 61.3553,  0.1000, 61.3553,\n",
      "         61.4269,  0.1000, 61.4269, 61.4269, 61.4269, 61.4092, 61.4092,  0.1000,\n",
      "         61.4269,  0.1000, 61.3143, 61.3143, 61.4092, 61.4269, 61.4269,  0.1000,\n",
      "          0.1000, 61.3143, 61.4092, 61.4269,  0.1000, 61.4092, 61.4269,  0.1000,\n",
      "         61.3143, 61.4269]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 485 was 98.7%\n",
      "current params: tensor([61.3143, 61.4092, 61.3553, 61.4269], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.7\n",
      "SLow rates:  tensor([[61.4146, 61.5095, 61.4556, 61.5273,  0.1000,  0.1000,  0.1000, 61.4146,\n",
      "         61.4146, 61.4146,  0.1000,  0.1000, 61.5095, 61.5095, 61.5095,  0.1000,\n",
      "          0.1000, 61.5095, 61.5095,  0.1000, 61.4556, 61.4556, 61.4556,  0.1000,\n",
      "          0.1000, 61.4556, 61.4556,  0.1000, 61.4556,  0.1000, 61.4556, 61.5273,\n",
      "         61.5273, 61.5273,  0.1000,  0.1000, 61.5273, 61.5273,  0.1000, 61.5273,\n",
      "          0.1000, 61.5273, 61.5095, 61.5273, 61.5273, 61.5273, 61.4556, 61.5273,\n",
      "         61.5273, 61.5273, 61.5095, 61.5273, 61.5273, 61.5273, 61.5095, 61.4556,\n",
      "         61.5095, 61.5095, 61.5095,  0.1000, 61.5095, 61.4556,  0.1000, 61.4556,\n",
      "         61.5273,  0.1000, 61.5273, 61.5273, 61.5273, 61.5095, 61.5095,  0.1000,\n",
      "         61.5273,  0.1000, 61.4146, 61.4146, 61.5095, 61.5273, 61.5273,  0.1000,\n",
      "          0.1000, 61.4146, 61.5095, 61.5273,  0.1000, 61.5095, 61.5273,  0.1000,\n",
      "         61.4146, 61.5273]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 486 was 98.7%\n",
      "current params: tensor([61.4146, 61.5095, 61.4556, 61.5273], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.7\n",
      "SLow rates:  tensor([[61.5150, 61.6099, 61.5560, 61.6276,  0.1000,  0.1000,  0.1000, 61.5150,\n",
      "         61.5150, 61.5150,  0.1000,  0.1000, 61.6099, 61.6099, 61.6099,  0.1000,\n",
      "          0.1000, 61.6099, 61.6099,  0.1000, 61.5560, 61.5560, 61.5560,  0.1000,\n",
      "          0.1000, 61.5560, 61.5560,  0.1000, 61.5560,  0.1000, 61.5560, 61.6276,\n",
      "         61.6276, 61.6276,  0.1000,  0.1000, 61.6276, 61.6276,  0.1000, 61.6276,\n",
      "          0.1000, 61.6276, 61.6099, 61.6276, 61.6276, 61.6276, 61.5560, 61.6276,\n",
      "         61.6276, 61.6276, 61.6099, 61.6276, 61.6276, 61.6276, 61.6099, 61.5560,\n",
      "         61.6099, 61.6099, 61.6099,  0.1000, 61.6099, 61.5560,  0.1000, 61.5560,\n",
      "         61.6276,  0.1000, 61.6276, 61.6276, 61.6276, 61.6099, 61.6099,  0.1000,\n",
      "         61.6276,  0.1000, 61.5150, 61.5150, 61.6099, 61.6276, 61.6276,  0.1000,\n",
      "          0.1000, 61.5150, 61.6099, 61.6276,  0.1000, 61.6099, 61.6276,  0.1000,\n",
      "         61.5150, 61.6276]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 487 was 98.7%\n",
      "current params: tensor([61.5150, 61.6099, 61.5560, 61.6276], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.8\n",
      "SLow rates:  tensor([[61.6154, 61.7102, 61.6564, 61.7279,  0.1000,  0.1000,  0.1000, 61.6154,\n",
      "         61.6154, 61.6154,  0.1000,  0.1000, 61.7102, 61.7102, 61.7102,  0.1000,\n",
      "          0.1000, 61.7102, 61.7102,  0.1000, 61.6564, 61.6564, 61.6564,  0.1000,\n",
      "          0.1000, 61.6564, 61.6564,  0.1000, 61.6564,  0.1000, 61.6564, 61.7279,\n",
      "         61.7279, 61.7279,  0.1000,  0.1000, 61.7279, 61.7279,  0.1000, 61.7279,\n",
      "          0.1000, 61.7279, 61.7102, 61.7279, 61.7279, 61.7279, 61.6564, 61.7279,\n",
      "         61.7279, 61.7279, 61.7102, 61.7279, 61.7279, 61.7279, 61.7102, 61.6564,\n",
      "         61.7102, 61.7102, 61.7102,  0.1000, 61.7102, 61.6564,  0.1000, 61.6564,\n",
      "         61.7279,  0.1000, 61.7279, 61.7279, 61.7279, 61.7102, 61.7102,  0.1000,\n",
      "         61.7279,  0.1000, 61.6154, 61.6154, 61.7102, 61.7279, 61.7279,  0.1000,\n",
      "          0.1000, 61.6154, 61.7102, 61.7279,  0.1000, 61.7102, 61.7279,  0.1000,\n",
      "         61.6154, 61.7279]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 488 was 98.7%\n",
      "current params: tensor([61.6154, 61.7102, 61.6564, 61.7279], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.8\n",
      "SLow rates:  tensor([[61.7157, 61.8106, 61.7567, 61.8283,  0.1000,  0.1000,  0.1000, 61.7157,\n",
      "         61.7157, 61.7157,  0.1000,  0.1000, 61.8106, 61.8106, 61.8106,  0.1000,\n",
      "          0.1000, 61.8106, 61.8106,  0.1000, 61.7567, 61.7567, 61.7567,  0.1000,\n",
      "          0.1000, 61.7567, 61.7567,  0.1000, 61.7567,  0.1000, 61.7567, 61.8283,\n",
      "         61.8283, 61.8283,  0.1000,  0.1000, 61.8283, 61.8283,  0.1000, 61.8283,\n",
      "          0.1000, 61.8283, 61.8106, 61.8283, 61.8283, 61.8283, 61.7567, 61.8283,\n",
      "         61.8283, 61.8283, 61.8106, 61.8283, 61.8283, 61.8283, 61.8106, 61.7567,\n",
      "         61.8106, 61.8106, 61.8106,  0.1000, 61.8106, 61.7567,  0.1000, 61.7567,\n",
      "         61.8283,  0.1000, 61.8283, 61.8283, 61.8283, 61.8106, 61.8106,  0.1000,\n",
      "         61.8283,  0.1000, 61.7157, 61.7157, 61.8106, 61.8283, 61.8283,  0.1000,\n",
      "          0.1000, 61.7157, 61.8106, 61.8283,  0.1000, 61.8106, 61.8283,  0.1000,\n",
      "         61.7157, 61.8283]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 489 was 98.7%\n",
      "current params: tensor([61.7157, 61.8106, 61.7567, 61.8283], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.8\n",
      "SLow rates:  tensor([[61.8161, 61.9109, 61.8571, 61.9286,  0.1000,  0.1000,  0.1000, 61.8161,\n",
      "         61.8161, 61.8161,  0.1000,  0.1000, 61.9109, 61.9109, 61.9109,  0.1000,\n",
      "          0.1000, 61.9109, 61.9109,  0.1000, 61.8571, 61.8571, 61.8571,  0.1000,\n",
      "          0.1000, 61.8571, 61.8571,  0.1000, 61.8571,  0.1000, 61.8571, 61.9286,\n",
      "         61.9286, 61.9286,  0.1000,  0.1000, 61.9286, 61.9286,  0.1000, 61.9286,\n",
      "          0.1000, 61.9286, 61.9109, 61.9286, 61.9286, 61.9286, 61.8571, 61.9286,\n",
      "         61.9286, 61.9286, 61.9109, 61.9286, 61.9286, 61.9286, 61.9109, 61.8571,\n",
      "         61.9109, 61.9109, 61.9109,  0.1000, 61.9109, 61.8571,  0.1000, 61.8571,\n",
      "         61.9286,  0.1000, 61.9286, 61.9286, 61.9286, 61.9109, 61.9109,  0.1000,\n",
      "         61.9286,  0.1000, 61.8161, 61.8161, 61.9109, 61.9286, 61.9286,  0.1000,\n",
      "          0.1000, 61.8161, 61.9109, 61.9286,  0.1000, 61.9109, 61.9286,  0.1000,\n",
      "         61.8161, 61.9286]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 490 was 98.7%\n",
      "current params: tensor([61.8161, 61.9109, 61.8571, 61.9286], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.8\n",
      "SLow rates:  tensor([[61.9164, 62.0113, 61.9574, 62.0290,  0.1000,  0.1000,  0.1000, 61.9164,\n",
      "         61.9164, 61.9164,  0.1000,  0.1000, 62.0113, 62.0113, 62.0113,  0.1000,\n",
      "          0.1000, 62.0113, 62.0113,  0.1000, 61.9574, 61.9574, 61.9574,  0.1000,\n",
      "          0.1000, 61.9574, 61.9574,  0.1000, 61.9574,  0.1000, 61.9574, 62.0290,\n",
      "         62.0290, 62.0290,  0.1000,  0.1000, 62.0290, 62.0290,  0.1000, 62.0290,\n",
      "          0.1000, 62.0290, 62.0113, 62.0290, 62.0290, 62.0290, 61.9574, 62.0290,\n",
      "         62.0290, 62.0290, 62.0113, 62.0290, 62.0290, 62.0290, 62.0113, 61.9574,\n",
      "         62.0113, 62.0113, 62.0113,  0.1000, 62.0113, 61.9574,  0.1000, 61.9574,\n",
      "         62.0290,  0.1000, 62.0290, 62.0290, 62.0290, 62.0113, 62.0113,  0.1000,\n",
      "         62.0290,  0.1000, 61.9164, 61.9164, 62.0113, 62.0290, 62.0290,  0.1000,\n",
      "          0.1000, 61.9164, 62.0113, 62.0290,  0.1000, 62.0113, 62.0290,  0.1000,\n",
      "         61.9164, 62.0290]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 491 was 98.7%\n",
      "current params: tensor([61.9164, 62.0113, 61.9574, 62.0290], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.8\n",
      "SLow rates:  tensor([[62.0168, 62.1116, 62.0577, 62.1293,  0.1000,  0.1000,  0.1000, 62.0168,\n",
      "         62.0168, 62.0168,  0.1000,  0.1000, 62.1116, 62.1116, 62.1116,  0.1000,\n",
      "          0.1000, 62.1116, 62.1116,  0.1000, 62.0577, 62.0577, 62.0577,  0.1000,\n",
      "          0.1000, 62.0577, 62.0577,  0.1000, 62.0577,  0.1000, 62.0577, 62.1293,\n",
      "         62.1293, 62.1293,  0.1000,  0.1000, 62.1293, 62.1293,  0.1000, 62.1293,\n",
      "          0.1000, 62.1293, 62.1116, 62.1293, 62.1293, 62.1293, 62.0577, 62.1293,\n",
      "         62.1293, 62.1293, 62.1116, 62.1293, 62.1293, 62.1293, 62.1116, 62.0577,\n",
      "         62.1116, 62.1116, 62.1116,  0.1000, 62.1116, 62.0577,  0.1000, 62.0577,\n",
      "         62.1293,  0.1000, 62.1293, 62.1293, 62.1293, 62.1116, 62.1116,  0.1000,\n",
      "         62.1293,  0.1000, 62.0168, 62.0168, 62.1116, 62.1293, 62.1293,  0.1000,\n",
      "          0.1000, 62.0168, 62.1116, 62.1293,  0.1000, 62.1116, 62.1293,  0.1000,\n",
      "         62.0168, 62.1293]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 492 was 98.7%\n",
      "current params: tensor([62.0168, 62.1116, 62.0577, 62.1293], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.9\n",
      "SLow rates:  tensor([[62.1171, 62.2119, 62.1581, 62.2296,  0.1000,  0.1000,  0.1000, 62.1171,\n",
      "         62.1171, 62.1171,  0.1000,  0.1000, 62.2119, 62.2119, 62.2119,  0.1000,\n",
      "          0.1000, 62.2119, 62.2119,  0.1000, 62.1581, 62.1581, 62.1581,  0.1000,\n",
      "          0.1000, 62.1581, 62.1581,  0.1000, 62.1581,  0.1000, 62.1581, 62.2296,\n",
      "         62.2296, 62.2296,  0.1000,  0.1000, 62.2296, 62.2296,  0.1000, 62.2296,\n",
      "          0.1000, 62.2296, 62.2119, 62.2296, 62.2296, 62.2296, 62.1581, 62.2296,\n",
      "         62.2296, 62.2296, 62.2119, 62.2296, 62.2296, 62.2296, 62.2119, 62.1581,\n",
      "         62.2119, 62.2119, 62.2119,  0.1000, 62.2119, 62.1581,  0.1000, 62.1581,\n",
      "         62.2296,  0.1000, 62.2296, 62.2296, 62.2296, 62.2119, 62.2119,  0.1000,\n",
      "         62.2296,  0.1000, 62.1171, 62.1171, 62.2119, 62.2296, 62.2296,  0.1000,\n",
      "          0.1000, 62.1171, 62.2119, 62.2296,  0.1000, 62.2119, 62.2296,  0.1000,\n",
      "         62.1171, 62.2296]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 493 was 98.7%\n",
      "current params: tensor([62.1171, 62.2119, 62.1581, 62.2296], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.9\n",
      "SLow rates:  tensor([[62.2174, 62.3123, 62.2584, 62.3299,  0.1000,  0.1000,  0.1000, 62.2174,\n",
      "         62.2174, 62.2174,  0.1000,  0.1000, 62.3123, 62.3123, 62.3123,  0.1000,\n",
      "          0.1000, 62.3123, 62.3123,  0.1000, 62.2584, 62.2584, 62.2584,  0.1000,\n",
      "          0.1000, 62.2584, 62.2584,  0.1000, 62.2584,  0.1000, 62.2584, 62.3299,\n",
      "         62.3299, 62.3299,  0.1000,  0.1000, 62.3299, 62.3299,  0.1000, 62.3299,\n",
      "          0.1000, 62.3299, 62.3123, 62.3299, 62.3299, 62.3299, 62.2584, 62.3299,\n",
      "         62.3299, 62.3299, 62.3123, 62.3299, 62.3299, 62.3299, 62.3123, 62.2584,\n",
      "         62.3123, 62.3123, 62.3123,  0.1000, 62.3123, 62.2584,  0.1000, 62.2584,\n",
      "         62.3299,  0.1000, 62.3299, 62.3299, 62.3299, 62.3123, 62.3123,  0.1000,\n",
      "         62.3299,  0.1000, 62.2174, 62.2174, 62.3123, 62.3299, 62.3299,  0.1000,\n",
      "          0.1000, 62.2174, 62.3123, 62.3299,  0.1000, 62.3123, 62.3299,  0.1000,\n",
      "         62.2174, 62.3299]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 494 was 98.8%\n",
      "current params: tensor([62.2174, 62.3123, 62.2584, 62.3299], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.9\n",
      "SLow rates:  tensor([[62.3178, 62.4126, 62.3587, 62.4302,  0.1000,  0.1000,  0.1000, 62.3178,\n",
      "         62.3178, 62.3178,  0.1000,  0.1000, 62.4126, 62.4126, 62.4126,  0.1000,\n",
      "          0.1000, 62.4126, 62.4126,  0.1000, 62.3587, 62.3587, 62.3587,  0.1000,\n",
      "          0.1000, 62.3587, 62.3587,  0.1000, 62.3587,  0.1000, 62.3587, 62.4302,\n",
      "         62.4302, 62.4302,  0.1000,  0.1000, 62.4302, 62.4302,  0.1000, 62.4302,\n",
      "          0.1000, 62.4302, 62.4126, 62.4302, 62.4302, 62.4302, 62.3587, 62.4302,\n",
      "         62.4302, 62.4302, 62.4126, 62.4302, 62.4302, 62.4302, 62.4126, 62.3587,\n",
      "         62.4126, 62.4126, 62.4126,  0.1000, 62.4126, 62.3587,  0.1000, 62.3587,\n",
      "         62.4302,  0.1000, 62.4302, 62.4302, 62.4302, 62.4126, 62.4126,  0.1000,\n",
      "         62.4302,  0.1000, 62.3178, 62.3178, 62.4126, 62.4302, 62.4302,  0.1000,\n",
      "          0.1000, 62.3178, 62.4126, 62.4302,  0.1000, 62.4126, 62.4302,  0.1000,\n",
      "         62.3178, 62.4302]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 495 was 98.8%\n",
      "current params: tensor([62.3178, 62.4126, 62.3587, 62.4302], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.9\n",
      "SLow rates:  tensor([[62.4181, 62.5129, 62.4591, 62.5306,  0.1000,  0.1000,  0.1000, 62.4181,\n",
      "         62.4181, 62.4181,  0.1000,  0.1000, 62.5129, 62.5129, 62.5129,  0.1000,\n",
      "          0.1000, 62.5129, 62.5129,  0.1000, 62.4591, 62.4591, 62.4591,  0.1000,\n",
      "          0.1000, 62.4591, 62.4591,  0.1000, 62.4591,  0.1000, 62.4591, 62.5306,\n",
      "         62.5306, 62.5306,  0.1000,  0.1000, 62.5306, 62.5306,  0.1000, 62.5306,\n",
      "          0.1000, 62.5306, 62.5129, 62.5306, 62.5306, 62.5306, 62.4591, 62.5306,\n",
      "         62.5306, 62.5306, 62.5129, 62.5306, 62.5306, 62.5306, 62.5129, 62.4591,\n",
      "         62.5129, 62.5129, 62.5129,  0.1000, 62.5129, 62.4591,  0.1000, 62.4591,\n",
      "         62.5306,  0.1000, 62.5306, 62.5306, 62.5306, 62.5129, 62.5129,  0.1000,\n",
      "         62.5306,  0.1000, 62.4181, 62.4181, 62.5129, 62.5306, 62.5306,  0.1000,\n",
      "          0.1000, 62.4181, 62.5129, 62.5306,  0.1000, 62.5129, 62.5306,  0.1000,\n",
      "         62.4181, 62.5306]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 496 was 98.8%\n",
      "current params: tensor([62.4181, 62.5129, 62.4591, 62.5306], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.9\n",
      "SLow rates:  tensor([[62.5184, 62.6132, 62.5594, 62.6309,  0.1000,  0.1000,  0.1000, 62.5184,\n",
      "         62.5184, 62.5184,  0.1000,  0.1000, 62.6132, 62.6132, 62.6132,  0.1000,\n",
      "          0.1000, 62.6132, 62.6132,  0.1000, 62.5594, 62.5594, 62.5594,  0.1000,\n",
      "          0.1000, 62.5594, 62.5594,  0.1000, 62.5594,  0.1000, 62.5594, 62.6309,\n",
      "         62.6309, 62.6309,  0.1000,  0.1000, 62.6309, 62.6309,  0.1000, 62.6309,\n",
      "          0.1000, 62.6309, 62.6132, 62.6309, 62.6309, 62.6309, 62.5594, 62.6309,\n",
      "         62.6309, 62.6309, 62.6132, 62.6309, 62.6309, 62.6309, 62.6132, 62.5594,\n",
      "         62.6132, 62.6132, 62.6132,  0.1000, 62.6132, 62.5594,  0.1000, 62.5594,\n",
      "         62.6309,  0.1000, 62.6309, 62.6309, 62.6309, 62.6132, 62.6132,  0.1000,\n",
      "         62.6309,  0.1000, 62.5184, 62.5184, 62.6132, 62.6309, 62.6309,  0.1000,\n",
      "          0.1000, 62.5184, 62.6132, 62.6309,  0.1000, 62.6132, 62.6309,  0.1000,\n",
      "         62.5184, 62.6309]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 497 was 98.8%\n",
      "current params: tensor([62.5184, 62.6132, 62.5594, 62.6309], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  14.9\n",
      "SLow rates:  tensor([[62.6188, 62.7135, 62.6597, 62.7312,  0.1000,  0.1000,  0.1000, 62.6188,\n",
      "         62.6188, 62.6188,  0.1000,  0.1000, 62.7135, 62.7135, 62.7135,  0.1000,\n",
      "          0.1000, 62.7135, 62.7135,  0.1000, 62.6597, 62.6597, 62.6597,  0.1000,\n",
      "          0.1000, 62.6597, 62.6597,  0.1000, 62.6597,  0.1000, 62.6597, 62.7312,\n",
      "         62.7312, 62.7312,  0.1000,  0.1000, 62.7312, 62.7312,  0.1000, 62.7312,\n",
      "          0.1000, 62.7312, 62.7135, 62.7312, 62.7312, 62.7312, 62.6597, 62.7312,\n",
      "         62.7312, 62.7312, 62.7135, 62.7312, 62.7312, 62.7312, 62.7135, 62.6597,\n",
      "         62.7135, 62.7135, 62.7135,  0.1000, 62.7135, 62.6597,  0.1000, 62.6597,\n",
      "         62.7312,  0.1000, 62.7312, 62.7312, 62.7312, 62.7135, 62.7135,  0.1000,\n",
      "         62.7312,  0.1000, 62.6188, 62.6188, 62.7135, 62.7312, 62.7312,  0.1000,\n",
      "          0.1000, 62.6188, 62.7135, 62.7312,  0.1000, 62.7135, 62.7312,  0.1000,\n",
      "         62.6188, 62.7312]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 498 was 98.8%\n",
      "current params: tensor([62.6188, 62.7135, 62.6597, 62.7312], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.0\n",
      "SLow rates:  tensor([[62.7191, 62.8139, 62.7600, 62.8315,  0.1000,  0.1000,  0.1000, 62.7191,\n",
      "         62.7191, 62.7191,  0.1000,  0.1000, 62.8139, 62.8139, 62.8139,  0.1000,\n",
      "          0.1000, 62.8139, 62.8139,  0.1000, 62.7600, 62.7600, 62.7600,  0.1000,\n",
      "          0.1000, 62.7600, 62.7600,  0.1000, 62.7600,  0.1000, 62.7600, 62.8315,\n",
      "         62.8315, 62.8315,  0.1000,  0.1000, 62.8315, 62.8315,  0.1000, 62.8315,\n",
      "          0.1000, 62.8315, 62.8139, 62.8315, 62.8315, 62.8315, 62.7600, 62.8315,\n",
      "         62.8315, 62.8315, 62.8139, 62.8315, 62.8315, 62.8315, 62.8139, 62.7600,\n",
      "         62.8139, 62.8139, 62.8139,  0.1000, 62.8139, 62.7600,  0.1000, 62.7600,\n",
      "         62.8315,  0.1000, 62.8315, 62.8315, 62.8315, 62.8139, 62.8139,  0.1000,\n",
      "         62.8315,  0.1000, 62.7191, 62.7191, 62.8139, 62.8315, 62.8315,  0.1000,\n",
      "          0.1000, 62.7191, 62.8139, 62.8315,  0.1000, 62.8139, 62.8315,  0.1000,\n",
      "         62.7191, 62.8315]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 499 was 98.8%\n",
      "current params: tensor([62.7191, 62.8139, 62.7600, 62.8315], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.0\n",
      "SLow rates:  tensor([[62.8194, 62.9142, 62.8603, 62.9318,  0.1000,  0.1000,  0.1000, 62.8194,\n",
      "         62.8194, 62.8194,  0.1000,  0.1000, 62.9142, 62.9142, 62.9142,  0.1000,\n",
      "          0.1000, 62.9142, 62.9142,  0.1000, 62.8603, 62.8603, 62.8603,  0.1000,\n",
      "          0.1000, 62.8603, 62.8603,  0.1000, 62.8603,  0.1000, 62.8603, 62.9318,\n",
      "         62.9318, 62.9318,  0.1000,  0.1000, 62.9318, 62.9318,  0.1000, 62.9318,\n",
      "          0.1000, 62.9318, 62.9142, 62.9318, 62.9318, 62.9318, 62.8603, 62.9318,\n",
      "         62.9318, 62.9318, 62.9142, 62.9318, 62.9318, 62.9318, 62.9142, 62.8603,\n",
      "         62.9142, 62.9142, 62.9142,  0.1000, 62.9142, 62.8603,  0.1000, 62.8603,\n",
      "         62.9318,  0.1000, 62.9318, 62.9318, 62.9318, 62.9142, 62.9142,  0.1000,\n",
      "         62.9318,  0.1000, 62.8194, 62.8194, 62.9142, 62.9318, 62.9318,  0.1000,\n",
      "          0.1000, 62.8194, 62.9142, 62.9318,  0.1000, 62.9142, 62.9318,  0.1000,\n",
      "         62.8194, 62.9318]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 500 was 98.8%\n",
      "current params: tensor([62.8194, 62.9142, 62.8603, 62.9318], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.0\n",
      "SLow rates:  tensor([[62.9197, 63.0145, 62.9606, 63.0321,  0.1000,  0.1000,  0.1000, 62.9197,\n",
      "         62.9197, 62.9197,  0.1000,  0.1000, 63.0145, 63.0145, 63.0145,  0.1000,\n",
      "          0.1000, 63.0145, 63.0145,  0.1000, 62.9606, 62.9606, 62.9606,  0.1000,\n",
      "          0.1000, 62.9606, 62.9606,  0.1000, 62.9606,  0.1000, 62.9606, 63.0321,\n",
      "         63.0321, 63.0321,  0.1000,  0.1000, 63.0321, 63.0321,  0.1000, 63.0321,\n",
      "          0.1000, 63.0321, 63.0145, 63.0321, 63.0321, 63.0321, 62.9606, 63.0321,\n",
      "         63.0321, 63.0321, 63.0145, 63.0321, 63.0321, 63.0321, 63.0145, 62.9606,\n",
      "         63.0145, 63.0145, 63.0145,  0.1000, 63.0145, 62.9606,  0.1000, 62.9606,\n",
      "         63.0321,  0.1000, 63.0321, 63.0321, 63.0321, 63.0145, 63.0145,  0.1000,\n",
      "         63.0321,  0.1000, 62.9197, 62.9197, 63.0145, 63.0321, 63.0321,  0.1000,\n",
      "          0.1000, 62.9197, 63.0145, 63.0321,  0.1000, 63.0145, 63.0321,  0.1000,\n",
      "         62.9197, 63.0321]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 501 was 98.8%\n",
      "current params: tensor([62.9197, 63.0145, 62.9606, 63.0321], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.0\n",
      "SLow rates:  tensor([[63.0200, 63.1148, 63.0609, 63.1324,  0.1000,  0.1000,  0.1000, 63.0200,\n",
      "         63.0200, 63.0200,  0.1000,  0.1000, 63.1148, 63.1148, 63.1148,  0.1000,\n",
      "          0.1000, 63.1148, 63.1148,  0.1000, 63.0609, 63.0609, 63.0609,  0.1000,\n",
      "          0.1000, 63.0609, 63.0609,  0.1000, 63.0609,  0.1000, 63.0609, 63.1324,\n",
      "         63.1324, 63.1324,  0.1000,  0.1000, 63.1324, 63.1324,  0.1000, 63.1324,\n",
      "          0.1000, 63.1324, 63.1148, 63.1324, 63.1324, 63.1324, 63.0609, 63.1324,\n",
      "         63.1324, 63.1324, 63.1148, 63.1324, 63.1324, 63.1324, 63.1148, 63.0609,\n",
      "         63.1148, 63.1148, 63.1148,  0.1000, 63.1148, 63.0609,  0.1000, 63.0609,\n",
      "         63.1324,  0.1000, 63.1324, 63.1324, 63.1324, 63.1148, 63.1148,  0.1000,\n",
      "         63.1324,  0.1000, 63.0200, 63.0200, 63.1148, 63.1324, 63.1324,  0.1000,\n",
      "          0.1000, 63.0200, 63.1148, 63.1324,  0.1000, 63.1148, 63.1324,  0.1000,\n",
      "         63.0200, 63.1324]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 502 was 98.8%\n",
      "current params: tensor([63.0200, 63.1148, 63.0609, 63.1324], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.0\n",
      "SLow rates:  tensor([[63.1203, 63.2151, 63.1612, 63.2327,  0.1000,  0.1000,  0.1000, 63.1203,\n",
      "         63.1203, 63.1203,  0.1000,  0.1000, 63.2151, 63.2151, 63.2151,  0.1000,\n",
      "          0.1000, 63.2151, 63.2151,  0.1000, 63.1612, 63.1612, 63.1612,  0.1000,\n",
      "          0.1000, 63.1612, 63.1612,  0.1000, 63.1612,  0.1000, 63.1612, 63.2327,\n",
      "         63.2327, 63.2327,  0.1000,  0.1000, 63.2327, 63.2327,  0.1000, 63.2327,\n",
      "          0.1000, 63.2327, 63.2151, 63.2327, 63.2327, 63.2327, 63.1612, 63.2327,\n",
      "         63.2327, 63.2327, 63.2151, 63.2327, 63.2327, 63.2327, 63.2151, 63.1612,\n",
      "         63.2151, 63.2151, 63.2151,  0.1000, 63.2151, 63.1612,  0.1000, 63.1612,\n",
      "         63.2327,  0.1000, 63.2327, 63.2327, 63.2327, 63.2151, 63.2151,  0.1000,\n",
      "         63.2327,  0.1000, 63.1203, 63.1203, 63.2151, 63.2327, 63.2327,  0.1000,\n",
      "          0.1000, 63.1203, 63.2151, 63.2327,  0.1000, 63.2151, 63.2327,  0.1000,\n",
      "         63.1203, 63.2327]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 503 was 98.8%\n",
      "current params: tensor([63.1203, 63.2151, 63.1612, 63.2327], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.1\n",
      "SLow rates:  tensor([[63.2206, 63.3154, 63.2615, 63.3330,  0.1000,  0.1000,  0.1000, 63.2206,\n",
      "         63.2206, 63.2206,  0.1000,  0.1000, 63.3154, 63.3154, 63.3154,  0.1000,\n",
      "          0.1000, 63.3154, 63.3154,  0.1000, 63.2615, 63.2615, 63.2615,  0.1000,\n",
      "          0.1000, 63.2615, 63.2615,  0.1000, 63.2615,  0.1000, 63.2615, 63.3330,\n",
      "         63.3330, 63.3330,  0.1000,  0.1000, 63.3330, 63.3330,  0.1000, 63.3330,\n",
      "          0.1000, 63.3330, 63.3154, 63.3330, 63.3330, 63.3330, 63.2615, 63.3330,\n",
      "         63.3330, 63.3330, 63.3154, 63.3330, 63.3330, 63.3330, 63.3154, 63.2615,\n",
      "         63.3154, 63.3154, 63.3154,  0.1000, 63.3154, 63.2615,  0.1000, 63.2615,\n",
      "         63.3330,  0.1000, 63.3330, 63.3330, 63.3330, 63.3154, 63.3154,  0.1000,\n",
      "         63.3330,  0.1000, 63.2206, 63.2206, 63.3154, 63.3330, 63.3330,  0.1000,\n",
      "          0.1000, 63.2206, 63.3154, 63.3330,  0.1000, 63.3154, 63.3330,  0.1000,\n",
      "         63.2206, 63.3330]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 504 was 98.8%\n",
      "current params: tensor([63.2206, 63.3154, 63.2615, 63.3330], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.1\n",
      "SLow rates:  tensor([[63.3209, 63.4157, 63.3618, 63.4333,  0.1000,  0.1000,  0.1000, 63.3209,\n",
      "         63.3209, 63.3209,  0.1000,  0.1000, 63.4157, 63.4157, 63.4157,  0.1000,\n",
      "          0.1000, 63.4157, 63.4157,  0.1000, 63.3618, 63.3618, 63.3618,  0.1000,\n",
      "          0.1000, 63.3618, 63.3618,  0.1000, 63.3618,  0.1000, 63.3618, 63.4333,\n",
      "         63.4333, 63.4333,  0.1000,  0.1000, 63.4333, 63.4333,  0.1000, 63.4333,\n",
      "          0.1000, 63.4333, 63.4157, 63.4333, 63.4333, 63.4333, 63.3618, 63.4333,\n",
      "         63.4333, 63.4333, 63.4157, 63.4333, 63.4333, 63.4333, 63.4157, 63.3618,\n",
      "         63.4157, 63.4157, 63.4157,  0.1000, 63.4157, 63.3618,  0.1000, 63.3618,\n",
      "         63.4333,  0.1000, 63.4333, 63.4333, 63.4333, 63.4157, 63.4157,  0.1000,\n",
      "         63.4333,  0.1000, 63.3209, 63.3209, 63.4157, 63.4333, 63.4333,  0.1000,\n",
      "          0.1000, 63.3209, 63.4157, 63.4333,  0.1000, 63.4157, 63.4333,  0.1000,\n",
      "         63.3209, 63.4333]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 505 was 98.8%\n",
      "current params: tensor([63.3209, 63.4157, 63.3618, 63.4333], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.1\n",
      "SLow rates:  tensor([[63.4212, 63.5159, 63.4621, 63.5335,  0.1000,  0.1000,  0.1000, 63.4212,\n",
      "         63.4212, 63.4212,  0.1000,  0.1000, 63.5159, 63.5159, 63.5159,  0.1000,\n",
      "          0.1000, 63.5159, 63.5159,  0.1000, 63.4621, 63.4621, 63.4621,  0.1000,\n",
      "          0.1000, 63.4621, 63.4621,  0.1000, 63.4621,  0.1000, 63.4621, 63.5335,\n",
      "         63.5335, 63.5335,  0.1000,  0.1000, 63.5335, 63.5335,  0.1000, 63.5335,\n",
      "          0.1000, 63.5335, 63.5159, 63.5335, 63.5335, 63.5335, 63.4621, 63.5335,\n",
      "         63.5335, 63.5335, 63.5159, 63.5335, 63.5335, 63.5335, 63.5159, 63.4621,\n",
      "         63.5159, 63.5159, 63.5159,  0.1000, 63.5159, 63.4621,  0.1000, 63.4621,\n",
      "         63.5335,  0.1000, 63.5335, 63.5335, 63.5335, 63.5159, 63.5159,  0.1000,\n",
      "         63.5335,  0.1000, 63.4212, 63.4212, 63.5159, 63.5335, 63.5335,  0.1000,\n",
      "          0.1000, 63.4212, 63.5159, 63.5335,  0.1000, 63.5159, 63.5335,  0.1000,\n",
      "         63.4212, 63.5335]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 506 was 98.8%\n",
      "current params: tensor([63.4212, 63.5159, 63.4621, 63.5335], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.1\n",
      "SLow rates:  tensor([[63.5215, 63.6162, 63.5624, 63.6338,  0.1000,  0.1000,  0.1000, 63.5215,\n",
      "         63.5215, 63.5215,  0.1000,  0.1000, 63.6162, 63.6162, 63.6162,  0.1000,\n",
      "          0.1000, 63.6162, 63.6162,  0.1000, 63.5624, 63.5624, 63.5624,  0.1000,\n",
      "          0.1000, 63.5624, 63.5624,  0.1000, 63.5624,  0.1000, 63.5624, 63.6338,\n",
      "         63.6338, 63.6338,  0.1000,  0.1000, 63.6338, 63.6338,  0.1000, 63.6338,\n",
      "          0.1000, 63.6338, 63.6162, 63.6338, 63.6338, 63.6338, 63.5624, 63.6338,\n",
      "         63.6338, 63.6338, 63.6162, 63.6338, 63.6338, 63.6338, 63.6162, 63.5624,\n",
      "         63.6162, 63.6162, 63.6162,  0.1000, 63.6162, 63.5624,  0.1000, 63.5624,\n",
      "         63.6338,  0.1000, 63.6338, 63.6338, 63.6338, 63.6162, 63.6162,  0.1000,\n",
      "         63.6338,  0.1000, 63.5215, 63.5215, 63.6162, 63.6338, 63.6338,  0.1000,\n",
      "          0.1000, 63.5215, 63.6162, 63.6338,  0.1000, 63.6162, 63.6338,  0.1000,\n",
      "         63.5215, 63.6338]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 507 was 98.8%\n",
      "current params: tensor([63.5215, 63.6162, 63.5624, 63.6338], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.1\n",
      "SLow rates:  tensor([[63.6218, 63.7165, 63.6627, 63.7341,  0.1000,  0.1000,  0.1000, 63.6218,\n",
      "         63.6218, 63.6218,  0.1000,  0.1000, 63.7165, 63.7165, 63.7165,  0.1000,\n",
      "          0.1000, 63.7165, 63.7165,  0.1000, 63.6627, 63.6627, 63.6627,  0.1000,\n",
      "          0.1000, 63.6627, 63.6627,  0.1000, 63.6627,  0.1000, 63.6627, 63.7341,\n",
      "         63.7341, 63.7341,  0.1000,  0.1000, 63.7341, 63.7341,  0.1000, 63.7341,\n",
      "          0.1000, 63.7341, 63.7165, 63.7341, 63.7341, 63.7341, 63.6627, 63.7341,\n",
      "         63.7341, 63.7341, 63.7165, 63.7341, 63.7341, 63.7341, 63.7165, 63.6627,\n",
      "         63.7165, 63.7165, 63.7165,  0.1000, 63.7165, 63.6627,  0.1000, 63.6627,\n",
      "         63.7341,  0.1000, 63.7341, 63.7341, 63.7341, 63.7165, 63.7165,  0.1000,\n",
      "         63.7341,  0.1000, 63.6218, 63.6218, 63.7165, 63.7341, 63.7341,  0.1000,\n",
      "          0.1000, 63.6218, 63.7165, 63.7341,  0.1000, 63.7165, 63.7341,  0.1000,\n",
      "         63.6218, 63.7341]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 508 was 98.8%\n",
      "current params: tensor([63.6218, 63.7165, 63.6627, 63.7341], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.2\n",
      "SLow rates:  tensor([[63.7221, 63.8168, 63.7630, 63.8344,  0.1000,  0.1000,  0.1000, 63.7221,\n",
      "         63.7221, 63.7221,  0.1000,  0.1000, 63.8168, 63.8168, 63.8168,  0.1000,\n",
      "          0.1000, 63.8168, 63.8168,  0.1000, 63.7630, 63.7630, 63.7630,  0.1000,\n",
      "          0.1000, 63.7630, 63.7630,  0.1000, 63.7630,  0.1000, 63.7630, 63.8344,\n",
      "         63.8344, 63.8344,  0.1000,  0.1000, 63.8344, 63.8344,  0.1000, 63.8344,\n",
      "          0.1000, 63.8344, 63.8168, 63.8344, 63.8344, 63.8344, 63.7630, 63.8344,\n",
      "         63.8344, 63.8344, 63.8168, 63.8344, 63.8344, 63.8344, 63.8168, 63.7630,\n",
      "         63.8168, 63.8168, 63.8168,  0.1000, 63.8168, 63.7630,  0.1000, 63.7630,\n",
      "         63.8344,  0.1000, 63.8344, 63.8344, 63.8344, 63.8168, 63.8168,  0.1000,\n",
      "         63.8344,  0.1000, 63.7221, 63.7221, 63.8168, 63.8344, 63.8344,  0.1000,\n",
      "          0.1000, 63.7221, 63.8168, 63.8344,  0.1000, 63.8168, 63.8344,  0.1000,\n",
      "         63.7221, 63.8344]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 509 was 98.8%\n",
      "current params: tensor([63.7221, 63.8168, 63.7630, 63.8344], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.2\n",
      "SLow rates:  tensor([[63.8224, 63.9171, 63.8633, 63.9347,  0.1000,  0.1000,  0.1000, 63.8224,\n",
      "         63.8224, 63.8224,  0.1000,  0.1000, 63.9171, 63.9171, 63.9171,  0.1000,\n",
      "          0.1000, 63.9171, 63.9171,  0.1000, 63.8633, 63.8633, 63.8633,  0.1000,\n",
      "          0.1000, 63.8633, 63.8633,  0.1000, 63.8633,  0.1000, 63.8633, 63.9347,\n",
      "         63.9347, 63.9347,  0.1000,  0.1000, 63.9347, 63.9347,  0.1000, 63.9347,\n",
      "          0.1000, 63.9347, 63.9171, 63.9347, 63.9347, 63.9347, 63.8633, 63.9347,\n",
      "         63.9347, 63.9347, 63.9171, 63.9347, 63.9347, 63.9347, 63.9171, 63.8633,\n",
      "         63.9171, 63.9171, 63.9171,  0.1000, 63.9171, 63.8633,  0.1000, 63.8633,\n",
      "         63.9347,  0.1000, 63.9347, 63.9347, 63.9347, 63.9171, 63.9171,  0.1000,\n",
      "         63.9347,  0.1000, 63.8224, 63.8224, 63.9171, 63.9347, 63.9347,  0.1000,\n",
      "          0.1000, 63.8224, 63.9171, 63.9347,  0.1000, 63.9171, 63.9347,  0.1000,\n",
      "         63.8224, 63.9347]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 510 was 98.8%\n",
      "current params: tensor([63.8224, 63.9171, 63.8633, 63.9347], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.2\n",
      "SLow rates:  tensor([[63.9227, 64.0174, 63.9636, 64.0349,  0.1000,  0.1000,  0.1000, 63.9227,\n",
      "         63.9227, 63.9227,  0.1000,  0.1000, 64.0174, 64.0174, 64.0174,  0.1000,\n",
      "          0.1000, 64.0174, 64.0174,  0.1000, 63.9636, 63.9636, 63.9636,  0.1000,\n",
      "          0.1000, 63.9636, 63.9636,  0.1000, 63.9636,  0.1000, 63.9636, 64.0349,\n",
      "         64.0349, 64.0349,  0.1000,  0.1000, 64.0349, 64.0349,  0.1000, 64.0349,\n",
      "          0.1000, 64.0349, 64.0174, 64.0349, 64.0349, 64.0349, 63.9636, 64.0349,\n",
      "         64.0349, 64.0349, 64.0174, 64.0349, 64.0349, 64.0349, 64.0174, 63.9636,\n",
      "         64.0174, 64.0174, 64.0174,  0.1000, 64.0174, 63.9636,  0.1000, 63.9636,\n",
      "         64.0349,  0.1000, 64.0349, 64.0349, 64.0349, 64.0174, 64.0174,  0.1000,\n",
      "         64.0349,  0.1000, 63.9227, 63.9227, 64.0174, 64.0349, 64.0349,  0.1000,\n",
      "          0.1000, 63.9227, 64.0174, 64.0349,  0.1000, 64.0174, 64.0349,  0.1000,\n",
      "         63.9227, 64.0349]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 511 was 98.8%\n",
      "current params: tensor([63.9227, 64.0174, 63.9636, 64.0349], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.2\n",
      "SLow rates:  tensor([[64.0230, 64.1176, 64.0638, 64.1352,  0.1000,  0.1000,  0.1000, 64.0230,\n",
      "         64.0230, 64.0230,  0.1000,  0.1000, 64.1176, 64.1176, 64.1176,  0.1000,\n",
      "          0.1000, 64.1176, 64.1176,  0.1000, 64.0638, 64.0638, 64.0638,  0.1000,\n",
      "          0.1000, 64.0638, 64.0638,  0.1000, 64.0638,  0.1000, 64.0638, 64.1352,\n",
      "         64.1352, 64.1352,  0.1000,  0.1000, 64.1352, 64.1352,  0.1000, 64.1352,\n",
      "          0.1000, 64.1352, 64.1176, 64.1352, 64.1352, 64.1352, 64.0638, 64.1352,\n",
      "         64.1352, 64.1352, 64.1176, 64.1352, 64.1352, 64.1352, 64.1176, 64.0638,\n",
      "         64.1176, 64.1176, 64.1176,  0.1000, 64.1176, 64.0638,  0.1000, 64.0638,\n",
      "         64.1352,  0.1000, 64.1352, 64.1352, 64.1352, 64.1176, 64.1176,  0.1000,\n",
      "         64.1352,  0.1000, 64.0230, 64.0230, 64.1176, 64.1352, 64.1352,  0.1000,\n",
      "          0.1000, 64.0230, 64.1176, 64.1352,  0.1000, 64.1176, 64.1352,  0.1000,\n",
      "         64.0230, 64.1352]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 512 was 98.8%\n",
      "current params: tensor([64.0230, 64.1176, 64.0638, 64.1352], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.2\n",
      "SLow rates:  tensor([[64.1232, 64.2179, 64.1641, 64.2355,  0.1000,  0.1000,  0.1000, 64.1232,\n",
      "         64.1232, 64.1232,  0.1000,  0.1000, 64.2179, 64.2179, 64.2179,  0.1000,\n",
      "          0.1000, 64.2179, 64.2179,  0.1000, 64.1641, 64.1641, 64.1641,  0.1000,\n",
      "          0.1000, 64.1641, 64.1641,  0.1000, 64.1641,  0.1000, 64.1641, 64.2355,\n",
      "         64.2355, 64.2355,  0.1000,  0.1000, 64.2355, 64.2355,  0.1000, 64.2355,\n",
      "          0.1000, 64.2355, 64.2179, 64.2355, 64.2355, 64.2355, 64.1641, 64.2355,\n",
      "         64.2355, 64.2355, 64.2179, 64.2355, 64.2355, 64.2355, 64.2179, 64.1641,\n",
      "         64.2179, 64.2179, 64.2179,  0.1000, 64.2179, 64.1641,  0.1000, 64.1641,\n",
      "         64.2355,  0.1000, 64.2355, 64.2355, 64.2355, 64.2179, 64.2179,  0.1000,\n",
      "         64.2355,  0.1000, 64.1232, 64.1232, 64.2179, 64.2355, 64.2355,  0.1000,\n",
      "          0.1000, 64.1232, 64.2179, 64.2355,  0.1000, 64.2179, 64.2355,  0.1000,\n",
      "         64.1232, 64.2355]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 513 was 98.8%\n",
      "current params: tensor([64.1232, 64.2179, 64.1641, 64.2355], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.2\n",
      "SLow rates:  tensor([[64.2235, 64.3182, 64.2644, 64.3357,  0.1000,  0.1000,  0.1000, 64.2235,\n",
      "         64.2235, 64.2235,  0.1000,  0.1000, 64.3182, 64.3182, 64.3182,  0.1000,\n",
      "          0.1000, 64.3182, 64.3182,  0.1000, 64.2644, 64.2644, 64.2644,  0.1000,\n",
      "          0.1000, 64.2644, 64.2644,  0.1000, 64.2644,  0.1000, 64.2644, 64.3357,\n",
      "         64.3357, 64.3357,  0.1000,  0.1000, 64.3357, 64.3357,  0.1000, 64.3357,\n",
      "          0.1000, 64.3357, 64.3182, 64.3357, 64.3357, 64.3357, 64.2644, 64.3357,\n",
      "         64.3357, 64.3357, 64.3182, 64.3357, 64.3357, 64.3357, 64.3182, 64.2644,\n",
      "         64.3182, 64.3182, 64.3182,  0.1000, 64.3182, 64.2644,  0.1000, 64.2644,\n",
      "         64.3357,  0.1000, 64.3357, 64.3357, 64.3357, 64.3182, 64.3182,  0.1000,\n",
      "         64.3357,  0.1000, 64.2235, 64.2235, 64.3182, 64.3357, 64.3357,  0.1000,\n",
      "          0.1000, 64.2235, 64.3182, 64.3357,  0.1000, 64.3182, 64.3357,  0.1000,\n",
      "         64.2235, 64.3357]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 514 was 98.8%\n",
      "current params: tensor([64.2235, 64.3182, 64.2644, 64.3357], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.3\n",
      "SLow rates:  tensor([[64.3238, 64.4184, 64.3646, 64.4360,  0.1000,  0.1000,  0.1000, 64.3238,\n",
      "         64.3238, 64.3238,  0.1000,  0.1000, 64.4184, 64.4184, 64.4184,  0.1000,\n",
      "          0.1000, 64.4184, 64.4184,  0.1000, 64.3646, 64.3646, 64.3646,  0.1000,\n",
      "          0.1000, 64.3646, 64.3646,  0.1000, 64.3646,  0.1000, 64.3646, 64.4360,\n",
      "         64.4360, 64.4360,  0.1000,  0.1000, 64.4360, 64.4360,  0.1000, 64.4360,\n",
      "          0.1000, 64.4360, 64.4184, 64.4360, 64.4360, 64.4360, 64.3646, 64.4360,\n",
      "         64.4360, 64.4360, 64.4184, 64.4360, 64.4360, 64.4360, 64.4184, 64.3646,\n",
      "         64.4184, 64.4184, 64.4184,  0.1000, 64.4184, 64.3646,  0.1000, 64.3646,\n",
      "         64.4360,  0.1000, 64.4360, 64.4360, 64.4360, 64.4184, 64.4184,  0.1000,\n",
      "         64.4360,  0.1000, 64.3238, 64.3238, 64.4184, 64.4360, 64.4360,  0.1000,\n",
      "          0.1000, 64.3238, 64.4184, 64.4360,  0.1000, 64.4184, 64.4360,  0.1000,\n",
      "         64.3238, 64.4360]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 515 was 98.8%\n",
      "current params: tensor([64.3238, 64.4184, 64.3646, 64.4360], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.3\n",
      "SLow rates:  tensor([[64.4240, 64.5187, 64.4649, 64.5362,  0.1000,  0.1000,  0.1000, 64.4240,\n",
      "         64.4240, 64.4240,  0.1000,  0.1000, 64.5187, 64.5187, 64.5187,  0.1000,\n",
      "          0.1000, 64.5187, 64.5187,  0.1000, 64.4649, 64.4649, 64.4649,  0.1000,\n",
      "          0.1000, 64.4649, 64.4649,  0.1000, 64.4649,  0.1000, 64.4649, 64.5362,\n",
      "         64.5362, 64.5362,  0.1000,  0.1000, 64.5362, 64.5362,  0.1000, 64.5362,\n",
      "          0.1000, 64.5362, 64.5187, 64.5362, 64.5362, 64.5362, 64.4649, 64.5362,\n",
      "         64.5362, 64.5362, 64.5187, 64.5362, 64.5362, 64.5362, 64.5187, 64.4649,\n",
      "         64.5187, 64.5187, 64.5187,  0.1000, 64.5187, 64.4649,  0.1000, 64.4649,\n",
      "         64.5362,  0.1000, 64.5362, 64.5362, 64.5362, 64.5187, 64.5187,  0.1000,\n",
      "         64.5362,  0.1000, 64.4240, 64.4240, 64.5187, 64.5362, 64.5362,  0.1000,\n",
      "          0.1000, 64.4240, 64.5187, 64.5362,  0.1000, 64.5187, 64.5362,  0.1000,\n",
      "         64.4240, 64.5362]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 516 was 98.8%\n",
      "current params: tensor([64.4240, 64.5187, 64.4649, 64.5362], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.3\n",
      "SLow rates:  tensor([[64.5243, 64.6189, 64.5652, 64.6365,  0.1000,  0.1000,  0.1000, 64.5243,\n",
      "         64.5243, 64.5243,  0.1000,  0.1000, 64.6189, 64.6189, 64.6189,  0.1000,\n",
      "          0.1000, 64.6189, 64.6189,  0.1000, 64.5652, 64.5652, 64.5652,  0.1000,\n",
      "          0.1000, 64.5652, 64.5652,  0.1000, 64.5652,  0.1000, 64.5652, 64.6365,\n",
      "         64.6365, 64.6365,  0.1000,  0.1000, 64.6365, 64.6365,  0.1000, 64.6365,\n",
      "          0.1000, 64.6365, 64.6189, 64.6365, 64.6365, 64.6365, 64.5652, 64.6365,\n",
      "         64.6365, 64.6365, 64.6189, 64.6365, 64.6365, 64.6365, 64.6189, 64.5652,\n",
      "         64.6189, 64.6189, 64.6189,  0.1000, 64.6189, 64.5652,  0.1000, 64.5652,\n",
      "         64.6365,  0.1000, 64.6365, 64.6365, 64.6365, 64.6189, 64.6189,  0.1000,\n",
      "         64.6365,  0.1000, 64.5243, 64.5243, 64.6189, 64.6365, 64.6365,  0.1000,\n",
      "          0.1000, 64.5243, 64.6189, 64.6365,  0.1000, 64.6189, 64.6365,  0.1000,\n",
      "         64.5243, 64.6365]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 517 was 98.8%\n",
      "current params: tensor([64.5243, 64.6189, 64.5652, 64.6365], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.3\n",
      "SLow rates:  tensor([[64.6246, 64.7192, 64.6654, 64.7367,  0.1000,  0.1000,  0.1000, 64.6246,\n",
      "         64.6246, 64.6246,  0.1000,  0.1000, 64.7192, 64.7192, 64.7192,  0.1000,\n",
      "          0.1000, 64.7192, 64.7192,  0.1000, 64.6654, 64.6654, 64.6654,  0.1000,\n",
      "          0.1000, 64.6654, 64.6654,  0.1000, 64.6654,  0.1000, 64.6654, 64.7367,\n",
      "         64.7367, 64.7367,  0.1000,  0.1000, 64.7367, 64.7367,  0.1000, 64.7367,\n",
      "          0.1000, 64.7367, 64.7192, 64.7367, 64.7367, 64.7367, 64.6654, 64.7367,\n",
      "         64.7367, 64.7367, 64.7192, 64.7367, 64.7367, 64.7367, 64.7192, 64.6654,\n",
      "         64.7192, 64.7192, 64.7192,  0.1000, 64.7192, 64.6654,  0.1000, 64.6654,\n",
      "         64.7367,  0.1000, 64.7367, 64.7367, 64.7367, 64.7192, 64.7192,  0.1000,\n",
      "         64.7367,  0.1000, 64.6246, 64.6246, 64.7192, 64.7367, 64.7367,  0.1000,\n",
      "          0.1000, 64.6246, 64.7192, 64.7367,  0.1000, 64.7192, 64.7367,  0.1000,\n",
      "         64.6246, 64.7367]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 518 was 98.8%\n",
      "current params: tensor([64.6246, 64.7192, 64.6654, 64.7367], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.3\n",
      "SLow rates:  tensor([[64.7248, 64.8195, 64.7657, 64.8370,  0.1000,  0.1000,  0.1000, 64.7248,\n",
      "         64.7248, 64.7248,  0.1000,  0.1000, 64.8195, 64.8195, 64.8195,  0.1000,\n",
      "          0.1000, 64.8195, 64.8195,  0.1000, 64.7657, 64.7657, 64.7657,  0.1000,\n",
      "          0.1000, 64.7657, 64.7657,  0.1000, 64.7657,  0.1000, 64.7657, 64.8370,\n",
      "         64.8370, 64.8370,  0.1000,  0.1000, 64.8370, 64.8370,  0.1000, 64.8370,\n",
      "          0.1000, 64.8370, 64.8195, 64.8370, 64.8370, 64.8370, 64.7657, 64.8370,\n",
      "         64.8370, 64.8370, 64.8195, 64.8370, 64.8370, 64.8370, 64.8195, 64.7657,\n",
      "         64.8195, 64.8195, 64.8195,  0.1000, 64.8195, 64.7657,  0.1000, 64.7657,\n",
      "         64.8370,  0.1000, 64.8370, 64.8370, 64.8370, 64.8195, 64.8195,  0.1000,\n",
      "         64.8370,  0.1000, 64.7248, 64.7248, 64.8195, 64.8370, 64.8370,  0.1000,\n",
      "          0.1000, 64.7248, 64.8195, 64.8370,  0.1000, 64.8195, 64.8370,  0.1000,\n",
      "         64.7248, 64.8370]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 519 was 98.8%\n",
      "current params: tensor([64.7248, 64.8195, 64.7657, 64.8370], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.4\n",
      "SLow rates:  tensor([[64.8251, 64.9197, 64.8659, 64.9372,  0.1000,  0.1000,  0.1000, 64.8251,\n",
      "         64.8251, 64.8251,  0.1000,  0.1000, 64.9197, 64.9197, 64.9197,  0.1000,\n",
      "          0.1000, 64.9197, 64.9197,  0.1000, 64.8659, 64.8659, 64.8659,  0.1000,\n",
      "          0.1000, 64.8659, 64.8659,  0.1000, 64.8659,  0.1000, 64.8659, 64.9372,\n",
      "         64.9372, 64.9372,  0.1000,  0.1000, 64.9372, 64.9372,  0.1000, 64.9372,\n",
      "          0.1000, 64.9372, 64.9197, 64.9372, 64.9372, 64.9372, 64.8659, 64.9372,\n",
      "         64.9372, 64.9372, 64.9197, 64.9372, 64.9372, 64.9372, 64.9197, 64.8659,\n",
      "         64.9197, 64.9197, 64.9197,  0.1000, 64.9197, 64.8659,  0.1000, 64.8659,\n",
      "         64.9372,  0.1000, 64.9372, 64.9372, 64.9372, 64.9197, 64.9197,  0.1000,\n",
      "         64.9372,  0.1000, 64.8251, 64.8251, 64.9197, 64.9372, 64.9372,  0.1000,\n",
      "          0.1000, 64.8251, 64.9197, 64.9372,  0.1000, 64.9197, 64.9372,  0.1000,\n",
      "         64.8251, 64.9372]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 520 was 98.8%\n",
      "current params: tensor([64.8251, 64.9197, 64.8659, 64.9372], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.4\n",
      "SLow rates:  tensor([[64.9254, 65.0200, 64.9662, 65.0375,  0.1000,  0.1000,  0.1000, 64.9254,\n",
      "         64.9254, 64.9254,  0.1000,  0.1000, 65.0200, 65.0200, 65.0200,  0.1000,\n",
      "          0.1000, 65.0200, 65.0200,  0.1000, 64.9662, 64.9662, 64.9662,  0.1000,\n",
      "          0.1000, 64.9662, 64.9662,  0.1000, 64.9662,  0.1000, 64.9662, 65.0375,\n",
      "         65.0375, 65.0375,  0.1000,  0.1000, 65.0375, 65.0375,  0.1000, 65.0375,\n",
      "          0.1000, 65.0375, 65.0200, 65.0375, 65.0375, 65.0375, 64.9662, 65.0375,\n",
      "         65.0375, 65.0375, 65.0200, 65.0375, 65.0375, 65.0375, 65.0200, 64.9662,\n",
      "         65.0200, 65.0200, 65.0200,  0.1000, 65.0200, 64.9662,  0.1000, 64.9662,\n",
      "         65.0375,  0.1000, 65.0375, 65.0375, 65.0375, 65.0200, 65.0200,  0.1000,\n",
      "         65.0375,  0.1000, 64.9254, 64.9254, 65.0200, 65.0375, 65.0375,  0.1000,\n",
      "          0.1000, 64.9254, 65.0200, 65.0375,  0.1000, 65.0200, 65.0375,  0.1000,\n",
      "         64.9254, 65.0375]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 521 was 98.8%\n",
      "current params: tensor([64.9254, 65.0200, 64.9662, 65.0375], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.4\n",
      "SLow rates:  tensor([[65.0256, 65.1202, 65.0664, 65.1377,  0.1000,  0.1000,  0.1000, 65.0256,\n",
      "         65.0256, 65.0256,  0.1000,  0.1000, 65.1202, 65.1202, 65.1202,  0.1000,\n",
      "          0.1000, 65.1202, 65.1202,  0.1000, 65.0664, 65.0664, 65.0664,  0.1000,\n",
      "          0.1000, 65.0664, 65.0664,  0.1000, 65.0664,  0.1000, 65.0664, 65.1377,\n",
      "         65.1377, 65.1377,  0.1000,  0.1000, 65.1377, 65.1377,  0.1000, 65.1377,\n",
      "          0.1000, 65.1377, 65.1202, 65.1377, 65.1377, 65.1377, 65.0664, 65.1377,\n",
      "         65.1377, 65.1377, 65.1202, 65.1377, 65.1377, 65.1377, 65.1202, 65.0664,\n",
      "         65.1202, 65.1202, 65.1202,  0.1000, 65.1202, 65.0664,  0.1000, 65.0664,\n",
      "         65.1377,  0.1000, 65.1377, 65.1377, 65.1377, 65.1202, 65.1202,  0.1000,\n",
      "         65.1377,  0.1000, 65.0256, 65.0256, 65.1202, 65.1377, 65.1377,  0.1000,\n",
      "          0.1000, 65.0256, 65.1202, 65.1377,  0.1000, 65.1202, 65.1377,  0.1000,\n",
      "         65.0256, 65.1377]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 522 was 98.8%\n",
      "current params: tensor([65.0256, 65.1202, 65.0664, 65.1377], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.4\n",
      "SLow rates:  tensor([[65.1259, 65.2204, 65.1667, 65.2380,  0.1000,  0.1000,  0.1000, 65.1259,\n",
      "         65.1259, 65.1259,  0.1000,  0.1000, 65.2204, 65.2204, 65.2204,  0.1000,\n",
      "          0.1000, 65.2204, 65.2204,  0.1000, 65.1667, 65.1667, 65.1667,  0.1000,\n",
      "          0.1000, 65.1667, 65.1667,  0.1000, 65.1667,  0.1000, 65.1667, 65.2380,\n",
      "         65.2380, 65.2380,  0.1000,  0.1000, 65.2380, 65.2380,  0.1000, 65.2380,\n",
      "          0.1000, 65.2380, 65.2204, 65.2380, 65.2380, 65.2380, 65.1667, 65.2380,\n",
      "         65.2380, 65.2380, 65.2204, 65.2380, 65.2380, 65.2380, 65.2204, 65.1667,\n",
      "         65.2204, 65.2204, 65.2204,  0.1000, 65.2204, 65.1667,  0.1000, 65.1667,\n",
      "         65.2380,  0.1000, 65.2380, 65.2380, 65.2380, 65.2204, 65.2204,  0.1000,\n",
      "         65.2380,  0.1000, 65.1259, 65.1259, 65.2204, 65.2380, 65.2380,  0.1000,\n",
      "          0.1000, 65.1259, 65.2204, 65.2380,  0.1000, 65.2204, 65.2380,  0.1000,\n",
      "         65.1259, 65.2380]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 523 was 98.8%\n",
      "current params: tensor([65.1259, 65.2204, 65.1667, 65.2380], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.4\n",
      "SLow rates:  tensor([[65.2261, 65.3207, 65.2669, 65.3382,  0.1000,  0.1000,  0.1000, 65.2261,\n",
      "         65.2261, 65.2261,  0.1000,  0.1000, 65.3207, 65.3207, 65.3207,  0.1000,\n",
      "          0.1000, 65.3207, 65.3207,  0.1000, 65.2669, 65.2669, 65.2669,  0.1000,\n",
      "          0.1000, 65.2669, 65.2669,  0.1000, 65.2669,  0.1000, 65.2669, 65.3382,\n",
      "         65.3382, 65.3382,  0.1000,  0.1000, 65.3382, 65.3382,  0.1000, 65.3382,\n",
      "          0.1000, 65.3382, 65.3207, 65.3382, 65.3382, 65.3382, 65.2669, 65.3382,\n",
      "         65.3382, 65.3382, 65.3207, 65.3382, 65.3382, 65.3382, 65.3207, 65.2669,\n",
      "         65.3207, 65.3207, 65.3207,  0.1000, 65.3207, 65.2669,  0.1000, 65.2669,\n",
      "         65.3382,  0.1000, 65.3382, 65.3382, 65.3382, 65.3207, 65.3207,  0.1000,\n",
      "         65.3382,  0.1000, 65.2261, 65.2261, 65.3207, 65.3382, 65.3382,  0.1000,\n",
      "          0.1000, 65.2261, 65.3207, 65.3382,  0.1000, 65.3207, 65.3382,  0.1000,\n",
      "         65.2261, 65.3382]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 524 was 98.8%\n",
      "current params: tensor([65.2261, 65.3207, 65.2669, 65.3382], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.5\n",
      "SLow rates:  tensor([[65.3264, 65.4209, 65.3672, 65.4384,  0.1000,  0.1000,  0.1000, 65.3264,\n",
      "         65.3264, 65.3264,  0.1000,  0.1000, 65.4209, 65.4209, 65.4209,  0.1000,\n",
      "          0.1000, 65.4209, 65.4209,  0.1000, 65.3672, 65.3672, 65.3672,  0.1000,\n",
      "          0.1000, 65.3672, 65.3672,  0.1000, 65.3672,  0.1000, 65.3672, 65.4384,\n",
      "         65.4384, 65.4384,  0.1000,  0.1000, 65.4384, 65.4384,  0.1000, 65.4384,\n",
      "          0.1000, 65.4384, 65.4209, 65.4384, 65.4384, 65.4384, 65.3672, 65.4384,\n",
      "         65.4384, 65.4384, 65.4209, 65.4384, 65.4384, 65.4384, 65.4209, 65.3672,\n",
      "         65.4209, 65.4209, 65.4209,  0.1000, 65.4209, 65.3672,  0.1000, 65.3672,\n",
      "         65.4384,  0.1000, 65.4384, 65.4384, 65.4384, 65.4209, 65.4209,  0.1000,\n",
      "         65.4384,  0.1000, 65.3264, 65.3264, 65.4209, 65.4384, 65.4384,  0.1000,\n",
      "          0.1000, 65.3264, 65.4209, 65.4384,  0.1000, 65.4209, 65.4384,  0.1000,\n",
      "         65.3264, 65.4384]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 525 was 98.8%\n",
      "current params: tensor([65.3264, 65.4209, 65.3672, 65.4384], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.5\n",
      "SLow rates:  tensor([[65.4266, 65.5212, 65.4674, 65.5387,  0.1000,  0.1000,  0.1000, 65.4266,\n",
      "         65.4266, 65.4266,  0.1000,  0.1000, 65.5212, 65.5212, 65.5212,  0.1000,\n",
      "          0.1000, 65.5212, 65.5212,  0.1000, 65.4674, 65.4674, 65.4674,  0.1000,\n",
      "          0.1000, 65.4674, 65.4674,  0.1000, 65.4674,  0.1000, 65.4674, 65.5387,\n",
      "         65.5387, 65.5387,  0.1000,  0.1000, 65.5387, 65.5387,  0.1000, 65.5387,\n",
      "          0.1000, 65.5387, 65.5212, 65.5387, 65.5387, 65.5387, 65.4674, 65.5387,\n",
      "         65.5387, 65.5387, 65.5212, 65.5387, 65.5387, 65.5387, 65.5212, 65.4674,\n",
      "         65.5212, 65.5212, 65.5212,  0.1000, 65.5212, 65.4674,  0.1000, 65.4674,\n",
      "         65.5387,  0.1000, 65.5387, 65.5387, 65.5387, 65.5212, 65.5212,  0.1000,\n",
      "         65.5387,  0.1000, 65.4266, 65.4266, 65.5212, 65.5387, 65.5387,  0.1000,\n",
      "          0.1000, 65.4266, 65.5212, 65.5387,  0.1000, 65.5212, 65.5387,  0.1000,\n",
      "         65.4266, 65.5387]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 526 was 98.8%\n",
      "current params: tensor([65.4266, 65.5212, 65.4674, 65.5387], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.5\n",
      "SLow rates:  tensor([[65.5268, 65.6214, 65.5676, 65.6389,  0.1000,  0.1000,  0.1000, 65.5268,\n",
      "         65.5268, 65.5268,  0.1000,  0.1000, 65.6214, 65.6214, 65.6214,  0.1000,\n",
      "          0.1000, 65.6214, 65.6214,  0.1000, 65.5676, 65.5676, 65.5676,  0.1000,\n",
      "          0.1000, 65.5676, 65.5676,  0.1000, 65.5676,  0.1000, 65.5676, 65.6389,\n",
      "         65.6389, 65.6389,  0.1000,  0.1000, 65.6389, 65.6389,  0.1000, 65.6389,\n",
      "          0.1000, 65.6389, 65.6214, 65.6389, 65.6389, 65.6389, 65.5676, 65.6389,\n",
      "         65.6389, 65.6389, 65.6214, 65.6389, 65.6389, 65.6389, 65.6214, 65.5676,\n",
      "         65.6214, 65.6214, 65.6214,  0.1000, 65.6214, 65.5676,  0.1000, 65.5676,\n",
      "         65.6389,  0.1000, 65.6389, 65.6389, 65.6389, 65.6214, 65.6214,  0.1000,\n",
      "         65.6389,  0.1000, 65.5268, 65.5268, 65.6214, 65.6389, 65.6389,  0.1000,\n",
      "          0.1000, 65.5268, 65.6214, 65.6389,  0.1000, 65.6214, 65.6389,  0.1000,\n",
      "         65.5268, 65.6389]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 527 was 98.8%\n",
      "current params: tensor([65.5268, 65.6214, 65.5676, 65.6389], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.5\n",
      "SLow rates:  tensor([[65.6271, 65.7216, 65.6679, 65.7391,  0.1000,  0.1000,  0.1000, 65.6271,\n",
      "         65.6271, 65.6271,  0.1000,  0.1000, 65.7216, 65.7216, 65.7216,  0.1000,\n",
      "          0.1000, 65.7216, 65.7216,  0.1000, 65.6679, 65.6679, 65.6679,  0.1000,\n",
      "          0.1000, 65.6679, 65.6679,  0.1000, 65.6679,  0.1000, 65.6679, 65.7391,\n",
      "         65.7391, 65.7391,  0.1000,  0.1000, 65.7391, 65.7391,  0.1000, 65.7391,\n",
      "          0.1000, 65.7391, 65.7216, 65.7391, 65.7391, 65.7391, 65.6679, 65.7391,\n",
      "         65.7391, 65.7391, 65.7216, 65.7391, 65.7391, 65.7391, 65.7216, 65.6679,\n",
      "         65.7216, 65.7216, 65.7216,  0.1000, 65.7216, 65.6679,  0.1000, 65.6679,\n",
      "         65.7391,  0.1000, 65.7391, 65.7391, 65.7391, 65.7216, 65.7216,  0.1000,\n",
      "         65.7391,  0.1000, 65.6271, 65.6271, 65.7216, 65.7391, 65.7391,  0.1000,\n",
      "          0.1000, 65.6271, 65.7216, 65.7391,  0.1000, 65.7216, 65.7391,  0.1000,\n",
      "         65.6271, 65.7391]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 528 was 98.8%\n",
      "current params: tensor([65.6271, 65.7216, 65.6679, 65.7391], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.5\n",
      "SLow rates:  tensor([[65.7273, 65.8218, 65.7681, 65.8393,  0.1000,  0.1000,  0.1000, 65.7273,\n",
      "         65.7273, 65.7273,  0.1000,  0.1000, 65.8218, 65.8218, 65.8218,  0.1000,\n",
      "          0.1000, 65.8218, 65.8218,  0.1000, 65.7681, 65.7681, 65.7681,  0.1000,\n",
      "          0.1000, 65.7681, 65.7681,  0.1000, 65.7681,  0.1000, 65.7681, 65.8393,\n",
      "         65.8393, 65.8393,  0.1000,  0.1000, 65.8393, 65.8393,  0.1000, 65.8393,\n",
      "          0.1000, 65.8393, 65.8218, 65.8393, 65.8393, 65.8393, 65.7681, 65.8393,\n",
      "         65.8393, 65.8393, 65.8218, 65.8393, 65.8393, 65.8393, 65.8218, 65.7681,\n",
      "         65.8218, 65.8218, 65.8218,  0.1000, 65.8218, 65.7681,  0.1000, 65.7681,\n",
      "         65.8393,  0.1000, 65.8393, 65.8393, 65.8393, 65.8218, 65.8218,  0.1000,\n",
      "         65.8393,  0.1000, 65.7273, 65.7273, 65.8218, 65.8393, 65.8393,  0.1000,\n",
      "          0.1000, 65.7273, 65.8218, 65.8393,  0.1000, 65.8218, 65.8393,  0.1000,\n",
      "         65.7273, 65.8393]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 529 was 98.8%\n",
      "current params: tensor([65.7273, 65.8218, 65.7681, 65.8393], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.5\n",
      "SLow rates:  tensor([[65.8275, 65.9221, 65.8683, 65.9396,  0.1000,  0.1000,  0.1000, 65.8275,\n",
      "         65.8275, 65.8275,  0.1000,  0.1000, 65.9221, 65.9221, 65.9221,  0.1000,\n",
      "          0.1000, 65.9221, 65.9221,  0.1000, 65.8683, 65.8683, 65.8683,  0.1000,\n",
      "          0.1000, 65.8683, 65.8683,  0.1000, 65.8683,  0.1000, 65.8683, 65.9396,\n",
      "         65.9396, 65.9396,  0.1000,  0.1000, 65.9396, 65.9396,  0.1000, 65.9396,\n",
      "          0.1000, 65.9396, 65.9221, 65.9396, 65.9396, 65.9396, 65.8683, 65.9396,\n",
      "         65.9396, 65.9396, 65.9221, 65.9396, 65.9396, 65.9396, 65.9221, 65.8683,\n",
      "         65.9221, 65.9221, 65.9221,  0.1000, 65.9221, 65.8683,  0.1000, 65.8683,\n",
      "         65.9396,  0.1000, 65.9396, 65.9396, 65.9396, 65.9221, 65.9221,  0.1000,\n",
      "         65.9396,  0.1000, 65.8275, 65.8275, 65.9221, 65.9396, 65.9396,  0.1000,\n",
      "          0.1000, 65.8275, 65.9221, 65.9396,  0.1000, 65.9221, 65.9396,  0.1000,\n",
      "         65.8275, 65.9396]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 530 was 98.8%\n",
      "current params: tensor([65.8275, 65.9221, 65.8683, 65.9396], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.6\n",
      "SLow rates:  tensor([[65.9278, 66.0223, 65.9686, 66.0398,  0.1000,  0.1000,  0.1000, 65.9278,\n",
      "         65.9278, 65.9278,  0.1000,  0.1000, 66.0223, 66.0223, 66.0223,  0.1000,\n",
      "          0.1000, 66.0223, 66.0223,  0.1000, 65.9686, 65.9686, 65.9686,  0.1000,\n",
      "          0.1000, 65.9686, 65.9686,  0.1000, 65.9686,  0.1000, 65.9686, 66.0398,\n",
      "         66.0398, 66.0398,  0.1000,  0.1000, 66.0398, 66.0398,  0.1000, 66.0398,\n",
      "          0.1000, 66.0398, 66.0223, 66.0398, 66.0398, 66.0398, 65.9686, 66.0398,\n",
      "         66.0398, 66.0398, 66.0223, 66.0398, 66.0398, 66.0398, 66.0223, 65.9686,\n",
      "         66.0223, 66.0223, 66.0223,  0.1000, 66.0223, 65.9686,  0.1000, 65.9686,\n",
      "         66.0398,  0.1000, 66.0398, 66.0398, 66.0398, 66.0223, 66.0223,  0.1000,\n",
      "         66.0398,  0.1000, 65.9278, 65.9278, 66.0223, 66.0398, 66.0398,  0.1000,\n",
      "          0.1000, 65.9278, 66.0223, 66.0398,  0.1000, 66.0223, 66.0398,  0.1000,\n",
      "         65.9278, 66.0398]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 531 was 98.8%\n",
      "current params: tensor([65.9278, 66.0223, 65.9686, 66.0398], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.6\n",
      "SLow rates:  tensor([[66.0280, 66.1225, 66.0688, 66.1400,  0.1000,  0.1000,  0.1000, 66.0280,\n",
      "         66.0280, 66.0280,  0.1000,  0.1000, 66.1225, 66.1225, 66.1225,  0.1000,\n",
      "          0.1000, 66.1225, 66.1225,  0.1000, 66.0688, 66.0688, 66.0688,  0.1000,\n",
      "          0.1000, 66.0688, 66.0688,  0.1000, 66.0688,  0.1000, 66.0688, 66.1400,\n",
      "         66.1400, 66.1400,  0.1000,  0.1000, 66.1400, 66.1400,  0.1000, 66.1400,\n",
      "          0.1000, 66.1400, 66.1225, 66.1400, 66.1400, 66.1400, 66.0688, 66.1400,\n",
      "         66.1400, 66.1400, 66.1225, 66.1400, 66.1400, 66.1400, 66.1225, 66.0688,\n",
      "         66.1225, 66.1225, 66.1225,  0.1000, 66.1225, 66.0688,  0.1000, 66.0688,\n",
      "         66.1400,  0.1000, 66.1400, 66.1400, 66.1400, 66.1225, 66.1225,  0.1000,\n",
      "         66.1400,  0.1000, 66.0280, 66.0280, 66.1225, 66.1400, 66.1400,  0.1000,\n",
      "          0.1000, 66.0280, 66.1225, 66.1400,  0.1000, 66.1225, 66.1400,  0.1000,\n",
      "         66.0280, 66.1400]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 532 was 98.8%\n",
      "current params: tensor([66.0280, 66.1225, 66.0688, 66.1400], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.6\n",
      "SLow rates:  tensor([[66.1282, 66.2227, 66.1690, 66.2402,  0.1000,  0.1000,  0.1000, 66.1282,\n",
      "         66.1282, 66.1282,  0.1000,  0.1000, 66.2227, 66.2227, 66.2227,  0.1000,\n",
      "          0.1000, 66.2227, 66.2227,  0.1000, 66.1690, 66.1690, 66.1690,  0.1000,\n",
      "          0.1000, 66.1690, 66.1690,  0.1000, 66.1690,  0.1000, 66.1690, 66.2402,\n",
      "         66.2402, 66.2402,  0.1000,  0.1000, 66.2402, 66.2402,  0.1000, 66.2402,\n",
      "          0.1000, 66.2402, 66.2227, 66.2402, 66.2402, 66.2402, 66.1690, 66.2402,\n",
      "         66.2402, 66.2402, 66.2227, 66.2402, 66.2402, 66.2402, 66.2227, 66.1690,\n",
      "         66.2227, 66.2227, 66.2227,  0.1000, 66.2227, 66.1690,  0.1000, 66.1690,\n",
      "         66.2402,  0.1000, 66.2402, 66.2402, 66.2402, 66.2227, 66.2227,  0.1000,\n",
      "         66.2402,  0.1000, 66.1282, 66.1282, 66.2227, 66.2402, 66.2402,  0.1000,\n",
      "          0.1000, 66.1282, 66.2227, 66.2402,  0.1000, 66.2227, 66.2402,  0.1000,\n",
      "         66.1282, 66.2402]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 533 was 98.8%\n",
      "current params: tensor([66.1282, 66.2227, 66.1690, 66.2402], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.6\n",
      "SLow rates:  tensor([[66.2285, 66.3229, 66.2692, 66.3404,  0.1000,  0.1000,  0.1000, 66.2285,\n",
      "         66.2285, 66.2285,  0.1000,  0.1000, 66.3229, 66.3229, 66.3229,  0.1000,\n",
      "          0.1000, 66.3229, 66.3229,  0.1000, 66.2692, 66.2692, 66.2692,  0.1000,\n",
      "          0.1000, 66.2692, 66.2692,  0.1000, 66.2692,  0.1000, 66.2692, 66.3404,\n",
      "         66.3404, 66.3404,  0.1000,  0.1000, 66.3404, 66.3404,  0.1000, 66.3404,\n",
      "          0.1000, 66.3404, 66.3229, 66.3404, 66.3404, 66.3404, 66.2692, 66.3404,\n",
      "         66.3404, 66.3404, 66.3229, 66.3404, 66.3404, 66.3404, 66.3229, 66.2692,\n",
      "         66.3229, 66.3229, 66.3229,  0.1000, 66.3229, 66.2692,  0.1000, 66.2692,\n",
      "         66.3404,  0.1000, 66.3404, 66.3404, 66.3404, 66.3229, 66.3229,  0.1000,\n",
      "         66.3404,  0.1000, 66.2285, 66.2285, 66.3229, 66.3404, 66.3404,  0.1000,\n",
      "          0.1000, 66.2285, 66.3229, 66.3404,  0.1000, 66.3229, 66.3404,  0.1000,\n",
      "         66.2285, 66.3404]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 534 was 98.8%\n",
      "current params: tensor([66.2285, 66.3229, 66.2692, 66.3404], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.6\n",
      "SLow rates:  tensor([[66.3287, 66.4232, 66.3694, 66.4406,  0.1000,  0.1000,  0.1000, 66.3287,\n",
      "         66.3287, 66.3287,  0.1000,  0.1000, 66.4232, 66.4232, 66.4232,  0.1000,\n",
      "          0.1000, 66.4232, 66.4232,  0.1000, 66.3694, 66.3694, 66.3694,  0.1000,\n",
      "          0.1000, 66.3694, 66.3694,  0.1000, 66.3694,  0.1000, 66.3694, 66.4406,\n",
      "         66.4406, 66.4406,  0.1000,  0.1000, 66.4406, 66.4406,  0.1000, 66.4406,\n",
      "          0.1000, 66.4406, 66.4232, 66.4406, 66.4406, 66.4406, 66.3694, 66.4406,\n",
      "         66.4406, 66.4406, 66.4232, 66.4406, 66.4406, 66.4406, 66.4232, 66.3694,\n",
      "         66.4232, 66.4232, 66.4232,  0.1000, 66.4232, 66.3694,  0.1000, 66.3694,\n",
      "         66.4406,  0.1000, 66.4406, 66.4406, 66.4406, 66.4232, 66.4232,  0.1000,\n",
      "         66.4406,  0.1000, 66.3287, 66.3287, 66.4232, 66.4406, 66.4406,  0.1000,\n",
      "          0.1000, 66.3287, 66.4232, 66.4406,  0.1000, 66.4232, 66.4406,  0.1000,\n",
      "         66.3287, 66.4406]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 535 was 98.8%\n",
      "current params: tensor([66.3287, 66.4232, 66.3694, 66.4406], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.7\n",
      "SLow rates:  tensor([[66.4289, 66.5234, 66.4697, 66.5408,  0.1000,  0.1000,  0.1000, 66.4289,\n",
      "         66.4289, 66.4289,  0.1000,  0.1000, 66.5234, 66.5234, 66.5234,  0.1000,\n",
      "          0.1000, 66.5234, 66.5234,  0.1000, 66.4697, 66.4697, 66.4697,  0.1000,\n",
      "          0.1000, 66.4697, 66.4697,  0.1000, 66.4697,  0.1000, 66.4697, 66.5408,\n",
      "         66.5408, 66.5408,  0.1000,  0.1000, 66.5408, 66.5408,  0.1000, 66.5408,\n",
      "          0.1000, 66.5408, 66.5234, 66.5408, 66.5408, 66.5408, 66.4697, 66.5408,\n",
      "         66.5408, 66.5408, 66.5234, 66.5408, 66.5408, 66.5408, 66.5234, 66.4697,\n",
      "         66.5234, 66.5234, 66.5234,  0.1000, 66.5234, 66.4697,  0.1000, 66.4697,\n",
      "         66.5408,  0.1000, 66.5408, 66.5408, 66.5408, 66.5234, 66.5234,  0.1000,\n",
      "         66.5408,  0.1000, 66.4289, 66.4289, 66.5234, 66.5408, 66.5408,  0.1000,\n",
      "          0.1000, 66.4289, 66.5234, 66.5408,  0.1000, 66.5234, 66.5408,  0.1000,\n",
      "         66.4289, 66.5408]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 536 was 98.8%\n",
      "current params: tensor([66.4289, 66.5234, 66.4697, 66.5408], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.7\n",
      "SLow rates:  tensor([[66.5291, 66.6236, 66.5699, 66.6410,  0.1000,  0.1000,  0.1000, 66.5291,\n",
      "         66.5291, 66.5291,  0.1000,  0.1000, 66.6236, 66.6236, 66.6236,  0.1000,\n",
      "          0.1000, 66.6236, 66.6236,  0.1000, 66.5699, 66.5699, 66.5699,  0.1000,\n",
      "          0.1000, 66.5699, 66.5699,  0.1000, 66.5699,  0.1000, 66.5699, 66.6410,\n",
      "         66.6410, 66.6410,  0.1000,  0.1000, 66.6410, 66.6410,  0.1000, 66.6410,\n",
      "          0.1000, 66.6410, 66.6236, 66.6410, 66.6410, 66.6410, 66.5699, 66.6410,\n",
      "         66.6410, 66.6410, 66.6236, 66.6410, 66.6410, 66.6410, 66.6236, 66.5699,\n",
      "         66.6236, 66.6236, 66.6236,  0.1000, 66.6236, 66.5699,  0.1000, 66.5699,\n",
      "         66.6410,  0.1000, 66.6410, 66.6410, 66.6410, 66.6236, 66.6236,  0.1000,\n",
      "         66.6410,  0.1000, 66.5291, 66.5291, 66.6236, 66.6410, 66.6410,  0.1000,\n",
      "          0.1000, 66.5291, 66.6236, 66.6410,  0.1000, 66.6236, 66.6410,  0.1000,\n",
      "         66.5291, 66.6410]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 537 was 98.8%\n",
      "current params: tensor([66.5291, 66.6236, 66.5699, 66.6410], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.7\n",
      "SLow rates:  tensor([[66.6293, 66.7238, 66.6701, 66.7412,  0.1000,  0.1000,  0.1000, 66.6293,\n",
      "         66.6293, 66.6293,  0.1000,  0.1000, 66.7238, 66.7238, 66.7238,  0.1000,\n",
      "          0.1000, 66.7238, 66.7238,  0.1000, 66.6701, 66.6701, 66.6701,  0.1000,\n",
      "          0.1000, 66.6701, 66.6701,  0.1000, 66.6701,  0.1000, 66.6701, 66.7412,\n",
      "         66.7412, 66.7412,  0.1000,  0.1000, 66.7412, 66.7412,  0.1000, 66.7412,\n",
      "          0.1000, 66.7412, 66.7238, 66.7412, 66.7412, 66.7412, 66.6701, 66.7412,\n",
      "         66.7412, 66.7412, 66.7238, 66.7412, 66.7412, 66.7412, 66.7238, 66.6701,\n",
      "         66.7238, 66.7238, 66.7238,  0.1000, 66.7238, 66.6701,  0.1000, 66.6701,\n",
      "         66.7412,  0.1000, 66.7412, 66.7412, 66.7412, 66.7238, 66.7238,  0.1000,\n",
      "         66.7412,  0.1000, 66.6293, 66.6293, 66.7238, 66.7412, 66.7412,  0.1000,\n",
      "          0.1000, 66.6293, 66.7238, 66.7412,  0.1000, 66.7238, 66.7412,  0.1000,\n",
      "         66.6293, 66.7412]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 538 was 98.8%\n",
      "current params: tensor([66.6293, 66.7238, 66.6701, 66.7412], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.7\n",
      "SLow rates:  tensor([[66.7295, 66.8240, 66.7703, 66.8414,  0.1000,  0.1000,  0.1000, 66.7295,\n",
      "         66.7295, 66.7295,  0.1000,  0.1000, 66.8240, 66.8240, 66.8240,  0.1000,\n",
      "          0.1000, 66.8240, 66.8240,  0.1000, 66.7703, 66.7703, 66.7703,  0.1000,\n",
      "          0.1000, 66.7703, 66.7703,  0.1000, 66.7703,  0.1000, 66.7703, 66.8414,\n",
      "         66.8414, 66.8414,  0.1000,  0.1000, 66.8414, 66.8414,  0.1000, 66.8414,\n",
      "          0.1000, 66.8414, 66.8240, 66.8414, 66.8414, 66.8414, 66.7703, 66.8414,\n",
      "         66.8414, 66.8414, 66.8240, 66.8414, 66.8414, 66.8414, 66.8240, 66.7703,\n",
      "         66.8240, 66.8240, 66.8240,  0.1000, 66.8240, 66.7703,  0.1000, 66.7703,\n",
      "         66.8414,  0.1000, 66.8414, 66.8414, 66.8414, 66.8240, 66.8240,  0.1000,\n",
      "         66.8414,  0.1000, 66.7295, 66.7295, 66.8240, 66.8414, 66.8414,  0.1000,\n",
      "          0.1000, 66.7295, 66.8240, 66.8414,  0.1000, 66.8240, 66.8414,  0.1000,\n",
      "         66.7295, 66.8414]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 539 was 98.8%\n",
      "current params: tensor([66.7295, 66.8240, 66.7703, 66.8414], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.7\n",
      "SLow rates:  tensor([[66.8297, 66.9242, 66.8705, 66.9416,  0.1000,  0.1000,  0.1000, 66.8297,\n",
      "         66.8297, 66.8297,  0.1000,  0.1000, 66.9242, 66.9242, 66.9242,  0.1000,\n",
      "          0.1000, 66.9242, 66.9242,  0.1000, 66.8705, 66.8705, 66.8705,  0.1000,\n",
      "          0.1000, 66.8705, 66.8705,  0.1000, 66.8705,  0.1000, 66.8705, 66.9416,\n",
      "         66.9416, 66.9416,  0.1000,  0.1000, 66.9416, 66.9416,  0.1000, 66.9416,\n",
      "          0.1000, 66.9416, 66.9242, 66.9416, 66.9416, 66.9416, 66.8705, 66.9416,\n",
      "         66.9416, 66.9416, 66.9242, 66.9416, 66.9416, 66.9416, 66.9242, 66.8705,\n",
      "         66.9242, 66.9242, 66.9242,  0.1000, 66.9242, 66.8705,  0.1000, 66.8705,\n",
      "         66.9416,  0.1000, 66.9416, 66.9416, 66.9416, 66.9242, 66.9242,  0.1000,\n",
      "         66.9416,  0.1000, 66.8297, 66.8297, 66.9242, 66.9416, 66.9416,  0.1000,\n",
      "          0.1000, 66.8297, 66.9242, 66.9416,  0.1000, 66.9242, 66.9416,  0.1000,\n",
      "         66.8297, 66.9416]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 540 was 98.8%\n",
      "current params: tensor([66.8297, 66.9242, 66.8705, 66.9416], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.8\n",
      "SLow rates:  tensor([[66.9300, 67.0244, 66.9707, 67.0418,  0.1000,  0.1000,  0.1000, 66.9300,\n",
      "         66.9300, 66.9300,  0.1000,  0.1000, 67.0244, 67.0244, 67.0244,  0.1000,\n",
      "          0.1000, 67.0244, 67.0244,  0.1000, 66.9707, 66.9707, 66.9707,  0.1000,\n",
      "          0.1000, 66.9707, 66.9707,  0.1000, 66.9707,  0.1000, 66.9707, 67.0418,\n",
      "         67.0418, 67.0418,  0.1000,  0.1000, 67.0418, 67.0418,  0.1000, 67.0418,\n",
      "          0.1000, 67.0418, 67.0244, 67.0418, 67.0418, 67.0418, 66.9707, 67.0418,\n",
      "         67.0418, 67.0418, 67.0244, 67.0418, 67.0418, 67.0418, 67.0244, 66.9707,\n",
      "         67.0244, 67.0244, 67.0244,  0.1000, 67.0244, 66.9707,  0.1000, 66.9707,\n",
      "         67.0418,  0.1000, 67.0418, 67.0418, 67.0418, 67.0244, 67.0244,  0.1000,\n",
      "         67.0418,  0.1000, 66.9300, 66.9300, 67.0244, 67.0418, 67.0418,  0.1000,\n",
      "          0.1000, 66.9300, 67.0244, 67.0418,  0.1000, 67.0244, 67.0418,  0.1000,\n",
      "         66.9300, 67.0418]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 541 was 98.8%\n",
      "current params: tensor([66.9300, 67.0244, 66.9707, 67.0418], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.8\n",
      "SLow rates:  tensor([[67.0302, 67.1246, 67.0709, 67.1420,  0.1000,  0.1000,  0.1000, 67.0302,\n",
      "         67.0302, 67.0302,  0.1000,  0.1000, 67.1246, 67.1246, 67.1246,  0.1000,\n",
      "          0.1000, 67.1246, 67.1246,  0.1000, 67.0709, 67.0709, 67.0709,  0.1000,\n",
      "          0.1000, 67.0709, 67.0709,  0.1000, 67.0709,  0.1000, 67.0709, 67.1420,\n",
      "         67.1420, 67.1420,  0.1000,  0.1000, 67.1420, 67.1420,  0.1000, 67.1420,\n",
      "          0.1000, 67.1420, 67.1246, 67.1420, 67.1420, 67.1420, 67.0709, 67.1420,\n",
      "         67.1420, 67.1420, 67.1246, 67.1420, 67.1420, 67.1420, 67.1246, 67.0709,\n",
      "         67.1246, 67.1246, 67.1246,  0.1000, 67.1246, 67.0709,  0.1000, 67.0709,\n",
      "         67.1420,  0.1000, 67.1420, 67.1420, 67.1420, 67.1246, 67.1246,  0.1000,\n",
      "         67.1420,  0.1000, 67.0302, 67.0302, 67.1246, 67.1420, 67.1420,  0.1000,\n",
      "          0.1000, 67.0302, 67.1246, 67.1420,  0.1000, 67.1246, 67.1420,  0.1000,\n",
      "         67.0302, 67.1420]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 542 was 98.8%\n",
      "current params: tensor([67.0302, 67.1246, 67.0709, 67.1420], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.8\n",
      "SLow rates:  tensor([[67.1304, 67.2248, 67.1711, 67.2422,  0.1000,  0.1000,  0.1000, 67.1304,\n",
      "         67.1304, 67.1304,  0.1000,  0.1000, 67.2248, 67.2248, 67.2248,  0.1000,\n",
      "          0.1000, 67.2248, 67.2248,  0.1000, 67.1711, 67.1711, 67.1711,  0.1000,\n",
      "          0.1000, 67.1711, 67.1711,  0.1000, 67.1711,  0.1000, 67.1711, 67.2422,\n",
      "         67.2422, 67.2422,  0.1000,  0.1000, 67.2422, 67.2422,  0.1000, 67.2422,\n",
      "          0.1000, 67.2422, 67.2248, 67.2422, 67.2422, 67.2422, 67.1711, 67.2422,\n",
      "         67.2422, 67.2422, 67.2248, 67.2422, 67.2422, 67.2422, 67.2248, 67.1711,\n",
      "         67.2248, 67.2248, 67.2248,  0.1000, 67.2248, 67.1711,  0.1000, 67.1711,\n",
      "         67.2422,  0.1000, 67.2422, 67.2422, 67.2422, 67.2248, 67.2248,  0.1000,\n",
      "         67.2422,  0.1000, 67.1304, 67.1304, 67.2248, 67.2422, 67.2422,  0.1000,\n",
      "          0.1000, 67.1304, 67.2248, 67.2422,  0.1000, 67.2248, 67.2422,  0.1000,\n",
      "         67.1304, 67.2422]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 543 was 98.8%\n",
      "current params: tensor([67.1304, 67.2248, 67.1711, 67.2422], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.8\n",
      "SLow rates:  tensor([[67.2306, 67.3250, 67.2713, 67.3424,  0.1000,  0.1000,  0.1000, 67.2306,\n",
      "         67.2306, 67.2306,  0.1000,  0.1000, 67.3250, 67.3250, 67.3250,  0.1000,\n",
      "          0.1000, 67.3250, 67.3250,  0.1000, 67.2713, 67.2713, 67.2713,  0.1000,\n",
      "          0.1000, 67.2713, 67.2713,  0.1000, 67.2713,  0.1000, 67.2713, 67.3424,\n",
      "         67.3424, 67.3424,  0.1000,  0.1000, 67.3424, 67.3424,  0.1000, 67.3424,\n",
      "          0.1000, 67.3424, 67.3250, 67.3424, 67.3424, 67.3424, 67.2713, 67.3424,\n",
      "         67.3424, 67.3424, 67.3250, 67.3424, 67.3424, 67.3424, 67.3250, 67.2713,\n",
      "         67.3250, 67.3250, 67.3250,  0.1000, 67.3250, 67.2713,  0.1000, 67.2713,\n",
      "         67.3424,  0.1000, 67.3424, 67.3424, 67.3424, 67.3250, 67.3250,  0.1000,\n",
      "         67.3424,  0.1000, 67.2306, 67.2306, 67.3250, 67.3424, 67.3424,  0.1000,\n",
      "          0.1000, 67.2306, 67.3250, 67.3424,  0.1000, 67.3250, 67.3424,  0.1000,\n",
      "         67.2306, 67.3424]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 544 was 98.8%\n",
      "current params: tensor([67.2306, 67.3250, 67.2713, 67.3424], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.8\n",
      "SLow rates:  tensor([[67.3308, 67.4252, 67.3715, 67.4426,  0.1000,  0.1000,  0.1000, 67.3308,\n",
      "         67.3308, 67.3308,  0.1000,  0.1000, 67.4252, 67.4252, 67.4252,  0.1000,\n",
      "          0.1000, 67.4252, 67.4252,  0.1000, 67.3715, 67.3715, 67.3715,  0.1000,\n",
      "          0.1000, 67.3715, 67.3715,  0.1000, 67.3715,  0.1000, 67.3715, 67.4426,\n",
      "         67.4426, 67.4426,  0.1000,  0.1000, 67.4426, 67.4426,  0.1000, 67.4426,\n",
      "          0.1000, 67.4426, 67.4252, 67.4426, 67.4426, 67.4426, 67.3715, 67.4426,\n",
      "         67.4426, 67.4426, 67.4252, 67.4426, 67.4426, 67.4426, 67.4252, 67.3715,\n",
      "         67.4252, 67.4252, 67.4252,  0.1000, 67.4252, 67.3715,  0.1000, 67.3715,\n",
      "         67.4426,  0.1000, 67.4426, 67.4426, 67.4426, 67.4252, 67.4252,  0.1000,\n",
      "         67.4426,  0.1000, 67.3308, 67.3308, 67.4252, 67.4426, 67.4426,  0.1000,\n",
      "          0.1000, 67.3308, 67.4252, 67.4426,  0.1000, 67.4252, 67.4426,  0.1000,\n",
      "         67.3308, 67.4426]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 545 was 98.8%\n",
      "current params: tensor([67.3308, 67.4252, 67.3715, 67.4426], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.8\n",
      "SLow rates:  tensor([[67.4310, 67.5254, 67.4717, 67.5428,  0.1000,  0.1000,  0.1000, 67.4310,\n",
      "         67.4310, 67.4310,  0.1000,  0.1000, 67.5254, 67.5254, 67.5254,  0.1000,\n",
      "          0.1000, 67.5254, 67.5254,  0.1000, 67.4717, 67.4717, 67.4717,  0.1000,\n",
      "          0.1000, 67.4717, 67.4717,  0.1000, 67.4717,  0.1000, 67.4717, 67.5428,\n",
      "         67.5428, 67.5428,  0.1000,  0.1000, 67.5428, 67.5428,  0.1000, 67.5428,\n",
      "          0.1000, 67.5428, 67.5254, 67.5428, 67.5428, 67.5428, 67.4717, 67.5428,\n",
      "         67.5428, 67.5428, 67.5254, 67.5428, 67.5428, 67.5428, 67.5254, 67.4717,\n",
      "         67.5254, 67.5254, 67.5254,  0.1000, 67.5254, 67.4717,  0.1000, 67.4717,\n",
      "         67.5428,  0.1000, 67.5428, 67.5428, 67.5428, 67.5254, 67.5254,  0.1000,\n",
      "         67.5428,  0.1000, 67.4310, 67.4310, 67.5254, 67.5428, 67.5428,  0.1000,\n",
      "          0.1000, 67.4310, 67.5254, 67.5428,  0.1000, 67.5254, 67.5428,  0.1000,\n",
      "         67.4310, 67.5428]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 546 was 98.8%\n",
      "current params: tensor([67.4310, 67.5254, 67.4717, 67.5428], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.9\n",
      "SLow rates:  tensor([[67.5312, 67.6256, 67.5719, 67.6430,  0.1000,  0.1000,  0.1000, 67.5312,\n",
      "         67.5312, 67.5312,  0.1000,  0.1000, 67.6256, 67.6256, 67.6256,  0.1000,\n",
      "          0.1000, 67.6256, 67.6256,  0.1000, 67.5719, 67.5719, 67.5719,  0.1000,\n",
      "          0.1000, 67.5719, 67.5719,  0.1000, 67.5719,  0.1000, 67.5719, 67.6430,\n",
      "         67.6430, 67.6430,  0.1000,  0.1000, 67.6430, 67.6430,  0.1000, 67.6430,\n",
      "          0.1000, 67.6430, 67.6256, 67.6430, 67.6430, 67.6430, 67.5719, 67.6430,\n",
      "         67.6430, 67.6430, 67.6256, 67.6430, 67.6430, 67.6430, 67.6256, 67.5719,\n",
      "         67.6256, 67.6256, 67.6256,  0.1000, 67.6256, 67.5719,  0.1000, 67.5719,\n",
      "         67.6430,  0.1000, 67.6430, 67.6430, 67.6430, 67.6256, 67.6256,  0.1000,\n",
      "         67.6430,  0.1000, 67.5312, 67.5312, 67.6256, 67.6430, 67.6430,  0.1000,\n",
      "          0.1000, 67.5312, 67.6256, 67.6430,  0.1000, 67.6256, 67.6430,  0.1000,\n",
      "         67.5312, 67.6430]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 547 was 98.8%\n",
      "current params: tensor([67.5312, 67.6256, 67.5719, 67.6430], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.9\n",
      "SLow rates:  tensor([[67.6314, 67.7258, 67.6721, 67.7432,  0.1000,  0.1000,  0.1000, 67.6314,\n",
      "         67.6314, 67.6314,  0.1000,  0.1000, 67.7258, 67.7258, 67.7258,  0.1000,\n",
      "          0.1000, 67.7258, 67.7258,  0.1000, 67.6721, 67.6721, 67.6721,  0.1000,\n",
      "          0.1000, 67.6721, 67.6721,  0.1000, 67.6721,  0.1000, 67.6721, 67.7432,\n",
      "         67.7432, 67.7432,  0.1000,  0.1000, 67.7432, 67.7432,  0.1000, 67.7432,\n",
      "          0.1000, 67.7432, 67.7258, 67.7432, 67.7432, 67.7432, 67.6721, 67.7432,\n",
      "         67.7432, 67.7432, 67.7258, 67.7432, 67.7432, 67.7432, 67.7258, 67.6721,\n",
      "         67.7258, 67.7258, 67.7258,  0.1000, 67.7258, 67.6721,  0.1000, 67.6721,\n",
      "         67.7432,  0.1000, 67.7432, 67.7432, 67.7432, 67.7258, 67.7258,  0.1000,\n",
      "         67.7432,  0.1000, 67.6314, 67.6314, 67.7258, 67.7432, 67.7432,  0.1000,\n",
      "          0.1000, 67.6314, 67.7258, 67.7432,  0.1000, 67.7258, 67.7432,  0.1000,\n",
      "         67.6314, 67.7432]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 548 was 98.8%\n",
      "current params: tensor([67.6314, 67.7258, 67.6721, 67.7432], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.9\n",
      "SLow rates:  tensor([[67.7315, 67.8259, 67.7723, 67.8433,  0.1000,  0.1000,  0.1000, 67.7315,\n",
      "         67.7315, 67.7315,  0.1000,  0.1000, 67.8259, 67.8259, 67.8259,  0.1000,\n",
      "          0.1000, 67.8259, 67.8259,  0.1000, 67.7723, 67.7723, 67.7723,  0.1000,\n",
      "          0.1000, 67.7723, 67.7723,  0.1000, 67.7723,  0.1000, 67.7723, 67.8433,\n",
      "         67.8433, 67.8433,  0.1000,  0.1000, 67.8433, 67.8433,  0.1000, 67.8433,\n",
      "          0.1000, 67.8433, 67.8259, 67.8433, 67.8433, 67.8433, 67.7723, 67.8433,\n",
      "         67.8433, 67.8433, 67.8259, 67.8433, 67.8433, 67.8433, 67.8259, 67.7723,\n",
      "         67.8259, 67.8259, 67.8259,  0.1000, 67.8259, 67.7723,  0.1000, 67.7723,\n",
      "         67.8433,  0.1000, 67.8433, 67.8433, 67.8433, 67.8259, 67.8259,  0.1000,\n",
      "         67.8433,  0.1000, 67.7315, 67.7315, 67.8259, 67.8433, 67.8433,  0.1000,\n",
      "          0.1000, 67.7315, 67.8259, 67.8433,  0.1000, 67.8259, 67.8433,  0.1000,\n",
      "         67.7315, 67.8433]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 549 was 98.8%\n",
      "current params: tensor([67.7315, 67.8259, 67.7723, 67.8433], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.9\n",
      "SLow rates:  tensor([[67.8317, 67.9261, 67.8725, 67.9435,  0.1000,  0.1000,  0.1000, 67.8317,\n",
      "         67.8317, 67.8317,  0.1000,  0.1000, 67.9261, 67.9261, 67.9261,  0.1000,\n",
      "          0.1000, 67.9261, 67.9261,  0.1000, 67.8725, 67.8725, 67.8725,  0.1000,\n",
      "          0.1000, 67.8725, 67.8725,  0.1000, 67.8725,  0.1000, 67.8725, 67.9435,\n",
      "         67.9435, 67.9435,  0.1000,  0.1000, 67.9435, 67.9435,  0.1000, 67.9435,\n",
      "          0.1000, 67.9435, 67.9261, 67.9435, 67.9435, 67.9435, 67.8725, 67.9435,\n",
      "         67.9435, 67.9435, 67.9261, 67.9435, 67.9435, 67.9435, 67.9261, 67.8725,\n",
      "         67.9261, 67.9261, 67.9261,  0.1000, 67.9261, 67.8725,  0.1000, 67.8725,\n",
      "         67.9435,  0.1000, 67.9435, 67.9435, 67.9435, 67.9261, 67.9261,  0.1000,\n",
      "         67.9435,  0.1000, 67.8317, 67.8317, 67.9261, 67.9435, 67.9435,  0.1000,\n",
      "          0.1000, 67.8317, 67.9261, 67.9435,  0.1000, 67.9261, 67.9435,  0.1000,\n",
      "         67.8317, 67.9435]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 550 was 98.8%\n",
      "current params: tensor([67.8317, 67.9261, 67.8725, 67.9435], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.9\n",
      "SLow rates:  tensor([[67.9319, 68.0263, 67.9726, 68.0437,  0.1000,  0.1000,  0.1000, 67.9319,\n",
      "         67.9319, 67.9319,  0.1000,  0.1000, 68.0263, 68.0263, 68.0263,  0.1000,\n",
      "          0.1000, 68.0263, 68.0263,  0.1000, 67.9726, 67.9726, 67.9726,  0.1000,\n",
      "          0.1000, 67.9726, 67.9726,  0.1000, 67.9726,  0.1000, 67.9726, 68.0437,\n",
      "         68.0437, 68.0437,  0.1000,  0.1000, 68.0437, 68.0437,  0.1000, 68.0437,\n",
      "          0.1000, 68.0437, 68.0263, 68.0437, 68.0437, 68.0437, 67.9726, 68.0437,\n",
      "         68.0437, 68.0437, 68.0263, 68.0437, 68.0437, 68.0437, 68.0263, 67.9726,\n",
      "         68.0263, 68.0263, 68.0263,  0.1000, 68.0263, 67.9726,  0.1000, 67.9726,\n",
      "         68.0437,  0.1000, 68.0437, 68.0437, 68.0437, 68.0263, 68.0263,  0.1000,\n",
      "         68.0437,  0.1000, 67.9319, 67.9319, 68.0263, 68.0437, 68.0437,  0.1000,\n",
      "          0.1000, 67.9319, 68.0263, 68.0437,  0.1000, 68.0263, 68.0437,  0.1000,\n",
      "         67.9319, 68.0437]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 551 was 98.9%\n",
      "current params: tensor([67.9319, 68.0263, 67.9726, 68.0437], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.0\n",
      "SLow rates:  tensor([[68.0321, 68.1265, 68.0728, 68.1439,  0.1000,  0.1000,  0.1000, 68.0321,\n",
      "         68.0321, 68.0321,  0.1000,  0.1000, 68.1265, 68.1265, 68.1265,  0.1000,\n",
      "          0.1000, 68.1265, 68.1265,  0.1000, 68.0728, 68.0728, 68.0728,  0.1000,\n",
      "          0.1000, 68.0728, 68.0728,  0.1000, 68.0728,  0.1000, 68.0728, 68.1439,\n",
      "         68.1439, 68.1439,  0.1000,  0.1000, 68.1439, 68.1439,  0.1000, 68.1439,\n",
      "          0.1000, 68.1439, 68.1265, 68.1439, 68.1439, 68.1439, 68.0728, 68.1439,\n",
      "         68.1439, 68.1439, 68.1265, 68.1439, 68.1439, 68.1439, 68.1265, 68.0728,\n",
      "         68.1265, 68.1265, 68.1265,  0.1000, 68.1265, 68.0728,  0.1000, 68.0728,\n",
      "         68.1439,  0.1000, 68.1439, 68.1439, 68.1439, 68.1265, 68.1265,  0.1000,\n",
      "         68.1439,  0.1000, 68.0321, 68.0321, 68.1265, 68.1439, 68.1439,  0.1000,\n",
      "          0.1000, 68.0321, 68.1265, 68.1439,  0.1000, 68.1265, 68.1439,  0.1000,\n",
      "         68.0321, 68.1439]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 552 was 98.9%\n",
      "current params: tensor([68.0321, 68.1265, 68.0728, 68.1439], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.0\n",
      "SLow rates:  tensor([[68.1323, 68.2267, 68.1730, 68.2441,  0.1000,  0.1000,  0.1000, 68.1323,\n",
      "         68.1323, 68.1323,  0.1000,  0.1000, 68.2267, 68.2267, 68.2267,  0.1000,\n",
      "          0.1000, 68.2267, 68.2267,  0.1000, 68.1730, 68.1730, 68.1730,  0.1000,\n",
      "          0.1000, 68.1730, 68.1730,  0.1000, 68.1730,  0.1000, 68.1730, 68.2441,\n",
      "         68.2441, 68.2441,  0.1000,  0.1000, 68.2441, 68.2441,  0.1000, 68.2441,\n",
      "          0.1000, 68.2441, 68.2267, 68.2441, 68.2441, 68.2441, 68.1730, 68.2441,\n",
      "         68.2441, 68.2441, 68.2267, 68.2441, 68.2441, 68.2441, 68.2267, 68.1730,\n",
      "         68.2267, 68.2267, 68.2267,  0.1000, 68.2267, 68.1730,  0.1000, 68.1730,\n",
      "         68.2441,  0.1000, 68.2441, 68.2441, 68.2441, 68.2267, 68.2267,  0.1000,\n",
      "         68.2441,  0.1000, 68.1323, 68.1323, 68.2267, 68.2441, 68.2441,  0.1000,\n",
      "          0.1000, 68.1323, 68.2267, 68.2441,  0.1000, 68.2267, 68.2441,  0.1000,\n",
      "         68.1323, 68.2441]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 553 was 98.9%\n",
      "current params: tensor([68.1323, 68.2267, 68.1730, 68.2441], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.0\n",
      "SLow rates:  tensor([[68.2325, 68.3268, 68.2732, 68.3442,  0.1000,  0.1000,  0.1000, 68.2325,\n",
      "         68.2325, 68.2325,  0.1000,  0.1000, 68.3268, 68.3268, 68.3268,  0.1000,\n",
      "          0.1000, 68.3268, 68.3268,  0.1000, 68.2732, 68.2732, 68.2732,  0.1000,\n",
      "          0.1000, 68.2732, 68.2732,  0.1000, 68.2732,  0.1000, 68.2732, 68.3442,\n",
      "         68.3442, 68.3442,  0.1000,  0.1000, 68.3442, 68.3442,  0.1000, 68.3442,\n",
      "          0.1000, 68.3442, 68.3268, 68.3442, 68.3442, 68.3442, 68.2732, 68.3442,\n",
      "         68.3442, 68.3442, 68.3268, 68.3442, 68.3442, 68.3442, 68.3268, 68.2732,\n",
      "         68.3268, 68.3268, 68.3268,  0.1000, 68.3268, 68.2732,  0.1000, 68.2732,\n",
      "         68.3442,  0.1000, 68.3442, 68.3442, 68.3442, 68.3268, 68.3268,  0.1000,\n",
      "         68.3442,  0.1000, 68.2325, 68.2325, 68.3268, 68.3442, 68.3442,  0.1000,\n",
      "          0.1000, 68.2325, 68.3268, 68.3442,  0.1000, 68.3268, 68.3442,  0.1000,\n",
      "         68.2325, 68.3442]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 554 was 98.9%\n",
      "current params: tensor([68.2325, 68.3268, 68.2732, 68.3442], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.0\n",
      "SLow rates:  tensor([[68.3327, 68.4270, 68.3734, 68.4444,  0.1000,  0.1000,  0.1000, 68.3327,\n",
      "         68.3327, 68.3327,  0.1000,  0.1000, 68.4270, 68.4270, 68.4270,  0.1000,\n",
      "          0.1000, 68.4270, 68.4270,  0.1000, 68.3734, 68.3734, 68.3734,  0.1000,\n",
      "          0.1000, 68.3734, 68.3734,  0.1000, 68.3734,  0.1000, 68.3734, 68.4444,\n",
      "         68.4444, 68.4444,  0.1000,  0.1000, 68.4444, 68.4444,  0.1000, 68.4444,\n",
      "          0.1000, 68.4444, 68.4270, 68.4444, 68.4444, 68.4444, 68.3734, 68.4444,\n",
      "         68.4444, 68.4444, 68.4270, 68.4444, 68.4444, 68.4444, 68.4270, 68.3734,\n",
      "         68.4270, 68.4270, 68.4270,  0.1000, 68.4270, 68.3734,  0.1000, 68.3734,\n",
      "         68.4444,  0.1000, 68.4444, 68.4444, 68.4444, 68.4270, 68.4270,  0.1000,\n",
      "         68.4444,  0.1000, 68.3327, 68.3327, 68.4270, 68.4444, 68.4444,  0.1000,\n",
      "          0.1000, 68.3327, 68.4270, 68.4444,  0.1000, 68.4270, 68.4444,  0.1000,\n",
      "         68.3327, 68.4444]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 555 was 98.9%\n",
      "current params: tensor([68.3327, 68.4270, 68.3734, 68.4444], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.0\n",
      "SLow rates:  tensor([[68.4328, 68.5272, 68.4735, 68.5446,  0.1000,  0.1000,  0.1000, 68.4328,\n",
      "         68.4328, 68.4328,  0.1000,  0.1000, 68.5272, 68.5272, 68.5272,  0.1000,\n",
      "          0.1000, 68.5272, 68.5272,  0.1000, 68.4735, 68.4735, 68.4735,  0.1000,\n",
      "          0.1000, 68.4735, 68.4735,  0.1000, 68.4735,  0.1000, 68.4735, 68.5446,\n",
      "         68.5446, 68.5446,  0.1000,  0.1000, 68.5446, 68.5446,  0.1000, 68.5446,\n",
      "          0.1000, 68.5446, 68.5272, 68.5446, 68.5446, 68.5446, 68.4735, 68.5446,\n",
      "         68.5446, 68.5446, 68.5272, 68.5446, 68.5446, 68.5446, 68.5272, 68.4735,\n",
      "         68.5272, 68.5272, 68.5272,  0.1000, 68.5272, 68.4735,  0.1000, 68.4735,\n",
      "         68.5446,  0.1000, 68.5446, 68.5446, 68.5446, 68.5272, 68.5272,  0.1000,\n",
      "         68.5446,  0.1000, 68.4328, 68.4328, 68.5272, 68.5446, 68.5446,  0.1000,\n",
      "          0.1000, 68.4328, 68.5272, 68.5446,  0.1000, 68.5272, 68.5446,  0.1000,\n",
      "         68.4328, 68.5446]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 556 was 98.9%\n",
      "current params: tensor([68.4328, 68.5272, 68.4735, 68.5446], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "SLow rates:  tensor([[68.5330, 68.6274, 68.5737, 68.6447,  0.1000,  0.1000,  0.1000, 68.5330,\n",
      "         68.5330, 68.5330,  0.1000,  0.1000, 68.6274, 68.6274, 68.6274,  0.1000,\n",
      "          0.1000, 68.6274, 68.6274,  0.1000, 68.5737, 68.5737, 68.5737,  0.1000,\n",
      "          0.1000, 68.5737, 68.5737,  0.1000, 68.5737,  0.1000, 68.5737, 68.6447,\n",
      "         68.6447, 68.6447,  0.1000,  0.1000, 68.6447, 68.6447,  0.1000, 68.6447,\n",
      "          0.1000, 68.6447, 68.6274, 68.6447, 68.6447, 68.6447, 68.5737, 68.6447,\n",
      "         68.6447, 68.6447, 68.6274, 68.6447, 68.6447, 68.6447, 68.6274, 68.5737,\n",
      "         68.6274, 68.6274, 68.6274,  0.1000, 68.6274, 68.5737,  0.1000, 68.5737,\n",
      "         68.6447,  0.1000, 68.6447, 68.6447, 68.6447, 68.6274, 68.6274,  0.1000,\n",
      "         68.6447,  0.1000, 68.5330, 68.5330, 68.6274, 68.6447, 68.6447,  0.1000,\n",
      "          0.1000, 68.5330, 68.6274, 68.6447,  0.1000, 68.6274, 68.6447,  0.1000,\n",
      "         68.5330, 68.6447]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 557 was 98.9%\n",
      "current params: tensor([68.5330, 68.6274, 68.5737, 68.6447], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "SLow rates:  tensor([[68.6332, 68.7275, 68.6739, 68.7449,  0.1000,  0.1000,  0.1000, 68.6332,\n",
      "         68.6332, 68.6332,  0.1000,  0.1000, 68.7275, 68.7275, 68.7275,  0.1000,\n",
      "          0.1000, 68.7275, 68.7275,  0.1000, 68.6739, 68.6739, 68.6739,  0.1000,\n",
      "          0.1000, 68.6739, 68.6739,  0.1000, 68.6739,  0.1000, 68.6739, 68.7449,\n",
      "         68.7449, 68.7449,  0.1000,  0.1000, 68.7449, 68.7449,  0.1000, 68.7449,\n",
      "          0.1000, 68.7449, 68.7275, 68.7449, 68.7449, 68.7449, 68.6739, 68.7449,\n",
      "         68.7449, 68.7449, 68.7275, 68.7449, 68.7449, 68.7449, 68.7275, 68.6739,\n",
      "         68.7275, 68.7275, 68.7275,  0.1000, 68.7275, 68.6739,  0.1000, 68.6739,\n",
      "         68.7449,  0.1000, 68.7449, 68.7449, 68.7449, 68.7275, 68.7275,  0.1000,\n",
      "         68.7449,  0.1000, 68.6332, 68.6332, 68.7275, 68.7449, 68.7449,  0.1000,\n",
      "          0.1000, 68.6332, 68.7275, 68.7449,  0.1000, 68.7275, 68.7449,  0.1000,\n",
      "         68.6332, 68.7449]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 558 was 98.9%\n",
      "current params: tensor([68.6332, 68.7275, 68.6739, 68.7449], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "SLow rates:  tensor([[68.7334, 68.8277, 68.7741, 68.8451,  0.1000,  0.1000,  0.1000, 68.7334,\n",
      "         68.7334, 68.7334,  0.1000,  0.1000, 68.8277, 68.8277, 68.8277,  0.1000,\n",
      "          0.1000, 68.8277, 68.8277,  0.1000, 68.7741, 68.7741, 68.7741,  0.1000,\n",
      "          0.1000, 68.7741, 68.7741,  0.1000, 68.7741,  0.1000, 68.7741, 68.8451,\n",
      "         68.8451, 68.8451,  0.1000,  0.1000, 68.8451, 68.8451,  0.1000, 68.8451,\n",
      "          0.1000, 68.8451, 68.8277, 68.8451, 68.8451, 68.8451, 68.7741, 68.8451,\n",
      "         68.8451, 68.8451, 68.8277, 68.8451, 68.8451, 68.8451, 68.8277, 68.7741,\n",
      "         68.8277, 68.8277, 68.8277,  0.1000, 68.8277, 68.7741,  0.1000, 68.7741,\n",
      "         68.8451,  0.1000, 68.8451, 68.8451, 68.8451, 68.8277, 68.8277,  0.1000,\n",
      "         68.8451,  0.1000, 68.7334, 68.7334, 68.8277, 68.8451, 68.8451,  0.1000,\n",
      "          0.1000, 68.7334, 68.8277, 68.8451,  0.1000, 68.8277, 68.8451,  0.1000,\n",
      "         68.7334, 68.8451]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 559 was 98.9%\n",
      "current params: tensor([68.7334, 68.8277, 68.7741, 68.8451], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "SLow rates:  tensor([[68.8335, 68.9279, 68.8742, 68.9452,  0.1000,  0.1000,  0.1000, 68.8335,\n",
      "         68.8335, 68.8335,  0.1000,  0.1000, 68.9279, 68.9279, 68.9279,  0.1000,\n",
      "          0.1000, 68.9279, 68.9279,  0.1000, 68.8742, 68.8742, 68.8742,  0.1000,\n",
      "          0.1000, 68.8742, 68.8742,  0.1000, 68.8742,  0.1000, 68.8742, 68.9452,\n",
      "         68.9452, 68.9452,  0.1000,  0.1000, 68.9452, 68.9452,  0.1000, 68.9452,\n",
      "          0.1000, 68.9452, 68.9279, 68.9452, 68.9452, 68.9452, 68.8742, 68.9452,\n",
      "         68.9452, 68.9452, 68.9279, 68.9452, 68.9452, 68.9452, 68.9279, 68.8742,\n",
      "         68.9279, 68.9279, 68.9279,  0.1000, 68.9279, 68.8742,  0.1000, 68.8742,\n",
      "         68.9452,  0.1000, 68.9452, 68.9452, 68.9452, 68.9279, 68.9279,  0.1000,\n",
      "         68.9452,  0.1000, 68.8335, 68.8335, 68.9279, 68.9452, 68.9452,  0.1000,\n",
      "          0.1000, 68.8335, 68.9279, 68.9452,  0.1000, 68.9279, 68.9452,  0.1000,\n",
      "         68.8335, 68.9452]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 560 was 98.9%\n",
      "current params: tensor([68.8335, 68.9279, 68.8742, 68.9452], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "SLow rates:  tensor([[68.9337, 69.0280, 68.9744, 69.0454,  0.1000,  0.1000,  0.1000, 68.9337,\n",
      "         68.9337, 68.9337,  0.1000,  0.1000, 69.0280, 69.0280, 69.0280,  0.1000,\n",
      "          0.1000, 69.0280, 69.0280,  0.1000, 68.9744, 68.9744, 68.9744,  0.1000,\n",
      "          0.1000, 68.9744, 68.9744,  0.1000, 68.9744,  0.1000, 68.9744, 69.0454,\n",
      "         69.0454, 69.0454,  0.1000,  0.1000, 69.0454, 69.0454,  0.1000, 69.0454,\n",
      "          0.1000, 69.0454, 69.0280, 69.0454, 69.0454, 69.0454, 68.9744, 69.0454,\n",
      "         69.0454, 69.0454, 69.0280, 69.0454, 69.0454, 69.0454, 69.0280, 68.9744,\n",
      "         69.0280, 69.0280, 69.0280,  0.1000, 69.0280, 68.9744,  0.1000, 68.9744,\n",
      "         69.0454,  0.1000, 69.0454, 69.0454, 69.0454, 69.0280, 69.0280,  0.1000,\n",
      "         69.0454,  0.1000, 68.9337, 68.9337, 69.0280, 69.0454, 69.0454,  0.1000,\n",
      "          0.1000, 68.9337, 69.0280, 69.0454,  0.1000, 69.0280, 69.0454,  0.1000,\n",
      "         68.9337, 69.0454]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 561 was 98.9%\n",
      "current params: tensor([68.9337, 69.0280, 68.9744, 69.0454], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "SLow rates:  tensor([[69.0339, 69.1282, 69.0746, 69.1455,  0.1000,  0.1000,  0.1000, 69.0339,\n",
      "         69.0339, 69.0339,  0.1000,  0.1000, 69.1282, 69.1282, 69.1282,  0.1000,\n",
      "          0.1000, 69.1282, 69.1282,  0.1000, 69.0746, 69.0746, 69.0746,  0.1000,\n",
      "          0.1000, 69.0746, 69.0746,  0.1000, 69.0746,  0.1000, 69.0746, 69.1455,\n",
      "         69.1455, 69.1455,  0.1000,  0.1000, 69.1455, 69.1455,  0.1000, 69.1455,\n",
      "          0.1000, 69.1455, 69.1282, 69.1455, 69.1455, 69.1455, 69.0746, 69.1455,\n",
      "         69.1455, 69.1455, 69.1282, 69.1455, 69.1455, 69.1455, 69.1282, 69.0746,\n",
      "         69.1282, 69.1282, 69.1282,  0.1000, 69.1282, 69.0746,  0.1000, 69.0746,\n",
      "         69.1455,  0.1000, 69.1455, 69.1455, 69.1455, 69.1282, 69.1282,  0.1000,\n",
      "         69.1455,  0.1000, 69.0339, 69.0339, 69.1282, 69.1455, 69.1455,  0.1000,\n",
      "          0.1000, 69.0339, 69.1282, 69.1455,  0.1000, 69.1282, 69.1455,  0.1000,\n",
      "         69.0339, 69.1455]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 562 was 98.9%\n",
      "current params: tensor([69.0339, 69.1282, 69.0746, 69.1455], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.2\n",
      "SLow rates:  tensor([[69.1340, 69.2283, 69.1747, 69.2457,  0.1000,  0.1000,  0.1000, 69.1340,\n",
      "         69.1340, 69.1340,  0.1000,  0.1000, 69.2283, 69.2283, 69.2283,  0.1000,\n",
      "          0.1000, 69.2283, 69.2283,  0.1000, 69.1747, 69.1747, 69.1747,  0.1000,\n",
      "          0.1000, 69.1747, 69.1747,  0.1000, 69.1747,  0.1000, 69.1747, 69.2457,\n",
      "         69.2457, 69.2457,  0.1000,  0.1000, 69.2457, 69.2457,  0.1000, 69.2457,\n",
      "          0.1000, 69.2457, 69.2283, 69.2457, 69.2457, 69.2457, 69.1747, 69.2457,\n",
      "         69.2457, 69.2457, 69.2283, 69.2457, 69.2457, 69.2457, 69.2283, 69.1747,\n",
      "         69.2283, 69.2283, 69.2283,  0.1000, 69.2283, 69.1747,  0.1000, 69.1747,\n",
      "         69.2457,  0.1000, 69.2457, 69.2457, 69.2457, 69.2283, 69.2283,  0.1000,\n",
      "         69.2457,  0.1000, 69.1340, 69.1340, 69.2283, 69.2457, 69.2457,  0.1000,\n",
      "          0.1000, 69.1340, 69.2283, 69.2457,  0.1000, 69.2283, 69.2457,  0.1000,\n",
      "         69.1340, 69.2457]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 563 was 98.9%\n",
      "current params: tensor([69.1340, 69.2283, 69.1747, 69.2457], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.2\n",
      "SLow rates:  tensor([[69.2342, 69.3285, 69.2749, 69.3458,  0.1000,  0.1000,  0.1000, 69.2342,\n",
      "         69.2342, 69.2342,  0.1000,  0.1000, 69.3285, 69.3285, 69.3285,  0.1000,\n",
      "          0.1000, 69.3285, 69.3285,  0.1000, 69.2749, 69.2749, 69.2749,  0.1000,\n",
      "          0.1000, 69.2749, 69.2749,  0.1000, 69.2749,  0.1000, 69.2749, 69.3458,\n",
      "         69.3458, 69.3458,  0.1000,  0.1000, 69.3458, 69.3458,  0.1000, 69.3458,\n",
      "          0.1000, 69.3458, 69.3285, 69.3458, 69.3458, 69.3458, 69.2749, 69.3458,\n",
      "         69.3458, 69.3458, 69.3285, 69.3458, 69.3458, 69.3458, 69.3285, 69.2749,\n",
      "         69.3285, 69.3285, 69.3285,  0.1000, 69.3285, 69.2749,  0.1000, 69.2749,\n",
      "         69.3458,  0.1000, 69.3458, 69.3458, 69.3458, 69.3285, 69.3285,  0.1000,\n",
      "         69.3458,  0.1000, 69.2342, 69.2342, 69.3285, 69.3458, 69.3458,  0.1000,\n",
      "          0.1000, 69.2342, 69.3285, 69.3458,  0.1000, 69.3285, 69.3458,  0.1000,\n",
      "         69.2342, 69.3458]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 564 was 98.9%\n",
      "current params: tensor([69.2342, 69.3285, 69.2749, 69.3458], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.2\n",
      "SLow rates:  tensor([[69.3344, 69.4287, 69.3750, 69.4460,  0.1000,  0.1000,  0.1000, 69.3344,\n",
      "         69.3344, 69.3344,  0.1000,  0.1000, 69.4287, 69.4287, 69.4287,  0.1000,\n",
      "          0.1000, 69.4287, 69.4287,  0.1000, 69.3750, 69.3750, 69.3750,  0.1000,\n",
      "          0.1000, 69.3750, 69.3750,  0.1000, 69.3750,  0.1000, 69.3750, 69.4460,\n",
      "         69.4460, 69.4460,  0.1000,  0.1000, 69.4460, 69.4460,  0.1000, 69.4460,\n",
      "          0.1000, 69.4460, 69.4287, 69.4460, 69.4460, 69.4460, 69.3750, 69.4460,\n",
      "         69.4460, 69.4460, 69.4287, 69.4460, 69.4460, 69.4460, 69.4287, 69.3750,\n",
      "         69.4287, 69.4287, 69.4287,  0.1000, 69.4287, 69.3750,  0.1000, 69.3750,\n",
      "         69.4460,  0.1000, 69.4460, 69.4460, 69.4460, 69.4287, 69.4287,  0.1000,\n",
      "         69.4460,  0.1000, 69.3344, 69.3344, 69.4287, 69.4460, 69.4460,  0.1000,\n",
      "          0.1000, 69.3344, 69.4287, 69.4460,  0.1000, 69.4287, 69.4460,  0.1000,\n",
      "         69.3344, 69.4460]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 565 was 98.9%\n",
      "current params: tensor([69.3344, 69.4287, 69.3750, 69.4460], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.2\n",
      "SLow rates:  tensor([[69.4345, 69.5288, 69.4752, 69.5462,  0.1000,  0.1000,  0.1000, 69.4345,\n",
      "         69.4345, 69.4345,  0.1000,  0.1000, 69.5288, 69.5288, 69.5288,  0.1000,\n",
      "          0.1000, 69.5288, 69.5288,  0.1000, 69.4752, 69.4752, 69.4752,  0.1000,\n",
      "          0.1000, 69.4752, 69.4752,  0.1000, 69.4752,  0.1000, 69.4752, 69.5462,\n",
      "         69.5462, 69.5462,  0.1000,  0.1000, 69.5462, 69.5462,  0.1000, 69.5462,\n",
      "          0.1000, 69.5462, 69.5288, 69.5462, 69.5462, 69.5462, 69.4752, 69.5462,\n",
      "         69.5462, 69.5462, 69.5288, 69.5462, 69.5462, 69.5462, 69.5288, 69.4752,\n",
      "         69.5288, 69.5288, 69.5288,  0.1000, 69.5288, 69.4752,  0.1000, 69.4752,\n",
      "         69.5462,  0.1000, 69.5462, 69.5462, 69.5462, 69.5288, 69.5288,  0.1000,\n",
      "         69.5462,  0.1000, 69.4345, 69.4345, 69.5288, 69.5462, 69.5462,  0.1000,\n",
      "          0.1000, 69.4345, 69.5288, 69.5462,  0.1000, 69.5288, 69.5462,  0.1000,\n",
      "         69.4345, 69.5462]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 566 was 98.9%\n",
      "current params: tensor([69.4345, 69.5288, 69.4752, 69.5462], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.2\n",
      "SLow rates:  tensor([[69.5347, 69.6290, 69.5753, 69.6463,  0.1000,  0.1000,  0.1000, 69.5347,\n",
      "         69.5347, 69.5347,  0.1000,  0.1000, 69.6290, 69.6290, 69.6290,  0.1000,\n",
      "          0.1000, 69.6290, 69.6290,  0.1000, 69.5753, 69.5753, 69.5753,  0.1000,\n",
      "          0.1000, 69.5753, 69.5753,  0.1000, 69.5753,  0.1000, 69.5753, 69.6463,\n",
      "         69.6463, 69.6463,  0.1000,  0.1000, 69.6463, 69.6463,  0.1000, 69.6463,\n",
      "          0.1000, 69.6463, 69.6290, 69.6463, 69.6463, 69.6463, 69.5753, 69.6463,\n",
      "         69.6463, 69.6463, 69.6290, 69.6463, 69.6463, 69.6463, 69.6290, 69.5753,\n",
      "         69.6290, 69.6290, 69.6290,  0.1000, 69.6290, 69.5753,  0.1000, 69.5753,\n",
      "         69.6463,  0.1000, 69.6463, 69.6463, 69.6463, 69.6290, 69.6290,  0.1000,\n",
      "         69.6463,  0.1000, 69.5347, 69.5347, 69.6290, 69.6463, 69.6463,  0.1000,\n",
      "          0.1000, 69.5347, 69.6290, 69.6463,  0.1000, 69.6290, 69.6463,  0.1000,\n",
      "         69.5347, 69.6463]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 567 was 98.9%\n",
      "current params: tensor([69.5347, 69.6290, 69.5753, 69.6463], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.3\n",
      "SLow rates:  tensor([[69.6348, 69.7291, 69.6755, 69.7464,  0.1000,  0.1000,  0.1000, 69.6348,\n",
      "         69.6348, 69.6348,  0.1000,  0.1000, 69.7291, 69.7291, 69.7291,  0.1000,\n",
      "          0.1000, 69.7291, 69.7291,  0.1000, 69.6755, 69.6755, 69.6755,  0.1000,\n",
      "          0.1000, 69.6755, 69.6755,  0.1000, 69.6755,  0.1000, 69.6755, 69.7464,\n",
      "         69.7464, 69.7464,  0.1000,  0.1000, 69.7464, 69.7464,  0.1000, 69.7464,\n",
      "          0.1000, 69.7464, 69.7291, 69.7464, 69.7464, 69.7464, 69.6755, 69.7464,\n",
      "         69.7464, 69.7464, 69.7291, 69.7464, 69.7464, 69.7464, 69.7291, 69.6755,\n",
      "         69.7291, 69.7291, 69.7291,  0.1000, 69.7291, 69.6755,  0.1000, 69.6755,\n",
      "         69.7464,  0.1000, 69.7464, 69.7464, 69.7464, 69.7291, 69.7291,  0.1000,\n",
      "         69.7464,  0.1000, 69.6348, 69.6348, 69.7291, 69.7464, 69.7464,  0.1000,\n",
      "          0.1000, 69.6348, 69.7291, 69.7464,  0.1000, 69.7291, 69.7464,  0.1000,\n",
      "         69.6348, 69.7464]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 568 was 98.9%\n",
      "current params: tensor([69.6348, 69.7291, 69.6755, 69.7464], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.3\n",
      "SLow rates:  tensor([[69.7350, 69.8293, 69.7757, 69.8466,  0.1000,  0.1000,  0.1000, 69.7350,\n",
      "         69.7350, 69.7350,  0.1000,  0.1000, 69.8293, 69.8293, 69.8293,  0.1000,\n",
      "          0.1000, 69.8293, 69.8293,  0.1000, 69.7757, 69.7757, 69.7757,  0.1000,\n",
      "          0.1000, 69.7757, 69.7757,  0.1000, 69.7757,  0.1000, 69.7757, 69.8466,\n",
      "         69.8466, 69.8466,  0.1000,  0.1000, 69.8466, 69.8466,  0.1000, 69.8466,\n",
      "          0.1000, 69.8466, 69.8293, 69.8466, 69.8466, 69.8466, 69.7757, 69.8466,\n",
      "         69.8466, 69.8466, 69.8293, 69.8466, 69.8466, 69.8466, 69.8293, 69.7757,\n",
      "         69.8293, 69.8293, 69.8293,  0.1000, 69.8293, 69.7757,  0.1000, 69.7757,\n",
      "         69.8466,  0.1000, 69.8466, 69.8466, 69.8466, 69.8293, 69.8293,  0.1000,\n",
      "         69.8466,  0.1000, 69.7350, 69.7350, 69.8293, 69.8466, 69.8466,  0.1000,\n",
      "          0.1000, 69.7350, 69.8293, 69.8466,  0.1000, 69.8293, 69.8466,  0.1000,\n",
      "         69.7350, 69.8466]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 569 was 98.9%\n",
      "current params: tensor([69.7350, 69.8293, 69.7757, 69.8466], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.3\n",
      "SLow rates:  tensor([[69.8352, 69.9294, 69.8758, 69.9467,  0.1000,  0.1000,  0.1000, 69.8352,\n",
      "         69.8352, 69.8352,  0.1000,  0.1000, 69.9294, 69.9294, 69.9294,  0.1000,\n",
      "          0.1000, 69.9294, 69.9294,  0.1000, 69.8758, 69.8758, 69.8758,  0.1000,\n",
      "          0.1000, 69.8758, 69.8758,  0.1000, 69.8758,  0.1000, 69.8758, 69.9467,\n",
      "         69.9467, 69.9467,  0.1000,  0.1000, 69.9467, 69.9467,  0.1000, 69.9467,\n",
      "          0.1000, 69.9467, 69.9294, 69.9467, 69.9467, 69.9467, 69.8758, 69.9467,\n",
      "         69.9467, 69.9467, 69.9294, 69.9467, 69.9467, 69.9467, 69.9294, 69.8758,\n",
      "         69.9294, 69.9294, 69.9294,  0.1000, 69.9294, 69.8758,  0.1000, 69.8758,\n",
      "         69.9467,  0.1000, 69.9467, 69.9467, 69.9467, 69.9294, 69.9294,  0.1000,\n",
      "         69.9467,  0.1000, 69.8352, 69.8352, 69.9294, 69.9467, 69.9467,  0.1000,\n",
      "          0.1000, 69.8352, 69.9294, 69.9467,  0.1000, 69.9294, 69.9467,  0.1000,\n",
      "         69.8352, 69.9467]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 570 was 98.9%\n",
      "current params: tensor([69.8352, 69.9294, 69.8758, 69.9467], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.3\n",
      "SLow rates:  tensor([[69.9353, 70.0296, 69.9760, 70.0469,  0.1000,  0.1000,  0.1000, 69.9353,\n",
      "         69.9353, 69.9353,  0.1000,  0.1000, 70.0296, 70.0296, 70.0296,  0.1000,\n",
      "          0.1000, 70.0296, 70.0296,  0.1000, 69.9760, 69.9760, 69.9760,  0.1000,\n",
      "          0.1000, 69.9760, 69.9760,  0.1000, 69.9760,  0.1000, 69.9760, 70.0469,\n",
      "         70.0469, 70.0469,  0.1000,  0.1000, 70.0469, 70.0469,  0.1000, 70.0469,\n",
      "          0.1000, 70.0469, 70.0296, 70.0469, 70.0469, 70.0469, 69.9760, 70.0469,\n",
      "         70.0469, 70.0469, 70.0296, 70.0469, 70.0469, 70.0469, 70.0296, 69.9760,\n",
      "         70.0296, 70.0296, 70.0296,  0.1000, 70.0296, 69.9760,  0.1000, 69.9760,\n",
      "         70.0469,  0.1000, 70.0469, 70.0469, 70.0469, 70.0296, 70.0296,  0.1000,\n",
      "         70.0469,  0.1000, 69.9353, 69.9353, 70.0296, 70.0469, 70.0469,  0.1000,\n",
      "          0.1000, 69.9353, 70.0296, 70.0469,  0.1000, 70.0296, 70.0469,  0.1000,\n",
      "         69.9353, 70.0469]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 571 was 98.9%\n",
      "current params: tensor([69.9353, 70.0296, 69.9760, 70.0469], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.3\n",
      "SLow rates:  tensor([[70.0355, 70.1297, 70.0761, 70.1470,  0.1000,  0.1000,  0.1000, 70.0355,\n",
      "         70.0355, 70.0355,  0.1000,  0.1000, 70.1297, 70.1297, 70.1297,  0.1000,\n",
      "          0.1000, 70.1297, 70.1297,  0.1000, 70.0761, 70.0761, 70.0761,  0.1000,\n",
      "          0.1000, 70.0761, 70.0761,  0.1000, 70.0761,  0.1000, 70.0761, 70.1470,\n",
      "         70.1470, 70.1470,  0.1000,  0.1000, 70.1470, 70.1470,  0.1000, 70.1470,\n",
      "          0.1000, 70.1470, 70.1297, 70.1470, 70.1470, 70.1470, 70.0761, 70.1470,\n",
      "         70.1470, 70.1470, 70.1297, 70.1470, 70.1470, 70.1470, 70.1297, 70.0761,\n",
      "         70.1297, 70.1297, 70.1297,  0.1000, 70.1297, 70.0761,  0.1000, 70.0761,\n",
      "         70.1470,  0.1000, 70.1470, 70.1470, 70.1470, 70.1297, 70.1297,  0.1000,\n",
      "         70.1470,  0.1000, 70.0355, 70.0355, 70.1297, 70.1470, 70.1470,  0.1000,\n",
      "          0.1000, 70.0355, 70.1297, 70.1470,  0.1000, 70.1297, 70.1470,  0.1000,\n",
      "         70.0355, 70.1470]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 572 was 98.9%\n",
      "current params: tensor([70.0355, 70.1297, 70.0761, 70.1470], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "SLow rates:  tensor([[70.1356, 70.2299, 70.1763, 70.2472,  0.1000,  0.1000,  0.1000, 70.1356,\n",
      "         70.1356, 70.1356,  0.1000,  0.1000, 70.2299, 70.2299, 70.2299,  0.1000,\n",
      "          0.1000, 70.2299, 70.2299,  0.1000, 70.1763, 70.1763, 70.1763,  0.1000,\n",
      "          0.1000, 70.1763, 70.1763,  0.1000, 70.1763,  0.1000, 70.1763, 70.2472,\n",
      "         70.2472, 70.2472,  0.1000,  0.1000, 70.2472, 70.2472,  0.1000, 70.2472,\n",
      "          0.1000, 70.2472, 70.2299, 70.2472, 70.2472, 70.2472, 70.1763, 70.2472,\n",
      "         70.2472, 70.2472, 70.2299, 70.2472, 70.2472, 70.2472, 70.2299, 70.1763,\n",
      "         70.2299, 70.2299, 70.2299,  0.1000, 70.2299, 70.1763,  0.1000, 70.1763,\n",
      "         70.2472,  0.1000, 70.2472, 70.2472, 70.2472, 70.2299, 70.2299,  0.1000,\n",
      "         70.2472,  0.1000, 70.1356, 70.1356, 70.2299, 70.2472, 70.2472,  0.1000,\n",
      "          0.1000, 70.1356, 70.2299, 70.2472,  0.1000, 70.2299, 70.2472,  0.1000,\n",
      "         70.1356, 70.2472]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 573 was 98.9%\n",
      "current params: tensor([70.1356, 70.2299, 70.1763, 70.2472], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "SLow rates:  tensor([[70.2358, 70.3300, 70.2764, 70.3473,  0.1000,  0.1000,  0.1000, 70.2358,\n",
      "         70.2358, 70.2358,  0.1000,  0.1000, 70.3300, 70.3300, 70.3300,  0.1000,\n",
      "          0.1000, 70.3300, 70.3300,  0.1000, 70.2764, 70.2764, 70.2764,  0.1000,\n",
      "          0.1000, 70.2764, 70.2764,  0.1000, 70.2764,  0.1000, 70.2764, 70.3473,\n",
      "         70.3473, 70.3473,  0.1000,  0.1000, 70.3473, 70.3473,  0.1000, 70.3473,\n",
      "          0.1000, 70.3473, 70.3300, 70.3473, 70.3473, 70.3473, 70.2764, 70.3473,\n",
      "         70.3473, 70.3473, 70.3300, 70.3473, 70.3473, 70.3473, 70.3300, 70.2764,\n",
      "         70.3300, 70.3300, 70.3300,  0.1000, 70.3300, 70.2764,  0.1000, 70.2764,\n",
      "         70.3473,  0.1000, 70.3473, 70.3473, 70.3473, 70.3300, 70.3300,  0.1000,\n",
      "         70.3473,  0.1000, 70.2358, 70.2358, 70.3300, 70.3473, 70.3473,  0.1000,\n",
      "          0.1000, 70.2358, 70.3300, 70.3473,  0.1000, 70.3300, 70.3473,  0.1000,\n",
      "         70.2358, 70.3473]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 574 was 98.9%\n",
      "current params: tensor([70.2358, 70.3300, 70.2764, 70.3473], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "SLow rates:  tensor([[70.3359, 70.4301, 70.3765, 70.4474,  0.1000,  0.1000,  0.1000, 70.3359,\n",
      "         70.3359, 70.3359,  0.1000,  0.1000, 70.4301, 70.4301, 70.4301,  0.1000,\n",
      "          0.1000, 70.4301, 70.4301,  0.1000, 70.3765, 70.3765, 70.3765,  0.1000,\n",
      "          0.1000, 70.3765, 70.3765,  0.1000, 70.3765,  0.1000, 70.3765, 70.4474,\n",
      "         70.4474, 70.4474,  0.1000,  0.1000, 70.4474, 70.4474,  0.1000, 70.4474,\n",
      "          0.1000, 70.4474, 70.4301, 70.4474, 70.4474, 70.4474, 70.3765, 70.4474,\n",
      "         70.4474, 70.4474, 70.4301, 70.4474, 70.4474, 70.4474, 70.4301, 70.3765,\n",
      "         70.4301, 70.4301, 70.4301,  0.1000, 70.4301, 70.3765,  0.1000, 70.3765,\n",
      "         70.4474,  0.1000, 70.4474, 70.4474, 70.4474, 70.4301, 70.4301,  0.1000,\n",
      "         70.4474,  0.1000, 70.3359, 70.3359, 70.4301, 70.4474, 70.4474,  0.1000,\n",
      "          0.1000, 70.3359, 70.4301, 70.4474,  0.1000, 70.4301, 70.4474,  0.1000,\n",
      "         70.3359, 70.4474]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 575 was 98.9%\n",
      "current params: tensor([70.3359, 70.4301, 70.3765, 70.4474], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "SLow rates:  tensor([[70.4361, 70.5303, 70.4767, 70.5476,  0.1000,  0.1000,  0.1000, 70.4361,\n",
      "         70.4361, 70.4361,  0.1000,  0.1000, 70.5303, 70.5303, 70.5303,  0.1000,\n",
      "          0.1000, 70.5303, 70.5303,  0.1000, 70.4767, 70.4767, 70.4767,  0.1000,\n",
      "          0.1000, 70.4767, 70.4767,  0.1000, 70.4767,  0.1000, 70.4767, 70.5476,\n",
      "         70.5476, 70.5476,  0.1000,  0.1000, 70.5476, 70.5476,  0.1000, 70.5476,\n",
      "          0.1000, 70.5476, 70.5303, 70.5476, 70.5476, 70.5476, 70.4767, 70.5476,\n",
      "         70.5476, 70.5476, 70.5303, 70.5476, 70.5476, 70.5476, 70.5303, 70.4767,\n",
      "         70.5303, 70.5303, 70.5303,  0.1000, 70.5303, 70.4767,  0.1000, 70.4767,\n",
      "         70.5476,  0.1000, 70.5476, 70.5476, 70.5476, 70.5303, 70.5303,  0.1000,\n",
      "         70.5476,  0.1000, 70.4361, 70.4361, 70.5303, 70.5476, 70.5476,  0.1000,\n",
      "          0.1000, 70.4361, 70.5303, 70.5476,  0.1000, 70.5303, 70.5476,  0.1000,\n",
      "         70.4361, 70.5476]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 576 was 98.9%\n",
      "current params: tensor([70.4361, 70.5303, 70.4767, 70.5476], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "SLow rates:  tensor([[70.5362, 70.6304, 70.5768, 70.6477,  0.1000,  0.1000,  0.1000, 70.5362,\n",
      "         70.5362, 70.5362,  0.1000,  0.1000, 70.6304, 70.6304, 70.6304,  0.1000,\n",
      "          0.1000, 70.6304, 70.6304,  0.1000, 70.5768, 70.5768, 70.5768,  0.1000,\n",
      "          0.1000, 70.5768, 70.5768,  0.1000, 70.5768,  0.1000, 70.5768, 70.6477,\n",
      "         70.6477, 70.6477,  0.1000,  0.1000, 70.6477, 70.6477,  0.1000, 70.6477,\n",
      "          0.1000, 70.6477, 70.6304, 70.6477, 70.6477, 70.6477, 70.5768, 70.6477,\n",
      "         70.6477, 70.6477, 70.6304, 70.6477, 70.6477, 70.6477, 70.6304, 70.5768,\n",
      "         70.6304, 70.6304, 70.6304,  0.1000, 70.6304, 70.5768,  0.1000, 70.5768,\n",
      "         70.6477,  0.1000, 70.6477, 70.6477, 70.6477, 70.6304, 70.6304,  0.1000,\n",
      "         70.6477,  0.1000, 70.5362, 70.5362, 70.6304, 70.6477, 70.6477,  0.1000,\n",
      "          0.1000, 70.5362, 70.6304, 70.6477,  0.1000, 70.6304, 70.6477,  0.1000,\n",
      "         70.5362, 70.6477]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 577 was 98.9%\n",
      "current params: tensor([70.5362, 70.6304, 70.5768, 70.6477], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "SLow rates:  tensor([[70.6363, 70.7306, 70.6770, 70.7478,  0.1000,  0.1000,  0.1000, 70.6363,\n",
      "         70.6363, 70.6363,  0.1000,  0.1000, 70.7306, 70.7306, 70.7306,  0.1000,\n",
      "          0.1000, 70.7306, 70.7306,  0.1000, 70.6770, 70.6770, 70.6770,  0.1000,\n",
      "          0.1000, 70.6770, 70.6770,  0.1000, 70.6770,  0.1000, 70.6770, 70.7478,\n",
      "         70.7478, 70.7478,  0.1000,  0.1000, 70.7478, 70.7478,  0.1000, 70.7478,\n",
      "          0.1000, 70.7478, 70.7306, 70.7478, 70.7478, 70.7478, 70.6770, 70.7478,\n",
      "         70.7478, 70.7478, 70.7306, 70.7478, 70.7478, 70.7478, 70.7306, 70.6770,\n",
      "         70.7306, 70.7306, 70.7306,  0.1000, 70.7306, 70.6770,  0.1000, 70.6770,\n",
      "         70.7478,  0.1000, 70.7478, 70.7478, 70.7478, 70.7306, 70.7306,  0.1000,\n",
      "         70.7478,  0.1000, 70.6363, 70.6363, 70.7306, 70.7478, 70.7478,  0.1000,\n",
      "          0.1000, 70.6363, 70.7306, 70.7478,  0.1000, 70.7306, 70.7478,  0.1000,\n",
      "         70.6363, 70.7478]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 578 was 98.9%\n",
      "current params: tensor([70.6363, 70.7306, 70.6770, 70.7478], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.5\n",
      "SLow rates:  tensor([[70.7365, 70.8307, 70.7771, 70.8480,  0.1000,  0.1000,  0.1000, 70.7365,\n",
      "         70.7365, 70.7365,  0.1000,  0.1000, 70.8307, 70.8307, 70.8307,  0.1000,\n",
      "          0.1000, 70.8307, 70.8307,  0.1000, 70.7771, 70.7771, 70.7771,  0.1000,\n",
      "          0.1000, 70.7771, 70.7771,  0.1000, 70.7771,  0.1000, 70.7771, 70.8480,\n",
      "         70.8480, 70.8480,  0.1000,  0.1000, 70.8480, 70.8480,  0.1000, 70.8480,\n",
      "          0.1000, 70.8480, 70.8307, 70.8480, 70.8480, 70.8480, 70.7771, 70.8480,\n",
      "         70.8480, 70.8480, 70.8307, 70.8480, 70.8480, 70.8480, 70.8307, 70.7771,\n",
      "         70.8307, 70.8307, 70.8307,  0.1000, 70.8307, 70.7771,  0.1000, 70.7771,\n",
      "         70.8480,  0.1000, 70.8480, 70.8480, 70.8480, 70.8307, 70.8307,  0.1000,\n",
      "         70.8480,  0.1000, 70.7365, 70.7365, 70.8307, 70.8480, 70.8480,  0.1000,\n",
      "          0.1000, 70.7365, 70.8307, 70.8480,  0.1000, 70.8307, 70.8480,  0.1000,\n",
      "         70.7365, 70.8480]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 579 was 98.9%\n",
      "current params: tensor([70.7365, 70.8307, 70.7771, 70.8480], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.5\n",
      "SLow rates:  tensor([[70.8366, 70.9308, 70.8772, 70.9481,  0.1000,  0.1000,  0.1000, 70.8366,\n",
      "         70.8366, 70.8366,  0.1000,  0.1000, 70.9308, 70.9308, 70.9308,  0.1000,\n",
      "          0.1000, 70.9308, 70.9308,  0.1000, 70.8772, 70.8772, 70.8772,  0.1000,\n",
      "          0.1000, 70.8772, 70.8772,  0.1000, 70.8772,  0.1000, 70.8772, 70.9481,\n",
      "         70.9481, 70.9481,  0.1000,  0.1000, 70.9481, 70.9481,  0.1000, 70.9481,\n",
      "          0.1000, 70.9481, 70.9308, 70.9481, 70.9481, 70.9481, 70.8772, 70.9481,\n",
      "         70.9481, 70.9481, 70.9308, 70.9481, 70.9481, 70.9481, 70.9308, 70.8772,\n",
      "         70.9308, 70.9308, 70.9308,  0.1000, 70.9308, 70.8772,  0.1000, 70.8772,\n",
      "         70.9481,  0.1000, 70.9481, 70.9481, 70.9481, 70.9308, 70.9308,  0.1000,\n",
      "         70.9481,  0.1000, 70.8366, 70.8366, 70.9308, 70.9481, 70.9481,  0.1000,\n",
      "          0.1000, 70.8366, 70.9308, 70.9481,  0.1000, 70.9308, 70.9481,  0.1000,\n",
      "         70.8366, 70.9481]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 580 was 98.9%\n",
      "current params: tensor([70.8366, 70.9308, 70.8772, 70.9481], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.5\n",
      "SLow rates:  tensor([[70.9368, 71.0310, 70.9774, 71.0482,  0.1000,  0.1000,  0.1000, 70.9368,\n",
      "         70.9368, 70.9368,  0.1000,  0.1000, 71.0310, 71.0310, 71.0310,  0.1000,\n",
      "          0.1000, 71.0310, 71.0310,  0.1000, 70.9774, 70.9774, 70.9774,  0.1000,\n",
      "          0.1000, 70.9774, 70.9774,  0.1000, 70.9774,  0.1000, 70.9774, 71.0482,\n",
      "         71.0482, 71.0482,  0.1000,  0.1000, 71.0482, 71.0482,  0.1000, 71.0482,\n",
      "          0.1000, 71.0482, 71.0310, 71.0482, 71.0482, 71.0482, 70.9774, 71.0482,\n",
      "         71.0482, 71.0482, 71.0310, 71.0482, 71.0482, 71.0482, 71.0310, 70.9774,\n",
      "         71.0310, 71.0310, 71.0310,  0.1000, 71.0310, 70.9774,  0.1000, 70.9774,\n",
      "         71.0482,  0.1000, 71.0482, 71.0482, 71.0482, 71.0310, 71.0310,  0.1000,\n",
      "         71.0482,  0.1000, 70.9368, 70.9368, 71.0310, 71.0482, 71.0482,  0.1000,\n",
      "          0.1000, 70.9368, 71.0310, 71.0482,  0.1000, 71.0310, 71.0482,  0.1000,\n",
      "         70.9368, 71.0482]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 581 was 98.9%\n",
      "current params: tensor([70.9368, 71.0310, 70.9774, 71.0482], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.5\n",
      "SLow rates:  tensor([[71.0369, 71.1311, 71.0775, 71.1484,  0.1000,  0.1000,  0.1000, 71.0369,\n",
      "         71.0369, 71.0369,  0.1000,  0.1000, 71.1311, 71.1311, 71.1311,  0.1000,\n",
      "          0.1000, 71.1311, 71.1311,  0.1000, 71.0775, 71.0775, 71.0775,  0.1000,\n",
      "          0.1000, 71.0775, 71.0775,  0.1000, 71.0775,  0.1000, 71.0775, 71.1484,\n",
      "         71.1484, 71.1484,  0.1000,  0.1000, 71.1484, 71.1484,  0.1000, 71.1484,\n",
      "          0.1000, 71.1484, 71.1311, 71.1484, 71.1484, 71.1484, 71.0775, 71.1484,\n",
      "         71.1484, 71.1484, 71.1311, 71.1484, 71.1484, 71.1484, 71.1311, 71.0775,\n",
      "         71.1311, 71.1311, 71.1311,  0.1000, 71.1311, 71.0775,  0.1000, 71.0775,\n",
      "         71.1484,  0.1000, 71.1484, 71.1484, 71.1484, 71.1311, 71.1311,  0.1000,\n",
      "         71.1484,  0.1000, 71.0369, 71.0369, 71.1311, 71.1484, 71.1484,  0.1000,\n",
      "          0.1000, 71.0369, 71.1311, 71.1484,  0.1000, 71.1311, 71.1484,  0.1000,\n",
      "         71.0369, 71.1484]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 582 was 98.9%\n",
      "current params: tensor([71.0369, 71.1311, 71.0775, 71.1484], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.5\n",
      "SLow rates:  tensor([[71.1370, 71.2312, 71.1776, 71.2485,  0.1000,  0.1000,  0.1000, 71.1370,\n",
      "         71.1370, 71.1370,  0.1000,  0.1000, 71.2312, 71.2312, 71.2312,  0.1000,\n",
      "          0.1000, 71.2312, 71.2312,  0.1000, 71.1776, 71.1776, 71.1776,  0.1000,\n",
      "          0.1000, 71.1776, 71.1776,  0.1000, 71.1776,  0.1000, 71.1776, 71.2485,\n",
      "         71.2485, 71.2485,  0.1000,  0.1000, 71.2485, 71.2485,  0.1000, 71.2485,\n",
      "          0.1000, 71.2485, 71.2312, 71.2485, 71.2485, 71.2485, 71.1776, 71.2485,\n",
      "         71.2485, 71.2485, 71.2312, 71.2485, 71.2485, 71.2485, 71.2312, 71.1776,\n",
      "         71.2312, 71.2312, 71.2312,  0.1000, 71.2312, 71.1776,  0.1000, 71.1776,\n",
      "         71.2485,  0.1000, 71.2485, 71.2485, 71.2485, 71.2312, 71.2312,  0.1000,\n",
      "         71.2485,  0.1000, 71.1370, 71.1370, 71.2312, 71.2485, 71.2485,  0.1000,\n",
      "          0.1000, 71.1370, 71.2312, 71.2485,  0.1000, 71.2312, 71.2485,  0.1000,\n",
      "         71.1370, 71.2485]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 583 was 98.9%\n",
      "current params: tensor([71.1370, 71.2312, 71.1776, 71.2485], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.6\n",
      "SLow rates:  tensor([[71.2372, 71.3313, 71.2778, 71.3486,  0.1000,  0.1000,  0.1000, 71.2372,\n",
      "         71.2372, 71.2372,  0.1000,  0.1000, 71.3313, 71.3313, 71.3313,  0.1000,\n",
      "          0.1000, 71.3313, 71.3313,  0.1000, 71.2778, 71.2778, 71.2778,  0.1000,\n",
      "          0.1000, 71.2778, 71.2778,  0.1000, 71.2778,  0.1000, 71.2778, 71.3486,\n",
      "         71.3486, 71.3486,  0.1000,  0.1000, 71.3486, 71.3486,  0.1000, 71.3486,\n",
      "          0.1000, 71.3486, 71.3313, 71.3486, 71.3486, 71.3486, 71.2778, 71.3486,\n",
      "         71.3486, 71.3486, 71.3313, 71.3486, 71.3486, 71.3486, 71.3313, 71.2778,\n",
      "         71.3313, 71.3313, 71.3313,  0.1000, 71.3313, 71.2778,  0.1000, 71.2778,\n",
      "         71.3486,  0.1000, 71.3486, 71.3486, 71.3486, 71.3313, 71.3313,  0.1000,\n",
      "         71.3486,  0.1000, 71.2372, 71.2372, 71.3313, 71.3486, 71.3486,  0.1000,\n",
      "          0.1000, 71.2372, 71.3313, 71.3486,  0.1000, 71.3313, 71.3486,  0.1000,\n",
      "         71.2372, 71.3486]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 584 was 98.9%\n",
      "current params: tensor([71.2372, 71.3313, 71.2778, 71.3486], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.6\n",
      "SLow rates:  tensor([[71.3373, 71.4315, 71.3779, 71.4487,  0.1000,  0.1000,  0.1000, 71.3373,\n",
      "         71.3373, 71.3373,  0.1000,  0.1000, 71.4315, 71.4315, 71.4315,  0.1000,\n",
      "          0.1000, 71.4315, 71.4315,  0.1000, 71.3779, 71.3779, 71.3779,  0.1000,\n",
      "          0.1000, 71.3779, 71.3779,  0.1000, 71.3779,  0.1000, 71.3779, 71.4487,\n",
      "         71.4487, 71.4487,  0.1000,  0.1000, 71.4487, 71.4487,  0.1000, 71.4487,\n",
      "          0.1000, 71.4487, 71.4315, 71.4487, 71.4487, 71.4487, 71.3779, 71.4487,\n",
      "         71.4487, 71.4487, 71.4315, 71.4487, 71.4487, 71.4487, 71.4315, 71.3779,\n",
      "         71.4315, 71.4315, 71.4315,  0.1000, 71.4315, 71.3779,  0.1000, 71.3779,\n",
      "         71.4487,  0.1000, 71.4487, 71.4487, 71.4487, 71.4315, 71.4315,  0.1000,\n",
      "         71.4487,  0.1000, 71.3373, 71.3373, 71.4315, 71.4487, 71.4487,  0.1000,\n",
      "          0.1000, 71.3373, 71.4315, 71.4487,  0.1000, 71.4315, 71.4487,  0.1000,\n",
      "         71.3373, 71.4487]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 585 was 98.9%\n",
      "current params: tensor([71.3373, 71.4315, 71.3779, 71.4487], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.6\n",
      "SLow rates:  tensor([[71.4374, 71.5316, 71.4780, 71.5489,  0.1000,  0.1000,  0.1000, 71.4374,\n",
      "         71.4374, 71.4374,  0.1000,  0.1000, 71.5316, 71.5316, 71.5316,  0.1000,\n",
      "          0.1000, 71.5316, 71.5316,  0.1000, 71.4780, 71.4780, 71.4780,  0.1000,\n",
      "          0.1000, 71.4780, 71.4780,  0.1000, 71.4780,  0.1000, 71.4780, 71.5489,\n",
      "         71.5489, 71.5489,  0.1000,  0.1000, 71.5489, 71.5489,  0.1000, 71.5489,\n",
      "          0.1000, 71.5489, 71.5316, 71.5489, 71.5489, 71.5489, 71.4780, 71.5489,\n",
      "         71.5489, 71.5489, 71.5316, 71.5489, 71.5489, 71.5489, 71.5316, 71.4780,\n",
      "         71.5316, 71.5316, 71.5316,  0.1000, 71.5316, 71.4780,  0.1000, 71.4780,\n",
      "         71.5489,  0.1000, 71.5489, 71.5489, 71.5489, 71.5316, 71.5316,  0.1000,\n",
      "         71.5489,  0.1000, 71.4374, 71.4374, 71.5316, 71.5489, 71.5489,  0.1000,\n",
      "          0.1000, 71.4374, 71.5316, 71.5489,  0.1000, 71.5316, 71.5489,  0.1000,\n",
      "         71.4374, 71.5489]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 586 was 98.9%\n",
      "current params: tensor([71.4374, 71.5316, 71.4780, 71.5489], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.6\n",
      "SLow rates:  tensor([[71.5376, 71.6317, 71.5782, 71.6490,  0.1000,  0.1000,  0.1000, 71.5376,\n",
      "         71.5376, 71.5376,  0.1000,  0.1000, 71.6317, 71.6317, 71.6317,  0.1000,\n",
      "          0.1000, 71.6317, 71.6317,  0.1000, 71.5782, 71.5782, 71.5782,  0.1000,\n",
      "          0.1000, 71.5782, 71.5782,  0.1000, 71.5782,  0.1000, 71.5782, 71.6490,\n",
      "         71.6490, 71.6490,  0.1000,  0.1000, 71.6490, 71.6490,  0.1000, 71.6490,\n",
      "          0.1000, 71.6490, 71.6317, 71.6490, 71.6490, 71.6490, 71.5782, 71.6490,\n",
      "         71.6490, 71.6490, 71.6317, 71.6490, 71.6490, 71.6490, 71.6317, 71.5782,\n",
      "         71.6317, 71.6317, 71.6317,  0.1000, 71.6317, 71.5782,  0.1000, 71.5782,\n",
      "         71.6490,  0.1000, 71.6490, 71.6490, 71.6490, 71.6317, 71.6317,  0.1000,\n",
      "         71.6490,  0.1000, 71.5376, 71.5376, 71.6317, 71.6490, 71.6490,  0.1000,\n",
      "          0.1000, 71.5376, 71.6317, 71.6490,  0.1000, 71.6317, 71.6490,  0.1000,\n",
      "         71.5376, 71.6490]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 587 was 98.9%\n",
      "current params: tensor([71.5376, 71.6317, 71.5782, 71.6490], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.6\n",
      "SLow rates:  tensor([[71.6377, 71.7318, 71.6783, 71.7491,  0.1000,  0.1000,  0.1000, 71.6377,\n",
      "         71.6377, 71.6377,  0.1000,  0.1000, 71.7318, 71.7318, 71.7318,  0.1000,\n",
      "          0.1000, 71.7318, 71.7318,  0.1000, 71.6783, 71.6783, 71.6783,  0.1000,\n",
      "          0.1000, 71.6783, 71.6783,  0.1000, 71.6783,  0.1000, 71.6783, 71.7491,\n",
      "         71.7491, 71.7491,  0.1000,  0.1000, 71.7491, 71.7491,  0.1000, 71.7491,\n",
      "          0.1000, 71.7491, 71.7318, 71.7491, 71.7491, 71.7491, 71.6783, 71.7491,\n",
      "         71.7491, 71.7491, 71.7318, 71.7491, 71.7491, 71.7491, 71.7318, 71.6783,\n",
      "         71.7318, 71.7318, 71.7318,  0.1000, 71.7318, 71.6783,  0.1000, 71.6783,\n",
      "         71.7491,  0.1000, 71.7491, 71.7491, 71.7491, 71.7318, 71.7318,  0.1000,\n",
      "         71.7491,  0.1000, 71.6377, 71.6377, 71.7318, 71.7491, 71.7491,  0.1000,\n",
      "          0.1000, 71.6377, 71.7318, 71.7491,  0.1000, 71.7318, 71.7491,  0.1000,\n",
      "         71.6377, 71.7491]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 588 was 98.9%\n",
      "current params: tensor([71.6377, 71.7318, 71.6783, 71.7491], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.7\n",
      "SLow rates:  tensor([[71.7378, 71.8320, 71.7784, 71.8492,  0.1000,  0.1000,  0.1000, 71.7378,\n",
      "         71.7378, 71.7378,  0.1000,  0.1000, 71.8320, 71.8320, 71.8320,  0.1000,\n",
      "          0.1000, 71.8320, 71.8320,  0.1000, 71.7784, 71.7784, 71.7784,  0.1000,\n",
      "          0.1000, 71.7784, 71.7784,  0.1000, 71.7784,  0.1000, 71.7784, 71.8492,\n",
      "         71.8492, 71.8492,  0.1000,  0.1000, 71.8492, 71.8492,  0.1000, 71.8492,\n",
      "          0.1000, 71.8492, 71.8320, 71.8492, 71.8492, 71.8492, 71.7784, 71.8492,\n",
      "         71.8492, 71.8492, 71.8320, 71.8492, 71.8492, 71.8492, 71.8320, 71.7784,\n",
      "         71.8320, 71.8320, 71.8320,  0.1000, 71.8320, 71.7784,  0.1000, 71.7784,\n",
      "         71.8492,  0.1000, 71.8492, 71.8492, 71.8492, 71.8320, 71.8320,  0.1000,\n",
      "         71.8492,  0.1000, 71.7378, 71.7378, 71.8320, 71.8492, 71.8492,  0.1000,\n",
      "          0.1000, 71.7378, 71.8320, 71.8492,  0.1000, 71.8320, 71.8492,  0.1000,\n",
      "         71.7378, 71.8492]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 589 was 98.9%\n",
      "current params: tensor([71.7378, 71.8320, 71.7784, 71.8492], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.7\n",
      "SLow rates:  tensor([[71.8379, 71.9321, 71.8785, 71.9493,  0.1000,  0.1000,  0.1000, 71.8379,\n",
      "         71.8379, 71.8379,  0.1000,  0.1000, 71.9321, 71.9321, 71.9321,  0.1000,\n",
      "          0.1000, 71.9321, 71.9321,  0.1000, 71.8785, 71.8785, 71.8785,  0.1000,\n",
      "          0.1000, 71.8785, 71.8785,  0.1000, 71.8785,  0.1000, 71.8785, 71.9493,\n",
      "         71.9493, 71.9493,  0.1000,  0.1000, 71.9493, 71.9493,  0.1000, 71.9493,\n",
      "          0.1000, 71.9493, 71.9321, 71.9493, 71.9493, 71.9493, 71.8785, 71.9493,\n",
      "         71.9493, 71.9493, 71.9321, 71.9493, 71.9493, 71.9493, 71.9321, 71.8785,\n",
      "         71.9321, 71.9321, 71.9321,  0.1000, 71.9321, 71.8785,  0.1000, 71.8785,\n",
      "         71.9493,  0.1000, 71.9493, 71.9493, 71.9493, 71.9321, 71.9321,  0.1000,\n",
      "         71.9493,  0.1000, 71.8379, 71.8379, 71.9321, 71.9493, 71.9493,  0.1000,\n",
      "          0.1000, 71.8379, 71.9321, 71.9493,  0.1000, 71.9321, 71.9493,  0.1000,\n",
      "         71.8379, 71.9493]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 590 was 98.9%\n",
      "current params: tensor([71.8379, 71.9321, 71.8785, 71.9493], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.7\n",
      "SLow rates:  tensor([[71.9381, 72.0322, 71.9787, 72.0495,  0.1000,  0.1000,  0.1000, 71.9381,\n",
      "         71.9381, 71.9381,  0.1000,  0.1000, 72.0322, 72.0322, 72.0322,  0.1000,\n",
      "          0.1000, 72.0322, 72.0322,  0.1000, 71.9787, 71.9787, 71.9787,  0.1000,\n",
      "          0.1000, 71.9787, 71.9787,  0.1000, 71.9787,  0.1000, 71.9787, 72.0495,\n",
      "         72.0495, 72.0495,  0.1000,  0.1000, 72.0495, 72.0495,  0.1000, 72.0495,\n",
      "          0.1000, 72.0495, 72.0322, 72.0495, 72.0495, 72.0495, 71.9787, 72.0495,\n",
      "         72.0495, 72.0495, 72.0322, 72.0495, 72.0495, 72.0495, 72.0322, 71.9787,\n",
      "         72.0322, 72.0322, 72.0322,  0.1000, 72.0322, 71.9787,  0.1000, 71.9787,\n",
      "         72.0495,  0.1000, 72.0495, 72.0495, 72.0495, 72.0322, 72.0322,  0.1000,\n",
      "         72.0495,  0.1000, 71.9381, 71.9381, 72.0322, 72.0495, 72.0495,  0.1000,\n",
      "          0.1000, 71.9381, 72.0322, 72.0495,  0.1000, 72.0322, 72.0495,  0.1000,\n",
      "         71.9381, 72.0495]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 591 was 98.9%\n",
      "current params: tensor([71.9381, 72.0322, 71.9787, 72.0495], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.7\n",
      "SLow rates:  tensor([[72.0382, 72.1323, 72.0788, 72.1496,  0.1000,  0.1000,  0.1000, 72.0382,\n",
      "         72.0382, 72.0382,  0.1000,  0.1000, 72.1323, 72.1323, 72.1323,  0.1000,\n",
      "          0.1000, 72.1323, 72.1323,  0.1000, 72.0788, 72.0788, 72.0788,  0.1000,\n",
      "          0.1000, 72.0788, 72.0788,  0.1000, 72.0788,  0.1000, 72.0788, 72.1496,\n",
      "         72.1496, 72.1496,  0.1000,  0.1000, 72.1496, 72.1496,  0.1000, 72.1496,\n",
      "          0.1000, 72.1496, 72.1323, 72.1496, 72.1496, 72.1496, 72.0788, 72.1496,\n",
      "         72.1496, 72.1496, 72.1323, 72.1496, 72.1496, 72.1496, 72.1323, 72.0788,\n",
      "         72.1323, 72.1323, 72.1323,  0.1000, 72.1323, 72.0788,  0.1000, 72.0788,\n",
      "         72.1496,  0.1000, 72.1496, 72.1496, 72.1496, 72.1323, 72.1323,  0.1000,\n",
      "         72.1496,  0.1000, 72.0382, 72.0382, 72.1323, 72.1496, 72.1496,  0.1000,\n",
      "          0.1000, 72.0382, 72.1323, 72.1496,  0.1000, 72.1323, 72.1496,  0.1000,\n",
      "         72.0382, 72.1496]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 592 was 98.9%\n",
      "current params: tensor([72.0382, 72.1323, 72.0788, 72.1496], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.7\n",
      "SLow rates:  tensor([[72.1383, 72.2324, 72.1789, 72.2497,  0.1000,  0.1000,  0.1000, 72.1383,\n",
      "         72.1383, 72.1383,  0.1000,  0.1000, 72.2324, 72.2324, 72.2324,  0.1000,\n",
      "          0.1000, 72.2324, 72.2324,  0.1000, 72.1789, 72.1789, 72.1789,  0.1000,\n",
      "          0.1000, 72.1789, 72.1789,  0.1000, 72.1789,  0.1000, 72.1789, 72.2497,\n",
      "         72.2497, 72.2497,  0.1000,  0.1000, 72.2497, 72.2497,  0.1000, 72.2497,\n",
      "          0.1000, 72.2497, 72.2324, 72.2497, 72.2497, 72.2497, 72.1789, 72.2497,\n",
      "         72.2497, 72.2497, 72.2324, 72.2497, 72.2497, 72.2497, 72.2324, 72.1789,\n",
      "         72.2324, 72.2324, 72.2324,  0.1000, 72.2324, 72.1789,  0.1000, 72.1789,\n",
      "         72.2497,  0.1000, 72.2497, 72.2497, 72.2497, 72.2324, 72.2324,  0.1000,\n",
      "         72.2497,  0.1000, 72.1383, 72.1383, 72.2324, 72.2497, 72.2497,  0.1000,\n",
      "          0.1000, 72.1383, 72.2324, 72.2497,  0.1000, 72.2324, 72.2497,  0.1000,\n",
      "         72.1383, 72.2497]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 593 was 98.9%\n",
      "current params: tensor([72.1383, 72.2324, 72.1789, 72.2497], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.8\n",
      "SLow rates:  tensor([[72.2384, 72.3326, 72.2790, 72.3498,  0.1000,  0.1000,  0.1000, 72.2384,\n",
      "         72.2384, 72.2384,  0.1000,  0.1000, 72.3326, 72.3326, 72.3326,  0.1000,\n",
      "          0.1000, 72.3326, 72.3326,  0.1000, 72.2790, 72.2790, 72.2790,  0.1000,\n",
      "          0.1000, 72.2790, 72.2790,  0.1000, 72.2790,  0.1000, 72.2790, 72.3498,\n",
      "         72.3498, 72.3498,  0.1000,  0.1000, 72.3498, 72.3498,  0.1000, 72.3498,\n",
      "          0.1000, 72.3498, 72.3326, 72.3498, 72.3498, 72.3498, 72.2790, 72.3498,\n",
      "         72.3498, 72.3498, 72.3326, 72.3498, 72.3498, 72.3498, 72.3326, 72.2790,\n",
      "         72.3326, 72.3326, 72.3326,  0.1000, 72.3326, 72.2790,  0.1000, 72.2790,\n",
      "         72.3498,  0.1000, 72.3498, 72.3498, 72.3498, 72.3326, 72.3326,  0.1000,\n",
      "         72.3498,  0.1000, 72.2384, 72.2384, 72.3326, 72.3498, 72.3498,  0.1000,\n",
      "          0.1000, 72.2384, 72.3326, 72.3498,  0.1000, 72.3326, 72.3498,  0.1000,\n",
      "         72.2384, 72.3498]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 594 was 98.9%\n",
      "current params: tensor([72.2384, 72.3326, 72.2790, 72.3498], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.8\n",
      "SLow rates:  tensor([[72.3386, 72.4327, 72.3791, 72.4499,  0.1000,  0.1000,  0.1000, 72.3386,\n",
      "         72.3386, 72.3386,  0.1000,  0.1000, 72.4327, 72.4327, 72.4327,  0.1000,\n",
      "          0.1000, 72.4327, 72.4327,  0.1000, 72.3791, 72.3791, 72.3791,  0.1000,\n",
      "          0.1000, 72.3791, 72.3791,  0.1000, 72.3791,  0.1000, 72.3791, 72.4499,\n",
      "         72.4499, 72.4499,  0.1000,  0.1000, 72.4499, 72.4499,  0.1000, 72.4499,\n",
      "          0.1000, 72.4499, 72.4327, 72.4499, 72.4499, 72.4499, 72.3791, 72.4499,\n",
      "         72.4499, 72.4499, 72.4327, 72.4499, 72.4499, 72.4499, 72.4327, 72.3791,\n",
      "         72.4327, 72.4327, 72.4327,  0.1000, 72.4327, 72.3791,  0.1000, 72.3791,\n",
      "         72.4499,  0.1000, 72.4499, 72.4499, 72.4499, 72.4327, 72.4327,  0.1000,\n",
      "         72.4499,  0.1000, 72.3386, 72.3386, 72.4327, 72.4499, 72.4499,  0.1000,\n",
      "          0.1000, 72.3386, 72.4327, 72.4499,  0.1000, 72.4327, 72.4499,  0.1000,\n",
      "         72.3386, 72.4499]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 595 was 98.9%\n",
      "current params: tensor([72.3386, 72.4327, 72.3791, 72.4499], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.8\n",
      "SLow rates:  tensor([[72.4387, 72.5328, 72.4792, 72.5500,  0.1000,  0.1000,  0.1000, 72.4387,\n",
      "         72.4387, 72.4387,  0.1000,  0.1000, 72.5328, 72.5328, 72.5328,  0.1000,\n",
      "          0.1000, 72.5328, 72.5328,  0.1000, 72.4792, 72.4792, 72.4792,  0.1000,\n",
      "          0.1000, 72.4792, 72.4792,  0.1000, 72.4792,  0.1000, 72.4792, 72.5500,\n",
      "         72.5500, 72.5500,  0.1000,  0.1000, 72.5500, 72.5500,  0.1000, 72.5500,\n",
      "          0.1000, 72.5500, 72.5328, 72.5500, 72.5500, 72.5500, 72.4792, 72.5500,\n",
      "         72.5500, 72.5500, 72.5328, 72.5500, 72.5500, 72.5500, 72.5328, 72.4792,\n",
      "         72.5328, 72.5328, 72.5328,  0.1000, 72.5328, 72.4792,  0.1000, 72.4792,\n",
      "         72.5500,  0.1000, 72.5500, 72.5500, 72.5500, 72.5328, 72.5328,  0.1000,\n",
      "         72.5500,  0.1000, 72.4387, 72.4387, 72.5328, 72.5500, 72.5500,  0.1000,\n",
      "          0.1000, 72.4387, 72.5328, 72.5500,  0.1000, 72.5328, 72.5500,  0.1000,\n",
      "         72.4387, 72.5500]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 596 was 98.9%\n",
      "current params: tensor([72.4387, 72.5328, 72.4792, 72.5500], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.8\n",
      "SLow rates:  tensor([[72.5388, 72.6329, 72.5794, 72.6501,  0.1000,  0.1000,  0.1000, 72.5388,\n",
      "         72.5388, 72.5388,  0.1000,  0.1000, 72.6329, 72.6329, 72.6329,  0.1000,\n",
      "          0.1000, 72.6329, 72.6329,  0.1000, 72.5794, 72.5794, 72.5794,  0.1000,\n",
      "          0.1000, 72.5794, 72.5794,  0.1000, 72.5794,  0.1000, 72.5794, 72.6501,\n",
      "         72.6501, 72.6501,  0.1000,  0.1000, 72.6501, 72.6501,  0.1000, 72.6501,\n",
      "          0.1000, 72.6501, 72.6329, 72.6501, 72.6501, 72.6501, 72.5794, 72.6501,\n",
      "         72.6501, 72.6501, 72.6329, 72.6501, 72.6501, 72.6501, 72.6329, 72.5794,\n",
      "         72.6329, 72.6329, 72.6329,  0.1000, 72.6329, 72.5794,  0.1000, 72.5794,\n",
      "         72.6501,  0.1000, 72.6501, 72.6501, 72.6501, 72.6329, 72.6329,  0.1000,\n",
      "         72.6501,  0.1000, 72.5388, 72.5388, 72.6329, 72.6501, 72.6501,  0.1000,\n",
      "          0.1000, 72.5388, 72.6329, 72.6501,  0.1000, 72.6329, 72.6501,  0.1000,\n",
      "         72.5388, 72.6501]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 597 was 98.9%\n",
      "current params: tensor([72.5388, 72.6329, 72.5794, 72.6501], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.8\n",
      "SLow rates:  tensor([[72.6389, 72.7330, 72.6795, 72.7502,  0.1000,  0.1000,  0.1000, 72.6389,\n",
      "         72.6389, 72.6389,  0.1000,  0.1000, 72.7330, 72.7330, 72.7330,  0.1000,\n",
      "          0.1000, 72.7330, 72.7330,  0.1000, 72.6795, 72.6795, 72.6795,  0.1000,\n",
      "          0.1000, 72.6795, 72.6795,  0.1000, 72.6795,  0.1000, 72.6795, 72.7502,\n",
      "         72.7502, 72.7502,  0.1000,  0.1000, 72.7502, 72.7502,  0.1000, 72.7502,\n",
      "          0.1000, 72.7502, 72.7330, 72.7502, 72.7502, 72.7502, 72.6795, 72.7502,\n",
      "         72.7502, 72.7502, 72.7330, 72.7502, 72.7502, 72.7502, 72.7330, 72.6795,\n",
      "         72.7330, 72.7330, 72.7330,  0.1000, 72.7330, 72.6795,  0.1000, 72.6795,\n",
      "         72.7502,  0.1000, 72.7502, 72.7502, 72.7502, 72.7330, 72.7330,  0.1000,\n",
      "         72.7502,  0.1000, 72.6389, 72.6389, 72.7330, 72.7502, 72.7502,  0.1000,\n",
      "          0.1000, 72.6389, 72.7330, 72.7502,  0.1000, 72.7330, 72.7502,  0.1000,\n",
      "         72.6389, 72.7502]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 598 was 98.9%\n",
      "current params: tensor([72.6389, 72.7330, 72.6795, 72.7502], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.8\n",
      "SLow rates:  tensor([[72.7390, 72.8331, 72.7796, 72.8503,  0.1000,  0.1000,  0.1000, 72.7390,\n",
      "         72.7390, 72.7390,  0.1000,  0.1000, 72.8331, 72.8331, 72.8331,  0.1000,\n",
      "          0.1000, 72.8331, 72.8331,  0.1000, 72.7796, 72.7796, 72.7796,  0.1000,\n",
      "          0.1000, 72.7796, 72.7796,  0.1000, 72.7796,  0.1000, 72.7796, 72.8503,\n",
      "         72.8503, 72.8503,  0.1000,  0.1000, 72.8503, 72.8503,  0.1000, 72.8503,\n",
      "          0.1000, 72.8503, 72.8331, 72.8503, 72.8503, 72.8503, 72.7796, 72.8503,\n",
      "         72.8503, 72.8503, 72.8331, 72.8503, 72.8503, 72.8503, 72.8331, 72.7796,\n",
      "         72.8331, 72.8331, 72.8331,  0.1000, 72.8331, 72.7796,  0.1000, 72.7796,\n",
      "         72.8503,  0.1000, 72.8503, 72.8503, 72.8503, 72.8331, 72.8331,  0.1000,\n",
      "         72.8503,  0.1000, 72.7390, 72.7390, 72.8331, 72.8503, 72.8503,  0.1000,\n",
      "          0.1000, 72.7390, 72.8331, 72.8503,  0.1000, 72.8331, 72.8503,  0.1000,\n",
      "         72.7390, 72.8503]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 599 was 98.9%\n",
      "current params: tensor([72.7390, 72.8331, 72.7796, 72.8503], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.9\n",
      "SLow rates:  tensor([[72.8391, 72.9332, 72.8797, 72.9505,  0.1000,  0.1000,  0.1000, 72.8391,\n",
      "         72.8391, 72.8391,  0.1000,  0.1000, 72.9332, 72.9332, 72.9332,  0.1000,\n",
      "          0.1000, 72.9332, 72.9332,  0.1000, 72.8797, 72.8797, 72.8797,  0.1000,\n",
      "          0.1000, 72.8797, 72.8797,  0.1000, 72.8797,  0.1000, 72.8797, 72.9505,\n",
      "         72.9505, 72.9505,  0.1000,  0.1000, 72.9505, 72.9505,  0.1000, 72.9505,\n",
      "          0.1000, 72.9505, 72.9332, 72.9505, 72.9505, 72.9505, 72.8797, 72.9505,\n",
      "         72.9505, 72.9505, 72.9332, 72.9505, 72.9505, 72.9505, 72.9332, 72.8797,\n",
      "         72.9332, 72.9332, 72.9332,  0.1000, 72.9332, 72.8797,  0.1000, 72.8797,\n",
      "         72.9505,  0.1000, 72.9505, 72.9505, 72.9505, 72.9332, 72.9332,  0.1000,\n",
      "         72.9505,  0.1000, 72.8391, 72.8391, 72.9332, 72.9505, 72.9505,  0.1000,\n",
      "          0.1000, 72.8391, 72.9332, 72.9505,  0.1000, 72.9332, 72.9505,  0.1000,\n",
      "         72.8391, 72.9505]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 600 was 98.9%\n",
      "current params: tensor([72.8391, 72.9332, 72.8797, 72.9505], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.9\n",
      "SLow rates:  tensor([[72.9392, 73.0333, 72.9798, 73.0506,  0.1000,  0.1000,  0.1000, 72.9392,\n",
      "         72.9392, 72.9392,  0.1000,  0.1000, 73.0333, 73.0333, 73.0333,  0.1000,\n",
      "          0.1000, 73.0333, 73.0333,  0.1000, 72.9798, 72.9798, 72.9798,  0.1000,\n",
      "          0.1000, 72.9798, 72.9798,  0.1000, 72.9798,  0.1000, 72.9798, 73.0506,\n",
      "         73.0506, 73.0506,  0.1000,  0.1000, 73.0506, 73.0506,  0.1000, 73.0506,\n",
      "          0.1000, 73.0506, 73.0333, 73.0506, 73.0506, 73.0506, 72.9798, 73.0506,\n",
      "         73.0506, 73.0506, 73.0333, 73.0506, 73.0506, 73.0506, 73.0333, 72.9798,\n",
      "         73.0333, 73.0333, 73.0333,  0.1000, 73.0333, 72.9798,  0.1000, 72.9798,\n",
      "         73.0506,  0.1000, 73.0506, 73.0506, 73.0506, 73.0333, 73.0333,  0.1000,\n",
      "         73.0506,  0.1000, 72.9392, 72.9392, 73.0333, 73.0506, 73.0506,  0.1000,\n",
      "          0.1000, 72.9392, 73.0333, 73.0506,  0.1000, 73.0333, 73.0506,  0.1000,\n",
      "         72.9392, 73.0506]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 601 was 98.9%\n",
      "current params: tensor([72.9392, 73.0333, 72.9798, 73.0506], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.9\n",
      "SLow rates:  tensor([[73.0394, 73.1334, 73.0799, 73.1507,  0.1000,  0.1000,  0.1000, 73.0394,\n",
      "         73.0394, 73.0394,  0.1000,  0.1000, 73.1334, 73.1334, 73.1334,  0.1000,\n",
      "          0.1000, 73.1334, 73.1334,  0.1000, 73.0799, 73.0799, 73.0799,  0.1000,\n",
      "          0.1000, 73.0799, 73.0799,  0.1000, 73.0799,  0.1000, 73.0799, 73.1507,\n",
      "         73.1507, 73.1507,  0.1000,  0.1000, 73.1507, 73.1507,  0.1000, 73.1507,\n",
      "          0.1000, 73.1507, 73.1334, 73.1507, 73.1507, 73.1507, 73.0799, 73.1507,\n",
      "         73.1507, 73.1507, 73.1334, 73.1507, 73.1507, 73.1507, 73.1334, 73.0799,\n",
      "         73.1334, 73.1334, 73.1334,  0.1000, 73.1334, 73.0799,  0.1000, 73.0799,\n",
      "         73.1507,  0.1000, 73.1507, 73.1507, 73.1507, 73.1334, 73.1334,  0.1000,\n",
      "         73.1507,  0.1000, 73.0394, 73.0394, 73.1334, 73.1507, 73.1507,  0.1000,\n",
      "          0.1000, 73.0394, 73.1334, 73.1507,  0.1000, 73.1334, 73.1507,  0.1000,\n",
      "         73.0394, 73.1507]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 602 was 98.9%\n",
      "current params: tensor([73.0394, 73.1334, 73.0799, 73.1507], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.9\n",
      "SLow rates:  tensor([[73.1395, 73.2335, 73.1800, 73.2508,  0.1000,  0.1000,  0.1000, 73.1395,\n",
      "         73.1395, 73.1395,  0.1000,  0.1000, 73.2335, 73.2335, 73.2335,  0.1000,\n",
      "          0.1000, 73.2335, 73.2335,  0.1000, 73.1800, 73.1800, 73.1800,  0.1000,\n",
      "          0.1000, 73.1800, 73.1800,  0.1000, 73.1800,  0.1000, 73.1800, 73.2508,\n",
      "         73.2508, 73.2508,  0.1000,  0.1000, 73.2508, 73.2508,  0.1000, 73.2508,\n",
      "          0.1000, 73.2508, 73.2335, 73.2508, 73.2508, 73.2508, 73.1800, 73.2508,\n",
      "         73.2508, 73.2508, 73.2335, 73.2508, 73.2508, 73.2508, 73.2335, 73.1800,\n",
      "         73.2335, 73.2335, 73.2335,  0.1000, 73.2335, 73.1800,  0.1000, 73.1800,\n",
      "         73.2508,  0.1000, 73.2508, 73.2508, 73.2508, 73.2335, 73.2335,  0.1000,\n",
      "         73.2508,  0.1000, 73.1395, 73.1395, 73.2335, 73.2508, 73.2508,  0.1000,\n",
      "          0.1000, 73.1395, 73.2335, 73.2508,  0.1000, 73.2335, 73.2508,  0.1000,\n",
      "         73.1395, 73.2508]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 603 was 98.9%\n",
      "current params: tensor([73.1395, 73.2335, 73.1800, 73.2508], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.9\n",
      "SLow rates:  tensor([[73.2396, 73.3337, 73.2801, 73.3509,  0.1000,  0.1000,  0.1000, 73.2396,\n",
      "         73.2396, 73.2396,  0.1000,  0.1000, 73.3337, 73.3337, 73.3337,  0.1000,\n",
      "          0.1000, 73.3337, 73.3337,  0.1000, 73.2801, 73.2801, 73.2801,  0.1000,\n",
      "          0.1000, 73.2801, 73.2801,  0.1000, 73.2801,  0.1000, 73.2801, 73.3509,\n",
      "         73.3509, 73.3509,  0.1000,  0.1000, 73.3509, 73.3509,  0.1000, 73.3509,\n",
      "          0.1000, 73.3509, 73.3337, 73.3509, 73.3509, 73.3509, 73.2801, 73.3509,\n",
      "         73.3509, 73.3509, 73.3337, 73.3509, 73.3509, 73.3509, 73.3337, 73.2801,\n",
      "         73.3337, 73.3337, 73.3337,  0.1000, 73.3337, 73.2801,  0.1000, 73.2801,\n",
      "         73.3509,  0.1000, 73.3509, 73.3509, 73.3509, 73.3337, 73.3337,  0.1000,\n",
      "         73.3509,  0.1000, 73.2396, 73.2396, 73.3337, 73.3509, 73.3509,  0.1000,\n",
      "          0.1000, 73.2396, 73.3337, 73.3509,  0.1000, 73.3337, 73.3509,  0.1000,\n",
      "         73.2396, 73.3509]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 604 was 98.9%\n",
      "current params: tensor([73.2396, 73.3337, 73.2801, 73.3509], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.0\n",
      "SLow rates:  tensor([[73.3397, 73.4338, 73.3802, 73.4510,  0.1000,  0.1000,  0.1000, 73.3397,\n",
      "         73.3397, 73.3397,  0.1000,  0.1000, 73.4338, 73.4338, 73.4338,  0.1000,\n",
      "          0.1000, 73.4338, 73.4338,  0.1000, 73.3802, 73.3802, 73.3802,  0.1000,\n",
      "          0.1000, 73.3802, 73.3802,  0.1000, 73.3802,  0.1000, 73.3802, 73.4510,\n",
      "         73.4510, 73.4510,  0.1000,  0.1000, 73.4510, 73.4510,  0.1000, 73.4510,\n",
      "          0.1000, 73.4510, 73.4338, 73.4510, 73.4510, 73.4510, 73.3802, 73.4510,\n",
      "         73.4510, 73.4510, 73.4338, 73.4510, 73.4510, 73.4510, 73.4338, 73.3802,\n",
      "         73.4338, 73.4338, 73.4338,  0.1000, 73.4338, 73.3802,  0.1000, 73.3802,\n",
      "         73.4510,  0.1000, 73.4510, 73.4510, 73.4510, 73.4338, 73.4338,  0.1000,\n",
      "         73.4510,  0.1000, 73.3397, 73.3397, 73.4338, 73.4510, 73.4510,  0.1000,\n",
      "          0.1000, 73.3397, 73.4338, 73.4510,  0.1000, 73.4338, 73.4510,  0.1000,\n",
      "         73.3397, 73.4510]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 605 was 98.9%\n",
      "current params: tensor([73.3397, 73.4338, 73.3802, 73.4510], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.0\n",
      "SLow rates:  tensor([[73.4398, 73.5339, 73.4803, 73.5511,  0.1000,  0.1000,  0.1000, 73.4398,\n",
      "         73.4398, 73.4398,  0.1000,  0.1000, 73.5339, 73.5339, 73.5339,  0.1000,\n",
      "          0.1000, 73.5339, 73.5339,  0.1000, 73.4803, 73.4803, 73.4803,  0.1000,\n",
      "          0.1000, 73.4803, 73.4803,  0.1000, 73.4803,  0.1000, 73.4803, 73.5511,\n",
      "         73.5511, 73.5511,  0.1000,  0.1000, 73.5511, 73.5511,  0.1000, 73.5511,\n",
      "          0.1000, 73.5511, 73.5339, 73.5511, 73.5511, 73.5511, 73.4803, 73.5511,\n",
      "         73.5511, 73.5511, 73.5339, 73.5511, 73.5511, 73.5511, 73.5339, 73.4803,\n",
      "         73.5339, 73.5339, 73.5339,  0.1000, 73.5339, 73.4803,  0.1000, 73.4803,\n",
      "         73.5511,  0.1000, 73.5511, 73.5511, 73.5511, 73.5339, 73.5339,  0.1000,\n",
      "         73.5511,  0.1000, 73.4398, 73.4398, 73.5339, 73.5511, 73.5511,  0.1000,\n",
      "          0.1000, 73.4398, 73.5339, 73.5511,  0.1000, 73.5339, 73.5511,  0.1000,\n",
      "         73.4398, 73.5511]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 606 was 98.9%\n",
      "current params: tensor([73.4398, 73.5339, 73.4803, 73.5511], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.0\n",
      "SLow rates:  tensor([[73.5399, 73.6340, 73.5804, 73.6512,  0.1000,  0.1000,  0.1000, 73.5399,\n",
      "         73.5399, 73.5399,  0.1000,  0.1000, 73.6340, 73.6340, 73.6340,  0.1000,\n",
      "          0.1000, 73.6340, 73.6340,  0.1000, 73.5804, 73.5804, 73.5804,  0.1000,\n",
      "          0.1000, 73.5804, 73.5804,  0.1000, 73.5804,  0.1000, 73.5804, 73.6512,\n",
      "         73.6512, 73.6512,  0.1000,  0.1000, 73.6512, 73.6512,  0.1000, 73.6512,\n",
      "          0.1000, 73.6512, 73.6340, 73.6512, 73.6512, 73.6512, 73.5804, 73.6512,\n",
      "         73.6512, 73.6512, 73.6340, 73.6512, 73.6512, 73.6512, 73.6340, 73.5804,\n",
      "         73.6340, 73.6340, 73.6340,  0.1000, 73.6340, 73.5804,  0.1000, 73.5804,\n",
      "         73.6512,  0.1000, 73.6512, 73.6512, 73.6512, 73.6340, 73.6340,  0.1000,\n",
      "         73.6512,  0.1000, 73.5399, 73.5399, 73.6340, 73.6512, 73.6512,  0.1000,\n",
      "          0.1000, 73.5399, 73.6340, 73.6512,  0.1000, 73.6340, 73.6512,  0.1000,\n",
      "         73.5399, 73.6512]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 607 was 98.9%\n",
      "current params: tensor([73.5399, 73.6340, 73.5804, 73.6512], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.0\n",
      "SLow rates:  tensor([[73.6400, 73.7341, 73.6805, 73.7513,  0.1000,  0.1000,  0.1000, 73.6400,\n",
      "         73.6400, 73.6400,  0.1000,  0.1000, 73.7341, 73.7341, 73.7341,  0.1000,\n",
      "          0.1000, 73.7341, 73.7341,  0.1000, 73.6805, 73.6805, 73.6805,  0.1000,\n",
      "          0.1000, 73.6805, 73.6805,  0.1000, 73.6805,  0.1000, 73.6805, 73.7513,\n",
      "         73.7513, 73.7513,  0.1000,  0.1000, 73.7513, 73.7513,  0.1000, 73.7513,\n",
      "          0.1000, 73.7513, 73.7341, 73.7513, 73.7513, 73.7513, 73.6805, 73.7513,\n",
      "         73.7513, 73.7513, 73.7341, 73.7513, 73.7513, 73.7513, 73.7341, 73.6805,\n",
      "         73.7341, 73.7341, 73.7341,  0.1000, 73.7341, 73.6805,  0.1000, 73.6805,\n",
      "         73.7513,  0.1000, 73.7513, 73.7513, 73.7513, 73.7341, 73.7341,  0.1000,\n",
      "         73.7513,  0.1000, 73.6400, 73.6400, 73.7341, 73.7513, 73.7513,  0.1000,\n",
      "          0.1000, 73.6400, 73.7341, 73.7513,  0.1000, 73.7341, 73.7513,  0.1000,\n",
      "         73.6400, 73.7513]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 608 was 98.9%\n",
      "current params: tensor([73.6400, 73.7341, 73.6805, 73.7513], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.0\n",
      "SLow rates:  tensor([[73.7401, 73.8342, 73.7806, 73.8514,  0.1000,  0.1000,  0.1000, 73.7401,\n",
      "         73.7401, 73.7401,  0.1000,  0.1000, 73.8342, 73.8342, 73.8342,  0.1000,\n",
      "          0.1000, 73.8342, 73.8342,  0.1000, 73.7806, 73.7806, 73.7806,  0.1000,\n",
      "          0.1000, 73.7806, 73.7806,  0.1000, 73.7806,  0.1000, 73.7806, 73.8514,\n",
      "         73.8514, 73.8514,  0.1000,  0.1000, 73.8514, 73.8514,  0.1000, 73.8514,\n",
      "          0.1000, 73.8514, 73.8342, 73.8514, 73.8514, 73.8514, 73.7806, 73.8514,\n",
      "         73.8514, 73.8514, 73.8342, 73.8514, 73.8514, 73.8514, 73.8342, 73.7806,\n",
      "         73.8342, 73.8342, 73.8342,  0.1000, 73.8342, 73.7806,  0.1000, 73.7806,\n",
      "         73.8514,  0.1000, 73.8514, 73.8514, 73.8514, 73.8342, 73.8342,  0.1000,\n",
      "         73.8514,  0.1000, 73.7401, 73.7401, 73.8342, 73.8514, 73.8514,  0.1000,\n",
      "          0.1000, 73.7401, 73.8342, 73.8514,  0.1000, 73.8342, 73.8514,  0.1000,\n",
      "         73.7401, 73.8514]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 609 was 98.9%\n",
      "current params: tensor([73.7401, 73.8342, 73.7806, 73.8514], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "SLow rates:  tensor([[73.8402, 73.9343, 73.8807, 73.9515,  0.1000,  0.1000,  0.1000, 73.8402,\n",
      "         73.8402, 73.8402,  0.1000,  0.1000, 73.9343, 73.9343, 73.9343,  0.1000,\n",
      "          0.1000, 73.9343, 73.9343,  0.1000, 73.8807, 73.8807, 73.8807,  0.1000,\n",
      "          0.1000, 73.8807, 73.8807,  0.1000, 73.8807,  0.1000, 73.8807, 73.9515,\n",
      "         73.9515, 73.9515,  0.1000,  0.1000, 73.9515, 73.9515,  0.1000, 73.9515,\n",
      "          0.1000, 73.9515, 73.9343, 73.9515, 73.9515, 73.9515, 73.8807, 73.9515,\n",
      "         73.9515, 73.9515, 73.9343, 73.9515, 73.9515, 73.9515, 73.9343, 73.8807,\n",
      "         73.9343, 73.9343, 73.9343,  0.1000, 73.9343, 73.8807,  0.1000, 73.8807,\n",
      "         73.9515,  0.1000, 73.9515, 73.9515, 73.9515, 73.9343, 73.9343,  0.1000,\n",
      "         73.9515,  0.1000, 73.8402, 73.8402, 73.9343, 73.9515, 73.9515,  0.1000,\n",
      "          0.1000, 73.8402, 73.9343, 73.9515,  0.1000, 73.9343, 73.9515,  0.1000,\n",
      "         73.8402, 73.9515]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 610 was 98.9%\n",
      "current params: tensor([73.8402, 73.9343, 73.8807, 73.9515], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "SLow rates:  tensor([[73.9403, 74.0344, 73.9808, 74.0515,  0.1000,  0.1000,  0.1000, 73.9403,\n",
      "         73.9403, 73.9403,  0.1000,  0.1000, 74.0344, 74.0344, 74.0344,  0.1000,\n",
      "          0.1000, 74.0344, 74.0344,  0.1000, 73.9808, 73.9808, 73.9808,  0.1000,\n",
      "          0.1000, 73.9808, 73.9808,  0.1000, 73.9808,  0.1000, 73.9808, 74.0515,\n",
      "         74.0515, 74.0515,  0.1000,  0.1000, 74.0515, 74.0515,  0.1000, 74.0515,\n",
      "          0.1000, 74.0515, 74.0344, 74.0515, 74.0515, 74.0515, 73.9808, 74.0515,\n",
      "         74.0515, 74.0515, 74.0344, 74.0515, 74.0515, 74.0515, 74.0344, 73.9808,\n",
      "         74.0344, 74.0344, 74.0344,  0.1000, 74.0344, 73.9808,  0.1000, 73.9808,\n",
      "         74.0515,  0.1000, 74.0515, 74.0515, 74.0515, 74.0344, 74.0344,  0.1000,\n",
      "         74.0515,  0.1000, 73.9403, 73.9403, 74.0344, 74.0515, 74.0515,  0.1000,\n",
      "          0.1000, 73.9403, 74.0344, 74.0515,  0.1000, 74.0344, 74.0515,  0.1000,\n",
      "         73.9403, 74.0515]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 611 was 98.9%\n",
      "current params: tensor([73.9403, 74.0344, 73.9808, 74.0515], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "SLow rates:  tensor([[74.0404, 74.1344, 74.0809, 74.1516,  0.1000,  0.1000,  0.1000, 74.0404,\n",
      "         74.0404, 74.0404,  0.1000,  0.1000, 74.1344, 74.1344, 74.1344,  0.1000,\n",
      "          0.1000, 74.1344, 74.1344,  0.1000, 74.0809, 74.0809, 74.0809,  0.1000,\n",
      "          0.1000, 74.0809, 74.0809,  0.1000, 74.0809,  0.1000, 74.0809, 74.1516,\n",
      "         74.1516, 74.1516,  0.1000,  0.1000, 74.1516, 74.1516,  0.1000, 74.1516,\n",
      "          0.1000, 74.1516, 74.1344, 74.1516, 74.1516, 74.1516, 74.0809, 74.1516,\n",
      "         74.1516, 74.1516, 74.1344, 74.1516, 74.1516, 74.1516, 74.1344, 74.0809,\n",
      "         74.1344, 74.1344, 74.1344,  0.1000, 74.1344, 74.0809,  0.1000, 74.0809,\n",
      "         74.1516,  0.1000, 74.1516, 74.1516, 74.1516, 74.1344, 74.1344,  0.1000,\n",
      "         74.1516,  0.1000, 74.0404, 74.0404, 74.1344, 74.1516, 74.1516,  0.1000,\n",
      "          0.1000, 74.0404, 74.1344, 74.1516,  0.1000, 74.1344, 74.1516,  0.1000,\n",
      "         74.0404, 74.1516]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 612 was 98.9%\n",
      "current params: tensor([74.0404, 74.1344, 74.0809, 74.1516], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "SLow rates:  tensor([[74.1405, 74.2345, 74.1810, 74.2517,  0.1000,  0.1000,  0.1000, 74.1405,\n",
      "         74.1405, 74.1405,  0.1000,  0.1000, 74.2345, 74.2345, 74.2345,  0.1000,\n",
      "          0.1000, 74.2345, 74.2345,  0.1000, 74.1810, 74.1810, 74.1810,  0.1000,\n",
      "          0.1000, 74.1810, 74.1810,  0.1000, 74.1810,  0.1000, 74.1810, 74.2517,\n",
      "         74.2517, 74.2517,  0.1000,  0.1000, 74.2517, 74.2517,  0.1000, 74.2517,\n",
      "          0.1000, 74.2517, 74.2345, 74.2517, 74.2517, 74.2517, 74.1810, 74.2517,\n",
      "         74.2517, 74.2517, 74.2345, 74.2517, 74.2517, 74.2517, 74.2345, 74.1810,\n",
      "         74.2345, 74.2345, 74.2345,  0.1000, 74.2345, 74.1810,  0.1000, 74.1810,\n",
      "         74.2517,  0.1000, 74.2517, 74.2517, 74.2517, 74.2345, 74.2345,  0.1000,\n",
      "         74.2517,  0.1000, 74.1405, 74.1405, 74.2345, 74.2517, 74.2517,  0.1000,\n",
      "          0.1000, 74.1405, 74.2345, 74.2517,  0.1000, 74.2345, 74.2517,  0.1000,\n",
      "         74.1405, 74.2517]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 613 was 98.9%\n",
      "current params: tensor([74.1405, 74.2345, 74.1810, 74.2517], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "SLow rates:  tensor([[74.2406, 74.3346, 74.2811, 74.3518,  0.1000,  0.1000,  0.1000, 74.2406,\n",
      "         74.2406, 74.2406,  0.1000,  0.1000, 74.3346, 74.3346, 74.3346,  0.1000,\n",
      "          0.1000, 74.3346, 74.3346,  0.1000, 74.2811, 74.2811, 74.2811,  0.1000,\n",
      "          0.1000, 74.2811, 74.2811,  0.1000, 74.2811,  0.1000, 74.2811, 74.3518,\n",
      "         74.3518, 74.3518,  0.1000,  0.1000, 74.3518, 74.3518,  0.1000, 74.3518,\n",
      "          0.1000, 74.3518, 74.3346, 74.3518, 74.3518, 74.3518, 74.2811, 74.3518,\n",
      "         74.3518, 74.3518, 74.3346, 74.3518, 74.3518, 74.3518, 74.3346, 74.2811,\n",
      "         74.3346, 74.3346, 74.3346,  0.1000, 74.3346, 74.2811,  0.1000, 74.2811,\n",
      "         74.3518,  0.1000, 74.3518, 74.3518, 74.3518, 74.3346, 74.3346,  0.1000,\n",
      "         74.3518,  0.1000, 74.2406, 74.2406, 74.3346, 74.3518, 74.3518,  0.1000,\n",
      "          0.1000, 74.2406, 74.3346, 74.3518,  0.1000, 74.3346, 74.3518,  0.1000,\n",
      "         74.2406, 74.3518]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 614 was 98.9%\n",
      "current params: tensor([74.2406, 74.3346, 74.2811, 74.3518], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "SLow rates:  tensor([[74.3407, 74.4347, 74.3812, 74.4519,  0.1000,  0.1000,  0.1000, 74.3407,\n",
      "         74.3407, 74.3407,  0.1000,  0.1000, 74.4347, 74.4347, 74.4347,  0.1000,\n",
      "          0.1000, 74.4347, 74.4347,  0.1000, 74.3812, 74.3812, 74.3812,  0.1000,\n",
      "          0.1000, 74.3812, 74.3812,  0.1000, 74.3812,  0.1000, 74.3812, 74.4519,\n",
      "         74.4519, 74.4519,  0.1000,  0.1000, 74.4519, 74.4519,  0.1000, 74.4519,\n",
      "          0.1000, 74.4519, 74.4347, 74.4519, 74.4519, 74.4519, 74.3812, 74.4519,\n",
      "         74.4519, 74.4519, 74.4347, 74.4519, 74.4519, 74.4519, 74.4347, 74.3812,\n",
      "         74.4347, 74.4347, 74.4347,  0.1000, 74.4347, 74.3812,  0.1000, 74.3812,\n",
      "         74.4519,  0.1000, 74.4519, 74.4519, 74.4519, 74.4347, 74.4347,  0.1000,\n",
      "         74.4519,  0.1000, 74.3407, 74.3407, 74.4347, 74.4519, 74.4519,  0.1000,\n",
      "          0.1000, 74.3407, 74.4347, 74.4519,  0.1000, 74.4347, 74.4519,  0.1000,\n",
      "         74.3407, 74.4519]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 615 was 98.9%\n",
      "current params: tensor([74.3407, 74.4347, 74.3812, 74.4519], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.2\n",
      "SLow rates:  tensor([[74.4408, 74.5348, 74.4813, 74.5520,  0.1000,  0.1000,  0.1000, 74.4408,\n",
      "         74.4408, 74.4408,  0.1000,  0.1000, 74.5348, 74.5348, 74.5348,  0.1000,\n",
      "          0.1000, 74.5348, 74.5348,  0.1000, 74.4813, 74.4813, 74.4813,  0.1000,\n",
      "          0.1000, 74.4813, 74.4813,  0.1000, 74.4813,  0.1000, 74.4813, 74.5520,\n",
      "         74.5520, 74.5520,  0.1000,  0.1000, 74.5520, 74.5520,  0.1000, 74.5520,\n",
      "          0.1000, 74.5520, 74.5348, 74.5520, 74.5520, 74.5520, 74.4813, 74.5520,\n",
      "         74.5520, 74.5520, 74.5348, 74.5520, 74.5520, 74.5520, 74.5348, 74.4813,\n",
      "         74.5348, 74.5348, 74.5348,  0.1000, 74.5348, 74.4813,  0.1000, 74.4813,\n",
      "         74.5520,  0.1000, 74.5520, 74.5520, 74.5520, 74.5348, 74.5348,  0.1000,\n",
      "         74.5520,  0.1000, 74.4408, 74.4408, 74.5348, 74.5520, 74.5520,  0.1000,\n",
      "          0.1000, 74.4408, 74.5348, 74.5520,  0.1000, 74.5348, 74.5520,  0.1000,\n",
      "         74.4408, 74.5520]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 616 was 98.9%\n",
      "current params: tensor([74.4408, 74.5348, 74.4813, 74.5520], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.2\n",
      "SLow rates:  tensor([[74.5409, 74.6349, 74.5814, 74.6521,  0.1000,  0.1000,  0.1000, 74.5409,\n",
      "         74.5409, 74.5409,  0.1000,  0.1000, 74.6349, 74.6349, 74.6349,  0.1000,\n",
      "          0.1000, 74.6349, 74.6349,  0.1000, 74.5814, 74.5814, 74.5814,  0.1000,\n",
      "          0.1000, 74.5814, 74.5814,  0.1000, 74.5814,  0.1000, 74.5814, 74.6521,\n",
      "         74.6521, 74.6521,  0.1000,  0.1000, 74.6521, 74.6521,  0.1000, 74.6521,\n",
      "          0.1000, 74.6521, 74.6349, 74.6521, 74.6521, 74.6521, 74.5814, 74.6521,\n",
      "         74.6521, 74.6521, 74.6349, 74.6521, 74.6521, 74.6521, 74.6349, 74.5814,\n",
      "         74.6349, 74.6349, 74.6349,  0.1000, 74.6349, 74.5814,  0.1000, 74.5814,\n",
      "         74.6521,  0.1000, 74.6521, 74.6521, 74.6521, 74.6349, 74.6349,  0.1000,\n",
      "         74.6521,  0.1000, 74.5409, 74.5409, 74.6349, 74.6521, 74.6521,  0.1000,\n",
      "          0.1000, 74.5409, 74.6349, 74.6521,  0.1000, 74.6349, 74.6521,  0.1000,\n",
      "         74.5409, 74.6521]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 617 was 98.9%\n",
      "current params: tensor([74.5409, 74.6349, 74.5814, 74.6521], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.2\n",
      "SLow rates:  tensor([[74.6410, 74.7350, 74.6815, 74.7522,  0.1000,  0.1000,  0.1000, 74.6410,\n",
      "         74.6410, 74.6410,  0.1000,  0.1000, 74.7350, 74.7350, 74.7350,  0.1000,\n",
      "          0.1000, 74.7350, 74.7350,  0.1000, 74.6815, 74.6815, 74.6815,  0.1000,\n",
      "          0.1000, 74.6815, 74.6815,  0.1000, 74.6815,  0.1000, 74.6815, 74.7522,\n",
      "         74.7522, 74.7522,  0.1000,  0.1000, 74.7522, 74.7522,  0.1000, 74.7522,\n",
      "          0.1000, 74.7522, 74.7350, 74.7522, 74.7522, 74.7522, 74.6815, 74.7522,\n",
      "         74.7522, 74.7522, 74.7350, 74.7522, 74.7522, 74.7522, 74.7350, 74.6815,\n",
      "         74.7350, 74.7350, 74.7350,  0.1000, 74.7350, 74.6815,  0.1000, 74.6815,\n",
      "         74.7522,  0.1000, 74.7522, 74.7522, 74.7522, 74.7350, 74.7350,  0.1000,\n",
      "         74.7522,  0.1000, 74.6410, 74.6410, 74.7350, 74.7522, 74.7522,  0.1000,\n",
      "          0.1000, 74.6410, 74.7350, 74.7522,  0.1000, 74.7350, 74.7522,  0.1000,\n",
      "         74.6410, 74.7522]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 618 was 98.9%\n",
      "current params: tensor([74.6410, 74.7350, 74.6815, 74.7522], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.2\n",
      "SLow rates:  tensor([[74.7411, 74.8351, 74.7816, 74.8523,  0.1000,  0.1000,  0.1000, 74.7411,\n",
      "         74.7411, 74.7411,  0.1000,  0.1000, 74.8351, 74.8351, 74.8351,  0.1000,\n",
      "          0.1000, 74.8351, 74.8351,  0.1000, 74.7816, 74.7816, 74.7816,  0.1000,\n",
      "          0.1000, 74.7816, 74.7816,  0.1000, 74.7816,  0.1000, 74.7816, 74.8523,\n",
      "         74.8523, 74.8523,  0.1000,  0.1000, 74.8523, 74.8523,  0.1000, 74.8523,\n",
      "          0.1000, 74.8523, 74.8351, 74.8523, 74.8523, 74.8523, 74.7816, 74.8523,\n",
      "         74.8523, 74.8523, 74.8351, 74.8523, 74.8523, 74.8523, 74.8351, 74.7816,\n",
      "         74.8351, 74.8351, 74.8351,  0.1000, 74.8351, 74.7816,  0.1000, 74.7816,\n",
      "         74.8523,  0.1000, 74.8523, 74.8523, 74.8523, 74.8351, 74.8351,  0.1000,\n",
      "         74.8523,  0.1000, 74.7411, 74.7411, 74.8351, 74.8523, 74.8523,  0.1000,\n",
      "          0.1000, 74.7411, 74.8351, 74.8523,  0.1000, 74.8351, 74.8523,  0.1000,\n",
      "         74.7411, 74.8523]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 619 was 98.9%\n",
      "current params: tensor([74.7411, 74.8351, 74.7816, 74.8523], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.2\n",
      "SLow rates:  tensor([[74.8412, 74.9352, 74.8817, 74.9523,  0.1000,  0.1000,  0.1000, 74.8412,\n",
      "         74.8412, 74.8412,  0.1000,  0.1000, 74.9352, 74.9352, 74.9352,  0.1000,\n",
      "          0.1000, 74.9352, 74.9352,  0.1000, 74.8817, 74.8817, 74.8817,  0.1000,\n",
      "          0.1000, 74.8817, 74.8817,  0.1000, 74.8817,  0.1000, 74.8817, 74.9523,\n",
      "         74.9523, 74.9523,  0.1000,  0.1000, 74.9523, 74.9523,  0.1000, 74.9523,\n",
      "          0.1000, 74.9523, 74.9352, 74.9523, 74.9523, 74.9523, 74.8817, 74.9523,\n",
      "         74.9523, 74.9523, 74.9352, 74.9523, 74.9523, 74.9523, 74.9352, 74.8817,\n",
      "         74.9352, 74.9352, 74.9352,  0.1000, 74.9352, 74.8817,  0.1000, 74.8817,\n",
      "         74.9523,  0.1000, 74.9523, 74.9523, 74.9523, 74.9352, 74.9352,  0.1000,\n",
      "         74.9523,  0.1000, 74.8412, 74.8412, 74.9352, 74.9523, 74.9523,  0.1000,\n",
      "          0.1000, 74.8412, 74.9352, 74.9523,  0.1000, 74.9352, 74.9523,  0.1000,\n",
      "         74.8412, 74.9523]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 620 was 98.9%\n",
      "current params: tensor([74.8412, 74.9352, 74.8817, 74.9523], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.3\n",
      "SLow rates:  tensor([[74.9413, 75.0353, 74.9818, 75.0524,  0.1000,  0.1000,  0.1000, 74.9413,\n",
      "         74.9413, 74.9413,  0.1000,  0.1000, 75.0353, 75.0353, 75.0353,  0.1000,\n",
      "          0.1000, 75.0353, 75.0353,  0.1000, 74.9818, 74.9818, 74.9818,  0.1000,\n",
      "          0.1000, 74.9818, 74.9818,  0.1000, 74.9818,  0.1000, 74.9818, 75.0524,\n",
      "         75.0524, 75.0524,  0.1000,  0.1000, 75.0524, 75.0524,  0.1000, 75.0524,\n",
      "          0.1000, 75.0524, 75.0353, 75.0524, 75.0524, 75.0524, 74.9818, 75.0524,\n",
      "         75.0524, 75.0524, 75.0353, 75.0524, 75.0524, 75.0524, 75.0353, 74.9818,\n",
      "         75.0353, 75.0353, 75.0353,  0.1000, 75.0353, 74.9818,  0.1000, 74.9818,\n",
      "         75.0524,  0.1000, 75.0524, 75.0524, 75.0524, 75.0353, 75.0353,  0.1000,\n",
      "         75.0524,  0.1000, 74.9413, 74.9413, 75.0353, 75.0524, 75.0524,  0.1000,\n",
      "          0.1000, 74.9413, 75.0353, 75.0524,  0.1000, 75.0353, 75.0524,  0.1000,\n",
      "         74.9413, 75.0524]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 621 was 99.0%\n",
      "current params: tensor([74.9413, 75.0353, 74.9818, 75.0524], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.3\n",
      "SLow rates:  tensor([[75.0414, 75.1354, 75.0819, 75.1525,  0.1000,  0.1000,  0.1000, 75.0414,\n",
      "         75.0414, 75.0414,  0.1000,  0.1000, 75.1354, 75.1354, 75.1354,  0.1000,\n",
      "          0.1000, 75.1354, 75.1354,  0.1000, 75.0819, 75.0819, 75.0819,  0.1000,\n",
      "          0.1000, 75.0819, 75.0819,  0.1000, 75.0819,  0.1000, 75.0819, 75.1525,\n",
      "         75.1525, 75.1525,  0.1000,  0.1000, 75.1525, 75.1525,  0.1000, 75.1525,\n",
      "          0.1000, 75.1525, 75.1354, 75.1525, 75.1525, 75.1525, 75.0819, 75.1525,\n",
      "         75.1525, 75.1525, 75.1354, 75.1525, 75.1525, 75.1525, 75.1354, 75.0819,\n",
      "         75.1354, 75.1354, 75.1354,  0.1000, 75.1354, 75.0819,  0.1000, 75.0819,\n",
      "         75.1525,  0.1000, 75.1525, 75.1525, 75.1525, 75.1354, 75.1354,  0.1000,\n",
      "         75.1525,  0.1000, 75.0414, 75.0414, 75.1354, 75.1525, 75.1525,  0.1000,\n",
      "          0.1000, 75.0414, 75.1354, 75.1525,  0.1000, 75.1354, 75.1525,  0.1000,\n",
      "         75.0414, 75.1525]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 622 was 99.0%\n",
      "current params: tensor([75.0414, 75.1354, 75.0819, 75.1525], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.3\n",
      "SLow rates:  tensor([[75.1415, 75.2354, 75.1820, 75.2526,  0.1000,  0.1000,  0.1000, 75.1415,\n",
      "         75.1415, 75.1415,  0.1000,  0.1000, 75.2354, 75.2354, 75.2354,  0.1000,\n",
      "          0.1000, 75.2354, 75.2354,  0.1000, 75.1820, 75.1820, 75.1820,  0.1000,\n",
      "          0.1000, 75.1820, 75.1820,  0.1000, 75.1820,  0.1000, 75.1820, 75.2526,\n",
      "         75.2526, 75.2526,  0.1000,  0.1000, 75.2526, 75.2526,  0.1000, 75.2526,\n",
      "          0.1000, 75.2526, 75.2354, 75.2526, 75.2526, 75.2526, 75.1820, 75.2526,\n",
      "         75.2526, 75.2526, 75.2354, 75.2526, 75.2526, 75.2526, 75.2354, 75.1820,\n",
      "         75.2354, 75.2354, 75.2354,  0.1000, 75.2354, 75.1820,  0.1000, 75.1820,\n",
      "         75.2526,  0.1000, 75.2526, 75.2526, 75.2526, 75.2354, 75.2354,  0.1000,\n",
      "         75.2526,  0.1000, 75.1415, 75.1415, 75.2354, 75.2526, 75.2526,  0.1000,\n",
      "          0.1000, 75.1415, 75.2354, 75.2526,  0.1000, 75.2354, 75.2526,  0.1000,\n",
      "         75.1415, 75.2526]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 623 was 99.0%\n",
      "current params: tensor([75.1415, 75.2354, 75.1820, 75.2526], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.3\n",
      "SLow rates:  tensor([[75.2415, 75.3355, 75.2820, 75.3527,  0.1000,  0.1000,  0.1000, 75.2415,\n",
      "         75.2415, 75.2415,  0.1000,  0.1000, 75.3355, 75.3355, 75.3355,  0.1000,\n",
      "          0.1000, 75.3355, 75.3355,  0.1000, 75.2820, 75.2820, 75.2820,  0.1000,\n",
      "          0.1000, 75.2820, 75.2820,  0.1000, 75.2820,  0.1000, 75.2820, 75.3527,\n",
      "         75.3527, 75.3527,  0.1000,  0.1000, 75.3527, 75.3527,  0.1000, 75.3527,\n",
      "          0.1000, 75.3527, 75.3355, 75.3527, 75.3527, 75.3527, 75.2820, 75.3527,\n",
      "         75.3527, 75.3527, 75.3355, 75.3527, 75.3527, 75.3527, 75.3355, 75.2820,\n",
      "         75.3355, 75.3355, 75.3355,  0.1000, 75.3355, 75.2820,  0.1000, 75.2820,\n",
      "         75.3527,  0.1000, 75.3527, 75.3527, 75.3527, 75.3355, 75.3355,  0.1000,\n",
      "         75.3527,  0.1000, 75.2415, 75.2415, 75.3355, 75.3527, 75.3527,  0.1000,\n",
      "          0.1000, 75.2415, 75.3355, 75.3527,  0.1000, 75.3355, 75.3527,  0.1000,\n",
      "         75.2415, 75.3527]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 624 was 99.0%\n",
      "current params: tensor([75.2415, 75.3355, 75.2820, 75.3527], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.3\n",
      "SLow rates:  tensor([[75.3416, 75.4356, 75.3821, 75.4528,  0.1000,  0.1000,  0.1000, 75.3416,\n",
      "         75.3416, 75.3416,  0.1000,  0.1000, 75.4356, 75.4356, 75.4356,  0.1000,\n",
      "          0.1000, 75.4356, 75.4356,  0.1000, 75.3821, 75.3821, 75.3821,  0.1000,\n",
      "          0.1000, 75.3821, 75.3821,  0.1000, 75.3821,  0.1000, 75.3821, 75.4528,\n",
      "         75.4528, 75.4528,  0.1000,  0.1000, 75.4528, 75.4528,  0.1000, 75.4528,\n",
      "          0.1000, 75.4528, 75.4356, 75.4528, 75.4528, 75.4528, 75.3821, 75.4528,\n",
      "         75.4528, 75.4528, 75.4356, 75.4528, 75.4528, 75.4528, 75.4356, 75.3821,\n",
      "         75.4356, 75.4356, 75.4356,  0.1000, 75.4356, 75.3821,  0.1000, 75.3821,\n",
      "         75.4528,  0.1000, 75.4528, 75.4528, 75.4528, 75.4356, 75.4356,  0.1000,\n",
      "         75.4528,  0.1000, 75.3416, 75.3416, 75.4356, 75.4528, 75.4528,  0.1000,\n",
      "          0.1000, 75.3416, 75.4356, 75.4528,  0.1000, 75.4356, 75.4528,  0.1000,\n",
      "         75.3416, 75.4528]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 625 was 99.0%\n",
      "current params: tensor([75.3416, 75.4356, 75.3821, 75.4528], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "SLow rates:  tensor([[75.4417, 75.5357, 75.4822, 75.5528,  0.1000,  0.1000,  0.1000, 75.4417,\n",
      "         75.4417, 75.4417,  0.1000,  0.1000, 75.5357, 75.5357, 75.5357,  0.1000,\n",
      "          0.1000, 75.5357, 75.5357,  0.1000, 75.4822, 75.4822, 75.4822,  0.1000,\n",
      "          0.1000, 75.4822, 75.4822,  0.1000, 75.4822,  0.1000, 75.4822, 75.5528,\n",
      "         75.5528, 75.5528,  0.1000,  0.1000, 75.5528, 75.5528,  0.1000, 75.5528,\n",
      "          0.1000, 75.5528, 75.5357, 75.5528, 75.5528, 75.5528, 75.4822, 75.5528,\n",
      "         75.5528, 75.5528, 75.5357, 75.5528, 75.5528, 75.5528, 75.5357, 75.4822,\n",
      "         75.5357, 75.5357, 75.5357,  0.1000, 75.5357, 75.4822,  0.1000, 75.4822,\n",
      "         75.5528,  0.1000, 75.5528, 75.5528, 75.5528, 75.5357, 75.5357,  0.1000,\n",
      "         75.5528,  0.1000, 75.4417, 75.4417, 75.5357, 75.5528, 75.5528,  0.1000,\n",
      "          0.1000, 75.4417, 75.5357, 75.5528,  0.1000, 75.5357, 75.5528,  0.1000,\n",
      "         75.4417, 75.5528]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 626 was 99.0%\n",
      "current params: tensor([75.4417, 75.5357, 75.4822, 75.5528], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "SLow rates:  tensor([[75.5418, 75.6358, 75.5823, 75.6529,  0.1000,  0.1000,  0.1000, 75.5418,\n",
      "         75.5418, 75.5418,  0.1000,  0.1000, 75.6358, 75.6358, 75.6358,  0.1000,\n",
      "          0.1000, 75.6358, 75.6358,  0.1000, 75.5823, 75.5823, 75.5823,  0.1000,\n",
      "          0.1000, 75.5823, 75.5823,  0.1000, 75.5823,  0.1000, 75.5823, 75.6529,\n",
      "         75.6529, 75.6529,  0.1000,  0.1000, 75.6529, 75.6529,  0.1000, 75.6529,\n",
      "          0.1000, 75.6529, 75.6358, 75.6529, 75.6529, 75.6529, 75.5823, 75.6529,\n",
      "         75.6529, 75.6529, 75.6358, 75.6529, 75.6529, 75.6529, 75.6358, 75.5823,\n",
      "         75.6358, 75.6358, 75.6358,  0.1000, 75.6358, 75.5823,  0.1000, 75.5823,\n",
      "         75.6529,  0.1000, 75.6529, 75.6529, 75.6529, 75.6358, 75.6358,  0.1000,\n",
      "         75.6529,  0.1000, 75.5418, 75.5418, 75.6358, 75.6529, 75.6529,  0.1000,\n",
      "          0.1000, 75.5418, 75.6358, 75.6529,  0.1000, 75.6358, 75.6529,  0.1000,\n",
      "         75.5418, 75.6529]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 627 was 99.0%\n",
      "current params: tensor([75.5418, 75.6358, 75.5823, 75.6529], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "SLow rates:  tensor([[75.6419, 75.7358, 75.6824, 75.7530,  0.1000,  0.1000,  0.1000, 75.6419,\n",
      "         75.6419, 75.6419,  0.1000,  0.1000, 75.7358, 75.7358, 75.7358,  0.1000,\n",
      "          0.1000, 75.7358, 75.7358,  0.1000, 75.6824, 75.6824, 75.6824,  0.1000,\n",
      "          0.1000, 75.6824, 75.6824,  0.1000, 75.6824,  0.1000, 75.6824, 75.7530,\n",
      "         75.7530, 75.7530,  0.1000,  0.1000, 75.7530, 75.7530,  0.1000, 75.7530,\n",
      "          0.1000, 75.7530, 75.7358, 75.7530, 75.7530, 75.7530, 75.6824, 75.7530,\n",
      "         75.7530, 75.7530, 75.7358, 75.7530, 75.7530, 75.7530, 75.7358, 75.6824,\n",
      "         75.7358, 75.7358, 75.7358,  0.1000, 75.7358, 75.6824,  0.1000, 75.6824,\n",
      "         75.7530,  0.1000, 75.7530, 75.7530, 75.7530, 75.7358, 75.7358,  0.1000,\n",
      "         75.7530,  0.1000, 75.6419, 75.6419, 75.7358, 75.7530, 75.7530,  0.1000,\n",
      "          0.1000, 75.6419, 75.7358, 75.7530,  0.1000, 75.7358, 75.7530,  0.1000,\n",
      "         75.6419, 75.7530]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 628 was 99.0%\n",
      "current params: tensor([75.6419, 75.7358, 75.6824, 75.7530], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "SLow rates:  tensor([[75.7420, 75.8359, 75.7825, 75.8531,  0.1000,  0.1000,  0.1000, 75.7420,\n",
      "         75.7420, 75.7420,  0.1000,  0.1000, 75.8359, 75.8359, 75.8359,  0.1000,\n",
      "          0.1000, 75.8359, 75.8359,  0.1000, 75.7825, 75.7825, 75.7825,  0.1000,\n",
      "          0.1000, 75.7825, 75.7825,  0.1000, 75.7825,  0.1000, 75.7825, 75.8531,\n",
      "         75.8531, 75.8531,  0.1000,  0.1000, 75.8531, 75.8531,  0.1000, 75.8531,\n",
      "          0.1000, 75.8531, 75.8359, 75.8531, 75.8531, 75.8531, 75.7825, 75.8531,\n",
      "         75.8531, 75.8531, 75.8359, 75.8531, 75.8531, 75.8531, 75.8359, 75.7825,\n",
      "         75.8359, 75.8359, 75.8359,  0.1000, 75.8359, 75.7825,  0.1000, 75.7825,\n",
      "         75.8531,  0.1000, 75.8531, 75.8531, 75.8531, 75.8359, 75.8359,  0.1000,\n",
      "         75.8531,  0.1000, 75.7420, 75.7420, 75.8359, 75.8531, 75.8531,  0.1000,\n",
      "          0.1000, 75.7420, 75.8359, 75.8531,  0.1000, 75.8359, 75.8531,  0.1000,\n",
      "         75.7420, 75.8531]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 629 was 99.0%\n",
      "current params: tensor([75.7420, 75.8359, 75.7825, 75.8531], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "SLow rates:  tensor([[75.8421, 75.9360, 75.8825, 75.9532,  0.1000,  0.1000,  0.1000, 75.8421,\n",
      "         75.8421, 75.8421,  0.1000,  0.1000, 75.9360, 75.9360, 75.9360,  0.1000,\n",
      "          0.1000, 75.9360, 75.9360,  0.1000, 75.8825, 75.8825, 75.8825,  0.1000,\n",
      "          0.1000, 75.8825, 75.8825,  0.1000, 75.8825,  0.1000, 75.8825, 75.9532,\n",
      "         75.9532, 75.9532,  0.1000,  0.1000, 75.9532, 75.9532,  0.1000, 75.9532,\n",
      "          0.1000, 75.9532, 75.9360, 75.9532, 75.9532, 75.9532, 75.8825, 75.9532,\n",
      "         75.9532, 75.9532, 75.9360, 75.9532, 75.9532, 75.9532, 75.9360, 75.8825,\n",
      "         75.9360, 75.9360, 75.9360,  0.1000, 75.9360, 75.8825,  0.1000, 75.8825,\n",
      "         75.9532,  0.1000, 75.9532, 75.9532, 75.9532, 75.9360, 75.9360,  0.1000,\n",
      "         75.9532,  0.1000, 75.8421, 75.8421, 75.9360, 75.9532, 75.9532,  0.1000,\n",
      "          0.1000, 75.8421, 75.9360, 75.9532,  0.1000, 75.9360, 75.9532,  0.1000,\n",
      "         75.8421, 75.9532]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 630 was 99.0%\n",
      "current params: tensor([75.8421, 75.9360, 75.8825, 75.9532], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "SLow rates:  tensor([[75.9421, 76.0361, 75.9826, 76.0532,  0.1000,  0.1000,  0.1000, 75.9421,\n",
      "         75.9421, 75.9421,  0.1000,  0.1000, 76.0361, 76.0361, 76.0361,  0.1000,\n",
      "          0.1000, 76.0361, 76.0361,  0.1000, 75.9826, 75.9826, 75.9826,  0.1000,\n",
      "          0.1000, 75.9826, 75.9826,  0.1000, 75.9826,  0.1000, 75.9826, 76.0532,\n",
      "         76.0532, 76.0532,  0.1000,  0.1000, 76.0532, 76.0532,  0.1000, 76.0532,\n",
      "          0.1000, 76.0532, 76.0361, 76.0532, 76.0532, 76.0532, 75.9826, 76.0532,\n",
      "         76.0532, 76.0532, 76.0361, 76.0532, 76.0532, 76.0532, 76.0361, 75.9826,\n",
      "         76.0361, 76.0361, 76.0361,  0.1000, 76.0361, 75.9826,  0.1000, 75.9826,\n",
      "         76.0532,  0.1000, 76.0532, 76.0532, 76.0532, 76.0361, 76.0361,  0.1000,\n",
      "         76.0532,  0.1000, 75.9421, 75.9421, 76.0361, 76.0532, 76.0532,  0.1000,\n",
      "          0.1000, 75.9421, 76.0361, 76.0532,  0.1000, 76.0361, 76.0532,  0.1000,\n",
      "         75.9421, 76.0532]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 631 was 99.0%\n",
      "current params: tensor([75.9421, 76.0361, 75.9826, 76.0532], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.5\n",
      "SLow rates:  tensor([[76.0422, 76.1362, 76.0827, 76.1533,  0.1000,  0.1000,  0.1000, 76.0422,\n",
      "         76.0422, 76.0422,  0.1000,  0.1000, 76.1362, 76.1362, 76.1362,  0.1000,\n",
      "          0.1000, 76.1362, 76.1362,  0.1000, 76.0827, 76.0827, 76.0827,  0.1000,\n",
      "          0.1000, 76.0827, 76.0827,  0.1000, 76.0827,  0.1000, 76.0827, 76.1533,\n",
      "         76.1533, 76.1533,  0.1000,  0.1000, 76.1533, 76.1533,  0.1000, 76.1533,\n",
      "          0.1000, 76.1533, 76.1362, 76.1533, 76.1533, 76.1533, 76.0827, 76.1533,\n",
      "         76.1533, 76.1533, 76.1362, 76.1533, 76.1533, 76.1533, 76.1362, 76.0827,\n",
      "         76.1362, 76.1362, 76.1362,  0.1000, 76.1362, 76.0827,  0.1000, 76.0827,\n",
      "         76.1533,  0.1000, 76.1533, 76.1533, 76.1533, 76.1362, 76.1362,  0.1000,\n",
      "         76.1533,  0.1000, 76.0422, 76.0422, 76.1362, 76.1533, 76.1533,  0.1000,\n",
      "          0.1000, 76.0422, 76.1362, 76.1533,  0.1000, 76.1362, 76.1533,  0.1000,\n",
      "         76.0422, 76.1533]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 632 was 99.0%\n",
      "current params: tensor([76.0422, 76.1362, 76.0827, 76.1533], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.5\n",
      "SLow rates:  tensor([[76.1423, 76.2362, 76.1828, 76.2534,  0.1000,  0.1000,  0.1000, 76.1423,\n",
      "         76.1423, 76.1423,  0.1000,  0.1000, 76.2362, 76.2362, 76.2362,  0.1000,\n",
      "          0.1000, 76.2362, 76.2362,  0.1000, 76.1828, 76.1828, 76.1828,  0.1000,\n",
      "          0.1000, 76.1828, 76.1828,  0.1000, 76.1828,  0.1000, 76.1828, 76.2534,\n",
      "         76.2534, 76.2534,  0.1000,  0.1000, 76.2534, 76.2534,  0.1000, 76.2534,\n",
      "          0.1000, 76.2534, 76.2362, 76.2534, 76.2534, 76.2534, 76.1828, 76.2534,\n",
      "         76.2534, 76.2534, 76.2362, 76.2534, 76.2534, 76.2534, 76.2362, 76.1828,\n",
      "         76.2362, 76.2362, 76.2362,  0.1000, 76.2362, 76.1828,  0.1000, 76.1828,\n",
      "         76.2534,  0.1000, 76.2534, 76.2534, 76.2534, 76.2362, 76.2362,  0.1000,\n",
      "         76.2534,  0.1000, 76.1423, 76.1423, 76.2362, 76.2534, 76.2534,  0.1000,\n",
      "          0.1000, 76.1423, 76.2362, 76.2534,  0.1000, 76.2362, 76.2534,  0.1000,\n",
      "         76.1423, 76.2534]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 633 was 99.0%\n",
      "current params: tensor([76.1423, 76.2362, 76.1828, 76.2534], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.5\n",
      "SLow rates:  tensor([[76.2424, 76.3363, 76.2829, 76.3534,  0.1000,  0.1000,  0.1000, 76.2424,\n",
      "         76.2424, 76.2424,  0.1000,  0.1000, 76.3363, 76.3363, 76.3363,  0.1000,\n",
      "          0.1000, 76.3363, 76.3363,  0.1000, 76.2829, 76.2829, 76.2829,  0.1000,\n",
      "          0.1000, 76.2829, 76.2829,  0.1000, 76.2829,  0.1000, 76.2829, 76.3534,\n",
      "         76.3534, 76.3534,  0.1000,  0.1000, 76.3534, 76.3534,  0.1000, 76.3534,\n",
      "          0.1000, 76.3534, 76.3363, 76.3534, 76.3534, 76.3534, 76.2829, 76.3534,\n",
      "         76.3534, 76.3534, 76.3363, 76.3534, 76.3534, 76.3534, 76.3363, 76.2829,\n",
      "         76.3363, 76.3363, 76.3363,  0.1000, 76.3363, 76.2829,  0.1000, 76.2829,\n",
      "         76.3534,  0.1000, 76.3534, 76.3534, 76.3534, 76.3363, 76.3363,  0.1000,\n",
      "         76.3534,  0.1000, 76.2424, 76.2424, 76.3363, 76.3534, 76.3534,  0.1000,\n",
      "          0.1000, 76.2424, 76.3363, 76.3534,  0.1000, 76.3363, 76.3534,  0.1000,\n",
      "         76.2424, 76.3534]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 634 was 99.0%\n",
      "current params: tensor([76.2424, 76.3363, 76.2829, 76.3534], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.5\n",
      "SLow rates:  tensor([[76.3425, 76.4364, 76.3829, 76.4535,  0.1000,  0.1000,  0.1000, 76.3425,\n",
      "         76.3425, 76.3425,  0.1000,  0.1000, 76.4364, 76.4364, 76.4364,  0.1000,\n",
      "          0.1000, 76.4364, 76.4364,  0.1000, 76.3829, 76.3829, 76.3829,  0.1000,\n",
      "          0.1000, 76.3829, 76.3829,  0.1000, 76.3829,  0.1000, 76.3829, 76.4535,\n",
      "         76.4535, 76.4535,  0.1000,  0.1000, 76.4535, 76.4535,  0.1000, 76.4535,\n",
      "          0.1000, 76.4535, 76.4364, 76.4535, 76.4535, 76.4535, 76.3829, 76.4535,\n",
      "         76.4535, 76.4535, 76.4364, 76.4535, 76.4535, 76.4535, 76.4364, 76.3829,\n",
      "         76.4364, 76.4364, 76.4364,  0.1000, 76.4364, 76.3829,  0.1000, 76.3829,\n",
      "         76.4535,  0.1000, 76.4535, 76.4535, 76.4535, 76.4364, 76.4364,  0.1000,\n",
      "         76.4535,  0.1000, 76.3425, 76.3425, 76.4364, 76.4535, 76.4535,  0.1000,\n",
      "          0.1000, 76.3425, 76.4364, 76.4535,  0.1000, 76.4364, 76.4535,  0.1000,\n",
      "         76.3425, 76.4535]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 635 was 99.0%\n",
      "current params: tensor([76.3425, 76.4364, 76.3829, 76.4535], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.5\n",
      "SLow rates:  tensor([[76.4425, 76.5365, 76.4830, 76.5536,  0.1000,  0.1000,  0.1000, 76.4425,\n",
      "         76.4425, 76.4425,  0.1000,  0.1000, 76.5365, 76.5365, 76.5365,  0.1000,\n",
      "          0.1000, 76.5365, 76.5365,  0.1000, 76.4830, 76.4830, 76.4830,  0.1000,\n",
      "          0.1000, 76.4830, 76.4830,  0.1000, 76.4830,  0.1000, 76.4830, 76.5536,\n",
      "         76.5536, 76.5536,  0.1000,  0.1000, 76.5536, 76.5536,  0.1000, 76.5536,\n",
      "          0.1000, 76.5536, 76.5365, 76.5536, 76.5536, 76.5536, 76.4830, 76.5536,\n",
      "         76.5536, 76.5536, 76.5365, 76.5536, 76.5536, 76.5536, 76.5365, 76.4830,\n",
      "         76.5365, 76.5365, 76.5365,  0.1000, 76.5365, 76.4830,  0.1000, 76.4830,\n",
      "         76.5536,  0.1000, 76.5536, 76.5536, 76.5536, 76.5365, 76.5365,  0.1000,\n",
      "         76.5536,  0.1000, 76.4425, 76.4425, 76.5365, 76.5536, 76.5536,  0.1000,\n",
      "          0.1000, 76.4425, 76.5365, 76.5536,  0.1000, 76.5365, 76.5536,  0.1000,\n",
      "         76.4425, 76.5536]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 636 was 99.0%\n",
      "current params: tensor([76.4425, 76.5365, 76.4830, 76.5536], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.6\n",
      "SLow rates:  tensor([[76.5426, 76.6365, 76.5831, 76.6537,  0.1000,  0.1000,  0.1000, 76.5426,\n",
      "         76.5426, 76.5426,  0.1000,  0.1000, 76.6365, 76.6365, 76.6365,  0.1000,\n",
      "          0.1000, 76.6365, 76.6365,  0.1000, 76.5831, 76.5831, 76.5831,  0.1000,\n",
      "          0.1000, 76.5831, 76.5831,  0.1000, 76.5831,  0.1000, 76.5831, 76.6537,\n",
      "         76.6537, 76.6537,  0.1000,  0.1000, 76.6537, 76.6537,  0.1000, 76.6537,\n",
      "          0.1000, 76.6537, 76.6365, 76.6537, 76.6537, 76.6537, 76.5831, 76.6537,\n",
      "         76.6537, 76.6537, 76.6365, 76.6537, 76.6537, 76.6537, 76.6365, 76.5831,\n",
      "         76.6365, 76.6365, 76.6365,  0.1000, 76.6365, 76.5831,  0.1000, 76.5831,\n",
      "         76.6537,  0.1000, 76.6537, 76.6537, 76.6537, 76.6365, 76.6365,  0.1000,\n",
      "         76.6537,  0.1000, 76.5426, 76.5426, 76.6365, 76.6537, 76.6537,  0.1000,\n",
      "          0.1000, 76.5426, 76.6365, 76.6537,  0.1000, 76.6365, 76.6537,  0.1000,\n",
      "         76.5426, 76.6537]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 637 was 99.0%\n",
      "current params: tensor([76.5426, 76.6365, 76.5831, 76.6537], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.6\n",
      "SLow rates:  tensor([[76.6427, 76.7366, 76.6832, 76.7537,  0.1000,  0.1000,  0.1000, 76.6427,\n",
      "         76.6427, 76.6427,  0.1000,  0.1000, 76.7366, 76.7366, 76.7366,  0.1000,\n",
      "          0.1000, 76.7366, 76.7366,  0.1000, 76.6832, 76.6832, 76.6832,  0.1000,\n",
      "          0.1000, 76.6832, 76.6832,  0.1000, 76.6832,  0.1000, 76.6832, 76.7537,\n",
      "         76.7537, 76.7537,  0.1000,  0.1000, 76.7537, 76.7537,  0.1000, 76.7537,\n",
      "          0.1000, 76.7537, 76.7366, 76.7537, 76.7537, 76.7537, 76.6832, 76.7537,\n",
      "         76.7537, 76.7537, 76.7366, 76.7537, 76.7537, 76.7537, 76.7366, 76.6832,\n",
      "         76.7366, 76.7366, 76.7366,  0.1000, 76.7366, 76.6832,  0.1000, 76.6832,\n",
      "         76.7537,  0.1000, 76.7537, 76.7537, 76.7537, 76.7366, 76.7366,  0.1000,\n",
      "         76.7537,  0.1000, 76.6427, 76.6427, 76.7366, 76.7537, 76.7537,  0.1000,\n",
      "          0.1000, 76.6427, 76.7366, 76.7537,  0.1000, 76.7366, 76.7537,  0.1000,\n",
      "         76.6427, 76.7537]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 638 was 99.0%\n",
      "current params: tensor([76.6427, 76.7366, 76.6832, 76.7537], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.6\n",
      "SLow rates:  tensor([[76.7428, 76.8367, 76.7832, 76.8538,  0.1000,  0.1000,  0.1000, 76.7428,\n",
      "         76.7428, 76.7428,  0.1000,  0.1000, 76.8367, 76.8367, 76.8367,  0.1000,\n",
      "          0.1000, 76.8367, 76.8367,  0.1000, 76.7832, 76.7832, 76.7832,  0.1000,\n",
      "          0.1000, 76.7832, 76.7832,  0.1000, 76.7832,  0.1000, 76.7832, 76.8538,\n",
      "         76.8538, 76.8538,  0.1000,  0.1000, 76.8538, 76.8538,  0.1000, 76.8538,\n",
      "          0.1000, 76.8538, 76.8367, 76.8538, 76.8538, 76.8538, 76.7832, 76.8538,\n",
      "         76.8538, 76.8538, 76.8367, 76.8538, 76.8538, 76.8538, 76.8367, 76.7832,\n",
      "         76.8367, 76.8367, 76.8367,  0.1000, 76.8367, 76.7832,  0.1000, 76.7832,\n",
      "         76.8538,  0.1000, 76.8538, 76.8538, 76.8538, 76.8367, 76.8367,  0.1000,\n",
      "         76.8538,  0.1000, 76.7428, 76.7428, 76.8367, 76.8538, 76.8538,  0.1000,\n",
      "          0.1000, 76.7428, 76.8367, 76.8538,  0.1000, 76.8367, 76.8538,  0.1000,\n",
      "         76.7428, 76.8538]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 639 was 99.0%\n",
      "current params: tensor([76.7428, 76.8367, 76.7832, 76.8538], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.6\n",
      "SLow rates:  tensor([[76.8428, 76.9368, 76.8833, 76.9539,  0.1000,  0.1000,  0.1000, 76.8428,\n",
      "         76.8428, 76.8428,  0.1000,  0.1000, 76.9368, 76.9368, 76.9368,  0.1000,\n",
      "          0.1000, 76.9368, 76.9368,  0.1000, 76.8833, 76.8833, 76.8833,  0.1000,\n",
      "          0.1000, 76.8833, 76.8833,  0.1000, 76.8833,  0.1000, 76.8833, 76.9539,\n",
      "         76.9539, 76.9539,  0.1000,  0.1000, 76.9539, 76.9539,  0.1000, 76.9539,\n",
      "          0.1000, 76.9539, 76.9368, 76.9539, 76.9539, 76.9539, 76.8833, 76.9539,\n",
      "         76.9539, 76.9539, 76.9368, 76.9539, 76.9539, 76.9539, 76.9368, 76.8833,\n",
      "         76.9368, 76.9368, 76.9368,  0.1000, 76.9368, 76.8833,  0.1000, 76.8833,\n",
      "         76.9539,  0.1000, 76.9539, 76.9539, 76.9539, 76.9368, 76.9368,  0.1000,\n",
      "         76.9539,  0.1000, 76.8428, 76.8428, 76.9368, 76.9539, 76.9539,  0.1000,\n",
      "          0.1000, 76.8428, 76.9368, 76.9539,  0.1000, 76.9368, 76.9539,  0.1000,\n",
      "         76.8428, 76.9539]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 640 was 99.0%\n",
      "current params: tensor([76.8428, 76.9368, 76.8833, 76.9539], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.6\n",
      "SLow rates:  tensor([[76.9429, 77.0368, 76.9834, 77.0539,  0.1000,  0.1000,  0.1000, 76.9429,\n",
      "         76.9429, 76.9429,  0.1000,  0.1000, 77.0368, 77.0368, 77.0368,  0.1000,\n",
      "          0.1000, 77.0368, 77.0368,  0.1000, 76.9834, 76.9834, 76.9834,  0.1000,\n",
      "          0.1000, 76.9834, 76.9834,  0.1000, 76.9834,  0.1000, 76.9834, 77.0539,\n",
      "         77.0539, 77.0539,  0.1000,  0.1000, 77.0539, 77.0539,  0.1000, 77.0539,\n",
      "          0.1000, 77.0539, 77.0368, 77.0539, 77.0539, 77.0539, 76.9834, 77.0539,\n",
      "         77.0539, 77.0539, 77.0368, 77.0539, 77.0539, 77.0539, 77.0368, 76.9834,\n",
      "         77.0368, 77.0368, 77.0368,  0.1000, 77.0368, 76.9834,  0.1000, 76.9834,\n",
      "         77.0539,  0.1000, 77.0539, 77.0539, 77.0539, 77.0368, 77.0368,  0.1000,\n",
      "         77.0539,  0.1000, 76.9429, 76.9429, 77.0368, 77.0539, 77.0539,  0.1000,\n",
      "          0.1000, 76.9429, 77.0368, 77.0539,  0.1000, 77.0368, 77.0539,  0.1000,\n",
      "         76.9429, 77.0539]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 641 was 99.0%\n",
      "current params: tensor([76.9429, 77.0368, 76.9834, 77.0539], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.7\n",
      "SLow rates:  tensor([[77.0430, 77.1369, 77.0835, 77.1540,  0.1000,  0.1000,  0.1000, 77.0430,\n",
      "         77.0430, 77.0430,  0.1000,  0.1000, 77.1369, 77.1369, 77.1369,  0.1000,\n",
      "          0.1000, 77.1369, 77.1369,  0.1000, 77.0835, 77.0835, 77.0835,  0.1000,\n",
      "          0.1000, 77.0835, 77.0835,  0.1000, 77.0835,  0.1000, 77.0835, 77.1540,\n",
      "         77.1540, 77.1540,  0.1000,  0.1000, 77.1540, 77.1540,  0.1000, 77.1540,\n",
      "          0.1000, 77.1540, 77.1369, 77.1540, 77.1540, 77.1540, 77.0835, 77.1540,\n",
      "         77.1540, 77.1540, 77.1369, 77.1540, 77.1540, 77.1540, 77.1369, 77.0835,\n",
      "         77.1369, 77.1369, 77.1369,  0.1000, 77.1369, 77.0835,  0.1000, 77.0835,\n",
      "         77.1540,  0.1000, 77.1540, 77.1540, 77.1540, 77.1369, 77.1369,  0.1000,\n",
      "         77.1540,  0.1000, 77.0430, 77.0430, 77.1369, 77.1540, 77.1540,  0.1000,\n",
      "          0.1000, 77.0430, 77.1369, 77.1540,  0.1000, 77.1369, 77.1540,  0.1000,\n",
      "         77.0430, 77.1540]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 642 was 99.0%\n",
      "current params: tensor([77.0430, 77.1369, 77.0835, 77.1540], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.7\n",
      "SLow rates:  tensor([[77.1431, 77.2370, 77.1835, 77.2541,  0.1000,  0.1000,  0.1000, 77.1431,\n",
      "         77.1431, 77.1431,  0.1000,  0.1000, 77.2370, 77.2370, 77.2370,  0.1000,\n",
      "          0.1000, 77.2370, 77.2370,  0.1000, 77.1835, 77.1835, 77.1835,  0.1000,\n",
      "          0.1000, 77.1835, 77.1835,  0.1000, 77.1835,  0.1000, 77.1835, 77.2541,\n",
      "         77.2541, 77.2541,  0.1000,  0.1000, 77.2541, 77.2541,  0.1000, 77.2541,\n",
      "          0.1000, 77.2541, 77.2370, 77.2541, 77.2541, 77.2541, 77.1835, 77.2541,\n",
      "         77.2541, 77.2541, 77.2370, 77.2541, 77.2541, 77.2541, 77.2370, 77.1835,\n",
      "         77.2370, 77.2370, 77.2370,  0.1000, 77.2370, 77.1835,  0.1000, 77.1835,\n",
      "         77.2541,  0.1000, 77.2541, 77.2541, 77.2541, 77.2370, 77.2370,  0.1000,\n",
      "         77.2541,  0.1000, 77.1431, 77.1431, 77.2370, 77.2541, 77.2541,  0.1000,\n",
      "          0.1000, 77.1431, 77.2370, 77.2541,  0.1000, 77.2370, 77.2541,  0.1000,\n",
      "         77.1431, 77.2541]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 643 was 99.0%\n",
      "current params: tensor([77.1431, 77.2370, 77.1835, 77.2541], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.7\n",
      "SLow rates:  tensor([[77.2431, 77.3370, 77.2836, 77.3541,  0.1000,  0.1000,  0.1000, 77.2431,\n",
      "         77.2431, 77.2431,  0.1000,  0.1000, 77.3370, 77.3370, 77.3370,  0.1000,\n",
      "          0.1000, 77.3370, 77.3370,  0.1000, 77.2836, 77.2836, 77.2836,  0.1000,\n",
      "          0.1000, 77.2836, 77.2836,  0.1000, 77.2836,  0.1000, 77.2836, 77.3541,\n",
      "         77.3541, 77.3541,  0.1000,  0.1000, 77.3541, 77.3541,  0.1000, 77.3541,\n",
      "          0.1000, 77.3541, 77.3370, 77.3541, 77.3541, 77.3541, 77.2836, 77.3541,\n",
      "         77.3541, 77.3541, 77.3370, 77.3541, 77.3541, 77.3541, 77.3370, 77.2836,\n",
      "         77.3370, 77.3370, 77.3370,  0.1000, 77.3370, 77.2836,  0.1000, 77.2836,\n",
      "         77.3541,  0.1000, 77.3541, 77.3541, 77.3541, 77.3370, 77.3370,  0.1000,\n",
      "         77.3541,  0.1000, 77.2431, 77.2431, 77.3370, 77.3541, 77.3541,  0.1000,\n",
      "          0.1000, 77.2431, 77.3370, 77.3541,  0.1000, 77.3370, 77.3541,  0.1000,\n",
      "         77.2431, 77.3541]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 644 was 99.0%\n",
      "current params: tensor([77.2431, 77.3370, 77.2836, 77.3541], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.7\n",
      "SLow rates:  tensor([[77.3432, 77.4371, 77.3837, 77.4542,  0.1000,  0.1000,  0.1000, 77.3432,\n",
      "         77.3432, 77.3432,  0.1000,  0.1000, 77.4371, 77.4371, 77.4371,  0.1000,\n",
      "          0.1000, 77.4371, 77.4371,  0.1000, 77.3837, 77.3837, 77.3837,  0.1000,\n",
      "          0.1000, 77.3837, 77.3837,  0.1000, 77.3837,  0.1000, 77.3837, 77.4542,\n",
      "         77.4542, 77.4542,  0.1000,  0.1000, 77.4542, 77.4542,  0.1000, 77.4542,\n",
      "          0.1000, 77.4542, 77.4371, 77.4542, 77.4542, 77.4542, 77.3837, 77.4542,\n",
      "         77.4542, 77.4542, 77.4371, 77.4542, 77.4542, 77.4542, 77.4371, 77.3837,\n",
      "         77.4371, 77.4371, 77.4371,  0.1000, 77.4371, 77.3837,  0.1000, 77.3837,\n",
      "         77.4542,  0.1000, 77.4542, 77.4542, 77.4542, 77.4371, 77.4371,  0.1000,\n",
      "         77.4542,  0.1000, 77.3432, 77.3432, 77.4371, 77.4542, 77.4542,  0.1000,\n",
      "          0.1000, 77.3432, 77.4371, 77.4542,  0.1000, 77.4371, 77.4542,  0.1000,\n",
      "         77.3432, 77.4542]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 645 was 99.0%\n",
      "current params: tensor([77.3432, 77.4371, 77.3837, 77.4542], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.7\n",
      "SLow rates:  tensor([[77.4433, 77.5372, 77.4837, 77.5543,  0.1000,  0.1000,  0.1000, 77.4433,\n",
      "         77.4433, 77.4433,  0.1000,  0.1000, 77.5372, 77.5372, 77.5372,  0.1000,\n",
      "          0.1000, 77.5372, 77.5372,  0.1000, 77.4837, 77.4837, 77.4837,  0.1000,\n",
      "          0.1000, 77.4837, 77.4837,  0.1000, 77.4837,  0.1000, 77.4837, 77.5543,\n",
      "         77.5543, 77.5543,  0.1000,  0.1000, 77.5543, 77.5543,  0.1000, 77.5543,\n",
      "          0.1000, 77.5543, 77.5372, 77.5543, 77.5543, 77.5543, 77.4837, 77.5543,\n",
      "         77.5543, 77.5543, 77.5372, 77.5543, 77.5543, 77.5543, 77.5372, 77.4837,\n",
      "         77.5372, 77.5372, 77.5372,  0.1000, 77.5372, 77.4837,  0.1000, 77.4837,\n",
      "         77.5543,  0.1000, 77.5543, 77.5543, 77.5543, 77.5372, 77.5372,  0.1000,\n",
      "         77.5543,  0.1000, 77.4433, 77.4433, 77.5372, 77.5543, 77.5543,  0.1000,\n",
      "          0.1000, 77.4433, 77.5372, 77.5543,  0.1000, 77.5372, 77.5543,  0.1000,\n",
      "         77.4433, 77.5543]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 646 was 99.0%\n",
      "current params: tensor([77.4433, 77.5372, 77.4837, 77.5543], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "SLow rates:  tensor([[77.5433, 77.6372, 77.5838, 77.6543,  0.1000,  0.1000,  0.1000, 77.5433,\n",
      "         77.5433, 77.5433,  0.1000,  0.1000, 77.6372, 77.6372, 77.6372,  0.1000,\n",
      "          0.1000, 77.6372, 77.6372,  0.1000, 77.5838, 77.5838, 77.5838,  0.1000,\n",
      "          0.1000, 77.5838, 77.5838,  0.1000, 77.5838,  0.1000, 77.5838, 77.6543,\n",
      "         77.6543, 77.6543,  0.1000,  0.1000, 77.6543, 77.6543,  0.1000, 77.6543,\n",
      "          0.1000, 77.6543, 77.6372, 77.6543, 77.6543, 77.6543, 77.5838, 77.6543,\n",
      "         77.6543, 77.6543, 77.6372, 77.6543, 77.6543, 77.6543, 77.6372, 77.5838,\n",
      "         77.6372, 77.6372, 77.6372,  0.1000, 77.6372, 77.5838,  0.1000, 77.5838,\n",
      "         77.6543,  0.1000, 77.6543, 77.6543, 77.6543, 77.6372, 77.6372,  0.1000,\n",
      "         77.6543,  0.1000, 77.5433, 77.5433, 77.6372, 77.6543, 77.6543,  0.1000,\n",
      "          0.1000, 77.5433, 77.6372, 77.6543,  0.1000, 77.6372, 77.6543,  0.1000,\n",
      "         77.5433, 77.6543]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 647 was 99.0%\n",
      "current params: tensor([77.5433, 77.6372, 77.5838, 77.6543], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "SLow rates:  tensor([[77.6434, 77.7373, 77.6839, 77.7544,  0.1000,  0.1000,  0.1000, 77.6434,\n",
      "         77.6434, 77.6434,  0.1000,  0.1000, 77.7373, 77.7373, 77.7373,  0.1000,\n",
      "          0.1000, 77.7373, 77.7373,  0.1000, 77.6839, 77.6839, 77.6839,  0.1000,\n",
      "          0.1000, 77.6839, 77.6839,  0.1000, 77.6839,  0.1000, 77.6839, 77.7544,\n",
      "         77.7544, 77.7544,  0.1000,  0.1000, 77.7544, 77.7544,  0.1000, 77.7544,\n",
      "          0.1000, 77.7544, 77.7373, 77.7544, 77.7544, 77.7544, 77.6839, 77.7544,\n",
      "         77.7544, 77.7544, 77.7373, 77.7544, 77.7544, 77.7544, 77.7373, 77.6839,\n",
      "         77.7373, 77.7373, 77.7373,  0.1000, 77.7373, 77.6839,  0.1000, 77.6839,\n",
      "         77.7544,  0.1000, 77.7544, 77.7544, 77.7544, 77.7373, 77.7373,  0.1000,\n",
      "         77.7544,  0.1000, 77.6434, 77.6434, 77.7373, 77.7544, 77.7544,  0.1000,\n",
      "          0.1000, 77.6434, 77.7373, 77.7544,  0.1000, 77.7373, 77.7544,  0.1000,\n",
      "         77.6434, 77.7544]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 648 was 99.0%\n",
      "current params: tensor([77.6434, 77.7373, 77.6839, 77.7544], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "SLow rates:  tensor([[77.7435, 77.8374, 77.7839, 77.8545,  0.1000,  0.1000,  0.1000, 77.7435,\n",
      "         77.7435, 77.7435,  0.1000,  0.1000, 77.8374, 77.8374, 77.8374,  0.1000,\n",
      "          0.1000, 77.8374, 77.8374,  0.1000, 77.7839, 77.7839, 77.7839,  0.1000,\n",
      "          0.1000, 77.7839, 77.7839,  0.1000, 77.7839,  0.1000, 77.7839, 77.8545,\n",
      "         77.8545, 77.8545,  0.1000,  0.1000, 77.8545, 77.8545,  0.1000, 77.8545,\n",
      "          0.1000, 77.8545, 77.8374, 77.8545, 77.8545, 77.8545, 77.7839, 77.8545,\n",
      "         77.8545, 77.8545, 77.8374, 77.8545, 77.8545, 77.8545, 77.8374, 77.7839,\n",
      "         77.8374, 77.8374, 77.8374,  0.1000, 77.8374, 77.7839,  0.1000, 77.7839,\n",
      "         77.8545,  0.1000, 77.8545, 77.8545, 77.8545, 77.8374, 77.8374,  0.1000,\n",
      "         77.8545,  0.1000, 77.7435, 77.7435, 77.8374, 77.8545, 77.8545,  0.1000,\n",
      "          0.1000, 77.7435, 77.8374, 77.8545,  0.1000, 77.8374, 77.8545,  0.1000,\n",
      "         77.7435, 77.8545]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 649 was 99.0%\n",
      "current params: tensor([77.7435, 77.8374, 77.7839, 77.8545], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "SLow rates:  tensor([[77.8436, 77.9374, 77.8840, 77.9545,  0.1000,  0.1000,  0.1000, 77.8436,\n",
      "         77.8436, 77.8436,  0.1000,  0.1000, 77.9374, 77.9374, 77.9374,  0.1000,\n",
      "          0.1000, 77.9374, 77.9374,  0.1000, 77.8840, 77.8840, 77.8840,  0.1000,\n",
      "          0.1000, 77.8840, 77.8840,  0.1000, 77.8840,  0.1000, 77.8840, 77.9545,\n",
      "         77.9545, 77.9545,  0.1000,  0.1000, 77.9545, 77.9545,  0.1000, 77.9545,\n",
      "          0.1000, 77.9545, 77.9374, 77.9545, 77.9545, 77.9545, 77.8840, 77.9545,\n",
      "         77.9545, 77.9545, 77.9374, 77.9545, 77.9545, 77.9545, 77.9374, 77.8840,\n",
      "         77.9374, 77.9374, 77.9374,  0.1000, 77.9374, 77.8840,  0.1000, 77.8840,\n",
      "         77.9545,  0.1000, 77.9545, 77.9545, 77.9545, 77.9374, 77.9374,  0.1000,\n",
      "         77.9545,  0.1000, 77.8436, 77.8436, 77.9374, 77.9545, 77.9545,  0.1000,\n",
      "          0.1000, 77.8436, 77.9374, 77.9545,  0.1000, 77.9374, 77.9545,  0.1000,\n",
      "         77.8436, 77.9545]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 650 was 99.0%\n",
      "current params: tensor([77.8436, 77.9374, 77.8840, 77.9545], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "SLow rates:  tensor([[77.9436, 78.0375, 77.9841, 78.0546,  0.1000,  0.1000,  0.1000, 77.9436,\n",
      "         77.9436, 77.9436,  0.1000,  0.1000, 78.0375, 78.0375, 78.0375,  0.1000,\n",
      "          0.1000, 78.0375, 78.0375,  0.1000, 77.9841, 77.9841, 77.9841,  0.1000,\n",
      "          0.1000, 77.9841, 77.9841,  0.1000, 77.9841,  0.1000, 77.9841, 78.0546,\n",
      "         78.0546, 78.0546,  0.1000,  0.1000, 78.0546, 78.0546,  0.1000, 78.0546,\n",
      "          0.1000, 78.0546, 78.0375, 78.0546, 78.0546, 78.0546, 77.9841, 78.0546,\n",
      "         78.0546, 78.0546, 78.0375, 78.0546, 78.0546, 78.0546, 78.0375, 77.9841,\n",
      "         78.0375, 78.0375, 78.0375,  0.1000, 78.0375, 77.9841,  0.1000, 77.9841,\n",
      "         78.0546,  0.1000, 78.0546, 78.0546, 78.0546, 78.0375, 78.0375,  0.1000,\n",
      "         78.0546,  0.1000, 77.9436, 77.9436, 78.0375, 78.0546, 78.0546,  0.1000,\n",
      "          0.1000, 77.9436, 78.0375, 78.0546,  0.1000, 78.0375, 78.0546,  0.1000,\n",
      "         77.9436, 78.0546]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 651 was 99.0%\n",
      "current params: tensor([77.9436, 78.0375, 77.9841, 78.0546], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "SLow rates:  tensor([[78.0437, 78.1375, 78.0841, 78.1546,  0.1000,  0.1000,  0.1000, 78.0437,\n",
      "         78.0437, 78.0437,  0.1000,  0.1000, 78.1375, 78.1375, 78.1375,  0.1000,\n",
      "          0.1000, 78.1375, 78.1375,  0.1000, 78.0841, 78.0841, 78.0841,  0.1000,\n",
      "          0.1000, 78.0841, 78.0841,  0.1000, 78.0841,  0.1000, 78.0841, 78.1546,\n",
      "         78.1546, 78.1546,  0.1000,  0.1000, 78.1546, 78.1546,  0.1000, 78.1546,\n",
      "          0.1000, 78.1546, 78.1375, 78.1546, 78.1546, 78.1546, 78.0841, 78.1546,\n",
      "         78.1546, 78.1546, 78.1375, 78.1546, 78.1546, 78.1546, 78.1375, 78.0841,\n",
      "         78.1375, 78.1375, 78.1375,  0.1000, 78.1375, 78.0841,  0.1000, 78.0841,\n",
      "         78.1546,  0.1000, 78.1546, 78.1546, 78.1546, 78.1375, 78.1375,  0.1000,\n",
      "         78.1546,  0.1000, 78.0437, 78.0437, 78.1375, 78.1546, 78.1546,  0.1000,\n",
      "          0.1000, 78.0437, 78.1375, 78.1546,  0.1000, 78.1375, 78.1546,  0.1000,\n",
      "         78.0437, 78.1546]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 652 was 99.0%\n",
      "current params: tensor([78.0437, 78.1375, 78.0841, 78.1546], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.9\n",
      "SLow rates:  tensor([[78.1438, 78.2376, 78.1842, 78.2547,  0.1000,  0.1000,  0.1000, 78.1438,\n",
      "         78.1438, 78.1438,  0.1000,  0.1000, 78.2376, 78.2376, 78.2376,  0.1000,\n",
      "          0.1000, 78.2376, 78.2376,  0.1000, 78.1842, 78.1842, 78.1842,  0.1000,\n",
      "          0.1000, 78.1842, 78.1842,  0.1000, 78.1842,  0.1000, 78.1842, 78.2547,\n",
      "         78.2547, 78.2547,  0.1000,  0.1000, 78.2547, 78.2547,  0.1000, 78.2547,\n",
      "          0.1000, 78.2547, 78.2376, 78.2547, 78.2547, 78.2547, 78.1842, 78.2547,\n",
      "         78.2547, 78.2547, 78.2376, 78.2547, 78.2547, 78.2547, 78.2376, 78.1842,\n",
      "         78.2376, 78.2376, 78.2376,  0.1000, 78.2376, 78.1842,  0.1000, 78.1842,\n",
      "         78.2547,  0.1000, 78.2547, 78.2547, 78.2547, 78.2376, 78.2376,  0.1000,\n",
      "         78.2547,  0.1000, 78.1438, 78.1438, 78.2376, 78.2547, 78.2547,  0.1000,\n",
      "          0.1000, 78.1438, 78.2376, 78.2547,  0.1000, 78.2376, 78.2547,  0.1000,\n",
      "         78.1438, 78.2547]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 653 was 99.0%\n",
      "current params: tensor([78.1438, 78.2376, 78.1842, 78.2547], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.9\n",
      "SLow rates:  tensor([[78.2438, 78.3377, 78.2843, 78.3548,  0.1000,  0.1000,  0.1000, 78.2438,\n",
      "         78.2438, 78.2438,  0.1000,  0.1000, 78.3377, 78.3377, 78.3377,  0.1000,\n",
      "          0.1000, 78.3377, 78.3377,  0.1000, 78.2843, 78.2843, 78.2843,  0.1000,\n",
      "          0.1000, 78.2843, 78.2843,  0.1000, 78.2843,  0.1000, 78.2843, 78.3548,\n",
      "         78.3548, 78.3548,  0.1000,  0.1000, 78.3548, 78.3548,  0.1000, 78.3548,\n",
      "          0.1000, 78.3548, 78.3377, 78.3548, 78.3548, 78.3548, 78.2843, 78.3548,\n",
      "         78.3548, 78.3548, 78.3377, 78.3548, 78.3548, 78.3548, 78.3377, 78.2843,\n",
      "         78.3377, 78.3377, 78.3377,  0.1000, 78.3377, 78.2843,  0.1000, 78.2843,\n",
      "         78.3548,  0.1000, 78.3548, 78.3548, 78.3548, 78.3377, 78.3377,  0.1000,\n",
      "         78.3548,  0.1000, 78.2438, 78.2438, 78.3377, 78.3548, 78.3548,  0.1000,\n",
      "          0.1000, 78.2438, 78.3377, 78.3548,  0.1000, 78.3377, 78.3548,  0.1000,\n",
      "         78.2438, 78.3548]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 654 was 99.0%\n",
      "current params: tensor([78.2438, 78.3377, 78.2843, 78.3548], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.9\n",
      "SLow rates:  tensor([[78.3439, 78.4377, 78.3843, 78.4548,  0.1000,  0.1000,  0.1000, 78.3439,\n",
      "         78.3439, 78.3439,  0.1000,  0.1000, 78.4377, 78.4377, 78.4377,  0.1000,\n",
      "          0.1000, 78.4377, 78.4377,  0.1000, 78.3843, 78.3843, 78.3843,  0.1000,\n",
      "          0.1000, 78.3843, 78.3843,  0.1000, 78.3843,  0.1000, 78.3843, 78.4548,\n",
      "         78.4548, 78.4548,  0.1000,  0.1000, 78.4548, 78.4548,  0.1000, 78.4548,\n",
      "          0.1000, 78.4548, 78.4377, 78.4548, 78.4548, 78.4548, 78.3843, 78.4548,\n",
      "         78.4548, 78.4548, 78.4377, 78.4548, 78.4548, 78.4548, 78.4377, 78.3843,\n",
      "         78.4377, 78.4377, 78.4377,  0.1000, 78.4377, 78.3843,  0.1000, 78.3843,\n",
      "         78.4548,  0.1000, 78.4548, 78.4548, 78.4548, 78.4377, 78.4377,  0.1000,\n",
      "         78.4548,  0.1000, 78.3439, 78.3439, 78.4377, 78.4548, 78.4548,  0.1000,\n",
      "          0.1000, 78.3439, 78.4377, 78.4548,  0.1000, 78.4377, 78.4548,  0.1000,\n",
      "         78.3439, 78.4548]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 655 was 99.0%\n",
      "current params: tensor([78.3439, 78.4377, 78.3843, 78.4548], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.9\n",
      "SLow rates:  tensor([[78.4439, 78.5378, 78.4844, 78.5549,  0.1000,  0.1000,  0.1000, 78.4439,\n",
      "         78.4439, 78.4439,  0.1000,  0.1000, 78.5378, 78.5378, 78.5378,  0.1000,\n",
      "          0.1000, 78.5378, 78.5378,  0.1000, 78.4844, 78.4844, 78.4844,  0.1000,\n",
      "          0.1000, 78.4844, 78.4844,  0.1000, 78.4844,  0.1000, 78.4844, 78.5549,\n",
      "         78.5549, 78.5549,  0.1000,  0.1000, 78.5549, 78.5549,  0.1000, 78.5549,\n",
      "          0.1000, 78.5549, 78.5378, 78.5549, 78.5549, 78.5549, 78.4844, 78.5549,\n",
      "         78.5549, 78.5549, 78.5378, 78.5549, 78.5549, 78.5549, 78.5378, 78.4844,\n",
      "         78.5378, 78.5378, 78.5378,  0.1000, 78.5378, 78.4844,  0.1000, 78.4844,\n",
      "         78.5549,  0.1000, 78.5549, 78.5549, 78.5549, 78.5378, 78.5378,  0.1000,\n",
      "         78.5549,  0.1000, 78.4439, 78.4439, 78.5378, 78.5549, 78.5549,  0.1000,\n",
      "          0.1000, 78.4439, 78.5378, 78.5549,  0.1000, 78.5378, 78.5549,  0.1000,\n",
      "         78.4439, 78.5549]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 656 was 99.0%\n",
      "current params: tensor([78.4439, 78.5378, 78.4844, 78.5549], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.9\n",
      "SLow rates:  tensor([[78.5440, 78.6379, 78.5844, 78.6549,  0.1000,  0.1000,  0.1000, 78.5440,\n",
      "         78.5440, 78.5440,  0.1000,  0.1000, 78.6379, 78.6379, 78.6379,  0.1000,\n",
      "          0.1000, 78.6379, 78.6379,  0.1000, 78.5844, 78.5844, 78.5844,  0.1000,\n",
      "          0.1000, 78.5844, 78.5844,  0.1000, 78.5844,  0.1000, 78.5844, 78.6549,\n",
      "         78.6549, 78.6549,  0.1000,  0.1000, 78.6549, 78.6549,  0.1000, 78.6549,\n",
      "          0.1000, 78.6549, 78.6379, 78.6549, 78.6549, 78.6549, 78.5844, 78.6549,\n",
      "         78.6549, 78.6549, 78.6379, 78.6549, 78.6549, 78.6549, 78.6379, 78.5844,\n",
      "         78.6379, 78.6379, 78.6379,  0.1000, 78.6379, 78.5844,  0.1000, 78.5844,\n",
      "         78.6549,  0.1000, 78.6549, 78.6549, 78.6549, 78.6379, 78.6379,  0.1000,\n",
      "         78.6549,  0.1000, 78.5440, 78.5440, 78.6379, 78.6549, 78.6549,  0.1000,\n",
      "          0.1000, 78.5440, 78.6379, 78.6549,  0.1000, 78.6379, 78.6549,  0.1000,\n",
      "         78.5440, 78.6549]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 657 was 99.0%\n",
      "current params: tensor([78.5440, 78.6379, 78.5844, 78.6549], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.0\n",
      "SLow rates:  tensor([[78.6441, 78.7379, 78.6845, 78.7550,  0.1000,  0.1000,  0.1000, 78.6441,\n",
      "         78.6441, 78.6441,  0.1000,  0.1000, 78.7379, 78.7379, 78.7379,  0.1000,\n",
      "          0.1000, 78.7379, 78.7379,  0.1000, 78.6845, 78.6845, 78.6845,  0.1000,\n",
      "          0.1000, 78.6845, 78.6845,  0.1000, 78.6845,  0.1000, 78.6845, 78.7550,\n",
      "         78.7550, 78.7550,  0.1000,  0.1000, 78.7550, 78.7550,  0.1000, 78.7550,\n",
      "          0.1000, 78.7550, 78.7379, 78.7550, 78.7550, 78.7550, 78.6845, 78.7550,\n",
      "         78.7550, 78.7550, 78.7379, 78.7550, 78.7550, 78.7550, 78.7379, 78.6845,\n",
      "         78.7379, 78.7379, 78.7379,  0.1000, 78.7379, 78.6845,  0.1000, 78.6845,\n",
      "         78.7550,  0.1000, 78.7550, 78.7550, 78.7550, 78.7379, 78.7379,  0.1000,\n",
      "         78.7550,  0.1000, 78.6441, 78.6441, 78.7379, 78.7550, 78.7550,  0.1000,\n",
      "          0.1000, 78.6441, 78.7379, 78.7550,  0.1000, 78.7379, 78.7550,  0.1000,\n",
      "         78.6441, 78.7550]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 658 was 99.0%\n",
      "current params: tensor([78.6441, 78.7379, 78.6845, 78.7550], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.0\n",
      "SLow rates:  tensor([[78.7441, 78.8380, 78.7846, 78.8550,  0.1000,  0.1000,  0.1000, 78.7441,\n",
      "         78.7441, 78.7441,  0.1000,  0.1000, 78.8380, 78.8380, 78.8380,  0.1000,\n",
      "          0.1000, 78.8380, 78.8380,  0.1000, 78.7846, 78.7846, 78.7846,  0.1000,\n",
      "          0.1000, 78.7846, 78.7846,  0.1000, 78.7846,  0.1000, 78.7846, 78.8550,\n",
      "         78.8550, 78.8550,  0.1000,  0.1000, 78.8550, 78.8550,  0.1000, 78.8550,\n",
      "          0.1000, 78.8550, 78.8380, 78.8550, 78.8550, 78.8550, 78.7846, 78.8550,\n",
      "         78.8550, 78.8550, 78.8380, 78.8550, 78.8550, 78.8550, 78.8380, 78.7846,\n",
      "         78.8380, 78.8380, 78.8380,  0.1000, 78.8380, 78.7846,  0.1000, 78.7846,\n",
      "         78.8550,  0.1000, 78.8550, 78.8550, 78.8550, 78.8380, 78.8380,  0.1000,\n",
      "         78.8550,  0.1000, 78.7441, 78.7441, 78.8380, 78.8550, 78.8550,  0.1000,\n",
      "          0.1000, 78.7441, 78.8380, 78.8550,  0.1000, 78.8380, 78.8550,  0.1000,\n",
      "         78.7441, 78.8550]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 659 was 99.0%\n",
      "current params: tensor([78.7441, 78.8380, 78.7846, 78.8550], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.0\n",
      "SLow rates:  tensor([[78.8442, 78.9380, 78.8846, 78.9551,  0.1000,  0.1000,  0.1000, 78.8442,\n",
      "         78.8442, 78.8442,  0.1000,  0.1000, 78.9380, 78.9380, 78.9380,  0.1000,\n",
      "          0.1000, 78.9380, 78.9380,  0.1000, 78.8846, 78.8846, 78.8846,  0.1000,\n",
      "          0.1000, 78.8846, 78.8846,  0.1000, 78.8846,  0.1000, 78.8846, 78.9551,\n",
      "         78.9551, 78.9551,  0.1000,  0.1000, 78.9551, 78.9551,  0.1000, 78.9551,\n",
      "          0.1000, 78.9551, 78.9380, 78.9551, 78.9551, 78.9551, 78.8846, 78.9551,\n",
      "         78.9551, 78.9551, 78.9380, 78.9551, 78.9551, 78.9551, 78.9380, 78.8846,\n",
      "         78.9380, 78.9380, 78.9380,  0.1000, 78.9380, 78.8846,  0.1000, 78.8846,\n",
      "         78.9551,  0.1000, 78.9551, 78.9551, 78.9551, 78.9380, 78.9380,  0.1000,\n",
      "         78.9551,  0.1000, 78.8442, 78.8442, 78.9380, 78.9551, 78.9551,  0.1000,\n",
      "          0.1000, 78.8442, 78.9380, 78.9551,  0.1000, 78.9380, 78.9551,  0.1000,\n",
      "         78.8442, 78.9551]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 660 was 99.0%\n",
      "current params: tensor([78.8442, 78.9380, 78.8846, 78.9551], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.0\n",
      "SLow rates:  tensor([[78.9443, 79.0381, 78.9847, 79.0552,  0.1000,  0.1000,  0.1000, 78.9443,\n",
      "         78.9443, 78.9443,  0.1000,  0.1000, 79.0381, 79.0381, 79.0381,  0.1000,\n",
      "          0.1000, 79.0381, 79.0381,  0.1000, 78.9847, 78.9847, 78.9847,  0.1000,\n",
      "          0.1000, 78.9847, 78.9847,  0.1000, 78.9847,  0.1000, 78.9847, 79.0552,\n",
      "         79.0552, 79.0552,  0.1000,  0.1000, 79.0552, 79.0552,  0.1000, 79.0552,\n",
      "          0.1000, 79.0552, 79.0381, 79.0552, 79.0552, 79.0552, 78.9847, 79.0552,\n",
      "         79.0552, 79.0552, 79.0381, 79.0552, 79.0552, 79.0552, 79.0381, 78.9847,\n",
      "         79.0381, 79.0381, 79.0381,  0.1000, 79.0381, 78.9847,  0.1000, 78.9847,\n",
      "         79.0552,  0.1000, 79.0552, 79.0552, 79.0552, 79.0381, 79.0381,  0.1000,\n",
      "         79.0552,  0.1000, 78.9443, 78.9443, 79.0381, 79.0552, 79.0552,  0.1000,\n",
      "          0.1000, 78.9443, 79.0381, 79.0552,  0.1000, 79.0381, 79.0552,  0.1000,\n",
      "         78.9443, 79.0552]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 661 was 99.0%\n",
      "current params: tensor([78.9443, 79.0381, 78.9847, 79.0552], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.0\n",
      "SLow rates:  tensor([[79.0443, 79.1381, 79.0847, 79.1552,  0.1000,  0.1000,  0.1000, 79.0443,\n",
      "         79.0443, 79.0443,  0.1000,  0.1000, 79.1381, 79.1381, 79.1381,  0.1000,\n",
      "          0.1000, 79.1381, 79.1381,  0.1000, 79.0847, 79.0847, 79.0847,  0.1000,\n",
      "          0.1000, 79.0847, 79.0847,  0.1000, 79.0847,  0.1000, 79.0847, 79.1552,\n",
      "         79.1552, 79.1552,  0.1000,  0.1000, 79.1552, 79.1552,  0.1000, 79.1552,\n",
      "          0.1000, 79.1552, 79.1381, 79.1552, 79.1552, 79.1552, 79.0847, 79.1552,\n",
      "         79.1552, 79.1552, 79.1381, 79.1552, 79.1552, 79.1552, 79.1381, 79.0847,\n",
      "         79.1381, 79.1381, 79.1381,  0.1000, 79.1381, 79.0847,  0.1000, 79.0847,\n",
      "         79.1552,  0.1000, 79.1552, 79.1552, 79.1552, 79.1381, 79.1381,  0.1000,\n",
      "         79.1552,  0.1000, 79.0443, 79.0443, 79.1381, 79.1552, 79.1552,  0.1000,\n",
      "          0.1000, 79.0443, 79.1381, 79.1552,  0.1000, 79.1381, 79.1552,  0.1000,\n",
      "         79.0443, 79.1552]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 662 was 99.0%\n",
      "current params: tensor([79.0443, 79.1381, 79.0847, 79.1552], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "SLow rates:  tensor([[79.1444, 79.2382, 79.1848, 79.2553,  0.1000,  0.1000,  0.1000, 79.1444,\n",
      "         79.1444, 79.1444,  0.1000,  0.1000, 79.2382, 79.2382, 79.2382,  0.1000,\n",
      "          0.1000, 79.2382, 79.2382,  0.1000, 79.1848, 79.1848, 79.1848,  0.1000,\n",
      "          0.1000, 79.1848, 79.1848,  0.1000, 79.1848,  0.1000, 79.1848, 79.2553,\n",
      "         79.2553, 79.2553,  0.1000,  0.1000, 79.2553, 79.2553,  0.1000, 79.2553,\n",
      "          0.1000, 79.2553, 79.2382, 79.2553, 79.2553, 79.2553, 79.1848, 79.2553,\n",
      "         79.2553, 79.2553, 79.2382, 79.2553, 79.2553, 79.2553, 79.2382, 79.1848,\n",
      "         79.2382, 79.2382, 79.2382,  0.1000, 79.2382, 79.1848,  0.1000, 79.1848,\n",
      "         79.2553,  0.1000, 79.2553, 79.2553, 79.2553, 79.2382, 79.2382,  0.1000,\n",
      "         79.2553,  0.1000, 79.1444, 79.1444, 79.2382, 79.2553, 79.2553,  0.1000,\n",
      "          0.1000, 79.1444, 79.2382, 79.2553,  0.1000, 79.2382, 79.2553,  0.1000,\n",
      "         79.1444, 79.2553]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 663 was 99.0%\n",
      "current params: tensor([79.1444, 79.2382, 79.1848, 79.2553], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "SLow rates:  tensor([[79.2444, 79.3382, 79.2848, 79.3553,  0.1000,  0.1000,  0.1000, 79.2444,\n",
      "         79.2444, 79.2444,  0.1000,  0.1000, 79.3382, 79.3382, 79.3382,  0.1000,\n",
      "          0.1000, 79.3382, 79.3382,  0.1000, 79.2848, 79.2848, 79.2848,  0.1000,\n",
      "          0.1000, 79.2848, 79.2848,  0.1000, 79.2848,  0.1000, 79.2848, 79.3553,\n",
      "         79.3553, 79.3553,  0.1000,  0.1000, 79.3553, 79.3553,  0.1000, 79.3553,\n",
      "          0.1000, 79.3553, 79.3382, 79.3553, 79.3553, 79.3553, 79.2848, 79.3553,\n",
      "         79.3553, 79.3553, 79.3382, 79.3553, 79.3553, 79.3553, 79.3382, 79.2848,\n",
      "         79.3382, 79.3382, 79.3382,  0.1000, 79.3382, 79.2848,  0.1000, 79.2848,\n",
      "         79.3553,  0.1000, 79.3553, 79.3553, 79.3553, 79.3382, 79.3382,  0.1000,\n",
      "         79.3553,  0.1000, 79.2444, 79.2444, 79.3382, 79.3553, 79.3553,  0.1000,\n",
      "          0.1000, 79.2444, 79.3382, 79.3553,  0.1000, 79.3382, 79.3553,  0.1000,\n",
      "         79.2444, 79.3553]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 664 was 99.0%\n",
      "current params: tensor([79.2444, 79.3382, 79.2848, 79.3553], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "SLow rates:  tensor([[79.3445, 79.4383, 79.3849, 79.4554,  0.1000,  0.1000,  0.1000, 79.3445,\n",
      "         79.3445, 79.3445,  0.1000,  0.1000, 79.4383, 79.4383, 79.4383,  0.1000,\n",
      "          0.1000, 79.4383, 79.4383,  0.1000, 79.3849, 79.3849, 79.3849,  0.1000,\n",
      "          0.1000, 79.3849, 79.3849,  0.1000, 79.3849,  0.1000, 79.3849, 79.4554,\n",
      "         79.4554, 79.4554,  0.1000,  0.1000, 79.4554, 79.4554,  0.1000, 79.4554,\n",
      "          0.1000, 79.4554, 79.4383, 79.4554, 79.4554, 79.4554, 79.3849, 79.4554,\n",
      "         79.4554, 79.4554, 79.4383, 79.4554, 79.4554, 79.4554, 79.4383, 79.3849,\n",
      "         79.4383, 79.4383, 79.4383,  0.1000, 79.4383, 79.3849,  0.1000, 79.3849,\n",
      "         79.4554,  0.1000, 79.4554, 79.4554, 79.4554, 79.4383, 79.4383,  0.1000,\n",
      "         79.4554,  0.1000, 79.3445, 79.3445, 79.4383, 79.4554, 79.4554,  0.1000,\n",
      "          0.1000, 79.3445, 79.4383, 79.4554,  0.1000, 79.4383, 79.4554,  0.1000,\n",
      "         79.3445, 79.4554]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 665 was 99.0%\n",
      "current params: tensor([79.3445, 79.4383, 79.3849, 79.4554], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "SLow rates:  tensor([[79.4446, 79.5384, 79.4850, 79.5554,  0.1000,  0.1000,  0.1000, 79.4446,\n",
      "         79.4446, 79.4446,  0.1000,  0.1000, 79.5384, 79.5384, 79.5384,  0.1000,\n",
      "          0.1000, 79.5384, 79.5384,  0.1000, 79.4850, 79.4850, 79.4850,  0.1000,\n",
      "          0.1000, 79.4850, 79.4850,  0.1000, 79.4850,  0.1000, 79.4850, 79.5554,\n",
      "         79.5554, 79.5554,  0.1000,  0.1000, 79.5554, 79.5554,  0.1000, 79.5554,\n",
      "          0.1000, 79.5554, 79.5384, 79.5554, 79.5554, 79.5554, 79.4850, 79.5554,\n",
      "         79.5554, 79.5554, 79.5384, 79.5554, 79.5554, 79.5554, 79.5384, 79.4850,\n",
      "         79.5384, 79.5384, 79.5384,  0.1000, 79.5384, 79.4850,  0.1000, 79.4850,\n",
      "         79.5554,  0.1000, 79.5554, 79.5554, 79.5554, 79.5384, 79.5384,  0.1000,\n",
      "         79.5554,  0.1000, 79.4446, 79.4446, 79.5384, 79.5554, 79.5554,  0.1000,\n",
      "          0.1000, 79.4446, 79.5384, 79.5554,  0.1000, 79.5384, 79.5554,  0.1000,\n",
      "         79.4446, 79.5554]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 666 was 99.0%\n",
      "current params: tensor([79.4446, 79.5384, 79.4850, 79.5554], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "SLow rates:  tensor([[79.5446, 79.6384, 79.5850, 79.6555,  0.1000,  0.1000,  0.1000, 79.5446,\n",
      "         79.5446, 79.5446,  0.1000,  0.1000, 79.6384, 79.6384, 79.6384,  0.1000,\n",
      "          0.1000, 79.6384, 79.6384,  0.1000, 79.5850, 79.5850, 79.5850,  0.1000,\n",
      "          0.1000, 79.5850, 79.5850,  0.1000, 79.5850,  0.1000, 79.5850, 79.6555,\n",
      "         79.6555, 79.6555,  0.1000,  0.1000, 79.6555, 79.6555,  0.1000, 79.6555,\n",
      "          0.1000, 79.6555, 79.6384, 79.6555, 79.6555, 79.6555, 79.5850, 79.6555,\n",
      "         79.6555, 79.6555, 79.6384, 79.6555, 79.6555, 79.6555, 79.6384, 79.5850,\n",
      "         79.6384, 79.6384, 79.6384,  0.1000, 79.6384, 79.5850,  0.1000, 79.5850,\n",
      "         79.6555,  0.1000, 79.6555, 79.6555, 79.6555, 79.6384, 79.6384,  0.1000,\n",
      "         79.6555,  0.1000, 79.5446, 79.5446, 79.6384, 79.6555, 79.6555,  0.1000,\n",
      "          0.1000, 79.5446, 79.6384, 79.6555,  0.1000, 79.6384, 79.6555,  0.1000,\n",
      "         79.5446, 79.6555]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 667 was 99.0%\n",
      "current params: tensor([79.5446, 79.6384, 79.5850, 79.6555], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "SLow rates:  tensor([[79.6447, 79.7385, 79.6851, 79.7555,  0.1000,  0.1000,  0.1000, 79.6447,\n",
      "         79.6447, 79.6447,  0.1000,  0.1000, 79.7385, 79.7385, 79.7385,  0.1000,\n",
      "          0.1000, 79.7385, 79.7385,  0.1000, 79.6851, 79.6851, 79.6851,  0.1000,\n",
      "          0.1000, 79.6851, 79.6851,  0.1000, 79.6851,  0.1000, 79.6851, 79.7555,\n",
      "         79.7555, 79.7555,  0.1000,  0.1000, 79.7555, 79.7555,  0.1000, 79.7555,\n",
      "          0.1000, 79.7555, 79.7385, 79.7555, 79.7555, 79.7555, 79.6851, 79.7555,\n",
      "         79.7555, 79.7555, 79.7385, 79.7555, 79.7555, 79.7555, 79.7385, 79.6851,\n",
      "         79.7385, 79.7385, 79.7385,  0.1000, 79.7385, 79.6851,  0.1000, 79.6851,\n",
      "         79.7555,  0.1000, 79.7555, 79.7555, 79.7555, 79.7385, 79.7385,  0.1000,\n",
      "         79.7555,  0.1000, 79.6447, 79.6447, 79.7385, 79.7555, 79.7555,  0.1000,\n",
      "          0.1000, 79.6447, 79.7385, 79.7555,  0.1000, 79.7385, 79.7555,  0.1000,\n",
      "         79.6447, 79.7555]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 668 was 99.0%\n",
      "current params: tensor([79.6447, 79.7385, 79.6851, 79.7555], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.2\n",
      "SLow rates:  tensor([[79.7447, 79.8385, 79.7851, 79.8556,  0.1000,  0.1000,  0.1000, 79.7447,\n",
      "         79.7447, 79.7447,  0.1000,  0.1000, 79.8385, 79.8385, 79.8385,  0.1000,\n",
      "          0.1000, 79.8385, 79.8385,  0.1000, 79.7851, 79.7851, 79.7851,  0.1000,\n",
      "          0.1000, 79.7851, 79.7851,  0.1000, 79.7851,  0.1000, 79.7851, 79.8556,\n",
      "         79.8556, 79.8556,  0.1000,  0.1000, 79.8556, 79.8556,  0.1000, 79.8556,\n",
      "          0.1000, 79.8556, 79.8385, 79.8556, 79.8556, 79.8556, 79.7851, 79.8556,\n",
      "         79.8556, 79.8556, 79.8385, 79.8556, 79.8556, 79.8556, 79.8385, 79.7851,\n",
      "         79.8385, 79.8385, 79.8385,  0.1000, 79.8385, 79.7851,  0.1000, 79.7851,\n",
      "         79.8556,  0.1000, 79.8556, 79.8556, 79.8556, 79.8385, 79.8385,  0.1000,\n",
      "         79.8556,  0.1000, 79.7447, 79.7447, 79.8385, 79.8556, 79.8556,  0.1000,\n",
      "          0.1000, 79.7447, 79.8385, 79.8556,  0.1000, 79.8385, 79.8556,  0.1000,\n",
      "         79.7447, 79.8556]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 669 was 99.0%\n",
      "current params: tensor([79.7447, 79.8385, 79.7851, 79.8556], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.2\n",
      "SLow rates:  tensor([[79.8448, 79.9386, 79.8852, 79.9556,  0.1000,  0.1000,  0.1000, 79.8448,\n",
      "         79.8448, 79.8448,  0.1000,  0.1000, 79.9386, 79.9386, 79.9386,  0.1000,\n",
      "          0.1000, 79.9386, 79.9386,  0.1000, 79.8852, 79.8852, 79.8852,  0.1000,\n",
      "          0.1000, 79.8852, 79.8852,  0.1000, 79.8852,  0.1000, 79.8852, 79.9556,\n",
      "         79.9556, 79.9556,  0.1000,  0.1000, 79.9556, 79.9556,  0.1000, 79.9556,\n",
      "          0.1000, 79.9556, 79.9386, 79.9556, 79.9556, 79.9556, 79.8852, 79.9556,\n",
      "         79.9556, 79.9556, 79.9386, 79.9556, 79.9556, 79.9556, 79.9386, 79.8852,\n",
      "         79.9386, 79.9386, 79.9386,  0.1000, 79.9386, 79.8852,  0.1000, 79.8852,\n",
      "         79.9556,  0.1000, 79.9556, 79.9556, 79.9556, 79.9386, 79.9386,  0.1000,\n",
      "         79.9556,  0.1000, 79.8448, 79.8448, 79.9386, 79.9556, 79.9556,  0.1000,\n",
      "          0.1000, 79.8448, 79.9386, 79.9556,  0.1000, 79.9386, 79.9556,  0.1000,\n",
      "         79.8448, 79.9556]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 670 was 99.0%\n",
      "current params: tensor([79.8448, 79.9386, 79.8852, 79.9556], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.2\n",
      "SLow rates:  tensor([[79.9448, 80.0386, 79.9852, 80.0557,  0.1000,  0.1000,  0.1000, 79.9448,\n",
      "         79.9448, 79.9448,  0.1000,  0.1000, 80.0386, 80.0386, 80.0386,  0.1000,\n",
      "          0.1000, 80.0386, 80.0386,  0.1000, 79.9852, 79.9852, 79.9852,  0.1000,\n",
      "          0.1000, 79.9852, 79.9852,  0.1000, 79.9852,  0.1000, 79.9852, 80.0557,\n",
      "         80.0557, 80.0557,  0.1000,  0.1000, 80.0557, 80.0557,  0.1000, 80.0557,\n",
      "          0.1000, 80.0557, 80.0386, 80.0557, 80.0557, 80.0557, 79.9852, 80.0557,\n",
      "         80.0557, 80.0557, 80.0386, 80.0557, 80.0557, 80.0557, 80.0386, 79.9852,\n",
      "         80.0386, 80.0386, 80.0386,  0.1000, 80.0386, 79.9852,  0.1000, 79.9852,\n",
      "         80.0557,  0.1000, 80.0557, 80.0557, 80.0557, 80.0386, 80.0386,  0.1000,\n",
      "         80.0557,  0.1000, 79.9448, 79.9448, 80.0386, 80.0557, 80.0557,  0.1000,\n",
      "          0.1000, 79.9448, 80.0386, 80.0557,  0.1000, 80.0386, 80.0557,  0.1000,\n",
      "         79.9448, 80.0557]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 671 was 99.0%\n",
      "current params: tensor([79.9448, 80.0386, 79.9852, 80.0557], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.2\n",
      "SLow rates:  tensor([[80.0449, 80.1387, 80.0853, 80.1557,  0.1000,  0.1000,  0.1000, 80.0449,\n",
      "         80.0449, 80.0449,  0.1000,  0.1000, 80.1387, 80.1387, 80.1387,  0.1000,\n",
      "          0.1000, 80.1387, 80.1387,  0.1000, 80.0853, 80.0853, 80.0853,  0.1000,\n",
      "          0.1000, 80.0853, 80.0853,  0.1000, 80.0853,  0.1000, 80.0853, 80.1557,\n",
      "         80.1557, 80.1557,  0.1000,  0.1000, 80.1557, 80.1557,  0.1000, 80.1557,\n",
      "          0.1000, 80.1557, 80.1387, 80.1557, 80.1557, 80.1557, 80.0853, 80.1557,\n",
      "         80.1557, 80.1557, 80.1387, 80.1557, 80.1557, 80.1557, 80.1387, 80.0853,\n",
      "         80.1387, 80.1387, 80.1387,  0.1000, 80.1387, 80.0853,  0.1000, 80.0853,\n",
      "         80.1557,  0.1000, 80.1557, 80.1557, 80.1557, 80.1387, 80.1387,  0.1000,\n",
      "         80.1557,  0.1000, 80.0449, 80.0449, 80.1387, 80.1557, 80.1557,  0.1000,\n",
      "          0.1000, 80.0449, 80.1387, 80.1557,  0.1000, 80.1387, 80.1557,  0.1000,\n",
      "         80.0449, 80.1557]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 672 was 99.0%\n",
      "current params: tensor([80.0449, 80.1387, 80.0853, 80.1557], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.2\n",
      "SLow rates:  tensor([[80.1449, 80.2387, 80.1853, 80.2558,  0.1000,  0.1000,  0.1000, 80.1449,\n",
      "         80.1449, 80.1449,  0.1000,  0.1000, 80.2387, 80.2387, 80.2387,  0.1000,\n",
      "          0.1000, 80.2387, 80.2387,  0.1000, 80.1853, 80.1853, 80.1853,  0.1000,\n",
      "          0.1000, 80.1853, 80.1853,  0.1000, 80.1853,  0.1000, 80.1853, 80.2558,\n",
      "         80.2558, 80.2558,  0.1000,  0.1000, 80.2558, 80.2558,  0.1000, 80.2558,\n",
      "          0.1000, 80.2558, 80.2387, 80.2558, 80.2558, 80.2558, 80.1853, 80.2558,\n",
      "         80.2558, 80.2558, 80.2387, 80.2558, 80.2558, 80.2558, 80.2387, 80.1853,\n",
      "         80.2387, 80.2387, 80.2387,  0.1000, 80.2387, 80.1853,  0.1000, 80.1853,\n",
      "         80.2558,  0.1000, 80.2558, 80.2558, 80.2558, 80.2387, 80.2387,  0.1000,\n",
      "         80.2558,  0.1000, 80.1449, 80.1449, 80.2387, 80.2558, 80.2558,  0.1000,\n",
      "          0.1000, 80.1449, 80.2387, 80.2558,  0.1000, 80.2387, 80.2558,  0.1000,\n",
      "         80.1449, 80.2558]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 673 was 99.0%\n",
      "current params: tensor([80.1449, 80.2387, 80.1853, 80.2558], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.3\n",
      "SLow rates:  tensor([[80.2450, 80.3388, 80.2854, 80.3558,  0.1000,  0.1000,  0.1000, 80.2450,\n",
      "         80.2450, 80.2450,  0.1000,  0.1000, 80.3388, 80.3388, 80.3388,  0.1000,\n",
      "          0.1000, 80.3388, 80.3388,  0.1000, 80.2854, 80.2854, 80.2854,  0.1000,\n",
      "          0.1000, 80.2854, 80.2854,  0.1000, 80.2854,  0.1000, 80.2854, 80.3558,\n",
      "         80.3558, 80.3558,  0.1000,  0.1000, 80.3558, 80.3558,  0.1000, 80.3558,\n",
      "          0.1000, 80.3558, 80.3388, 80.3558, 80.3558, 80.3558, 80.2854, 80.3558,\n",
      "         80.3558, 80.3558, 80.3388, 80.3558, 80.3558, 80.3558, 80.3388, 80.2854,\n",
      "         80.3388, 80.3388, 80.3388,  0.1000, 80.3388, 80.2854,  0.1000, 80.2854,\n",
      "         80.3558,  0.1000, 80.3558, 80.3558, 80.3558, 80.3388, 80.3388,  0.1000,\n",
      "         80.3558,  0.1000, 80.2450, 80.2450, 80.3388, 80.3558, 80.3558,  0.1000,\n",
      "          0.1000, 80.2450, 80.3388, 80.3558,  0.1000, 80.3388, 80.3558,  0.1000,\n",
      "         80.2450, 80.3558]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 674 was 99.0%\n",
      "current params: tensor([80.2450, 80.3388, 80.2854, 80.3558], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.3\n",
      "SLow rates:  tensor([[80.3450, 80.4388, 80.3854, 80.4559,  0.1000,  0.1000,  0.1000, 80.3450,\n",
      "         80.3450, 80.3450,  0.1000,  0.1000, 80.4388, 80.4388, 80.4388,  0.1000,\n",
      "          0.1000, 80.4388, 80.4388,  0.1000, 80.3854, 80.3854, 80.3854,  0.1000,\n",
      "          0.1000, 80.3854, 80.3854,  0.1000, 80.3854,  0.1000, 80.3854, 80.4559,\n",
      "         80.4559, 80.4559,  0.1000,  0.1000, 80.4559, 80.4559,  0.1000, 80.4559,\n",
      "          0.1000, 80.4559, 80.4388, 80.4559, 80.4559, 80.4559, 80.3854, 80.4559,\n",
      "         80.4559, 80.4559, 80.4388, 80.4559, 80.4559, 80.4559, 80.4388, 80.3854,\n",
      "         80.4388, 80.4388, 80.4388,  0.1000, 80.4388, 80.3854,  0.1000, 80.3854,\n",
      "         80.4559,  0.1000, 80.4559, 80.4559, 80.4559, 80.4388, 80.4388,  0.1000,\n",
      "         80.4559,  0.1000, 80.3450, 80.3450, 80.4388, 80.4559, 80.4559,  0.1000,\n",
      "          0.1000, 80.3450, 80.4388, 80.4559,  0.1000, 80.4388, 80.4559,  0.1000,\n",
      "         80.3450, 80.4559]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 675 was 99.0%\n",
      "current params: tensor([80.3450, 80.4388, 80.3854, 80.4559], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.3\n",
      "SLow rates:  tensor([[80.4451, 80.5389, 80.4855, 80.5559,  0.1000,  0.1000,  0.1000, 80.4451,\n",
      "         80.4451, 80.4451,  0.1000,  0.1000, 80.5389, 80.5389, 80.5389,  0.1000,\n",
      "          0.1000, 80.5389, 80.5389,  0.1000, 80.4855, 80.4855, 80.4855,  0.1000,\n",
      "          0.1000, 80.4855, 80.4855,  0.1000, 80.4855,  0.1000, 80.4855, 80.5559,\n",
      "         80.5559, 80.5559,  0.1000,  0.1000, 80.5559, 80.5559,  0.1000, 80.5559,\n",
      "          0.1000, 80.5559, 80.5389, 80.5559, 80.5559, 80.5559, 80.4855, 80.5559,\n",
      "         80.5559, 80.5559, 80.5389, 80.5559, 80.5559, 80.5559, 80.5389, 80.4855,\n",
      "         80.5389, 80.5389, 80.5389,  0.1000, 80.5389, 80.4855,  0.1000, 80.4855,\n",
      "         80.5559,  0.1000, 80.5559, 80.5559, 80.5559, 80.5389, 80.5389,  0.1000,\n",
      "         80.5559,  0.1000, 80.4451, 80.4451, 80.5389, 80.5559, 80.5559,  0.1000,\n",
      "          0.1000, 80.4451, 80.5389, 80.5559,  0.1000, 80.5389, 80.5559,  0.1000,\n",
      "         80.4451, 80.5559]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 676 was 99.0%\n",
      "current params: tensor([80.4451, 80.5389, 80.4855, 80.5559], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.3\n",
      "SLow rates:  tensor([[80.5451, 80.6389, 80.5855, 80.6560,  0.1000,  0.1000,  0.1000, 80.5451,\n",
      "         80.5451, 80.5451,  0.1000,  0.1000, 80.6389, 80.6389, 80.6389,  0.1000,\n",
      "          0.1000, 80.6389, 80.6389,  0.1000, 80.5855, 80.5855, 80.5855,  0.1000,\n",
      "          0.1000, 80.5855, 80.5855,  0.1000, 80.5855,  0.1000, 80.5855, 80.6560,\n",
      "         80.6560, 80.6560,  0.1000,  0.1000, 80.6560, 80.6560,  0.1000, 80.6560,\n",
      "          0.1000, 80.6560, 80.6389, 80.6560, 80.6560, 80.6560, 80.5855, 80.6560,\n",
      "         80.6560, 80.6560, 80.6389, 80.6560, 80.6560, 80.6560, 80.6389, 80.5855,\n",
      "         80.6389, 80.6389, 80.6389,  0.1000, 80.6389, 80.5855,  0.1000, 80.5855,\n",
      "         80.6560,  0.1000, 80.6560, 80.6560, 80.6560, 80.6389, 80.6389,  0.1000,\n",
      "         80.6560,  0.1000, 80.5451, 80.5451, 80.6389, 80.6560, 80.6560,  0.1000,\n",
      "          0.1000, 80.5451, 80.6389, 80.6560,  0.1000, 80.6389, 80.6560,  0.1000,\n",
      "         80.5451, 80.6560]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 677 was 99.0%\n",
      "current params: tensor([80.5451, 80.6389, 80.5855, 80.6560], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.3\n",
      "SLow rates:  tensor([[80.6452, 80.7390, 80.6856, 80.7560,  0.1000,  0.1000,  0.1000, 80.6452,\n",
      "         80.6452, 80.6452,  0.1000,  0.1000, 80.7390, 80.7390, 80.7390,  0.1000,\n",
      "          0.1000, 80.7390, 80.7390,  0.1000, 80.6856, 80.6856, 80.6856,  0.1000,\n",
      "          0.1000, 80.6856, 80.6856,  0.1000, 80.6856,  0.1000, 80.6856, 80.7560,\n",
      "         80.7560, 80.7560,  0.1000,  0.1000, 80.7560, 80.7560,  0.1000, 80.7560,\n",
      "          0.1000, 80.7560, 80.7390, 80.7560, 80.7560, 80.7560, 80.6856, 80.7560,\n",
      "         80.7560, 80.7560, 80.7390, 80.7560, 80.7560, 80.7560, 80.7390, 80.6856,\n",
      "         80.7390, 80.7390, 80.7390,  0.1000, 80.7390, 80.6856,  0.1000, 80.6856,\n",
      "         80.7560,  0.1000, 80.7560, 80.7560, 80.7560, 80.7390, 80.7390,  0.1000,\n",
      "         80.7560,  0.1000, 80.6452, 80.6452, 80.7390, 80.7560, 80.7560,  0.1000,\n",
      "          0.1000, 80.6452, 80.7390, 80.7560,  0.1000, 80.7390, 80.7560,  0.1000,\n",
      "         80.6452, 80.7560]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 678 was 99.0%\n",
      "current params: tensor([80.6452, 80.7390, 80.6856, 80.7560], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.4\n",
      "SLow rates:  tensor([[80.7452, 80.8390, 80.7856, 80.8561,  0.1000,  0.1000,  0.1000, 80.7452,\n",
      "         80.7452, 80.7452,  0.1000,  0.1000, 80.8390, 80.8390, 80.8390,  0.1000,\n",
      "          0.1000, 80.8390, 80.8390,  0.1000, 80.7856, 80.7856, 80.7856,  0.1000,\n",
      "          0.1000, 80.7856, 80.7856,  0.1000, 80.7856,  0.1000, 80.7856, 80.8561,\n",
      "         80.8561, 80.8561,  0.1000,  0.1000, 80.8561, 80.8561,  0.1000, 80.8561,\n",
      "          0.1000, 80.8561, 80.8390, 80.8561, 80.8561, 80.8561, 80.7856, 80.8561,\n",
      "         80.8561, 80.8561, 80.8390, 80.8561, 80.8561, 80.8561, 80.8390, 80.7856,\n",
      "         80.8390, 80.8390, 80.8390,  0.1000, 80.8390, 80.7856,  0.1000, 80.7856,\n",
      "         80.8561,  0.1000, 80.8561, 80.8561, 80.8561, 80.8390, 80.8390,  0.1000,\n",
      "         80.8561,  0.1000, 80.7452, 80.7452, 80.8390, 80.8561, 80.8561,  0.1000,\n",
      "          0.1000, 80.7452, 80.8390, 80.8561,  0.1000, 80.8390, 80.8561,  0.1000,\n",
      "         80.7452, 80.8561]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 679 was 99.0%\n",
      "current params: tensor([80.7452, 80.8390, 80.7856, 80.8561], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.4\n",
      "SLow rates:  tensor([[80.8453, 80.9391, 80.8857, 80.9561,  0.1000,  0.1000,  0.1000, 80.8453,\n",
      "         80.8453, 80.8453,  0.1000,  0.1000, 80.9391, 80.9391, 80.9391,  0.1000,\n",
      "          0.1000, 80.9391, 80.9391,  0.1000, 80.8857, 80.8857, 80.8857,  0.1000,\n",
      "          0.1000, 80.8857, 80.8857,  0.1000, 80.8857,  0.1000, 80.8857, 80.9561,\n",
      "         80.9561, 80.9561,  0.1000,  0.1000, 80.9561, 80.9561,  0.1000, 80.9561,\n",
      "          0.1000, 80.9561, 80.9391, 80.9561, 80.9561, 80.9561, 80.8857, 80.9561,\n",
      "         80.9561, 80.9561, 80.9391, 80.9561, 80.9561, 80.9561, 80.9391, 80.8857,\n",
      "         80.9391, 80.9391, 80.9391,  0.1000, 80.9391, 80.8857,  0.1000, 80.8857,\n",
      "         80.9561,  0.1000, 80.9561, 80.9561, 80.9561, 80.9391, 80.9391,  0.1000,\n",
      "         80.9561,  0.1000, 80.8453, 80.8453, 80.9391, 80.9561, 80.9561,  0.1000,\n",
      "          0.1000, 80.8453, 80.9391, 80.9561,  0.1000, 80.9391, 80.9561,  0.1000,\n",
      "         80.8453, 80.9561]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 680 was 99.0%\n",
      "current params: tensor([80.8453, 80.9391, 80.8857, 80.9561], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.4\n",
      "SLow rates:  tensor([[80.9453, 81.0391, 80.9857, 81.0562,  0.1000,  0.1000,  0.1000, 80.9453,\n",
      "         80.9453, 80.9453,  0.1000,  0.1000, 81.0391, 81.0391, 81.0391,  0.1000,\n",
      "          0.1000, 81.0391, 81.0391,  0.1000, 80.9857, 80.9857, 80.9857,  0.1000,\n",
      "          0.1000, 80.9857, 80.9857,  0.1000, 80.9857,  0.1000, 80.9857, 81.0562,\n",
      "         81.0562, 81.0562,  0.1000,  0.1000, 81.0562, 81.0562,  0.1000, 81.0562,\n",
      "          0.1000, 81.0562, 81.0391, 81.0562, 81.0562, 81.0562, 80.9857, 81.0562,\n",
      "         81.0562, 81.0562, 81.0391, 81.0562, 81.0562, 81.0562, 81.0391, 80.9857,\n",
      "         81.0391, 81.0391, 81.0391,  0.1000, 81.0391, 80.9857,  0.1000, 80.9857,\n",
      "         81.0562,  0.1000, 81.0562, 81.0562, 81.0562, 81.0391, 81.0391,  0.1000,\n",
      "         81.0562,  0.1000, 80.9453, 80.9453, 81.0391, 81.0562, 81.0562,  0.1000,\n",
      "          0.1000, 80.9453, 81.0391, 81.0562,  0.1000, 81.0391, 81.0562,  0.1000,\n",
      "         80.9453, 81.0562]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 681 was 99.0%\n",
      "current params: tensor([80.9453, 81.0391, 80.9857, 81.0562], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.4\n",
      "SLow rates:  tensor([[81.0454, 81.1392, 81.0858, 81.1562,  0.1000,  0.1000,  0.1000, 81.0454,\n",
      "         81.0454, 81.0454,  0.1000,  0.1000, 81.1392, 81.1392, 81.1392,  0.1000,\n",
      "          0.1000, 81.1392, 81.1392,  0.1000, 81.0858, 81.0858, 81.0858,  0.1000,\n",
      "          0.1000, 81.0858, 81.0858,  0.1000, 81.0858,  0.1000, 81.0858, 81.1562,\n",
      "         81.1562, 81.1562,  0.1000,  0.1000, 81.1562, 81.1562,  0.1000, 81.1562,\n",
      "          0.1000, 81.1562, 81.1392, 81.1562, 81.1562, 81.1562, 81.0858, 81.1562,\n",
      "         81.1562, 81.1562, 81.1392, 81.1562, 81.1562, 81.1562, 81.1392, 81.0858,\n",
      "         81.1392, 81.1392, 81.1392,  0.1000, 81.1392, 81.0858,  0.1000, 81.0858,\n",
      "         81.1562,  0.1000, 81.1562, 81.1562, 81.1562, 81.1392, 81.1392,  0.1000,\n",
      "         81.1562,  0.1000, 81.0454, 81.0454, 81.1392, 81.1562, 81.1562,  0.1000,\n",
      "          0.1000, 81.0454, 81.1392, 81.1562,  0.1000, 81.1392, 81.1562,  0.1000,\n",
      "         81.0454, 81.1562]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 682 was 99.0%\n",
      "current params: tensor([81.0454, 81.1392, 81.0858, 81.1562], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.4\n",
      "SLow rates:  tensor([[81.1454, 81.2392, 81.1858, 81.2562,  0.1000,  0.1000,  0.1000, 81.1454,\n",
      "         81.1454, 81.1454,  0.1000,  0.1000, 81.2392, 81.2392, 81.2392,  0.1000,\n",
      "          0.1000, 81.2392, 81.2392,  0.1000, 81.1858, 81.1858, 81.1858,  0.1000,\n",
      "          0.1000, 81.1858, 81.1858,  0.1000, 81.1858,  0.1000, 81.1858, 81.2562,\n",
      "         81.2562, 81.2562,  0.1000,  0.1000, 81.2562, 81.2562,  0.1000, 81.2562,\n",
      "          0.1000, 81.2562, 81.2392, 81.2562, 81.2562, 81.2562, 81.1858, 81.2562,\n",
      "         81.2562, 81.2562, 81.2392, 81.2562, 81.2562, 81.2562, 81.2392, 81.1858,\n",
      "         81.2392, 81.2392, 81.2392,  0.1000, 81.2392, 81.1858,  0.1000, 81.1858,\n",
      "         81.2562,  0.1000, 81.2562, 81.2562, 81.2562, 81.2392, 81.2392,  0.1000,\n",
      "         81.2562,  0.1000, 81.1454, 81.1454, 81.2392, 81.2562, 81.2562,  0.1000,\n",
      "          0.1000, 81.1454, 81.2392, 81.2562,  0.1000, 81.2392, 81.2562,  0.1000,\n",
      "         81.1454, 81.2562]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 683 was 99.0%\n",
      "current params: tensor([81.1454, 81.2392, 81.1858, 81.2562], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "SLow rates:  tensor([[81.2455, 81.3392, 81.2859, 81.3563,  0.1000,  0.1000,  0.1000, 81.2455,\n",
      "         81.2455, 81.2455,  0.1000,  0.1000, 81.3392, 81.3392, 81.3392,  0.1000,\n",
      "          0.1000, 81.3392, 81.3392,  0.1000, 81.2859, 81.2859, 81.2859,  0.1000,\n",
      "          0.1000, 81.2859, 81.2859,  0.1000, 81.2859,  0.1000, 81.2859, 81.3563,\n",
      "         81.3563, 81.3563,  0.1000,  0.1000, 81.3563, 81.3563,  0.1000, 81.3563,\n",
      "          0.1000, 81.3563, 81.3392, 81.3563, 81.3563, 81.3563, 81.2859, 81.3563,\n",
      "         81.3563, 81.3563, 81.3392, 81.3563, 81.3563, 81.3563, 81.3392, 81.2859,\n",
      "         81.3392, 81.3392, 81.3392,  0.1000, 81.3392, 81.2859,  0.1000, 81.2859,\n",
      "         81.3563,  0.1000, 81.3563, 81.3563, 81.3563, 81.3392, 81.3392,  0.1000,\n",
      "         81.3563,  0.1000, 81.2455, 81.2455, 81.3392, 81.3563, 81.3563,  0.1000,\n",
      "          0.1000, 81.2455, 81.3392, 81.3563,  0.1000, 81.3392, 81.3563,  0.1000,\n",
      "         81.2455, 81.3563]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 684 was 99.0%\n",
      "current params: tensor([81.2455, 81.3392, 81.2859, 81.3563], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "SLow rates:  tensor([[81.3455, 81.4393, 81.3859, 81.4563,  0.1000,  0.1000,  0.1000, 81.3455,\n",
      "         81.3455, 81.3455,  0.1000,  0.1000, 81.4393, 81.4393, 81.4393,  0.1000,\n",
      "          0.1000, 81.4393, 81.4393,  0.1000, 81.3859, 81.3859, 81.3859,  0.1000,\n",
      "          0.1000, 81.3859, 81.3859,  0.1000, 81.3859,  0.1000, 81.3859, 81.4563,\n",
      "         81.4563, 81.4563,  0.1000,  0.1000, 81.4563, 81.4563,  0.1000, 81.4563,\n",
      "          0.1000, 81.4563, 81.4393, 81.4563, 81.4563, 81.4563, 81.3859, 81.4563,\n",
      "         81.4563, 81.4563, 81.4393, 81.4563, 81.4563, 81.4563, 81.4393, 81.3859,\n",
      "         81.4393, 81.4393, 81.4393,  0.1000, 81.4393, 81.3859,  0.1000, 81.3859,\n",
      "         81.4563,  0.1000, 81.4563, 81.4563, 81.4563, 81.4393, 81.4393,  0.1000,\n",
      "         81.4563,  0.1000, 81.3455, 81.3455, 81.4393, 81.4563, 81.4563,  0.1000,\n",
      "          0.1000, 81.3455, 81.4393, 81.4563,  0.1000, 81.4393, 81.4563,  0.1000,\n",
      "         81.3455, 81.4563]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 685 was 99.0%\n",
      "current params: tensor([81.3455, 81.4393, 81.3859, 81.4563], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "SLow rates:  tensor([[81.4456, 81.5393, 81.4860, 81.5564,  0.1000,  0.1000,  0.1000, 81.4456,\n",
      "         81.4456, 81.4456,  0.1000,  0.1000, 81.5393, 81.5393, 81.5393,  0.1000,\n",
      "          0.1000, 81.5393, 81.5393,  0.1000, 81.4860, 81.4860, 81.4860,  0.1000,\n",
      "          0.1000, 81.4860, 81.4860,  0.1000, 81.4860,  0.1000, 81.4860, 81.5564,\n",
      "         81.5564, 81.5564,  0.1000,  0.1000, 81.5564, 81.5564,  0.1000, 81.5564,\n",
      "          0.1000, 81.5564, 81.5393, 81.5564, 81.5564, 81.5564, 81.4860, 81.5564,\n",
      "         81.5564, 81.5564, 81.5393, 81.5564, 81.5564, 81.5564, 81.5393, 81.4860,\n",
      "         81.5393, 81.5393, 81.5393,  0.1000, 81.5393, 81.4860,  0.1000, 81.4860,\n",
      "         81.5564,  0.1000, 81.5564, 81.5564, 81.5564, 81.5393, 81.5393,  0.1000,\n",
      "         81.5564,  0.1000, 81.4456, 81.4456, 81.5393, 81.5564, 81.5564,  0.1000,\n",
      "          0.1000, 81.4456, 81.5393, 81.5564,  0.1000, 81.5393, 81.5564,  0.1000,\n",
      "         81.4456, 81.5564]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 686 was 99.0%\n",
      "current params: tensor([81.4456, 81.5393, 81.4860, 81.5564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "SLow rates:  tensor([[81.5456, 81.6394, 81.5860, 81.6564,  0.1000,  0.1000,  0.1000, 81.5456,\n",
      "         81.5456, 81.5456,  0.1000,  0.1000, 81.6394, 81.6394, 81.6394,  0.1000,\n",
      "          0.1000, 81.6394, 81.6394,  0.1000, 81.5860, 81.5860, 81.5860,  0.1000,\n",
      "          0.1000, 81.5860, 81.5860,  0.1000, 81.5860,  0.1000, 81.5860, 81.6564,\n",
      "         81.6564, 81.6564,  0.1000,  0.1000, 81.6564, 81.6564,  0.1000, 81.6564,\n",
      "          0.1000, 81.6564, 81.6394, 81.6564, 81.6564, 81.6564, 81.5860, 81.6564,\n",
      "         81.6564, 81.6564, 81.6394, 81.6564, 81.6564, 81.6564, 81.6394, 81.5860,\n",
      "         81.6394, 81.6394, 81.6394,  0.1000, 81.6394, 81.5860,  0.1000, 81.5860,\n",
      "         81.6564,  0.1000, 81.6564, 81.6564, 81.6564, 81.6394, 81.6394,  0.1000,\n",
      "         81.6564,  0.1000, 81.5456, 81.5456, 81.6394, 81.6564, 81.6564,  0.1000,\n",
      "          0.1000, 81.5456, 81.6394, 81.6564,  0.1000, 81.6394, 81.6564,  0.1000,\n",
      "         81.5456, 81.6564]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 687 was 99.0%\n",
      "current params: tensor([81.5456, 81.6394, 81.5860, 81.6564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "SLow rates:  tensor([[81.6456, 81.7394, 81.6860, 81.7564,  0.1000,  0.1000,  0.1000, 81.6456,\n",
      "         81.6456, 81.6456,  0.1000,  0.1000, 81.7394, 81.7394, 81.7394,  0.1000,\n",
      "          0.1000, 81.7394, 81.7394,  0.1000, 81.6860, 81.6860, 81.6860,  0.1000,\n",
      "          0.1000, 81.6860, 81.6860,  0.1000, 81.6860,  0.1000, 81.6860, 81.7564,\n",
      "         81.7564, 81.7564,  0.1000,  0.1000, 81.7564, 81.7564,  0.1000, 81.7564,\n",
      "          0.1000, 81.7564, 81.7394, 81.7564, 81.7564, 81.7564, 81.6860, 81.7564,\n",
      "         81.7564, 81.7564, 81.7394, 81.7564, 81.7564, 81.7564, 81.7394, 81.6860,\n",
      "         81.7394, 81.7394, 81.7394,  0.1000, 81.7394, 81.6860,  0.1000, 81.6860,\n",
      "         81.7564,  0.1000, 81.7564, 81.7564, 81.7564, 81.7394, 81.7394,  0.1000,\n",
      "         81.7564,  0.1000, 81.6456, 81.6456, 81.7394, 81.7564, 81.7564,  0.1000,\n",
      "          0.1000, 81.6456, 81.7394, 81.7564,  0.1000, 81.7394, 81.7564,  0.1000,\n",
      "         81.6456, 81.7564]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 688 was 99.0%\n",
      "current params: tensor([81.6456, 81.7394, 81.6860, 81.7564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "SLow rates:  tensor([[81.7457, 81.8395, 81.7861, 81.8565,  0.1000,  0.1000,  0.1000, 81.7457,\n",
      "         81.7457, 81.7457,  0.1000,  0.1000, 81.8395, 81.8395, 81.8395,  0.1000,\n",
      "          0.1000, 81.8395, 81.8395,  0.1000, 81.7861, 81.7861, 81.7861,  0.1000,\n",
      "          0.1000, 81.7861, 81.7861,  0.1000, 81.7861,  0.1000, 81.7861, 81.8565,\n",
      "         81.8565, 81.8565,  0.1000,  0.1000, 81.8565, 81.8565,  0.1000, 81.8565,\n",
      "          0.1000, 81.8565, 81.8395, 81.8565, 81.8565, 81.8565, 81.7861, 81.8565,\n",
      "         81.8565, 81.8565, 81.8395, 81.8565, 81.8565, 81.8565, 81.8395, 81.7861,\n",
      "         81.8395, 81.8395, 81.8395,  0.1000, 81.8395, 81.7861,  0.1000, 81.7861,\n",
      "         81.8565,  0.1000, 81.8565, 81.8565, 81.8565, 81.8395, 81.8395,  0.1000,\n",
      "         81.8565,  0.1000, 81.7457, 81.7457, 81.8395, 81.8565, 81.8565,  0.1000,\n",
      "          0.1000, 81.7457, 81.8395, 81.8565,  0.1000, 81.8395, 81.8565,  0.1000,\n",
      "         81.7457, 81.8565]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 689 was 99.0%\n",
      "current params: tensor([81.7457, 81.8395, 81.7861, 81.8565], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.6\n",
      "SLow rates:  tensor([[81.8457, 81.9395, 81.8861, 81.9565,  0.1000,  0.1000,  0.1000, 81.8457,\n",
      "         81.8457, 81.8457,  0.1000,  0.1000, 81.9395, 81.9395, 81.9395,  0.1000,\n",
      "          0.1000, 81.9395, 81.9395,  0.1000, 81.8861, 81.8861, 81.8861,  0.1000,\n",
      "          0.1000, 81.8861, 81.8861,  0.1000, 81.8861,  0.1000, 81.8861, 81.9565,\n",
      "         81.9565, 81.9565,  0.1000,  0.1000, 81.9565, 81.9565,  0.1000, 81.9565,\n",
      "          0.1000, 81.9565, 81.9395, 81.9565, 81.9565, 81.9565, 81.8861, 81.9565,\n",
      "         81.9565, 81.9565, 81.9395, 81.9565, 81.9565, 81.9565, 81.9395, 81.8861,\n",
      "         81.9395, 81.9395, 81.9395,  0.1000, 81.9395, 81.8861,  0.1000, 81.8861,\n",
      "         81.9565,  0.1000, 81.9565, 81.9565, 81.9565, 81.9395, 81.9395,  0.1000,\n",
      "         81.9565,  0.1000, 81.8457, 81.8457, 81.9395, 81.9565, 81.9565,  0.1000,\n",
      "          0.1000, 81.8457, 81.9395, 81.9565,  0.1000, 81.9395, 81.9565,  0.1000,\n",
      "         81.8457, 81.9565]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 690 was 99.0%\n",
      "current params: tensor([81.8457, 81.9395, 81.8861, 81.9565], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.6\n",
      "SLow rates:  tensor([[81.9458, 82.0395, 81.9862, 82.0566,  0.1000,  0.1000,  0.1000, 81.9458,\n",
      "         81.9458, 81.9458,  0.1000,  0.1000, 82.0395, 82.0395, 82.0395,  0.1000,\n",
      "          0.1000, 82.0395, 82.0395,  0.1000, 81.9862, 81.9862, 81.9862,  0.1000,\n",
      "          0.1000, 81.9862, 81.9862,  0.1000, 81.9862,  0.1000, 81.9862, 82.0566,\n",
      "         82.0566, 82.0566,  0.1000,  0.1000, 82.0566, 82.0566,  0.1000, 82.0566,\n",
      "          0.1000, 82.0566, 82.0395, 82.0566, 82.0566, 82.0566, 81.9862, 82.0566,\n",
      "         82.0566, 82.0566, 82.0395, 82.0566, 82.0566, 82.0566, 82.0395, 81.9862,\n",
      "         82.0395, 82.0395, 82.0395,  0.1000, 82.0395, 81.9862,  0.1000, 81.9862,\n",
      "         82.0566,  0.1000, 82.0566, 82.0566, 82.0566, 82.0395, 82.0395,  0.1000,\n",
      "         82.0566,  0.1000, 81.9458, 81.9458, 82.0395, 82.0566, 82.0566,  0.1000,\n",
      "          0.1000, 81.9458, 82.0395, 82.0566,  0.1000, 82.0395, 82.0566,  0.1000,\n",
      "         81.9458, 82.0566]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 691 was 99.0%\n",
      "current params: tensor([81.9458, 82.0395, 81.9862, 82.0566], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.6\n",
      "SLow rates:  tensor([[82.0458, 82.1396, 82.0862, 82.1566,  0.1000,  0.1000,  0.1000, 82.0458,\n",
      "         82.0458, 82.0458,  0.1000,  0.1000, 82.1396, 82.1396, 82.1396,  0.1000,\n",
      "          0.1000, 82.1396, 82.1396,  0.1000, 82.0862, 82.0862, 82.0862,  0.1000,\n",
      "          0.1000, 82.0862, 82.0862,  0.1000, 82.0862,  0.1000, 82.0862, 82.1566,\n",
      "         82.1566, 82.1566,  0.1000,  0.1000, 82.1566, 82.1566,  0.1000, 82.1566,\n",
      "          0.1000, 82.1566, 82.1396, 82.1566, 82.1566, 82.1566, 82.0862, 82.1566,\n",
      "         82.1566, 82.1566, 82.1396, 82.1566, 82.1566, 82.1566, 82.1396, 82.0862,\n",
      "         82.1396, 82.1396, 82.1396,  0.1000, 82.1396, 82.0862,  0.1000, 82.0862,\n",
      "         82.1566,  0.1000, 82.1566, 82.1566, 82.1566, 82.1396, 82.1396,  0.1000,\n",
      "         82.1566,  0.1000, 82.0458, 82.0458, 82.1396, 82.1566, 82.1566,  0.1000,\n",
      "          0.1000, 82.0458, 82.1396, 82.1566,  0.1000, 82.1396, 82.1566,  0.1000,\n",
      "         82.0458, 82.1566]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 692 was 99.0%\n",
      "current params: tensor([82.0458, 82.1396, 82.0862, 82.1566], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.6\n",
      "SLow rates:  tensor([[82.1459, 82.2396, 82.1863, 82.2566,  0.1000,  0.1000,  0.1000, 82.1459,\n",
      "         82.1459, 82.1459,  0.1000,  0.1000, 82.2396, 82.2396, 82.2396,  0.1000,\n",
      "          0.1000, 82.2396, 82.2396,  0.1000, 82.1863, 82.1863, 82.1863,  0.1000,\n",
      "          0.1000, 82.1863, 82.1863,  0.1000, 82.1863,  0.1000, 82.1863, 82.2566,\n",
      "         82.2566, 82.2566,  0.1000,  0.1000, 82.2566, 82.2566,  0.1000, 82.2566,\n",
      "          0.1000, 82.2566, 82.2396, 82.2566, 82.2566, 82.2566, 82.1863, 82.2566,\n",
      "         82.2566, 82.2566, 82.2396, 82.2566, 82.2566, 82.2566, 82.2396, 82.1863,\n",
      "         82.2396, 82.2396, 82.2396,  0.1000, 82.2396, 82.1863,  0.1000, 82.1863,\n",
      "         82.2566,  0.1000, 82.2566, 82.2566, 82.2566, 82.2396, 82.2396,  0.1000,\n",
      "         82.2566,  0.1000, 82.1459, 82.1459, 82.2396, 82.2566, 82.2566,  0.1000,\n",
      "          0.1000, 82.1459, 82.2396, 82.2566,  0.1000, 82.2396, 82.2566,  0.1000,\n",
      "         82.1459, 82.2566]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 693 was 99.0%\n",
      "current params: tensor([82.1459, 82.2396, 82.1863, 82.2566], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.6\n",
      "SLow rates:  tensor([[82.2459, 82.3397, 82.2863, 82.3567,  0.1000,  0.1000,  0.1000, 82.2459,\n",
      "         82.2459, 82.2459,  0.1000,  0.1000, 82.3397, 82.3397, 82.3397,  0.1000,\n",
      "          0.1000, 82.3397, 82.3397,  0.1000, 82.2863, 82.2863, 82.2863,  0.1000,\n",
      "          0.1000, 82.2863, 82.2863,  0.1000, 82.2863,  0.1000, 82.2863, 82.3567,\n",
      "         82.3567, 82.3567,  0.1000,  0.1000, 82.3567, 82.3567,  0.1000, 82.3567,\n",
      "          0.1000, 82.3567, 82.3397, 82.3567, 82.3567, 82.3567, 82.2863, 82.3567,\n",
      "         82.3567, 82.3567, 82.3397, 82.3567, 82.3567, 82.3567, 82.3397, 82.2863,\n",
      "         82.3397, 82.3397, 82.3397,  0.1000, 82.3397, 82.2863,  0.1000, 82.2863,\n",
      "         82.3567,  0.1000, 82.3567, 82.3567, 82.3567, 82.3397, 82.3397,  0.1000,\n",
      "         82.3567,  0.1000, 82.2459, 82.2459, 82.3397, 82.3567, 82.3567,  0.1000,\n",
      "          0.1000, 82.2459, 82.3397, 82.3567,  0.1000, 82.3397, 82.3567,  0.1000,\n",
      "         82.2459, 82.3567]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 694 was 99.0%\n",
      "current params: tensor([82.2459, 82.3397, 82.2863, 82.3567], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.7\n",
      "SLow rates:  tensor([[82.3460, 82.4397, 82.3863, 82.4567,  0.1000,  0.1000,  0.1000, 82.3460,\n",
      "         82.3460, 82.3460,  0.1000,  0.1000, 82.4397, 82.4397, 82.4397,  0.1000,\n",
      "          0.1000, 82.4397, 82.4397,  0.1000, 82.3863, 82.3863, 82.3863,  0.1000,\n",
      "          0.1000, 82.3863, 82.3863,  0.1000, 82.3863,  0.1000, 82.3863, 82.4567,\n",
      "         82.4567, 82.4567,  0.1000,  0.1000, 82.4567, 82.4567,  0.1000, 82.4567,\n",
      "          0.1000, 82.4567, 82.4397, 82.4567, 82.4567, 82.4567, 82.3863, 82.4567,\n",
      "         82.4567, 82.4567, 82.4397, 82.4567, 82.4567, 82.4567, 82.4397, 82.3863,\n",
      "         82.4397, 82.4397, 82.4397,  0.1000, 82.4397, 82.3863,  0.1000, 82.3863,\n",
      "         82.4567,  0.1000, 82.4567, 82.4567, 82.4567, 82.4397, 82.4397,  0.1000,\n",
      "         82.4567,  0.1000, 82.3460, 82.3460, 82.4397, 82.4567, 82.4567,  0.1000,\n",
      "          0.1000, 82.3460, 82.4397, 82.4567,  0.1000, 82.4397, 82.4567,  0.1000,\n",
      "         82.3460, 82.4567]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 695 was 99.0%\n",
      "current params: tensor([82.3460, 82.4397, 82.3863, 82.4567], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.7\n",
      "SLow rates:  tensor([[82.4460, 82.5397, 82.4864, 82.5568,  0.1000,  0.1000,  0.1000, 82.4460,\n",
      "         82.4460, 82.4460,  0.1000,  0.1000, 82.5397, 82.5397, 82.5397,  0.1000,\n",
      "          0.1000, 82.5397, 82.5397,  0.1000, 82.4864, 82.4864, 82.4864,  0.1000,\n",
      "          0.1000, 82.4864, 82.4864,  0.1000, 82.4864,  0.1000, 82.4864, 82.5568,\n",
      "         82.5568, 82.5568,  0.1000,  0.1000, 82.5568, 82.5568,  0.1000, 82.5568,\n",
      "          0.1000, 82.5568, 82.5397, 82.5568, 82.5568, 82.5568, 82.4864, 82.5568,\n",
      "         82.5568, 82.5568, 82.5397, 82.5568, 82.5568, 82.5568, 82.5397, 82.4864,\n",
      "         82.5397, 82.5397, 82.5397,  0.1000, 82.5397, 82.4864,  0.1000, 82.4864,\n",
      "         82.5568,  0.1000, 82.5568, 82.5568, 82.5568, 82.5397, 82.5397,  0.1000,\n",
      "         82.5568,  0.1000, 82.4460, 82.4460, 82.5397, 82.5568, 82.5568,  0.1000,\n",
      "          0.1000, 82.4460, 82.5397, 82.5568,  0.1000, 82.5397, 82.5568,  0.1000,\n",
      "         82.4460, 82.5568]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 696 was 99.0%\n",
      "current params: tensor([82.4460, 82.5397, 82.4864, 82.5568], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.7\n",
      "SLow rates:  tensor([[82.5460, 82.6398, 82.5864, 82.6568,  0.1000,  0.1000,  0.1000, 82.5460,\n",
      "         82.5460, 82.5460,  0.1000,  0.1000, 82.6398, 82.6398, 82.6398,  0.1000,\n",
      "          0.1000, 82.6398, 82.6398,  0.1000, 82.5864, 82.5864, 82.5864,  0.1000,\n",
      "          0.1000, 82.5864, 82.5864,  0.1000, 82.5864,  0.1000, 82.5864, 82.6568,\n",
      "         82.6568, 82.6568,  0.1000,  0.1000, 82.6568, 82.6568,  0.1000, 82.6568,\n",
      "          0.1000, 82.6568, 82.6398, 82.6568, 82.6568, 82.6568, 82.5864, 82.6568,\n",
      "         82.6568, 82.6568, 82.6398, 82.6568, 82.6568, 82.6568, 82.6398, 82.5864,\n",
      "         82.6398, 82.6398, 82.6398,  0.1000, 82.6398, 82.5864,  0.1000, 82.5864,\n",
      "         82.6568,  0.1000, 82.6568, 82.6568, 82.6568, 82.6398, 82.6398,  0.1000,\n",
      "         82.6568,  0.1000, 82.5460, 82.5460, 82.6398, 82.6568, 82.6568,  0.1000,\n",
      "          0.1000, 82.5460, 82.6398, 82.6568,  0.1000, 82.6398, 82.6568,  0.1000,\n",
      "         82.5460, 82.6568]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 697 was 99.0%\n",
      "current params: tensor([82.5460, 82.6398, 82.5864, 82.6568], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.7\n",
      "SLow rates:  tensor([[82.6461, 82.7398, 82.6865, 82.7568,  0.1000,  0.1000,  0.1000, 82.6461,\n",
      "         82.6461, 82.6461,  0.1000,  0.1000, 82.7398, 82.7398, 82.7398,  0.1000,\n",
      "          0.1000, 82.7398, 82.7398,  0.1000, 82.6865, 82.6865, 82.6865,  0.1000,\n",
      "          0.1000, 82.6865, 82.6865,  0.1000, 82.6865,  0.1000, 82.6865, 82.7568,\n",
      "         82.7568, 82.7568,  0.1000,  0.1000, 82.7568, 82.7568,  0.1000, 82.7568,\n",
      "          0.1000, 82.7568, 82.7398, 82.7568, 82.7568, 82.7568, 82.6865, 82.7568,\n",
      "         82.7568, 82.7568, 82.7398, 82.7568, 82.7568, 82.7568, 82.7398, 82.6865,\n",
      "         82.7398, 82.7398, 82.7398,  0.1000, 82.7398, 82.6865,  0.1000, 82.6865,\n",
      "         82.7568,  0.1000, 82.7568, 82.7568, 82.7568, 82.7398, 82.7398,  0.1000,\n",
      "         82.7568,  0.1000, 82.6461, 82.6461, 82.7398, 82.7568, 82.7568,  0.1000,\n",
      "          0.1000, 82.6461, 82.7398, 82.7568,  0.1000, 82.7398, 82.7568,  0.1000,\n",
      "         82.6461, 82.7568]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 698 was 99.0%\n",
      "current params: tensor([82.6461, 82.7398, 82.6865, 82.7568], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.7\n",
      "SLow rates:  tensor([[82.7461, 82.8398, 82.7865, 82.8569,  0.1000,  0.1000,  0.1000, 82.7461,\n",
      "         82.7461, 82.7461,  0.1000,  0.1000, 82.8398, 82.8398, 82.8398,  0.1000,\n",
      "          0.1000, 82.8398, 82.8398,  0.1000, 82.7865, 82.7865, 82.7865,  0.1000,\n",
      "          0.1000, 82.7865, 82.7865,  0.1000, 82.7865,  0.1000, 82.7865, 82.8569,\n",
      "         82.8569, 82.8569,  0.1000,  0.1000, 82.8569, 82.8569,  0.1000, 82.8569,\n",
      "          0.1000, 82.8569, 82.8398, 82.8569, 82.8569, 82.8569, 82.7865, 82.8569,\n",
      "         82.8569, 82.8569, 82.8398, 82.8569, 82.8569, 82.8569, 82.8398, 82.7865,\n",
      "         82.8398, 82.8398, 82.8398,  0.1000, 82.8398, 82.7865,  0.1000, 82.7865,\n",
      "         82.8569,  0.1000, 82.8569, 82.8569, 82.8569, 82.8398, 82.8398,  0.1000,\n",
      "         82.8569,  0.1000, 82.7461, 82.7461, 82.8398, 82.8569, 82.8569,  0.1000,\n",
      "          0.1000, 82.7461, 82.8398, 82.8569,  0.1000, 82.8398, 82.8569,  0.1000,\n",
      "         82.7461, 82.8569]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 699 was 99.0%\n",
      "current params: tensor([82.7461, 82.8398, 82.7865, 82.8569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "SLow rates:  tensor([[82.8462, 82.9399, 82.8865, 82.9569,  0.1000,  0.1000,  0.1000, 82.8462,\n",
      "         82.8462, 82.8462,  0.1000,  0.1000, 82.9399, 82.9399, 82.9399,  0.1000,\n",
      "          0.1000, 82.9399, 82.9399,  0.1000, 82.8865, 82.8865, 82.8865,  0.1000,\n",
      "          0.1000, 82.8865, 82.8865,  0.1000, 82.8865,  0.1000, 82.8865, 82.9569,\n",
      "         82.9569, 82.9569,  0.1000,  0.1000, 82.9569, 82.9569,  0.1000, 82.9569,\n",
      "          0.1000, 82.9569, 82.9399, 82.9569, 82.9569, 82.9569, 82.8865, 82.9569,\n",
      "         82.9569, 82.9569, 82.9399, 82.9569, 82.9569, 82.9569, 82.9399, 82.8865,\n",
      "         82.9399, 82.9399, 82.9399,  0.1000, 82.9399, 82.8865,  0.1000, 82.8865,\n",
      "         82.9569,  0.1000, 82.9569, 82.9569, 82.9569, 82.9399, 82.9399,  0.1000,\n",
      "         82.9569,  0.1000, 82.8462, 82.8462, 82.9399, 82.9569, 82.9569,  0.1000,\n",
      "          0.1000, 82.8462, 82.9399, 82.9569,  0.1000, 82.9399, 82.9569,  0.1000,\n",
      "         82.8462, 82.9569]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 700 was 99.0%\n",
      "current params: tensor([82.8462, 82.9399, 82.8865, 82.9569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "SLow rates:  tensor([[82.9462, 83.0399, 82.9866, 83.0569,  0.1000,  0.1000,  0.1000, 82.9462,\n",
      "         82.9462, 82.9462,  0.1000,  0.1000, 83.0399, 83.0399, 83.0399,  0.1000,\n",
      "          0.1000, 83.0399, 83.0399,  0.1000, 82.9866, 82.9866, 82.9866,  0.1000,\n",
      "          0.1000, 82.9866, 82.9866,  0.1000, 82.9866,  0.1000, 82.9866, 83.0569,\n",
      "         83.0569, 83.0569,  0.1000,  0.1000, 83.0569, 83.0569,  0.1000, 83.0569,\n",
      "          0.1000, 83.0569, 83.0399, 83.0569, 83.0569, 83.0569, 82.9866, 83.0569,\n",
      "         83.0569, 83.0569, 83.0399, 83.0569, 83.0569, 83.0569, 83.0399, 82.9866,\n",
      "         83.0399, 83.0399, 83.0399,  0.1000, 83.0399, 82.9866,  0.1000, 82.9866,\n",
      "         83.0569,  0.1000, 83.0569, 83.0569, 83.0569, 83.0399, 83.0399,  0.1000,\n",
      "         83.0569,  0.1000, 82.9462, 82.9462, 83.0399, 83.0569, 83.0569,  0.1000,\n",
      "          0.1000, 82.9462, 83.0399, 83.0569,  0.1000, 83.0399, 83.0569,  0.1000,\n",
      "         82.9462, 83.0569]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 701 was 99.0%\n",
      "current params: tensor([82.9462, 83.0399, 82.9866, 83.0569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "SLow rates:  tensor([[83.0462, 83.1400, 83.0866, 83.1570,  0.1000,  0.1000,  0.1000, 83.0462,\n",
      "         83.0462, 83.0462,  0.1000,  0.1000, 83.1400, 83.1400, 83.1400,  0.1000,\n",
      "          0.1000, 83.1400, 83.1400,  0.1000, 83.0866, 83.0866, 83.0866,  0.1000,\n",
      "          0.1000, 83.0866, 83.0866,  0.1000, 83.0866,  0.1000, 83.0866, 83.1570,\n",
      "         83.1570, 83.1570,  0.1000,  0.1000, 83.1570, 83.1570,  0.1000, 83.1570,\n",
      "          0.1000, 83.1570, 83.1400, 83.1570, 83.1570, 83.1570, 83.0866, 83.1570,\n",
      "         83.1570, 83.1570, 83.1400, 83.1570, 83.1570, 83.1570, 83.1400, 83.0866,\n",
      "         83.1400, 83.1400, 83.1400,  0.1000, 83.1400, 83.0866,  0.1000, 83.0866,\n",
      "         83.1570,  0.1000, 83.1570, 83.1570, 83.1570, 83.1400, 83.1400,  0.1000,\n",
      "         83.1570,  0.1000, 83.0462, 83.0462, 83.1400, 83.1570, 83.1570,  0.1000,\n",
      "          0.1000, 83.0462, 83.1400, 83.1570,  0.1000, 83.1400, 83.1570,  0.1000,\n",
      "         83.0462, 83.1570]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 702 was 99.0%\n",
      "current params: tensor([83.0462, 83.1400, 83.0866, 83.1570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "SLow rates:  tensor([[83.1463, 83.2400, 83.1867, 83.2570,  0.1000,  0.1000,  0.1000, 83.1463,\n",
      "         83.1463, 83.1463,  0.1000,  0.1000, 83.2400, 83.2400, 83.2400,  0.1000,\n",
      "          0.1000, 83.2400, 83.2400,  0.1000, 83.1867, 83.1867, 83.1867,  0.1000,\n",
      "          0.1000, 83.1867, 83.1867,  0.1000, 83.1867,  0.1000, 83.1867, 83.2570,\n",
      "         83.2570, 83.2570,  0.1000,  0.1000, 83.2570, 83.2570,  0.1000, 83.2570,\n",
      "          0.1000, 83.2570, 83.2400, 83.2570, 83.2570, 83.2570, 83.1867, 83.2570,\n",
      "         83.2570, 83.2570, 83.2400, 83.2570, 83.2570, 83.2570, 83.2400, 83.1867,\n",
      "         83.2400, 83.2400, 83.2400,  0.1000, 83.2400, 83.1867,  0.1000, 83.1867,\n",
      "         83.2570,  0.1000, 83.2570, 83.2570, 83.2570, 83.2400, 83.2400,  0.1000,\n",
      "         83.2570,  0.1000, 83.1463, 83.1463, 83.2400, 83.2570, 83.2570,  0.1000,\n",
      "          0.1000, 83.1463, 83.2400, 83.2570,  0.1000, 83.2400, 83.2570,  0.1000,\n",
      "         83.1463, 83.2570]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 703 was 99.0%\n",
      "current params: tensor([83.1463, 83.2400, 83.1867, 83.2570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "SLow rates:  tensor([[83.2463, 83.3400, 83.2867, 83.3570,  0.1000,  0.1000,  0.1000, 83.2463,\n",
      "         83.2463, 83.2463,  0.1000,  0.1000, 83.3400, 83.3400, 83.3400,  0.1000,\n",
      "          0.1000, 83.3400, 83.3400,  0.1000, 83.2867, 83.2867, 83.2867,  0.1000,\n",
      "          0.1000, 83.2867, 83.2867,  0.1000, 83.2867,  0.1000, 83.2867, 83.3570,\n",
      "         83.3570, 83.3570,  0.1000,  0.1000, 83.3570, 83.3570,  0.1000, 83.3570,\n",
      "          0.1000, 83.3570, 83.3400, 83.3570, 83.3570, 83.3570, 83.2867, 83.3570,\n",
      "         83.3570, 83.3570, 83.3400, 83.3570, 83.3570, 83.3570, 83.3400, 83.2867,\n",
      "         83.3400, 83.3400, 83.3400,  0.1000, 83.3400, 83.2867,  0.1000, 83.2867,\n",
      "         83.3570,  0.1000, 83.3570, 83.3570, 83.3570, 83.3400, 83.3400,  0.1000,\n",
      "         83.3570,  0.1000, 83.2463, 83.2463, 83.3400, 83.3570, 83.3570,  0.1000,\n",
      "          0.1000, 83.2463, 83.3400, 83.3570,  0.1000, 83.3400, 83.3570,  0.1000,\n",
      "         83.2463, 83.3570]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 704 was 99.0%\n",
      "current params: tensor([83.2463, 83.3400, 83.2867, 83.3570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "SLow rates:  tensor([[83.3464, 83.4401, 83.3867, 83.4571,  0.1000,  0.1000,  0.1000, 83.3464,\n",
      "         83.3464, 83.3464,  0.1000,  0.1000, 83.4401, 83.4401, 83.4401,  0.1000,\n",
      "          0.1000, 83.4401, 83.4401,  0.1000, 83.3867, 83.3867, 83.3867,  0.1000,\n",
      "          0.1000, 83.3867, 83.3867,  0.1000, 83.3867,  0.1000, 83.3867, 83.4571,\n",
      "         83.4571, 83.4571,  0.1000,  0.1000, 83.4571, 83.4571,  0.1000, 83.4571,\n",
      "          0.1000, 83.4571, 83.4401, 83.4571, 83.4571, 83.4571, 83.3867, 83.4571,\n",
      "         83.4571, 83.4571, 83.4401, 83.4571, 83.4571, 83.4571, 83.4401, 83.3867,\n",
      "         83.4401, 83.4401, 83.4401,  0.1000, 83.4401, 83.3867,  0.1000, 83.3867,\n",
      "         83.4571,  0.1000, 83.4571, 83.4571, 83.4571, 83.4401, 83.4401,  0.1000,\n",
      "         83.4571,  0.1000, 83.3464, 83.3464, 83.4401, 83.4571, 83.4571,  0.1000,\n",
      "          0.1000, 83.3464, 83.4401, 83.4571,  0.1000, 83.4401, 83.4571,  0.1000,\n",
      "         83.3464, 83.4571]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 705 was 99.0%\n",
      "current params: tensor([83.3464, 83.4401, 83.3867, 83.4571], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.9\n",
      "SLow rates:  tensor([[83.4464, 83.5401, 83.4868, 83.5571,  0.1000,  0.1000,  0.1000, 83.4464,\n",
      "         83.4464, 83.4464,  0.1000,  0.1000, 83.5401, 83.5401, 83.5401,  0.1000,\n",
      "          0.1000, 83.5401, 83.5401,  0.1000, 83.4868, 83.4868, 83.4868,  0.1000,\n",
      "          0.1000, 83.4868, 83.4868,  0.1000, 83.4868,  0.1000, 83.4868, 83.5571,\n",
      "         83.5571, 83.5571,  0.1000,  0.1000, 83.5571, 83.5571,  0.1000, 83.5571,\n",
      "          0.1000, 83.5571, 83.5401, 83.5571, 83.5571, 83.5571, 83.4868, 83.5571,\n",
      "         83.5571, 83.5571, 83.5401, 83.5571, 83.5571, 83.5571, 83.5401, 83.4868,\n",
      "         83.5401, 83.5401, 83.5401,  0.1000, 83.5401, 83.4868,  0.1000, 83.4868,\n",
      "         83.5571,  0.1000, 83.5571, 83.5571, 83.5571, 83.5401, 83.5401,  0.1000,\n",
      "         83.5571,  0.1000, 83.4464, 83.4464, 83.5401, 83.5571, 83.5571,  0.1000,\n",
      "          0.1000, 83.4464, 83.5401, 83.5571,  0.1000, 83.5401, 83.5571,  0.1000,\n",
      "         83.4464, 83.5571]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 706 was 99.1%\n",
      "current params: tensor([83.4464, 83.5401, 83.4868, 83.5571], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.9\n",
      "SLow rates:  tensor([[83.5464, 83.6401, 83.5868, 83.6571,  0.1000,  0.1000,  0.1000, 83.5464,\n",
      "         83.5464, 83.5464,  0.1000,  0.1000, 83.6401, 83.6401, 83.6401,  0.1000,\n",
      "          0.1000, 83.6401, 83.6401,  0.1000, 83.5868, 83.5868, 83.5868,  0.1000,\n",
      "          0.1000, 83.5868, 83.5868,  0.1000, 83.5868,  0.1000, 83.5868, 83.6571,\n",
      "         83.6571, 83.6571,  0.1000,  0.1000, 83.6571, 83.6571,  0.1000, 83.6571,\n",
      "          0.1000, 83.6571, 83.6401, 83.6571, 83.6571, 83.6571, 83.5868, 83.6571,\n",
      "         83.6571, 83.6571, 83.6401, 83.6571, 83.6571, 83.6571, 83.6401, 83.5868,\n",
      "         83.6401, 83.6401, 83.6401,  0.1000, 83.6401, 83.5868,  0.1000, 83.5868,\n",
      "         83.6571,  0.1000, 83.6571, 83.6571, 83.6571, 83.6401, 83.6401,  0.1000,\n",
      "         83.6571,  0.1000, 83.5464, 83.5464, 83.6401, 83.6571, 83.6571,  0.1000,\n",
      "          0.1000, 83.5464, 83.6401, 83.6571,  0.1000, 83.6401, 83.6571,  0.1000,\n",
      "         83.5464, 83.6571]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 707 was 99.1%\n",
      "current params: tensor([83.5464, 83.6401, 83.5868, 83.6571], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.9\n",
      "SLow rates:  tensor([[83.6465, 83.7402, 83.6868, 83.7572,  0.1000,  0.1000,  0.1000, 83.6465,\n",
      "         83.6465, 83.6465,  0.1000,  0.1000, 83.7402, 83.7402, 83.7402,  0.1000,\n",
      "          0.1000, 83.7402, 83.7402,  0.1000, 83.6868, 83.6868, 83.6868,  0.1000,\n",
      "          0.1000, 83.6868, 83.6868,  0.1000, 83.6868,  0.1000, 83.6868, 83.7572,\n",
      "         83.7572, 83.7572,  0.1000,  0.1000, 83.7572, 83.7572,  0.1000, 83.7572,\n",
      "          0.1000, 83.7572, 83.7402, 83.7572, 83.7572, 83.7572, 83.6868, 83.7572,\n",
      "         83.7572, 83.7572, 83.7402, 83.7572, 83.7572, 83.7572, 83.7402, 83.6868,\n",
      "         83.7402, 83.7402, 83.7402,  0.1000, 83.7402, 83.6868,  0.1000, 83.6868,\n",
      "         83.7572,  0.1000, 83.7572, 83.7572, 83.7572, 83.7402, 83.7402,  0.1000,\n",
      "         83.7572,  0.1000, 83.6465, 83.6465, 83.7402, 83.7572, 83.7572,  0.1000,\n",
      "          0.1000, 83.6465, 83.7402, 83.7572,  0.1000, 83.7402, 83.7572,  0.1000,\n",
      "         83.6465, 83.7572]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 708 was 99.1%\n",
      "current params: tensor([83.6465, 83.7402, 83.6868, 83.7572], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.9\n",
      "SLow rates:  tensor([[83.7465, 83.8402, 83.7869, 83.8572,  0.1000,  0.1000,  0.1000, 83.7465,\n",
      "         83.7465, 83.7465,  0.1000,  0.1000, 83.8402, 83.8402, 83.8402,  0.1000,\n",
      "          0.1000, 83.8402, 83.8402,  0.1000, 83.7869, 83.7869, 83.7869,  0.1000,\n",
      "          0.1000, 83.7869, 83.7869,  0.1000, 83.7869,  0.1000, 83.7869, 83.8572,\n",
      "         83.8572, 83.8572,  0.1000,  0.1000, 83.8572, 83.8572,  0.1000, 83.8572,\n",
      "          0.1000, 83.8572, 83.8402, 83.8572, 83.8572, 83.8572, 83.7869, 83.8572,\n",
      "         83.8572, 83.8572, 83.8402, 83.8572, 83.8572, 83.8572, 83.8402, 83.7869,\n",
      "         83.8402, 83.8402, 83.8402,  0.1000, 83.8402, 83.7869,  0.1000, 83.7869,\n",
      "         83.8572,  0.1000, 83.8572, 83.8572, 83.8572, 83.8402, 83.8402,  0.1000,\n",
      "         83.8572,  0.1000, 83.7465, 83.7465, 83.8402, 83.8572, 83.8572,  0.1000,\n",
      "          0.1000, 83.7465, 83.8402, 83.8572,  0.1000, 83.8402, 83.8572,  0.1000,\n",
      "         83.7465, 83.8572]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 709 was 99.1%\n",
      "current params: tensor([83.7465, 83.8402, 83.7869, 83.8572], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.9\n",
      "SLow rates:  tensor([[83.8465, 83.9402, 83.8869, 83.9572,  0.1000,  0.1000,  0.1000, 83.8465,\n",
      "         83.8465, 83.8465,  0.1000,  0.1000, 83.9402, 83.9402, 83.9402,  0.1000,\n",
      "          0.1000, 83.9402, 83.9402,  0.1000, 83.8869, 83.8869, 83.8869,  0.1000,\n",
      "          0.1000, 83.8869, 83.8869,  0.1000, 83.8869,  0.1000, 83.8869, 83.9572,\n",
      "         83.9572, 83.9572,  0.1000,  0.1000, 83.9572, 83.9572,  0.1000, 83.9572,\n",
      "          0.1000, 83.9572, 83.9402, 83.9572, 83.9572, 83.9572, 83.8869, 83.9572,\n",
      "         83.9572, 83.9572, 83.9402, 83.9572, 83.9572, 83.9572, 83.9402, 83.8869,\n",
      "         83.9402, 83.9402, 83.9402,  0.1000, 83.9402, 83.8869,  0.1000, 83.8869,\n",
      "         83.9572,  0.1000, 83.9572, 83.9572, 83.9572, 83.9402, 83.9402,  0.1000,\n",
      "         83.9572,  0.1000, 83.8465, 83.8465, 83.9402, 83.9572, 83.9572,  0.1000,\n",
      "          0.1000, 83.8465, 83.9402, 83.9572,  0.1000, 83.9402, 83.9572,  0.1000,\n",
      "         83.8465, 83.9572]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 710 was 99.1%\n",
      "current params: tensor([83.8465, 83.9402, 83.8869, 83.9572], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.0\n",
      "SLow rates:  tensor([[83.9466, 84.0403, 83.9869, 84.0573,  0.1000,  0.1000,  0.1000, 83.9466,\n",
      "         83.9466, 83.9466,  0.1000,  0.1000, 84.0403, 84.0403, 84.0403,  0.1000,\n",
      "          0.1000, 84.0403, 84.0403,  0.1000, 83.9869, 83.9869, 83.9869,  0.1000,\n",
      "          0.1000, 83.9869, 83.9869,  0.1000, 83.9869,  0.1000, 83.9869, 84.0573,\n",
      "         84.0573, 84.0573,  0.1000,  0.1000, 84.0573, 84.0573,  0.1000, 84.0573,\n",
      "          0.1000, 84.0573, 84.0403, 84.0573, 84.0573, 84.0573, 83.9869, 84.0573,\n",
      "         84.0573, 84.0573, 84.0403, 84.0573, 84.0573, 84.0573, 84.0403, 83.9869,\n",
      "         84.0403, 84.0403, 84.0403,  0.1000, 84.0403, 83.9869,  0.1000, 83.9869,\n",
      "         84.0573,  0.1000, 84.0573, 84.0573, 84.0573, 84.0403, 84.0403,  0.1000,\n",
      "         84.0573,  0.1000, 83.9466, 83.9466, 84.0403, 84.0573, 84.0573,  0.1000,\n",
      "          0.1000, 83.9466, 84.0403, 84.0573,  0.1000, 84.0403, 84.0573,  0.1000,\n",
      "         83.9466, 84.0573]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 711 was 99.1%\n",
      "current params: tensor([83.9466, 84.0403, 83.9869, 84.0573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.0\n",
      "SLow rates:  tensor([[84.0466, 84.1403, 84.0870, 84.1573,  0.1000,  0.1000,  0.1000, 84.0466,\n",
      "         84.0466, 84.0466,  0.1000,  0.1000, 84.1403, 84.1403, 84.1403,  0.1000,\n",
      "          0.1000, 84.1403, 84.1403,  0.1000, 84.0870, 84.0870, 84.0870,  0.1000,\n",
      "          0.1000, 84.0870, 84.0870,  0.1000, 84.0870,  0.1000, 84.0870, 84.1573,\n",
      "         84.1573, 84.1573,  0.1000,  0.1000, 84.1573, 84.1573,  0.1000, 84.1573,\n",
      "          0.1000, 84.1573, 84.1403, 84.1573, 84.1573, 84.1573, 84.0870, 84.1573,\n",
      "         84.1573, 84.1573, 84.1403, 84.1573, 84.1573, 84.1573, 84.1403, 84.0870,\n",
      "         84.1403, 84.1403, 84.1403,  0.1000, 84.1403, 84.0870,  0.1000, 84.0870,\n",
      "         84.1573,  0.1000, 84.1573, 84.1573, 84.1573, 84.1403, 84.1403,  0.1000,\n",
      "         84.1573,  0.1000, 84.0466, 84.0466, 84.1403, 84.1573, 84.1573,  0.1000,\n",
      "          0.1000, 84.0466, 84.1403, 84.1573,  0.1000, 84.1403, 84.1573,  0.1000,\n",
      "         84.0466, 84.1573]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 712 was 99.1%\n",
      "current params: tensor([84.0466, 84.1403, 84.0870, 84.1573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.0\n",
      "SLow rates:  tensor([[84.1467, 84.2403, 84.1870, 84.2573,  0.1000,  0.1000,  0.1000, 84.1467,\n",
      "         84.1467, 84.1467,  0.1000,  0.1000, 84.2403, 84.2403, 84.2403,  0.1000,\n",
      "          0.1000, 84.2403, 84.2403,  0.1000, 84.1870, 84.1870, 84.1870,  0.1000,\n",
      "          0.1000, 84.1870, 84.1870,  0.1000, 84.1870,  0.1000, 84.1870, 84.2573,\n",
      "         84.2573, 84.2573,  0.1000,  0.1000, 84.2573, 84.2573,  0.1000, 84.2573,\n",
      "          0.1000, 84.2573, 84.2403, 84.2573, 84.2573, 84.2573, 84.1870, 84.2573,\n",
      "         84.2573, 84.2573, 84.2403, 84.2573, 84.2573, 84.2573, 84.2403, 84.1870,\n",
      "         84.2403, 84.2403, 84.2403,  0.1000, 84.2403, 84.1870,  0.1000, 84.1870,\n",
      "         84.2573,  0.1000, 84.2573, 84.2573, 84.2573, 84.2403, 84.2403,  0.1000,\n",
      "         84.2573,  0.1000, 84.1467, 84.1467, 84.2403, 84.2573, 84.2573,  0.1000,\n",
      "          0.1000, 84.1467, 84.2403, 84.2573,  0.1000, 84.2403, 84.2573,  0.1000,\n",
      "         84.1467, 84.2573]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 713 was 99.1%\n",
      "current params: tensor([84.1467, 84.2403, 84.1870, 84.2573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.0\n",
      "SLow rates:  tensor([[84.2467, 84.3404, 84.2870, 84.3573,  0.1000,  0.1000,  0.1000, 84.2467,\n",
      "         84.2467, 84.2467,  0.1000,  0.1000, 84.3404, 84.3404, 84.3404,  0.1000,\n",
      "          0.1000, 84.3404, 84.3404,  0.1000, 84.2870, 84.2870, 84.2870,  0.1000,\n",
      "          0.1000, 84.2870, 84.2870,  0.1000, 84.2870,  0.1000, 84.2870, 84.3573,\n",
      "         84.3573, 84.3573,  0.1000,  0.1000, 84.3573, 84.3573,  0.1000, 84.3573,\n",
      "          0.1000, 84.3573, 84.3404, 84.3573, 84.3573, 84.3573, 84.2870, 84.3573,\n",
      "         84.3573, 84.3573, 84.3404, 84.3573, 84.3573, 84.3573, 84.3404, 84.2870,\n",
      "         84.3404, 84.3404, 84.3404,  0.1000, 84.3404, 84.2870,  0.1000, 84.2870,\n",
      "         84.3573,  0.1000, 84.3573, 84.3573, 84.3573, 84.3404, 84.3404,  0.1000,\n",
      "         84.3573,  0.1000, 84.2467, 84.2467, 84.3404, 84.3573, 84.3573,  0.1000,\n",
      "          0.1000, 84.2467, 84.3404, 84.3573,  0.1000, 84.3404, 84.3573,  0.1000,\n",
      "         84.2467, 84.3573]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 714 was 99.1%\n",
      "current params: tensor([84.2467, 84.3404, 84.2870, 84.3573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.0\n",
      "SLow rates:  tensor([[84.3467, 84.4404, 84.3871, 84.4574,  0.1000,  0.1000,  0.1000, 84.3467,\n",
      "         84.3467, 84.3467,  0.1000,  0.1000, 84.4404, 84.4404, 84.4404,  0.1000,\n",
      "          0.1000, 84.4404, 84.4404,  0.1000, 84.3871, 84.3871, 84.3871,  0.1000,\n",
      "          0.1000, 84.3871, 84.3871,  0.1000, 84.3871,  0.1000, 84.3871, 84.4574,\n",
      "         84.4574, 84.4574,  0.1000,  0.1000, 84.4574, 84.4574,  0.1000, 84.4574,\n",
      "          0.1000, 84.4574, 84.4404, 84.4574, 84.4574, 84.4574, 84.3871, 84.4574,\n",
      "         84.4574, 84.4574, 84.4404, 84.4574, 84.4574, 84.4574, 84.4404, 84.3871,\n",
      "         84.4404, 84.4404, 84.4404,  0.1000, 84.4404, 84.3871,  0.1000, 84.3871,\n",
      "         84.4574,  0.1000, 84.4574, 84.4574, 84.4574, 84.4404, 84.4404,  0.1000,\n",
      "         84.4574,  0.1000, 84.3467, 84.3467, 84.4404, 84.4574, 84.4574,  0.1000,\n",
      "          0.1000, 84.3467, 84.4404, 84.4574,  0.1000, 84.4404, 84.4574,  0.1000,\n",
      "         84.3467, 84.4574]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 715 was 99.1%\n",
      "current params: tensor([84.3467, 84.4404, 84.3871, 84.4574], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.1\n",
      "SLow rates:  tensor([[84.4468, 84.5404, 84.4871, 84.5574,  0.1000,  0.1000,  0.1000, 84.4468,\n",
      "         84.4468, 84.4468,  0.1000,  0.1000, 84.5404, 84.5404, 84.5404,  0.1000,\n",
      "          0.1000, 84.5404, 84.5404,  0.1000, 84.4871, 84.4871, 84.4871,  0.1000,\n",
      "          0.1000, 84.4871, 84.4871,  0.1000, 84.4871,  0.1000, 84.4871, 84.5574,\n",
      "         84.5574, 84.5574,  0.1000,  0.1000, 84.5574, 84.5574,  0.1000, 84.5574,\n",
      "          0.1000, 84.5574, 84.5404, 84.5574, 84.5574, 84.5574, 84.4871, 84.5574,\n",
      "         84.5574, 84.5574, 84.5404, 84.5574, 84.5574, 84.5574, 84.5404, 84.4871,\n",
      "         84.5404, 84.5404, 84.5404,  0.1000, 84.5404, 84.4871,  0.1000, 84.4871,\n",
      "         84.5574,  0.1000, 84.5574, 84.5574, 84.5574, 84.5404, 84.5404,  0.1000,\n",
      "         84.5574,  0.1000, 84.4468, 84.4468, 84.5404, 84.5574, 84.5574,  0.1000,\n",
      "          0.1000, 84.4468, 84.5404, 84.5574,  0.1000, 84.5404, 84.5574,  0.1000,\n",
      "         84.4468, 84.5574]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 716 was 99.1%\n",
      "current params: tensor([84.4468, 84.5404, 84.4871, 84.5574], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.1\n",
      "SLow rates:  tensor([[84.5468, 84.6405, 84.5871, 84.6574,  0.1000,  0.1000,  0.1000, 84.5468,\n",
      "         84.5468, 84.5468,  0.1000,  0.1000, 84.6405, 84.6405, 84.6405,  0.1000,\n",
      "          0.1000, 84.6405, 84.6405,  0.1000, 84.5871, 84.5871, 84.5871,  0.1000,\n",
      "          0.1000, 84.5871, 84.5871,  0.1000, 84.5871,  0.1000, 84.5871, 84.6574,\n",
      "         84.6574, 84.6574,  0.1000,  0.1000, 84.6574, 84.6574,  0.1000, 84.6574,\n",
      "          0.1000, 84.6574, 84.6405, 84.6574, 84.6574, 84.6574, 84.5871, 84.6574,\n",
      "         84.6574, 84.6574, 84.6405, 84.6574, 84.6574, 84.6574, 84.6405, 84.5871,\n",
      "         84.6405, 84.6405, 84.6405,  0.1000, 84.6405, 84.5871,  0.1000, 84.5871,\n",
      "         84.6574,  0.1000, 84.6574, 84.6574, 84.6574, 84.6405, 84.6405,  0.1000,\n",
      "         84.6574,  0.1000, 84.5468, 84.5468, 84.6405, 84.6574, 84.6574,  0.1000,\n",
      "          0.1000, 84.5468, 84.6405, 84.6574,  0.1000, 84.6405, 84.6574,  0.1000,\n",
      "         84.5468, 84.6574]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 717 was 99.1%\n",
      "current params: tensor([84.5468, 84.6405, 84.5871, 84.6574], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.1\n",
      "SLow rates:  tensor([[84.6468, 84.7405, 84.6872, 84.7575,  0.1000,  0.1000,  0.1000, 84.6468,\n",
      "         84.6468, 84.6468,  0.1000,  0.1000, 84.7405, 84.7405, 84.7405,  0.1000,\n",
      "          0.1000, 84.7405, 84.7405,  0.1000, 84.6872, 84.6872, 84.6872,  0.1000,\n",
      "          0.1000, 84.6872, 84.6872,  0.1000, 84.6872,  0.1000, 84.6872, 84.7575,\n",
      "         84.7575, 84.7575,  0.1000,  0.1000, 84.7575, 84.7575,  0.1000, 84.7575,\n",
      "          0.1000, 84.7575, 84.7405, 84.7575, 84.7575, 84.7575, 84.6872, 84.7575,\n",
      "         84.7575, 84.7575, 84.7405, 84.7575, 84.7575, 84.7575, 84.7405, 84.6872,\n",
      "         84.7405, 84.7405, 84.7405,  0.1000, 84.7405, 84.6872,  0.1000, 84.6872,\n",
      "         84.7575,  0.1000, 84.7575, 84.7575, 84.7575, 84.7405, 84.7405,  0.1000,\n",
      "         84.7575,  0.1000, 84.6468, 84.6468, 84.7405, 84.7575, 84.7575,  0.1000,\n",
      "          0.1000, 84.6468, 84.7405, 84.7575,  0.1000, 84.7405, 84.7575,  0.1000,\n",
      "         84.6468, 84.7575]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 718 was 99.1%\n",
      "current params: tensor([84.6468, 84.7405, 84.6872, 84.7575], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.1\n",
      "SLow rates:  tensor([[84.7469, 84.8405, 84.7872, 84.8575,  0.1000,  0.1000,  0.1000, 84.7469,\n",
      "         84.7469, 84.7469,  0.1000,  0.1000, 84.8405, 84.8405, 84.8405,  0.1000,\n",
      "          0.1000, 84.8405, 84.8405,  0.1000, 84.7872, 84.7872, 84.7872,  0.1000,\n",
      "          0.1000, 84.7872, 84.7872,  0.1000, 84.7872,  0.1000, 84.7872, 84.8575,\n",
      "         84.8575, 84.8575,  0.1000,  0.1000, 84.8575, 84.8575,  0.1000, 84.8575,\n",
      "          0.1000, 84.8575, 84.8405, 84.8575, 84.8575, 84.8575, 84.7872, 84.8575,\n",
      "         84.8575, 84.8575, 84.8405, 84.8575, 84.8575, 84.8575, 84.8405, 84.7872,\n",
      "         84.8405, 84.8405, 84.8405,  0.1000, 84.8405, 84.7872,  0.1000, 84.7872,\n",
      "         84.8575,  0.1000, 84.8575, 84.8575, 84.8575, 84.8405, 84.8405,  0.1000,\n",
      "         84.8575,  0.1000, 84.7469, 84.7469, 84.8405, 84.8575, 84.8575,  0.1000,\n",
      "          0.1000, 84.7469, 84.8405, 84.8575,  0.1000, 84.8405, 84.8575,  0.1000,\n",
      "         84.7469, 84.8575]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 719 was 99.1%\n",
      "current params: tensor([84.7469, 84.8405, 84.7872, 84.8575], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.1\n",
      "SLow rates:  tensor([[84.8469, 84.9405, 84.8872, 84.9575,  0.1000,  0.1000,  0.1000, 84.8469,\n",
      "         84.8469, 84.8469,  0.1000,  0.1000, 84.9405, 84.9405, 84.9405,  0.1000,\n",
      "          0.1000, 84.9405, 84.9405,  0.1000, 84.8872, 84.8872, 84.8872,  0.1000,\n",
      "          0.1000, 84.8872, 84.8872,  0.1000, 84.8872,  0.1000, 84.8872, 84.9575,\n",
      "         84.9575, 84.9575,  0.1000,  0.1000, 84.9575, 84.9575,  0.1000, 84.9575,\n",
      "          0.1000, 84.9575, 84.9405, 84.9575, 84.9575, 84.9575, 84.8872, 84.9575,\n",
      "         84.9575, 84.9575, 84.9405, 84.9575, 84.9575, 84.9575, 84.9405, 84.8872,\n",
      "         84.9405, 84.9405, 84.9405,  0.1000, 84.9405, 84.8872,  0.1000, 84.8872,\n",
      "         84.9575,  0.1000, 84.9575, 84.9575, 84.9575, 84.9405, 84.9405,  0.1000,\n",
      "         84.9575,  0.1000, 84.8469, 84.8469, 84.9405, 84.9575, 84.9575,  0.1000,\n",
      "          0.1000, 84.8469, 84.9405, 84.9575,  0.1000, 84.9405, 84.9575,  0.1000,\n",
      "         84.8469, 84.9575]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 720 was 99.1%\n",
      "current params: tensor([84.8469, 84.9405, 84.8872, 84.9575], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.1\n",
      "SLow rates:  tensor([[84.9469, 85.0406, 84.9873, 85.0575,  0.1000,  0.1000,  0.1000, 84.9469,\n",
      "         84.9469, 84.9469,  0.1000,  0.1000, 85.0406, 85.0406, 85.0406,  0.1000,\n",
      "          0.1000, 85.0406, 85.0406,  0.1000, 84.9873, 84.9873, 84.9873,  0.1000,\n",
      "          0.1000, 84.9873, 84.9873,  0.1000, 84.9873,  0.1000, 84.9873, 85.0575,\n",
      "         85.0575, 85.0575,  0.1000,  0.1000, 85.0575, 85.0575,  0.1000, 85.0575,\n",
      "          0.1000, 85.0575, 85.0406, 85.0575, 85.0575, 85.0575, 84.9873, 85.0575,\n",
      "         85.0575, 85.0575, 85.0406, 85.0575, 85.0575, 85.0575, 85.0406, 84.9873,\n",
      "         85.0406, 85.0406, 85.0406,  0.1000, 85.0406, 84.9873,  0.1000, 84.9873,\n",
      "         85.0575,  0.1000, 85.0575, 85.0575, 85.0575, 85.0406, 85.0406,  0.1000,\n",
      "         85.0575,  0.1000, 84.9469, 84.9469, 85.0406, 85.0575, 85.0575,  0.1000,\n",
      "          0.1000, 84.9469, 85.0406, 85.0575,  0.1000, 85.0406, 85.0575,  0.1000,\n",
      "         84.9469, 85.0575]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 721 was 99.1%\n",
      "current params: tensor([84.9469, 85.0406, 84.9873, 85.0575], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.2\n",
      "SLow rates:  tensor([[85.0470, 85.1406, 85.0873, 85.1576,  0.1000,  0.1000,  0.1000, 85.0470,\n",
      "         85.0470, 85.0470,  0.1000,  0.1000, 85.1406, 85.1406, 85.1406,  0.1000,\n",
      "          0.1000, 85.1406, 85.1406,  0.1000, 85.0873, 85.0873, 85.0873,  0.1000,\n",
      "          0.1000, 85.0873, 85.0873,  0.1000, 85.0873,  0.1000, 85.0873, 85.1576,\n",
      "         85.1576, 85.1576,  0.1000,  0.1000, 85.1576, 85.1576,  0.1000, 85.1576,\n",
      "          0.1000, 85.1576, 85.1406, 85.1576, 85.1576, 85.1576, 85.0873, 85.1576,\n",
      "         85.1576, 85.1576, 85.1406, 85.1576, 85.1576, 85.1576, 85.1406, 85.0873,\n",
      "         85.1406, 85.1406, 85.1406,  0.1000, 85.1406, 85.0873,  0.1000, 85.0873,\n",
      "         85.1576,  0.1000, 85.1576, 85.1576, 85.1576, 85.1406, 85.1406,  0.1000,\n",
      "         85.1576,  0.1000, 85.0470, 85.0470, 85.1406, 85.1576, 85.1576,  0.1000,\n",
      "          0.1000, 85.0470, 85.1406, 85.1576,  0.1000, 85.1406, 85.1576,  0.1000,\n",
      "         85.0470, 85.1576]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 722 was 99.1%\n",
      "current params: tensor([85.0470, 85.1406, 85.0873, 85.1576], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.2\n",
      "SLow rates:  tensor([[85.1470, 85.2406, 85.1873, 85.2576,  0.1000,  0.1000,  0.1000, 85.1470,\n",
      "         85.1470, 85.1470,  0.1000,  0.1000, 85.2406, 85.2406, 85.2406,  0.1000,\n",
      "          0.1000, 85.2406, 85.2406,  0.1000, 85.1873, 85.1873, 85.1873,  0.1000,\n",
      "          0.1000, 85.1873, 85.1873,  0.1000, 85.1873,  0.1000, 85.1873, 85.2576,\n",
      "         85.2576, 85.2576,  0.1000,  0.1000, 85.2576, 85.2576,  0.1000, 85.2576,\n",
      "          0.1000, 85.2576, 85.2406, 85.2576, 85.2576, 85.2576, 85.1873, 85.2576,\n",
      "         85.2576, 85.2576, 85.2406, 85.2576, 85.2576, 85.2576, 85.2406, 85.1873,\n",
      "         85.2406, 85.2406, 85.2406,  0.1000, 85.2406, 85.1873,  0.1000, 85.1873,\n",
      "         85.2576,  0.1000, 85.2576, 85.2576, 85.2576, 85.2406, 85.2406,  0.1000,\n",
      "         85.2576,  0.1000, 85.1470, 85.1470, 85.2406, 85.2576, 85.2576,  0.1000,\n",
      "          0.1000, 85.1470, 85.2406, 85.2576,  0.1000, 85.2406, 85.2576,  0.1000,\n",
      "         85.1470, 85.2576]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 723 was 99.1%\n",
      "current params: tensor([85.1470, 85.2406, 85.1873, 85.2576], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.2\n",
      "SLow rates:  tensor([[85.2470, 85.3407, 85.2873, 85.3576,  0.1000,  0.1000,  0.1000, 85.2470,\n",
      "         85.2470, 85.2470,  0.1000,  0.1000, 85.3407, 85.3407, 85.3407,  0.1000,\n",
      "          0.1000, 85.3407, 85.3407,  0.1000, 85.2873, 85.2873, 85.2873,  0.1000,\n",
      "          0.1000, 85.2873, 85.2873,  0.1000, 85.2873,  0.1000, 85.2873, 85.3576,\n",
      "         85.3576, 85.3576,  0.1000,  0.1000, 85.3576, 85.3576,  0.1000, 85.3576,\n",
      "          0.1000, 85.3576, 85.3407, 85.3576, 85.3576, 85.3576, 85.2873, 85.3576,\n",
      "         85.3576, 85.3576, 85.3407, 85.3576, 85.3576, 85.3576, 85.3407, 85.2873,\n",
      "         85.3407, 85.3407, 85.3407,  0.1000, 85.3407, 85.2873,  0.1000, 85.2873,\n",
      "         85.3576,  0.1000, 85.3576, 85.3576, 85.3576, 85.3407, 85.3407,  0.1000,\n",
      "         85.3576,  0.1000, 85.2470, 85.2470, 85.3407, 85.3576, 85.3576,  0.1000,\n",
      "          0.1000, 85.2470, 85.3407, 85.3576,  0.1000, 85.3407, 85.3576,  0.1000,\n",
      "         85.2470, 85.3576]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 724 was 99.1%\n",
      "current params: tensor([85.2470, 85.3407, 85.2873, 85.3576], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.2\n",
      "SLow rates:  tensor([[85.3470, 85.4407, 85.3874, 85.4577,  0.1000,  0.1000,  0.1000, 85.3470,\n",
      "         85.3470, 85.3470,  0.1000,  0.1000, 85.4407, 85.4407, 85.4407,  0.1000,\n",
      "          0.1000, 85.4407, 85.4407,  0.1000, 85.3874, 85.3874, 85.3874,  0.1000,\n",
      "          0.1000, 85.3874, 85.3874,  0.1000, 85.3874,  0.1000, 85.3874, 85.4577,\n",
      "         85.4577, 85.4577,  0.1000,  0.1000, 85.4577, 85.4577,  0.1000, 85.4577,\n",
      "          0.1000, 85.4577, 85.4407, 85.4577, 85.4577, 85.4577, 85.3874, 85.4577,\n",
      "         85.4577, 85.4577, 85.4407, 85.4577, 85.4577, 85.4577, 85.4407, 85.3874,\n",
      "         85.4407, 85.4407, 85.4407,  0.1000, 85.4407, 85.3874,  0.1000, 85.3874,\n",
      "         85.4577,  0.1000, 85.4577, 85.4577, 85.4577, 85.4407, 85.4407,  0.1000,\n",
      "         85.4577,  0.1000, 85.3470, 85.3470, 85.4407, 85.4577, 85.4577,  0.1000,\n",
      "          0.1000, 85.3470, 85.4407, 85.4577,  0.1000, 85.4407, 85.4577,  0.1000,\n",
      "         85.3470, 85.4577]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 725 was 99.1%\n",
      "current params: tensor([85.3470, 85.4407, 85.3874, 85.4577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.2\n",
      "SLow rates:  tensor([[85.4471, 85.5407, 85.4874, 85.5577,  0.1000,  0.1000,  0.1000, 85.4471,\n",
      "         85.4471, 85.4471,  0.1000,  0.1000, 85.5407, 85.5407, 85.5407,  0.1000,\n",
      "          0.1000, 85.5407, 85.5407,  0.1000, 85.4874, 85.4874, 85.4874,  0.1000,\n",
      "          0.1000, 85.4874, 85.4874,  0.1000, 85.4874,  0.1000, 85.4874, 85.5577,\n",
      "         85.5577, 85.5577,  0.1000,  0.1000, 85.5577, 85.5577,  0.1000, 85.5577,\n",
      "          0.1000, 85.5577, 85.5407, 85.5577, 85.5577, 85.5577, 85.4874, 85.5577,\n",
      "         85.5577, 85.5577, 85.5407, 85.5577, 85.5577, 85.5577, 85.5407, 85.4874,\n",
      "         85.5407, 85.5407, 85.5407,  0.1000, 85.5407, 85.4874,  0.1000, 85.4874,\n",
      "         85.5577,  0.1000, 85.5577, 85.5577, 85.5577, 85.5407, 85.5407,  0.1000,\n",
      "         85.5577,  0.1000, 85.4471, 85.4471, 85.5407, 85.5577, 85.5577,  0.1000,\n",
      "          0.1000, 85.4471, 85.5407, 85.5577,  0.1000, 85.5407, 85.5577,  0.1000,\n",
      "         85.4471, 85.5577]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 726 was 99.1%\n",
      "current params: tensor([85.4471, 85.5407, 85.4874, 85.5577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.3\n",
      "SLow rates:  tensor([[85.5471, 85.6407, 85.5874, 85.6577,  0.1000,  0.1000,  0.1000, 85.5471,\n",
      "         85.5471, 85.5471,  0.1000,  0.1000, 85.6407, 85.6407, 85.6407,  0.1000,\n",
      "          0.1000, 85.6407, 85.6407,  0.1000, 85.5874, 85.5874, 85.5874,  0.1000,\n",
      "          0.1000, 85.5874, 85.5874,  0.1000, 85.5874,  0.1000, 85.5874, 85.6577,\n",
      "         85.6577, 85.6577,  0.1000,  0.1000, 85.6577, 85.6577,  0.1000, 85.6577,\n",
      "          0.1000, 85.6577, 85.6407, 85.6577, 85.6577, 85.6577, 85.5874, 85.6577,\n",
      "         85.6577, 85.6577, 85.6407, 85.6577, 85.6577, 85.6577, 85.6407, 85.5874,\n",
      "         85.6407, 85.6407, 85.6407,  0.1000, 85.6407, 85.5874,  0.1000, 85.5874,\n",
      "         85.6577,  0.1000, 85.6577, 85.6577, 85.6577, 85.6407, 85.6407,  0.1000,\n",
      "         85.6577,  0.1000, 85.5471, 85.5471, 85.6407, 85.6577, 85.6577,  0.1000,\n",
      "          0.1000, 85.5471, 85.6407, 85.6577,  0.1000, 85.6407, 85.6577,  0.1000,\n",
      "         85.5471, 85.6577]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 727 was 99.1%\n",
      "current params: tensor([85.5471, 85.6407, 85.5874, 85.6577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.3\n",
      "SLow rates:  tensor([[85.6471, 85.7408, 85.6875, 85.7577,  0.1000,  0.1000,  0.1000, 85.6471,\n",
      "         85.6471, 85.6471,  0.1000,  0.1000, 85.7408, 85.7408, 85.7408,  0.1000,\n",
      "          0.1000, 85.7408, 85.7408,  0.1000, 85.6875, 85.6875, 85.6875,  0.1000,\n",
      "          0.1000, 85.6875, 85.6875,  0.1000, 85.6875,  0.1000, 85.6875, 85.7577,\n",
      "         85.7577, 85.7577,  0.1000,  0.1000, 85.7577, 85.7577,  0.1000, 85.7577,\n",
      "          0.1000, 85.7577, 85.7408, 85.7577, 85.7577, 85.7577, 85.6875, 85.7577,\n",
      "         85.7577, 85.7577, 85.7408, 85.7577, 85.7577, 85.7577, 85.7408, 85.6875,\n",
      "         85.7408, 85.7408, 85.7408,  0.1000, 85.7408, 85.6875,  0.1000, 85.6875,\n",
      "         85.7577,  0.1000, 85.7577, 85.7577, 85.7577, 85.7408, 85.7408,  0.1000,\n",
      "         85.7577,  0.1000, 85.6471, 85.6471, 85.7408, 85.7577, 85.7577,  0.1000,\n",
      "          0.1000, 85.6471, 85.7408, 85.7577,  0.1000, 85.7408, 85.7577,  0.1000,\n",
      "         85.6471, 85.7577]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 728 was 99.1%\n",
      "current params: tensor([85.6471, 85.7408, 85.6875, 85.7577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.3\n",
      "SLow rates:  tensor([[85.7472, 85.8408, 85.7875, 85.8578,  0.1000,  0.1000,  0.1000, 85.7472,\n",
      "         85.7472, 85.7472,  0.1000,  0.1000, 85.8408, 85.8408, 85.8408,  0.1000,\n",
      "          0.1000, 85.8408, 85.8408,  0.1000, 85.7875, 85.7875, 85.7875,  0.1000,\n",
      "          0.1000, 85.7875, 85.7875,  0.1000, 85.7875,  0.1000, 85.7875, 85.8578,\n",
      "         85.8578, 85.8578,  0.1000,  0.1000, 85.8578, 85.8578,  0.1000, 85.8578,\n",
      "          0.1000, 85.8578, 85.8408, 85.8578, 85.8578, 85.8578, 85.7875, 85.8578,\n",
      "         85.8578, 85.8578, 85.8408, 85.8578, 85.8578, 85.8578, 85.8408, 85.7875,\n",
      "         85.8408, 85.8408, 85.8408,  0.1000, 85.8408, 85.7875,  0.1000, 85.7875,\n",
      "         85.8578,  0.1000, 85.8578, 85.8578, 85.8578, 85.8408, 85.8408,  0.1000,\n",
      "         85.8578,  0.1000, 85.7472, 85.7472, 85.8408, 85.8578, 85.8578,  0.1000,\n",
      "          0.1000, 85.7472, 85.8408, 85.8578,  0.1000, 85.8408, 85.8578,  0.1000,\n",
      "         85.7472, 85.8578]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 729 was 99.1%\n",
      "current params: tensor([85.7472, 85.8408, 85.7875, 85.8578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.3\n",
      "SLow rates:  tensor([[85.8472, 85.9408, 85.8875, 85.9578,  0.1000,  0.1000,  0.1000, 85.8472,\n",
      "         85.8472, 85.8472,  0.1000,  0.1000, 85.9408, 85.9408, 85.9408,  0.1000,\n",
      "          0.1000, 85.9408, 85.9408,  0.1000, 85.8875, 85.8875, 85.8875,  0.1000,\n",
      "          0.1000, 85.8875, 85.8875,  0.1000, 85.8875,  0.1000, 85.8875, 85.9578,\n",
      "         85.9578, 85.9578,  0.1000,  0.1000, 85.9578, 85.9578,  0.1000, 85.9578,\n",
      "          0.1000, 85.9578, 85.9408, 85.9578, 85.9578, 85.9578, 85.8875, 85.9578,\n",
      "         85.9578, 85.9578, 85.9408, 85.9578, 85.9578, 85.9578, 85.9408, 85.8875,\n",
      "         85.9408, 85.9408, 85.9408,  0.1000, 85.9408, 85.8875,  0.1000, 85.8875,\n",
      "         85.9578,  0.1000, 85.9578, 85.9578, 85.9578, 85.9408, 85.9408,  0.1000,\n",
      "         85.9578,  0.1000, 85.8472, 85.8472, 85.9408, 85.9578, 85.9578,  0.1000,\n",
      "          0.1000, 85.8472, 85.9408, 85.9578,  0.1000, 85.9408, 85.9578,  0.1000,\n",
      "         85.8472, 85.9578]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 730 was 99.1%\n",
      "current params: tensor([85.8472, 85.9408, 85.8875, 85.9578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.3\n",
      "SLow rates:  tensor([[85.9472, 86.0409, 85.9875, 86.0578,  0.1000,  0.1000,  0.1000, 85.9472,\n",
      "         85.9472, 85.9472,  0.1000,  0.1000, 86.0409, 86.0409, 86.0409,  0.1000,\n",
      "          0.1000, 86.0409, 86.0409,  0.1000, 85.9875, 85.9875, 85.9875,  0.1000,\n",
      "          0.1000, 85.9875, 85.9875,  0.1000, 85.9875,  0.1000, 85.9875, 86.0578,\n",
      "         86.0578, 86.0578,  0.1000,  0.1000, 86.0578, 86.0578,  0.1000, 86.0578,\n",
      "          0.1000, 86.0578, 86.0409, 86.0578, 86.0578, 86.0578, 85.9875, 86.0578,\n",
      "         86.0578, 86.0578, 86.0409, 86.0578, 86.0578, 86.0578, 86.0409, 85.9875,\n",
      "         86.0409, 86.0409, 86.0409,  0.1000, 86.0409, 85.9875,  0.1000, 85.9875,\n",
      "         86.0578,  0.1000, 86.0578, 86.0578, 86.0578, 86.0409, 86.0409,  0.1000,\n",
      "         86.0578,  0.1000, 85.9472, 85.9472, 86.0409, 86.0578, 86.0578,  0.1000,\n",
      "          0.1000, 85.9472, 86.0409, 86.0578,  0.1000, 86.0409, 86.0578,  0.1000,\n",
      "         85.9472, 86.0578]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 731 was 99.1%\n",
      "current params: tensor([85.9472, 86.0409, 85.9875, 86.0578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.4\n",
      "SLow rates:  tensor([[86.0473, 86.1409, 86.0876, 86.1578,  0.1000,  0.1000,  0.1000, 86.0473,\n",
      "         86.0473, 86.0473,  0.1000,  0.1000, 86.1409, 86.1409, 86.1409,  0.1000,\n",
      "          0.1000, 86.1409, 86.1409,  0.1000, 86.0876, 86.0876, 86.0876,  0.1000,\n",
      "          0.1000, 86.0876, 86.0876,  0.1000, 86.0876,  0.1000, 86.0876, 86.1578,\n",
      "         86.1578, 86.1578,  0.1000,  0.1000, 86.1578, 86.1578,  0.1000, 86.1578,\n",
      "          0.1000, 86.1578, 86.1409, 86.1578, 86.1578, 86.1578, 86.0876, 86.1578,\n",
      "         86.1578, 86.1578, 86.1409, 86.1578, 86.1578, 86.1578, 86.1409, 86.0876,\n",
      "         86.1409, 86.1409, 86.1409,  0.1000, 86.1409, 86.0876,  0.1000, 86.0876,\n",
      "         86.1578,  0.1000, 86.1578, 86.1578, 86.1578, 86.1409, 86.1409,  0.1000,\n",
      "         86.1578,  0.1000, 86.0473, 86.0473, 86.1409, 86.1578, 86.1578,  0.1000,\n",
      "          0.1000, 86.0473, 86.1409, 86.1578,  0.1000, 86.1409, 86.1578,  0.1000,\n",
      "         86.0473, 86.1578]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 732 was 99.1%\n",
      "current params: tensor([86.0473, 86.1409, 86.0876, 86.1578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.4\n",
      "SLow rates:  tensor([[86.1473, 86.2409, 86.1876, 86.2579,  0.1000,  0.1000,  0.1000, 86.1473,\n",
      "         86.1473, 86.1473,  0.1000,  0.1000, 86.2409, 86.2409, 86.2409,  0.1000,\n",
      "          0.1000, 86.2409, 86.2409,  0.1000, 86.1876, 86.1876, 86.1876,  0.1000,\n",
      "          0.1000, 86.1876, 86.1876,  0.1000, 86.1876,  0.1000, 86.1876, 86.2579,\n",
      "         86.2579, 86.2579,  0.1000,  0.1000, 86.2579, 86.2579,  0.1000, 86.2579,\n",
      "          0.1000, 86.2579, 86.2409, 86.2579, 86.2579, 86.2579, 86.1876, 86.2579,\n",
      "         86.2579, 86.2579, 86.2409, 86.2579, 86.2579, 86.2579, 86.2409, 86.1876,\n",
      "         86.2409, 86.2409, 86.2409,  0.1000, 86.2409, 86.1876,  0.1000, 86.1876,\n",
      "         86.2579,  0.1000, 86.2579, 86.2579, 86.2579, 86.2409, 86.2409,  0.1000,\n",
      "         86.2579,  0.1000, 86.1473, 86.1473, 86.2409, 86.2579, 86.2579,  0.1000,\n",
      "          0.1000, 86.1473, 86.2409, 86.2579,  0.1000, 86.2409, 86.2579,  0.1000,\n",
      "         86.1473, 86.2579]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 733 was 99.1%\n",
      "current params: tensor([86.1473, 86.2409, 86.1876, 86.2579], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.4\n",
      "SLow rates:  tensor([[86.2473, 86.3409, 86.2876, 86.3579,  0.1000,  0.1000,  0.1000, 86.2473,\n",
      "         86.2473, 86.2473,  0.1000,  0.1000, 86.3409, 86.3409, 86.3409,  0.1000,\n",
      "          0.1000, 86.3409, 86.3409,  0.1000, 86.2876, 86.2876, 86.2876,  0.1000,\n",
      "          0.1000, 86.2876, 86.2876,  0.1000, 86.2876,  0.1000, 86.2876, 86.3579,\n",
      "         86.3579, 86.3579,  0.1000,  0.1000, 86.3579, 86.3579,  0.1000, 86.3579,\n",
      "          0.1000, 86.3579, 86.3409, 86.3579, 86.3579, 86.3579, 86.2876, 86.3579,\n",
      "         86.3579, 86.3579, 86.3409, 86.3579, 86.3579, 86.3579, 86.3409, 86.2876,\n",
      "         86.3409, 86.3409, 86.3409,  0.1000, 86.3409, 86.2876,  0.1000, 86.2876,\n",
      "         86.3579,  0.1000, 86.3579, 86.3579, 86.3579, 86.3409, 86.3409,  0.1000,\n",
      "         86.3579,  0.1000, 86.2473, 86.2473, 86.3409, 86.3579, 86.3579,  0.1000,\n",
      "          0.1000, 86.2473, 86.3409, 86.3579,  0.1000, 86.3409, 86.3579,  0.1000,\n",
      "         86.2473, 86.3579]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 734 was 99.1%\n",
      "current params: tensor([86.2473, 86.3409, 86.2876, 86.3579], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.4\n",
      "SLow rates:  tensor([[86.3473, 86.4410, 86.3877, 86.4579,  0.1000,  0.1000,  0.1000, 86.3473,\n",
      "         86.3473, 86.3473,  0.1000,  0.1000, 86.4410, 86.4410, 86.4410,  0.1000,\n",
      "          0.1000, 86.4410, 86.4410,  0.1000, 86.3877, 86.3877, 86.3877,  0.1000,\n",
      "          0.1000, 86.3877, 86.3877,  0.1000, 86.3877,  0.1000, 86.3877, 86.4579,\n",
      "         86.4579, 86.4579,  0.1000,  0.1000, 86.4579, 86.4579,  0.1000, 86.4579,\n",
      "          0.1000, 86.4579, 86.4410, 86.4579, 86.4579, 86.4579, 86.3877, 86.4579,\n",
      "         86.4579, 86.4579, 86.4410, 86.4579, 86.4579, 86.4579, 86.4410, 86.3877,\n",
      "         86.4410, 86.4410, 86.4410,  0.1000, 86.4410, 86.3877,  0.1000, 86.3877,\n",
      "         86.4579,  0.1000, 86.4579, 86.4579, 86.4579, 86.4410, 86.4410,  0.1000,\n",
      "         86.4579,  0.1000, 86.3473, 86.3473, 86.4410, 86.4579, 86.4579,  0.1000,\n",
      "          0.1000, 86.3473, 86.4410, 86.4579,  0.1000, 86.4410, 86.4579,  0.1000,\n",
      "         86.3473, 86.4579]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 735 was 99.1%\n",
      "current params: tensor([86.3473, 86.4410, 86.3877, 86.4579], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.4\n",
      "SLow rates:  tensor([[86.4474, 86.5410, 86.4877, 86.5579,  0.1000,  0.1000,  0.1000, 86.4474,\n",
      "         86.4474, 86.4474,  0.1000,  0.1000, 86.5410, 86.5410, 86.5410,  0.1000,\n",
      "          0.1000, 86.5410, 86.5410,  0.1000, 86.4877, 86.4877, 86.4877,  0.1000,\n",
      "          0.1000, 86.4877, 86.4877,  0.1000, 86.4877,  0.1000, 86.4877, 86.5579,\n",
      "         86.5579, 86.5579,  0.1000,  0.1000, 86.5579, 86.5579,  0.1000, 86.5579,\n",
      "          0.1000, 86.5579, 86.5410, 86.5579, 86.5579, 86.5579, 86.4877, 86.5579,\n",
      "         86.5579, 86.5579, 86.5410, 86.5579, 86.5579, 86.5579, 86.5410, 86.4877,\n",
      "         86.5410, 86.5410, 86.5410,  0.1000, 86.5410, 86.4877,  0.1000, 86.4877,\n",
      "         86.5579,  0.1000, 86.5579, 86.5579, 86.5579, 86.5410, 86.5410,  0.1000,\n",
      "         86.5579,  0.1000, 86.4474, 86.4474, 86.5410, 86.5579, 86.5579,  0.1000,\n",
      "          0.1000, 86.4474, 86.5410, 86.5579,  0.1000, 86.5410, 86.5579,  0.1000,\n",
      "         86.4474, 86.5579]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 736 was 99.1%\n",
      "current params: tensor([86.4474, 86.5410, 86.4877, 86.5579], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "SLow rates:  tensor([[86.5474, 86.6410, 86.5877, 86.6580,  0.1000,  0.1000,  0.1000, 86.5474,\n",
      "         86.5474, 86.5474,  0.1000,  0.1000, 86.6410, 86.6410, 86.6410,  0.1000,\n",
      "          0.1000, 86.6410, 86.6410,  0.1000, 86.5877, 86.5877, 86.5877,  0.1000,\n",
      "          0.1000, 86.5877, 86.5877,  0.1000, 86.5877,  0.1000, 86.5877, 86.6580,\n",
      "         86.6580, 86.6580,  0.1000,  0.1000, 86.6580, 86.6580,  0.1000, 86.6580,\n",
      "          0.1000, 86.6580, 86.6410, 86.6580, 86.6580, 86.6580, 86.5877, 86.6580,\n",
      "         86.6580, 86.6580, 86.6410, 86.6580, 86.6580, 86.6580, 86.6410, 86.5877,\n",
      "         86.6410, 86.6410, 86.6410,  0.1000, 86.6410, 86.5877,  0.1000, 86.5877,\n",
      "         86.6580,  0.1000, 86.6580, 86.6580, 86.6580, 86.6410, 86.6410,  0.1000,\n",
      "         86.6580,  0.1000, 86.5474, 86.5474, 86.6410, 86.6580, 86.6580,  0.1000,\n",
      "          0.1000, 86.5474, 86.6410, 86.6580,  0.1000, 86.6410, 86.6580,  0.1000,\n",
      "         86.5474, 86.6580]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 737 was 99.1%\n",
      "current params: tensor([86.5474, 86.6410, 86.5877, 86.6580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "SLow rates:  tensor([[86.6474, 86.7410, 86.6877, 86.7580,  0.1000,  0.1000,  0.1000, 86.6474,\n",
      "         86.6474, 86.6474,  0.1000,  0.1000, 86.7410, 86.7410, 86.7410,  0.1000,\n",
      "          0.1000, 86.7410, 86.7410,  0.1000, 86.6877, 86.6877, 86.6877,  0.1000,\n",
      "          0.1000, 86.6877, 86.6877,  0.1000, 86.6877,  0.1000, 86.6877, 86.7580,\n",
      "         86.7580, 86.7580,  0.1000,  0.1000, 86.7580, 86.7580,  0.1000, 86.7580,\n",
      "          0.1000, 86.7580, 86.7410, 86.7580, 86.7580, 86.7580, 86.6877, 86.7580,\n",
      "         86.7580, 86.7580, 86.7410, 86.7580, 86.7580, 86.7580, 86.7410, 86.6877,\n",
      "         86.7410, 86.7410, 86.7410,  0.1000, 86.7410, 86.6877,  0.1000, 86.6877,\n",
      "         86.7580,  0.1000, 86.7580, 86.7580, 86.7580, 86.7410, 86.7410,  0.1000,\n",
      "         86.7580,  0.1000, 86.6474, 86.6474, 86.7410, 86.7580, 86.7580,  0.1000,\n",
      "          0.1000, 86.6474, 86.7410, 86.7580,  0.1000, 86.7410, 86.7580,  0.1000,\n",
      "         86.6474, 86.7580]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 738 was 99.1%\n",
      "current params: tensor([86.6474, 86.7410, 86.6877, 86.7580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "SLow rates:  tensor([[86.7475, 86.8411, 86.7878, 86.8580,  0.1000,  0.1000,  0.1000, 86.7475,\n",
      "         86.7475, 86.7475,  0.1000,  0.1000, 86.8411, 86.8411, 86.8411,  0.1000,\n",
      "          0.1000, 86.8411, 86.8411,  0.1000, 86.7878, 86.7878, 86.7878,  0.1000,\n",
      "          0.1000, 86.7878, 86.7878,  0.1000, 86.7878,  0.1000, 86.7878, 86.8580,\n",
      "         86.8580, 86.8580,  0.1000,  0.1000, 86.8580, 86.8580,  0.1000, 86.8580,\n",
      "          0.1000, 86.8580, 86.8411, 86.8580, 86.8580, 86.8580, 86.7878, 86.8580,\n",
      "         86.8580, 86.8580, 86.8411, 86.8580, 86.8580, 86.8580, 86.8411, 86.7878,\n",
      "         86.8411, 86.8411, 86.8411,  0.1000, 86.8411, 86.7878,  0.1000, 86.7878,\n",
      "         86.8580,  0.1000, 86.8580, 86.8580, 86.8580, 86.8411, 86.8411,  0.1000,\n",
      "         86.8580,  0.1000, 86.7475, 86.7475, 86.8411, 86.8580, 86.8580,  0.1000,\n",
      "          0.1000, 86.7475, 86.8411, 86.8580,  0.1000, 86.8411, 86.8580,  0.1000,\n",
      "         86.7475, 86.8580]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 739 was 99.1%\n",
      "current params: tensor([86.7475, 86.8411, 86.7878, 86.8580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "SLow rates:  tensor([[86.8475, 86.9411, 86.8878, 86.9580,  0.1000,  0.1000,  0.1000, 86.8475,\n",
      "         86.8475, 86.8475,  0.1000,  0.1000, 86.9411, 86.9411, 86.9411,  0.1000,\n",
      "          0.1000, 86.9411, 86.9411,  0.1000, 86.8878, 86.8878, 86.8878,  0.1000,\n",
      "          0.1000, 86.8878, 86.8878,  0.1000, 86.8878,  0.1000, 86.8878, 86.9580,\n",
      "         86.9580, 86.9580,  0.1000,  0.1000, 86.9580, 86.9580,  0.1000, 86.9580,\n",
      "          0.1000, 86.9580, 86.9411, 86.9580, 86.9580, 86.9580, 86.8878, 86.9580,\n",
      "         86.9580, 86.9580, 86.9411, 86.9580, 86.9580, 86.9580, 86.9411, 86.8878,\n",
      "         86.9411, 86.9411, 86.9411,  0.1000, 86.9411, 86.8878,  0.1000, 86.8878,\n",
      "         86.9580,  0.1000, 86.9580, 86.9580, 86.9580, 86.9411, 86.9411,  0.1000,\n",
      "         86.9580,  0.1000, 86.8475, 86.8475, 86.9411, 86.9580, 86.9580,  0.1000,\n",
      "          0.1000, 86.8475, 86.9411, 86.9580,  0.1000, 86.9411, 86.9580,  0.1000,\n",
      "         86.8475, 86.9580]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 740 was 99.1%\n",
      "current params: tensor([86.8475, 86.9411, 86.8878, 86.9580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "SLow rates:  tensor([[86.9475, 87.0411, 86.9878, 87.0580,  0.1000,  0.1000,  0.1000, 86.9475,\n",
      "         86.9475, 86.9475,  0.1000,  0.1000, 87.0411, 87.0411, 87.0411,  0.1000,\n",
      "          0.1000, 87.0411, 87.0411,  0.1000, 86.9878, 86.9878, 86.9878,  0.1000,\n",
      "          0.1000, 86.9878, 86.9878,  0.1000, 86.9878,  0.1000, 86.9878, 87.0580,\n",
      "         87.0580, 87.0580,  0.1000,  0.1000, 87.0580, 87.0580,  0.1000, 87.0580,\n",
      "          0.1000, 87.0580, 87.0411, 87.0580, 87.0580, 87.0580, 86.9878, 87.0580,\n",
      "         87.0580, 87.0580, 87.0411, 87.0580, 87.0580, 87.0580, 87.0411, 86.9878,\n",
      "         87.0411, 87.0411, 87.0411,  0.1000, 87.0411, 86.9878,  0.1000, 86.9878,\n",
      "         87.0580,  0.1000, 87.0580, 87.0580, 87.0580, 87.0411, 87.0411,  0.1000,\n",
      "         87.0580,  0.1000, 86.9475, 86.9475, 87.0411, 87.0580, 87.0580,  0.1000,\n",
      "          0.1000, 86.9475, 87.0411, 87.0580,  0.1000, 87.0411, 87.0580,  0.1000,\n",
      "         86.9475, 87.0580]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 741 was 99.1%\n",
      "current params: tensor([86.9475, 87.0411, 86.9878, 87.0580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "SLow rates:  tensor([[87.0475, 87.1411, 87.0878, 87.1581,  0.1000,  0.1000,  0.1000, 87.0475,\n",
      "         87.0475, 87.0475,  0.1000,  0.1000, 87.1411, 87.1411, 87.1411,  0.1000,\n",
      "          0.1000, 87.1411, 87.1411,  0.1000, 87.0878, 87.0878, 87.0878,  0.1000,\n",
      "          0.1000, 87.0878, 87.0878,  0.1000, 87.0878,  0.1000, 87.0878, 87.1581,\n",
      "         87.1581, 87.1581,  0.1000,  0.1000, 87.1581, 87.1581,  0.1000, 87.1581,\n",
      "          0.1000, 87.1581, 87.1411, 87.1581, 87.1581, 87.1581, 87.0878, 87.1581,\n",
      "         87.1581, 87.1581, 87.1411, 87.1581, 87.1581, 87.1581, 87.1411, 87.0878,\n",
      "         87.1411, 87.1411, 87.1411,  0.1000, 87.1411, 87.0878,  0.1000, 87.0878,\n",
      "         87.1581,  0.1000, 87.1581, 87.1581, 87.1581, 87.1411, 87.1411,  0.1000,\n",
      "         87.1581,  0.1000, 87.0475, 87.0475, 87.1411, 87.1581, 87.1581,  0.1000,\n",
      "          0.1000, 87.0475, 87.1411, 87.1581,  0.1000, 87.1411, 87.1581,  0.1000,\n",
      "         87.0475, 87.1581]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 742 was 99.1%\n",
      "current params: tensor([87.0475, 87.1411, 87.0878, 87.1581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.6\n",
      "SLow rates:  tensor([[87.1476, 87.2411, 87.1879, 87.2581,  0.1000,  0.1000,  0.1000, 87.1476,\n",
      "         87.1476, 87.1476,  0.1000,  0.1000, 87.2411, 87.2411, 87.2411,  0.1000,\n",
      "          0.1000, 87.2411, 87.2411,  0.1000, 87.1879, 87.1879, 87.1879,  0.1000,\n",
      "          0.1000, 87.1879, 87.1879,  0.1000, 87.1879,  0.1000, 87.1879, 87.2581,\n",
      "         87.2581, 87.2581,  0.1000,  0.1000, 87.2581, 87.2581,  0.1000, 87.2581,\n",
      "          0.1000, 87.2581, 87.2411, 87.2581, 87.2581, 87.2581, 87.1879, 87.2581,\n",
      "         87.2581, 87.2581, 87.2411, 87.2581, 87.2581, 87.2581, 87.2411, 87.1879,\n",
      "         87.2411, 87.2411, 87.2411,  0.1000, 87.2411, 87.1879,  0.1000, 87.1879,\n",
      "         87.2581,  0.1000, 87.2581, 87.2581, 87.2581, 87.2411, 87.2411,  0.1000,\n",
      "         87.2581,  0.1000, 87.1476, 87.1476, 87.2411, 87.2581, 87.2581,  0.1000,\n",
      "          0.1000, 87.1476, 87.2411, 87.2581,  0.1000, 87.2411, 87.2581,  0.1000,\n",
      "         87.1476, 87.2581]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 743 was 99.1%\n",
      "current params: tensor([87.1476, 87.2411, 87.1879, 87.2581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.6\n",
      "SLow rates:  tensor([[87.2476, 87.3412, 87.2879, 87.3581,  0.1000,  0.1000,  0.1000, 87.2476,\n",
      "         87.2476, 87.2476,  0.1000,  0.1000, 87.3412, 87.3412, 87.3412,  0.1000,\n",
      "          0.1000, 87.3412, 87.3412,  0.1000, 87.2879, 87.2879, 87.2879,  0.1000,\n",
      "          0.1000, 87.2879, 87.2879,  0.1000, 87.2879,  0.1000, 87.2879, 87.3581,\n",
      "         87.3581, 87.3581,  0.1000,  0.1000, 87.3581, 87.3581,  0.1000, 87.3581,\n",
      "          0.1000, 87.3581, 87.3412, 87.3581, 87.3581, 87.3581, 87.2879, 87.3581,\n",
      "         87.3581, 87.3581, 87.3412, 87.3581, 87.3581, 87.3581, 87.3412, 87.2879,\n",
      "         87.3412, 87.3412, 87.3412,  0.1000, 87.3412, 87.2879,  0.1000, 87.2879,\n",
      "         87.3581,  0.1000, 87.3581, 87.3581, 87.3581, 87.3412, 87.3412,  0.1000,\n",
      "         87.3581,  0.1000, 87.2476, 87.2476, 87.3412, 87.3581, 87.3581,  0.1000,\n",
      "          0.1000, 87.2476, 87.3412, 87.3581,  0.1000, 87.3412, 87.3581,  0.1000,\n",
      "         87.2476, 87.3581]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 744 was 99.1%\n",
      "current params: tensor([87.2476, 87.3412, 87.2879, 87.3581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.6\n",
      "SLow rates:  tensor([[87.3476, 87.4412, 87.3879, 87.4581,  0.1000,  0.1000,  0.1000, 87.3476,\n",
      "         87.3476, 87.3476,  0.1000,  0.1000, 87.4412, 87.4412, 87.4412,  0.1000,\n",
      "          0.1000, 87.4412, 87.4412,  0.1000, 87.3879, 87.3879, 87.3879,  0.1000,\n",
      "          0.1000, 87.3879, 87.3879,  0.1000, 87.3879,  0.1000, 87.3879, 87.4581,\n",
      "         87.4581, 87.4581,  0.1000,  0.1000, 87.4581, 87.4581,  0.1000, 87.4581,\n",
      "          0.1000, 87.4581, 87.4412, 87.4581, 87.4581, 87.4581, 87.3879, 87.4581,\n",
      "         87.4581, 87.4581, 87.4412, 87.4581, 87.4581, 87.4581, 87.4412, 87.3879,\n",
      "         87.4412, 87.4412, 87.4412,  0.1000, 87.4412, 87.3879,  0.1000, 87.3879,\n",
      "         87.4581,  0.1000, 87.4581, 87.4581, 87.4581, 87.4412, 87.4412,  0.1000,\n",
      "         87.4581,  0.1000, 87.3476, 87.3476, 87.4412, 87.4581, 87.4581,  0.1000,\n",
      "          0.1000, 87.3476, 87.4412, 87.4581,  0.1000, 87.4412, 87.4581,  0.1000,\n",
      "         87.3476, 87.4581]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 745 was 99.1%\n",
      "current params: tensor([87.3476, 87.4412, 87.3879, 87.4581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.6\n",
      "SLow rates:  tensor([[87.4476, 87.5412, 87.4879, 87.5581,  0.1000,  0.1000,  0.1000, 87.4476,\n",
      "         87.4476, 87.4476,  0.1000,  0.1000, 87.5412, 87.5412, 87.5412,  0.1000,\n",
      "          0.1000, 87.5412, 87.5412,  0.1000, 87.4879, 87.4879, 87.4879,  0.1000,\n",
      "          0.1000, 87.4879, 87.4879,  0.1000, 87.4879,  0.1000, 87.4879, 87.5581,\n",
      "         87.5581, 87.5581,  0.1000,  0.1000, 87.5581, 87.5581,  0.1000, 87.5581,\n",
      "          0.1000, 87.5581, 87.5412, 87.5581, 87.5581, 87.5581, 87.4879, 87.5581,\n",
      "         87.5581, 87.5581, 87.5412, 87.5581, 87.5581, 87.5581, 87.5412, 87.4879,\n",
      "         87.5412, 87.5412, 87.5412,  0.1000, 87.5412, 87.4879,  0.1000, 87.4879,\n",
      "         87.5581,  0.1000, 87.5581, 87.5581, 87.5581, 87.5412, 87.5412,  0.1000,\n",
      "         87.5581,  0.1000, 87.4476, 87.4476, 87.5412, 87.5581, 87.5581,  0.1000,\n",
      "          0.1000, 87.4476, 87.5412, 87.5581,  0.1000, 87.5412, 87.5581,  0.1000,\n",
      "         87.4476, 87.5581]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 746 was 99.1%\n",
      "current params: tensor([87.4476, 87.5412, 87.4879, 87.5581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.6\n",
      "SLow rates:  tensor([[87.5477, 87.6412, 87.5879, 87.6582,  0.1000,  0.1000,  0.1000, 87.5477,\n",
      "         87.5477, 87.5477,  0.1000,  0.1000, 87.6412, 87.6412, 87.6412,  0.1000,\n",
      "          0.1000, 87.6412, 87.6412,  0.1000, 87.5879, 87.5879, 87.5879,  0.1000,\n",
      "          0.1000, 87.5879, 87.5879,  0.1000, 87.5879,  0.1000, 87.5879, 87.6582,\n",
      "         87.6582, 87.6582,  0.1000,  0.1000, 87.6582, 87.6582,  0.1000, 87.6582,\n",
      "          0.1000, 87.6582, 87.6412, 87.6582, 87.6582, 87.6582, 87.5879, 87.6582,\n",
      "         87.6582, 87.6582, 87.6412, 87.6582, 87.6582, 87.6582, 87.6412, 87.5879,\n",
      "         87.6412, 87.6412, 87.6412,  0.1000, 87.6412, 87.5879,  0.1000, 87.5879,\n",
      "         87.6582,  0.1000, 87.6582, 87.6582, 87.6582, 87.6412, 87.6412,  0.1000,\n",
      "         87.6582,  0.1000, 87.5477, 87.5477, 87.6412, 87.6582, 87.6582,  0.1000,\n",
      "          0.1000, 87.5477, 87.6412, 87.6582,  0.1000, 87.6412, 87.6582,  0.1000,\n",
      "         87.5477, 87.6582]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 747 was 99.1%\n",
      "current params: tensor([87.5477, 87.6412, 87.5879, 87.6582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.7\n",
      "SLow rates:  tensor([[87.6477, 87.7413, 87.6880, 87.7582,  0.1000,  0.1000,  0.1000, 87.6477,\n",
      "         87.6477, 87.6477,  0.1000,  0.1000, 87.7413, 87.7413, 87.7413,  0.1000,\n",
      "          0.1000, 87.7413, 87.7413,  0.1000, 87.6880, 87.6880, 87.6880,  0.1000,\n",
      "          0.1000, 87.6880, 87.6880,  0.1000, 87.6880,  0.1000, 87.6880, 87.7582,\n",
      "         87.7582, 87.7582,  0.1000,  0.1000, 87.7582, 87.7582,  0.1000, 87.7582,\n",
      "          0.1000, 87.7582, 87.7413, 87.7582, 87.7582, 87.7582, 87.6880, 87.7582,\n",
      "         87.7582, 87.7582, 87.7413, 87.7582, 87.7582, 87.7582, 87.7413, 87.6880,\n",
      "         87.7413, 87.7413, 87.7413,  0.1000, 87.7413, 87.6880,  0.1000, 87.6880,\n",
      "         87.7582,  0.1000, 87.7582, 87.7582, 87.7582, 87.7413, 87.7413,  0.1000,\n",
      "         87.7582,  0.1000, 87.6477, 87.6477, 87.7413, 87.7582, 87.7582,  0.1000,\n",
      "          0.1000, 87.6477, 87.7413, 87.7582,  0.1000, 87.7413, 87.7582,  0.1000,\n",
      "         87.6477, 87.7582]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 748 was 99.1%\n",
      "current params: tensor([87.6477, 87.7413, 87.6880, 87.7582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.7\n",
      "SLow rates:  tensor([[87.7477, 87.8413, 87.7880, 87.8582,  0.1000,  0.1000,  0.1000, 87.7477,\n",
      "         87.7477, 87.7477,  0.1000,  0.1000, 87.8413, 87.8413, 87.8413,  0.1000,\n",
      "          0.1000, 87.8413, 87.8413,  0.1000, 87.7880, 87.7880, 87.7880,  0.1000,\n",
      "          0.1000, 87.7880, 87.7880,  0.1000, 87.7880,  0.1000, 87.7880, 87.8582,\n",
      "         87.8582, 87.8582,  0.1000,  0.1000, 87.8582, 87.8582,  0.1000, 87.8582,\n",
      "          0.1000, 87.8582, 87.8413, 87.8582, 87.8582, 87.8582, 87.7880, 87.8582,\n",
      "         87.8582, 87.8582, 87.8413, 87.8582, 87.8582, 87.8582, 87.8413, 87.7880,\n",
      "         87.8413, 87.8413, 87.8413,  0.1000, 87.8413, 87.7880,  0.1000, 87.7880,\n",
      "         87.8582,  0.1000, 87.8582, 87.8582, 87.8582, 87.8413, 87.8413,  0.1000,\n",
      "         87.8582,  0.1000, 87.7477, 87.7477, 87.8413, 87.8582, 87.8582,  0.1000,\n",
      "          0.1000, 87.7477, 87.8413, 87.8582,  0.1000, 87.8413, 87.8582,  0.1000,\n",
      "         87.7477, 87.8582]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 749 was 99.1%\n",
      "current params: tensor([87.7477, 87.8413, 87.7880, 87.8582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.7\n",
      "SLow rates:  tensor([[87.8477, 87.9413, 87.8880, 87.9582,  0.1000,  0.1000,  0.1000, 87.8477,\n",
      "         87.8477, 87.8477,  0.1000,  0.1000, 87.9413, 87.9413, 87.9413,  0.1000,\n",
      "          0.1000, 87.9413, 87.9413,  0.1000, 87.8880, 87.8880, 87.8880,  0.1000,\n",
      "          0.1000, 87.8880, 87.8880,  0.1000, 87.8880,  0.1000, 87.8880, 87.9582,\n",
      "         87.9582, 87.9582,  0.1000,  0.1000, 87.9582, 87.9582,  0.1000, 87.9582,\n",
      "          0.1000, 87.9582, 87.9413, 87.9582, 87.9582, 87.9582, 87.8880, 87.9582,\n",
      "         87.9582, 87.9582, 87.9413, 87.9582, 87.9582, 87.9582, 87.9413, 87.8880,\n",
      "         87.9413, 87.9413, 87.9413,  0.1000, 87.9413, 87.8880,  0.1000, 87.8880,\n",
      "         87.9582,  0.1000, 87.9582, 87.9582, 87.9582, 87.9413, 87.9413,  0.1000,\n",
      "         87.9582,  0.1000, 87.8477, 87.8477, 87.9413, 87.9582, 87.9582,  0.1000,\n",
      "          0.1000, 87.8477, 87.9413, 87.9582,  0.1000, 87.9413, 87.9582,  0.1000,\n",
      "         87.8477, 87.9582]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.1013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 750 was 99.1%\n",
      "current params: tensor([87.8477, 87.9413, 87.8880, 87.9582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.7\n",
      "SLow rates:  tensor([[87.9478, 88.0413, 87.9880, 88.0582,  0.1000,  0.1000,  0.1000, 87.9478,\n",
      "         87.9478, 87.9478,  0.1000,  0.1000, 88.0413, 88.0413, 88.0413,  0.1000,\n",
      "          0.1000, 88.0413, 88.0413,  0.1000, 87.9880, 87.9880, 87.9880,  0.1000,\n",
      "          0.1000, 87.9880, 87.9880,  0.1000, 87.9880,  0.1000, 87.9880, 88.0582,\n",
      "         88.0582, 88.0582,  0.1000,  0.1000, 88.0582, 88.0582,  0.1000, 88.0582,\n",
      "          0.1000, 88.0582, 88.0413, 88.0582, 88.0582, 88.0582, 87.9880, 88.0582,\n",
      "         88.0582, 88.0582, 88.0413, 88.0582, 88.0582, 88.0582, 88.0413, 87.9880,\n",
      "         88.0413, 88.0413, 88.0413,  0.1000, 88.0413, 87.9880,  0.1000, 87.9880,\n",
      "         88.0582,  0.1000, 88.0582, 88.0582, 88.0582, 88.0413, 88.0413,  0.1000,\n",
      "         88.0582,  0.1000, 87.9478, 87.9478, 88.0413, 88.0582, 88.0582,  0.1000,\n",
      "          0.1000, 87.9478, 88.0413, 88.0582,  0.1000, 88.0413, 88.0582,  0.1000,\n",
      "         87.9478, 88.0582]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.1004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 751 was 99.1%\n",
      "current params: tensor([87.9478, 88.0413, 87.9880, 88.0582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.7\n",
      "SLow rates:  tensor([[88.0478, 88.1413, 88.0881, 88.1583,  0.1000,  0.1000,  0.1000, 88.0478,\n",
      "         88.0478, 88.0478,  0.1000,  0.1000, 88.1413, 88.1413, 88.1413,  0.1000,\n",
      "          0.1000, 88.1413, 88.1413,  0.1000, 88.0881, 88.0881, 88.0881,  0.1000,\n",
      "          0.1000, 88.0881, 88.0881,  0.1000, 88.0881,  0.1000, 88.0881, 88.1583,\n",
      "         88.1583, 88.1583,  0.1000,  0.1000, 88.1583, 88.1583,  0.1000, 88.1583,\n",
      "          0.1000, 88.1583, 88.1413, 88.1583, 88.1583, 88.1583, 88.0881, 88.1583,\n",
      "         88.1583, 88.1583, 88.1413, 88.1583, 88.1583, 88.1583, 88.1413, 88.0881,\n",
      "         88.1413, 88.1413, 88.1413,  0.1000, 88.1413, 88.0881,  0.1000, 88.0881,\n",
      "         88.1583,  0.1000, 88.1583, 88.1583, 88.1583, 88.1413, 88.1413,  0.1000,\n",
      "         88.1583,  0.1000, 88.0478, 88.0478, 88.1413, 88.1583, 88.1583,  0.1000,\n",
      "          0.1000, 88.0478, 88.1413, 88.1583,  0.1000, 88.1413, 88.1583,  0.1000,\n",
      "         88.0478, 88.1583]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 752 was 99.1%\n",
      "current params: tensor([88.0478, 88.1413, 88.0881, 88.1583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.8\n",
      "SLow rates:  tensor([[88.1478, 88.2414, 88.1881, 88.2583,  0.1000,  0.1000,  0.1000, 88.1478,\n",
      "         88.1478, 88.1478,  0.1000,  0.1000, 88.2414, 88.2414, 88.2414,  0.1000,\n",
      "          0.1000, 88.2414, 88.2414,  0.1000, 88.1881, 88.1881, 88.1881,  0.1000,\n",
      "          0.1000, 88.1881, 88.1881,  0.1000, 88.1881,  0.1000, 88.1881, 88.2583,\n",
      "         88.2583, 88.2583,  0.1000,  0.1000, 88.2583, 88.2583,  0.1000, 88.2583,\n",
      "          0.1000, 88.2583, 88.2414, 88.2583, 88.2583, 88.2583, 88.1881, 88.2583,\n",
      "         88.2583, 88.2583, 88.2414, 88.2583, 88.2583, 88.2583, 88.2414, 88.1881,\n",
      "         88.2414, 88.2414, 88.2414,  0.1000, 88.2414, 88.1881,  0.1000, 88.1881,\n",
      "         88.2583,  0.1000, 88.2583, 88.2583, 88.2583, 88.2414, 88.2414,  0.1000,\n",
      "         88.2583,  0.1000, 88.1478, 88.1478, 88.2414, 88.2583, 88.2583,  0.1000,\n",
      "          0.1000, 88.1478, 88.2414, 88.2583,  0.1000, 88.2414, 88.2583,  0.1000,\n",
      "         88.1478, 88.2583]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 753 was 99.1%\n",
      "current params: tensor([88.1478, 88.2414, 88.1881, 88.2583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.8\n",
      "SLow rates:  tensor([[88.2478, 88.3414, 88.2881, 88.3583,  0.1000,  0.1000,  0.1000, 88.2478,\n",
      "         88.2478, 88.2478,  0.1000,  0.1000, 88.3414, 88.3414, 88.3414,  0.1000,\n",
      "          0.1000, 88.3414, 88.3414,  0.1000, 88.2881, 88.2881, 88.2881,  0.1000,\n",
      "          0.1000, 88.2881, 88.2881,  0.1000, 88.2881,  0.1000, 88.2881, 88.3583,\n",
      "         88.3583, 88.3583,  0.1000,  0.1000, 88.3583, 88.3583,  0.1000, 88.3583,\n",
      "          0.1000, 88.3583, 88.3414, 88.3583, 88.3583, 88.3583, 88.2881, 88.3583,\n",
      "         88.3583, 88.3583, 88.3414, 88.3583, 88.3583, 88.3583, 88.3414, 88.2881,\n",
      "         88.3414, 88.3414, 88.3414,  0.1000, 88.3414, 88.2881,  0.1000, 88.2881,\n",
      "         88.3583,  0.1000, 88.3583, 88.3583, 88.3583, 88.3414, 88.3414,  0.1000,\n",
      "         88.3583,  0.1000, 88.2478, 88.2478, 88.3414, 88.3583, 88.3583,  0.1000,\n",
      "          0.1000, 88.2478, 88.3414, 88.3583,  0.1000, 88.3414, 88.3583,  0.1000,\n",
      "         88.2478, 88.3583]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 754 was 99.1%\n",
      "current params: tensor([88.2478, 88.3414, 88.2881, 88.3583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.8\n",
      "SLow rates:  tensor([[88.3478, 88.4414, 88.3881, 88.4583,  0.1000,  0.1000,  0.1000, 88.3478,\n",
      "         88.3478, 88.3478,  0.1000,  0.1000, 88.4414, 88.4414, 88.4414,  0.1000,\n",
      "          0.1000, 88.4414, 88.4414,  0.1000, 88.3881, 88.3881, 88.3881,  0.1000,\n",
      "          0.1000, 88.3881, 88.3881,  0.1000, 88.3881,  0.1000, 88.3881, 88.4583,\n",
      "         88.4583, 88.4583,  0.1000,  0.1000, 88.4583, 88.4583,  0.1000, 88.4583,\n",
      "          0.1000, 88.4583, 88.4414, 88.4583, 88.4583, 88.4583, 88.3881, 88.4583,\n",
      "         88.4583, 88.4583, 88.4414, 88.4583, 88.4583, 88.4583, 88.4414, 88.3881,\n",
      "         88.4414, 88.4414, 88.4414,  0.1000, 88.4414, 88.3881,  0.1000, 88.3881,\n",
      "         88.4583,  0.1000, 88.4583, 88.4583, 88.4583, 88.4414, 88.4414,  0.1000,\n",
      "         88.4583,  0.1000, 88.3478, 88.3478, 88.4414, 88.4583, 88.4583,  0.1000,\n",
      "          0.1000, 88.3478, 88.4414, 88.4583,  0.1000, 88.4414, 88.4583,  0.1000,\n",
      "         88.3478, 88.4583]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 755 was 99.1%\n",
      "current params: tensor([88.3478, 88.4414, 88.3881, 88.4583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.8\n",
      "SLow rates:  tensor([[88.4479, 88.5414, 88.4881, 88.5583,  0.1000,  0.1000,  0.1000, 88.4479,\n",
      "         88.4479, 88.4479,  0.1000,  0.1000, 88.5414, 88.5414, 88.5414,  0.1000,\n",
      "          0.1000, 88.5414, 88.5414,  0.1000, 88.4881, 88.4881, 88.4881,  0.1000,\n",
      "          0.1000, 88.4881, 88.4881,  0.1000, 88.4881,  0.1000, 88.4881, 88.5583,\n",
      "         88.5583, 88.5583,  0.1000,  0.1000, 88.5583, 88.5583,  0.1000, 88.5583,\n",
      "          0.1000, 88.5583, 88.5414, 88.5583, 88.5583, 88.5583, 88.4881, 88.5583,\n",
      "         88.5583, 88.5583, 88.5414, 88.5583, 88.5583, 88.5583, 88.5414, 88.4881,\n",
      "         88.5414, 88.5414, 88.5414,  0.1000, 88.5414, 88.4881,  0.1000, 88.4881,\n",
      "         88.5583,  0.1000, 88.5583, 88.5583, 88.5583, 88.5414, 88.5414,  0.1000,\n",
      "         88.5583,  0.1000, 88.4479, 88.4479, 88.5414, 88.5583, 88.5583,  0.1000,\n",
      "          0.1000, 88.4479, 88.5414, 88.5583,  0.1000, 88.5414, 88.5583,  0.1000,\n",
      "         88.4479, 88.5583]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 756 was 99.1%\n",
      "current params: tensor([88.4479, 88.5414, 88.4881, 88.5583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.9\n",
      "SLow rates:  tensor([[88.5479, 88.6414, 88.5882, 88.6584,  0.1000,  0.1000,  0.1000, 88.5479,\n",
      "         88.5479, 88.5479,  0.1000,  0.1000, 88.6414, 88.6414, 88.6414,  0.1000,\n",
      "          0.1000, 88.6414, 88.6414,  0.1000, 88.5882, 88.5882, 88.5882,  0.1000,\n",
      "          0.1000, 88.5882, 88.5882,  0.1000, 88.5882,  0.1000, 88.5882, 88.6584,\n",
      "         88.6584, 88.6584,  0.1000,  0.1000, 88.6584, 88.6584,  0.1000, 88.6584,\n",
      "          0.1000, 88.6584, 88.6414, 88.6584, 88.6584, 88.6584, 88.5882, 88.6584,\n",
      "         88.6584, 88.6584, 88.6414, 88.6584, 88.6584, 88.6584, 88.6414, 88.5882,\n",
      "         88.6414, 88.6414, 88.6414,  0.1000, 88.6414, 88.5882,  0.1000, 88.5882,\n",
      "         88.6584,  0.1000, 88.6584, 88.6584, 88.6584, 88.6414, 88.6414,  0.1000,\n",
      "         88.6584,  0.1000, 88.5479, 88.5479, 88.6414, 88.6584, 88.6584,  0.1000,\n",
      "          0.1000, 88.5479, 88.6414, 88.6584,  0.1000, 88.6414, 88.6584,  0.1000,\n",
      "         88.5479, 88.6584]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0960, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 757 was 99.1%\n",
      "current params: tensor([88.5479, 88.6414, 88.5882, 88.6584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.9\n",
      "SLow rates:  tensor([[88.6479, 88.7415, 88.6882, 88.7584,  0.1000,  0.1000,  0.1000, 88.6479,\n",
      "         88.6479, 88.6479,  0.1000,  0.1000, 88.7415, 88.7415, 88.7415,  0.1000,\n",
      "          0.1000, 88.7415, 88.7415,  0.1000, 88.6882, 88.6882, 88.6882,  0.1000,\n",
      "          0.1000, 88.6882, 88.6882,  0.1000, 88.6882,  0.1000, 88.6882, 88.7584,\n",
      "         88.7584, 88.7584,  0.1000,  0.1000, 88.7584, 88.7584,  0.1000, 88.7584,\n",
      "          0.1000, 88.7584, 88.7415, 88.7584, 88.7584, 88.7584, 88.6882, 88.7584,\n",
      "         88.7584, 88.7584, 88.7415, 88.7584, 88.7584, 88.7584, 88.7415, 88.6882,\n",
      "         88.7415, 88.7415, 88.7415,  0.1000, 88.7415, 88.6882,  0.1000, 88.6882,\n",
      "         88.7584,  0.1000, 88.7584, 88.7584, 88.7584, 88.7415, 88.7415,  0.1000,\n",
      "         88.7584,  0.1000, 88.6479, 88.6479, 88.7415, 88.7584, 88.7584,  0.1000,\n",
      "          0.1000, 88.6479, 88.7415, 88.7584,  0.1000, 88.7415, 88.7584,  0.1000,\n",
      "         88.6479, 88.7584]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 758 was 99.1%\n",
      "current params: tensor([88.6479, 88.7415, 88.6882, 88.7584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.9\n",
      "SLow rates:  tensor([[88.7479, 88.8415, 88.7882, 88.8584,  0.1000,  0.1000,  0.1000, 88.7479,\n",
      "         88.7479, 88.7479,  0.1000,  0.1000, 88.8415, 88.8415, 88.8415,  0.1000,\n",
      "          0.1000, 88.8415, 88.8415,  0.1000, 88.7882, 88.7882, 88.7882,  0.1000,\n",
      "          0.1000, 88.7882, 88.7882,  0.1000, 88.7882,  0.1000, 88.7882, 88.8584,\n",
      "         88.8584, 88.8584,  0.1000,  0.1000, 88.8584, 88.8584,  0.1000, 88.8584,\n",
      "          0.1000, 88.8584, 88.8415, 88.8584, 88.8584, 88.8584, 88.7882, 88.8584,\n",
      "         88.8584, 88.8584, 88.8415, 88.8584, 88.8584, 88.8584, 88.8415, 88.7882,\n",
      "         88.8415, 88.8415, 88.8415,  0.1000, 88.8415, 88.7882,  0.1000, 88.7882,\n",
      "         88.8584,  0.1000, 88.8584, 88.8584, 88.8584, 88.8415, 88.8415,  0.1000,\n",
      "         88.8584,  0.1000, 88.7479, 88.7479, 88.8415, 88.8584, 88.8584,  0.1000,\n",
      "          0.1000, 88.7479, 88.8415, 88.8584,  0.1000, 88.8415, 88.8584,  0.1000,\n",
      "         88.7479, 88.8584]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 759 was 99.1%\n",
      "current params: tensor([88.7479, 88.8415, 88.7882, 88.8584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.9\n",
      "SLow rates:  tensor([[88.8480, 88.9415, 88.8882, 88.9584,  0.1000,  0.1000,  0.1000, 88.8480,\n",
      "         88.8480, 88.8480,  0.1000,  0.1000, 88.9415, 88.9415, 88.9415,  0.1000,\n",
      "          0.1000, 88.9415, 88.9415,  0.1000, 88.8882, 88.8882, 88.8882,  0.1000,\n",
      "          0.1000, 88.8882, 88.8882,  0.1000, 88.8882,  0.1000, 88.8882, 88.9584,\n",
      "         88.9584, 88.9584,  0.1000,  0.1000, 88.9584, 88.9584,  0.1000, 88.9584,\n",
      "          0.1000, 88.9584, 88.9415, 88.9584, 88.9584, 88.9584, 88.8882, 88.9584,\n",
      "         88.9584, 88.9584, 88.9415, 88.9584, 88.9584, 88.9584, 88.9415, 88.8882,\n",
      "         88.9415, 88.9415, 88.9415,  0.1000, 88.9415, 88.8882,  0.1000, 88.8882,\n",
      "         88.9584,  0.1000, 88.9584, 88.9584, 88.9584, 88.9415, 88.9415,  0.1000,\n",
      "         88.9584,  0.1000, 88.8480, 88.8480, 88.9415, 88.9584, 88.9584,  0.1000,\n",
      "          0.1000, 88.8480, 88.9415, 88.9584,  0.1000, 88.9415, 88.9584,  0.1000,\n",
      "         88.8480, 88.9584]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 760 was 99.1%\n",
      "current params: tensor([88.8480, 88.9415, 88.8882, 88.9584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.9\n",
      "SLow rates:  tensor([[88.9480, 89.0415, 88.9882, 89.0584,  0.1000,  0.1000,  0.1000, 88.9480,\n",
      "         88.9480, 88.9480,  0.1000,  0.1000, 89.0415, 89.0415, 89.0415,  0.1000,\n",
      "          0.1000, 89.0415, 89.0415,  0.1000, 88.9882, 88.9882, 88.9882,  0.1000,\n",
      "          0.1000, 88.9882, 88.9882,  0.1000, 88.9882,  0.1000, 88.9882, 89.0584,\n",
      "         89.0584, 89.0584,  0.1000,  0.1000, 89.0584, 89.0584,  0.1000, 89.0584,\n",
      "          0.1000, 89.0584, 89.0415, 89.0584, 89.0584, 89.0584, 88.9882, 89.0584,\n",
      "         89.0584, 89.0584, 89.0415, 89.0584, 89.0584, 89.0584, 89.0415, 88.9882,\n",
      "         89.0415, 89.0415, 89.0415,  0.1000, 89.0415, 88.9882,  0.1000, 88.9882,\n",
      "         89.0584,  0.1000, 89.0584, 89.0584, 89.0584, 89.0415, 89.0415,  0.1000,\n",
      "         89.0584,  0.1000, 88.9480, 88.9480, 89.0415, 89.0584, 89.0584,  0.1000,\n",
      "          0.1000, 88.9480, 89.0415, 89.0584,  0.1000, 89.0415, 89.0584,  0.1000,\n",
      "         88.9480, 89.0584]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 761 was 99.1%\n",
      "current params: tensor([88.9480, 89.0415, 88.9882, 89.0584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.9\n",
      "SLow rates:  tensor([[89.0480, 89.1415, 89.0883, 89.1584,  0.1000,  0.1000,  0.1000, 89.0480,\n",
      "         89.0480, 89.0480,  0.1000,  0.1000, 89.1415, 89.1415, 89.1415,  0.1000,\n",
      "          0.1000, 89.1415, 89.1415,  0.1000, 89.0883, 89.0883, 89.0883,  0.1000,\n",
      "          0.1000, 89.0883, 89.0883,  0.1000, 89.0883,  0.1000, 89.0883, 89.1584,\n",
      "         89.1584, 89.1584,  0.1000,  0.1000, 89.1584, 89.1584,  0.1000, 89.1584,\n",
      "          0.1000, 89.1584, 89.1415, 89.1584, 89.1584, 89.1584, 89.0883, 89.1584,\n",
      "         89.1584, 89.1584, 89.1415, 89.1584, 89.1584, 89.1584, 89.1415, 89.0883,\n",
      "         89.1415, 89.1415, 89.1415,  0.1000, 89.1415, 89.0883,  0.1000, 89.0883,\n",
      "         89.1584,  0.1000, 89.1584, 89.1584, 89.1584, 89.1415, 89.1415,  0.1000,\n",
      "         89.1584,  0.1000, 89.0480, 89.0480, 89.1415, 89.1584, 89.1584,  0.1000,\n",
      "          0.1000, 89.0480, 89.1415, 89.1584,  0.1000, 89.1415, 89.1584,  0.1000,\n",
      "         89.0480, 89.1584]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 762 was 99.1%\n",
      "current params: tensor([89.0480, 89.1415, 89.0883, 89.1584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.0\n",
      "SLow rates:  tensor([[89.1480, 89.2416, 89.1883, 89.2585,  0.1000,  0.1000,  0.1000, 89.1480,\n",
      "         89.1480, 89.1480,  0.1000,  0.1000, 89.2416, 89.2416, 89.2416,  0.1000,\n",
      "          0.1000, 89.2416, 89.2416,  0.1000, 89.1883, 89.1883, 89.1883,  0.1000,\n",
      "          0.1000, 89.1883, 89.1883,  0.1000, 89.1883,  0.1000, 89.1883, 89.2585,\n",
      "         89.2585, 89.2585,  0.1000,  0.1000, 89.2585, 89.2585,  0.1000, 89.2585,\n",
      "          0.1000, 89.2585, 89.2416, 89.2585, 89.2585, 89.2585, 89.1883, 89.2585,\n",
      "         89.2585, 89.2585, 89.2416, 89.2585, 89.2585, 89.2585, 89.2416, 89.1883,\n",
      "         89.2416, 89.2416, 89.2416,  0.1000, 89.2416, 89.1883,  0.1000, 89.1883,\n",
      "         89.2585,  0.1000, 89.2585, 89.2585, 89.2585, 89.2416, 89.2416,  0.1000,\n",
      "         89.2585,  0.1000, 89.1480, 89.1480, 89.2416, 89.2585, 89.2585,  0.1000,\n",
      "          0.1000, 89.1480, 89.2416, 89.2585,  0.1000, 89.2416, 89.2585,  0.1000,\n",
      "         89.1480, 89.2585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 763 was 99.1%\n",
      "current params: tensor([89.1480, 89.2416, 89.1883, 89.2585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.0\n",
      "SLow rates:  tensor([[89.2480, 89.3416, 89.2883, 89.3585,  0.1000,  0.1000,  0.1000, 89.2480,\n",
      "         89.2480, 89.2480,  0.1000,  0.1000, 89.3416, 89.3416, 89.3416,  0.1000,\n",
      "          0.1000, 89.3416, 89.3416,  0.1000, 89.2883, 89.2883, 89.2883,  0.1000,\n",
      "          0.1000, 89.2883, 89.2883,  0.1000, 89.2883,  0.1000, 89.2883, 89.3585,\n",
      "         89.3585, 89.3585,  0.1000,  0.1000, 89.3585, 89.3585,  0.1000, 89.3585,\n",
      "          0.1000, 89.3585, 89.3416, 89.3585, 89.3585, 89.3585, 89.2883, 89.3585,\n",
      "         89.3585, 89.3585, 89.3416, 89.3585, 89.3585, 89.3585, 89.3416, 89.2883,\n",
      "         89.3416, 89.3416, 89.3416,  0.1000, 89.3416, 89.2883,  0.1000, 89.2883,\n",
      "         89.3585,  0.1000, 89.3585, 89.3585, 89.3585, 89.3416, 89.3416,  0.1000,\n",
      "         89.3585,  0.1000, 89.2480, 89.2480, 89.3416, 89.3585, 89.3585,  0.1000,\n",
      "          0.1000, 89.2480, 89.3416, 89.3585,  0.1000, 89.3416, 89.3585,  0.1000,\n",
      "         89.2480, 89.3585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 764 was 99.1%\n",
      "current params: tensor([89.2480, 89.3416, 89.2883, 89.3585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.0\n",
      "SLow rates:  tensor([[89.3481, 89.4416, 89.3883, 89.4585,  0.1000,  0.1000,  0.1000, 89.3481,\n",
      "         89.3481, 89.3481,  0.1000,  0.1000, 89.4416, 89.4416, 89.4416,  0.1000,\n",
      "          0.1000, 89.4416, 89.4416,  0.1000, 89.3883, 89.3883, 89.3883,  0.1000,\n",
      "          0.1000, 89.3883, 89.3883,  0.1000, 89.3883,  0.1000, 89.3883, 89.4585,\n",
      "         89.4585, 89.4585,  0.1000,  0.1000, 89.4585, 89.4585,  0.1000, 89.4585,\n",
      "          0.1000, 89.4585, 89.4416, 89.4585, 89.4585, 89.4585, 89.3883, 89.4585,\n",
      "         89.4585, 89.4585, 89.4416, 89.4585, 89.4585, 89.4585, 89.4416, 89.3883,\n",
      "         89.4416, 89.4416, 89.4416,  0.1000, 89.4416, 89.3883,  0.1000, 89.3883,\n",
      "         89.4585,  0.1000, 89.4585, 89.4585, 89.4585, 89.4416, 89.4416,  0.1000,\n",
      "         89.4585,  0.1000, 89.3481, 89.3481, 89.4416, 89.4585, 89.4585,  0.1000,\n",
      "          0.1000, 89.3481, 89.4416, 89.4585,  0.1000, 89.4416, 89.4585,  0.1000,\n",
      "         89.3481, 89.4585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 765 was 99.1%\n",
      "current params: tensor([89.3481, 89.4416, 89.3883, 89.4585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.0\n",
      "SLow rates:  tensor([[89.4481, 89.5416, 89.4883, 89.5585,  0.1000,  0.1000,  0.1000, 89.4481,\n",
      "         89.4481, 89.4481,  0.1000,  0.1000, 89.5416, 89.5416, 89.5416,  0.1000,\n",
      "          0.1000, 89.5416, 89.5416,  0.1000, 89.4883, 89.4883, 89.4883,  0.1000,\n",
      "          0.1000, 89.4883, 89.4883,  0.1000, 89.4883,  0.1000, 89.4883, 89.5585,\n",
      "         89.5585, 89.5585,  0.1000,  0.1000, 89.5585, 89.5585,  0.1000, 89.5585,\n",
      "          0.1000, 89.5585, 89.5416, 89.5585, 89.5585, 89.5585, 89.4883, 89.5585,\n",
      "         89.5585, 89.5585, 89.5416, 89.5585, 89.5585, 89.5585, 89.5416, 89.4883,\n",
      "         89.5416, 89.5416, 89.5416,  0.1000, 89.5416, 89.4883,  0.1000, 89.4883,\n",
      "         89.5585,  0.1000, 89.5585, 89.5585, 89.5585, 89.5416, 89.5416,  0.1000,\n",
      "         89.5585,  0.1000, 89.4481, 89.4481, 89.5416, 89.5585, 89.5585,  0.1000,\n",
      "          0.1000, 89.4481, 89.5416, 89.5585,  0.1000, 89.5416, 89.5585,  0.1000,\n",
      "         89.4481, 89.5585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 766 was 99.1%\n",
      "current params: tensor([89.4481, 89.5416, 89.4883, 89.5585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.0\n",
      "SLow rates:  tensor([[89.5481, 89.6416, 89.5884, 89.6585,  0.1000,  0.1000,  0.1000, 89.5481,\n",
      "         89.5481, 89.5481,  0.1000,  0.1000, 89.6416, 89.6416, 89.6416,  0.1000,\n",
      "          0.1000, 89.6416, 89.6416,  0.1000, 89.5884, 89.5884, 89.5884,  0.1000,\n",
      "          0.1000, 89.5884, 89.5884,  0.1000, 89.5884,  0.1000, 89.5884, 89.6585,\n",
      "         89.6585, 89.6585,  0.1000,  0.1000, 89.6585, 89.6585,  0.1000, 89.6585,\n",
      "          0.1000, 89.6585, 89.6416, 89.6585, 89.6585, 89.6585, 89.5884, 89.6585,\n",
      "         89.6585, 89.6585, 89.6416, 89.6585, 89.6585, 89.6585, 89.6416, 89.5884,\n",
      "         89.6416, 89.6416, 89.6416,  0.1000, 89.6416, 89.5884,  0.1000, 89.5884,\n",
      "         89.6585,  0.1000, 89.6585, 89.6585, 89.6585, 89.6416, 89.6416,  0.1000,\n",
      "         89.6585,  0.1000, 89.5481, 89.5481, 89.6416, 89.6585, 89.6585,  0.1000,\n",
      "          0.1000, 89.5481, 89.6416, 89.6585,  0.1000, 89.6416, 89.6585,  0.1000,\n",
      "         89.5481, 89.6585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 767 was 99.1%\n",
      "current params: tensor([89.5481, 89.6416, 89.5884, 89.6585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.1\n",
      "SLow rates:  tensor([[89.6481, 89.7416, 89.6884, 89.7585,  0.1000,  0.1000,  0.1000, 89.6481,\n",
      "         89.6481, 89.6481,  0.1000,  0.1000, 89.7416, 89.7416, 89.7416,  0.1000,\n",
      "          0.1000, 89.7416, 89.7416,  0.1000, 89.6884, 89.6884, 89.6884,  0.1000,\n",
      "          0.1000, 89.6884, 89.6884,  0.1000, 89.6884,  0.1000, 89.6884, 89.7585,\n",
      "         89.7585, 89.7585,  0.1000,  0.1000, 89.7585, 89.7585,  0.1000, 89.7585,\n",
      "          0.1000, 89.7585, 89.7416, 89.7585, 89.7585, 89.7585, 89.6884, 89.7585,\n",
      "         89.7585, 89.7585, 89.7416, 89.7585, 89.7585, 89.7585, 89.7416, 89.6884,\n",
      "         89.7416, 89.7416, 89.7416,  0.1000, 89.7416, 89.6884,  0.1000, 89.6884,\n",
      "         89.7585,  0.1000, 89.7585, 89.7585, 89.7585, 89.7416, 89.7416,  0.1000,\n",
      "         89.7585,  0.1000, 89.6481, 89.6481, 89.7416, 89.7585, 89.7585,  0.1000,\n",
      "          0.1000, 89.6481, 89.7416, 89.7585,  0.1000, 89.7416, 89.7585,  0.1000,\n",
      "         89.6481, 89.7585]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 768 was 99.1%\n",
      "current params: tensor([89.6481, 89.7416, 89.6884, 89.7585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.1\n",
      "SLow rates:  tensor([[89.7481, 89.8417, 89.7884, 89.8586,  0.1000,  0.1000,  0.1000, 89.7481,\n",
      "         89.7481, 89.7481,  0.1000,  0.1000, 89.8417, 89.8417, 89.8417,  0.1000,\n",
      "          0.1000, 89.8417, 89.8417,  0.1000, 89.7884, 89.7884, 89.7884,  0.1000,\n",
      "          0.1000, 89.7884, 89.7884,  0.1000, 89.7884,  0.1000, 89.7884, 89.8586,\n",
      "         89.8586, 89.8586,  0.1000,  0.1000, 89.8586, 89.8586,  0.1000, 89.8586,\n",
      "          0.1000, 89.8586, 89.8417, 89.8586, 89.8586, 89.8586, 89.7884, 89.8586,\n",
      "         89.8586, 89.8586, 89.8417, 89.8586, 89.8586, 89.8586, 89.8417, 89.7884,\n",
      "         89.8417, 89.8417, 89.8417,  0.1000, 89.8417, 89.7884,  0.1000, 89.7884,\n",
      "         89.8586,  0.1000, 89.8586, 89.8586, 89.8586, 89.8417, 89.8417,  0.1000,\n",
      "         89.8586,  0.1000, 89.7481, 89.7481, 89.8417, 89.8586, 89.8586,  0.1000,\n",
      "          0.1000, 89.7481, 89.8417, 89.8586,  0.1000, 89.8417, 89.8586,  0.1000,\n",
      "         89.7481, 89.8586]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0890, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 769 was 99.1%\n",
      "current params: tensor([89.7481, 89.8417, 89.7884, 89.8586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.1\n",
      "SLow rates:  tensor([[89.8482, 89.9417, 89.8884, 89.9586,  0.1000,  0.1000,  0.1000, 89.8482,\n",
      "         89.8482, 89.8482,  0.1000,  0.1000, 89.9417, 89.9417, 89.9417,  0.1000,\n",
      "          0.1000, 89.9417, 89.9417,  0.1000, 89.8884, 89.8884, 89.8884,  0.1000,\n",
      "          0.1000, 89.8884, 89.8884,  0.1000, 89.8884,  0.1000, 89.8884, 89.9586,\n",
      "         89.9586, 89.9586,  0.1000,  0.1000, 89.9586, 89.9586,  0.1000, 89.9586,\n",
      "          0.1000, 89.9586, 89.9417, 89.9586, 89.9586, 89.9586, 89.8884, 89.9586,\n",
      "         89.9586, 89.9586, 89.9417, 89.9586, 89.9586, 89.9586, 89.9417, 89.8884,\n",
      "         89.9417, 89.9417, 89.9417,  0.1000, 89.9417, 89.8884,  0.1000, 89.8884,\n",
      "         89.9586,  0.1000, 89.9586, 89.9586, 89.9586, 89.9417, 89.9417,  0.1000,\n",
      "         89.9586,  0.1000, 89.8482, 89.8482, 89.9417, 89.9586, 89.9586,  0.1000,\n",
      "          0.1000, 89.8482, 89.9417, 89.9586,  0.1000, 89.9417, 89.9586,  0.1000,\n",
      "         89.8482, 89.9586]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 770 was 99.1%\n",
      "current params: tensor([89.8482, 89.9417, 89.8884, 89.9586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.1\n",
      "SLow rates:  tensor([[89.9482, 90.0417, 89.9884, 90.0586,  0.1000,  0.1000,  0.1000, 89.9482,\n",
      "         89.9482, 89.9482,  0.1000,  0.1000, 90.0417, 90.0417, 90.0417,  0.1000,\n",
      "          0.1000, 90.0417, 90.0417,  0.1000, 89.9884, 89.9884, 89.9884,  0.1000,\n",
      "          0.1000, 89.9884, 89.9884,  0.1000, 89.9884,  0.1000, 89.9884, 90.0586,\n",
      "         90.0586, 90.0586,  0.1000,  0.1000, 90.0586, 90.0586,  0.1000, 90.0586,\n",
      "          0.1000, 90.0586, 90.0417, 90.0586, 90.0586, 90.0586, 89.9884, 90.0586,\n",
      "         90.0586, 90.0586, 90.0417, 90.0586, 90.0586, 90.0586, 90.0417, 89.9884,\n",
      "         90.0417, 90.0417, 90.0417,  0.1000, 90.0417, 89.9884,  0.1000, 89.9884,\n",
      "         90.0586,  0.1000, 90.0586, 90.0586, 90.0586, 90.0417, 90.0417,  0.1000,\n",
      "         90.0586,  0.1000, 89.9482, 89.9482, 90.0417, 90.0586, 90.0586,  0.1000,\n",
      "          0.1000, 89.9482, 90.0417, 90.0586,  0.1000, 90.0417, 90.0586,  0.1000,\n",
      "         89.9482, 90.0586]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 771 was 99.1%\n",
      "current params: tensor([89.9482, 90.0417, 89.9884, 90.0586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.1\n",
      "SLow rates:  tensor([[90.0482, 90.1417, 90.0885, 90.1586,  0.1000,  0.1000,  0.1000, 90.0482,\n",
      "         90.0482, 90.0482,  0.1000,  0.1000, 90.1417, 90.1417, 90.1417,  0.1000,\n",
      "          0.1000, 90.1417, 90.1417,  0.1000, 90.0885, 90.0885, 90.0885,  0.1000,\n",
      "          0.1000, 90.0885, 90.0885,  0.1000, 90.0885,  0.1000, 90.0885, 90.1586,\n",
      "         90.1586, 90.1586,  0.1000,  0.1000, 90.1586, 90.1586,  0.1000, 90.1586,\n",
      "          0.1000, 90.1586, 90.1417, 90.1586, 90.1586, 90.1586, 90.0885, 90.1586,\n",
      "         90.1586, 90.1586, 90.1417, 90.1586, 90.1586, 90.1586, 90.1417, 90.0885,\n",
      "         90.1417, 90.1417, 90.1417,  0.1000, 90.1417, 90.0885,  0.1000, 90.0885,\n",
      "         90.1586,  0.1000, 90.1586, 90.1586, 90.1586, 90.1417, 90.1417,  0.1000,\n",
      "         90.1586,  0.1000, 90.0482, 90.0482, 90.1417, 90.1586, 90.1586,  0.1000,\n",
      "          0.1000, 90.0482, 90.1417, 90.1586,  0.1000, 90.1417, 90.1586,  0.1000,\n",
      "         90.0482, 90.1586]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0874, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 772 was 99.1%\n",
      "current params: tensor([90.0482, 90.1417, 90.0885, 90.1586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.2\n",
      "SLow rates:  tensor([[90.1482, 90.2417, 90.1885, 90.2586,  0.1000,  0.1000,  0.1000, 90.1482,\n",
      "         90.1482, 90.1482,  0.1000,  0.1000, 90.2417, 90.2417, 90.2417,  0.1000,\n",
      "          0.1000, 90.2417, 90.2417,  0.1000, 90.1885, 90.1885, 90.1885,  0.1000,\n",
      "          0.1000, 90.1885, 90.1885,  0.1000, 90.1885,  0.1000, 90.1885, 90.2586,\n",
      "         90.2586, 90.2586,  0.1000,  0.1000, 90.2586, 90.2586,  0.1000, 90.2586,\n",
      "          0.1000, 90.2586, 90.2417, 90.2586, 90.2586, 90.2586, 90.1885, 90.2586,\n",
      "         90.2586, 90.2586, 90.2417, 90.2586, 90.2586, 90.2586, 90.2417, 90.1885,\n",
      "         90.2417, 90.2417, 90.2417,  0.1000, 90.2417, 90.1885,  0.1000, 90.1885,\n",
      "         90.2586,  0.1000, 90.2586, 90.2586, 90.2586, 90.2417, 90.2417,  0.1000,\n",
      "         90.2586,  0.1000, 90.1482, 90.1482, 90.2417, 90.2586, 90.2586,  0.1000,\n",
      "          0.1000, 90.1482, 90.2417, 90.2586,  0.1000, 90.2417, 90.2586,  0.1000,\n",
      "         90.1482, 90.2586]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 773 was 99.1%\n",
      "current params: tensor([90.1482, 90.2417, 90.1885, 90.2586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.2\n",
      "SLow rates:  tensor([[90.2482, 90.3417, 90.2885, 90.3586,  0.1000,  0.1000,  0.1000, 90.2482,\n",
      "         90.2482, 90.2482,  0.1000,  0.1000, 90.3417, 90.3417, 90.3417,  0.1000,\n",
      "          0.1000, 90.3417, 90.3417,  0.1000, 90.2885, 90.2885, 90.2885,  0.1000,\n",
      "          0.1000, 90.2885, 90.2885,  0.1000, 90.2885,  0.1000, 90.2885, 90.3586,\n",
      "         90.3586, 90.3586,  0.1000,  0.1000, 90.3586, 90.3586,  0.1000, 90.3586,\n",
      "          0.1000, 90.3586, 90.3417, 90.3586, 90.3586, 90.3586, 90.2885, 90.3586,\n",
      "         90.3586, 90.3586, 90.3417, 90.3586, 90.3586, 90.3586, 90.3417, 90.2885,\n",
      "         90.3417, 90.3417, 90.3417,  0.1000, 90.3417, 90.2885,  0.1000, 90.2885,\n",
      "         90.3586,  0.1000, 90.3586, 90.3586, 90.3586, 90.3417, 90.3417,  0.1000,\n",
      "         90.3586,  0.1000, 90.2482, 90.2482, 90.3417, 90.3586, 90.3586,  0.1000,\n",
      "          0.1000, 90.2482, 90.3417, 90.3586,  0.1000, 90.3417, 90.3586,  0.1000,\n",
      "         90.2482, 90.3586]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0864, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 774 was 99.1%\n",
      "current params: tensor([90.2482, 90.3417, 90.2885, 90.3586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.2\n",
      "SLow rates:  tensor([[90.3483, 90.4418, 90.3885, 90.4587,  0.1000,  0.1000,  0.1000, 90.3483,\n",
      "         90.3483, 90.3483,  0.1000,  0.1000, 90.4418, 90.4418, 90.4418,  0.1000,\n",
      "          0.1000, 90.4418, 90.4418,  0.1000, 90.3885, 90.3885, 90.3885,  0.1000,\n",
      "          0.1000, 90.3885, 90.3885,  0.1000, 90.3885,  0.1000, 90.3885, 90.4587,\n",
      "         90.4587, 90.4587,  0.1000,  0.1000, 90.4587, 90.4587,  0.1000, 90.4587,\n",
      "          0.1000, 90.4587, 90.4418, 90.4587, 90.4587, 90.4587, 90.3885, 90.4587,\n",
      "         90.4587, 90.4587, 90.4418, 90.4587, 90.4587, 90.4587, 90.4418, 90.3885,\n",
      "         90.4418, 90.4418, 90.4418,  0.1000, 90.4418, 90.3885,  0.1000, 90.3885,\n",
      "         90.4587,  0.1000, 90.4587, 90.4587, 90.4587, 90.4418, 90.4418,  0.1000,\n",
      "         90.4587,  0.1000, 90.3483, 90.3483, 90.4418, 90.4587, 90.4587,  0.1000,\n",
      "          0.1000, 90.3483, 90.4418, 90.4587,  0.1000, 90.4418, 90.4587,  0.1000,\n",
      "         90.3483, 90.4587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 775 was 99.1%\n",
      "current params: tensor([90.3483, 90.4418, 90.3885, 90.4587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.3\n",
      "SLow rates:  tensor([[90.4483, 90.5418, 90.4885, 90.5587,  0.1000,  0.1000,  0.1000, 90.4483,\n",
      "         90.4483, 90.4483,  0.1000,  0.1000, 90.5418, 90.5418, 90.5418,  0.1000,\n",
      "          0.1000, 90.5418, 90.5418,  0.1000, 90.4885, 90.4885, 90.4885,  0.1000,\n",
      "          0.1000, 90.4885, 90.4885,  0.1000, 90.4885,  0.1000, 90.4885, 90.5587,\n",
      "         90.5587, 90.5587,  0.1000,  0.1000, 90.5587, 90.5587,  0.1000, 90.5587,\n",
      "          0.1000, 90.5587, 90.5418, 90.5587, 90.5587, 90.5587, 90.4885, 90.5587,\n",
      "         90.5587, 90.5587, 90.5418, 90.5587, 90.5587, 90.5587, 90.5418, 90.4885,\n",
      "         90.5418, 90.5418, 90.5418,  0.1000, 90.5418, 90.4885,  0.1000, 90.4885,\n",
      "         90.5587,  0.1000, 90.5587, 90.5587, 90.5587, 90.5418, 90.5418,  0.1000,\n",
      "         90.5587,  0.1000, 90.4483, 90.4483, 90.5418, 90.5587, 90.5587,  0.1000,\n",
      "          0.1000, 90.4483, 90.5418, 90.5587,  0.1000, 90.5418, 90.5587,  0.1000,\n",
      "         90.4483, 90.5587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 776 was 99.1%\n",
      "current params: tensor([90.4483, 90.5418, 90.4885, 90.5587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.3\n",
      "SLow rates:  tensor([[90.5483, 90.6418, 90.5885, 90.6587,  0.1000,  0.1000,  0.1000, 90.5483,\n",
      "         90.5483, 90.5483,  0.1000,  0.1000, 90.6418, 90.6418, 90.6418,  0.1000,\n",
      "          0.1000, 90.6418, 90.6418,  0.1000, 90.5885, 90.5885, 90.5885,  0.1000,\n",
      "          0.1000, 90.5885, 90.5885,  0.1000, 90.5885,  0.1000, 90.5885, 90.6587,\n",
      "         90.6587, 90.6587,  0.1000,  0.1000, 90.6587, 90.6587,  0.1000, 90.6587,\n",
      "          0.1000, 90.6587, 90.6418, 90.6587, 90.6587, 90.6587, 90.5885, 90.6587,\n",
      "         90.6587, 90.6587, 90.6418, 90.6587, 90.6587, 90.6587, 90.6418, 90.5885,\n",
      "         90.6418, 90.6418, 90.6418,  0.1000, 90.6418, 90.5885,  0.1000, 90.5885,\n",
      "         90.6587,  0.1000, 90.6587, 90.6587, 90.6587, 90.6418, 90.6418,  0.1000,\n",
      "         90.6587,  0.1000, 90.5483, 90.5483, 90.6418, 90.6587, 90.6587,  0.1000,\n",
      "          0.1000, 90.5483, 90.6418, 90.6587,  0.1000, 90.6418, 90.6587,  0.1000,\n",
      "         90.5483, 90.6587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0850, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 777 was 99.1%\n",
      "current params: tensor([90.5483, 90.6418, 90.5885, 90.6587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.3\n",
      "SLow rates:  tensor([[90.6483, 90.7418, 90.6886, 90.7587,  0.1000,  0.1000,  0.1000, 90.6483,\n",
      "         90.6483, 90.6483,  0.1000,  0.1000, 90.7418, 90.7418, 90.7418,  0.1000,\n",
      "          0.1000, 90.7418, 90.7418,  0.1000, 90.6886, 90.6886, 90.6886,  0.1000,\n",
      "          0.1000, 90.6886, 90.6886,  0.1000, 90.6886,  0.1000, 90.6886, 90.7587,\n",
      "         90.7587, 90.7587,  0.1000,  0.1000, 90.7587, 90.7587,  0.1000, 90.7587,\n",
      "          0.1000, 90.7587, 90.7418, 90.7587, 90.7587, 90.7587, 90.6886, 90.7587,\n",
      "         90.7587, 90.7587, 90.7418, 90.7587, 90.7587, 90.7587, 90.7418, 90.6886,\n",
      "         90.7418, 90.7418, 90.7418,  0.1000, 90.7418, 90.6886,  0.1000, 90.6886,\n",
      "         90.7587,  0.1000, 90.7587, 90.7587, 90.7587, 90.7418, 90.7418,  0.1000,\n",
      "         90.7587,  0.1000, 90.6483, 90.6483, 90.7418, 90.7587, 90.7587,  0.1000,\n",
      "          0.1000, 90.6483, 90.7418, 90.7587,  0.1000, 90.7418, 90.7587,  0.1000,\n",
      "         90.6483, 90.7587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 778 was 99.1%\n",
      "current params: tensor([90.6483, 90.7418, 90.6886, 90.7587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.3\n",
      "SLow rates:  tensor([[90.7483, 90.8418, 90.7886, 90.8587,  0.1000,  0.1000,  0.1000, 90.7483,\n",
      "         90.7483, 90.7483,  0.1000,  0.1000, 90.8418, 90.8418, 90.8418,  0.1000,\n",
      "          0.1000, 90.8418, 90.8418,  0.1000, 90.7886, 90.7886, 90.7886,  0.1000,\n",
      "          0.1000, 90.7886, 90.7886,  0.1000, 90.7886,  0.1000, 90.7886, 90.8587,\n",
      "         90.8587, 90.8587,  0.1000,  0.1000, 90.8587, 90.8587,  0.1000, 90.8587,\n",
      "          0.1000, 90.8587, 90.8418, 90.8587, 90.8587, 90.8587, 90.7886, 90.8587,\n",
      "         90.8587, 90.8587, 90.8418, 90.8587, 90.8587, 90.8587, 90.8418, 90.7886,\n",
      "         90.8418, 90.8418, 90.8418,  0.1000, 90.8418, 90.7886,  0.1000, 90.7886,\n",
      "         90.8587,  0.1000, 90.8587, 90.8587, 90.8587, 90.8418, 90.8418,  0.1000,\n",
      "         90.8587,  0.1000, 90.7483, 90.7483, 90.8418, 90.8587, 90.8587,  0.1000,\n",
      "          0.1000, 90.7483, 90.8418, 90.8587,  0.1000, 90.8418, 90.8587,  0.1000,\n",
      "         90.7483, 90.8587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0840, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 779 was 99.1%\n",
      "current params: tensor([90.7483, 90.8418, 90.7886, 90.8587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.3\n",
      "SLow rates:  tensor([[90.8483, 90.9418, 90.8886, 90.9587,  0.1000,  0.1000,  0.1000, 90.8483,\n",
      "         90.8483, 90.8483,  0.1000,  0.1000, 90.9418, 90.9418, 90.9418,  0.1000,\n",
      "          0.1000, 90.9418, 90.9418,  0.1000, 90.8886, 90.8886, 90.8886,  0.1000,\n",
      "          0.1000, 90.8886, 90.8886,  0.1000, 90.8886,  0.1000, 90.8886, 90.9587,\n",
      "         90.9587, 90.9587,  0.1000,  0.1000, 90.9587, 90.9587,  0.1000, 90.9587,\n",
      "          0.1000, 90.9587, 90.9418, 90.9587, 90.9587, 90.9587, 90.8886, 90.9587,\n",
      "         90.9587, 90.9587, 90.9418, 90.9587, 90.9587, 90.9587, 90.9418, 90.8886,\n",
      "         90.9418, 90.9418, 90.9418,  0.1000, 90.9418, 90.8886,  0.1000, 90.8886,\n",
      "         90.9587,  0.1000, 90.9587, 90.9587, 90.9587, 90.9418, 90.9418,  0.1000,\n",
      "         90.9587,  0.1000, 90.8483, 90.8483, 90.9418, 90.9587, 90.9587,  0.1000,\n",
      "          0.1000, 90.8483, 90.9418, 90.9587,  0.1000, 90.9418, 90.9587,  0.1000,\n",
      "         90.8483, 90.9587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0836, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 780 was 99.1%\n",
      "current params: tensor([90.8483, 90.9418, 90.8886, 90.9587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.4\n",
      "SLow rates:  tensor([[90.9484, 91.0418, 90.9886, 91.0587,  0.1000,  0.1000,  0.1000, 90.9484,\n",
      "         90.9484, 90.9484,  0.1000,  0.1000, 91.0418, 91.0418, 91.0418,  0.1000,\n",
      "          0.1000, 91.0418, 91.0418,  0.1000, 90.9886, 90.9886, 90.9886,  0.1000,\n",
      "          0.1000, 90.9886, 90.9886,  0.1000, 90.9886,  0.1000, 90.9886, 91.0587,\n",
      "         91.0587, 91.0587,  0.1000,  0.1000, 91.0587, 91.0587,  0.1000, 91.0587,\n",
      "          0.1000, 91.0587, 91.0418, 91.0587, 91.0587, 91.0587, 90.9886, 91.0587,\n",
      "         91.0587, 91.0587, 91.0418, 91.0587, 91.0587, 91.0587, 91.0418, 90.9886,\n",
      "         91.0418, 91.0418, 91.0418,  0.1000, 91.0418, 90.9886,  0.1000, 90.9886,\n",
      "         91.0587,  0.1000, 91.0587, 91.0587, 91.0587, 91.0418, 91.0418,  0.1000,\n",
      "         91.0587,  0.1000, 90.9484, 90.9484, 91.0418, 91.0587, 91.0587,  0.1000,\n",
      "          0.1000, 90.9484, 91.0418, 91.0587,  0.1000, 91.0418, 91.0587,  0.1000,\n",
      "         90.9484, 91.0587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 781 was 99.1%\n",
      "current params: tensor([90.9484, 91.0418, 90.9886, 91.0587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.4\n",
      "SLow rates:  tensor([[91.0484, 91.1419, 91.0886, 91.1587,  0.1000,  0.1000,  0.1000, 91.0484,\n",
      "         91.0484, 91.0484,  0.1000,  0.1000, 91.1419, 91.1419, 91.1419,  0.1000,\n",
      "          0.1000, 91.1419, 91.1419,  0.1000, 91.0886, 91.0886, 91.0886,  0.1000,\n",
      "          0.1000, 91.0886, 91.0886,  0.1000, 91.0886,  0.1000, 91.0886, 91.1587,\n",
      "         91.1587, 91.1587,  0.1000,  0.1000, 91.1587, 91.1587,  0.1000, 91.1587,\n",
      "          0.1000, 91.1587, 91.1419, 91.1587, 91.1587, 91.1587, 91.0886, 91.1587,\n",
      "         91.1587, 91.1587, 91.1419, 91.1587, 91.1587, 91.1587, 91.1419, 91.0886,\n",
      "         91.1419, 91.1419, 91.1419,  0.1000, 91.1419, 91.0886,  0.1000, 91.0886,\n",
      "         91.1587,  0.1000, 91.1587, 91.1587, 91.1587, 91.1419, 91.1419,  0.1000,\n",
      "         91.1587,  0.1000, 91.0484, 91.0484, 91.1419, 91.1587, 91.1587,  0.1000,\n",
      "          0.1000, 91.0484, 91.1419, 91.1587,  0.1000, 91.1419, 91.1587,  0.1000,\n",
      "         91.0484, 91.1587]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 782 was 99.1%\n",
      "current params: tensor([91.0484, 91.1419, 91.0886, 91.1587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.4\n",
      "SLow rates:  tensor([[91.1484, 91.2419, 91.1886, 91.2588,  0.1000,  0.1000,  0.1000, 91.1484,\n",
      "         91.1484, 91.1484,  0.1000,  0.1000, 91.2419, 91.2419, 91.2419,  0.1000,\n",
      "          0.1000, 91.2419, 91.2419,  0.1000, 91.1886, 91.1886, 91.1886,  0.1000,\n",
      "          0.1000, 91.1886, 91.1886,  0.1000, 91.1886,  0.1000, 91.1886, 91.2588,\n",
      "         91.2588, 91.2588,  0.1000,  0.1000, 91.2588, 91.2588,  0.1000, 91.2588,\n",
      "          0.1000, 91.2588, 91.2419, 91.2588, 91.2588, 91.2588, 91.1886, 91.2588,\n",
      "         91.2588, 91.2588, 91.2419, 91.2588, 91.2588, 91.2588, 91.2419, 91.1886,\n",
      "         91.2419, 91.2419, 91.2419,  0.1000, 91.2419, 91.1886,  0.1000, 91.1886,\n",
      "         91.2588,  0.1000, 91.2588, 91.2588, 91.2588, 91.2419, 91.2419,  0.1000,\n",
      "         91.2588,  0.1000, 91.1484, 91.1484, 91.2419, 91.2588, 91.2588,  0.1000,\n",
      "          0.1000, 91.1484, 91.2419, 91.2588,  0.1000, 91.2419, 91.2588,  0.1000,\n",
      "         91.1484, 91.2588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0822, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 783 was 99.1%\n",
      "current params: tensor([91.1484, 91.2419, 91.1886, 91.2588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.4\n",
      "SLow rates:  tensor([[91.2484, 91.3419, 91.2886, 91.3588,  0.1000,  0.1000,  0.1000, 91.2484,\n",
      "         91.2484, 91.2484,  0.1000,  0.1000, 91.3419, 91.3419, 91.3419,  0.1000,\n",
      "          0.1000, 91.3419, 91.3419,  0.1000, 91.2886, 91.2886, 91.2886,  0.1000,\n",
      "          0.1000, 91.2886, 91.2886,  0.1000, 91.2886,  0.1000, 91.2886, 91.3588,\n",
      "         91.3588, 91.3588,  0.1000,  0.1000, 91.3588, 91.3588,  0.1000, 91.3588,\n",
      "          0.1000, 91.3588, 91.3419, 91.3588, 91.3588, 91.3588, 91.2886, 91.3588,\n",
      "         91.3588, 91.3588, 91.3419, 91.3588, 91.3588, 91.3588, 91.3419, 91.2886,\n",
      "         91.3419, 91.3419, 91.3419,  0.1000, 91.3419, 91.2886,  0.1000, 91.2886,\n",
      "         91.3588,  0.1000, 91.3588, 91.3588, 91.3588, 91.3419, 91.3419,  0.1000,\n",
      "         91.3588,  0.1000, 91.2484, 91.2484, 91.3419, 91.3588, 91.3588,  0.1000,\n",
      "          0.1000, 91.2484, 91.3419, 91.3588,  0.1000, 91.3419, 91.3588,  0.1000,\n",
      "         91.2484, 91.3588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0818, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 784 was 99.1%\n",
      "current params: tensor([91.2484, 91.3419, 91.2886, 91.3588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.4\n",
      "SLow rates:  tensor([[91.3484, 91.4419, 91.3887, 91.4588,  0.1000,  0.1000,  0.1000, 91.3484,\n",
      "         91.3484, 91.3484,  0.1000,  0.1000, 91.4419, 91.4419, 91.4419,  0.1000,\n",
      "          0.1000, 91.4419, 91.4419,  0.1000, 91.3887, 91.3887, 91.3887,  0.1000,\n",
      "          0.1000, 91.3887, 91.3887,  0.1000, 91.3887,  0.1000, 91.3887, 91.4588,\n",
      "         91.4588, 91.4588,  0.1000,  0.1000, 91.4588, 91.4588,  0.1000, 91.4588,\n",
      "          0.1000, 91.4588, 91.4419, 91.4588, 91.4588, 91.4588, 91.3887, 91.4588,\n",
      "         91.4588, 91.4588, 91.4419, 91.4588, 91.4588, 91.4588, 91.4419, 91.3887,\n",
      "         91.4419, 91.4419, 91.4419,  0.1000, 91.4419, 91.3887,  0.1000, 91.3887,\n",
      "         91.4588,  0.1000, 91.4588, 91.4588, 91.4588, 91.4419, 91.4419,  0.1000,\n",
      "         91.4588,  0.1000, 91.3484, 91.3484, 91.4419, 91.4588, 91.4588,  0.1000,\n",
      "          0.1000, 91.3484, 91.4419, 91.4588,  0.1000, 91.4419, 91.4588,  0.1000,\n",
      "         91.3484, 91.4588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0813, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 785 was 99.1%\n",
      "current params: tensor([91.3484, 91.4419, 91.3887, 91.4588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.5\n",
      "SLow rates:  tensor([[91.4484, 91.5419, 91.4887, 91.5588,  0.1000,  0.1000,  0.1000, 91.4484,\n",
      "         91.4484, 91.4484,  0.1000,  0.1000, 91.5419, 91.5419, 91.5419,  0.1000,\n",
      "          0.1000, 91.5419, 91.5419,  0.1000, 91.4887, 91.4887, 91.4887,  0.1000,\n",
      "          0.1000, 91.4887, 91.4887,  0.1000, 91.4887,  0.1000, 91.4887, 91.5588,\n",
      "         91.5588, 91.5588,  0.1000,  0.1000, 91.5588, 91.5588,  0.1000, 91.5588,\n",
      "          0.1000, 91.5588, 91.5419, 91.5588, 91.5588, 91.5588, 91.4887, 91.5588,\n",
      "         91.5588, 91.5588, 91.5419, 91.5588, 91.5588, 91.5588, 91.5419, 91.4887,\n",
      "         91.5419, 91.5419, 91.5419,  0.1000, 91.5419, 91.4887,  0.1000, 91.4887,\n",
      "         91.5588,  0.1000, 91.5588, 91.5588, 91.5588, 91.5419, 91.5419,  0.1000,\n",
      "         91.5588,  0.1000, 91.4484, 91.4484, 91.5419, 91.5588, 91.5588,  0.1000,\n",
      "          0.1000, 91.4484, 91.5419, 91.5588,  0.1000, 91.5419, 91.5588,  0.1000,\n",
      "         91.4484, 91.5588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 786 was 99.1%\n",
      "current params: tensor([91.4484, 91.5419, 91.4887, 91.5588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.5\n",
      "SLow rates:  tensor([[91.5485, 91.6419, 91.5887, 91.6588,  0.1000,  0.1000,  0.1000, 91.5485,\n",
      "         91.5485, 91.5485,  0.1000,  0.1000, 91.6419, 91.6419, 91.6419,  0.1000,\n",
      "          0.1000, 91.6419, 91.6419,  0.1000, 91.5887, 91.5887, 91.5887,  0.1000,\n",
      "          0.1000, 91.5887, 91.5887,  0.1000, 91.5887,  0.1000, 91.5887, 91.6588,\n",
      "         91.6588, 91.6588,  0.1000,  0.1000, 91.6588, 91.6588,  0.1000, 91.6588,\n",
      "          0.1000, 91.6588, 91.6419, 91.6588, 91.6588, 91.6588, 91.5887, 91.6588,\n",
      "         91.6588, 91.6588, 91.6419, 91.6588, 91.6588, 91.6588, 91.6419, 91.5887,\n",
      "         91.6419, 91.6419, 91.6419,  0.1000, 91.6419, 91.5887,  0.1000, 91.5887,\n",
      "         91.6588,  0.1000, 91.6588, 91.6588, 91.6588, 91.6419, 91.6419,  0.1000,\n",
      "         91.6588,  0.1000, 91.5485, 91.5485, 91.6419, 91.6588, 91.6588,  0.1000,\n",
      "          0.1000, 91.5485, 91.6419, 91.6588,  0.1000, 91.6419, 91.6588,  0.1000,\n",
      "         91.5485, 91.6588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 787 was 99.1%\n",
      "current params: tensor([91.5485, 91.6419, 91.5887, 91.6588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.5\n",
      "SLow rates:  tensor([[91.6485, 91.7419, 91.6887, 91.7588,  0.1000,  0.1000,  0.1000, 91.6485,\n",
      "         91.6485, 91.6485,  0.1000,  0.1000, 91.7419, 91.7419, 91.7419,  0.1000,\n",
      "          0.1000, 91.7419, 91.7419,  0.1000, 91.6887, 91.6887, 91.6887,  0.1000,\n",
      "          0.1000, 91.6887, 91.6887,  0.1000, 91.6887,  0.1000, 91.6887, 91.7588,\n",
      "         91.7588, 91.7588,  0.1000,  0.1000, 91.7588, 91.7588,  0.1000, 91.7588,\n",
      "          0.1000, 91.7588, 91.7419, 91.7588, 91.7588, 91.7588, 91.6887, 91.7588,\n",
      "         91.7588, 91.7588, 91.7419, 91.7588, 91.7588, 91.7588, 91.7419, 91.6887,\n",
      "         91.7419, 91.7419, 91.7419,  0.1000, 91.7419, 91.6887,  0.1000, 91.6887,\n",
      "         91.7588,  0.1000, 91.7588, 91.7588, 91.7588, 91.7419, 91.7419,  0.1000,\n",
      "         91.7588,  0.1000, 91.6485, 91.6485, 91.7419, 91.7588, 91.7588,  0.1000,\n",
      "          0.1000, 91.6485, 91.7419, 91.7588,  0.1000, 91.7419, 91.7588,  0.1000,\n",
      "         91.6485, 91.7588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 788 was 99.1%\n",
      "current params: tensor([91.6485, 91.7419, 91.6887, 91.7588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.5\n",
      "SLow rates:  tensor([[91.7485, 91.8420, 91.7887, 91.8588,  0.1000,  0.1000,  0.1000, 91.7485,\n",
      "         91.7485, 91.7485,  0.1000,  0.1000, 91.8420, 91.8420, 91.8420,  0.1000,\n",
      "          0.1000, 91.8420, 91.8420,  0.1000, 91.7887, 91.7887, 91.7887,  0.1000,\n",
      "          0.1000, 91.7887, 91.7887,  0.1000, 91.7887,  0.1000, 91.7887, 91.8588,\n",
      "         91.8588, 91.8588,  0.1000,  0.1000, 91.8588, 91.8588,  0.1000, 91.8588,\n",
      "          0.1000, 91.8588, 91.8420, 91.8588, 91.8588, 91.8588, 91.7887, 91.8588,\n",
      "         91.8588, 91.8588, 91.8420, 91.8588, 91.8588, 91.8588, 91.8420, 91.7887,\n",
      "         91.8420, 91.8420, 91.8420,  0.1000, 91.8420, 91.7887,  0.1000, 91.7887,\n",
      "         91.8588,  0.1000, 91.8588, 91.8588, 91.8588, 91.8420, 91.8420,  0.1000,\n",
      "         91.8588,  0.1000, 91.7485, 91.7485, 91.8420, 91.8588, 91.8588,  0.1000,\n",
      "          0.1000, 91.7485, 91.8420, 91.8588,  0.1000, 91.8420, 91.8588,  0.1000,\n",
      "         91.7485, 91.8588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 789 was 99.1%\n",
      "current params: tensor([91.7485, 91.8420, 91.7887, 91.8588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.5\n",
      "SLow rates:  tensor([[91.8485, 91.9420, 91.8887, 91.9588,  0.1000,  0.1000,  0.1000, 91.8485,\n",
      "         91.8485, 91.8485,  0.1000,  0.1000, 91.9420, 91.9420, 91.9420,  0.1000,\n",
      "          0.1000, 91.9420, 91.9420,  0.1000, 91.8887, 91.8887, 91.8887,  0.1000,\n",
      "          0.1000, 91.8887, 91.8887,  0.1000, 91.8887,  0.1000, 91.8887, 91.9588,\n",
      "         91.9588, 91.9588,  0.1000,  0.1000, 91.9588, 91.9588,  0.1000, 91.9588,\n",
      "          0.1000, 91.9588, 91.9420, 91.9588, 91.9588, 91.9588, 91.8887, 91.9588,\n",
      "         91.9588, 91.9588, 91.9420, 91.9588, 91.9588, 91.9588, 91.9420, 91.8887,\n",
      "         91.9420, 91.9420, 91.9420,  0.1000, 91.9420, 91.8887,  0.1000, 91.8887,\n",
      "         91.9588,  0.1000, 91.9588, 91.9588, 91.9588, 91.9420, 91.9420,  0.1000,\n",
      "         91.9588,  0.1000, 91.8485, 91.8485, 91.9420, 91.9588, 91.9588,  0.1000,\n",
      "          0.1000, 91.8485, 91.9420, 91.9588,  0.1000, 91.9420, 91.9588,  0.1000,\n",
      "         91.8485, 91.9588]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 790 was 99.1%\n",
      "current params: tensor([91.8485, 91.9420, 91.8887, 91.9588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.5\n",
      "SLow rates:  tensor([[91.9485, 92.0420, 91.9888, 92.0589,  0.1000,  0.1000,  0.1000, 91.9485,\n",
      "         91.9485, 91.9485,  0.1000,  0.1000, 92.0420, 92.0420, 92.0420,  0.1000,\n",
      "          0.1000, 92.0420, 92.0420,  0.1000, 91.9888, 91.9888, 91.9888,  0.1000,\n",
      "          0.1000, 91.9888, 91.9888,  0.1000, 91.9888,  0.1000, 91.9888, 92.0589,\n",
      "         92.0589, 92.0589,  0.1000,  0.1000, 92.0589, 92.0589,  0.1000, 92.0589,\n",
      "          0.1000, 92.0589, 92.0420, 92.0589, 92.0589, 92.0589, 91.9888, 92.0589,\n",
      "         92.0589, 92.0589, 92.0420, 92.0589, 92.0589, 92.0589, 92.0420, 91.9888,\n",
      "         92.0420, 92.0420, 92.0420,  0.1000, 92.0420, 91.9888,  0.1000, 91.9888,\n",
      "         92.0589,  0.1000, 92.0589, 92.0589, 92.0589, 92.0420, 92.0420,  0.1000,\n",
      "         92.0589,  0.1000, 91.9485, 91.9485, 92.0420, 92.0589, 92.0589,  0.1000,\n",
      "          0.1000, 91.9485, 92.0420, 92.0589,  0.1000, 92.0420, 92.0589,  0.1000,\n",
      "         91.9485, 92.0589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 791 was 99.1%\n",
      "current params: tensor([91.9485, 92.0420, 91.9888, 92.0589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.6\n",
      "SLow rates:  tensor([[92.0485, 92.1420, 92.0888, 92.1589,  0.1000,  0.1000,  0.1000, 92.0485,\n",
      "         92.0485, 92.0485,  0.1000,  0.1000, 92.1420, 92.1420, 92.1420,  0.1000,\n",
      "          0.1000, 92.1420, 92.1420,  0.1000, 92.0888, 92.0888, 92.0888,  0.1000,\n",
      "          0.1000, 92.0888, 92.0888,  0.1000, 92.0888,  0.1000, 92.0888, 92.1589,\n",
      "         92.1589, 92.1589,  0.1000,  0.1000, 92.1589, 92.1589,  0.1000, 92.1589,\n",
      "          0.1000, 92.1589, 92.1420, 92.1589, 92.1589, 92.1589, 92.0888, 92.1589,\n",
      "         92.1589, 92.1589, 92.1420, 92.1589, 92.1589, 92.1589, 92.1420, 92.0888,\n",
      "         92.1420, 92.1420, 92.1420,  0.1000, 92.1420, 92.0888,  0.1000, 92.0888,\n",
      "         92.1589,  0.1000, 92.1589, 92.1589, 92.1589, 92.1420, 92.1420,  0.1000,\n",
      "         92.1589,  0.1000, 92.0485, 92.0485, 92.1420, 92.1589, 92.1589,  0.1000,\n",
      "          0.1000, 92.0485, 92.1420, 92.1589,  0.1000, 92.1420, 92.1589,  0.1000,\n",
      "         92.0485, 92.1589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 792 was 99.1%\n",
      "current params: tensor([92.0485, 92.1420, 92.0888, 92.1589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.6\n",
      "SLow rates:  tensor([[92.1485, 92.2420, 92.1888, 92.2589,  0.1000,  0.1000,  0.1000, 92.1485,\n",
      "         92.1485, 92.1485,  0.1000,  0.1000, 92.2420, 92.2420, 92.2420,  0.1000,\n",
      "          0.1000, 92.2420, 92.2420,  0.1000, 92.1888, 92.1888, 92.1888,  0.1000,\n",
      "          0.1000, 92.1888, 92.1888,  0.1000, 92.1888,  0.1000, 92.1888, 92.2589,\n",
      "         92.2589, 92.2589,  0.1000,  0.1000, 92.2589, 92.2589,  0.1000, 92.2589,\n",
      "          0.1000, 92.2589, 92.2420, 92.2589, 92.2589, 92.2589, 92.1888, 92.2589,\n",
      "         92.2589, 92.2589, 92.2420, 92.2589, 92.2589, 92.2589, 92.2420, 92.1888,\n",
      "         92.2420, 92.2420, 92.2420,  0.1000, 92.2420, 92.1888,  0.1000, 92.1888,\n",
      "         92.2589,  0.1000, 92.2589, 92.2589, 92.2589, 92.2420, 92.2420,  0.1000,\n",
      "         92.2589,  0.1000, 92.1485, 92.1485, 92.2420, 92.2589, 92.2589,  0.1000,\n",
      "          0.1000, 92.1485, 92.2420, 92.2589,  0.1000, 92.2420, 92.2589,  0.1000,\n",
      "         92.1485, 92.2589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 793 was 99.1%\n",
      "current params: tensor([92.1485, 92.2420, 92.1888, 92.2589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.6\n",
      "SLow rates:  tensor([[92.2486, 92.3420, 92.2888, 92.3589,  0.1000,  0.1000,  0.1000, 92.2486,\n",
      "         92.2486, 92.2486,  0.1000,  0.1000, 92.3420, 92.3420, 92.3420,  0.1000,\n",
      "          0.1000, 92.3420, 92.3420,  0.1000, 92.2888, 92.2888, 92.2888,  0.1000,\n",
      "          0.1000, 92.2888, 92.2888,  0.1000, 92.2888,  0.1000, 92.2888, 92.3589,\n",
      "         92.3589, 92.3589,  0.1000,  0.1000, 92.3589, 92.3589,  0.1000, 92.3589,\n",
      "          0.1000, 92.3589, 92.3420, 92.3589, 92.3589, 92.3589, 92.2888, 92.3589,\n",
      "         92.3589, 92.3589, 92.3420, 92.3589, 92.3589, 92.3589, 92.3420, 92.2888,\n",
      "         92.3420, 92.3420, 92.3420,  0.1000, 92.3420, 92.2888,  0.1000, 92.2888,\n",
      "         92.3589,  0.1000, 92.3589, 92.3589, 92.3589, 92.3420, 92.3420,  0.1000,\n",
      "         92.3589,  0.1000, 92.2486, 92.2486, 92.3420, 92.3589, 92.3589,  0.1000,\n",
      "          0.1000, 92.2486, 92.3420, 92.3589,  0.1000, 92.3420, 92.3589,  0.1000,\n",
      "         92.2486, 92.3589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 794 was 99.1%\n",
      "current params: tensor([92.2486, 92.3420, 92.2888, 92.3589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.6\n",
      "SLow rates:  tensor([[92.3486, 92.4420, 92.3888, 92.4589,  0.1000,  0.1000,  0.1000, 92.3486,\n",
      "         92.3486, 92.3486,  0.1000,  0.1000, 92.4420, 92.4420, 92.4420,  0.1000,\n",
      "          0.1000, 92.4420, 92.4420,  0.1000, 92.3888, 92.3888, 92.3888,  0.1000,\n",
      "          0.1000, 92.3888, 92.3888,  0.1000, 92.3888,  0.1000, 92.3888, 92.4589,\n",
      "         92.4589, 92.4589,  0.1000,  0.1000, 92.4589, 92.4589,  0.1000, 92.4589,\n",
      "          0.1000, 92.4589, 92.4420, 92.4589, 92.4589, 92.4589, 92.3888, 92.4589,\n",
      "         92.4589, 92.4589, 92.4420, 92.4589, 92.4589, 92.4589, 92.4420, 92.3888,\n",
      "         92.4420, 92.4420, 92.4420,  0.1000, 92.4420, 92.3888,  0.1000, 92.3888,\n",
      "         92.4589,  0.1000, 92.4589, 92.4589, 92.4589, 92.4420, 92.4420,  0.1000,\n",
      "         92.4589,  0.1000, 92.3486, 92.3486, 92.4420, 92.4589, 92.4589,  0.1000,\n",
      "          0.1000, 92.3486, 92.4420, 92.4589,  0.1000, 92.4420, 92.4589,  0.1000,\n",
      "         92.3486, 92.4589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0771, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 795 was 99.1%\n",
      "current params: tensor([92.3486, 92.4420, 92.3888, 92.4589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.6\n",
      "SLow rates:  tensor([[92.4486, 92.5420, 92.4888, 92.5589,  0.1000,  0.1000,  0.1000, 92.4486,\n",
      "         92.4486, 92.4486,  0.1000,  0.1000, 92.5420, 92.5420, 92.5420,  0.1000,\n",
      "          0.1000, 92.5420, 92.5420,  0.1000, 92.4888, 92.4888, 92.4888,  0.1000,\n",
      "          0.1000, 92.4888, 92.4888,  0.1000, 92.4888,  0.1000, 92.4888, 92.5589,\n",
      "         92.5589, 92.5589,  0.1000,  0.1000, 92.5589, 92.5589,  0.1000, 92.5589,\n",
      "          0.1000, 92.5589, 92.5420, 92.5589, 92.5589, 92.5589, 92.4888, 92.5589,\n",
      "         92.5589, 92.5589, 92.5420, 92.5589, 92.5589, 92.5589, 92.5420, 92.4888,\n",
      "         92.5420, 92.5420, 92.5420,  0.1000, 92.5420, 92.4888,  0.1000, 92.4888,\n",
      "         92.5589,  0.1000, 92.5589, 92.5589, 92.5589, 92.5420, 92.5420,  0.1000,\n",
      "         92.5589,  0.1000, 92.4486, 92.4486, 92.5420, 92.5589, 92.5589,  0.1000,\n",
      "          0.1000, 92.4486, 92.5420, 92.5589,  0.1000, 92.5420, 92.5589,  0.1000,\n",
      "         92.4486, 92.5589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 796 was 99.1%\n",
      "current params: tensor([92.4486, 92.5420, 92.4888, 92.5589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.7\n",
      "SLow rates:  tensor([[92.5486, 92.6421, 92.5888, 92.6589,  0.1000,  0.1000,  0.1000, 92.5486,\n",
      "         92.5486, 92.5486,  0.1000,  0.1000, 92.6421, 92.6421, 92.6421,  0.1000,\n",
      "          0.1000, 92.6421, 92.6421,  0.1000, 92.5888, 92.5888, 92.5888,  0.1000,\n",
      "          0.1000, 92.5888, 92.5888,  0.1000, 92.5888,  0.1000, 92.5888, 92.6589,\n",
      "         92.6589, 92.6589,  0.1000,  0.1000, 92.6589, 92.6589,  0.1000, 92.6589,\n",
      "          0.1000, 92.6589, 92.6421, 92.6589, 92.6589, 92.6589, 92.5888, 92.6589,\n",
      "         92.6589, 92.6589, 92.6421, 92.6589, 92.6589, 92.6589, 92.6421, 92.5888,\n",
      "         92.6421, 92.6421, 92.6421,  0.1000, 92.6421, 92.5888,  0.1000, 92.5888,\n",
      "         92.6589,  0.1000, 92.6589, 92.6589, 92.6589, 92.6421, 92.6421,  0.1000,\n",
      "         92.6589,  0.1000, 92.5486, 92.5486, 92.6421, 92.6589, 92.6589,  0.1000,\n",
      "          0.1000, 92.5486, 92.6421, 92.6589,  0.1000, 92.6421, 92.6589,  0.1000,\n",
      "         92.5486, 92.6589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 797 was 99.1%\n",
      "current params: tensor([92.5486, 92.6421, 92.5888, 92.6589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.6\n",
      "SLow rates:  tensor([[92.6486, 92.7421, 92.6888, 92.7589,  0.1000,  0.1000,  0.1000, 92.6486,\n",
      "         92.6486, 92.6486,  0.1000,  0.1000, 92.7421, 92.7421, 92.7421,  0.1000,\n",
      "          0.1000, 92.7421, 92.7421,  0.1000, 92.6888, 92.6888, 92.6888,  0.1000,\n",
      "          0.1000, 92.6888, 92.6888,  0.1000, 92.6888,  0.1000, 92.6888, 92.7589,\n",
      "         92.7589, 92.7589,  0.1000,  0.1000, 92.7589, 92.7589,  0.1000, 92.7589,\n",
      "          0.1000, 92.7589, 92.7421, 92.7589, 92.7589, 92.7589, 92.6888, 92.7589,\n",
      "         92.7589, 92.7589, 92.7421, 92.7589, 92.7589, 92.7589, 92.7421, 92.6888,\n",
      "         92.7421, 92.7421, 92.7421,  0.1000, 92.7421, 92.6888,  0.1000, 92.6888,\n",
      "         92.7589,  0.1000, 92.7589, 92.7589, 92.7589, 92.7421, 92.7421,  0.1000,\n",
      "         92.7589,  0.1000, 92.6486, 92.6486, 92.7421, 92.7589, 92.7589,  0.1000,\n",
      "          0.1000, 92.6486, 92.7421, 92.7589,  0.1000, 92.7421, 92.7589,  0.1000,\n",
      "         92.6486, 92.7589]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 798 was 99.1%\n",
      "current params: tensor([92.6486, 92.7421, 92.6888, 92.7589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.7\n",
      "SLow rates:  tensor([[92.7486, 92.8421, 92.7889, 92.8590,  0.1000,  0.1000,  0.1000, 92.7486,\n",
      "         92.7486, 92.7486,  0.1000,  0.1000, 92.8421, 92.8421, 92.8421,  0.1000,\n",
      "          0.1000, 92.8421, 92.8421,  0.1000, 92.7889, 92.7889, 92.7889,  0.1000,\n",
      "          0.1000, 92.7889, 92.7889,  0.1000, 92.7889,  0.1000, 92.7889, 92.8590,\n",
      "         92.8590, 92.8590,  0.1000,  0.1000, 92.8590, 92.8590,  0.1000, 92.8590,\n",
      "          0.1000, 92.8590, 92.8421, 92.8590, 92.8590, 92.8590, 92.7889, 92.8590,\n",
      "         92.8590, 92.8590, 92.8421, 92.8590, 92.8590, 92.8590, 92.8421, 92.7889,\n",
      "         92.8421, 92.8421, 92.8421,  0.1000, 92.8421, 92.7889,  0.1000, 92.7889,\n",
      "         92.8590,  0.1000, 92.8590, 92.8590, 92.8590, 92.8421, 92.8421,  0.1000,\n",
      "         92.8590,  0.1000, 92.7486, 92.7486, 92.8421, 92.8590, 92.8590,  0.1000,\n",
      "          0.1000, 92.7486, 92.8421, 92.8590,  0.1000, 92.8421, 92.8590,  0.1000,\n",
      "         92.7486, 92.8590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0755, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 799 was 99.1%\n",
      "current params: tensor([92.7486, 92.8421, 92.7889, 92.8590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.7\n",
      "SLow rates:  tensor([[92.8486, 92.9421, 92.8889, 92.9590,  0.1000,  0.1000,  0.1000, 92.8486,\n",
      "         92.8486, 92.8486,  0.1000,  0.1000, 92.9421, 92.9421, 92.9421,  0.1000,\n",
      "          0.1000, 92.9421, 92.9421,  0.1000, 92.8889, 92.8889, 92.8889,  0.1000,\n",
      "          0.1000, 92.8889, 92.8889,  0.1000, 92.8889,  0.1000, 92.8889, 92.9590,\n",
      "         92.9590, 92.9590,  0.1000,  0.1000, 92.9590, 92.9590,  0.1000, 92.9590,\n",
      "          0.1000, 92.9590, 92.9421, 92.9590, 92.9590, 92.9590, 92.8889, 92.9590,\n",
      "         92.9590, 92.9590, 92.9421, 92.9590, 92.9590, 92.9590, 92.9421, 92.8889,\n",
      "         92.9421, 92.9421, 92.9421,  0.1000, 92.9421, 92.8889,  0.1000, 92.8889,\n",
      "         92.9590,  0.1000, 92.9590, 92.9590, 92.9590, 92.9421, 92.9421,  0.1000,\n",
      "         92.9590,  0.1000, 92.8486, 92.8486, 92.9421, 92.9590, 92.9590,  0.1000,\n",
      "          0.1000, 92.8486, 92.9421, 92.9590,  0.1000, 92.9421, 92.9590,  0.1000,\n",
      "         92.8486, 92.9590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 800 was 99.1%\n",
      "current params: tensor([92.8486, 92.9421, 92.8889, 92.9590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.7\n",
      "SLow rates:  tensor([[92.9487, 93.0421, 92.9889, 93.0590,  0.1000,  0.1000,  0.1000, 92.9487,\n",
      "         92.9487, 92.9487,  0.1000,  0.1000, 93.0421, 93.0421, 93.0421,  0.1000,\n",
      "          0.1000, 93.0421, 93.0421,  0.1000, 92.9889, 92.9889, 92.9889,  0.1000,\n",
      "          0.1000, 92.9889, 92.9889,  0.1000, 92.9889,  0.1000, 92.9889, 93.0590,\n",
      "         93.0590, 93.0590,  0.1000,  0.1000, 93.0590, 93.0590,  0.1000, 93.0590,\n",
      "          0.1000, 93.0590, 93.0421, 93.0590, 93.0590, 93.0590, 92.9889, 93.0590,\n",
      "         93.0590, 93.0590, 93.0421, 93.0590, 93.0590, 93.0590, 93.0421, 92.9889,\n",
      "         93.0421, 93.0421, 93.0421,  0.1000, 93.0421, 92.9889,  0.1000, 92.9889,\n",
      "         93.0590,  0.1000, 93.0590, 93.0590, 93.0590, 93.0421, 93.0421,  0.1000,\n",
      "         93.0590,  0.1000, 92.9487, 92.9487, 93.0421, 93.0590, 93.0590,  0.1000,\n",
      "          0.1000, 92.9487, 93.0421, 93.0590,  0.1000, 93.0421, 93.0590,  0.1000,\n",
      "         92.9487, 93.0590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0747, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 801 was 99.1%\n",
      "current params: tensor([92.9487, 93.0421, 92.9889, 93.0590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.0487, 93.1421, 93.0889, 93.1590,  0.1000,  0.1000,  0.1000, 93.0487,\n",
      "         93.0487, 93.0487,  0.1000,  0.1000, 93.1421, 93.1421, 93.1421,  0.1000,\n",
      "          0.1000, 93.1421, 93.1421,  0.1000, 93.0889, 93.0889, 93.0889,  0.1000,\n",
      "          0.1000, 93.0889, 93.0889,  0.1000, 93.0889,  0.1000, 93.0889, 93.1590,\n",
      "         93.1590, 93.1590,  0.1000,  0.1000, 93.1590, 93.1590,  0.1000, 93.1590,\n",
      "          0.1000, 93.1590, 93.1421, 93.1590, 93.1590, 93.1590, 93.0889, 93.1590,\n",
      "         93.1590, 93.1590, 93.1421, 93.1590, 93.1590, 93.1590, 93.1421, 93.0889,\n",
      "         93.1421, 93.1421, 93.1421,  0.1000, 93.1421, 93.0889,  0.1000, 93.0889,\n",
      "         93.1590,  0.1000, 93.1590, 93.1590, 93.1590, 93.1421, 93.1421,  0.1000,\n",
      "         93.1590,  0.1000, 93.0487, 93.0487, 93.1421, 93.1590, 93.1590,  0.1000,\n",
      "          0.1000, 93.0487, 93.1421, 93.1590,  0.1000, 93.1421, 93.1590,  0.1000,\n",
      "         93.0487, 93.1590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 802 was 99.1%\n",
      "current params: tensor([93.0487, 93.1421, 93.0889, 93.1590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.7\n",
      "SLow rates:  tensor([[93.1487, 93.2421, 93.1889, 93.2590,  0.1000,  0.1000,  0.1000, 93.1487,\n",
      "         93.1487, 93.1487,  0.1000,  0.1000, 93.2421, 93.2421, 93.2421,  0.1000,\n",
      "          0.1000, 93.2421, 93.2421,  0.1000, 93.1889, 93.1889, 93.1889,  0.1000,\n",
      "          0.1000, 93.1889, 93.1889,  0.1000, 93.1889,  0.1000, 93.1889, 93.2590,\n",
      "         93.2590, 93.2590,  0.1000,  0.1000, 93.2590, 93.2590,  0.1000, 93.2590,\n",
      "          0.1000, 93.2590, 93.2421, 93.2590, 93.2590, 93.2590, 93.1889, 93.2590,\n",
      "         93.2590, 93.2590, 93.2421, 93.2590, 93.2590, 93.2590, 93.2421, 93.1889,\n",
      "         93.2421, 93.2421, 93.2421,  0.1000, 93.2421, 93.1889,  0.1000, 93.1889,\n",
      "         93.2590,  0.1000, 93.2590, 93.2590, 93.2590, 93.2421, 93.2421,  0.1000,\n",
      "         93.2590,  0.1000, 93.1487, 93.1487, 93.2421, 93.2590, 93.2590,  0.1000,\n",
      "          0.1000, 93.1487, 93.2421, 93.2590,  0.1000, 93.2421, 93.2590,  0.1000,\n",
      "         93.1487, 93.2590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 803 was 99.1%\n",
      "current params: tensor([93.1487, 93.2421, 93.1889, 93.2590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.2487, 93.3421, 93.2889, 93.3590,  0.1000,  0.1000,  0.1000, 93.2487,\n",
      "         93.2487, 93.2487,  0.1000,  0.1000, 93.3421, 93.3421, 93.3421,  0.1000,\n",
      "          0.1000, 93.3421, 93.3421,  0.1000, 93.2889, 93.2889, 93.2889,  0.1000,\n",
      "          0.1000, 93.2889, 93.2889,  0.1000, 93.2889,  0.1000, 93.2889, 93.3590,\n",
      "         93.3590, 93.3590,  0.1000,  0.1000, 93.3590, 93.3590,  0.1000, 93.3590,\n",
      "          0.1000, 93.3590, 93.3421, 93.3590, 93.3590, 93.3590, 93.2889, 93.3590,\n",
      "         93.3590, 93.3590, 93.3421, 93.3590, 93.3590, 93.3590, 93.3421, 93.2889,\n",
      "         93.3421, 93.3421, 93.3421,  0.1000, 93.3421, 93.2889,  0.1000, 93.2889,\n",
      "         93.3590,  0.1000, 93.3590, 93.3590, 93.3590, 93.3421, 93.3421,  0.1000,\n",
      "         93.3590,  0.1000, 93.2487, 93.2487, 93.3421, 93.3590, 93.3590,  0.1000,\n",
      "          0.1000, 93.2487, 93.3421, 93.3590,  0.1000, 93.3421, 93.3590,  0.1000,\n",
      "         93.2487, 93.3590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0736, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 804 was 99.1%\n",
      "current params: tensor([93.2487, 93.3421, 93.2889, 93.3590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.3487, 93.4422, 93.3889, 93.4590,  0.1000,  0.1000,  0.1000, 93.3487,\n",
      "         93.3487, 93.3487,  0.1000,  0.1000, 93.4422, 93.4422, 93.4422,  0.1000,\n",
      "          0.1000, 93.4422, 93.4422,  0.1000, 93.3889, 93.3889, 93.3889,  0.1000,\n",
      "          0.1000, 93.3889, 93.3889,  0.1000, 93.3889,  0.1000, 93.3889, 93.4590,\n",
      "         93.4590, 93.4590,  0.1000,  0.1000, 93.4590, 93.4590,  0.1000, 93.4590,\n",
      "          0.1000, 93.4590, 93.4422, 93.4590, 93.4590, 93.4590, 93.3889, 93.4590,\n",
      "         93.4590, 93.4590, 93.4422, 93.4590, 93.4590, 93.4590, 93.4422, 93.3889,\n",
      "         93.4422, 93.4422, 93.4422,  0.1000, 93.4422, 93.3889,  0.1000, 93.3889,\n",
      "         93.4590,  0.1000, 93.4590, 93.4590, 93.4590, 93.4422, 93.4422,  0.1000,\n",
      "         93.4590,  0.1000, 93.3487, 93.3487, 93.4422, 93.4590, 93.4590,  0.1000,\n",
      "          0.1000, 93.3487, 93.4422, 93.4590,  0.1000, 93.4422, 93.4590,  0.1000,\n",
      "         93.3487, 93.4590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0732, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 805 was 99.1%\n",
      "current params: tensor([93.3487, 93.4422, 93.3889, 93.4590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.4487, 93.5422, 93.4889, 93.5590,  0.1000,  0.1000,  0.1000, 93.4487,\n",
      "         93.4487, 93.4487,  0.1000,  0.1000, 93.5422, 93.5422, 93.5422,  0.1000,\n",
      "          0.1000, 93.5422, 93.5422,  0.1000, 93.4889, 93.4889, 93.4889,  0.1000,\n",
      "          0.1000, 93.4889, 93.4889,  0.1000, 93.4889,  0.1000, 93.4889, 93.5590,\n",
      "         93.5590, 93.5590,  0.1000,  0.1000, 93.5590, 93.5590,  0.1000, 93.5590,\n",
      "          0.1000, 93.5590, 93.5422, 93.5590, 93.5590, 93.5590, 93.4889, 93.5590,\n",
      "         93.5590, 93.5590, 93.5422, 93.5590, 93.5590, 93.5590, 93.5422, 93.4889,\n",
      "         93.5422, 93.5422, 93.5422,  0.1000, 93.5422, 93.4889,  0.1000, 93.4889,\n",
      "         93.5590,  0.1000, 93.5590, 93.5590, 93.5590, 93.5422, 93.5422,  0.1000,\n",
      "         93.5590,  0.1000, 93.4487, 93.4487, 93.5422, 93.5590, 93.5590,  0.1000,\n",
      "          0.1000, 93.4487, 93.5422, 93.5590,  0.1000, 93.5422, 93.5590,  0.1000,\n",
      "         93.4487, 93.5590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0729, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 806 was 99.1%\n",
      "current params: tensor([93.4487, 93.5422, 93.4889, 93.5590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.5487, 93.6422, 93.5890, 93.6590,  0.1000,  0.1000,  0.1000, 93.5487,\n",
      "         93.5487, 93.5487,  0.1000,  0.1000, 93.6422, 93.6422, 93.6422,  0.1000,\n",
      "          0.1000, 93.6422, 93.6422,  0.1000, 93.5890, 93.5890, 93.5890,  0.1000,\n",
      "          0.1000, 93.5890, 93.5890,  0.1000, 93.5890,  0.1000, 93.5890, 93.6590,\n",
      "         93.6590, 93.6590,  0.1000,  0.1000, 93.6590, 93.6590,  0.1000, 93.6590,\n",
      "          0.1000, 93.6590, 93.6422, 93.6590, 93.6590, 93.6590, 93.5890, 93.6590,\n",
      "         93.6590, 93.6590, 93.6422, 93.6590, 93.6590, 93.6590, 93.6422, 93.5890,\n",
      "         93.6422, 93.6422, 93.6422,  0.1000, 93.6422, 93.5890,  0.1000, 93.5890,\n",
      "         93.6590,  0.1000, 93.6590, 93.6590, 93.6590, 93.6422, 93.6422,  0.1000,\n",
      "         93.6590,  0.1000, 93.5487, 93.5487, 93.6422, 93.6590, 93.6590,  0.1000,\n",
      "          0.1000, 93.5487, 93.6422, 93.6590,  0.1000, 93.6422, 93.6590,  0.1000,\n",
      "         93.5487, 93.6590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 807 was 99.1%\n",
      "current params: tensor([93.5487, 93.6422, 93.5890, 93.6590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.6488, 93.7422, 93.6890, 93.7590,  0.1000,  0.1000,  0.1000, 93.6488,\n",
      "         93.6488, 93.6488,  0.1000,  0.1000, 93.7422, 93.7422, 93.7422,  0.1000,\n",
      "          0.1000, 93.7422, 93.7422,  0.1000, 93.6890, 93.6890, 93.6890,  0.1000,\n",
      "          0.1000, 93.6890, 93.6890,  0.1000, 93.6890,  0.1000, 93.6890, 93.7590,\n",
      "         93.7590, 93.7590,  0.1000,  0.1000, 93.7590, 93.7590,  0.1000, 93.7590,\n",
      "          0.1000, 93.7590, 93.7422, 93.7590, 93.7590, 93.7590, 93.6890, 93.7590,\n",
      "         93.7590, 93.7590, 93.7422, 93.7590, 93.7590, 93.7590, 93.7422, 93.6890,\n",
      "         93.7422, 93.7422, 93.7422,  0.1000, 93.7422, 93.6890,  0.1000, 93.6890,\n",
      "         93.7590,  0.1000, 93.7590, 93.7590, 93.7590, 93.7422, 93.7422,  0.1000,\n",
      "         93.7590,  0.1000, 93.6488, 93.6488, 93.7422, 93.7590, 93.7590,  0.1000,\n",
      "          0.1000, 93.6488, 93.7422, 93.7590,  0.1000, 93.7422, 93.7590,  0.1000,\n",
      "         93.6488, 93.7590]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 808 was 99.1%\n",
      "current params: tensor([93.6488, 93.7422, 93.6890, 93.7590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.8\n",
      "SLow rates:  tensor([[93.7488, 93.8422, 93.7890, 93.8591,  0.1000,  0.1000,  0.1000, 93.7488,\n",
      "         93.7488, 93.7488,  0.1000,  0.1000, 93.8422, 93.8422, 93.8422,  0.1000,\n",
      "          0.1000, 93.8422, 93.8422,  0.1000, 93.7890, 93.7890, 93.7890,  0.1000,\n",
      "          0.1000, 93.7890, 93.7890,  0.1000, 93.7890,  0.1000, 93.7890, 93.8591,\n",
      "         93.8591, 93.8591,  0.1000,  0.1000, 93.8591, 93.8591,  0.1000, 93.8591,\n",
      "          0.1000, 93.8591, 93.8422, 93.8591, 93.8591, 93.8591, 93.7890, 93.8591,\n",
      "         93.8591, 93.8591, 93.8422, 93.8591, 93.8591, 93.8591, 93.8422, 93.7890,\n",
      "         93.8422, 93.8422, 93.8422,  0.1000, 93.8422, 93.7890,  0.1000, 93.7890,\n",
      "         93.8591,  0.1000, 93.8591, 93.8591, 93.8591, 93.8422, 93.8422,  0.1000,\n",
      "         93.8591,  0.1000, 93.7488, 93.7488, 93.8422, 93.8591, 93.8591,  0.1000,\n",
      "          0.1000, 93.7488, 93.8422, 93.8591,  0.1000, 93.8422, 93.8591,  0.1000,\n",
      "         93.7488, 93.8591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 809 was 99.1%\n",
      "current params: tensor([93.7488, 93.8422, 93.7890, 93.8591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.9\n",
      "SLow rates:  tensor([[93.8488, 93.9422, 93.8890, 93.9591,  0.1000,  0.1000,  0.1000, 93.8488,\n",
      "         93.8488, 93.8488,  0.1000,  0.1000, 93.9422, 93.9422, 93.9422,  0.1000,\n",
      "          0.1000, 93.9422, 93.9422,  0.1000, 93.8890, 93.8890, 93.8890,  0.1000,\n",
      "          0.1000, 93.8890, 93.8890,  0.1000, 93.8890,  0.1000, 93.8890, 93.9591,\n",
      "         93.9591, 93.9591,  0.1000,  0.1000, 93.9591, 93.9591,  0.1000, 93.9591,\n",
      "          0.1000, 93.9591, 93.9422, 93.9591, 93.9591, 93.9591, 93.8890, 93.9591,\n",
      "         93.9591, 93.9591, 93.9422, 93.9591, 93.9591, 93.9591, 93.9422, 93.8890,\n",
      "         93.9422, 93.9422, 93.9422,  0.1000, 93.9422, 93.8890,  0.1000, 93.8890,\n",
      "         93.9591,  0.1000, 93.9591, 93.9591, 93.9591, 93.9422, 93.9422,  0.1000,\n",
      "         93.9591,  0.1000, 93.8488, 93.8488, 93.9422, 93.9591, 93.9591,  0.1000,\n",
      "          0.1000, 93.8488, 93.9422, 93.9591,  0.1000, 93.9422, 93.9591,  0.1000,\n",
      "         93.8488, 93.9591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 810 was 99.1%\n",
      "current params: tensor([93.8488, 93.9422, 93.8890, 93.9591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.9\n",
      "SLow rates:  tensor([[93.9488, 94.0422, 93.9890, 94.0591,  0.1000,  0.1000,  0.1000, 93.9488,\n",
      "         93.9488, 93.9488,  0.1000,  0.1000, 94.0422, 94.0422, 94.0422,  0.1000,\n",
      "          0.1000, 94.0422, 94.0422,  0.1000, 93.9890, 93.9890, 93.9890,  0.1000,\n",
      "          0.1000, 93.9890, 93.9890,  0.1000, 93.9890,  0.1000, 93.9890, 94.0591,\n",
      "         94.0591, 94.0591,  0.1000,  0.1000, 94.0591, 94.0591,  0.1000, 94.0591,\n",
      "          0.1000, 94.0591, 94.0422, 94.0591, 94.0591, 94.0591, 93.9890, 94.0591,\n",
      "         94.0591, 94.0591, 94.0422, 94.0591, 94.0591, 94.0591, 94.0422, 93.9890,\n",
      "         94.0422, 94.0422, 94.0422,  0.1000, 94.0422, 93.9890,  0.1000, 93.9890,\n",
      "         94.0591,  0.1000, 94.0591, 94.0591, 94.0591, 94.0422, 94.0422,  0.1000,\n",
      "         94.0591,  0.1000, 93.9488, 93.9488, 94.0422, 94.0591, 94.0591,  0.1000,\n",
      "          0.1000, 93.9488, 94.0422, 94.0591,  0.1000, 94.0422, 94.0591,  0.1000,\n",
      "         93.9488, 94.0591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0710, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 811 was 99.1%\n",
      "current params: tensor([93.9488, 94.0422, 93.9890, 94.0591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.9\n",
      "SLow rates:  tensor([[94.0488, 94.1422, 94.0890, 94.1591,  0.1000,  0.1000,  0.1000, 94.0488,\n",
      "         94.0488, 94.0488,  0.1000,  0.1000, 94.1422, 94.1422, 94.1422,  0.1000,\n",
      "          0.1000, 94.1422, 94.1422,  0.1000, 94.0890, 94.0890, 94.0890,  0.1000,\n",
      "          0.1000, 94.0890, 94.0890,  0.1000, 94.0890,  0.1000, 94.0890, 94.1591,\n",
      "         94.1591, 94.1591,  0.1000,  0.1000, 94.1591, 94.1591,  0.1000, 94.1591,\n",
      "          0.1000, 94.1591, 94.1422, 94.1591, 94.1591, 94.1591, 94.0890, 94.1591,\n",
      "         94.1591, 94.1591, 94.1422, 94.1591, 94.1591, 94.1591, 94.1422, 94.0890,\n",
      "         94.1422, 94.1422, 94.1422,  0.1000, 94.1422, 94.0890,  0.1000, 94.0890,\n",
      "         94.1591,  0.1000, 94.1591, 94.1591, 94.1591, 94.1422, 94.1422,  0.1000,\n",
      "         94.1591,  0.1000, 94.0488, 94.0488, 94.1422, 94.1591, 94.1591,  0.1000,\n",
      "          0.1000, 94.0488, 94.1422, 94.1591,  0.1000, 94.1422, 94.1591,  0.1000,\n",
      "         94.0488, 94.1591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0707, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 812 was 99.1%\n",
      "current params: tensor([94.0488, 94.1422, 94.0890, 94.1591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.9\n",
      "SLow rates:  tensor([[94.1488, 94.2422, 94.1890, 94.2591,  0.1000,  0.1000,  0.1000, 94.1488,\n",
      "         94.1488, 94.1488,  0.1000,  0.1000, 94.2422, 94.2422, 94.2422,  0.1000,\n",
      "          0.1000, 94.2422, 94.2422,  0.1000, 94.1890, 94.1890, 94.1890,  0.1000,\n",
      "          0.1000, 94.1890, 94.1890,  0.1000, 94.1890,  0.1000, 94.1890, 94.2591,\n",
      "         94.2591, 94.2591,  0.1000,  0.1000, 94.2591, 94.2591,  0.1000, 94.2591,\n",
      "          0.1000, 94.2591, 94.2422, 94.2591, 94.2591, 94.2591, 94.1890, 94.2591,\n",
      "         94.2591, 94.2591, 94.2422, 94.2591, 94.2591, 94.2591, 94.2422, 94.1890,\n",
      "         94.2422, 94.2422, 94.2422,  0.1000, 94.2422, 94.1890,  0.1000, 94.1890,\n",
      "         94.2591,  0.1000, 94.2591, 94.2591, 94.2591, 94.2422, 94.2422,  0.1000,\n",
      "         94.2591,  0.1000, 94.1488, 94.1488, 94.2422, 94.2591, 94.2591,  0.1000,\n",
      "          0.1000, 94.1488, 94.2422, 94.2591,  0.1000, 94.2422, 94.2591,  0.1000,\n",
      "         94.1488, 94.2591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 813 was 99.2%\n",
      "current params: tensor([94.1488, 94.2422, 94.1890, 94.2591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.9\n",
      "SLow rates:  tensor([[94.2488, 94.3422, 94.2890, 94.3591,  0.1000,  0.1000,  0.1000, 94.2488,\n",
      "         94.2488, 94.2488,  0.1000,  0.1000, 94.3422, 94.3422, 94.3422,  0.1000,\n",
      "          0.1000, 94.3422, 94.3422,  0.1000, 94.2890, 94.2890, 94.2890,  0.1000,\n",
      "          0.1000, 94.2890, 94.2890,  0.1000, 94.2890,  0.1000, 94.2890, 94.3591,\n",
      "         94.3591, 94.3591,  0.1000,  0.1000, 94.3591, 94.3591,  0.1000, 94.3591,\n",
      "          0.1000, 94.3591, 94.3422, 94.3591, 94.3591, 94.3591, 94.2890, 94.3591,\n",
      "         94.3591, 94.3591, 94.3422, 94.3591, 94.3591, 94.3591, 94.3422, 94.2890,\n",
      "         94.3422, 94.3422, 94.3422,  0.1000, 94.3422, 94.2890,  0.1000, 94.2890,\n",
      "         94.3591,  0.1000, 94.3591, 94.3591, 94.3591, 94.3422, 94.3422,  0.1000,\n",
      "         94.3591,  0.1000, 94.2488, 94.2488, 94.3422, 94.3591, 94.3591,  0.1000,\n",
      "          0.1000, 94.2488, 94.3422, 94.3591,  0.1000, 94.3422, 94.3591,  0.1000,\n",
      "         94.2488, 94.3591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0700, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 814 was 99.2%\n",
      "current params: tensor([94.2488, 94.3422, 94.2890, 94.3591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.9\n",
      "SLow rates:  tensor([[94.3488, 94.4423, 94.3890, 94.4591,  0.1000,  0.1000,  0.1000, 94.3488,\n",
      "         94.3488, 94.3488,  0.1000,  0.1000, 94.4423, 94.4423, 94.4423,  0.1000,\n",
      "          0.1000, 94.4423, 94.4423,  0.1000, 94.3890, 94.3890, 94.3890,  0.1000,\n",
      "          0.1000, 94.3890, 94.3890,  0.1000, 94.3890,  0.1000, 94.3890, 94.4591,\n",
      "         94.4591, 94.4591,  0.1000,  0.1000, 94.4591, 94.4591,  0.1000, 94.4591,\n",
      "          0.1000, 94.4591, 94.4423, 94.4591, 94.4591, 94.4591, 94.3890, 94.4591,\n",
      "         94.4591, 94.4591, 94.4423, 94.4591, 94.4591, 94.4591, 94.4423, 94.3890,\n",
      "         94.4423, 94.4423, 94.4423,  0.1000, 94.4423, 94.3890,  0.1000, 94.3890,\n",
      "         94.4591,  0.1000, 94.4591, 94.4591, 94.4591, 94.4423, 94.4423,  0.1000,\n",
      "         94.4591,  0.1000, 94.3488, 94.3488, 94.4423, 94.4591, 94.4591,  0.1000,\n",
      "          0.1000, 94.3488, 94.4423, 94.4591,  0.1000, 94.4423, 94.4591,  0.1000,\n",
      "         94.3488, 94.4591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0696, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 815 was 99.2%\n",
      "current params: tensor([94.3488, 94.4423, 94.3890, 94.4591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.0\n",
      "SLow rates:  tensor([[94.4489, 94.5423, 94.4891, 94.5591,  0.1000,  0.1000,  0.1000, 94.4489,\n",
      "         94.4489, 94.4489,  0.1000,  0.1000, 94.5423, 94.5423, 94.5423,  0.1000,\n",
      "          0.1000, 94.5423, 94.5423,  0.1000, 94.4891, 94.4891, 94.4891,  0.1000,\n",
      "          0.1000, 94.4891, 94.4891,  0.1000, 94.4891,  0.1000, 94.4891, 94.5591,\n",
      "         94.5591, 94.5591,  0.1000,  0.1000, 94.5591, 94.5591,  0.1000, 94.5591,\n",
      "          0.1000, 94.5591, 94.5423, 94.5591, 94.5591, 94.5591, 94.4891, 94.5591,\n",
      "         94.5591, 94.5591, 94.5423, 94.5591, 94.5591, 94.5591, 94.5423, 94.4891,\n",
      "         94.5423, 94.5423, 94.5423,  0.1000, 94.5423, 94.4891,  0.1000, 94.4891,\n",
      "         94.5591,  0.1000, 94.5591, 94.5591, 94.5591, 94.5423, 94.5423,  0.1000,\n",
      "         94.5591,  0.1000, 94.4489, 94.4489, 94.5423, 94.5591, 94.5591,  0.1000,\n",
      "          0.1000, 94.4489, 94.5423, 94.5591,  0.1000, 94.5423, 94.5591,  0.1000,\n",
      "         94.4489, 94.5591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 816 was 99.2%\n",
      "current params: tensor([94.4489, 94.5423, 94.4891, 94.5591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.0\n",
      "SLow rates:  tensor([[94.5489, 94.6423, 94.5891, 94.6591,  0.1000,  0.1000,  0.1000, 94.5489,\n",
      "         94.5489, 94.5489,  0.1000,  0.1000, 94.6423, 94.6423, 94.6423,  0.1000,\n",
      "          0.1000, 94.6423, 94.6423,  0.1000, 94.5891, 94.5891, 94.5891,  0.1000,\n",
      "          0.1000, 94.5891, 94.5891,  0.1000, 94.5891,  0.1000, 94.5891, 94.6591,\n",
      "         94.6591, 94.6591,  0.1000,  0.1000, 94.6591, 94.6591,  0.1000, 94.6591,\n",
      "          0.1000, 94.6591, 94.6423, 94.6591, 94.6591, 94.6591, 94.5891, 94.6591,\n",
      "         94.6591, 94.6591, 94.6423, 94.6591, 94.6591, 94.6591, 94.6423, 94.5891,\n",
      "         94.6423, 94.6423, 94.6423,  0.1000, 94.6423, 94.5891,  0.1000, 94.5891,\n",
      "         94.6591,  0.1000, 94.6591, 94.6591, 94.6591, 94.6423, 94.6423,  0.1000,\n",
      "         94.6591,  0.1000, 94.5489, 94.5489, 94.6423, 94.6591, 94.6591,  0.1000,\n",
      "          0.1000, 94.5489, 94.6423, 94.6591,  0.1000, 94.6423, 94.6591,  0.1000,\n",
      "         94.5489, 94.6591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 817 was 99.2%\n",
      "current params: tensor([94.5489, 94.6423, 94.5891, 94.6591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.0\n",
      "SLow rates:  tensor([[94.6489, 94.7423, 94.6891, 94.7591,  0.1000,  0.1000,  0.1000, 94.6489,\n",
      "         94.6489, 94.6489,  0.1000,  0.1000, 94.7423, 94.7423, 94.7423,  0.1000,\n",
      "          0.1000, 94.7423, 94.7423,  0.1000, 94.6891, 94.6891, 94.6891,  0.1000,\n",
      "          0.1000, 94.6891, 94.6891,  0.1000, 94.6891,  0.1000, 94.6891, 94.7591,\n",
      "         94.7591, 94.7591,  0.1000,  0.1000, 94.7591, 94.7591,  0.1000, 94.7591,\n",
      "          0.1000, 94.7591, 94.7423, 94.7591, 94.7591, 94.7591, 94.6891, 94.7591,\n",
      "         94.7591, 94.7591, 94.7423, 94.7591, 94.7591, 94.7591, 94.7423, 94.6891,\n",
      "         94.7423, 94.7423, 94.7423,  0.1000, 94.7423, 94.6891,  0.1000, 94.6891,\n",
      "         94.7591,  0.1000, 94.7591, 94.7591, 94.7591, 94.7423, 94.7423,  0.1000,\n",
      "         94.7591,  0.1000, 94.6489, 94.6489, 94.7423, 94.7591, 94.7591,  0.1000,\n",
      "          0.1000, 94.6489, 94.7423, 94.7591,  0.1000, 94.7423, 94.7591,  0.1000,\n",
      "         94.6489, 94.7591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 818 was 99.2%\n",
      "current params: tensor([94.6489, 94.7423, 94.6891, 94.7591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.0\n",
      "SLow rates:  tensor([[94.7489, 94.8423, 94.7891, 94.8591,  0.1000,  0.1000,  0.1000, 94.7489,\n",
      "         94.7489, 94.7489,  0.1000,  0.1000, 94.8423, 94.8423, 94.8423,  0.1000,\n",
      "          0.1000, 94.8423, 94.8423,  0.1000, 94.7891, 94.7891, 94.7891,  0.1000,\n",
      "          0.1000, 94.7891, 94.7891,  0.1000, 94.7891,  0.1000, 94.7891, 94.8591,\n",
      "         94.8591, 94.8591,  0.1000,  0.1000, 94.8591, 94.8591,  0.1000, 94.8591,\n",
      "          0.1000, 94.8591, 94.8423, 94.8591, 94.8591, 94.8591, 94.7891, 94.8591,\n",
      "         94.8591, 94.8591, 94.8423, 94.8591, 94.8591, 94.8591, 94.8423, 94.7891,\n",
      "         94.8423, 94.8423, 94.8423,  0.1000, 94.8423, 94.7891,  0.1000, 94.7891,\n",
      "         94.8591,  0.1000, 94.8591, 94.8591, 94.8591, 94.8423, 94.8423,  0.1000,\n",
      "         94.8591,  0.1000, 94.7489, 94.7489, 94.8423, 94.8591, 94.8591,  0.1000,\n",
      "          0.1000, 94.7489, 94.8423, 94.8591,  0.1000, 94.8423, 94.8591,  0.1000,\n",
      "         94.7489, 94.8591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 819 was 99.2%\n",
      "current params: tensor([94.7489, 94.8423, 94.7891, 94.8591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.0\n",
      "SLow rates:  tensor([[94.8489, 94.9423, 94.8891, 94.9591,  0.1000,  0.1000,  0.1000, 94.8489,\n",
      "         94.8489, 94.8489,  0.1000,  0.1000, 94.9423, 94.9423, 94.9423,  0.1000,\n",
      "          0.1000, 94.9423, 94.9423,  0.1000, 94.8891, 94.8891, 94.8891,  0.1000,\n",
      "          0.1000, 94.8891, 94.8891,  0.1000, 94.8891,  0.1000, 94.8891, 94.9591,\n",
      "         94.9591, 94.9591,  0.1000,  0.1000, 94.9591, 94.9591,  0.1000, 94.9591,\n",
      "          0.1000, 94.9591, 94.9423, 94.9591, 94.9591, 94.9591, 94.8891, 94.9591,\n",
      "         94.9591, 94.9591, 94.9423, 94.9591, 94.9591, 94.9591, 94.9423, 94.8891,\n",
      "         94.9423, 94.9423, 94.9423,  0.1000, 94.9423, 94.8891,  0.1000, 94.8891,\n",
      "         94.9591,  0.1000, 94.9591, 94.9591, 94.9591, 94.9423, 94.9423,  0.1000,\n",
      "         94.9591,  0.1000, 94.8489, 94.8489, 94.9423, 94.9591, 94.9591,  0.1000,\n",
      "          0.1000, 94.8489, 94.9423, 94.9591,  0.1000, 94.9423, 94.9591,  0.1000,\n",
      "         94.8489, 94.9591]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 820 was 99.2%\n",
      "current params: tensor([94.8489, 94.9423, 94.8891, 94.9591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.1\n",
      "SLow rates:  tensor([[94.9489, 95.0423, 94.9891, 95.0592,  0.1000,  0.1000,  0.1000, 94.9489,\n",
      "         94.9489, 94.9489,  0.1000,  0.1000, 95.0423, 95.0423, 95.0423,  0.1000,\n",
      "          0.1000, 95.0423, 95.0423,  0.1000, 94.9891, 94.9891, 94.9891,  0.1000,\n",
      "          0.1000, 94.9891, 94.9891,  0.1000, 94.9891,  0.1000, 94.9891, 95.0592,\n",
      "         95.0592, 95.0592,  0.1000,  0.1000, 95.0592, 95.0592,  0.1000, 95.0592,\n",
      "          0.1000, 95.0592, 95.0423, 95.0592, 95.0592, 95.0592, 94.9891, 95.0592,\n",
      "         95.0592, 95.0592, 95.0423, 95.0592, 95.0592, 95.0592, 95.0423, 94.9891,\n",
      "         95.0423, 95.0423, 95.0423,  0.1000, 95.0423, 94.9891,  0.1000, 94.9891,\n",
      "         95.0592,  0.1000, 95.0592, 95.0592, 95.0592, 95.0423, 95.0423,  0.1000,\n",
      "         95.0592,  0.1000, 94.9489, 94.9489, 95.0423, 95.0592, 95.0592,  0.1000,\n",
      "          0.1000, 94.9489, 95.0423, 95.0592,  0.1000, 95.0423, 95.0592,  0.1000,\n",
      "         94.9489, 95.0592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 821 was 99.2%\n",
      "current params: tensor([94.9489, 95.0423, 94.9891, 95.0592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.1\n",
      "SLow rates:  tensor([[95.0489, 95.1423, 95.0891, 95.1592,  0.1000,  0.1000,  0.1000, 95.0489,\n",
      "         95.0489, 95.0489,  0.1000,  0.1000, 95.1423, 95.1423, 95.1423,  0.1000,\n",
      "          0.1000, 95.1423, 95.1423,  0.1000, 95.0891, 95.0891, 95.0891,  0.1000,\n",
      "          0.1000, 95.0891, 95.0891,  0.1000, 95.0891,  0.1000, 95.0891, 95.1592,\n",
      "         95.1592, 95.1592,  0.1000,  0.1000, 95.1592, 95.1592,  0.1000, 95.1592,\n",
      "          0.1000, 95.1592, 95.1423, 95.1592, 95.1592, 95.1592, 95.0891, 95.1592,\n",
      "         95.1592, 95.1592, 95.1423, 95.1592, 95.1592, 95.1592, 95.1423, 95.0891,\n",
      "         95.1423, 95.1423, 95.1423,  0.1000, 95.1423, 95.0891,  0.1000, 95.0891,\n",
      "         95.1592,  0.1000, 95.1592, 95.1592, 95.1592, 95.1423, 95.1423,  0.1000,\n",
      "         95.1592,  0.1000, 95.0489, 95.0489, 95.1423, 95.1592, 95.1592,  0.1000,\n",
      "          0.1000, 95.0489, 95.1423, 95.1592,  0.1000, 95.1423, 95.1592,  0.1000,\n",
      "         95.0489, 95.1592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0672, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 822 was 99.2%\n",
      "current params: tensor([95.0489, 95.1423, 95.0891, 95.1592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.1\n",
      "SLow rates:  tensor([[95.1489, 95.2423, 95.1891, 95.2592,  0.1000,  0.1000,  0.1000, 95.1489,\n",
      "         95.1489, 95.1489,  0.1000,  0.1000, 95.2423, 95.2423, 95.2423,  0.1000,\n",
      "          0.1000, 95.2423, 95.2423,  0.1000, 95.1891, 95.1891, 95.1891,  0.1000,\n",
      "          0.1000, 95.1891, 95.1891,  0.1000, 95.1891,  0.1000, 95.1891, 95.2592,\n",
      "         95.2592, 95.2592,  0.1000,  0.1000, 95.2592, 95.2592,  0.1000, 95.2592,\n",
      "          0.1000, 95.2592, 95.2423, 95.2592, 95.2592, 95.2592, 95.1891, 95.2592,\n",
      "         95.2592, 95.2592, 95.2423, 95.2592, 95.2592, 95.2592, 95.2423, 95.1891,\n",
      "         95.2423, 95.2423, 95.2423,  0.1000, 95.2423, 95.1891,  0.1000, 95.1891,\n",
      "         95.2592,  0.1000, 95.2592, 95.2592, 95.2592, 95.2423, 95.2423,  0.1000,\n",
      "         95.2592,  0.1000, 95.1489, 95.1489, 95.2423, 95.2592, 95.2592,  0.1000,\n",
      "          0.1000, 95.1489, 95.2423, 95.2592,  0.1000, 95.2423, 95.2592,  0.1000,\n",
      "         95.1489, 95.2592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 823 was 99.2%\n",
      "current params: tensor([95.1489, 95.2423, 95.1891, 95.2592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.1\n",
      "SLow rates:  tensor([[95.2489, 95.3423, 95.2891, 95.3592,  0.1000,  0.1000,  0.1000, 95.2489,\n",
      "         95.2489, 95.2489,  0.1000,  0.1000, 95.3423, 95.3423, 95.3423,  0.1000,\n",
      "          0.1000, 95.3423, 95.3423,  0.1000, 95.2891, 95.2891, 95.2891,  0.1000,\n",
      "          0.1000, 95.2891, 95.2891,  0.1000, 95.2891,  0.1000, 95.2891, 95.3592,\n",
      "         95.3592, 95.3592,  0.1000,  0.1000, 95.3592, 95.3592,  0.1000, 95.3592,\n",
      "          0.1000, 95.3592, 95.3423, 95.3592, 95.3592, 95.3592, 95.2891, 95.3592,\n",
      "         95.3592, 95.3592, 95.3423, 95.3592, 95.3592, 95.3592, 95.3423, 95.2891,\n",
      "         95.3423, 95.3423, 95.3423,  0.1000, 95.3423, 95.2891,  0.1000, 95.2891,\n",
      "         95.3592,  0.1000, 95.3592, 95.3592, 95.3592, 95.3423, 95.3423,  0.1000,\n",
      "         95.3592,  0.1000, 95.2489, 95.2489, 95.3423, 95.3592, 95.3592,  0.1000,\n",
      "          0.1000, 95.2489, 95.3423, 95.3592,  0.1000, 95.3423, 95.3592,  0.1000,\n",
      "         95.2489, 95.3592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 824 was 99.2%\n",
      "current params: tensor([95.2489, 95.3423, 95.2891, 95.3592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.2\n",
      "SLow rates:  tensor([[95.3489, 95.4423, 95.3891, 95.4592,  0.1000,  0.1000,  0.1000, 95.3489,\n",
      "         95.3489, 95.3489,  0.1000,  0.1000, 95.4423, 95.4423, 95.4423,  0.1000,\n",
      "          0.1000, 95.4423, 95.4423,  0.1000, 95.3891, 95.3891, 95.3891,  0.1000,\n",
      "          0.1000, 95.3891, 95.3891,  0.1000, 95.3891,  0.1000, 95.3891, 95.4592,\n",
      "         95.4592, 95.4592,  0.1000,  0.1000, 95.4592, 95.4592,  0.1000, 95.4592,\n",
      "          0.1000, 95.4592, 95.4423, 95.4592, 95.4592, 95.4592, 95.3891, 95.4592,\n",
      "         95.4592, 95.4592, 95.4423, 95.4592, 95.4592, 95.4592, 95.4423, 95.3891,\n",
      "         95.4423, 95.4423, 95.4423,  0.1000, 95.4423, 95.3891,  0.1000, 95.3891,\n",
      "         95.4592,  0.1000, 95.4592, 95.4592, 95.4592, 95.4423, 95.4423,  0.1000,\n",
      "         95.4592,  0.1000, 95.3489, 95.3489, 95.4423, 95.4592, 95.4592,  0.1000,\n",
      "          0.1000, 95.3489, 95.4423, 95.4592,  0.1000, 95.4423, 95.4592,  0.1000,\n",
      "         95.3489, 95.4592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0662, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 825 was 99.2%\n",
      "current params: tensor([95.3489, 95.4423, 95.3891, 95.4592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.2\n",
      "SLow rates:  tensor([[95.4490, 95.5424, 95.4892, 95.5592,  0.1000,  0.1000,  0.1000, 95.4490,\n",
      "         95.4490, 95.4490,  0.1000,  0.1000, 95.5424, 95.5424, 95.5424,  0.1000,\n",
      "          0.1000, 95.5424, 95.5424,  0.1000, 95.4892, 95.4892, 95.4892,  0.1000,\n",
      "          0.1000, 95.4892, 95.4892,  0.1000, 95.4892,  0.1000, 95.4892, 95.5592,\n",
      "         95.5592, 95.5592,  0.1000,  0.1000, 95.5592, 95.5592,  0.1000, 95.5592,\n",
      "          0.1000, 95.5592, 95.5424, 95.5592, 95.5592, 95.5592, 95.4892, 95.5592,\n",
      "         95.5592, 95.5592, 95.5424, 95.5592, 95.5592, 95.5592, 95.5424, 95.4892,\n",
      "         95.5424, 95.5424, 95.5424,  0.1000, 95.5424, 95.4892,  0.1000, 95.4892,\n",
      "         95.5592,  0.1000, 95.5592, 95.5592, 95.5592, 95.5424, 95.5424,  0.1000,\n",
      "         95.5592,  0.1000, 95.4490, 95.4490, 95.5424, 95.5592, 95.5592,  0.1000,\n",
      "          0.1000, 95.4490, 95.5424, 95.5592,  0.1000, 95.5424, 95.5592,  0.1000,\n",
      "         95.4490, 95.5592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 826 was 99.2%\n",
      "current params: tensor([95.4490, 95.5424, 95.4892, 95.5592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.2\n",
      "SLow rates:  tensor([[95.5490, 95.6424, 95.5892, 95.6592,  0.1000,  0.1000,  0.1000, 95.5490,\n",
      "         95.5490, 95.5490,  0.1000,  0.1000, 95.6424, 95.6424, 95.6424,  0.1000,\n",
      "          0.1000, 95.6424, 95.6424,  0.1000, 95.5892, 95.5892, 95.5892,  0.1000,\n",
      "          0.1000, 95.5892, 95.5892,  0.1000, 95.5892,  0.1000, 95.5892, 95.6592,\n",
      "         95.6592, 95.6592,  0.1000,  0.1000, 95.6592, 95.6592,  0.1000, 95.6592,\n",
      "          0.1000, 95.6592, 95.6424, 95.6592, 95.6592, 95.6592, 95.5892, 95.6592,\n",
      "         95.6592, 95.6592, 95.6424, 95.6592, 95.6592, 95.6592, 95.6424, 95.5892,\n",
      "         95.6424, 95.6424, 95.6424,  0.1000, 95.6424, 95.5892,  0.1000, 95.5892,\n",
      "         95.6592,  0.1000, 95.6592, 95.6592, 95.6592, 95.6424, 95.6424,  0.1000,\n",
      "         95.6592,  0.1000, 95.5490, 95.5490, 95.6424, 95.6592, 95.6592,  0.1000,\n",
      "          0.1000, 95.5490, 95.6424, 95.6592,  0.1000, 95.6424, 95.6592,  0.1000,\n",
      "         95.5490, 95.6592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 827 was 99.2%\n",
      "current params: tensor([95.5490, 95.6424, 95.5892, 95.6592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.2\n",
      "SLow rates:  tensor([[95.6490, 95.7424, 95.6892, 95.7592,  0.1000,  0.1000,  0.1000, 95.6490,\n",
      "         95.6490, 95.6490,  0.1000,  0.1000, 95.7424, 95.7424, 95.7424,  0.1000,\n",
      "          0.1000, 95.7424, 95.7424,  0.1000, 95.6892, 95.6892, 95.6892,  0.1000,\n",
      "          0.1000, 95.6892, 95.6892,  0.1000, 95.6892,  0.1000, 95.6892, 95.7592,\n",
      "         95.7592, 95.7592,  0.1000,  0.1000, 95.7592, 95.7592,  0.1000, 95.7592,\n",
      "          0.1000, 95.7592, 95.7424, 95.7592, 95.7592, 95.7592, 95.6892, 95.7592,\n",
      "         95.7592, 95.7592, 95.7424, 95.7592, 95.7592, 95.7592, 95.7424, 95.6892,\n",
      "         95.7424, 95.7424, 95.7424,  0.1000, 95.7424, 95.6892,  0.1000, 95.6892,\n",
      "         95.7592,  0.1000, 95.7592, 95.7592, 95.7592, 95.7424, 95.7424,  0.1000,\n",
      "         95.7592,  0.1000, 95.6490, 95.6490, 95.7424, 95.7592, 95.7592,  0.1000,\n",
      "          0.1000, 95.6490, 95.7424, 95.7592,  0.1000, 95.7424, 95.7592,  0.1000,\n",
      "         95.6490, 95.7592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 828 was 99.2%\n",
      "current params: tensor([95.6490, 95.7424, 95.6892, 95.7592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.2\n",
      "SLow rates:  tensor([[95.7490, 95.8424, 95.7892, 95.8592,  0.1000,  0.1000,  0.1000, 95.7490,\n",
      "         95.7490, 95.7490,  0.1000,  0.1000, 95.8424, 95.8424, 95.8424,  0.1000,\n",
      "          0.1000, 95.8424, 95.8424,  0.1000, 95.7892, 95.7892, 95.7892,  0.1000,\n",
      "          0.1000, 95.7892, 95.7892,  0.1000, 95.7892,  0.1000, 95.7892, 95.8592,\n",
      "         95.8592, 95.8592,  0.1000,  0.1000, 95.8592, 95.8592,  0.1000, 95.8592,\n",
      "          0.1000, 95.8592, 95.8424, 95.8592, 95.8592, 95.8592, 95.7892, 95.8592,\n",
      "         95.8592, 95.8592, 95.8424, 95.8592, 95.8592, 95.8592, 95.8424, 95.7892,\n",
      "         95.8424, 95.8424, 95.8424,  0.1000, 95.8424, 95.7892,  0.1000, 95.7892,\n",
      "         95.8592,  0.1000, 95.8592, 95.8592, 95.8592, 95.8424, 95.8424,  0.1000,\n",
      "         95.8592,  0.1000, 95.7490, 95.7490, 95.8424, 95.8592, 95.8592,  0.1000,\n",
      "          0.1000, 95.7490, 95.8424, 95.8592,  0.1000, 95.8424, 95.8592,  0.1000,\n",
      "         95.7490, 95.8592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 829 was 99.2%\n",
      "current params: tensor([95.7490, 95.8424, 95.7892, 95.8592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.3\n",
      "SLow rates:  tensor([[95.8490, 95.9424, 95.8892, 95.9592,  0.1000,  0.1000,  0.1000, 95.8490,\n",
      "         95.8490, 95.8490,  0.1000,  0.1000, 95.9424, 95.9424, 95.9424,  0.1000,\n",
      "          0.1000, 95.9424, 95.9424,  0.1000, 95.8892, 95.8892, 95.8892,  0.1000,\n",
      "          0.1000, 95.8892, 95.8892,  0.1000, 95.8892,  0.1000, 95.8892, 95.9592,\n",
      "         95.9592, 95.9592,  0.1000,  0.1000, 95.9592, 95.9592,  0.1000, 95.9592,\n",
      "          0.1000, 95.9592, 95.9424, 95.9592, 95.9592, 95.9592, 95.8892, 95.9592,\n",
      "         95.9592, 95.9592, 95.9424, 95.9592, 95.9592, 95.9592, 95.9424, 95.8892,\n",
      "         95.9424, 95.9424, 95.9424,  0.1000, 95.9424, 95.8892,  0.1000, 95.8892,\n",
      "         95.9592,  0.1000, 95.9592, 95.9592, 95.9592, 95.9424, 95.9424,  0.1000,\n",
      "         95.9592,  0.1000, 95.8490, 95.8490, 95.9424, 95.9592, 95.9592,  0.1000,\n",
      "          0.1000, 95.8490, 95.9424, 95.9592,  0.1000, 95.9424, 95.9592,  0.1000,\n",
      "         95.8490, 95.9592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 830 was 99.2%\n",
      "current params: tensor([95.8490, 95.9424, 95.8892, 95.9592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.3\n",
      "SLow rates:  tensor([[95.9490, 96.0424, 95.9892, 96.0592,  0.1000,  0.1000,  0.1000, 95.9490,\n",
      "         95.9490, 95.9490,  0.1000,  0.1000, 96.0424, 96.0424, 96.0424,  0.1000,\n",
      "          0.1000, 96.0424, 96.0424,  0.1000, 95.9892, 95.9892, 95.9892,  0.1000,\n",
      "          0.1000, 95.9892, 95.9892,  0.1000, 95.9892,  0.1000, 95.9892, 96.0592,\n",
      "         96.0592, 96.0592,  0.1000,  0.1000, 96.0592, 96.0592,  0.1000, 96.0592,\n",
      "          0.1000, 96.0592, 96.0424, 96.0592, 96.0592, 96.0592, 95.9892, 96.0592,\n",
      "         96.0592, 96.0592, 96.0424, 96.0592, 96.0592, 96.0592, 96.0424, 95.9892,\n",
      "         96.0424, 96.0424, 96.0424,  0.1000, 96.0424, 95.9892,  0.1000, 95.9892,\n",
      "         96.0592,  0.1000, 96.0592, 96.0592, 96.0592, 96.0424, 96.0424,  0.1000,\n",
      "         96.0592,  0.1000, 95.9490, 95.9490, 96.0424, 96.0592, 96.0592,  0.1000,\n",
      "          0.1000, 95.9490, 96.0424, 96.0592,  0.1000, 96.0424, 96.0592,  0.1000,\n",
      "         95.9490, 96.0592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 831 was 99.2%\n",
      "current params: tensor([95.9490, 96.0424, 95.9892, 96.0592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.3\n",
      "SLow rates:  tensor([[96.0490, 96.1424, 96.0892, 96.1592,  0.1000,  0.1000,  0.1000, 96.0490,\n",
      "         96.0490, 96.0490,  0.1000,  0.1000, 96.1424, 96.1424, 96.1424,  0.1000,\n",
      "          0.1000, 96.1424, 96.1424,  0.1000, 96.0892, 96.0892, 96.0892,  0.1000,\n",
      "          0.1000, 96.0892, 96.0892,  0.1000, 96.0892,  0.1000, 96.0892, 96.1592,\n",
      "         96.1592, 96.1592,  0.1000,  0.1000, 96.1592, 96.1592,  0.1000, 96.1592,\n",
      "          0.1000, 96.1592, 96.1424, 96.1592, 96.1592, 96.1592, 96.0892, 96.1592,\n",
      "         96.1592, 96.1592, 96.1424, 96.1592, 96.1592, 96.1592, 96.1424, 96.0892,\n",
      "         96.1424, 96.1424, 96.1424,  0.1000, 96.1424, 96.0892,  0.1000, 96.0892,\n",
      "         96.1592,  0.1000, 96.1592, 96.1592, 96.1592, 96.1424, 96.1424,  0.1000,\n",
      "         96.1592,  0.1000, 96.0490, 96.0490, 96.1424, 96.1592, 96.1592,  0.1000,\n",
      "          0.1000, 96.0490, 96.1424, 96.1592,  0.1000, 96.1424, 96.1592,  0.1000,\n",
      "         96.0490, 96.1592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 832 was 99.2%\n",
      "current params: tensor([96.0490, 96.1424, 96.0892, 96.1592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.3\n",
      "SLow rates:  tensor([[96.1490, 96.2424, 96.1892, 96.2592,  0.1000,  0.1000,  0.1000, 96.1490,\n",
      "         96.1490, 96.1490,  0.1000,  0.1000, 96.2424, 96.2424, 96.2424,  0.1000,\n",
      "          0.1000, 96.2424, 96.2424,  0.1000, 96.1892, 96.1892, 96.1892,  0.1000,\n",
      "          0.1000, 96.1892, 96.1892,  0.1000, 96.1892,  0.1000, 96.1892, 96.2592,\n",
      "         96.2592, 96.2592,  0.1000,  0.1000, 96.2592, 96.2592,  0.1000, 96.2592,\n",
      "          0.1000, 96.2592, 96.2424, 96.2592, 96.2592, 96.2592, 96.1892, 96.2592,\n",
      "         96.2592, 96.2592, 96.2424, 96.2592, 96.2592, 96.2592, 96.2424, 96.1892,\n",
      "         96.2424, 96.2424, 96.2424,  0.1000, 96.2424, 96.1892,  0.1000, 96.1892,\n",
      "         96.2592,  0.1000, 96.2592, 96.2592, 96.2592, 96.2424, 96.2424,  0.1000,\n",
      "         96.2592,  0.1000, 96.1490, 96.1490, 96.2424, 96.2592, 96.2592,  0.1000,\n",
      "          0.1000, 96.1490, 96.2424, 96.2592,  0.1000, 96.2424, 96.2592,  0.1000,\n",
      "         96.1490, 96.2592]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 833 was 99.2%\n",
      "current params: tensor([96.1490, 96.2424, 96.1892, 96.2592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.3\n",
      "SLow rates:  tensor([[96.2490, 96.3424, 96.2892, 96.3593,  0.1000,  0.1000,  0.1000, 96.2490,\n",
      "         96.2490, 96.2490,  0.1000,  0.1000, 96.3424, 96.3424, 96.3424,  0.1000,\n",
      "          0.1000, 96.3424, 96.3424,  0.1000, 96.2892, 96.2892, 96.2892,  0.1000,\n",
      "          0.1000, 96.2892, 96.2892,  0.1000, 96.2892,  0.1000, 96.2892, 96.3593,\n",
      "         96.3593, 96.3593,  0.1000,  0.1000, 96.3593, 96.3593,  0.1000, 96.3593,\n",
      "          0.1000, 96.3593, 96.3424, 96.3593, 96.3593, 96.3593, 96.2892, 96.3593,\n",
      "         96.3593, 96.3593, 96.3424, 96.3593, 96.3593, 96.3593, 96.3424, 96.2892,\n",
      "         96.3424, 96.3424, 96.3424,  0.1000, 96.3424, 96.2892,  0.1000, 96.2892,\n",
      "         96.3593,  0.1000, 96.3593, 96.3593, 96.3593, 96.3424, 96.3424,  0.1000,\n",
      "         96.3593,  0.1000, 96.2490, 96.2490, 96.3424, 96.3593, 96.3593,  0.1000,\n",
      "          0.1000, 96.2490, 96.3424, 96.3593,  0.1000, 96.3424, 96.3593,  0.1000,\n",
      "         96.2490, 96.3593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 834 was 99.2%\n",
      "current params: tensor([96.2490, 96.3424, 96.2892, 96.3593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.3\n",
      "SLow rates:  tensor([[96.3490, 96.4424, 96.3892, 96.4593,  0.1000,  0.1000,  0.1000, 96.3490,\n",
      "         96.3490, 96.3490,  0.1000,  0.1000, 96.4424, 96.4424, 96.4424,  0.1000,\n",
      "          0.1000, 96.4424, 96.4424,  0.1000, 96.3892, 96.3892, 96.3892,  0.1000,\n",
      "          0.1000, 96.3892, 96.3892,  0.1000, 96.3892,  0.1000, 96.3892, 96.4593,\n",
      "         96.4593, 96.4593,  0.1000,  0.1000, 96.4593, 96.4593,  0.1000, 96.4593,\n",
      "          0.1000, 96.4593, 96.4424, 96.4593, 96.4593, 96.4593, 96.3892, 96.4593,\n",
      "         96.4593, 96.4593, 96.4424, 96.4593, 96.4593, 96.4593, 96.4424, 96.3892,\n",
      "         96.4424, 96.4424, 96.4424,  0.1000, 96.4424, 96.3892,  0.1000, 96.3892,\n",
      "         96.4593,  0.1000, 96.4593, 96.4593, 96.4593, 96.4424, 96.4424,  0.1000,\n",
      "         96.4593,  0.1000, 96.3490, 96.3490, 96.4424, 96.4593, 96.4593,  0.1000,\n",
      "          0.1000, 96.3490, 96.4424, 96.4593,  0.1000, 96.4424, 96.4593,  0.1000,\n",
      "         96.3490, 96.4593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 835 was 99.2%\n",
      "current params: tensor([96.3490, 96.4424, 96.3892, 96.4593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.4\n",
      "SLow rates:  tensor([[96.4491, 96.5424, 96.4892, 96.5593,  0.1000,  0.1000,  0.1000, 96.4491,\n",
      "         96.4491, 96.4491,  0.1000,  0.1000, 96.5424, 96.5424, 96.5424,  0.1000,\n",
      "          0.1000, 96.5424, 96.5424,  0.1000, 96.4892, 96.4892, 96.4892,  0.1000,\n",
      "          0.1000, 96.4892, 96.4892,  0.1000, 96.4892,  0.1000, 96.4892, 96.5593,\n",
      "         96.5593, 96.5593,  0.1000,  0.1000, 96.5593, 96.5593,  0.1000, 96.5593,\n",
      "          0.1000, 96.5593, 96.5424, 96.5593, 96.5593, 96.5593, 96.4892, 96.5593,\n",
      "         96.5593, 96.5593, 96.5424, 96.5593, 96.5593, 96.5593, 96.5424, 96.4892,\n",
      "         96.5424, 96.5424, 96.5424,  0.1000, 96.5424, 96.4892,  0.1000, 96.4892,\n",
      "         96.5593,  0.1000, 96.5593, 96.5593, 96.5593, 96.5424, 96.5424,  0.1000,\n",
      "         96.5593,  0.1000, 96.4491, 96.4491, 96.5424, 96.5593, 96.5593,  0.1000,\n",
      "          0.1000, 96.4491, 96.5424, 96.5593,  0.1000, 96.5424, 96.5593,  0.1000,\n",
      "         96.4491, 96.5593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 836 was 99.2%\n",
      "current params: tensor([96.4491, 96.5424, 96.4892, 96.5593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.4\n",
      "SLow rates:  tensor([[96.5491, 96.6424, 96.5893, 96.6593,  0.1000,  0.1000,  0.1000, 96.5491,\n",
      "         96.5491, 96.5491,  0.1000,  0.1000, 96.6424, 96.6424, 96.6424,  0.1000,\n",
      "          0.1000, 96.6424, 96.6424,  0.1000, 96.5893, 96.5893, 96.5893,  0.1000,\n",
      "          0.1000, 96.5893, 96.5893,  0.1000, 96.5893,  0.1000, 96.5893, 96.6593,\n",
      "         96.6593, 96.6593,  0.1000,  0.1000, 96.6593, 96.6593,  0.1000, 96.6593,\n",
      "          0.1000, 96.6593, 96.6424, 96.6593, 96.6593, 96.6593, 96.5893, 96.6593,\n",
      "         96.6593, 96.6593, 96.6424, 96.6593, 96.6593, 96.6593, 96.6424, 96.5893,\n",
      "         96.6424, 96.6424, 96.6424,  0.1000, 96.6424, 96.5893,  0.1000, 96.5893,\n",
      "         96.6593,  0.1000, 96.6593, 96.6593, 96.6593, 96.6424, 96.6424,  0.1000,\n",
      "         96.6593,  0.1000, 96.5491, 96.5491, 96.6424, 96.6593, 96.6593,  0.1000,\n",
      "          0.1000, 96.5491, 96.6424, 96.6593,  0.1000, 96.6424, 96.6593,  0.1000,\n",
      "         96.5491, 96.6593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 837 was 99.2%\n",
      "current params: tensor([96.5491, 96.6424, 96.5893, 96.6593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.4\n",
      "SLow rates:  tensor([[96.6491, 96.7424, 96.6893, 96.7593,  0.1000,  0.1000,  0.1000, 96.6491,\n",
      "         96.6491, 96.6491,  0.1000,  0.1000, 96.7424, 96.7424, 96.7424,  0.1000,\n",
      "          0.1000, 96.7424, 96.7424,  0.1000, 96.6893, 96.6893, 96.6893,  0.1000,\n",
      "          0.1000, 96.6893, 96.6893,  0.1000, 96.6893,  0.1000, 96.6893, 96.7593,\n",
      "         96.7593, 96.7593,  0.1000,  0.1000, 96.7593, 96.7593,  0.1000, 96.7593,\n",
      "          0.1000, 96.7593, 96.7424, 96.7593, 96.7593, 96.7593, 96.6893, 96.7593,\n",
      "         96.7593, 96.7593, 96.7424, 96.7593, 96.7593, 96.7593, 96.7424, 96.6893,\n",
      "         96.7424, 96.7424, 96.7424,  0.1000, 96.7424, 96.6893,  0.1000, 96.6893,\n",
      "         96.7593,  0.1000, 96.7593, 96.7593, 96.7593, 96.7424, 96.7424,  0.1000,\n",
      "         96.7593,  0.1000, 96.6491, 96.6491, 96.7424, 96.7593, 96.7593,  0.1000,\n",
      "          0.1000, 96.6491, 96.7424, 96.7593,  0.1000, 96.7424, 96.7593,  0.1000,\n",
      "         96.6491, 96.7593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 838 was 99.2%\n",
      "current params: tensor([96.6491, 96.7424, 96.6893, 96.7593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.4\n",
      "SLow rates:  tensor([[96.7491, 96.8425, 96.7893, 96.8593,  0.1000,  0.1000,  0.1000, 96.7491,\n",
      "         96.7491, 96.7491,  0.1000,  0.1000, 96.8425, 96.8425, 96.8425,  0.1000,\n",
      "          0.1000, 96.8425, 96.8425,  0.1000, 96.7893, 96.7893, 96.7893,  0.1000,\n",
      "          0.1000, 96.7893, 96.7893,  0.1000, 96.7893,  0.1000, 96.7893, 96.8593,\n",
      "         96.8593, 96.8593,  0.1000,  0.1000, 96.8593, 96.8593,  0.1000, 96.8593,\n",
      "          0.1000, 96.8593, 96.8425, 96.8593, 96.8593, 96.8593, 96.7893, 96.8593,\n",
      "         96.8593, 96.8593, 96.8425, 96.8593, 96.8593, 96.8593, 96.8425, 96.7893,\n",
      "         96.8425, 96.8425, 96.8425,  0.1000, 96.8425, 96.7893,  0.1000, 96.7893,\n",
      "         96.8593,  0.1000, 96.8593, 96.8593, 96.8593, 96.8425, 96.8425,  0.1000,\n",
      "         96.8593,  0.1000, 96.7491, 96.7491, 96.8425, 96.8593, 96.8593,  0.1000,\n",
      "          0.1000, 96.7491, 96.8425, 96.8593,  0.1000, 96.8425, 96.8593,  0.1000,\n",
      "         96.7491, 96.8593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0619, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 839 was 99.2%\n",
      "current params: tensor([96.7491, 96.8425, 96.7893, 96.8593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.4\n",
      "SLow rates:  tensor([[96.8491, 96.9425, 96.8893, 96.9593,  0.1000,  0.1000,  0.1000, 96.8491,\n",
      "         96.8491, 96.8491,  0.1000,  0.1000, 96.9425, 96.9425, 96.9425,  0.1000,\n",
      "          0.1000, 96.9425, 96.9425,  0.1000, 96.8893, 96.8893, 96.8893,  0.1000,\n",
      "          0.1000, 96.8893, 96.8893,  0.1000, 96.8893,  0.1000, 96.8893, 96.9593,\n",
      "         96.9593, 96.9593,  0.1000,  0.1000, 96.9593, 96.9593,  0.1000, 96.9593,\n",
      "          0.1000, 96.9593, 96.9425, 96.9593, 96.9593, 96.9593, 96.8893, 96.9593,\n",
      "         96.9593, 96.9593, 96.9425, 96.9593, 96.9593, 96.9593, 96.9425, 96.8893,\n",
      "         96.9425, 96.9425, 96.9425,  0.1000, 96.9425, 96.8893,  0.1000, 96.8893,\n",
      "         96.9593,  0.1000, 96.9593, 96.9593, 96.9593, 96.9425, 96.9425,  0.1000,\n",
      "         96.9593,  0.1000, 96.8491, 96.8491, 96.9425, 96.9593, 96.9593,  0.1000,\n",
      "          0.1000, 96.8491, 96.9425, 96.9593,  0.1000, 96.9425, 96.9593,  0.1000,\n",
      "         96.8491, 96.9593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 840 was 99.2%\n",
      "current params: tensor([96.8491, 96.9425, 96.8893, 96.9593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.5\n",
      "SLow rates:  tensor([[96.9491, 97.0425, 96.9893, 97.0593,  0.1000,  0.1000,  0.1000, 96.9491,\n",
      "         96.9491, 96.9491,  0.1000,  0.1000, 97.0425, 97.0425, 97.0425,  0.1000,\n",
      "          0.1000, 97.0425, 97.0425,  0.1000, 96.9893, 96.9893, 96.9893,  0.1000,\n",
      "          0.1000, 96.9893, 96.9893,  0.1000, 96.9893,  0.1000, 96.9893, 97.0593,\n",
      "         97.0593, 97.0593,  0.1000,  0.1000, 97.0593, 97.0593,  0.1000, 97.0593,\n",
      "          0.1000, 97.0593, 97.0425, 97.0593, 97.0593, 97.0593, 96.9893, 97.0593,\n",
      "         97.0593, 97.0593, 97.0425, 97.0593, 97.0593, 97.0593, 97.0425, 96.9893,\n",
      "         97.0425, 97.0425, 97.0425,  0.1000, 97.0425, 96.9893,  0.1000, 96.9893,\n",
      "         97.0593,  0.1000, 97.0593, 97.0593, 97.0593, 97.0425, 97.0425,  0.1000,\n",
      "         97.0593,  0.1000, 96.9491, 96.9491, 97.0425, 97.0593, 97.0593,  0.1000,\n",
      "          0.1000, 96.9491, 97.0425, 97.0593,  0.1000, 97.0425, 97.0593,  0.1000,\n",
      "         96.9491, 97.0593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 841 was 99.2%\n",
      "current params: tensor([96.9491, 97.0425, 96.9893, 97.0593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.5\n",
      "SLow rates:  tensor([[97.0491, 97.1425, 97.0893, 97.1593,  0.1000,  0.1000,  0.1000, 97.0491,\n",
      "         97.0491, 97.0491,  0.1000,  0.1000, 97.1425, 97.1425, 97.1425,  0.1000,\n",
      "          0.1000, 97.1425, 97.1425,  0.1000, 97.0893, 97.0893, 97.0893,  0.1000,\n",
      "          0.1000, 97.0893, 97.0893,  0.1000, 97.0893,  0.1000, 97.0893, 97.1593,\n",
      "         97.1593, 97.1593,  0.1000,  0.1000, 97.1593, 97.1593,  0.1000, 97.1593,\n",
      "          0.1000, 97.1593, 97.1425, 97.1593, 97.1593, 97.1593, 97.0893, 97.1593,\n",
      "         97.1593, 97.1593, 97.1425, 97.1593, 97.1593, 97.1593, 97.1425, 97.0893,\n",
      "         97.1425, 97.1425, 97.1425,  0.1000, 97.1425, 97.0893,  0.1000, 97.0893,\n",
      "         97.1593,  0.1000, 97.1593, 97.1593, 97.1593, 97.1425, 97.1425,  0.1000,\n",
      "         97.1593,  0.1000, 97.0491, 97.0491, 97.1425, 97.1593, 97.1593,  0.1000,\n",
      "          0.1000, 97.0491, 97.1425, 97.1593,  0.1000, 97.1425, 97.1593,  0.1000,\n",
      "         97.0491, 97.1593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 842 was 99.2%\n",
      "current params: tensor([97.0491, 97.1425, 97.0893, 97.1593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.5\n",
      "SLow rates:  tensor([[97.1491, 97.2425, 97.1893, 97.2593,  0.1000,  0.1000,  0.1000, 97.1491,\n",
      "         97.1491, 97.1491,  0.1000,  0.1000, 97.2425, 97.2425, 97.2425,  0.1000,\n",
      "          0.1000, 97.2425, 97.2425,  0.1000, 97.1893, 97.1893, 97.1893,  0.1000,\n",
      "          0.1000, 97.1893, 97.1893,  0.1000, 97.1893,  0.1000, 97.1893, 97.2593,\n",
      "         97.2593, 97.2593,  0.1000,  0.1000, 97.2593, 97.2593,  0.1000, 97.2593,\n",
      "          0.1000, 97.2593, 97.2425, 97.2593, 97.2593, 97.2593, 97.1893, 97.2593,\n",
      "         97.2593, 97.2593, 97.2425, 97.2593, 97.2593, 97.2593, 97.2425, 97.1893,\n",
      "         97.2425, 97.2425, 97.2425,  0.1000, 97.2425, 97.1893,  0.1000, 97.1893,\n",
      "         97.2593,  0.1000, 97.2593, 97.2593, 97.2593, 97.2425, 97.2425,  0.1000,\n",
      "         97.2593,  0.1000, 97.1491, 97.1491, 97.2425, 97.2593, 97.2593,  0.1000,\n",
      "          0.1000, 97.1491, 97.2425, 97.2593,  0.1000, 97.2425, 97.2593,  0.1000,\n",
      "         97.1491, 97.2593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 843 was 99.2%\n",
      "current params: tensor([97.1491, 97.2425, 97.1893, 97.2593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.5\n",
      "SLow rates:  tensor([[97.2491, 97.3425, 97.2893, 97.3593,  0.1000,  0.1000,  0.1000, 97.2491,\n",
      "         97.2491, 97.2491,  0.1000,  0.1000, 97.3425, 97.3425, 97.3425,  0.1000,\n",
      "          0.1000, 97.3425, 97.3425,  0.1000, 97.2893, 97.2893, 97.2893,  0.1000,\n",
      "          0.1000, 97.2893, 97.2893,  0.1000, 97.2893,  0.1000, 97.2893, 97.3593,\n",
      "         97.3593, 97.3593,  0.1000,  0.1000, 97.3593, 97.3593,  0.1000, 97.3593,\n",
      "          0.1000, 97.3593, 97.3425, 97.3593, 97.3593, 97.3593, 97.2893, 97.3593,\n",
      "         97.3593, 97.3593, 97.3425, 97.3593, 97.3593, 97.3593, 97.3425, 97.2893,\n",
      "         97.3425, 97.3425, 97.3425,  0.1000, 97.3425, 97.2893,  0.1000, 97.2893,\n",
      "         97.3593,  0.1000, 97.3593, 97.3593, 97.3593, 97.3425, 97.3425,  0.1000,\n",
      "         97.3593,  0.1000, 97.2491, 97.2491, 97.3425, 97.3593, 97.3593,  0.1000,\n",
      "          0.1000, 97.2491, 97.3425, 97.3593,  0.1000, 97.3425, 97.3593,  0.1000,\n",
      "         97.2491, 97.3593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 844 was 99.2%\n",
      "current params: tensor([97.2491, 97.3425, 97.2893, 97.3593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.5\n",
      "SLow rates:  tensor([[97.3491, 97.4425, 97.3893, 97.4593,  0.1000,  0.1000,  0.1000, 97.3491,\n",
      "         97.3491, 97.3491,  0.1000,  0.1000, 97.4425, 97.4425, 97.4425,  0.1000,\n",
      "          0.1000, 97.4425, 97.4425,  0.1000, 97.3893, 97.3893, 97.3893,  0.1000,\n",
      "          0.1000, 97.3893, 97.3893,  0.1000, 97.3893,  0.1000, 97.3893, 97.4593,\n",
      "         97.4593, 97.4593,  0.1000,  0.1000, 97.4593, 97.4593,  0.1000, 97.4593,\n",
      "          0.1000, 97.4593, 97.4425, 97.4593, 97.4593, 97.4593, 97.3893, 97.4593,\n",
      "         97.4593, 97.4593, 97.4425, 97.4593, 97.4593, 97.4593, 97.4425, 97.3893,\n",
      "         97.4425, 97.4425, 97.4425,  0.1000, 97.4425, 97.3893,  0.1000, 97.3893,\n",
      "         97.4593,  0.1000, 97.4593, 97.4593, 97.4593, 97.4425, 97.4425,  0.1000,\n",
      "         97.4593,  0.1000, 97.3491, 97.3491, 97.4425, 97.4593, 97.4593,  0.1000,\n",
      "          0.1000, 97.3491, 97.4425, 97.4593,  0.1000, 97.4425, 97.4593,  0.1000,\n",
      "         97.3491, 97.4593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 845 was 99.2%\n",
      "current params: tensor([97.3491, 97.4425, 97.3893, 97.4593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.6\n",
      "SLow rates:  tensor([[97.4491, 97.5425, 97.4893, 97.5593,  0.1000,  0.1000,  0.1000, 97.4491,\n",
      "         97.4491, 97.4491,  0.1000,  0.1000, 97.5425, 97.5425, 97.5425,  0.1000,\n",
      "          0.1000, 97.5425, 97.5425,  0.1000, 97.4893, 97.4893, 97.4893,  0.1000,\n",
      "          0.1000, 97.4893, 97.4893,  0.1000, 97.4893,  0.1000, 97.4893, 97.5593,\n",
      "         97.5593, 97.5593,  0.1000,  0.1000, 97.5593, 97.5593,  0.1000, 97.5593,\n",
      "          0.1000, 97.5593, 97.5425, 97.5593, 97.5593, 97.5593, 97.4893, 97.5593,\n",
      "         97.5593, 97.5593, 97.5425, 97.5593, 97.5593, 97.5593, 97.5425, 97.4893,\n",
      "         97.5425, 97.5425, 97.5425,  0.1000, 97.5425, 97.4893,  0.1000, 97.4893,\n",
      "         97.5593,  0.1000, 97.5593, 97.5593, 97.5593, 97.5425, 97.5425,  0.1000,\n",
      "         97.5593,  0.1000, 97.4491, 97.4491, 97.5425, 97.5593, 97.5593,  0.1000,\n",
      "          0.1000, 97.4491, 97.5425, 97.5593,  0.1000, 97.5425, 97.5593,  0.1000,\n",
      "         97.4491, 97.5593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 846 was 99.2%\n",
      "current params: tensor([97.4491, 97.5425, 97.4893, 97.5593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.6\n",
      "SLow rates:  tensor([[97.5492, 97.6425, 97.5893, 97.6593,  0.1000,  0.1000,  0.1000, 97.5492,\n",
      "         97.5492, 97.5492,  0.1000,  0.1000, 97.6425, 97.6425, 97.6425,  0.1000,\n",
      "          0.1000, 97.6425, 97.6425,  0.1000, 97.5893, 97.5893, 97.5893,  0.1000,\n",
      "          0.1000, 97.5893, 97.5893,  0.1000, 97.5893,  0.1000, 97.5893, 97.6593,\n",
      "         97.6593, 97.6593,  0.1000,  0.1000, 97.6593, 97.6593,  0.1000, 97.6593,\n",
      "          0.1000, 97.6593, 97.6425, 97.6593, 97.6593, 97.6593, 97.5893, 97.6593,\n",
      "         97.6593, 97.6593, 97.6425, 97.6593, 97.6593, 97.6593, 97.6425, 97.5893,\n",
      "         97.6425, 97.6425, 97.6425,  0.1000, 97.6425, 97.5893,  0.1000, 97.5893,\n",
      "         97.6593,  0.1000, 97.6593, 97.6593, 97.6593, 97.6425, 97.6425,  0.1000,\n",
      "         97.6593,  0.1000, 97.5492, 97.5492, 97.6425, 97.6593, 97.6593,  0.1000,\n",
      "          0.1000, 97.5492, 97.6425, 97.6593,  0.1000, 97.6425, 97.6593,  0.1000,\n",
      "         97.5492, 97.6593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 847 was 99.2%\n",
      "current params: tensor([97.5492, 97.6425, 97.5893, 97.6593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.6\n",
      "SLow rates:  tensor([[97.6492, 97.7425, 97.6893, 97.7593,  0.1000,  0.1000,  0.1000, 97.6492,\n",
      "         97.6492, 97.6492,  0.1000,  0.1000, 97.7425, 97.7425, 97.7425,  0.1000,\n",
      "          0.1000, 97.7425, 97.7425,  0.1000, 97.6893, 97.6893, 97.6893,  0.1000,\n",
      "          0.1000, 97.6893, 97.6893,  0.1000, 97.6893,  0.1000, 97.6893, 97.7593,\n",
      "         97.7593, 97.7593,  0.1000,  0.1000, 97.7593, 97.7593,  0.1000, 97.7593,\n",
      "          0.1000, 97.7593, 97.7425, 97.7593, 97.7593, 97.7593, 97.6893, 97.7593,\n",
      "         97.7593, 97.7593, 97.7425, 97.7593, 97.7593, 97.7593, 97.7425, 97.6893,\n",
      "         97.7425, 97.7425, 97.7425,  0.1000, 97.7425, 97.6893,  0.1000, 97.6893,\n",
      "         97.7593,  0.1000, 97.7593, 97.7593, 97.7593, 97.7425, 97.7425,  0.1000,\n",
      "         97.7593,  0.1000, 97.6492, 97.6492, 97.7425, 97.7593, 97.7593,  0.1000,\n",
      "          0.1000, 97.6492, 97.7425, 97.7593,  0.1000, 97.7425, 97.7593,  0.1000,\n",
      "         97.6492, 97.7593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 848 was 99.2%\n",
      "current params: tensor([97.6492, 97.7425, 97.6893, 97.7593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.6\n",
      "SLow rates:  tensor([[97.7492, 97.8425, 97.7893, 97.8593,  0.1000,  0.1000,  0.1000, 97.7492,\n",
      "         97.7492, 97.7492,  0.1000,  0.1000, 97.8425, 97.8425, 97.8425,  0.1000,\n",
      "          0.1000, 97.8425, 97.8425,  0.1000, 97.7893, 97.7893, 97.7893,  0.1000,\n",
      "          0.1000, 97.7893, 97.7893,  0.1000, 97.7893,  0.1000, 97.7893, 97.8593,\n",
      "         97.8593, 97.8593,  0.1000,  0.1000, 97.8593, 97.8593,  0.1000, 97.8593,\n",
      "          0.1000, 97.8593, 97.8425, 97.8593, 97.8593, 97.8593, 97.7893, 97.8593,\n",
      "         97.8593, 97.8593, 97.8425, 97.8593, 97.8593, 97.8593, 97.8425, 97.7893,\n",
      "         97.8425, 97.8425, 97.8425,  0.1000, 97.8425, 97.7893,  0.1000, 97.7893,\n",
      "         97.8593,  0.1000, 97.8593, 97.8593, 97.8593, 97.8425, 97.8425,  0.1000,\n",
      "         97.8593,  0.1000, 97.7492, 97.7492, 97.8425, 97.8593, 97.8593,  0.1000,\n",
      "          0.1000, 97.7492, 97.8425, 97.8593,  0.1000, 97.8425, 97.8593,  0.1000,\n",
      "         97.7492, 97.8593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 849 was 99.2%\n",
      "current params: tensor([97.7492, 97.8425, 97.7893, 97.8593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.6\n",
      "SLow rates:  tensor([[97.8492, 97.9425, 97.8893, 97.9593,  0.1000,  0.1000,  0.1000, 97.8492,\n",
      "         97.8492, 97.8492,  0.1000,  0.1000, 97.9425, 97.9425, 97.9425,  0.1000,\n",
      "          0.1000, 97.9425, 97.9425,  0.1000, 97.8893, 97.8893, 97.8893,  0.1000,\n",
      "          0.1000, 97.8893, 97.8893,  0.1000, 97.8893,  0.1000, 97.8893, 97.9593,\n",
      "         97.9593, 97.9593,  0.1000,  0.1000, 97.9593, 97.9593,  0.1000, 97.9593,\n",
      "          0.1000, 97.9593, 97.9425, 97.9593, 97.9593, 97.9593, 97.8893, 97.9593,\n",
      "         97.9593, 97.9593, 97.9425, 97.9593, 97.9593, 97.9593, 97.9425, 97.8893,\n",
      "         97.9425, 97.9425, 97.9425,  0.1000, 97.9425, 97.8893,  0.1000, 97.8893,\n",
      "         97.9593,  0.1000, 97.9593, 97.9593, 97.9593, 97.9425, 97.9425,  0.1000,\n",
      "         97.9593,  0.1000, 97.8492, 97.8492, 97.9425, 97.9593, 97.9593,  0.1000,\n",
      "          0.1000, 97.8492, 97.9425, 97.9593,  0.1000, 97.9425, 97.9593,  0.1000,\n",
      "         97.8492, 97.9593]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 850 was 99.2%\n",
      "current params: tensor([97.8492, 97.9425, 97.8893, 97.9593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.7\n",
      "SLow rates:  tensor([[97.9492, 98.0425, 97.9894, 98.0594,  0.1000,  0.1000,  0.1000, 97.9492,\n",
      "         97.9492, 97.9492,  0.1000,  0.1000, 98.0425, 98.0425, 98.0425,  0.1000,\n",
      "          0.1000, 98.0425, 98.0425,  0.1000, 97.9894, 97.9894, 97.9894,  0.1000,\n",
      "          0.1000, 97.9894, 97.9894,  0.1000, 97.9894,  0.1000, 97.9894, 98.0594,\n",
      "         98.0594, 98.0594,  0.1000,  0.1000, 98.0594, 98.0594,  0.1000, 98.0594,\n",
      "          0.1000, 98.0594, 98.0425, 98.0594, 98.0594, 98.0594, 97.9894, 98.0594,\n",
      "         98.0594, 98.0594, 98.0425, 98.0594, 98.0594, 98.0594, 98.0425, 97.9894,\n",
      "         98.0425, 98.0425, 98.0425,  0.1000, 98.0425, 97.9894,  0.1000, 97.9894,\n",
      "         98.0594,  0.1000, 98.0594, 98.0594, 98.0594, 98.0425, 98.0425,  0.1000,\n",
      "         98.0594,  0.1000, 97.9492, 97.9492, 98.0425, 98.0594, 98.0594,  0.1000,\n",
      "          0.1000, 97.9492, 98.0425, 98.0594,  0.1000, 98.0425, 98.0594,  0.1000,\n",
      "         97.9492, 98.0594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 851 was 99.2%\n",
      "current params: tensor([97.9492, 98.0425, 97.9894, 98.0594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.7\n",
      "SLow rates:  tensor([[98.0492, 98.1425, 98.0894, 98.1594,  0.1000,  0.1000,  0.1000, 98.0492,\n",
      "         98.0492, 98.0492,  0.1000,  0.1000, 98.1425, 98.1425, 98.1425,  0.1000,\n",
      "          0.1000, 98.1425, 98.1425,  0.1000, 98.0894, 98.0894, 98.0894,  0.1000,\n",
      "          0.1000, 98.0894, 98.0894,  0.1000, 98.0894,  0.1000, 98.0894, 98.1594,\n",
      "         98.1594, 98.1594,  0.1000,  0.1000, 98.1594, 98.1594,  0.1000, 98.1594,\n",
      "          0.1000, 98.1594, 98.1425, 98.1594, 98.1594, 98.1594, 98.0894, 98.1594,\n",
      "         98.1594, 98.1594, 98.1425, 98.1594, 98.1594, 98.1594, 98.1425, 98.0894,\n",
      "         98.1425, 98.1425, 98.1425,  0.1000, 98.1425, 98.0894,  0.1000, 98.0894,\n",
      "         98.1594,  0.1000, 98.1594, 98.1594, 98.1594, 98.1425, 98.1425,  0.1000,\n",
      "         98.1594,  0.1000, 98.0492, 98.0492, 98.1425, 98.1594, 98.1594,  0.1000,\n",
      "          0.1000, 98.0492, 98.1425, 98.1594,  0.1000, 98.1425, 98.1594,  0.1000,\n",
      "         98.0492, 98.1594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 852 was 99.2%\n",
      "current params: tensor([98.0492, 98.1425, 98.0894, 98.1594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.7\n",
      "SLow rates:  tensor([[98.1492, 98.2425, 98.1894, 98.2594,  0.1000,  0.1000,  0.1000, 98.1492,\n",
      "         98.1492, 98.1492,  0.1000,  0.1000, 98.2425, 98.2425, 98.2425,  0.1000,\n",
      "          0.1000, 98.2425, 98.2425,  0.1000, 98.1894, 98.1894, 98.1894,  0.1000,\n",
      "          0.1000, 98.1894, 98.1894,  0.1000, 98.1894,  0.1000, 98.1894, 98.2594,\n",
      "         98.2594, 98.2594,  0.1000,  0.1000, 98.2594, 98.2594,  0.1000, 98.2594,\n",
      "          0.1000, 98.2594, 98.2425, 98.2594, 98.2594, 98.2594, 98.1894, 98.2594,\n",
      "         98.2594, 98.2594, 98.2425, 98.2594, 98.2594, 98.2594, 98.2425, 98.1894,\n",
      "         98.2425, 98.2425, 98.2425,  0.1000, 98.2425, 98.1894,  0.1000, 98.1894,\n",
      "         98.2594,  0.1000, 98.2594, 98.2594, 98.2594, 98.2425, 98.2425,  0.1000,\n",
      "         98.2594,  0.1000, 98.1492, 98.1492, 98.2425, 98.2594, 98.2594,  0.1000,\n",
      "          0.1000, 98.1492, 98.2425, 98.2594,  0.1000, 98.2425, 98.2594,  0.1000,\n",
      "         98.1492, 98.2594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 853 was 99.2%\n",
      "current params: tensor([98.1492, 98.2425, 98.1894, 98.2594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.7\n",
      "SLow rates:  tensor([[98.2492, 98.3426, 98.2894, 98.3594,  0.1000,  0.1000,  0.1000, 98.2492,\n",
      "         98.2492, 98.2492,  0.1000,  0.1000, 98.3426, 98.3426, 98.3426,  0.1000,\n",
      "          0.1000, 98.3426, 98.3426,  0.1000, 98.2894, 98.2894, 98.2894,  0.1000,\n",
      "          0.1000, 98.2894, 98.2894,  0.1000, 98.2894,  0.1000, 98.2894, 98.3594,\n",
      "         98.3594, 98.3594,  0.1000,  0.1000, 98.3594, 98.3594,  0.1000, 98.3594,\n",
      "          0.1000, 98.3594, 98.3426, 98.3594, 98.3594, 98.3594, 98.2894, 98.3594,\n",
      "         98.3594, 98.3594, 98.3426, 98.3594, 98.3594, 98.3594, 98.3426, 98.2894,\n",
      "         98.3426, 98.3426, 98.3426,  0.1000, 98.3426, 98.2894,  0.1000, 98.2894,\n",
      "         98.3594,  0.1000, 98.3594, 98.3594, 98.3594, 98.3426, 98.3426,  0.1000,\n",
      "         98.3594,  0.1000, 98.2492, 98.2492, 98.3426, 98.3594, 98.3594,  0.1000,\n",
      "          0.1000, 98.2492, 98.3426, 98.3594,  0.1000, 98.3426, 98.3594,  0.1000,\n",
      "         98.2492, 98.3594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 854 was 99.2%\n",
      "current params: tensor([98.2492, 98.3426, 98.2894, 98.3594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.7\n",
      "SLow rates:  tensor([[98.3492, 98.4426, 98.3894, 98.4594,  0.1000,  0.1000,  0.1000, 98.3492,\n",
      "         98.3492, 98.3492,  0.1000,  0.1000, 98.4426, 98.4426, 98.4426,  0.1000,\n",
      "          0.1000, 98.4426, 98.4426,  0.1000, 98.3894, 98.3894, 98.3894,  0.1000,\n",
      "          0.1000, 98.3894, 98.3894,  0.1000, 98.3894,  0.1000, 98.3894, 98.4594,\n",
      "         98.4594, 98.4594,  0.1000,  0.1000, 98.4594, 98.4594,  0.1000, 98.4594,\n",
      "          0.1000, 98.4594, 98.4426, 98.4594, 98.4594, 98.4594, 98.3894, 98.4594,\n",
      "         98.4594, 98.4594, 98.4426, 98.4594, 98.4594, 98.4594, 98.4426, 98.3894,\n",
      "         98.4426, 98.4426, 98.4426,  0.1000, 98.4426, 98.3894,  0.1000, 98.3894,\n",
      "         98.4594,  0.1000, 98.4594, 98.4594, 98.4594, 98.4426, 98.4426,  0.1000,\n",
      "         98.4594,  0.1000, 98.3492, 98.3492, 98.4426, 98.4594, 98.4594,  0.1000,\n",
      "          0.1000, 98.3492, 98.4426, 98.4594,  0.1000, 98.4426, 98.4594,  0.1000,\n",
      "         98.3492, 98.4594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 855 was 99.2%\n",
      "current params: tensor([98.3492, 98.4426, 98.3894, 98.4594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.7\n",
      "SLow rates:  tensor([[98.4492, 98.5426, 98.4894, 98.5594,  0.1000,  0.1000,  0.1000, 98.4492,\n",
      "         98.4492, 98.4492,  0.1000,  0.1000, 98.5426, 98.5426, 98.5426,  0.1000,\n",
      "          0.1000, 98.5426, 98.5426,  0.1000, 98.4894, 98.4894, 98.4894,  0.1000,\n",
      "          0.1000, 98.4894, 98.4894,  0.1000, 98.4894,  0.1000, 98.4894, 98.5594,\n",
      "         98.5594, 98.5594,  0.1000,  0.1000, 98.5594, 98.5594,  0.1000, 98.5594,\n",
      "          0.1000, 98.5594, 98.5426, 98.5594, 98.5594, 98.5594, 98.4894, 98.5594,\n",
      "         98.5594, 98.5594, 98.5426, 98.5594, 98.5594, 98.5594, 98.5426, 98.4894,\n",
      "         98.5426, 98.5426, 98.5426,  0.1000, 98.5426, 98.4894,  0.1000, 98.4894,\n",
      "         98.5594,  0.1000, 98.5594, 98.5594, 98.5594, 98.5426, 98.5426,  0.1000,\n",
      "         98.5594,  0.1000, 98.4492, 98.4492, 98.5426, 98.5594, 98.5594,  0.1000,\n",
      "          0.1000, 98.4492, 98.5426, 98.5594,  0.1000, 98.5426, 98.5594,  0.1000,\n",
      "         98.4492, 98.5594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 856 was 99.2%\n",
      "current params: tensor([98.4492, 98.5426, 98.4894, 98.5594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.8\n",
      "SLow rates:  tensor([[98.5492, 98.6426, 98.5894, 98.6594,  0.1000,  0.1000,  0.1000, 98.5492,\n",
      "         98.5492, 98.5492,  0.1000,  0.1000, 98.6426, 98.6426, 98.6426,  0.1000,\n",
      "          0.1000, 98.6426, 98.6426,  0.1000, 98.5894, 98.5894, 98.5894,  0.1000,\n",
      "          0.1000, 98.5894, 98.5894,  0.1000, 98.5894,  0.1000, 98.5894, 98.6594,\n",
      "         98.6594, 98.6594,  0.1000,  0.1000, 98.6594, 98.6594,  0.1000, 98.6594,\n",
      "          0.1000, 98.6594, 98.6426, 98.6594, 98.6594, 98.6594, 98.5894, 98.6594,\n",
      "         98.6594, 98.6594, 98.6426, 98.6594, 98.6594, 98.6594, 98.6426, 98.5894,\n",
      "         98.6426, 98.6426, 98.6426,  0.1000, 98.6426, 98.5894,  0.1000, 98.5894,\n",
      "         98.6594,  0.1000, 98.6594, 98.6594, 98.6594, 98.6426, 98.6426,  0.1000,\n",
      "         98.6594,  0.1000, 98.5492, 98.5492, 98.6426, 98.6594, 98.6594,  0.1000,\n",
      "          0.1000, 98.5492, 98.6426, 98.6594,  0.1000, 98.6426, 98.6594,  0.1000,\n",
      "         98.5492, 98.6594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 857 was 99.2%\n",
      "current params: tensor([98.5492, 98.6426, 98.5894, 98.6594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.8\n",
      "SLow rates:  tensor([[98.6492, 98.7426, 98.6894, 98.7594,  0.1000,  0.1000,  0.1000, 98.6492,\n",
      "         98.6492, 98.6492,  0.1000,  0.1000, 98.7426, 98.7426, 98.7426,  0.1000,\n",
      "          0.1000, 98.7426, 98.7426,  0.1000, 98.6894, 98.6894, 98.6894,  0.1000,\n",
      "          0.1000, 98.6894, 98.6894,  0.1000, 98.6894,  0.1000, 98.6894, 98.7594,\n",
      "         98.7594, 98.7594,  0.1000,  0.1000, 98.7594, 98.7594,  0.1000, 98.7594,\n",
      "          0.1000, 98.7594, 98.7426, 98.7594, 98.7594, 98.7594, 98.6894, 98.7594,\n",
      "         98.7594, 98.7594, 98.7426, 98.7594, 98.7594, 98.7594, 98.7426, 98.6894,\n",
      "         98.7426, 98.7426, 98.7426,  0.1000, 98.7426, 98.6894,  0.1000, 98.6894,\n",
      "         98.7594,  0.1000, 98.7594, 98.7594, 98.7594, 98.7426, 98.7426,  0.1000,\n",
      "         98.7594,  0.1000, 98.6492, 98.6492, 98.7426, 98.7594, 98.7594,  0.1000,\n",
      "          0.1000, 98.6492, 98.7426, 98.7594,  0.1000, 98.7426, 98.7594,  0.1000,\n",
      "         98.6492, 98.7594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 858 was 99.2%\n",
      "current params: tensor([98.6492, 98.7426, 98.6894, 98.7594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.8\n",
      "SLow rates:  tensor([[98.7492, 98.8426, 98.7894, 98.8594,  0.1000,  0.1000,  0.1000, 98.7492,\n",
      "         98.7492, 98.7492,  0.1000,  0.1000, 98.8426, 98.8426, 98.8426,  0.1000,\n",
      "          0.1000, 98.8426, 98.8426,  0.1000, 98.7894, 98.7894, 98.7894,  0.1000,\n",
      "          0.1000, 98.7894, 98.7894,  0.1000, 98.7894,  0.1000, 98.7894, 98.8594,\n",
      "         98.8594, 98.8594,  0.1000,  0.1000, 98.8594, 98.8594,  0.1000, 98.8594,\n",
      "          0.1000, 98.8594, 98.8426, 98.8594, 98.8594, 98.8594, 98.7894, 98.8594,\n",
      "         98.8594, 98.8594, 98.8426, 98.8594, 98.8594, 98.8594, 98.8426, 98.7894,\n",
      "         98.8426, 98.8426, 98.8426,  0.1000, 98.8426, 98.7894,  0.1000, 98.7894,\n",
      "         98.8594,  0.1000, 98.8594, 98.8594, 98.8594, 98.8426, 98.8426,  0.1000,\n",
      "         98.8594,  0.1000, 98.7492, 98.7492, 98.8426, 98.8594, 98.8594,  0.1000,\n",
      "          0.1000, 98.7492, 98.8426, 98.8594,  0.1000, 98.8426, 98.8594,  0.1000,\n",
      "         98.7492, 98.8594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 859 was 99.2%\n",
      "current params: tensor([98.7492, 98.8426, 98.7894, 98.8594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.8\n",
      "SLow rates:  tensor([[98.8493, 98.9426, 98.8894, 98.9594,  0.1000,  0.1000,  0.1000, 98.8493,\n",
      "         98.8493, 98.8493,  0.1000,  0.1000, 98.9426, 98.9426, 98.9426,  0.1000,\n",
      "          0.1000, 98.9426, 98.9426,  0.1000, 98.8894, 98.8894, 98.8894,  0.1000,\n",
      "          0.1000, 98.8894, 98.8894,  0.1000, 98.8894,  0.1000, 98.8894, 98.9594,\n",
      "         98.9594, 98.9594,  0.1000,  0.1000, 98.9594, 98.9594,  0.1000, 98.9594,\n",
      "          0.1000, 98.9594, 98.9426, 98.9594, 98.9594, 98.9594, 98.8894, 98.9594,\n",
      "         98.9594, 98.9594, 98.9426, 98.9594, 98.9594, 98.9594, 98.9426, 98.8894,\n",
      "         98.9426, 98.9426, 98.9426,  0.1000, 98.9426, 98.8894,  0.1000, 98.8894,\n",
      "         98.9594,  0.1000, 98.9594, 98.9594, 98.9594, 98.9426, 98.9426,  0.1000,\n",
      "         98.9594,  0.1000, 98.8493, 98.8493, 98.9426, 98.9594, 98.9594,  0.1000,\n",
      "          0.1000, 98.8493, 98.9426, 98.9594,  0.1000, 98.9426, 98.9594,  0.1000,\n",
      "         98.8493, 98.9594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 860 was 99.2%\n",
      "current params: tensor([98.8493, 98.9426, 98.8894, 98.9594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.8\n",
      "SLow rates:  tensor([[98.9493, 99.0426, 98.9894, 99.0594,  0.1000,  0.1000,  0.1000, 98.9493,\n",
      "         98.9493, 98.9493,  0.1000,  0.1000, 99.0426, 99.0426, 99.0426,  0.1000,\n",
      "          0.1000, 99.0426, 99.0426,  0.1000, 98.9894, 98.9894, 98.9894,  0.1000,\n",
      "          0.1000, 98.9894, 98.9894,  0.1000, 98.9894,  0.1000, 98.9894, 99.0594,\n",
      "         99.0594, 99.0594,  0.1000,  0.1000, 99.0594, 99.0594,  0.1000, 99.0594,\n",
      "          0.1000, 99.0594, 99.0426, 99.0594, 99.0594, 99.0594, 98.9894, 99.0594,\n",
      "         99.0594, 99.0594, 99.0426, 99.0594, 99.0594, 99.0594, 99.0426, 98.9894,\n",
      "         99.0426, 99.0426, 99.0426,  0.1000, 99.0426, 98.9894,  0.1000, 98.9894,\n",
      "         99.0594,  0.1000, 99.0594, 99.0594, 99.0594, 99.0426, 99.0426,  0.1000,\n",
      "         99.0594,  0.1000, 98.9493, 98.9493, 99.0426, 99.0594, 99.0594,  0.1000,\n",
      "          0.1000, 98.9493, 99.0426, 99.0594,  0.1000, 99.0426, 99.0594,  0.1000,\n",
      "         98.9493, 99.0594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 861 was 99.2%\n",
      "current params: tensor([98.9493, 99.0426, 98.9894, 99.0594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.9\n",
      "SLow rates:  tensor([[99.0493, 99.1426, 99.0894, 99.1594,  0.1000,  0.1000,  0.1000, 99.0493,\n",
      "         99.0493, 99.0493,  0.1000,  0.1000, 99.1426, 99.1426, 99.1426,  0.1000,\n",
      "          0.1000, 99.1426, 99.1426,  0.1000, 99.0894, 99.0894, 99.0894,  0.1000,\n",
      "          0.1000, 99.0894, 99.0894,  0.1000, 99.0894,  0.1000, 99.0894, 99.1594,\n",
      "         99.1594, 99.1594,  0.1000,  0.1000, 99.1594, 99.1594,  0.1000, 99.1594,\n",
      "          0.1000, 99.1594, 99.1426, 99.1594, 99.1594, 99.1594, 99.0894, 99.1594,\n",
      "         99.1594, 99.1594, 99.1426, 99.1594, 99.1594, 99.1594, 99.1426, 99.0894,\n",
      "         99.1426, 99.1426, 99.1426,  0.1000, 99.1426, 99.0894,  0.1000, 99.0894,\n",
      "         99.1594,  0.1000, 99.1594, 99.1594, 99.1594, 99.1426, 99.1426,  0.1000,\n",
      "         99.1594,  0.1000, 99.0493, 99.0493, 99.1426, 99.1594, 99.1594,  0.1000,\n",
      "          0.1000, 99.0493, 99.1426, 99.1594,  0.1000, 99.1426, 99.1594,  0.1000,\n",
      "         99.0493, 99.1594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 862 was 99.2%\n",
      "current params: tensor([99.0493, 99.1426, 99.0894, 99.1594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.9\n",
      "SLow rates:  tensor([[99.1493, 99.2426, 99.1894, 99.2594,  0.1000,  0.1000,  0.1000, 99.1493,\n",
      "         99.1493, 99.1493,  0.1000,  0.1000, 99.2426, 99.2426, 99.2426,  0.1000,\n",
      "          0.1000, 99.2426, 99.2426,  0.1000, 99.1894, 99.1894, 99.1894,  0.1000,\n",
      "          0.1000, 99.1894, 99.1894,  0.1000, 99.1894,  0.1000, 99.1894, 99.2594,\n",
      "         99.2594, 99.2594,  0.1000,  0.1000, 99.2594, 99.2594,  0.1000, 99.2594,\n",
      "          0.1000, 99.2594, 99.2426, 99.2594, 99.2594, 99.2594, 99.1894, 99.2594,\n",
      "         99.2594, 99.2594, 99.2426, 99.2594, 99.2594, 99.2594, 99.2426, 99.1894,\n",
      "         99.2426, 99.2426, 99.2426,  0.1000, 99.2426, 99.1894,  0.1000, 99.1894,\n",
      "         99.2594,  0.1000, 99.2594, 99.2594, 99.2594, 99.2426, 99.2426,  0.1000,\n",
      "         99.2594,  0.1000, 99.1493, 99.1493, 99.2426, 99.2594, 99.2594,  0.1000,\n",
      "          0.1000, 99.1493, 99.2426, 99.2594,  0.1000, 99.2426, 99.2594,  0.1000,\n",
      "         99.1493, 99.2594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 863 was 99.2%\n",
      "current params: tensor([99.1493, 99.2426, 99.1894, 99.2594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.9\n",
      "SLow rates:  tensor([[99.2493, 99.3426, 99.2894, 99.3594,  0.1000,  0.1000,  0.1000, 99.2493,\n",
      "         99.2493, 99.2493,  0.1000,  0.1000, 99.3426, 99.3426, 99.3426,  0.1000,\n",
      "          0.1000, 99.3426, 99.3426,  0.1000, 99.2894, 99.2894, 99.2894,  0.1000,\n",
      "          0.1000, 99.2894, 99.2894,  0.1000, 99.2894,  0.1000, 99.2894, 99.3594,\n",
      "         99.3594, 99.3594,  0.1000,  0.1000, 99.3594, 99.3594,  0.1000, 99.3594,\n",
      "          0.1000, 99.3594, 99.3426, 99.3594, 99.3594, 99.3594, 99.2894, 99.3594,\n",
      "         99.3594, 99.3594, 99.3426, 99.3594, 99.3594, 99.3594, 99.3426, 99.2894,\n",
      "         99.3426, 99.3426, 99.3426,  0.1000, 99.3426, 99.2894,  0.1000, 99.2894,\n",
      "         99.3594,  0.1000, 99.3594, 99.3594, 99.3594, 99.3426, 99.3426,  0.1000,\n",
      "         99.3594,  0.1000, 99.2493, 99.2493, 99.3426, 99.3594, 99.3594,  0.1000,\n",
      "          0.1000, 99.2493, 99.3426, 99.3594,  0.1000, 99.3426, 99.3594,  0.1000,\n",
      "         99.2493, 99.3594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 864 was 99.2%\n",
      "current params: tensor([99.2493, 99.3426, 99.2894, 99.3594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.9\n",
      "SLow rates:  tensor([[99.3493, 99.4426, 99.3894, 99.4594,  0.1000,  0.1000,  0.1000, 99.3493,\n",
      "         99.3493, 99.3493,  0.1000,  0.1000, 99.4426, 99.4426, 99.4426,  0.1000,\n",
      "          0.1000, 99.4426, 99.4426,  0.1000, 99.3894, 99.3894, 99.3894,  0.1000,\n",
      "          0.1000, 99.3894, 99.3894,  0.1000, 99.3894,  0.1000, 99.3894, 99.4594,\n",
      "         99.4594, 99.4594,  0.1000,  0.1000, 99.4594, 99.4594,  0.1000, 99.4594,\n",
      "          0.1000, 99.4594, 99.4426, 99.4594, 99.4594, 99.4594, 99.3894, 99.4594,\n",
      "         99.4594, 99.4594, 99.4426, 99.4594, 99.4594, 99.4594, 99.4426, 99.3894,\n",
      "         99.4426, 99.4426, 99.4426,  0.1000, 99.4426, 99.3894,  0.1000, 99.3894,\n",
      "         99.4594,  0.1000, 99.4594, 99.4594, 99.4594, 99.4426, 99.4426,  0.1000,\n",
      "         99.4594,  0.1000, 99.3493, 99.3493, 99.4426, 99.4594, 99.4594,  0.1000,\n",
      "          0.1000, 99.3493, 99.4426, 99.4594,  0.1000, 99.4426, 99.4594,  0.1000,\n",
      "         99.3493, 99.4594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 865 was 99.2%\n",
      "current params: tensor([99.3493, 99.4426, 99.3894, 99.4594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  21.9\n",
      "SLow rates:  tensor([[99.4493, 99.5426, 99.4895, 99.5594,  0.1000,  0.1000,  0.1000, 99.4493,\n",
      "         99.4493, 99.4493,  0.1000,  0.1000, 99.5426, 99.5426, 99.5426,  0.1000,\n",
      "          0.1000, 99.5426, 99.5426,  0.1000, 99.4895, 99.4895, 99.4895,  0.1000,\n",
      "          0.1000, 99.4895, 99.4895,  0.1000, 99.4895,  0.1000, 99.4895, 99.5594,\n",
      "         99.5594, 99.5594,  0.1000,  0.1000, 99.5594, 99.5594,  0.1000, 99.5594,\n",
      "          0.1000, 99.5594, 99.5426, 99.5594, 99.5594, 99.5594, 99.4895, 99.5594,\n",
      "         99.5594, 99.5594, 99.5426, 99.5594, 99.5594, 99.5594, 99.5426, 99.4895,\n",
      "         99.5426, 99.5426, 99.5426,  0.1000, 99.5426, 99.4895,  0.1000, 99.4895,\n",
      "         99.5594,  0.1000, 99.5594, 99.5594, 99.5594, 99.5426, 99.5426,  0.1000,\n",
      "         99.5594,  0.1000, 99.4493, 99.4493, 99.5426, 99.5594, 99.5594,  0.1000,\n",
      "          0.1000, 99.4493, 99.5426, 99.5594,  0.1000, 99.5426, 99.5594,  0.1000,\n",
      "         99.4493, 99.5594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 866 was 99.2%\n",
      "current params: tensor([99.4493, 99.5426, 99.4895, 99.5594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.0\n",
      "SLow rates:  tensor([[99.5493, 99.6426, 99.5895, 99.6594,  0.1000,  0.1000,  0.1000, 99.5493,\n",
      "         99.5493, 99.5493,  0.1000,  0.1000, 99.6426, 99.6426, 99.6426,  0.1000,\n",
      "          0.1000, 99.6426, 99.6426,  0.1000, 99.5895, 99.5895, 99.5895,  0.1000,\n",
      "          0.1000, 99.5895, 99.5895,  0.1000, 99.5895,  0.1000, 99.5895, 99.6594,\n",
      "         99.6594, 99.6594,  0.1000,  0.1000, 99.6594, 99.6594,  0.1000, 99.6594,\n",
      "          0.1000, 99.6594, 99.6426, 99.6594, 99.6594, 99.6594, 99.5895, 99.6594,\n",
      "         99.6594, 99.6594, 99.6426, 99.6594, 99.6594, 99.6594, 99.6426, 99.5895,\n",
      "         99.6426, 99.6426, 99.6426,  0.1000, 99.6426, 99.5895,  0.1000, 99.5895,\n",
      "         99.6594,  0.1000, 99.6594, 99.6594, 99.6594, 99.6426, 99.6426,  0.1000,\n",
      "         99.6594,  0.1000, 99.5493, 99.5493, 99.6426, 99.6594, 99.6594,  0.1000,\n",
      "          0.1000, 99.5493, 99.6426, 99.6594,  0.1000, 99.6426, 99.6594,  0.1000,\n",
      "         99.5493, 99.6594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 867 was 99.2%\n",
      "current params: tensor([99.5493, 99.6426, 99.5895, 99.6594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.0\n",
      "SLow rates:  tensor([[99.6493, 99.7426, 99.6895, 99.7594,  0.1000,  0.1000,  0.1000, 99.6493,\n",
      "         99.6493, 99.6493,  0.1000,  0.1000, 99.7426, 99.7426, 99.7426,  0.1000,\n",
      "          0.1000, 99.7426, 99.7426,  0.1000, 99.6895, 99.6895, 99.6895,  0.1000,\n",
      "          0.1000, 99.6895, 99.6895,  0.1000, 99.6895,  0.1000, 99.6895, 99.7594,\n",
      "         99.7594, 99.7594,  0.1000,  0.1000, 99.7594, 99.7594,  0.1000, 99.7594,\n",
      "          0.1000, 99.7594, 99.7426, 99.7594, 99.7594, 99.7594, 99.6895, 99.7594,\n",
      "         99.7594, 99.7594, 99.7426, 99.7594, 99.7594, 99.7594, 99.7426, 99.6895,\n",
      "         99.7426, 99.7426, 99.7426,  0.1000, 99.7426, 99.6895,  0.1000, 99.6895,\n",
      "         99.7594,  0.1000, 99.7594, 99.7594, 99.7594, 99.7426, 99.7426,  0.1000,\n",
      "         99.7594,  0.1000, 99.6493, 99.6493, 99.7426, 99.7594, 99.7594,  0.1000,\n",
      "          0.1000, 99.6493, 99.7426, 99.7594,  0.1000, 99.7426, 99.7594,  0.1000,\n",
      "         99.6493, 99.7594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 868 was 99.2%\n",
      "current params: tensor([99.6493, 99.7426, 99.6895, 99.7594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.0\n",
      "SLow rates:  tensor([[99.7493, 99.8426, 99.7895, 99.8594,  0.1000,  0.1000,  0.1000, 99.7493,\n",
      "         99.7493, 99.7493,  0.1000,  0.1000, 99.8426, 99.8426, 99.8426,  0.1000,\n",
      "          0.1000, 99.8426, 99.8426,  0.1000, 99.7895, 99.7895, 99.7895,  0.1000,\n",
      "          0.1000, 99.7895, 99.7895,  0.1000, 99.7895,  0.1000, 99.7895, 99.8594,\n",
      "         99.8594, 99.8594,  0.1000,  0.1000, 99.8594, 99.8594,  0.1000, 99.8594,\n",
      "          0.1000, 99.8594, 99.8426, 99.8594, 99.8594, 99.8594, 99.7895, 99.8594,\n",
      "         99.8594, 99.8594, 99.8426, 99.8594, 99.8594, 99.8594, 99.8426, 99.7895,\n",
      "         99.8426, 99.8426, 99.8426,  0.1000, 99.8426, 99.7895,  0.1000, 99.7895,\n",
      "         99.8594,  0.1000, 99.8594, 99.8594, 99.8594, 99.8426, 99.8426,  0.1000,\n",
      "         99.8594,  0.1000, 99.7493, 99.7493, 99.8426, 99.8594, 99.8594,  0.1000,\n",
      "          0.1000, 99.7493, 99.8426, 99.8594,  0.1000, 99.8426, 99.8594,  0.1000,\n",
      "         99.7493, 99.8594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 869 was 99.2%\n",
      "current params: tensor([99.7493, 99.8426, 99.7895, 99.8594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.0\n",
      "SLow rates:  tensor([[99.8493, 99.9426, 99.8895, 99.9594,  0.1000,  0.1000,  0.1000, 99.8493,\n",
      "         99.8493, 99.8493,  0.1000,  0.1000, 99.9426, 99.9426, 99.9426,  0.1000,\n",
      "          0.1000, 99.9426, 99.9426,  0.1000, 99.8895, 99.8895, 99.8895,  0.1000,\n",
      "          0.1000, 99.8895, 99.8895,  0.1000, 99.8895,  0.1000, 99.8895, 99.9594,\n",
      "         99.9594, 99.9594,  0.1000,  0.1000, 99.9594, 99.9594,  0.1000, 99.9594,\n",
      "          0.1000, 99.9594, 99.9426, 99.9594, 99.9594, 99.9594, 99.8895, 99.9594,\n",
      "         99.9594, 99.9594, 99.9426, 99.9594, 99.9594, 99.9594, 99.9426, 99.8895,\n",
      "         99.9426, 99.9426, 99.9426,  0.1000, 99.9426, 99.8895,  0.1000, 99.8895,\n",
      "         99.9594,  0.1000, 99.9594, 99.9594, 99.9594, 99.9426, 99.9426,  0.1000,\n",
      "         99.9594,  0.1000, 99.8493, 99.8493, 99.9426, 99.9594, 99.9594,  0.1000,\n",
      "          0.1000, 99.8493, 99.9426, 99.9594,  0.1000, 99.9426, 99.9594,  0.1000,\n",
      "         99.8493, 99.9594]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 870 was 99.2%\n",
      "current params: tensor([99.8493, 99.9426, 99.8895, 99.9594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.0\n",
      "SLow rates:  tensor([[9.9949e+01, 1.0004e+02, 9.9989e+01, 1.0006e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 9.9949e+01, 9.9949e+01, 9.9949e+01, 1.0000e-01, 1.0000e-01,\n",
      "         1.0004e+02, 1.0004e+02, 1.0004e+02, 1.0000e-01, 1.0000e-01, 1.0004e+02,\n",
      "         1.0004e+02, 1.0000e-01, 9.9989e+01, 9.9989e+01, 9.9989e+01, 1.0000e-01,\n",
      "         1.0000e-01, 9.9989e+01, 9.9989e+01, 1.0000e-01, 9.9989e+01, 1.0000e-01,\n",
      "         9.9989e+01, 1.0006e+02, 1.0006e+02, 1.0006e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0006e+02, 1.0006e+02, 1.0000e-01, 1.0006e+02, 1.0000e-01, 1.0006e+02,\n",
      "         1.0004e+02, 1.0006e+02, 1.0006e+02, 1.0006e+02, 9.9989e+01, 1.0006e+02,\n",
      "         1.0006e+02, 1.0006e+02, 1.0004e+02, 1.0006e+02, 1.0006e+02, 1.0006e+02,\n",
      "         1.0004e+02, 9.9989e+01, 1.0004e+02, 1.0004e+02, 1.0004e+02, 1.0000e-01,\n",
      "         1.0004e+02, 9.9989e+01, 1.0000e-01, 9.9989e+01, 1.0006e+02, 1.0000e-01,\n",
      "         1.0006e+02, 1.0006e+02, 1.0006e+02, 1.0004e+02, 1.0004e+02, 1.0000e-01,\n",
      "         1.0006e+02, 1.0000e-01, 9.9949e+01, 9.9949e+01, 1.0004e+02, 1.0006e+02,\n",
      "         1.0006e+02, 1.0000e-01, 1.0000e-01, 9.9949e+01, 1.0004e+02, 1.0006e+02,\n",
      "         1.0000e-01, 1.0004e+02, 1.0006e+02, 1.0000e-01, 9.9949e+01, 1.0006e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 871 was 99.2%\n",
      "current params: tensor([ 99.9493, 100.0426,  99.9895, 100.0594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.0\n",
      "SLow rates:  tensor([[1.0005e+02, 1.0014e+02, 1.0009e+02, 1.0016e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0005e+02, 1.0005e+02, 1.0005e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0014e+02, 1.0014e+02, 1.0014e+02, 1.0000e-01, 1.0000e-01, 1.0014e+02,\n",
      "         1.0014e+02, 1.0000e-01, 1.0009e+02, 1.0009e+02, 1.0009e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0009e+02, 1.0009e+02, 1.0000e-01, 1.0009e+02, 1.0000e-01,\n",
      "         1.0009e+02, 1.0016e+02, 1.0016e+02, 1.0016e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0016e+02, 1.0016e+02, 1.0000e-01, 1.0016e+02, 1.0000e-01, 1.0016e+02,\n",
      "         1.0014e+02, 1.0016e+02, 1.0016e+02, 1.0016e+02, 1.0009e+02, 1.0016e+02,\n",
      "         1.0016e+02, 1.0016e+02, 1.0014e+02, 1.0016e+02, 1.0016e+02, 1.0016e+02,\n",
      "         1.0014e+02, 1.0009e+02, 1.0014e+02, 1.0014e+02, 1.0014e+02, 1.0000e-01,\n",
      "         1.0014e+02, 1.0009e+02, 1.0000e-01, 1.0009e+02, 1.0016e+02, 1.0000e-01,\n",
      "         1.0016e+02, 1.0016e+02, 1.0016e+02, 1.0014e+02, 1.0014e+02, 1.0000e-01,\n",
      "         1.0016e+02, 1.0000e-01, 1.0005e+02, 1.0005e+02, 1.0014e+02, 1.0016e+02,\n",
      "         1.0016e+02, 1.0000e-01, 1.0000e-01, 1.0005e+02, 1.0014e+02, 1.0016e+02,\n",
      "         1.0000e-01, 1.0014e+02, 1.0016e+02, 1.0000e-01, 1.0005e+02, 1.0016e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 872 was 99.2%\n",
      "current params: tensor([100.0493, 100.1426, 100.0895, 100.1594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.1\n",
      "SLow rates:  tensor([[1.0015e+02, 1.0024e+02, 1.0019e+02, 1.0026e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0015e+02, 1.0015e+02, 1.0015e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0024e+02, 1.0024e+02, 1.0024e+02, 1.0000e-01, 1.0000e-01, 1.0024e+02,\n",
      "         1.0024e+02, 1.0000e-01, 1.0019e+02, 1.0019e+02, 1.0019e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0019e+02, 1.0019e+02, 1.0000e-01, 1.0019e+02, 1.0000e-01,\n",
      "         1.0019e+02, 1.0026e+02, 1.0026e+02, 1.0026e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0026e+02, 1.0026e+02, 1.0000e-01, 1.0026e+02, 1.0000e-01, 1.0026e+02,\n",
      "         1.0024e+02, 1.0026e+02, 1.0026e+02, 1.0026e+02, 1.0019e+02, 1.0026e+02,\n",
      "         1.0026e+02, 1.0026e+02, 1.0024e+02, 1.0026e+02, 1.0026e+02, 1.0026e+02,\n",
      "         1.0024e+02, 1.0019e+02, 1.0024e+02, 1.0024e+02, 1.0024e+02, 1.0000e-01,\n",
      "         1.0024e+02, 1.0019e+02, 1.0000e-01, 1.0019e+02, 1.0026e+02, 1.0000e-01,\n",
      "         1.0026e+02, 1.0026e+02, 1.0026e+02, 1.0024e+02, 1.0024e+02, 1.0000e-01,\n",
      "         1.0026e+02, 1.0000e-01, 1.0015e+02, 1.0015e+02, 1.0024e+02, 1.0026e+02,\n",
      "         1.0026e+02, 1.0000e-01, 1.0000e-01, 1.0015e+02, 1.0024e+02, 1.0026e+02,\n",
      "         1.0000e-01, 1.0024e+02, 1.0026e+02, 1.0000e-01, 1.0015e+02, 1.0026e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 873 was 99.2%\n",
      "current params: tensor([100.1493, 100.2426, 100.1895, 100.2594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.1\n",
      "SLow rates:  tensor([[1.0025e+02, 1.0034e+02, 1.0029e+02, 1.0036e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0025e+02, 1.0025e+02, 1.0025e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0034e+02, 1.0034e+02, 1.0034e+02, 1.0000e-01, 1.0000e-01, 1.0034e+02,\n",
      "         1.0034e+02, 1.0000e-01, 1.0029e+02, 1.0029e+02, 1.0029e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0029e+02, 1.0029e+02, 1.0000e-01, 1.0029e+02, 1.0000e-01,\n",
      "         1.0029e+02, 1.0036e+02, 1.0036e+02, 1.0036e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0036e+02, 1.0036e+02, 1.0000e-01, 1.0036e+02, 1.0000e-01, 1.0036e+02,\n",
      "         1.0034e+02, 1.0036e+02, 1.0036e+02, 1.0036e+02, 1.0029e+02, 1.0036e+02,\n",
      "         1.0036e+02, 1.0036e+02, 1.0034e+02, 1.0036e+02, 1.0036e+02, 1.0036e+02,\n",
      "         1.0034e+02, 1.0029e+02, 1.0034e+02, 1.0034e+02, 1.0034e+02, 1.0000e-01,\n",
      "         1.0034e+02, 1.0029e+02, 1.0000e-01, 1.0029e+02, 1.0036e+02, 1.0000e-01,\n",
      "         1.0036e+02, 1.0036e+02, 1.0036e+02, 1.0034e+02, 1.0034e+02, 1.0000e-01,\n",
      "         1.0036e+02, 1.0000e-01, 1.0025e+02, 1.0025e+02, 1.0034e+02, 1.0036e+02,\n",
      "         1.0036e+02, 1.0000e-01, 1.0000e-01, 1.0025e+02, 1.0034e+02, 1.0036e+02,\n",
      "         1.0000e-01, 1.0034e+02, 1.0036e+02, 1.0000e-01, 1.0025e+02, 1.0036e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 874 was 99.2%\n",
      "current params: tensor([100.2493, 100.3427, 100.2895, 100.3595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.1\n",
      "SLow rates:  tensor([[1.0035e+02, 1.0044e+02, 1.0039e+02, 1.0046e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0035e+02, 1.0035e+02, 1.0035e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0044e+02, 1.0044e+02, 1.0044e+02, 1.0000e-01, 1.0000e-01, 1.0044e+02,\n",
      "         1.0044e+02, 1.0000e-01, 1.0039e+02, 1.0039e+02, 1.0039e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0039e+02, 1.0039e+02, 1.0000e-01, 1.0039e+02, 1.0000e-01,\n",
      "         1.0039e+02, 1.0046e+02, 1.0046e+02, 1.0046e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0046e+02, 1.0046e+02, 1.0000e-01, 1.0046e+02, 1.0000e-01, 1.0046e+02,\n",
      "         1.0044e+02, 1.0046e+02, 1.0046e+02, 1.0046e+02, 1.0039e+02, 1.0046e+02,\n",
      "         1.0046e+02, 1.0046e+02, 1.0044e+02, 1.0046e+02, 1.0046e+02, 1.0046e+02,\n",
      "         1.0044e+02, 1.0039e+02, 1.0044e+02, 1.0044e+02, 1.0044e+02, 1.0000e-01,\n",
      "         1.0044e+02, 1.0039e+02, 1.0000e-01, 1.0039e+02, 1.0046e+02, 1.0000e-01,\n",
      "         1.0046e+02, 1.0046e+02, 1.0046e+02, 1.0044e+02, 1.0044e+02, 1.0000e-01,\n",
      "         1.0046e+02, 1.0000e-01, 1.0035e+02, 1.0035e+02, 1.0044e+02, 1.0046e+02,\n",
      "         1.0046e+02, 1.0000e-01, 1.0000e-01, 1.0035e+02, 1.0044e+02, 1.0046e+02,\n",
      "         1.0000e-01, 1.0044e+02, 1.0046e+02, 1.0000e-01, 1.0035e+02, 1.0046e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0520, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 875 was 99.2%\n",
      "current params: tensor([100.3493, 100.4427, 100.3895, 100.4595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.1\n",
      "SLow rates:  tensor([[1.0045e+02, 1.0054e+02, 1.0049e+02, 1.0056e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0045e+02, 1.0045e+02, 1.0045e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0054e+02, 1.0054e+02, 1.0054e+02, 1.0000e-01, 1.0000e-01, 1.0054e+02,\n",
      "         1.0054e+02, 1.0000e-01, 1.0049e+02, 1.0049e+02, 1.0049e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0049e+02, 1.0049e+02, 1.0000e-01, 1.0049e+02, 1.0000e-01,\n",
      "         1.0049e+02, 1.0056e+02, 1.0056e+02, 1.0056e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0056e+02, 1.0056e+02, 1.0000e-01, 1.0056e+02, 1.0000e-01, 1.0056e+02,\n",
      "         1.0054e+02, 1.0056e+02, 1.0056e+02, 1.0056e+02, 1.0049e+02, 1.0056e+02,\n",
      "         1.0056e+02, 1.0056e+02, 1.0054e+02, 1.0056e+02, 1.0056e+02, 1.0056e+02,\n",
      "         1.0054e+02, 1.0049e+02, 1.0054e+02, 1.0054e+02, 1.0054e+02, 1.0000e-01,\n",
      "         1.0054e+02, 1.0049e+02, 1.0000e-01, 1.0049e+02, 1.0056e+02, 1.0000e-01,\n",
      "         1.0056e+02, 1.0056e+02, 1.0056e+02, 1.0054e+02, 1.0054e+02, 1.0000e-01,\n",
      "         1.0056e+02, 1.0000e-01, 1.0045e+02, 1.0045e+02, 1.0054e+02, 1.0056e+02,\n",
      "         1.0056e+02, 1.0000e-01, 1.0000e-01, 1.0045e+02, 1.0054e+02, 1.0056e+02,\n",
      "         1.0000e-01, 1.0054e+02, 1.0056e+02, 1.0000e-01, 1.0045e+02, 1.0056e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 876 was 99.2%\n",
      "current params: tensor([100.4494, 100.5427, 100.4895, 100.5595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.1\n",
      "SLow rates:  tensor([[1.0055e+02, 1.0064e+02, 1.0059e+02, 1.0066e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0055e+02, 1.0055e+02, 1.0055e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0064e+02, 1.0064e+02, 1.0064e+02, 1.0000e-01, 1.0000e-01, 1.0064e+02,\n",
      "         1.0064e+02, 1.0000e-01, 1.0059e+02, 1.0059e+02, 1.0059e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0059e+02, 1.0059e+02, 1.0000e-01, 1.0059e+02, 1.0000e-01,\n",
      "         1.0059e+02, 1.0066e+02, 1.0066e+02, 1.0066e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0066e+02, 1.0066e+02, 1.0000e-01, 1.0066e+02, 1.0000e-01, 1.0066e+02,\n",
      "         1.0064e+02, 1.0066e+02, 1.0066e+02, 1.0066e+02, 1.0059e+02, 1.0066e+02,\n",
      "         1.0066e+02, 1.0066e+02, 1.0064e+02, 1.0066e+02, 1.0066e+02, 1.0066e+02,\n",
      "         1.0064e+02, 1.0059e+02, 1.0064e+02, 1.0064e+02, 1.0064e+02, 1.0000e-01,\n",
      "         1.0064e+02, 1.0059e+02, 1.0000e-01, 1.0059e+02, 1.0066e+02, 1.0000e-01,\n",
      "         1.0066e+02, 1.0066e+02, 1.0066e+02, 1.0064e+02, 1.0064e+02, 1.0000e-01,\n",
      "         1.0066e+02, 1.0000e-01, 1.0055e+02, 1.0055e+02, 1.0064e+02, 1.0066e+02,\n",
      "         1.0066e+02, 1.0000e-01, 1.0000e-01, 1.0055e+02, 1.0064e+02, 1.0066e+02,\n",
      "         1.0000e-01, 1.0064e+02, 1.0066e+02, 1.0000e-01, 1.0055e+02, 1.0066e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 877 was 99.2%\n",
      "current params: tensor([100.5494, 100.6427, 100.5895, 100.6595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.2\n",
      "SLow rates:  tensor([[1.0065e+02, 1.0074e+02, 1.0069e+02, 1.0076e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0065e+02, 1.0065e+02, 1.0065e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0074e+02, 1.0074e+02, 1.0074e+02, 1.0000e-01, 1.0000e-01, 1.0074e+02,\n",
      "         1.0074e+02, 1.0000e-01, 1.0069e+02, 1.0069e+02, 1.0069e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0069e+02, 1.0069e+02, 1.0000e-01, 1.0069e+02, 1.0000e-01,\n",
      "         1.0069e+02, 1.0076e+02, 1.0076e+02, 1.0076e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0076e+02, 1.0076e+02, 1.0000e-01, 1.0076e+02, 1.0000e-01, 1.0076e+02,\n",
      "         1.0074e+02, 1.0076e+02, 1.0076e+02, 1.0076e+02, 1.0069e+02, 1.0076e+02,\n",
      "         1.0076e+02, 1.0076e+02, 1.0074e+02, 1.0076e+02, 1.0076e+02, 1.0076e+02,\n",
      "         1.0074e+02, 1.0069e+02, 1.0074e+02, 1.0074e+02, 1.0074e+02, 1.0000e-01,\n",
      "         1.0074e+02, 1.0069e+02, 1.0000e-01, 1.0069e+02, 1.0076e+02, 1.0000e-01,\n",
      "         1.0076e+02, 1.0076e+02, 1.0076e+02, 1.0074e+02, 1.0074e+02, 1.0000e-01,\n",
      "         1.0076e+02, 1.0000e-01, 1.0065e+02, 1.0065e+02, 1.0074e+02, 1.0076e+02,\n",
      "         1.0076e+02, 1.0000e-01, 1.0000e-01, 1.0065e+02, 1.0074e+02, 1.0076e+02,\n",
      "         1.0000e-01, 1.0074e+02, 1.0076e+02, 1.0000e-01, 1.0065e+02, 1.0076e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 878 was 99.2%\n",
      "current params: tensor([100.6494, 100.7427, 100.6895, 100.7595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.2\n",
      "SLow rates:  tensor([[1.0075e+02, 1.0084e+02, 1.0079e+02, 1.0086e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0075e+02, 1.0075e+02, 1.0075e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0084e+02, 1.0084e+02, 1.0084e+02, 1.0000e-01, 1.0000e-01, 1.0084e+02,\n",
      "         1.0084e+02, 1.0000e-01, 1.0079e+02, 1.0079e+02, 1.0079e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0079e+02, 1.0079e+02, 1.0000e-01, 1.0079e+02, 1.0000e-01,\n",
      "         1.0079e+02, 1.0086e+02, 1.0086e+02, 1.0086e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0086e+02, 1.0086e+02, 1.0000e-01, 1.0086e+02, 1.0000e-01, 1.0086e+02,\n",
      "         1.0084e+02, 1.0086e+02, 1.0086e+02, 1.0086e+02, 1.0079e+02, 1.0086e+02,\n",
      "         1.0086e+02, 1.0086e+02, 1.0084e+02, 1.0086e+02, 1.0086e+02, 1.0086e+02,\n",
      "         1.0084e+02, 1.0079e+02, 1.0084e+02, 1.0084e+02, 1.0084e+02, 1.0000e-01,\n",
      "         1.0084e+02, 1.0079e+02, 1.0000e-01, 1.0079e+02, 1.0086e+02, 1.0000e-01,\n",
      "         1.0086e+02, 1.0086e+02, 1.0086e+02, 1.0084e+02, 1.0084e+02, 1.0000e-01,\n",
      "         1.0086e+02, 1.0000e-01, 1.0075e+02, 1.0075e+02, 1.0084e+02, 1.0086e+02,\n",
      "         1.0086e+02, 1.0000e-01, 1.0000e-01, 1.0075e+02, 1.0084e+02, 1.0086e+02,\n",
      "         1.0000e-01, 1.0084e+02, 1.0086e+02, 1.0000e-01, 1.0075e+02, 1.0086e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 879 was 99.2%\n",
      "current params: tensor([100.7494, 100.8427, 100.7895, 100.8595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.2\n",
      "SLow rates:  tensor([[1.0085e+02, 1.0094e+02, 1.0089e+02, 1.0096e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0085e+02, 1.0085e+02, 1.0085e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0094e+02, 1.0094e+02, 1.0094e+02, 1.0000e-01, 1.0000e-01, 1.0094e+02,\n",
      "         1.0094e+02, 1.0000e-01, 1.0089e+02, 1.0089e+02, 1.0089e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0089e+02, 1.0089e+02, 1.0000e-01, 1.0089e+02, 1.0000e-01,\n",
      "         1.0089e+02, 1.0096e+02, 1.0096e+02, 1.0096e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0096e+02, 1.0096e+02, 1.0000e-01, 1.0096e+02, 1.0000e-01, 1.0096e+02,\n",
      "         1.0094e+02, 1.0096e+02, 1.0096e+02, 1.0096e+02, 1.0089e+02, 1.0096e+02,\n",
      "         1.0096e+02, 1.0096e+02, 1.0094e+02, 1.0096e+02, 1.0096e+02, 1.0096e+02,\n",
      "         1.0094e+02, 1.0089e+02, 1.0094e+02, 1.0094e+02, 1.0094e+02, 1.0000e-01,\n",
      "         1.0094e+02, 1.0089e+02, 1.0000e-01, 1.0089e+02, 1.0096e+02, 1.0000e-01,\n",
      "         1.0096e+02, 1.0096e+02, 1.0096e+02, 1.0094e+02, 1.0094e+02, 1.0000e-01,\n",
      "         1.0096e+02, 1.0000e-01, 1.0085e+02, 1.0085e+02, 1.0094e+02, 1.0096e+02,\n",
      "         1.0096e+02, 1.0000e-01, 1.0000e-01, 1.0085e+02, 1.0094e+02, 1.0096e+02,\n",
      "         1.0000e-01, 1.0094e+02, 1.0096e+02, 1.0000e-01, 1.0085e+02, 1.0096e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 880 was 99.2%\n",
      "current params: tensor([100.8494, 100.9427, 100.8895, 100.9595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.2\n",
      "SLow rates:  tensor([[1.0095e+02, 1.0104e+02, 1.0099e+02, 1.0106e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0095e+02, 1.0095e+02, 1.0095e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0104e+02, 1.0104e+02, 1.0104e+02, 1.0000e-01, 1.0000e-01, 1.0104e+02,\n",
      "         1.0104e+02, 1.0000e-01, 1.0099e+02, 1.0099e+02, 1.0099e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0099e+02, 1.0099e+02, 1.0000e-01, 1.0099e+02, 1.0000e-01,\n",
      "         1.0099e+02, 1.0106e+02, 1.0106e+02, 1.0106e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0106e+02, 1.0106e+02, 1.0000e-01, 1.0106e+02, 1.0000e-01, 1.0106e+02,\n",
      "         1.0104e+02, 1.0106e+02, 1.0106e+02, 1.0106e+02, 1.0099e+02, 1.0106e+02,\n",
      "         1.0106e+02, 1.0106e+02, 1.0104e+02, 1.0106e+02, 1.0106e+02, 1.0106e+02,\n",
      "         1.0104e+02, 1.0099e+02, 1.0104e+02, 1.0104e+02, 1.0104e+02, 1.0000e-01,\n",
      "         1.0104e+02, 1.0099e+02, 1.0000e-01, 1.0099e+02, 1.0106e+02, 1.0000e-01,\n",
      "         1.0106e+02, 1.0106e+02, 1.0106e+02, 1.0104e+02, 1.0104e+02, 1.0000e-01,\n",
      "         1.0106e+02, 1.0000e-01, 1.0095e+02, 1.0095e+02, 1.0104e+02, 1.0106e+02,\n",
      "         1.0106e+02, 1.0000e-01, 1.0000e-01, 1.0095e+02, 1.0104e+02, 1.0106e+02,\n",
      "         1.0000e-01, 1.0104e+02, 1.0106e+02, 1.0000e-01, 1.0095e+02, 1.0106e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 881 was 99.2%\n",
      "current params: tensor([100.9494, 101.0427, 100.9895, 101.0595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.2\n",
      "SLow rates:  tensor([[1.0105e+02, 1.0114e+02, 1.0109e+02, 1.0116e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0105e+02, 1.0105e+02, 1.0105e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0114e+02, 1.0114e+02, 1.0114e+02, 1.0000e-01, 1.0000e-01, 1.0114e+02,\n",
      "         1.0114e+02, 1.0000e-01, 1.0109e+02, 1.0109e+02, 1.0109e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0109e+02, 1.0109e+02, 1.0000e-01, 1.0109e+02, 1.0000e-01,\n",
      "         1.0109e+02, 1.0116e+02, 1.0116e+02, 1.0116e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0116e+02, 1.0116e+02, 1.0000e-01, 1.0116e+02, 1.0000e-01, 1.0116e+02,\n",
      "         1.0114e+02, 1.0116e+02, 1.0116e+02, 1.0116e+02, 1.0109e+02, 1.0116e+02,\n",
      "         1.0116e+02, 1.0116e+02, 1.0114e+02, 1.0116e+02, 1.0116e+02, 1.0116e+02,\n",
      "         1.0114e+02, 1.0109e+02, 1.0114e+02, 1.0114e+02, 1.0114e+02, 1.0000e-01,\n",
      "         1.0114e+02, 1.0109e+02, 1.0000e-01, 1.0109e+02, 1.0116e+02, 1.0000e-01,\n",
      "         1.0116e+02, 1.0116e+02, 1.0116e+02, 1.0114e+02, 1.0114e+02, 1.0000e-01,\n",
      "         1.0116e+02, 1.0000e-01, 1.0105e+02, 1.0105e+02, 1.0114e+02, 1.0116e+02,\n",
      "         1.0116e+02, 1.0000e-01, 1.0000e-01, 1.0105e+02, 1.0114e+02, 1.0116e+02,\n",
      "         1.0000e-01, 1.0114e+02, 1.0116e+02, 1.0000e-01, 1.0105e+02, 1.0116e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 882 was 99.2%\n",
      "current params: tensor([101.0494, 101.1427, 101.0895, 101.1595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.3\n",
      "SLow rates:  tensor([[1.0115e+02, 1.0124e+02, 1.0119e+02, 1.0126e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0115e+02, 1.0115e+02, 1.0115e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0124e+02, 1.0124e+02, 1.0124e+02, 1.0000e-01, 1.0000e-01, 1.0124e+02,\n",
      "         1.0124e+02, 1.0000e-01, 1.0119e+02, 1.0119e+02, 1.0119e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0119e+02, 1.0119e+02, 1.0000e-01, 1.0119e+02, 1.0000e-01,\n",
      "         1.0119e+02, 1.0126e+02, 1.0126e+02, 1.0126e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0126e+02, 1.0126e+02, 1.0000e-01, 1.0126e+02, 1.0000e-01, 1.0126e+02,\n",
      "         1.0124e+02, 1.0126e+02, 1.0126e+02, 1.0126e+02, 1.0119e+02, 1.0126e+02,\n",
      "         1.0126e+02, 1.0126e+02, 1.0124e+02, 1.0126e+02, 1.0126e+02, 1.0126e+02,\n",
      "         1.0124e+02, 1.0119e+02, 1.0124e+02, 1.0124e+02, 1.0124e+02, 1.0000e-01,\n",
      "         1.0124e+02, 1.0119e+02, 1.0000e-01, 1.0119e+02, 1.0126e+02, 1.0000e-01,\n",
      "         1.0126e+02, 1.0126e+02, 1.0126e+02, 1.0124e+02, 1.0124e+02, 1.0000e-01,\n",
      "         1.0126e+02, 1.0000e-01, 1.0115e+02, 1.0115e+02, 1.0124e+02, 1.0126e+02,\n",
      "         1.0126e+02, 1.0000e-01, 1.0000e-01, 1.0115e+02, 1.0124e+02, 1.0126e+02,\n",
      "         1.0000e-01, 1.0124e+02, 1.0126e+02, 1.0000e-01, 1.0115e+02, 1.0126e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 883 was 99.2%\n",
      "current params: tensor([101.1494, 101.2427, 101.1895, 101.2595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.3\n",
      "SLow rates:  tensor([[1.0125e+02, 1.0134e+02, 1.0129e+02, 1.0136e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0125e+02, 1.0125e+02, 1.0125e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0134e+02, 1.0134e+02, 1.0134e+02, 1.0000e-01, 1.0000e-01, 1.0134e+02,\n",
      "         1.0134e+02, 1.0000e-01, 1.0129e+02, 1.0129e+02, 1.0129e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0129e+02, 1.0129e+02, 1.0000e-01, 1.0129e+02, 1.0000e-01,\n",
      "         1.0129e+02, 1.0136e+02, 1.0136e+02, 1.0136e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0136e+02, 1.0136e+02, 1.0000e-01, 1.0136e+02, 1.0000e-01, 1.0136e+02,\n",
      "         1.0134e+02, 1.0136e+02, 1.0136e+02, 1.0136e+02, 1.0129e+02, 1.0136e+02,\n",
      "         1.0136e+02, 1.0136e+02, 1.0134e+02, 1.0136e+02, 1.0136e+02, 1.0136e+02,\n",
      "         1.0134e+02, 1.0129e+02, 1.0134e+02, 1.0134e+02, 1.0134e+02, 1.0000e-01,\n",
      "         1.0134e+02, 1.0129e+02, 1.0000e-01, 1.0129e+02, 1.0136e+02, 1.0000e-01,\n",
      "         1.0136e+02, 1.0136e+02, 1.0136e+02, 1.0134e+02, 1.0134e+02, 1.0000e-01,\n",
      "         1.0136e+02, 1.0000e-01, 1.0125e+02, 1.0125e+02, 1.0134e+02, 1.0136e+02,\n",
      "         1.0136e+02, 1.0000e-01, 1.0000e-01, 1.0125e+02, 1.0134e+02, 1.0136e+02,\n",
      "         1.0000e-01, 1.0134e+02, 1.0136e+02, 1.0000e-01, 1.0125e+02, 1.0136e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 884 was 99.2%\n",
      "current params: tensor([101.2494, 101.3427, 101.2895, 101.3595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.3\n",
      "SLow rates:  tensor([[1.0135e+02, 1.0144e+02, 1.0139e+02, 1.0146e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0135e+02, 1.0135e+02, 1.0135e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0144e+02, 1.0144e+02, 1.0144e+02, 1.0000e-01, 1.0000e-01, 1.0144e+02,\n",
      "         1.0144e+02, 1.0000e-01, 1.0139e+02, 1.0139e+02, 1.0139e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0139e+02, 1.0139e+02, 1.0000e-01, 1.0139e+02, 1.0000e-01,\n",
      "         1.0139e+02, 1.0146e+02, 1.0146e+02, 1.0146e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0146e+02, 1.0146e+02, 1.0000e-01, 1.0146e+02, 1.0000e-01, 1.0146e+02,\n",
      "         1.0144e+02, 1.0146e+02, 1.0146e+02, 1.0146e+02, 1.0139e+02, 1.0146e+02,\n",
      "         1.0146e+02, 1.0146e+02, 1.0144e+02, 1.0146e+02, 1.0146e+02, 1.0146e+02,\n",
      "         1.0144e+02, 1.0139e+02, 1.0144e+02, 1.0144e+02, 1.0144e+02, 1.0000e-01,\n",
      "         1.0144e+02, 1.0139e+02, 1.0000e-01, 1.0139e+02, 1.0146e+02, 1.0000e-01,\n",
      "         1.0146e+02, 1.0146e+02, 1.0146e+02, 1.0144e+02, 1.0144e+02, 1.0000e-01,\n",
      "         1.0146e+02, 1.0000e-01, 1.0135e+02, 1.0135e+02, 1.0144e+02, 1.0146e+02,\n",
      "         1.0146e+02, 1.0000e-01, 1.0000e-01, 1.0135e+02, 1.0144e+02, 1.0146e+02,\n",
      "         1.0000e-01, 1.0144e+02, 1.0146e+02, 1.0000e-01, 1.0135e+02, 1.0146e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 885 was 99.2%\n",
      "current params: tensor([101.3494, 101.4427, 101.3895, 101.4595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.4\n",
      "SLow rates:  tensor([[1.0145e+02, 1.0154e+02, 1.0149e+02, 1.0156e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0145e+02, 1.0145e+02, 1.0145e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0154e+02, 1.0154e+02, 1.0154e+02, 1.0000e-01, 1.0000e-01, 1.0154e+02,\n",
      "         1.0154e+02, 1.0000e-01, 1.0149e+02, 1.0149e+02, 1.0149e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0149e+02, 1.0149e+02, 1.0000e-01, 1.0149e+02, 1.0000e-01,\n",
      "         1.0149e+02, 1.0156e+02, 1.0156e+02, 1.0156e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0156e+02, 1.0156e+02, 1.0000e-01, 1.0156e+02, 1.0000e-01, 1.0156e+02,\n",
      "         1.0154e+02, 1.0156e+02, 1.0156e+02, 1.0156e+02, 1.0149e+02, 1.0156e+02,\n",
      "         1.0156e+02, 1.0156e+02, 1.0154e+02, 1.0156e+02, 1.0156e+02, 1.0156e+02,\n",
      "         1.0154e+02, 1.0149e+02, 1.0154e+02, 1.0154e+02, 1.0154e+02, 1.0000e-01,\n",
      "         1.0154e+02, 1.0149e+02, 1.0000e-01, 1.0149e+02, 1.0156e+02, 1.0000e-01,\n",
      "         1.0156e+02, 1.0156e+02, 1.0156e+02, 1.0154e+02, 1.0154e+02, 1.0000e-01,\n",
      "         1.0156e+02, 1.0000e-01, 1.0145e+02, 1.0145e+02, 1.0154e+02, 1.0156e+02,\n",
      "         1.0156e+02, 1.0000e-01, 1.0000e-01, 1.0145e+02, 1.0154e+02, 1.0156e+02,\n",
      "         1.0000e-01, 1.0154e+02, 1.0156e+02, 1.0000e-01, 1.0145e+02, 1.0156e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 886 was 99.2%\n",
      "current params: tensor([101.4494, 101.5427, 101.4896, 101.5595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.4\n",
      "SLow rates:  tensor([[1.0155e+02, 1.0164e+02, 1.0159e+02, 1.0166e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0155e+02, 1.0155e+02, 1.0155e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0164e+02, 1.0164e+02, 1.0164e+02, 1.0000e-01, 1.0000e-01, 1.0164e+02,\n",
      "         1.0164e+02, 1.0000e-01, 1.0159e+02, 1.0159e+02, 1.0159e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0159e+02, 1.0159e+02, 1.0000e-01, 1.0159e+02, 1.0000e-01,\n",
      "         1.0159e+02, 1.0166e+02, 1.0166e+02, 1.0166e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0166e+02, 1.0166e+02, 1.0000e-01, 1.0166e+02, 1.0000e-01, 1.0166e+02,\n",
      "         1.0164e+02, 1.0166e+02, 1.0166e+02, 1.0166e+02, 1.0159e+02, 1.0166e+02,\n",
      "         1.0166e+02, 1.0166e+02, 1.0164e+02, 1.0166e+02, 1.0166e+02, 1.0166e+02,\n",
      "         1.0164e+02, 1.0159e+02, 1.0164e+02, 1.0164e+02, 1.0164e+02, 1.0000e-01,\n",
      "         1.0164e+02, 1.0159e+02, 1.0000e-01, 1.0159e+02, 1.0166e+02, 1.0000e-01,\n",
      "         1.0166e+02, 1.0166e+02, 1.0166e+02, 1.0164e+02, 1.0164e+02, 1.0000e-01,\n",
      "         1.0166e+02, 1.0000e-01, 1.0155e+02, 1.0155e+02, 1.0164e+02, 1.0166e+02,\n",
      "         1.0166e+02, 1.0000e-01, 1.0000e-01, 1.0155e+02, 1.0164e+02, 1.0166e+02,\n",
      "         1.0000e-01, 1.0164e+02, 1.0166e+02, 1.0000e-01, 1.0155e+02, 1.0166e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 887 was 99.2%\n",
      "current params: tensor([101.5494, 101.6427, 101.5896, 101.6595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.4\n",
      "SLow rates:  tensor([[1.0165e+02, 1.0174e+02, 1.0169e+02, 1.0176e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0165e+02, 1.0165e+02, 1.0165e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0174e+02, 1.0174e+02, 1.0174e+02, 1.0000e-01, 1.0000e-01, 1.0174e+02,\n",
      "         1.0174e+02, 1.0000e-01, 1.0169e+02, 1.0169e+02, 1.0169e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0169e+02, 1.0169e+02, 1.0000e-01, 1.0169e+02, 1.0000e-01,\n",
      "         1.0169e+02, 1.0176e+02, 1.0176e+02, 1.0176e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0176e+02, 1.0176e+02, 1.0000e-01, 1.0176e+02, 1.0000e-01, 1.0176e+02,\n",
      "         1.0174e+02, 1.0176e+02, 1.0176e+02, 1.0176e+02, 1.0169e+02, 1.0176e+02,\n",
      "         1.0176e+02, 1.0176e+02, 1.0174e+02, 1.0176e+02, 1.0176e+02, 1.0176e+02,\n",
      "         1.0174e+02, 1.0169e+02, 1.0174e+02, 1.0174e+02, 1.0174e+02, 1.0000e-01,\n",
      "         1.0174e+02, 1.0169e+02, 1.0000e-01, 1.0169e+02, 1.0176e+02, 1.0000e-01,\n",
      "         1.0176e+02, 1.0176e+02, 1.0176e+02, 1.0174e+02, 1.0174e+02, 1.0000e-01,\n",
      "         1.0176e+02, 1.0000e-01, 1.0165e+02, 1.0165e+02, 1.0174e+02, 1.0176e+02,\n",
      "         1.0176e+02, 1.0000e-01, 1.0000e-01, 1.0165e+02, 1.0174e+02, 1.0176e+02,\n",
      "         1.0000e-01, 1.0174e+02, 1.0176e+02, 1.0000e-01, 1.0165e+02, 1.0176e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 888 was 99.2%\n",
      "current params: tensor([101.6494, 101.7427, 101.6896, 101.7595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.4\n",
      "SLow rates:  tensor([[1.0175e+02, 1.0184e+02, 1.0179e+02, 1.0186e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0175e+02, 1.0175e+02, 1.0175e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0184e+02, 1.0184e+02, 1.0184e+02, 1.0000e-01, 1.0000e-01, 1.0184e+02,\n",
      "         1.0184e+02, 1.0000e-01, 1.0179e+02, 1.0179e+02, 1.0179e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0179e+02, 1.0179e+02, 1.0000e-01, 1.0179e+02, 1.0000e-01,\n",
      "         1.0179e+02, 1.0186e+02, 1.0186e+02, 1.0186e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0186e+02, 1.0186e+02, 1.0000e-01, 1.0186e+02, 1.0000e-01, 1.0186e+02,\n",
      "         1.0184e+02, 1.0186e+02, 1.0186e+02, 1.0186e+02, 1.0179e+02, 1.0186e+02,\n",
      "         1.0186e+02, 1.0186e+02, 1.0184e+02, 1.0186e+02, 1.0186e+02, 1.0186e+02,\n",
      "         1.0184e+02, 1.0179e+02, 1.0184e+02, 1.0184e+02, 1.0184e+02, 1.0000e-01,\n",
      "         1.0184e+02, 1.0179e+02, 1.0000e-01, 1.0179e+02, 1.0186e+02, 1.0000e-01,\n",
      "         1.0186e+02, 1.0186e+02, 1.0186e+02, 1.0184e+02, 1.0184e+02, 1.0000e-01,\n",
      "         1.0186e+02, 1.0000e-01, 1.0175e+02, 1.0175e+02, 1.0184e+02, 1.0186e+02,\n",
      "         1.0186e+02, 1.0000e-01, 1.0000e-01, 1.0175e+02, 1.0184e+02, 1.0186e+02,\n",
      "         1.0000e-01, 1.0184e+02, 1.0186e+02, 1.0000e-01, 1.0175e+02, 1.0186e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 889 was 99.2%\n",
      "current params: tensor([101.7494, 101.8427, 101.7896, 101.8595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.4\n",
      "SLow rates:  tensor([[1.0185e+02, 1.0194e+02, 1.0189e+02, 1.0196e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0185e+02, 1.0185e+02, 1.0185e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0194e+02, 1.0194e+02, 1.0194e+02, 1.0000e-01, 1.0000e-01, 1.0194e+02,\n",
      "         1.0194e+02, 1.0000e-01, 1.0189e+02, 1.0189e+02, 1.0189e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0189e+02, 1.0189e+02, 1.0000e-01, 1.0189e+02, 1.0000e-01,\n",
      "         1.0189e+02, 1.0196e+02, 1.0196e+02, 1.0196e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0196e+02, 1.0196e+02, 1.0000e-01, 1.0196e+02, 1.0000e-01, 1.0196e+02,\n",
      "         1.0194e+02, 1.0196e+02, 1.0196e+02, 1.0196e+02, 1.0189e+02, 1.0196e+02,\n",
      "         1.0196e+02, 1.0196e+02, 1.0194e+02, 1.0196e+02, 1.0196e+02, 1.0196e+02,\n",
      "         1.0194e+02, 1.0189e+02, 1.0194e+02, 1.0194e+02, 1.0194e+02, 1.0000e-01,\n",
      "         1.0194e+02, 1.0189e+02, 1.0000e-01, 1.0189e+02, 1.0196e+02, 1.0000e-01,\n",
      "         1.0196e+02, 1.0196e+02, 1.0196e+02, 1.0194e+02, 1.0194e+02, 1.0000e-01,\n",
      "         1.0196e+02, 1.0000e-01, 1.0185e+02, 1.0185e+02, 1.0194e+02, 1.0196e+02,\n",
      "         1.0196e+02, 1.0000e-01, 1.0000e-01, 1.0185e+02, 1.0194e+02, 1.0196e+02,\n",
      "         1.0000e-01, 1.0194e+02, 1.0196e+02, 1.0000e-01, 1.0185e+02, 1.0196e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 890 was 99.2%\n",
      "current params: tensor([101.8494, 101.9427, 101.8896, 101.9595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.5\n",
      "SLow rates:  tensor([[1.0195e+02, 1.0204e+02, 1.0199e+02, 1.0206e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0195e+02, 1.0195e+02, 1.0195e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0204e+02, 1.0204e+02, 1.0204e+02, 1.0000e-01, 1.0000e-01, 1.0204e+02,\n",
      "         1.0204e+02, 1.0000e-01, 1.0199e+02, 1.0199e+02, 1.0199e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0199e+02, 1.0199e+02, 1.0000e-01, 1.0199e+02, 1.0000e-01,\n",
      "         1.0199e+02, 1.0206e+02, 1.0206e+02, 1.0206e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0206e+02, 1.0206e+02, 1.0000e-01, 1.0206e+02, 1.0000e-01, 1.0206e+02,\n",
      "         1.0204e+02, 1.0206e+02, 1.0206e+02, 1.0206e+02, 1.0199e+02, 1.0206e+02,\n",
      "         1.0206e+02, 1.0206e+02, 1.0204e+02, 1.0206e+02, 1.0206e+02, 1.0206e+02,\n",
      "         1.0204e+02, 1.0199e+02, 1.0204e+02, 1.0204e+02, 1.0204e+02, 1.0000e-01,\n",
      "         1.0204e+02, 1.0199e+02, 1.0000e-01, 1.0199e+02, 1.0206e+02, 1.0000e-01,\n",
      "         1.0206e+02, 1.0206e+02, 1.0206e+02, 1.0204e+02, 1.0204e+02, 1.0000e-01,\n",
      "         1.0206e+02, 1.0000e-01, 1.0195e+02, 1.0195e+02, 1.0204e+02, 1.0206e+02,\n",
      "         1.0206e+02, 1.0000e-01, 1.0000e-01, 1.0195e+02, 1.0204e+02, 1.0206e+02,\n",
      "         1.0000e-01, 1.0204e+02, 1.0206e+02, 1.0000e-01, 1.0195e+02, 1.0206e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 891 was 99.2%\n",
      "current params: tensor([101.9494, 102.0427, 101.9896, 102.0595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.5\n",
      "SLow rates:  tensor([[1.0205e+02, 1.0214e+02, 1.0209e+02, 1.0216e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0205e+02, 1.0205e+02, 1.0205e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0214e+02, 1.0214e+02, 1.0214e+02, 1.0000e-01, 1.0000e-01, 1.0214e+02,\n",
      "         1.0214e+02, 1.0000e-01, 1.0209e+02, 1.0209e+02, 1.0209e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0209e+02, 1.0209e+02, 1.0000e-01, 1.0209e+02, 1.0000e-01,\n",
      "         1.0209e+02, 1.0216e+02, 1.0216e+02, 1.0216e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0216e+02, 1.0216e+02, 1.0000e-01, 1.0216e+02, 1.0000e-01, 1.0216e+02,\n",
      "         1.0214e+02, 1.0216e+02, 1.0216e+02, 1.0216e+02, 1.0209e+02, 1.0216e+02,\n",
      "         1.0216e+02, 1.0216e+02, 1.0214e+02, 1.0216e+02, 1.0216e+02, 1.0216e+02,\n",
      "         1.0214e+02, 1.0209e+02, 1.0214e+02, 1.0214e+02, 1.0214e+02, 1.0000e-01,\n",
      "         1.0214e+02, 1.0209e+02, 1.0000e-01, 1.0209e+02, 1.0216e+02, 1.0000e-01,\n",
      "         1.0216e+02, 1.0216e+02, 1.0216e+02, 1.0214e+02, 1.0214e+02, 1.0000e-01,\n",
      "         1.0216e+02, 1.0000e-01, 1.0205e+02, 1.0205e+02, 1.0214e+02, 1.0216e+02,\n",
      "         1.0216e+02, 1.0000e-01, 1.0000e-01, 1.0205e+02, 1.0214e+02, 1.0216e+02,\n",
      "         1.0000e-01, 1.0214e+02, 1.0216e+02, 1.0000e-01, 1.0205e+02, 1.0216e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 892 was 99.2%\n",
      "current params: tensor([102.0494, 102.1427, 102.0896, 102.1595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.5\n",
      "SLow rates:  tensor([[1.0215e+02, 1.0224e+02, 1.0219e+02, 1.0226e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0215e+02, 1.0215e+02, 1.0215e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0224e+02, 1.0224e+02, 1.0224e+02, 1.0000e-01, 1.0000e-01, 1.0224e+02,\n",
      "         1.0224e+02, 1.0000e-01, 1.0219e+02, 1.0219e+02, 1.0219e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0219e+02, 1.0219e+02, 1.0000e-01, 1.0219e+02, 1.0000e-01,\n",
      "         1.0219e+02, 1.0226e+02, 1.0226e+02, 1.0226e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0226e+02, 1.0226e+02, 1.0000e-01, 1.0226e+02, 1.0000e-01, 1.0226e+02,\n",
      "         1.0224e+02, 1.0226e+02, 1.0226e+02, 1.0226e+02, 1.0219e+02, 1.0226e+02,\n",
      "         1.0226e+02, 1.0226e+02, 1.0224e+02, 1.0226e+02, 1.0226e+02, 1.0226e+02,\n",
      "         1.0224e+02, 1.0219e+02, 1.0224e+02, 1.0224e+02, 1.0224e+02, 1.0000e-01,\n",
      "         1.0224e+02, 1.0219e+02, 1.0000e-01, 1.0219e+02, 1.0226e+02, 1.0000e-01,\n",
      "         1.0226e+02, 1.0226e+02, 1.0226e+02, 1.0224e+02, 1.0224e+02, 1.0000e-01,\n",
      "         1.0226e+02, 1.0000e-01, 1.0215e+02, 1.0215e+02, 1.0224e+02, 1.0226e+02,\n",
      "         1.0226e+02, 1.0000e-01, 1.0000e-01, 1.0215e+02, 1.0224e+02, 1.0226e+02,\n",
      "         1.0000e-01, 1.0224e+02, 1.0226e+02, 1.0000e-01, 1.0215e+02, 1.0226e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 893 was 99.2%\n",
      "current params: tensor([102.1494, 102.2427, 102.1896, 102.2595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.5\n",
      "SLow rates:  tensor([[1.0225e+02, 1.0234e+02, 1.0229e+02, 1.0236e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0225e+02, 1.0225e+02, 1.0225e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0234e+02, 1.0234e+02, 1.0234e+02, 1.0000e-01, 1.0000e-01, 1.0234e+02,\n",
      "         1.0234e+02, 1.0000e-01, 1.0229e+02, 1.0229e+02, 1.0229e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0229e+02, 1.0229e+02, 1.0000e-01, 1.0229e+02, 1.0000e-01,\n",
      "         1.0229e+02, 1.0236e+02, 1.0236e+02, 1.0236e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0236e+02, 1.0236e+02, 1.0000e-01, 1.0236e+02, 1.0000e-01, 1.0236e+02,\n",
      "         1.0234e+02, 1.0236e+02, 1.0236e+02, 1.0236e+02, 1.0229e+02, 1.0236e+02,\n",
      "         1.0236e+02, 1.0236e+02, 1.0234e+02, 1.0236e+02, 1.0236e+02, 1.0236e+02,\n",
      "         1.0234e+02, 1.0229e+02, 1.0234e+02, 1.0234e+02, 1.0234e+02, 1.0000e-01,\n",
      "         1.0234e+02, 1.0229e+02, 1.0000e-01, 1.0229e+02, 1.0236e+02, 1.0000e-01,\n",
      "         1.0236e+02, 1.0236e+02, 1.0236e+02, 1.0234e+02, 1.0234e+02, 1.0000e-01,\n",
      "         1.0236e+02, 1.0000e-01, 1.0225e+02, 1.0225e+02, 1.0234e+02, 1.0236e+02,\n",
      "         1.0236e+02, 1.0000e-01, 1.0000e-01, 1.0225e+02, 1.0234e+02, 1.0236e+02,\n",
      "         1.0000e-01, 1.0234e+02, 1.0236e+02, 1.0000e-01, 1.0225e+02, 1.0236e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 894 was 99.2%\n",
      "current params: tensor([102.2494, 102.3427, 102.2896, 102.3595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.5\n",
      "SLow rates:  tensor([[1.0235e+02, 1.0244e+02, 1.0239e+02, 1.0246e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0235e+02, 1.0235e+02, 1.0235e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0244e+02, 1.0244e+02, 1.0244e+02, 1.0000e-01, 1.0000e-01, 1.0244e+02,\n",
      "         1.0244e+02, 1.0000e-01, 1.0239e+02, 1.0239e+02, 1.0239e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0239e+02, 1.0239e+02, 1.0000e-01, 1.0239e+02, 1.0000e-01,\n",
      "         1.0239e+02, 1.0246e+02, 1.0246e+02, 1.0246e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0246e+02, 1.0246e+02, 1.0000e-01, 1.0246e+02, 1.0000e-01, 1.0246e+02,\n",
      "         1.0244e+02, 1.0246e+02, 1.0246e+02, 1.0246e+02, 1.0239e+02, 1.0246e+02,\n",
      "         1.0246e+02, 1.0246e+02, 1.0244e+02, 1.0246e+02, 1.0246e+02, 1.0246e+02,\n",
      "         1.0244e+02, 1.0239e+02, 1.0244e+02, 1.0244e+02, 1.0244e+02, 1.0000e-01,\n",
      "         1.0244e+02, 1.0239e+02, 1.0000e-01, 1.0239e+02, 1.0246e+02, 1.0000e-01,\n",
      "         1.0246e+02, 1.0246e+02, 1.0246e+02, 1.0244e+02, 1.0244e+02, 1.0000e-01,\n",
      "         1.0246e+02, 1.0000e-01, 1.0235e+02, 1.0235e+02, 1.0244e+02, 1.0246e+02,\n",
      "         1.0246e+02, 1.0000e-01, 1.0000e-01, 1.0235e+02, 1.0244e+02, 1.0246e+02,\n",
      "         1.0000e-01, 1.0244e+02, 1.0246e+02, 1.0000e-01, 1.0235e+02, 1.0246e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 895 was 99.2%\n",
      "current params: tensor([102.3495, 102.4427, 102.3896, 102.4595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.6\n",
      "SLow rates:  tensor([[1.0245e+02, 1.0254e+02, 1.0249e+02, 1.0256e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0245e+02, 1.0245e+02, 1.0245e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0254e+02, 1.0254e+02, 1.0254e+02, 1.0000e-01, 1.0000e-01, 1.0254e+02,\n",
      "         1.0254e+02, 1.0000e-01, 1.0249e+02, 1.0249e+02, 1.0249e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0249e+02, 1.0249e+02, 1.0000e-01, 1.0249e+02, 1.0000e-01,\n",
      "         1.0249e+02, 1.0256e+02, 1.0256e+02, 1.0256e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0256e+02, 1.0256e+02, 1.0000e-01, 1.0256e+02, 1.0000e-01, 1.0256e+02,\n",
      "         1.0254e+02, 1.0256e+02, 1.0256e+02, 1.0256e+02, 1.0249e+02, 1.0256e+02,\n",
      "         1.0256e+02, 1.0256e+02, 1.0254e+02, 1.0256e+02, 1.0256e+02, 1.0256e+02,\n",
      "         1.0254e+02, 1.0249e+02, 1.0254e+02, 1.0254e+02, 1.0254e+02, 1.0000e-01,\n",
      "         1.0254e+02, 1.0249e+02, 1.0000e-01, 1.0249e+02, 1.0256e+02, 1.0000e-01,\n",
      "         1.0256e+02, 1.0256e+02, 1.0256e+02, 1.0254e+02, 1.0254e+02, 1.0000e-01,\n",
      "         1.0256e+02, 1.0000e-01, 1.0245e+02, 1.0245e+02, 1.0254e+02, 1.0256e+02,\n",
      "         1.0256e+02, 1.0000e-01, 1.0000e-01, 1.0245e+02, 1.0254e+02, 1.0256e+02,\n",
      "         1.0000e-01, 1.0254e+02, 1.0256e+02, 1.0000e-01, 1.0245e+02, 1.0256e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 896 was 99.2%\n",
      "current params: tensor([102.4495, 102.5427, 102.4896, 102.5595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.6\n",
      "SLow rates:  tensor([[1.0255e+02, 1.0264e+02, 1.0259e+02, 1.0266e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0255e+02, 1.0255e+02, 1.0255e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0264e+02, 1.0264e+02, 1.0264e+02, 1.0000e-01, 1.0000e-01, 1.0264e+02,\n",
      "         1.0264e+02, 1.0000e-01, 1.0259e+02, 1.0259e+02, 1.0259e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0259e+02, 1.0259e+02, 1.0000e-01, 1.0259e+02, 1.0000e-01,\n",
      "         1.0259e+02, 1.0266e+02, 1.0266e+02, 1.0266e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0266e+02, 1.0266e+02, 1.0000e-01, 1.0266e+02, 1.0000e-01, 1.0266e+02,\n",
      "         1.0264e+02, 1.0266e+02, 1.0266e+02, 1.0266e+02, 1.0259e+02, 1.0266e+02,\n",
      "         1.0266e+02, 1.0266e+02, 1.0264e+02, 1.0266e+02, 1.0266e+02, 1.0266e+02,\n",
      "         1.0264e+02, 1.0259e+02, 1.0264e+02, 1.0264e+02, 1.0264e+02, 1.0000e-01,\n",
      "         1.0264e+02, 1.0259e+02, 1.0000e-01, 1.0259e+02, 1.0266e+02, 1.0000e-01,\n",
      "         1.0266e+02, 1.0266e+02, 1.0266e+02, 1.0264e+02, 1.0264e+02, 1.0000e-01,\n",
      "         1.0266e+02, 1.0000e-01, 1.0255e+02, 1.0255e+02, 1.0264e+02, 1.0266e+02,\n",
      "         1.0266e+02, 1.0000e-01, 1.0000e-01, 1.0255e+02, 1.0264e+02, 1.0266e+02,\n",
      "         1.0000e-01, 1.0264e+02, 1.0266e+02, 1.0000e-01, 1.0255e+02, 1.0266e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 897 was 99.2%\n",
      "current params: tensor([102.5495, 102.6427, 102.5896, 102.6595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.7\n",
      "SLow rates:  tensor([[1.0265e+02, 1.0274e+02, 1.0269e+02, 1.0276e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0265e+02, 1.0265e+02, 1.0265e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0274e+02, 1.0274e+02, 1.0274e+02, 1.0000e-01, 1.0000e-01, 1.0274e+02,\n",
      "         1.0274e+02, 1.0000e-01, 1.0269e+02, 1.0269e+02, 1.0269e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0269e+02, 1.0269e+02, 1.0000e-01, 1.0269e+02, 1.0000e-01,\n",
      "         1.0269e+02, 1.0276e+02, 1.0276e+02, 1.0276e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0276e+02, 1.0276e+02, 1.0000e-01, 1.0276e+02, 1.0000e-01, 1.0276e+02,\n",
      "         1.0274e+02, 1.0276e+02, 1.0276e+02, 1.0276e+02, 1.0269e+02, 1.0276e+02,\n",
      "         1.0276e+02, 1.0276e+02, 1.0274e+02, 1.0276e+02, 1.0276e+02, 1.0276e+02,\n",
      "         1.0274e+02, 1.0269e+02, 1.0274e+02, 1.0274e+02, 1.0274e+02, 1.0000e-01,\n",
      "         1.0274e+02, 1.0269e+02, 1.0000e-01, 1.0269e+02, 1.0276e+02, 1.0000e-01,\n",
      "         1.0276e+02, 1.0276e+02, 1.0276e+02, 1.0274e+02, 1.0274e+02, 1.0000e-01,\n",
      "         1.0276e+02, 1.0000e-01, 1.0265e+02, 1.0265e+02, 1.0274e+02, 1.0276e+02,\n",
      "         1.0276e+02, 1.0000e-01, 1.0000e-01, 1.0265e+02, 1.0274e+02, 1.0276e+02,\n",
      "         1.0000e-01, 1.0274e+02, 1.0276e+02, 1.0000e-01, 1.0265e+02, 1.0276e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 898 was 99.2%\n",
      "current params: tensor([102.6495, 102.7427, 102.6896, 102.7595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.7\n",
      "SLow rates:  tensor([[1.0275e+02, 1.0284e+02, 1.0279e+02, 1.0286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0275e+02, 1.0275e+02, 1.0275e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0284e+02, 1.0284e+02, 1.0284e+02, 1.0000e-01, 1.0000e-01, 1.0284e+02,\n",
      "         1.0284e+02, 1.0000e-01, 1.0279e+02, 1.0279e+02, 1.0279e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0279e+02, 1.0279e+02, 1.0000e-01, 1.0279e+02, 1.0000e-01,\n",
      "         1.0279e+02, 1.0286e+02, 1.0286e+02, 1.0286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0286e+02, 1.0286e+02, 1.0000e-01, 1.0286e+02, 1.0000e-01, 1.0286e+02,\n",
      "         1.0284e+02, 1.0286e+02, 1.0286e+02, 1.0286e+02, 1.0279e+02, 1.0286e+02,\n",
      "         1.0286e+02, 1.0286e+02, 1.0284e+02, 1.0286e+02, 1.0286e+02, 1.0286e+02,\n",
      "         1.0284e+02, 1.0279e+02, 1.0284e+02, 1.0284e+02, 1.0284e+02, 1.0000e-01,\n",
      "         1.0284e+02, 1.0279e+02, 1.0000e-01, 1.0279e+02, 1.0286e+02, 1.0000e-01,\n",
      "         1.0286e+02, 1.0286e+02, 1.0286e+02, 1.0284e+02, 1.0284e+02, 1.0000e-01,\n",
      "         1.0286e+02, 1.0000e-01, 1.0275e+02, 1.0275e+02, 1.0284e+02, 1.0286e+02,\n",
      "         1.0286e+02, 1.0000e-01, 1.0000e-01, 1.0275e+02, 1.0284e+02, 1.0286e+02,\n",
      "         1.0000e-01, 1.0284e+02, 1.0286e+02, 1.0000e-01, 1.0275e+02, 1.0286e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 899 was 99.2%\n",
      "current params: tensor([102.7495, 102.8427, 102.7896, 102.8595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.8\n",
      "SLow rates:  tensor([[1.0285e+02, 1.0294e+02, 1.0289e+02, 1.0296e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0285e+02, 1.0285e+02, 1.0285e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0294e+02, 1.0294e+02, 1.0294e+02, 1.0000e-01, 1.0000e-01, 1.0294e+02,\n",
      "         1.0294e+02, 1.0000e-01, 1.0289e+02, 1.0289e+02, 1.0289e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0289e+02, 1.0289e+02, 1.0000e-01, 1.0289e+02, 1.0000e-01,\n",
      "         1.0289e+02, 1.0296e+02, 1.0296e+02, 1.0296e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0296e+02, 1.0296e+02, 1.0000e-01, 1.0296e+02, 1.0000e-01, 1.0296e+02,\n",
      "         1.0294e+02, 1.0296e+02, 1.0296e+02, 1.0296e+02, 1.0289e+02, 1.0296e+02,\n",
      "         1.0296e+02, 1.0296e+02, 1.0294e+02, 1.0296e+02, 1.0296e+02, 1.0296e+02,\n",
      "         1.0294e+02, 1.0289e+02, 1.0294e+02, 1.0294e+02, 1.0294e+02, 1.0000e-01,\n",
      "         1.0294e+02, 1.0289e+02, 1.0000e-01, 1.0289e+02, 1.0296e+02, 1.0000e-01,\n",
      "         1.0296e+02, 1.0296e+02, 1.0296e+02, 1.0294e+02, 1.0294e+02, 1.0000e-01,\n",
      "         1.0296e+02, 1.0000e-01, 1.0285e+02, 1.0285e+02, 1.0294e+02, 1.0296e+02,\n",
      "         1.0296e+02, 1.0000e-01, 1.0000e-01, 1.0285e+02, 1.0294e+02, 1.0296e+02,\n",
      "         1.0000e-01, 1.0294e+02, 1.0296e+02, 1.0000e-01, 1.0285e+02, 1.0296e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 900 was 99.2%\n",
      "current params: tensor([102.8495, 102.9427, 102.8896, 102.9595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.8\n",
      "SLow rates:  tensor([[1.0295e+02, 1.0304e+02, 1.0299e+02, 1.0306e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0295e+02, 1.0295e+02, 1.0295e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0304e+02, 1.0304e+02, 1.0304e+02, 1.0000e-01, 1.0000e-01, 1.0304e+02,\n",
      "         1.0304e+02, 1.0000e-01, 1.0299e+02, 1.0299e+02, 1.0299e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0299e+02, 1.0299e+02, 1.0000e-01, 1.0299e+02, 1.0000e-01,\n",
      "         1.0299e+02, 1.0306e+02, 1.0306e+02, 1.0306e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0306e+02, 1.0306e+02, 1.0000e-01, 1.0306e+02, 1.0000e-01, 1.0306e+02,\n",
      "         1.0304e+02, 1.0306e+02, 1.0306e+02, 1.0306e+02, 1.0299e+02, 1.0306e+02,\n",
      "         1.0306e+02, 1.0306e+02, 1.0304e+02, 1.0306e+02, 1.0306e+02, 1.0306e+02,\n",
      "         1.0304e+02, 1.0299e+02, 1.0304e+02, 1.0304e+02, 1.0304e+02, 1.0000e-01,\n",
      "         1.0304e+02, 1.0299e+02, 1.0000e-01, 1.0299e+02, 1.0306e+02, 1.0000e-01,\n",
      "         1.0306e+02, 1.0306e+02, 1.0306e+02, 1.0304e+02, 1.0304e+02, 1.0000e-01,\n",
      "         1.0306e+02, 1.0000e-01, 1.0295e+02, 1.0295e+02, 1.0304e+02, 1.0306e+02,\n",
      "         1.0306e+02, 1.0000e-01, 1.0000e-01, 1.0295e+02, 1.0304e+02, 1.0306e+02,\n",
      "         1.0000e-01, 1.0304e+02, 1.0306e+02, 1.0000e-01, 1.0295e+02, 1.0306e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 901 was 99.2%\n",
      "current params: tensor([102.9495, 103.0428, 102.9896, 103.0595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.8\n",
      "SLow rates:  tensor([[1.0305e+02, 1.0314e+02, 1.0309e+02, 1.0316e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0305e+02, 1.0305e+02, 1.0305e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0314e+02, 1.0314e+02, 1.0314e+02, 1.0000e-01, 1.0000e-01, 1.0314e+02,\n",
      "         1.0314e+02, 1.0000e-01, 1.0309e+02, 1.0309e+02, 1.0309e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0309e+02, 1.0309e+02, 1.0000e-01, 1.0309e+02, 1.0000e-01,\n",
      "         1.0309e+02, 1.0316e+02, 1.0316e+02, 1.0316e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0316e+02, 1.0316e+02, 1.0000e-01, 1.0316e+02, 1.0000e-01, 1.0316e+02,\n",
      "         1.0314e+02, 1.0316e+02, 1.0316e+02, 1.0316e+02, 1.0309e+02, 1.0316e+02,\n",
      "         1.0316e+02, 1.0316e+02, 1.0314e+02, 1.0316e+02, 1.0316e+02, 1.0316e+02,\n",
      "         1.0314e+02, 1.0309e+02, 1.0314e+02, 1.0314e+02, 1.0314e+02, 1.0000e-01,\n",
      "         1.0314e+02, 1.0309e+02, 1.0000e-01, 1.0309e+02, 1.0316e+02, 1.0000e-01,\n",
      "         1.0316e+02, 1.0316e+02, 1.0316e+02, 1.0314e+02, 1.0314e+02, 1.0000e-01,\n",
      "         1.0316e+02, 1.0000e-01, 1.0305e+02, 1.0305e+02, 1.0314e+02, 1.0316e+02,\n",
      "         1.0316e+02, 1.0000e-01, 1.0000e-01, 1.0305e+02, 1.0314e+02, 1.0316e+02,\n",
      "         1.0000e-01, 1.0314e+02, 1.0316e+02, 1.0000e-01, 1.0305e+02, 1.0316e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 902 was 99.2%\n",
      "current params: tensor([103.0495, 103.1428, 103.0896, 103.1595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.9\n",
      "SLow rates:  tensor([[1.0315e+02, 1.0324e+02, 1.0319e+02, 1.0326e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0315e+02, 1.0315e+02, 1.0315e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0324e+02, 1.0324e+02, 1.0324e+02, 1.0000e-01, 1.0000e-01, 1.0324e+02,\n",
      "         1.0324e+02, 1.0000e-01, 1.0319e+02, 1.0319e+02, 1.0319e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0319e+02, 1.0319e+02, 1.0000e-01, 1.0319e+02, 1.0000e-01,\n",
      "         1.0319e+02, 1.0326e+02, 1.0326e+02, 1.0326e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0326e+02, 1.0326e+02, 1.0000e-01, 1.0326e+02, 1.0000e-01, 1.0326e+02,\n",
      "         1.0324e+02, 1.0326e+02, 1.0326e+02, 1.0326e+02, 1.0319e+02, 1.0326e+02,\n",
      "         1.0326e+02, 1.0326e+02, 1.0324e+02, 1.0326e+02, 1.0326e+02, 1.0326e+02,\n",
      "         1.0324e+02, 1.0319e+02, 1.0324e+02, 1.0324e+02, 1.0324e+02, 1.0000e-01,\n",
      "         1.0324e+02, 1.0319e+02, 1.0000e-01, 1.0319e+02, 1.0326e+02, 1.0000e-01,\n",
      "         1.0326e+02, 1.0326e+02, 1.0326e+02, 1.0324e+02, 1.0324e+02, 1.0000e-01,\n",
      "         1.0326e+02, 1.0000e-01, 1.0315e+02, 1.0315e+02, 1.0324e+02, 1.0326e+02,\n",
      "         1.0326e+02, 1.0000e-01, 1.0000e-01, 1.0315e+02, 1.0324e+02, 1.0326e+02,\n",
      "         1.0000e-01, 1.0324e+02, 1.0326e+02, 1.0000e-01, 1.0315e+02, 1.0326e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 903 was 99.2%\n",
      "current params: tensor([103.1495, 103.2428, 103.1896, 103.2595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.9\n",
      "SLow rates:  tensor([[1.0325e+02, 1.0334e+02, 1.0329e+02, 1.0336e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0325e+02, 1.0325e+02, 1.0325e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0334e+02, 1.0334e+02, 1.0334e+02, 1.0000e-01, 1.0000e-01, 1.0334e+02,\n",
      "         1.0334e+02, 1.0000e-01, 1.0329e+02, 1.0329e+02, 1.0329e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0329e+02, 1.0329e+02, 1.0000e-01, 1.0329e+02, 1.0000e-01,\n",
      "         1.0329e+02, 1.0336e+02, 1.0336e+02, 1.0336e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0336e+02, 1.0336e+02, 1.0000e-01, 1.0336e+02, 1.0000e-01, 1.0336e+02,\n",
      "         1.0334e+02, 1.0336e+02, 1.0336e+02, 1.0336e+02, 1.0329e+02, 1.0336e+02,\n",
      "         1.0336e+02, 1.0336e+02, 1.0334e+02, 1.0336e+02, 1.0336e+02, 1.0336e+02,\n",
      "         1.0334e+02, 1.0329e+02, 1.0334e+02, 1.0334e+02, 1.0334e+02, 1.0000e-01,\n",
      "         1.0334e+02, 1.0329e+02, 1.0000e-01, 1.0329e+02, 1.0336e+02, 1.0000e-01,\n",
      "         1.0336e+02, 1.0336e+02, 1.0336e+02, 1.0334e+02, 1.0334e+02, 1.0000e-01,\n",
      "         1.0336e+02, 1.0000e-01, 1.0325e+02, 1.0325e+02, 1.0334e+02, 1.0336e+02,\n",
      "         1.0336e+02, 1.0000e-01, 1.0000e-01, 1.0325e+02, 1.0334e+02, 1.0336e+02,\n",
      "         1.0000e-01, 1.0334e+02, 1.0336e+02, 1.0000e-01, 1.0325e+02, 1.0336e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 904 was 99.2%\n",
      "current params: tensor([103.2495, 103.3428, 103.2896, 103.3595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.9\n",
      "SLow rates:  tensor([[1.0335e+02, 1.0344e+02, 1.0339e+02, 1.0346e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0335e+02, 1.0335e+02, 1.0335e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0344e+02, 1.0344e+02, 1.0344e+02, 1.0000e-01, 1.0000e-01, 1.0344e+02,\n",
      "         1.0344e+02, 1.0000e-01, 1.0339e+02, 1.0339e+02, 1.0339e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0339e+02, 1.0339e+02, 1.0000e-01, 1.0339e+02, 1.0000e-01,\n",
      "         1.0339e+02, 1.0346e+02, 1.0346e+02, 1.0346e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0346e+02, 1.0346e+02, 1.0000e-01, 1.0346e+02, 1.0000e-01, 1.0346e+02,\n",
      "         1.0344e+02, 1.0346e+02, 1.0346e+02, 1.0346e+02, 1.0339e+02, 1.0346e+02,\n",
      "         1.0346e+02, 1.0346e+02, 1.0344e+02, 1.0346e+02, 1.0346e+02, 1.0346e+02,\n",
      "         1.0344e+02, 1.0339e+02, 1.0344e+02, 1.0344e+02, 1.0344e+02, 1.0000e-01,\n",
      "         1.0344e+02, 1.0339e+02, 1.0000e-01, 1.0339e+02, 1.0346e+02, 1.0000e-01,\n",
      "         1.0346e+02, 1.0346e+02, 1.0346e+02, 1.0344e+02, 1.0344e+02, 1.0000e-01,\n",
      "         1.0346e+02, 1.0000e-01, 1.0335e+02, 1.0335e+02, 1.0344e+02, 1.0346e+02,\n",
      "         1.0346e+02, 1.0000e-01, 1.0000e-01, 1.0335e+02, 1.0344e+02, 1.0346e+02,\n",
      "         1.0000e-01, 1.0344e+02, 1.0346e+02, 1.0000e-01, 1.0335e+02, 1.0346e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 905 was 99.2%\n",
      "current params: tensor([103.3495, 103.4428, 103.3896, 103.4595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  22.9\n",
      "SLow rates:  tensor([[1.0345e+02, 1.0354e+02, 1.0349e+02, 1.0356e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0345e+02, 1.0345e+02, 1.0345e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0354e+02, 1.0354e+02, 1.0354e+02, 1.0000e-01, 1.0000e-01, 1.0354e+02,\n",
      "         1.0354e+02, 1.0000e-01, 1.0349e+02, 1.0349e+02, 1.0349e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0349e+02, 1.0349e+02, 1.0000e-01, 1.0349e+02, 1.0000e-01,\n",
      "         1.0349e+02, 1.0356e+02, 1.0356e+02, 1.0356e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0356e+02, 1.0356e+02, 1.0000e-01, 1.0356e+02, 1.0000e-01, 1.0356e+02,\n",
      "         1.0354e+02, 1.0356e+02, 1.0356e+02, 1.0356e+02, 1.0349e+02, 1.0356e+02,\n",
      "         1.0356e+02, 1.0356e+02, 1.0354e+02, 1.0356e+02, 1.0356e+02, 1.0356e+02,\n",
      "         1.0354e+02, 1.0349e+02, 1.0354e+02, 1.0354e+02, 1.0354e+02, 1.0000e-01,\n",
      "         1.0354e+02, 1.0349e+02, 1.0000e-01, 1.0349e+02, 1.0356e+02, 1.0000e-01,\n",
      "         1.0356e+02, 1.0356e+02, 1.0356e+02, 1.0354e+02, 1.0354e+02, 1.0000e-01,\n",
      "         1.0356e+02, 1.0000e-01, 1.0345e+02, 1.0345e+02, 1.0354e+02, 1.0356e+02,\n",
      "         1.0356e+02, 1.0000e-01, 1.0000e-01, 1.0345e+02, 1.0354e+02, 1.0356e+02,\n",
      "         1.0000e-01, 1.0354e+02, 1.0356e+02, 1.0000e-01, 1.0345e+02, 1.0356e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 906 was 99.2%\n",
      "current params: tensor([103.4495, 103.5428, 103.4896, 103.5595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.0\n",
      "SLow rates:  tensor([[1.0355e+02, 1.0364e+02, 1.0359e+02, 1.0366e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0355e+02, 1.0355e+02, 1.0355e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0364e+02, 1.0364e+02, 1.0364e+02, 1.0000e-01, 1.0000e-01, 1.0364e+02,\n",
      "         1.0364e+02, 1.0000e-01, 1.0359e+02, 1.0359e+02, 1.0359e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0359e+02, 1.0359e+02, 1.0000e-01, 1.0359e+02, 1.0000e-01,\n",
      "         1.0359e+02, 1.0366e+02, 1.0366e+02, 1.0366e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0366e+02, 1.0366e+02, 1.0000e-01, 1.0366e+02, 1.0000e-01, 1.0366e+02,\n",
      "         1.0364e+02, 1.0366e+02, 1.0366e+02, 1.0366e+02, 1.0359e+02, 1.0366e+02,\n",
      "         1.0366e+02, 1.0366e+02, 1.0364e+02, 1.0366e+02, 1.0366e+02, 1.0366e+02,\n",
      "         1.0364e+02, 1.0359e+02, 1.0364e+02, 1.0364e+02, 1.0364e+02, 1.0000e-01,\n",
      "         1.0364e+02, 1.0359e+02, 1.0000e-01, 1.0359e+02, 1.0366e+02, 1.0000e-01,\n",
      "         1.0366e+02, 1.0366e+02, 1.0366e+02, 1.0364e+02, 1.0364e+02, 1.0000e-01,\n",
      "         1.0366e+02, 1.0000e-01, 1.0355e+02, 1.0355e+02, 1.0364e+02, 1.0366e+02,\n",
      "         1.0366e+02, 1.0000e-01, 1.0000e-01, 1.0355e+02, 1.0364e+02, 1.0366e+02,\n",
      "         1.0000e-01, 1.0364e+02, 1.0366e+02, 1.0000e-01, 1.0355e+02, 1.0366e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 907 was 99.2%\n",
      "current params: tensor([103.5495, 103.6428, 103.5896, 103.6595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.0\n",
      "SLow rates:  tensor([[1.0365e+02, 1.0374e+02, 1.0369e+02, 1.0376e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0365e+02, 1.0365e+02, 1.0365e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0374e+02, 1.0374e+02, 1.0374e+02, 1.0000e-01, 1.0000e-01, 1.0374e+02,\n",
      "         1.0374e+02, 1.0000e-01, 1.0369e+02, 1.0369e+02, 1.0369e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0369e+02, 1.0369e+02, 1.0000e-01, 1.0369e+02, 1.0000e-01,\n",
      "         1.0369e+02, 1.0376e+02, 1.0376e+02, 1.0376e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0376e+02, 1.0376e+02, 1.0000e-01, 1.0376e+02, 1.0000e-01, 1.0376e+02,\n",
      "         1.0374e+02, 1.0376e+02, 1.0376e+02, 1.0376e+02, 1.0369e+02, 1.0376e+02,\n",
      "         1.0376e+02, 1.0376e+02, 1.0374e+02, 1.0376e+02, 1.0376e+02, 1.0376e+02,\n",
      "         1.0374e+02, 1.0369e+02, 1.0374e+02, 1.0374e+02, 1.0374e+02, 1.0000e-01,\n",
      "         1.0374e+02, 1.0369e+02, 1.0000e-01, 1.0369e+02, 1.0376e+02, 1.0000e-01,\n",
      "         1.0376e+02, 1.0376e+02, 1.0376e+02, 1.0374e+02, 1.0374e+02, 1.0000e-01,\n",
      "         1.0376e+02, 1.0000e-01, 1.0365e+02, 1.0365e+02, 1.0374e+02, 1.0376e+02,\n",
      "         1.0376e+02, 1.0000e-01, 1.0000e-01, 1.0365e+02, 1.0374e+02, 1.0376e+02,\n",
      "         1.0000e-01, 1.0374e+02, 1.0376e+02, 1.0000e-01, 1.0365e+02, 1.0376e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 908 was 99.2%\n",
      "current params: tensor([103.6495, 103.7428, 103.6896, 103.7595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.0\n",
      "SLow rates:  tensor([[1.0375e+02, 1.0384e+02, 1.0379e+02, 1.0386e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0375e+02, 1.0375e+02, 1.0375e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0384e+02, 1.0384e+02, 1.0384e+02, 1.0000e-01, 1.0000e-01, 1.0384e+02,\n",
      "         1.0384e+02, 1.0000e-01, 1.0379e+02, 1.0379e+02, 1.0379e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0379e+02, 1.0379e+02, 1.0000e-01, 1.0379e+02, 1.0000e-01,\n",
      "         1.0379e+02, 1.0386e+02, 1.0386e+02, 1.0386e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0386e+02, 1.0386e+02, 1.0000e-01, 1.0386e+02, 1.0000e-01, 1.0386e+02,\n",
      "         1.0384e+02, 1.0386e+02, 1.0386e+02, 1.0386e+02, 1.0379e+02, 1.0386e+02,\n",
      "         1.0386e+02, 1.0386e+02, 1.0384e+02, 1.0386e+02, 1.0386e+02, 1.0386e+02,\n",
      "         1.0384e+02, 1.0379e+02, 1.0384e+02, 1.0384e+02, 1.0384e+02, 1.0000e-01,\n",
      "         1.0384e+02, 1.0379e+02, 1.0000e-01, 1.0379e+02, 1.0386e+02, 1.0000e-01,\n",
      "         1.0386e+02, 1.0386e+02, 1.0386e+02, 1.0384e+02, 1.0384e+02, 1.0000e-01,\n",
      "         1.0386e+02, 1.0000e-01, 1.0375e+02, 1.0375e+02, 1.0384e+02, 1.0386e+02,\n",
      "         1.0386e+02, 1.0000e-01, 1.0000e-01, 1.0375e+02, 1.0384e+02, 1.0386e+02,\n",
      "         1.0000e-01, 1.0384e+02, 1.0386e+02, 1.0000e-01, 1.0375e+02, 1.0386e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 909 was 99.2%\n",
      "current params: tensor([103.7495, 103.8428, 103.7896, 103.8595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.0\n",
      "SLow rates:  tensor([[1.0385e+02, 1.0394e+02, 1.0389e+02, 1.0396e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0385e+02, 1.0385e+02, 1.0385e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0394e+02, 1.0394e+02, 1.0394e+02, 1.0000e-01, 1.0000e-01, 1.0394e+02,\n",
      "         1.0394e+02, 1.0000e-01, 1.0389e+02, 1.0389e+02, 1.0389e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0389e+02, 1.0389e+02, 1.0000e-01, 1.0389e+02, 1.0000e-01,\n",
      "         1.0389e+02, 1.0396e+02, 1.0396e+02, 1.0396e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0396e+02, 1.0396e+02, 1.0000e-01, 1.0396e+02, 1.0000e-01, 1.0396e+02,\n",
      "         1.0394e+02, 1.0396e+02, 1.0396e+02, 1.0396e+02, 1.0389e+02, 1.0396e+02,\n",
      "         1.0396e+02, 1.0396e+02, 1.0394e+02, 1.0396e+02, 1.0396e+02, 1.0396e+02,\n",
      "         1.0394e+02, 1.0389e+02, 1.0394e+02, 1.0394e+02, 1.0394e+02, 1.0000e-01,\n",
      "         1.0394e+02, 1.0389e+02, 1.0000e-01, 1.0389e+02, 1.0396e+02, 1.0000e-01,\n",
      "         1.0396e+02, 1.0396e+02, 1.0396e+02, 1.0394e+02, 1.0394e+02, 1.0000e-01,\n",
      "         1.0396e+02, 1.0000e-01, 1.0385e+02, 1.0385e+02, 1.0394e+02, 1.0396e+02,\n",
      "         1.0396e+02, 1.0000e-01, 1.0000e-01, 1.0385e+02, 1.0394e+02, 1.0396e+02,\n",
      "         1.0000e-01, 1.0394e+02, 1.0396e+02, 1.0000e-01, 1.0385e+02, 1.0396e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0438, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 910 was 99.2%\n",
      "current params: tensor([103.8495, 103.9428, 103.8896, 103.9595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.0\n",
      "SLow rates:  tensor([[1.0395e+02, 1.0404e+02, 1.0399e+02, 1.0406e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0395e+02, 1.0395e+02, 1.0395e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0404e+02, 1.0404e+02, 1.0404e+02, 1.0000e-01, 1.0000e-01, 1.0404e+02,\n",
      "         1.0404e+02, 1.0000e-01, 1.0399e+02, 1.0399e+02, 1.0399e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0399e+02, 1.0399e+02, 1.0000e-01, 1.0399e+02, 1.0000e-01,\n",
      "         1.0399e+02, 1.0406e+02, 1.0406e+02, 1.0406e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0406e+02, 1.0406e+02, 1.0000e-01, 1.0406e+02, 1.0000e-01, 1.0406e+02,\n",
      "         1.0404e+02, 1.0406e+02, 1.0406e+02, 1.0406e+02, 1.0399e+02, 1.0406e+02,\n",
      "         1.0406e+02, 1.0406e+02, 1.0404e+02, 1.0406e+02, 1.0406e+02, 1.0406e+02,\n",
      "         1.0404e+02, 1.0399e+02, 1.0404e+02, 1.0404e+02, 1.0404e+02, 1.0000e-01,\n",
      "         1.0404e+02, 1.0399e+02, 1.0000e-01, 1.0399e+02, 1.0406e+02, 1.0000e-01,\n",
      "         1.0406e+02, 1.0406e+02, 1.0406e+02, 1.0404e+02, 1.0404e+02, 1.0000e-01,\n",
      "         1.0406e+02, 1.0000e-01, 1.0395e+02, 1.0395e+02, 1.0404e+02, 1.0406e+02,\n",
      "         1.0406e+02, 1.0000e-01, 1.0000e-01, 1.0395e+02, 1.0404e+02, 1.0406e+02,\n",
      "         1.0000e-01, 1.0404e+02, 1.0406e+02, 1.0000e-01, 1.0395e+02, 1.0406e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 911 was 99.2%\n",
      "current params: tensor([103.9495, 104.0428, 103.9896, 104.0595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.1\n",
      "SLow rates:  tensor([[1.0405e+02, 1.0414e+02, 1.0409e+02, 1.0416e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0405e+02, 1.0405e+02, 1.0405e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0414e+02, 1.0414e+02, 1.0414e+02, 1.0000e-01, 1.0000e-01, 1.0414e+02,\n",
      "         1.0414e+02, 1.0000e-01, 1.0409e+02, 1.0409e+02, 1.0409e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0409e+02, 1.0409e+02, 1.0000e-01, 1.0409e+02, 1.0000e-01,\n",
      "         1.0409e+02, 1.0416e+02, 1.0416e+02, 1.0416e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0416e+02, 1.0416e+02, 1.0000e-01, 1.0416e+02, 1.0000e-01, 1.0416e+02,\n",
      "         1.0414e+02, 1.0416e+02, 1.0416e+02, 1.0416e+02, 1.0409e+02, 1.0416e+02,\n",
      "         1.0416e+02, 1.0416e+02, 1.0414e+02, 1.0416e+02, 1.0416e+02, 1.0416e+02,\n",
      "         1.0414e+02, 1.0409e+02, 1.0414e+02, 1.0414e+02, 1.0414e+02, 1.0000e-01,\n",
      "         1.0414e+02, 1.0409e+02, 1.0000e-01, 1.0409e+02, 1.0416e+02, 1.0000e-01,\n",
      "         1.0416e+02, 1.0416e+02, 1.0416e+02, 1.0414e+02, 1.0414e+02, 1.0000e-01,\n",
      "         1.0416e+02, 1.0000e-01, 1.0405e+02, 1.0405e+02, 1.0414e+02, 1.0416e+02,\n",
      "         1.0416e+02, 1.0000e-01, 1.0000e-01, 1.0405e+02, 1.0414e+02, 1.0416e+02,\n",
      "         1.0000e-01, 1.0414e+02, 1.0416e+02, 1.0000e-01, 1.0405e+02, 1.0416e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 912 was 99.2%\n",
      "current params: tensor([104.0495, 104.1428, 104.0896, 104.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.1\n",
      "SLow rates:  tensor([[1.0415e+02, 1.0424e+02, 1.0419e+02, 1.0426e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0415e+02, 1.0415e+02, 1.0415e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0424e+02, 1.0424e+02, 1.0424e+02, 1.0000e-01, 1.0000e-01, 1.0424e+02,\n",
      "         1.0424e+02, 1.0000e-01, 1.0419e+02, 1.0419e+02, 1.0419e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0419e+02, 1.0419e+02, 1.0000e-01, 1.0419e+02, 1.0000e-01,\n",
      "         1.0419e+02, 1.0426e+02, 1.0426e+02, 1.0426e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0426e+02, 1.0426e+02, 1.0000e-01, 1.0426e+02, 1.0000e-01, 1.0426e+02,\n",
      "         1.0424e+02, 1.0426e+02, 1.0426e+02, 1.0426e+02, 1.0419e+02, 1.0426e+02,\n",
      "         1.0426e+02, 1.0426e+02, 1.0424e+02, 1.0426e+02, 1.0426e+02, 1.0426e+02,\n",
      "         1.0424e+02, 1.0419e+02, 1.0424e+02, 1.0424e+02, 1.0424e+02, 1.0000e-01,\n",
      "         1.0424e+02, 1.0419e+02, 1.0000e-01, 1.0419e+02, 1.0426e+02, 1.0000e-01,\n",
      "         1.0426e+02, 1.0426e+02, 1.0426e+02, 1.0424e+02, 1.0424e+02, 1.0000e-01,\n",
      "         1.0426e+02, 1.0000e-01, 1.0415e+02, 1.0415e+02, 1.0424e+02, 1.0426e+02,\n",
      "         1.0426e+02, 1.0000e-01, 1.0000e-01, 1.0415e+02, 1.0424e+02, 1.0426e+02,\n",
      "         1.0000e-01, 1.0424e+02, 1.0426e+02, 1.0000e-01, 1.0415e+02, 1.0426e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 913 was 99.2%\n",
      "current params: tensor([104.1495, 104.2428, 104.1897, 104.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.1\n",
      "SLow rates:  tensor([[1.0425e+02, 1.0434e+02, 1.0429e+02, 1.0436e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0425e+02, 1.0425e+02, 1.0425e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0434e+02, 1.0434e+02, 1.0434e+02, 1.0000e-01, 1.0000e-01, 1.0434e+02,\n",
      "         1.0434e+02, 1.0000e-01, 1.0429e+02, 1.0429e+02, 1.0429e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0429e+02, 1.0429e+02, 1.0000e-01, 1.0429e+02, 1.0000e-01,\n",
      "         1.0429e+02, 1.0436e+02, 1.0436e+02, 1.0436e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0436e+02, 1.0436e+02, 1.0000e-01, 1.0436e+02, 1.0000e-01, 1.0436e+02,\n",
      "         1.0434e+02, 1.0436e+02, 1.0436e+02, 1.0436e+02, 1.0429e+02, 1.0436e+02,\n",
      "         1.0436e+02, 1.0436e+02, 1.0434e+02, 1.0436e+02, 1.0436e+02, 1.0436e+02,\n",
      "         1.0434e+02, 1.0429e+02, 1.0434e+02, 1.0434e+02, 1.0434e+02, 1.0000e-01,\n",
      "         1.0434e+02, 1.0429e+02, 1.0000e-01, 1.0429e+02, 1.0436e+02, 1.0000e-01,\n",
      "         1.0436e+02, 1.0436e+02, 1.0436e+02, 1.0434e+02, 1.0434e+02, 1.0000e-01,\n",
      "         1.0436e+02, 1.0000e-01, 1.0425e+02, 1.0425e+02, 1.0434e+02, 1.0436e+02,\n",
      "         1.0436e+02, 1.0000e-01, 1.0000e-01, 1.0425e+02, 1.0434e+02, 1.0436e+02,\n",
      "         1.0000e-01, 1.0434e+02, 1.0436e+02, 1.0000e-01, 1.0425e+02, 1.0436e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 914 was 99.2%\n",
      "current params: tensor([104.2495, 104.3428, 104.2897, 104.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.1\n",
      "SLow rates:  tensor([[1.0435e+02, 1.0444e+02, 1.0439e+02, 1.0446e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0435e+02, 1.0435e+02, 1.0435e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0444e+02, 1.0444e+02, 1.0444e+02, 1.0000e-01, 1.0000e-01, 1.0444e+02,\n",
      "         1.0444e+02, 1.0000e-01, 1.0439e+02, 1.0439e+02, 1.0439e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0439e+02, 1.0439e+02, 1.0000e-01, 1.0439e+02, 1.0000e-01,\n",
      "         1.0439e+02, 1.0446e+02, 1.0446e+02, 1.0446e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0446e+02, 1.0446e+02, 1.0000e-01, 1.0446e+02, 1.0000e-01, 1.0446e+02,\n",
      "         1.0444e+02, 1.0446e+02, 1.0446e+02, 1.0446e+02, 1.0439e+02, 1.0446e+02,\n",
      "         1.0446e+02, 1.0446e+02, 1.0444e+02, 1.0446e+02, 1.0446e+02, 1.0446e+02,\n",
      "         1.0444e+02, 1.0439e+02, 1.0444e+02, 1.0444e+02, 1.0444e+02, 1.0000e-01,\n",
      "         1.0444e+02, 1.0439e+02, 1.0000e-01, 1.0439e+02, 1.0446e+02, 1.0000e-01,\n",
      "         1.0446e+02, 1.0446e+02, 1.0446e+02, 1.0444e+02, 1.0444e+02, 1.0000e-01,\n",
      "         1.0446e+02, 1.0000e-01, 1.0435e+02, 1.0435e+02, 1.0444e+02, 1.0446e+02,\n",
      "         1.0446e+02, 1.0000e-01, 1.0000e-01, 1.0435e+02, 1.0444e+02, 1.0446e+02,\n",
      "         1.0000e-01, 1.0444e+02, 1.0446e+02, 1.0000e-01, 1.0435e+02, 1.0446e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 915 was 99.2%\n",
      "current params: tensor([104.3495, 104.4428, 104.3897, 104.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.1\n",
      "SLow rates:  tensor([[1.0445e+02, 1.0454e+02, 1.0449e+02, 1.0456e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0445e+02, 1.0445e+02, 1.0445e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0454e+02, 1.0454e+02, 1.0454e+02, 1.0000e-01, 1.0000e-01, 1.0454e+02,\n",
      "         1.0454e+02, 1.0000e-01, 1.0449e+02, 1.0449e+02, 1.0449e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0449e+02, 1.0449e+02, 1.0000e-01, 1.0449e+02, 1.0000e-01,\n",
      "         1.0449e+02, 1.0456e+02, 1.0456e+02, 1.0456e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0456e+02, 1.0456e+02, 1.0000e-01, 1.0456e+02, 1.0000e-01, 1.0456e+02,\n",
      "         1.0454e+02, 1.0456e+02, 1.0456e+02, 1.0456e+02, 1.0449e+02, 1.0456e+02,\n",
      "         1.0456e+02, 1.0456e+02, 1.0454e+02, 1.0456e+02, 1.0456e+02, 1.0456e+02,\n",
      "         1.0454e+02, 1.0449e+02, 1.0454e+02, 1.0454e+02, 1.0454e+02, 1.0000e-01,\n",
      "         1.0454e+02, 1.0449e+02, 1.0000e-01, 1.0449e+02, 1.0456e+02, 1.0000e-01,\n",
      "         1.0456e+02, 1.0456e+02, 1.0456e+02, 1.0454e+02, 1.0454e+02, 1.0000e-01,\n",
      "         1.0456e+02, 1.0000e-01, 1.0445e+02, 1.0445e+02, 1.0454e+02, 1.0456e+02,\n",
      "         1.0456e+02, 1.0000e-01, 1.0000e-01, 1.0445e+02, 1.0454e+02, 1.0456e+02,\n",
      "         1.0000e-01, 1.0454e+02, 1.0456e+02, 1.0000e-01, 1.0445e+02, 1.0456e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 916 was 99.2%\n",
      "current params: tensor([104.4495, 104.5428, 104.4897, 104.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.1\n",
      "SLow rates:  tensor([[1.0455e+02, 1.0464e+02, 1.0459e+02, 1.0466e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0455e+02, 1.0455e+02, 1.0455e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0464e+02, 1.0464e+02, 1.0464e+02, 1.0000e-01, 1.0000e-01, 1.0464e+02,\n",
      "         1.0464e+02, 1.0000e-01, 1.0459e+02, 1.0459e+02, 1.0459e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0459e+02, 1.0459e+02, 1.0000e-01, 1.0459e+02, 1.0000e-01,\n",
      "         1.0459e+02, 1.0466e+02, 1.0466e+02, 1.0466e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0466e+02, 1.0466e+02, 1.0000e-01, 1.0466e+02, 1.0000e-01, 1.0466e+02,\n",
      "         1.0464e+02, 1.0466e+02, 1.0466e+02, 1.0466e+02, 1.0459e+02, 1.0466e+02,\n",
      "         1.0466e+02, 1.0466e+02, 1.0464e+02, 1.0466e+02, 1.0466e+02, 1.0466e+02,\n",
      "         1.0464e+02, 1.0459e+02, 1.0464e+02, 1.0464e+02, 1.0464e+02, 1.0000e-01,\n",
      "         1.0464e+02, 1.0459e+02, 1.0000e-01, 1.0459e+02, 1.0466e+02, 1.0000e-01,\n",
      "         1.0466e+02, 1.0466e+02, 1.0466e+02, 1.0464e+02, 1.0464e+02, 1.0000e-01,\n",
      "         1.0466e+02, 1.0000e-01, 1.0455e+02, 1.0455e+02, 1.0464e+02, 1.0466e+02,\n",
      "         1.0466e+02, 1.0000e-01, 1.0000e-01, 1.0455e+02, 1.0464e+02, 1.0466e+02,\n",
      "         1.0000e-01, 1.0464e+02, 1.0466e+02, 1.0000e-01, 1.0455e+02, 1.0466e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 917 was 99.2%\n",
      "current params: tensor([104.5495, 104.6428, 104.5897, 104.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.2\n",
      "SLow rates:  tensor([[1.0465e+02, 1.0474e+02, 1.0469e+02, 1.0476e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0465e+02, 1.0465e+02, 1.0465e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0474e+02, 1.0474e+02, 1.0474e+02, 1.0000e-01, 1.0000e-01, 1.0474e+02,\n",
      "         1.0474e+02, 1.0000e-01, 1.0469e+02, 1.0469e+02, 1.0469e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0469e+02, 1.0469e+02, 1.0000e-01, 1.0469e+02, 1.0000e-01,\n",
      "         1.0469e+02, 1.0476e+02, 1.0476e+02, 1.0476e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0476e+02, 1.0476e+02, 1.0000e-01, 1.0476e+02, 1.0000e-01, 1.0476e+02,\n",
      "         1.0474e+02, 1.0476e+02, 1.0476e+02, 1.0476e+02, 1.0469e+02, 1.0476e+02,\n",
      "         1.0476e+02, 1.0476e+02, 1.0474e+02, 1.0476e+02, 1.0476e+02, 1.0476e+02,\n",
      "         1.0474e+02, 1.0469e+02, 1.0474e+02, 1.0474e+02, 1.0474e+02, 1.0000e-01,\n",
      "         1.0474e+02, 1.0469e+02, 1.0000e-01, 1.0469e+02, 1.0476e+02, 1.0000e-01,\n",
      "         1.0476e+02, 1.0476e+02, 1.0476e+02, 1.0474e+02, 1.0474e+02, 1.0000e-01,\n",
      "         1.0476e+02, 1.0000e-01, 1.0465e+02, 1.0465e+02, 1.0474e+02, 1.0476e+02,\n",
      "         1.0476e+02, 1.0000e-01, 1.0000e-01, 1.0465e+02, 1.0474e+02, 1.0476e+02,\n",
      "         1.0000e-01, 1.0474e+02, 1.0476e+02, 1.0000e-01, 1.0465e+02, 1.0476e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 918 was 99.2%\n",
      "current params: tensor([104.6495, 104.7428, 104.6897, 104.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.2\n",
      "SLow rates:  tensor([[1.0475e+02, 1.0484e+02, 1.0479e+02, 1.0486e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0475e+02, 1.0475e+02, 1.0475e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0484e+02, 1.0484e+02, 1.0484e+02, 1.0000e-01, 1.0000e-01, 1.0484e+02,\n",
      "         1.0484e+02, 1.0000e-01, 1.0479e+02, 1.0479e+02, 1.0479e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0479e+02, 1.0479e+02, 1.0000e-01, 1.0479e+02, 1.0000e-01,\n",
      "         1.0479e+02, 1.0486e+02, 1.0486e+02, 1.0486e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0486e+02, 1.0486e+02, 1.0000e-01, 1.0486e+02, 1.0000e-01, 1.0486e+02,\n",
      "         1.0484e+02, 1.0486e+02, 1.0486e+02, 1.0486e+02, 1.0479e+02, 1.0486e+02,\n",
      "         1.0486e+02, 1.0486e+02, 1.0484e+02, 1.0486e+02, 1.0486e+02, 1.0486e+02,\n",
      "         1.0484e+02, 1.0479e+02, 1.0484e+02, 1.0484e+02, 1.0484e+02, 1.0000e-01,\n",
      "         1.0484e+02, 1.0479e+02, 1.0000e-01, 1.0479e+02, 1.0486e+02, 1.0000e-01,\n",
      "         1.0486e+02, 1.0486e+02, 1.0486e+02, 1.0484e+02, 1.0484e+02, 1.0000e-01,\n",
      "         1.0486e+02, 1.0000e-01, 1.0475e+02, 1.0475e+02, 1.0484e+02, 1.0486e+02,\n",
      "         1.0486e+02, 1.0000e-01, 1.0000e-01, 1.0475e+02, 1.0484e+02, 1.0486e+02,\n",
      "         1.0000e-01, 1.0484e+02, 1.0486e+02, 1.0000e-01, 1.0475e+02, 1.0486e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 919 was 99.2%\n",
      "current params: tensor([104.7495, 104.8428, 104.7897, 104.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.2\n",
      "SLow rates:  tensor([[1.0485e+02, 1.0494e+02, 1.0489e+02, 1.0496e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0485e+02, 1.0485e+02, 1.0485e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0494e+02, 1.0494e+02, 1.0494e+02, 1.0000e-01, 1.0000e-01, 1.0494e+02,\n",
      "         1.0494e+02, 1.0000e-01, 1.0489e+02, 1.0489e+02, 1.0489e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0489e+02, 1.0489e+02, 1.0000e-01, 1.0489e+02, 1.0000e-01,\n",
      "         1.0489e+02, 1.0496e+02, 1.0496e+02, 1.0496e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0496e+02, 1.0496e+02, 1.0000e-01, 1.0496e+02, 1.0000e-01, 1.0496e+02,\n",
      "         1.0494e+02, 1.0496e+02, 1.0496e+02, 1.0496e+02, 1.0489e+02, 1.0496e+02,\n",
      "         1.0496e+02, 1.0496e+02, 1.0494e+02, 1.0496e+02, 1.0496e+02, 1.0496e+02,\n",
      "         1.0494e+02, 1.0489e+02, 1.0494e+02, 1.0494e+02, 1.0494e+02, 1.0000e-01,\n",
      "         1.0494e+02, 1.0489e+02, 1.0000e-01, 1.0489e+02, 1.0496e+02, 1.0000e-01,\n",
      "         1.0496e+02, 1.0496e+02, 1.0496e+02, 1.0494e+02, 1.0494e+02, 1.0000e-01,\n",
      "         1.0496e+02, 1.0000e-01, 1.0485e+02, 1.0485e+02, 1.0494e+02, 1.0496e+02,\n",
      "         1.0496e+02, 1.0000e-01, 1.0000e-01, 1.0485e+02, 1.0494e+02, 1.0496e+02,\n",
      "         1.0000e-01, 1.0494e+02, 1.0496e+02, 1.0000e-01, 1.0485e+02, 1.0496e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 920 was 99.2%\n",
      "current params: tensor([104.8496, 104.9428, 104.8897, 104.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.2\n",
      "SLow rates:  tensor([[1.0495e+02, 1.0504e+02, 1.0499e+02, 1.0506e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0495e+02, 1.0495e+02, 1.0495e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0504e+02, 1.0504e+02, 1.0504e+02, 1.0000e-01, 1.0000e-01, 1.0504e+02,\n",
      "         1.0504e+02, 1.0000e-01, 1.0499e+02, 1.0499e+02, 1.0499e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0499e+02, 1.0499e+02, 1.0000e-01, 1.0499e+02, 1.0000e-01,\n",
      "         1.0499e+02, 1.0506e+02, 1.0506e+02, 1.0506e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0506e+02, 1.0506e+02, 1.0000e-01, 1.0506e+02, 1.0000e-01, 1.0506e+02,\n",
      "         1.0504e+02, 1.0506e+02, 1.0506e+02, 1.0506e+02, 1.0499e+02, 1.0506e+02,\n",
      "         1.0506e+02, 1.0506e+02, 1.0504e+02, 1.0506e+02, 1.0506e+02, 1.0506e+02,\n",
      "         1.0504e+02, 1.0499e+02, 1.0504e+02, 1.0504e+02, 1.0504e+02, 1.0000e-01,\n",
      "         1.0504e+02, 1.0499e+02, 1.0000e-01, 1.0499e+02, 1.0506e+02, 1.0000e-01,\n",
      "         1.0506e+02, 1.0506e+02, 1.0506e+02, 1.0504e+02, 1.0504e+02, 1.0000e-01,\n",
      "         1.0506e+02, 1.0000e-01, 1.0495e+02, 1.0495e+02, 1.0504e+02, 1.0506e+02,\n",
      "         1.0506e+02, 1.0000e-01, 1.0000e-01, 1.0495e+02, 1.0504e+02, 1.0506e+02,\n",
      "         1.0000e-01, 1.0504e+02, 1.0506e+02, 1.0000e-01, 1.0495e+02, 1.0506e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 921 was 99.2%\n",
      "current params: tensor([104.9496, 105.0428, 104.9897, 105.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.2\n",
      "SLow rates:  tensor([[1.0505e+02, 1.0514e+02, 1.0509e+02, 1.0516e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0505e+02, 1.0505e+02, 1.0505e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0514e+02, 1.0514e+02, 1.0514e+02, 1.0000e-01, 1.0000e-01, 1.0514e+02,\n",
      "         1.0514e+02, 1.0000e-01, 1.0509e+02, 1.0509e+02, 1.0509e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0509e+02, 1.0509e+02, 1.0000e-01, 1.0509e+02, 1.0000e-01,\n",
      "         1.0509e+02, 1.0516e+02, 1.0516e+02, 1.0516e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0516e+02, 1.0516e+02, 1.0000e-01, 1.0516e+02, 1.0000e-01, 1.0516e+02,\n",
      "         1.0514e+02, 1.0516e+02, 1.0516e+02, 1.0516e+02, 1.0509e+02, 1.0516e+02,\n",
      "         1.0516e+02, 1.0516e+02, 1.0514e+02, 1.0516e+02, 1.0516e+02, 1.0516e+02,\n",
      "         1.0514e+02, 1.0509e+02, 1.0514e+02, 1.0514e+02, 1.0514e+02, 1.0000e-01,\n",
      "         1.0514e+02, 1.0509e+02, 1.0000e-01, 1.0509e+02, 1.0516e+02, 1.0000e-01,\n",
      "         1.0516e+02, 1.0516e+02, 1.0516e+02, 1.0514e+02, 1.0514e+02, 1.0000e-01,\n",
      "         1.0516e+02, 1.0000e-01, 1.0505e+02, 1.0505e+02, 1.0514e+02, 1.0516e+02,\n",
      "         1.0516e+02, 1.0000e-01, 1.0000e-01, 1.0505e+02, 1.0514e+02, 1.0516e+02,\n",
      "         1.0000e-01, 1.0514e+02, 1.0516e+02, 1.0000e-01, 1.0505e+02, 1.0516e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 922 was 99.2%\n",
      "current params: tensor([105.0496, 105.1428, 105.0897, 105.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.3\n",
      "SLow rates:  tensor([[1.0515e+02, 1.0524e+02, 1.0519e+02, 1.0526e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0515e+02, 1.0515e+02, 1.0515e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0524e+02, 1.0524e+02, 1.0524e+02, 1.0000e-01, 1.0000e-01, 1.0524e+02,\n",
      "         1.0524e+02, 1.0000e-01, 1.0519e+02, 1.0519e+02, 1.0519e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0519e+02, 1.0519e+02, 1.0000e-01, 1.0519e+02, 1.0000e-01,\n",
      "         1.0519e+02, 1.0526e+02, 1.0526e+02, 1.0526e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0526e+02, 1.0526e+02, 1.0000e-01, 1.0526e+02, 1.0000e-01, 1.0526e+02,\n",
      "         1.0524e+02, 1.0526e+02, 1.0526e+02, 1.0526e+02, 1.0519e+02, 1.0526e+02,\n",
      "         1.0526e+02, 1.0526e+02, 1.0524e+02, 1.0526e+02, 1.0526e+02, 1.0526e+02,\n",
      "         1.0524e+02, 1.0519e+02, 1.0524e+02, 1.0524e+02, 1.0524e+02, 1.0000e-01,\n",
      "         1.0524e+02, 1.0519e+02, 1.0000e-01, 1.0519e+02, 1.0526e+02, 1.0000e-01,\n",
      "         1.0526e+02, 1.0526e+02, 1.0526e+02, 1.0524e+02, 1.0524e+02, 1.0000e-01,\n",
      "         1.0526e+02, 1.0000e-01, 1.0515e+02, 1.0515e+02, 1.0524e+02, 1.0526e+02,\n",
      "         1.0526e+02, 1.0000e-01, 1.0000e-01, 1.0515e+02, 1.0524e+02, 1.0526e+02,\n",
      "         1.0000e-01, 1.0524e+02, 1.0526e+02, 1.0000e-01, 1.0515e+02, 1.0526e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 923 was 99.2%\n",
      "current params: tensor([105.1496, 105.2428, 105.1897, 105.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.3\n",
      "SLow rates:  tensor([[1.0525e+02, 1.0534e+02, 1.0529e+02, 1.0536e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0525e+02, 1.0525e+02, 1.0525e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0534e+02, 1.0534e+02, 1.0534e+02, 1.0000e-01, 1.0000e-01, 1.0534e+02,\n",
      "         1.0534e+02, 1.0000e-01, 1.0529e+02, 1.0529e+02, 1.0529e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0529e+02, 1.0529e+02, 1.0000e-01, 1.0529e+02, 1.0000e-01,\n",
      "         1.0529e+02, 1.0536e+02, 1.0536e+02, 1.0536e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0536e+02, 1.0536e+02, 1.0000e-01, 1.0536e+02, 1.0000e-01, 1.0536e+02,\n",
      "         1.0534e+02, 1.0536e+02, 1.0536e+02, 1.0536e+02, 1.0529e+02, 1.0536e+02,\n",
      "         1.0536e+02, 1.0536e+02, 1.0534e+02, 1.0536e+02, 1.0536e+02, 1.0536e+02,\n",
      "         1.0534e+02, 1.0529e+02, 1.0534e+02, 1.0534e+02, 1.0534e+02, 1.0000e-01,\n",
      "         1.0534e+02, 1.0529e+02, 1.0000e-01, 1.0529e+02, 1.0536e+02, 1.0000e-01,\n",
      "         1.0536e+02, 1.0536e+02, 1.0536e+02, 1.0534e+02, 1.0534e+02, 1.0000e-01,\n",
      "         1.0536e+02, 1.0000e-01, 1.0525e+02, 1.0525e+02, 1.0534e+02, 1.0536e+02,\n",
      "         1.0536e+02, 1.0000e-01, 1.0000e-01, 1.0525e+02, 1.0534e+02, 1.0536e+02,\n",
      "         1.0000e-01, 1.0534e+02, 1.0536e+02, 1.0000e-01, 1.0525e+02, 1.0536e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 924 was 99.2%\n",
      "current params: tensor([105.2496, 105.3428, 105.2897, 105.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.3\n",
      "SLow rates:  tensor([[1.0535e+02, 1.0544e+02, 1.0539e+02, 1.0546e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0535e+02, 1.0535e+02, 1.0535e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0544e+02, 1.0544e+02, 1.0544e+02, 1.0000e-01, 1.0000e-01, 1.0544e+02,\n",
      "         1.0544e+02, 1.0000e-01, 1.0539e+02, 1.0539e+02, 1.0539e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0539e+02, 1.0539e+02, 1.0000e-01, 1.0539e+02, 1.0000e-01,\n",
      "         1.0539e+02, 1.0546e+02, 1.0546e+02, 1.0546e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0546e+02, 1.0546e+02, 1.0000e-01, 1.0546e+02, 1.0000e-01, 1.0546e+02,\n",
      "         1.0544e+02, 1.0546e+02, 1.0546e+02, 1.0546e+02, 1.0539e+02, 1.0546e+02,\n",
      "         1.0546e+02, 1.0546e+02, 1.0544e+02, 1.0546e+02, 1.0546e+02, 1.0546e+02,\n",
      "         1.0544e+02, 1.0539e+02, 1.0544e+02, 1.0544e+02, 1.0544e+02, 1.0000e-01,\n",
      "         1.0544e+02, 1.0539e+02, 1.0000e-01, 1.0539e+02, 1.0546e+02, 1.0000e-01,\n",
      "         1.0546e+02, 1.0546e+02, 1.0546e+02, 1.0544e+02, 1.0544e+02, 1.0000e-01,\n",
      "         1.0546e+02, 1.0000e-01, 1.0535e+02, 1.0535e+02, 1.0544e+02, 1.0546e+02,\n",
      "         1.0546e+02, 1.0000e-01, 1.0000e-01, 1.0535e+02, 1.0544e+02, 1.0546e+02,\n",
      "         1.0000e-01, 1.0544e+02, 1.0546e+02, 1.0000e-01, 1.0535e+02, 1.0546e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 925 was 99.2%\n",
      "current params: tensor([105.3496, 105.4428, 105.3897, 105.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.3\n",
      "SLow rates:  tensor([[1.0545e+02, 1.0554e+02, 1.0549e+02, 1.0556e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0545e+02, 1.0545e+02, 1.0545e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0554e+02, 1.0554e+02, 1.0554e+02, 1.0000e-01, 1.0000e-01, 1.0554e+02,\n",
      "         1.0554e+02, 1.0000e-01, 1.0549e+02, 1.0549e+02, 1.0549e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0549e+02, 1.0549e+02, 1.0000e-01, 1.0549e+02, 1.0000e-01,\n",
      "         1.0549e+02, 1.0556e+02, 1.0556e+02, 1.0556e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0556e+02, 1.0556e+02, 1.0000e-01, 1.0556e+02, 1.0000e-01, 1.0556e+02,\n",
      "         1.0554e+02, 1.0556e+02, 1.0556e+02, 1.0556e+02, 1.0549e+02, 1.0556e+02,\n",
      "         1.0556e+02, 1.0556e+02, 1.0554e+02, 1.0556e+02, 1.0556e+02, 1.0556e+02,\n",
      "         1.0554e+02, 1.0549e+02, 1.0554e+02, 1.0554e+02, 1.0554e+02, 1.0000e-01,\n",
      "         1.0554e+02, 1.0549e+02, 1.0000e-01, 1.0549e+02, 1.0556e+02, 1.0000e-01,\n",
      "         1.0556e+02, 1.0556e+02, 1.0556e+02, 1.0554e+02, 1.0554e+02, 1.0000e-01,\n",
      "         1.0556e+02, 1.0000e-01, 1.0545e+02, 1.0545e+02, 1.0554e+02, 1.0556e+02,\n",
      "         1.0556e+02, 1.0000e-01, 1.0000e-01, 1.0545e+02, 1.0554e+02, 1.0556e+02,\n",
      "         1.0000e-01, 1.0554e+02, 1.0556e+02, 1.0000e-01, 1.0545e+02, 1.0556e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 926 was 99.2%\n",
      "current params: tensor([105.4496, 105.5428, 105.4897, 105.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.3\n",
      "SLow rates:  tensor([[1.0555e+02, 1.0564e+02, 1.0559e+02, 1.0566e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0555e+02, 1.0555e+02, 1.0555e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0564e+02, 1.0564e+02, 1.0564e+02, 1.0000e-01, 1.0000e-01, 1.0564e+02,\n",
      "         1.0564e+02, 1.0000e-01, 1.0559e+02, 1.0559e+02, 1.0559e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0559e+02, 1.0559e+02, 1.0000e-01, 1.0559e+02, 1.0000e-01,\n",
      "         1.0559e+02, 1.0566e+02, 1.0566e+02, 1.0566e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0566e+02, 1.0566e+02, 1.0000e-01, 1.0566e+02, 1.0000e-01, 1.0566e+02,\n",
      "         1.0564e+02, 1.0566e+02, 1.0566e+02, 1.0566e+02, 1.0559e+02, 1.0566e+02,\n",
      "         1.0566e+02, 1.0566e+02, 1.0564e+02, 1.0566e+02, 1.0566e+02, 1.0566e+02,\n",
      "         1.0564e+02, 1.0559e+02, 1.0564e+02, 1.0564e+02, 1.0564e+02, 1.0000e-01,\n",
      "         1.0564e+02, 1.0559e+02, 1.0000e-01, 1.0559e+02, 1.0566e+02, 1.0000e-01,\n",
      "         1.0566e+02, 1.0566e+02, 1.0566e+02, 1.0564e+02, 1.0564e+02, 1.0000e-01,\n",
      "         1.0566e+02, 1.0000e-01, 1.0555e+02, 1.0555e+02, 1.0564e+02, 1.0566e+02,\n",
      "         1.0566e+02, 1.0000e-01, 1.0000e-01, 1.0555e+02, 1.0564e+02, 1.0566e+02,\n",
      "         1.0000e-01, 1.0564e+02, 1.0566e+02, 1.0000e-01, 1.0555e+02, 1.0566e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 927 was 99.2%\n",
      "current params: tensor([105.5496, 105.6428, 105.5897, 105.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.4\n",
      "SLow rates:  tensor([[1.0565e+02, 1.0574e+02, 1.0569e+02, 1.0576e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0565e+02, 1.0565e+02, 1.0565e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0574e+02, 1.0574e+02, 1.0574e+02, 1.0000e-01, 1.0000e-01, 1.0574e+02,\n",
      "         1.0574e+02, 1.0000e-01, 1.0569e+02, 1.0569e+02, 1.0569e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0569e+02, 1.0569e+02, 1.0000e-01, 1.0569e+02, 1.0000e-01,\n",
      "         1.0569e+02, 1.0576e+02, 1.0576e+02, 1.0576e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0576e+02, 1.0576e+02, 1.0000e-01, 1.0576e+02, 1.0000e-01, 1.0576e+02,\n",
      "         1.0574e+02, 1.0576e+02, 1.0576e+02, 1.0576e+02, 1.0569e+02, 1.0576e+02,\n",
      "         1.0576e+02, 1.0576e+02, 1.0574e+02, 1.0576e+02, 1.0576e+02, 1.0576e+02,\n",
      "         1.0574e+02, 1.0569e+02, 1.0574e+02, 1.0574e+02, 1.0574e+02, 1.0000e-01,\n",
      "         1.0574e+02, 1.0569e+02, 1.0000e-01, 1.0569e+02, 1.0576e+02, 1.0000e-01,\n",
      "         1.0576e+02, 1.0576e+02, 1.0576e+02, 1.0574e+02, 1.0574e+02, 1.0000e-01,\n",
      "         1.0576e+02, 1.0000e-01, 1.0565e+02, 1.0565e+02, 1.0574e+02, 1.0576e+02,\n",
      "         1.0576e+02, 1.0000e-01, 1.0000e-01, 1.0565e+02, 1.0574e+02, 1.0576e+02,\n",
      "         1.0000e-01, 1.0574e+02, 1.0576e+02, 1.0000e-01, 1.0565e+02, 1.0576e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 928 was 99.2%\n",
      "current params: tensor([105.6496, 105.7428, 105.6897, 105.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.4\n",
      "SLow rates:  tensor([[1.0575e+02, 1.0584e+02, 1.0579e+02, 1.0586e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0575e+02, 1.0575e+02, 1.0575e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0584e+02, 1.0584e+02, 1.0584e+02, 1.0000e-01, 1.0000e-01, 1.0584e+02,\n",
      "         1.0584e+02, 1.0000e-01, 1.0579e+02, 1.0579e+02, 1.0579e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0579e+02, 1.0579e+02, 1.0000e-01, 1.0579e+02, 1.0000e-01,\n",
      "         1.0579e+02, 1.0586e+02, 1.0586e+02, 1.0586e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0586e+02, 1.0586e+02, 1.0000e-01, 1.0586e+02, 1.0000e-01, 1.0586e+02,\n",
      "         1.0584e+02, 1.0586e+02, 1.0586e+02, 1.0586e+02, 1.0579e+02, 1.0586e+02,\n",
      "         1.0586e+02, 1.0586e+02, 1.0584e+02, 1.0586e+02, 1.0586e+02, 1.0586e+02,\n",
      "         1.0584e+02, 1.0579e+02, 1.0584e+02, 1.0584e+02, 1.0584e+02, 1.0000e-01,\n",
      "         1.0584e+02, 1.0579e+02, 1.0000e-01, 1.0579e+02, 1.0586e+02, 1.0000e-01,\n",
      "         1.0586e+02, 1.0586e+02, 1.0586e+02, 1.0584e+02, 1.0584e+02, 1.0000e-01,\n",
      "         1.0586e+02, 1.0000e-01, 1.0575e+02, 1.0575e+02, 1.0584e+02, 1.0586e+02,\n",
      "         1.0586e+02, 1.0000e-01, 1.0000e-01, 1.0575e+02, 1.0584e+02, 1.0586e+02,\n",
      "         1.0000e-01, 1.0584e+02, 1.0586e+02, 1.0000e-01, 1.0575e+02, 1.0586e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 929 was 99.2%\n",
      "current params: tensor([105.7496, 105.8428, 105.7897, 105.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.4\n",
      "SLow rates:  tensor([[1.0585e+02, 1.0594e+02, 1.0589e+02, 1.0596e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0585e+02, 1.0585e+02, 1.0585e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0594e+02, 1.0594e+02, 1.0594e+02, 1.0000e-01, 1.0000e-01, 1.0594e+02,\n",
      "         1.0594e+02, 1.0000e-01, 1.0589e+02, 1.0589e+02, 1.0589e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0589e+02, 1.0589e+02, 1.0000e-01, 1.0589e+02, 1.0000e-01,\n",
      "         1.0589e+02, 1.0596e+02, 1.0596e+02, 1.0596e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0596e+02, 1.0596e+02, 1.0000e-01, 1.0596e+02, 1.0000e-01, 1.0596e+02,\n",
      "         1.0594e+02, 1.0596e+02, 1.0596e+02, 1.0596e+02, 1.0589e+02, 1.0596e+02,\n",
      "         1.0596e+02, 1.0596e+02, 1.0594e+02, 1.0596e+02, 1.0596e+02, 1.0596e+02,\n",
      "         1.0594e+02, 1.0589e+02, 1.0594e+02, 1.0594e+02, 1.0594e+02, 1.0000e-01,\n",
      "         1.0594e+02, 1.0589e+02, 1.0000e-01, 1.0589e+02, 1.0596e+02, 1.0000e-01,\n",
      "         1.0596e+02, 1.0596e+02, 1.0596e+02, 1.0594e+02, 1.0594e+02, 1.0000e-01,\n",
      "         1.0596e+02, 1.0000e-01, 1.0585e+02, 1.0585e+02, 1.0594e+02, 1.0596e+02,\n",
      "         1.0596e+02, 1.0000e-01, 1.0000e-01, 1.0585e+02, 1.0594e+02, 1.0596e+02,\n",
      "         1.0000e-01, 1.0594e+02, 1.0596e+02, 1.0000e-01, 1.0585e+02, 1.0596e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 930 was 99.2%\n",
      "current params: tensor([105.8496, 105.9428, 105.8897, 105.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.4\n",
      "SLow rates:  tensor([[1.0595e+02, 1.0604e+02, 1.0599e+02, 1.0606e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0595e+02, 1.0595e+02, 1.0595e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0604e+02, 1.0604e+02, 1.0604e+02, 1.0000e-01, 1.0000e-01, 1.0604e+02,\n",
      "         1.0604e+02, 1.0000e-01, 1.0599e+02, 1.0599e+02, 1.0599e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0599e+02, 1.0599e+02, 1.0000e-01, 1.0599e+02, 1.0000e-01,\n",
      "         1.0599e+02, 1.0606e+02, 1.0606e+02, 1.0606e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0606e+02, 1.0606e+02, 1.0000e-01, 1.0606e+02, 1.0000e-01, 1.0606e+02,\n",
      "         1.0604e+02, 1.0606e+02, 1.0606e+02, 1.0606e+02, 1.0599e+02, 1.0606e+02,\n",
      "         1.0606e+02, 1.0606e+02, 1.0604e+02, 1.0606e+02, 1.0606e+02, 1.0606e+02,\n",
      "         1.0604e+02, 1.0599e+02, 1.0604e+02, 1.0604e+02, 1.0604e+02, 1.0000e-01,\n",
      "         1.0604e+02, 1.0599e+02, 1.0000e-01, 1.0599e+02, 1.0606e+02, 1.0000e-01,\n",
      "         1.0606e+02, 1.0606e+02, 1.0606e+02, 1.0604e+02, 1.0604e+02, 1.0000e-01,\n",
      "         1.0606e+02, 1.0000e-01, 1.0595e+02, 1.0595e+02, 1.0604e+02, 1.0606e+02,\n",
      "         1.0606e+02, 1.0000e-01, 1.0000e-01, 1.0595e+02, 1.0604e+02, 1.0606e+02,\n",
      "         1.0000e-01, 1.0604e+02, 1.0606e+02, 1.0000e-01, 1.0595e+02, 1.0606e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 931 was 99.2%\n",
      "current params: tensor([105.9496, 106.0428, 105.9897, 106.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.4\n",
      "SLow rates:  tensor([[1.0605e+02, 1.0614e+02, 1.0609e+02, 1.0616e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0605e+02, 1.0605e+02, 1.0605e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0614e+02, 1.0614e+02, 1.0614e+02, 1.0000e-01, 1.0000e-01, 1.0614e+02,\n",
      "         1.0614e+02, 1.0000e-01, 1.0609e+02, 1.0609e+02, 1.0609e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0609e+02, 1.0609e+02, 1.0000e-01, 1.0609e+02, 1.0000e-01,\n",
      "         1.0609e+02, 1.0616e+02, 1.0616e+02, 1.0616e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0616e+02, 1.0616e+02, 1.0000e-01, 1.0616e+02, 1.0000e-01, 1.0616e+02,\n",
      "         1.0614e+02, 1.0616e+02, 1.0616e+02, 1.0616e+02, 1.0609e+02, 1.0616e+02,\n",
      "         1.0616e+02, 1.0616e+02, 1.0614e+02, 1.0616e+02, 1.0616e+02, 1.0616e+02,\n",
      "         1.0614e+02, 1.0609e+02, 1.0614e+02, 1.0614e+02, 1.0614e+02, 1.0000e-01,\n",
      "         1.0614e+02, 1.0609e+02, 1.0000e-01, 1.0609e+02, 1.0616e+02, 1.0000e-01,\n",
      "         1.0616e+02, 1.0616e+02, 1.0616e+02, 1.0614e+02, 1.0614e+02, 1.0000e-01,\n",
      "         1.0616e+02, 1.0000e-01, 1.0605e+02, 1.0605e+02, 1.0614e+02, 1.0616e+02,\n",
      "         1.0616e+02, 1.0000e-01, 1.0000e-01, 1.0605e+02, 1.0614e+02, 1.0616e+02,\n",
      "         1.0000e-01, 1.0614e+02, 1.0616e+02, 1.0000e-01, 1.0605e+02, 1.0616e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 932 was 99.2%\n",
      "current params: tensor([106.0496, 106.1428, 106.0897, 106.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.4\n",
      "SLow rates:  tensor([[1.0615e+02, 1.0624e+02, 1.0619e+02, 1.0626e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0615e+02, 1.0615e+02, 1.0615e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0624e+02, 1.0624e+02, 1.0624e+02, 1.0000e-01, 1.0000e-01, 1.0624e+02,\n",
      "         1.0624e+02, 1.0000e-01, 1.0619e+02, 1.0619e+02, 1.0619e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0619e+02, 1.0619e+02, 1.0000e-01, 1.0619e+02, 1.0000e-01,\n",
      "         1.0619e+02, 1.0626e+02, 1.0626e+02, 1.0626e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0626e+02, 1.0626e+02, 1.0000e-01, 1.0626e+02, 1.0000e-01, 1.0626e+02,\n",
      "         1.0624e+02, 1.0626e+02, 1.0626e+02, 1.0626e+02, 1.0619e+02, 1.0626e+02,\n",
      "         1.0626e+02, 1.0626e+02, 1.0624e+02, 1.0626e+02, 1.0626e+02, 1.0626e+02,\n",
      "         1.0624e+02, 1.0619e+02, 1.0624e+02, 1.0624e+02, 1.0624e+02, 1.0000e-01,\n",
      "         1.0624e+02, 1.0619e+02, 1.0000e-01, 1.0619e+02, 1.0626e+02, 1.0000e-01,\n",
      "         1.0626e+02, 1.0626e+02, 1.0626e+02, 1.0624e+02, 1.0624e+02, 1.0000e-01,\n",
      "         1.0626e+02, 1.0000e-01, 1.0615e+02, 1.0615e+02, 1.0624e+02, 1.0626e+02,\n",
      "         1.0626e+02, 1.0000e-01, 1.0000e-01, 1.0615e+02, 1.0624e+02, 1.0626e+02,\n",
      "         1.0000e-01, 1.0624e+02, 1.0626e+02, 1.0000e-01, 1.0615e+02, 1.0626e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 933 was 99.2%\n",
      "current params: tensor([106.1496, 106.2428, 106.1897, 106.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.5\n",
      "SLow rates:  tensor([[1.0625e+02, 1.0634e+02, 1.0629e+02, 1.0636e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0625e+02, 1.0625e+02, 1.0625e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0634e+02, 1.0634e+02, 1.0634e+02, 1.0000e-01, 1.0000e-01, 1.0634e+02,\n",
      "         1.0634e+02, 1.0000e-01, 1.0629e+02, 1.0629e+02, 1.0629e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0629e+02, 1.0629e+02, 1.0000e-01, 1.0629e+02, 1.0000e-01,\n",
      "         1.0629e+02, 1.0636e+02, 1.0636e+02, 1.0636e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0636e+02, 1.0636e+02, 1.0000e-01, 1.0636e+02, 1.0000e-01, 1.0636e+02,\n",
      "         1.0634e+02, 1.0636e+02, 1.0636e+02, 1.0636e+02, 1.0629e+02, 1.0636e+02,\n",
      "         1.0636e+02, 1.0636e+02, 1.0634e+02, 1.0636e+02, 1.0636e+02, 1.0636e+02,\n",
      "         1.0634e+02, 1.0629e+02, 1.0634e+02, 1.0634e+02, 1.0634e+02, 1.0000e-01,\n",
      "         1.0634e+02, 1.0629e+02, 1.0000e-01, 1.0629e+02, 1.0636e+02, 1.0000e-01,\n",
      "         1.0636e+02, 1.0636e+02, 1.0636e+02, 1.0634e+02, 1.0634e+02, 1.0000e-01,\n",
      "         1.0636e+02, 1.0000e-01, 1.0625e+02, 1.0625e+02, 1.0634e+02, 1.0636e+02,\n",
      "         1.0636e+02, 1.0000e-01, 1.0000e-01, 1.0625e+02, 1.0634e+02, 1.0636e+02,\n",
      "         1.0000e-01, 1.0634e+02, 1.0636e+02, 1.0000e-01, 1.0625e+02, 1.0636e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 934 was 99.2%\n",
      "current params: tensor([106.2496, 106.3428, 106.2897, 106.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.5\n",
      "SLow rates:  tensor([[1.0635e+02, 1.0644e+02, 1.0639e+02, 1.0646e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0635e+02, 1.0635e+02, 1.0635e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0644e+02, 1.0644e+02, 1.0644e+02, 1.0000e-01, 1.0000e-01, 1.0644e+02,\n",
      "         1.0644e+02, 1.0000e-01, 1.0639e+02, 1.0639e+02, 1.0639e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0639e+02, 1.0639e+02, 1.0000e-01, 1.0639e+02, 1.0000e-01,\n",
      "         1.0639e+02, 1.0646e+02, 1.0646e+02, 1.0646e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0646e+02, 1.0646e+02, 1.0000e-01, 1.0646e+02, 1.0000e-01, 1.0646e+02,\n",
      "         1.0644e+02, 1.0646e+02, 1.0646e+02, 1.0646e+02, 1.0639e+02, 1.0646e+02,\n",
      "         1.0646e+02, 1.0646e+02, 1.0644e+02, 1.0646e+02, 1.0646e+02, 1.0646e+02,\n",
      "         1.0644e+02, 1.0639e+02, 1.0644e+02, 1.0644e+02, 1.0644e+02, 1.0000e-01,\n",
      "         1.0644e+02, 1.0639e+02, 1.0000e-01, 1.0639e+02, 1.0646e+02, 1.0000e-01,\n",
      "         1.0646e+02, 1.0646e+02, 1.0646e+02, 1.0644e+02, 1.0644e+02, 1.0000e-01,\n",
      "         1.0646e+02, 1.0000e-01, 1.0635e+02, 1.0635e+02, 1.0644e+02, 1.0646e+02,\n",
      "         1.0646e+02, 1.0000e-01, 1.0000e-01, 1.0635e+02, 1.0644e+02, 1.0646e+02,\n",
      "         1.0000e-01, 1.0644e+02, 1.0646e+02, 1.0000e-01, 1.0635e+02, 1.0646e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 935 was 99.2%\n",
      "current params: tensor([106.3496, 106.4428, 106.3897, 106.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.5\n",
      "SLow rates:  tensor([[1.0645e+02, 1.0654e+02, 1.0649e+02, 1.0656e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0645e+02, 1.0645e+02, 1.0645e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0654e+02, 1.0654e+02, 1.0654e+02, 1.0000e-01, 1.0000e-01, 1.0654e+02,\n",
      "         1.0654e+02, 1.0000e-01, 1.0649e+02, 1.0649e+02, 1.0649e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0649e+02, 1.0649e+02, 1.0000e-01, 1.0649e+02, 1.0000e-01,\n",
      "         1.0649e+02, 1.0656e+02, 1.0656e+02, 1.0656e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0656e+02, 1.0656e+02, 1.0000e-01, 1.0656e+02, 1.0000e-01, 1.0656e+02,\n",
      "         1.0654e+02, 1.0656e+02, 1.0656e+02, 1.0656e+02, 1.0649e+02, 1.0656e+02,\n",
      "         1.0656e+02, 1.0656e+02, 1.0654e+02, 1.0656e+02, 1.0656e+02, 1.0656e+02,\n",
      "         1.0654e+02, 1.0649e+02, 1.0654e+02, 1.0654e+02, 1.0654e+02, 1.0000e-01,\n",
      "         1.0654e+02, 1.0649e+02, 1.0000e-01, 1.0649e+02, 1.0656e+02, 1.0000e-01,\n",
      "         1.0656e+02, 1.0656e+02, 1.0656e+02, 1.0654e+02, 1.0654e+02, 1.0000e-01,\n",
      "         1.0656e+02, 1.0000e-01, 1.0645e+02, 1.0645e+02, 1.0654e+02, 1.0656e+02,\n",
      "         1.0656e+02, 1.0000e-01, 1.0000e-01, 1.0645e+02, 1.0654e+02, 1.0656e+02,\n",
      "         1.0000e-01, 1.0654e+02, 1.0656e+02, 1.0000e-01, 1.0645e+02, 1.0656e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 936 was 99.2%\n",
      "current params: tensor([106.4496, 106.5428, 106.4897, 106.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.5\n",
      "SLow rates:  tensor([[1.0655e+02, 1.0664e+02, 1.0659e+02, 1.0666e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0655e+02, 1.0655e+02, 1.0655e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0664e+02, 1.0664e+02, 1.0664e+02, 1.0000e-01, 1.0000e-01, 1.0664e+02,\n",
      "         1.0664e+02, 1.0000e-01, 1.0659e+02, 1.0659e+02, 1.0659e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0659e+02, 1.0659e+02, 1.0000e-01, 1.0659e+02, 1.0000e-01,\n",
      "         1.0659e+02, 1.0666e+02, 1.0666e+02, 1.0666e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0666e+02, 1.0666e+02, 1.0000e-01, 1.0666e+02, 1.0000e-01, 1.0666e+02,\n",
      "         1.0664e+02, 1.0666e+02, 1.0666e+02, 1.0666e+02, 1.0659e+02, 1.0666e+02,\n",
      "         1.0666e+02, 1.0666e+02, 1.0664e+02, 1.0666e+02, 1.0666e+02, 1.0666e+02,\n",
      "         1.0664e+02, 1.0659e+02, 1.0664e+02, 1.0664e+02, 1.0664e+02, 1.0000e-01,\n",
      "         1.0664e+02, 1.0659e+02, 1.0000e-01, 1.0659e+02, 1.0666e+02, 1.0000e-01,\n",
      "         1.0666e+02, 1.0666e+02, 1.0666e+02, 1.0664e+02, 1.0664e+02, 1.0000e-01,\n",
      "         1.0666e+02, 1.0000e-01, 1.0655e+02, 1.0655e+02, 1.0664e+02, 1.0666e+02,\n",
      "         1.0666e+02, 1.0000e-01, 1.0000e-01, 1.0655e+02, 1.0664e+02, 1.0666e+02,\n",
      "         1.0000e-01, 1.0664e+02, 1.0666e+02, 1.0000e-01, 1.0655e+02, 1.0666e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 937 was 99.2%\n",
      "current params: tensor([106.5496, 106.6428, 106.5897, 106.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.5\n",
      "SLow rates:  tensor([[1.0665e+02, 1.0674e+02, 1.0669e+02, 1.0676e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0665e+02, 1.0665e+02, 1.0665e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0674e+02, 1.0674e+02, 1.0674e+02, 1.0000e-01, 1.0000e-01, 1.0674e+02,\n",
      "         1.0674e+02, 1.0000e-01, 1.0669e+02, 1.0669e+02, 1.0669e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0669e+02, 1.0669e+02, 1.0000e-01, 1.0669e+02, 1.0000e-01,\n",
      "         1.0669e+02, 1.0676e+02, 1.0676e+02, 1.0676e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0676e+02, 1.0676e+02, 1.0000e-01, 1.0676e+02, 1.0000e-01, 1.0676e+02,\n",
      "         1.0674e+02, 1.0676e+02, 1.0676e+02, 1.0676e+02, 1.0669e+02, 1.0676e+02,\n",
      "         1.0676e+02, 1.0676e+02, 1.0674e+02, 1.0676e+02, 1.0676e+02, 1.0676e+02,\n",
      "         1.0674e+02, 1.0669e+02, 1.0674e+02, 1.0674e+02, 1.0674e+02, 1.0000e-01,\n",
      "         1.0674e+02, 1.0669e+02, 1.0000e-01, 1.0669e+02, 1.0676e+02, 1.0000e-01,\n",
      "         1.0676e+02, 1.0676e+02, 1.0676e+02, 1.0674e+02, 1.0674e+02, 1.0000e-01,\n",
      "         1.0676e+02, 1.0000e-01, 1.0665e+02, 1.0665e+02, 1.0674e+02, 1.0676e+02,\n",
      "         1.0676e+02, 1.0000e-01, 1.0000e-01, 1.0665e+02, 1.0674e+02, 1.0676e+02,\n",
      "         1.0000e-01, 1.0674e+02, 1.0676e+02, 1.0000e-01, 1.0665e+02, 1.0676e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 938 was 99.2%\n",
      "current params: tensor([106.6496, 106.7428, 106.6897, 106.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.6\n",
      "SLow rates:  tensor([[1.0675e+02, 1.0684e+02, 1.0679e+02, 1.0686e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0675e+02, 1.0675e+02, 1.0675e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0684e+02, 1.0684e+02, 1.0684e+02, 1.0000e-01, 1.0000e-01, 1.0684e+02,\n",
      "         1.0684e+02, 1.0000e-01, 1.0679e+02, 1.0679e+02, 1.0679e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0679e+02, 1.0679e+02, 1.0000e-01, 1.0679e+02, 1.0000e-01,\n",
      "         1.0679e+02, 1.0686e+02, 1.0686e+02, 1.0686e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0686e+02, 1.0686e+02, 1.0000e-01, 1.0686e+02, 1.0000e-01, 1.0686e+02,\n",
      "         1.0684e+02, 1.0686e+02, 1.0686e+02, 1.0686e+02, 1.0679e+02, 1.0686e+02,\n",
      "         1.0686e+02, 1.0686e+02, 1.0684e+02, 1.0686e+02, 1.0686e+02, 1.0686e+02,\n",
      "         1.0684e+02, 1.0679e+02, 1.0684e+02, 1.0684e+02, 1.0684e+02, 1.0000e-01,\n",
      "         1.0684e+02, 1.0679e+02, 1.0000e-01, 1.0679e+02, 1.0686e+02, 1.0000e-01,\n",
      "         1.0686e+02, 1.0686e+02, 1.0686e+02, 1.0684e+02, 1.0684e+02, 1.0000e-01,\n",
      "         1.0686e+02, 1.0000e-01, 1.0675e+02, 1.0675e+02, 1.0684e+02, 1.0686e+02,\n",
      "         1.0686e+02, 1.0000e-01, 1.0000e-01, 1.0675e+02, 1.0684e+02, 1.0686e+02,\n",
      "         1.0000e-01, 1.0684e+02, 1.0686e+02, 1.0000e-01, 1.0675e+02, 1.0686e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 939 was 99.2%\n",
      "current params: tensor([106.7496, 106.8428, 106.7897, 106.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.6\n",
      "SLow rates:  tensor([[1.0685e+02, 1.0694e+02, 1.0689e+02, 1.0696e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0685e+02, 1.0685e+02, 1.0685e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0694e+02, 1.0694e+02, 1.0694e+02, 1.0000e-01, 1.0000e-01, 1.0694e+02,\n",
      "         1.0694e+02, 1.0000e-01, 1.0689e+02, 1.0689e+02, 1.0689e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0689e+02, 1.0689e+02, 1.0000e-01, 1.0689e+02, 1.0000e-01,\n",
      "         1.0689e+02, 1.0696e+02, 1.0696e+02, 1.0696e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0696e+02, 1.0696e+02, 1.0000e-01, 1.0696e+02, 1.0000e-01, 1.0696e+02,\n",
      "         1.0694e+02, 1.0696e+02, 1.0696e+02, 1.0696e+02, 1.0689e+02, 1.0696e+02,\n",
      "         1.0696e+02, 1.0696e+02, 1.0694e+02, 1.0696e+02, 1.0696e+02, 1.0696e+02,\n",
      "         1.0694e+02, 1.0689e+02, 1.0694e+02, 1.0694e+02, 1.0694e+02, 1.0000e-01,\n",
      "         1.0694e+02, 1.0689e+02, 1.0000e-01, 1.0689e+02, 1.0696e+02, 1.0000e-01,\n",
      "         1.0696e+02, 1.0696e+02, 1.0696e+02, 1.0694e+02, 1.0694e+02, 1.0000e-01,\n",
      "         1.0696e+02, 1.0000e-01, 1.0685e+02, 1.0685e+02, 1.0694e+02, 1.0696e+02,\n",
      "         1.0696e+02, 1.0000e-01, 1.0000e-01, 1.0685e+02, 1.0694e+02, 1.0696e+02,\n",
      "         1.0000e-01, 1.0694e+02, 1.0696e+02, 1.0000e-01, 1.0685e+02, 1.0696e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 940 was 99.2%\n",
      "current params: tensor([106.8496, 106.9428, 106.8897, 106.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.6\n",
      "SLow rates:  tensor([[1.0695e+02, 1.0704e+02, 1.0699e+02, 1.0706e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0695e+02, 1.0695e+02, 1.0695e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0704e+02, 1.0704e+02, 1.0704e+02, 1.0000e-01, 1.0000e-01, 1.0704e+02,\n",
      "         1.0704e+02, 1.0000e-01, 1.0699e+02, 1.0699e+02, 1.0699e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0699e+02, 1.0699e+02, 1.0000e-01, 1.0699e+02, 1.0000e-01,\n",
      "         1.0699e+02, 1.0706e+02, 1.0706e+02, 1.0706e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0706e+02, 1.0706e+02, 1.0000e-01, 1.0706e+02, 1.0000e-01, 1.0706e+02,\n",
      "         1.0704e+02, 1.0706e+02, 1.0706e+02, 1.0706e+02, 1.0699e+02, 1.0706e+02,\n",
      "         1.0706e+02, 1.0706e+02, 1.0704e+02, 1.0706e+02, 1.0706e+02, 1.0706e+02,\n",
      "         1.0704e+02, 1.0699e+02, 1.0704e+02, 1.0704e+02, 1.0704e+02, 1.0000e-01,\n",
      "         1.0704e+02, 1.0699e+02, 1.0000e-01, 1.0699e+02, 1.0706e+02, 1.0000e-01,\n",
      "         1.0706e+02, 1.0706e+02, 1.0706e+02, 1.0704e+02, 1.0704e+02, 1.0000e-01,\n",
      "         1.0706e+02, 1.0000e-01, 1.0695e+02, 1.0695e+02, 1.0704e+02, 1.0706e+02,\n",
      "         1.0706e+02, 1.0000e-01, 1.0000e-01, 1.0695e+02, 1.0704e+02, 1.0706e+02,\n",
      "         1.0000e-01, 1.0704e+02, 1.0706e+02, 1.0000e-01, 1.0695e+02, 1.0706e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 941 was 99.2%\n",
      "current params: tensor([106.9496, 107.0428, 106.9897, 107.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.6\n",
      "SLow rates:  tensor([[1.0705e+02, 1.0714e+02, 1.0709e+02, 1.0716e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0705e+02, 1.0705e+02, 1.0705e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0714e+02, 1.0714e+02, 1.0714e+02, 1.0000e-01, 1.0000e-01, 1.0714e+02,\n",
      "         1.0714e+02, 1.0000e-01, 1.0709e+02, 1.0709e+02, 1.0709e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0709e+02, 1.0709e+02, 1.0000e-01, 1.0709e+02, 1.0000e-01,\n",
      "         1.0709e+02, 1.0716e+02, 1.0716e+02, 1.0716e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0716e+02, 1.0716e+02, 1.0000e-01, 1.0716e+02, 1.0000e-01, 1.0716e+02,\n",
      "         1.0714e+02, 1.0716e+02, 1.0716e+02, 1.0716e+02, 1.0709e+02, 1.0716e+02,\n",
      "         1.0716e+02, 1.0716e+02, 1.0714e+02, 1.0716e+02, 1.0716e+02, 1.0716e+02,\n",
      "         1.0714e+02, 1.0709e+02, 1.0714e+02, 1.0714e+02, 1.0714e+02, 1.0000e-01,\n",
      "         1.0714e+02, 1.0709e+02, 1.0000e-01, 1.0709e+02, 1.0716e+02, 1.0000e-01,\n",
      "         1.0716e+02, 1.0716e+02, 1.0716e+02, 1.0714e+02, 1.0714e+02, 1.0000e-01,\n",
      "         1.0716e+02, 1.0000e-01, 1.0705e+02, 1.0705e+02, 1.0714e+02, 1.0716e+02,\n",
      "         1.0716e+02, 1.0000e-01, 1.0000e-01, 1.0705e+02, 1.0714e+02, 1.0716e+02,\n",
      "         1.0000e-01, 1.0714e+02, 1.0716e+02, 1.0000e-01, 1.0705e+02, 1.0716e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 942 was 99.2%\n",
      "current params: tensor([107.0496, 107.1428, 107.0897, 107.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.6\n",
      "SLow rates:  tensor([[1.0715e+02, 1.0724e+02, 1.0719e+02, 1.0726e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0715e+02, 1.0715e+02, 1.0715e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0724e+02, 1.0724e+02, 1.0724e+02, 1.0000e-01, 1.0000e-01, 1.0724e+02,\n",
      "         1.0724e+02, 1.0000e-01, 1.0719e+02, 1.0719e+02, 1.0719e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0719e+02, 1.0719e+02, 1.0000e-01, 1.0719e+02, 1.0000e-01,\n",
      "         1.0719e+02, 1.0726e+02, 1.0726e+02, 1.0726e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0726e+02, 1.0726e+02, 1.0000e-01, 1.0726e+02, 1.0000e-01, 1.0726e+02,\n",
      "         1.0724e+02, 1.0726e+02, 1.0726e+02, 1.0726e+02, 1.0719e+02, 1.0726e+02,\n",
      "         1.0726e+02, 1.0726e+02, 1.0724e+02, 1.0726e+02, 1.0726e+02, 1.0726e+02,\n",
      "         1.0724e+02, 1.0719e+02, 1.0724e+02, 1.0724e+02, 1.0724e+02, 1.0000e-01,\n",
      "         1.0724e+02, 1.0719e+02, 1.0000e-01, 1.0719e+02, 1.0726e+02, 1.0000e-01,\n",
      "         1.0726e+02, 1.0726e+02, 1.0726e+02, 1.0724e+02, 1.0724e+02, 1.0000e-01,\n",
      "         1.0726e+02, 1.0000e-01, 1.0715e+02, 1.0715e+02, 1.0724e+02, 1.0726e+02,\n",
      "         1.0726e+02, 1.0000e-01, 1.0000e-01, 1.0715e+02, 1.0724e+02, 1.0726e+02,\n",
      "         1.0000e-01, 1.0724e+02, 1.0726e+02, 1.0000e-01, 1.0715e+02, 1.0726e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 943 was 99.2%\n",
      "current params: tensor([107.1496, 107.2428, 107.1897, 107.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.7\n",
      "SLow rates:  tensor([[1.0725e+02, 1.0734e+02, 1.0729e+02, 1.0736e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0725e+02, 1.0725e+02, 1.0725e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0734e+02, 1.0734e+02, 1.0734e+02, 1.0000e-01, 1.0000e-01, 1.0734e+02,\n",
      "         1.0734e+02, 1.0000e-01, 1.0729e+02, 1.0729e+02, 1.0729e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0729e+02, 1.0729e+02, 1.0000e-01, 1.0729e+02, 1.0000e-01,\n",
      "         1.0729e+02, 1.0736e+02, 1.0736e+02, 1.0736e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0736e+02, 1.0736e+02, 1.0000e-01, 1.0736e+02, 1.0000e-01, 1.0736e+02,\n",
      "         1.0734e+02, 1.0736e+02, 1.0736e+02, 1.0736e+02, 1.0729e+02, 1.0736e+02,\n",
      "         1.0736e+02, 1.0736e+02, 1.0734e+02, 1.0736e+02, 1.0736e+02, 1.0736e+02,\n",
      "         1.0734e+02, 1.0729e+02, 1.0734e+02, 1.0734e+02, 1.0734e+02, 1.0000e-01,\n",
      "         1.0734e+02, 1.0729e+02, 1.0000e-01, 1.0729e+02, 1.0736e+02, 1.0000e-01,\n",
      "         1.0736e+02, 1.0736e+02, 1.0736e+02, 1.0734e+02, 1.0734e+02, 1.0000e-01,\n",
      "         1.0736e+02, 1.0000e-01, 1.0725e+02, 1.0725e+02, 1.0734e+02, 1.0736e+02,\n",
      "         1.0736e+02, 1.0000e-01, 1.0000e-01, 1.0725e+02, 1.0734e+02, 1.0736e+02,\n",
      "         1.0000e-01, 1.0734e+02, 1.0736e+02, 1.0000e-01, 1.0725e+02, 1.0736e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 944 was 99.2%\n",
      "current params: tensor([107.2496, 107.3428, 107.2897, 107.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.7\n",
      "SLow rates:  tensor([[1.0735e+02, 1.0744e+02, 1.0739e+02, 1.0746e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0735e+02, 1.0735e+02, 1.0735e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0744e+02, 1.0744e+02, 1.0744e+02, 1.0000e-01, 1.0000e-01, 1.0744e+02,\n",
      "         1.0744e+02, 1.0000e-01, 1.0739e+02, 1.0739e+02, 1.0739e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0739e+02, 1.0739e+02, 1.0000e-01, 1.0739e+02, 1.0000e-01,\n",
      "         1.0739e+02, 1.0746e+02, 1.0746e+02, 1.0746e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0746e+02, 1.0746e+02, 1.0000e-01, 1.0746e+02, 1.0000e-01, 1.0746e+02,\n",
      "         1.0744e+02, 1.0746e+02, 1.0746e+02, 1.0746e+02, 1.0739e+02, 1.0746e+02,\n",
      "         1.0746e+02, 1.0746e+02, 1.0744e+02, 1.0746e+02, 1.0746e+02, 1.0746e+02,\n",
      "         1.0744e+02, 1.0739e+02, 1.0744e+02, 1.0744e+02, 1.0744e+02, 1.0000e-01,\n",
      "         1.0744e+02, 1.0739e+02, 1.0000e-01, 1.0739e+02, 1.0746e+02, 1.0000e-01,\n",
      "         1.0746e+02, 1.0746e+02, 1.0746e+02, 1.0744e+02, 1.0744e+02, 1.0000e-01,\n",
      "         1.0746e+02, 1.0000e-01, 1.0735e+02, 1.0735e+02, 1.0744e+02, 1.0746e+02,\n",
      "         1.0746e+02, 1.0000e-01, 1.0000e-01, 1.0735e+02, 1.0744e+02, 1.0746e+02,\n",
      "         1.0000e-01, 1.0744e+02, 1.0746e+02, 1.0000e-01, 1.0735e+02, 1.0746e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 945 was 99.2%\n",
      "current params: tensor([107.3496, 107.4428, 107.3897, 107.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.7\n",
      "SLow rates:  tensor([[1.0745e+02, 1.0754e+02, 1.0749e+02, 1.0756e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0745e+02, 1.0745e+02, 1.0745e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0754e+02, 1.0754e+02, 1.0754e+02, 1.0000e-01, 1.0000e-01, 1.0754e+02,\n",
      "         1.0754e+02, 1.0000e-01, 1.0749e+02, 1.0749e+02, 1.0749e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0749e+02, 1.0749e+02, 1.0000e-01, 1.0749e+02, 1.0000e-01,\n",
      "         1.0749e+02, 1.0756e+02, 1.0756e+02, 1.0756e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0756e+02, 1.0756e+02, 1.0000e-01, 1.0756e+02, 1.0000e-01, 1.0756e+02,\n",
      "         1.0754e+02, 1.0756e+02, 1.0756e+02, 1.0756e+02, 1.0749e+02, 1.0756e+02,\n",
      "         1.0756e+02, 1.0756e+02, 1.0754e+02, 1.0756e+02, 1.0756e+02, 1.0756e+02,\n",
      "         1.0754e+02, 1.0749e+02, 1.0754e+02, 1.0754e+02, 1.0754e+02, 1.0000e-01,\n",
      "         1.0754e+02, 1.0749e+02, 1.0000e-01, 1.0749e+02, 1.0756e+02, 1.0000e-01,\n",
      "         1.0756e+02, 1.0756e+02, 1.0756e+02, 1.0754e+02, 1.0754e+02, 1.0000e-01,\n",
      "         1.0756e+02, 1.0000e-01, 1.0745e+02, 1.0745e+02, 1.0754e+02, 1.0756e+02,\n",
      "         1.0756e+02, 1.0000e-01, 1.0000e-01, 1.0745e+02, 1.0754e+02, 1.0756e+02,\n",
      "         1.0000e-01, 1.0754e+02, 1.0756e+02, 1.0000e-01, 1.0745e+02, 1.0756e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 946 was 99.2%\n",
      "current params: tensor([107.4496, 107.5428, 107.4897, 107.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.7\n",
      "SLow rates:  tensor([[1.0755e+02, 1.0764e+02, 1.0759e+02, 1.0766e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0755e+02, 1.0755e+02, 1.0755e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0764e+02, 1.0764e+02, 1.0764e+02, 1.0000e-01, 1.0000e-01, 1.0764e+02,\n",
      "         1.0764e+02, 1.0000e-01, 1.0759e+02, 1.0759e+02, 1.0759e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0759e+02, 1.0759e+02, 1.0000e-01, 1.0759e+02, 1.0000e-01,\n",
      "         1.0759e+02, 1.0766e+02, 1.0766e+02, 1.0766e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0766e+02, 1.0766e+02, 1.0000e-01, 1.0766e+02, 1.0000e-01, 1.0766e+02,\n",
      "         1.0764e+02, 1.0766e+02, 1.0766e+02, 1.0766e+02, 1.0759e+02, 1.0766e+02,\n",
      "         1.0766e+02, 1.0766e+02, 1.0764e+02, 1.0766e+02, 1.0766e+02, 1.0766e+02,\n",
      "         1.0764e+02, 1.0759e+02, 1.0764e+02, 1.0764e+02, 1.0764e+02, 1.0000e-01,\n",
      "         1.0764e+02, 1.0759e+02, 1.0000e-01, 1.0759e+02, 1.0766e+02, 1.0000e-01,\n",
      "         1.0766e+02, 1.0766e+02, 1.0766e+02, 1.0764e+02, 1.0764e+02, 1.0000e-01,\n",
      "         1.0766e+02, 1.0000e-01, 1.0755e+02, 1.0755e+02, 1.0764e+02, 1.0766e+02,\n",
      "         1.0766e+02, 1.0000e-01, 1.0000e-01, 1.0755e+02, 1.0764e+02, 1.0766e+02,\n",
      "         1.0000e-01, 1.0764e+02, 1.0766e+02, 1.0000e-01, 1.0755e+02, 1.0766e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 947 was 99.2%\n",
      "current params: tensor([107.5496, 107.6428, 107.5897, 107.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.7\n",
      "SLow rates:  tensor([[1.0765e+02, 1.0774e+02, 1.0769e+02, 1.0776e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0765e+02, 1.0765e+02, 1.0765e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0774e+02, 1.0774e+02, 1.0774e+02, 1.0000e-01, 1.0000e-01, 1.0774e+02,\n",
      "         1.0774e+02, 1.0000e-01, 1.0769e+02, 1.0769e+02, 1.0769e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0769e+02, 1.0769e+02, 1.0000e-01, 1.0769e+02, 1.0000e-01,\n",
      "         1.0769e+02, 1.0776e+02, 1.0776e+02, 1.0776e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0776e+02, 1.0776e+02, 1.0000e-01, 1.0776e+02, 1.0000e-01, 1.0776e+02,\n",
      "         1.0774e+02, 1.0776e+02, 1.0776e+02, 1.0776e+02, 1.0769e+02, 1.0776e+02,\n",
      "         1.0776e+02, 1.0776e+02, 1.0774e+02, 1.0776e+02, 1.0776e+02, 1.0776e+02,\n",
      "         1.0774e+02, 1.0769e+02, 1.0774e+02, 1.0774e+02, 1.0774e+02, 1.0000e-01,\n",
      "         1.0774e+02, 1.0769e+02, 1.0000e-01, 1.0769e+02, 1.0776e+02, 1.0000e-01,\n",
      "         1.0776e+02, 1.0776e+02, 1.0776e+02, 1.0774e+02, 1.0774e+02, 1.0000e-01,\n",
      "         1.0776e+02, 1.0000e-01, 1.0765e+02, 1.0765e+02, 1.0774e+02, 1.0776e+02,\n",
      "         1.0776e+02, 1.0000e-01, 1.0000e-01, 1.0765e+02, 1.0774e+02, 1.0776e+02,\n",
      "         1.0000e-01, 1.0774e+02, 1.0776e+02, 1.0000e-01, 1.0765e+02, 1.0776e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 948 was 99.2%\n",
      "current params: tensor([107.6496, 107.7428, 107.6897, 107.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.8\n",
      "SLow rates:  tensor([[1.0775e+02, 1.0784e+02, 1.0779e+02, 1.0786e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0775e+02, 1.0775e+02, 1.0775e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0784e+02, 1.0784e+02, 1.0784e+02, 1.0000e-01, 1.0000e-01, 1.0784e+02,\n",
      "         1.0784e+02, 1.0000e-01, 1.0779e+02, 1.0779e+02, 1.0779e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0779e+02, 1.0779e+02, 1.0000e-01, 1.0779e+02, 1.0000e-01,\n",
      "         1.0779e+02, 1.0786e+02, 1.0786e+02, 1.0786e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0786e+02, 1.0786e+02, 1.0000e-01, 1.0786e+02, 1.0000e-01, 1.0786e+02,\n",
      "         1.0784e+02, 1.0786e+02, 1.0786e+02, 1.0786e+02, 1.0779e+02, 1.0786e+02,\n",
      "         1.0786e+02, 1.0786e+02, 1.0784e+02, 1.0786e+02, 1.0786e+02, 1.0786e+02,\n",
      "         1.0784e+02, 1.0779e+02, 1.0784e+02, 1.0784e+02, 1.0784e+02, 1.0000e-01,\n",
      "         1.0784e+02, 1.0779e+02, 1.0000e-01, 1.0779e+02, 1.0786e+02, 1.0000e-01,\n",
      "         1.0786e+02, 1.0786e+02, 1.0786e+02, 1.0784e+02, 1.0784e+02, 1.0000e-01,\n",
      "         1.0786e+02, 1.0000e-01, 1.0775e+02, 1.0775e+02, 1.0784e+02, 1.0786e+02,\n",
      "         1.0786e+02, 1.0000e-01, 1.0000e-01, 1.0775e+02, 1.0784e+02, 1.0786e+02,\n",
      "         1.0000e-01, 1.0784e+02, 1.0786e+02, 1.0000e-01, 1.0775e+02, 1.0786e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 949 was 99.2%\n",
      "current params: tensor([107.7496, 107.8428, 107.7897, 107.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.8\n",
      "SLow rates:  tensor([[1.0785e+02, 1.0794e+02, 1.0789e+02, 1.0796e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0785e+02, 1.0785e+02, 1.0785e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0794e+02, 1.0794e+02, 1.0794e+02, 1.0000e-01, 1.0000e-01, 1.0794e+02,\n",
      "         1.0794e+02, 1.0000e-01, 1.0789e+02, 1.0789e+02, 1.0789e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0789e+02, 1.0789e+02, 1.0000e-01, 1.0789e+02, 1.0000e-01,\n",
      "         1.0789e+02, 1.0796e+02, 1.0796e+02, 1.0796e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0796e+02, 1.0796e+02, 1.0000e-01, 1.0796e+02, 1.0000e-01, 1.0796e+02,\n",
      "         1.0794e+02, 1.0796e+02, 1.0796e+02, 1.0796e+02, 1.0789e+02, 1.0796e+02,\n",
      "         1.0796e+02, 1.0796e+02, 1.0794e+02, 1.0796e+02, 1.0796e+02, 1.0796e+02,\n",
      "         1.0794e+02, 1.0789e+02, 1.0794e+02, 1.0794e+02, 1.0794e+02, 1.0000e-01,\n",
      "         1.0794e+02, 1.0789e+02, 1.0000e-01, 1.0789e+02, 1.0796e+02, 1.0000e-01,\n",
      "         1.0796e+02, 1.0796e+02, 1.0796e+02, 1.0794e+02, 1.0794e+02, 1.0000e-01,\n",
      "         1.0796e+02, 1.0000e-01, 1.0785e+02, 1.0785e+02, 1.0794e+02, 1.0796e+02,\n",
      "         1.0796e+02, 1.0000e-01, 1.0000e-01, 1.0785e+02, 1.0794e+02, 1.0796e+02,\n",
      "         1.0000e-01, 1.0794e+02, 1.0796e+02, 1.0000e-01, 1.0785e+02, 1.0796e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 950 was 99.3%\n",
      "current params: tensor([107.8496, 107.9428, 107.8897, 107.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.8\n",
      "SLow rates:  tensor([[1.0795e+02, 1.0804e+02, 1.0799e+02, 1.0806e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0795e+02, 1.0795e+02, 1.0795e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0804e+02, 1.0804e+02, 1.0804e+02, 1.0000e-01, 1.0000e-01, 1.0804e+02,\n",
      "         1.0804e+02, 1.0000e-01, 1.0799e+02, 1.0799e+02, 1.0799e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0799e+02, 1.0799e+02, 1.0000e-01, 1.0799e+02, 1.0000e-01,\n",
      "         1.0799e+02, 1.0806e+02, 1.0806e+02, 1.0806e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0806e+02, 1.0806e+02, 1.0000e-01, 1.0806e+02, 1.0000e-01, 1.0806e+02,\n",
      "         1.0804e+02, 1.0806e+02, 1.0806e+02, 1.0806e+02, 1.0799e+02, 1.0806e+02,\n",
      "         1.0806e+02, 1.0806e+02, 1.0804e+02, 1.0806e+02, 1.0806e+02, 1.0806e+02,\n",
      "         1.0804e+02, 1.0799e+02, 1.0804e+02, 1.0804e+02, 1.0804e+02, 1.0000e-01,\n",
      "         1.0804e+02, 1.0799e+02, 1.0000e-01, 1.0799e+02, 1.0806e+02, 1.0000e-01,\n",
      "         1.0806e+02, 1.0806e+02, 1.0806e+02, 1.0804e+02, 1.0804e+02, 1.0000e-01,\n",
      "         1.0806e+02, 1.0000e-01, 1.0795e+02, 1.0795e+02, 1.0804e+02, 1.0806e+02,\n",
      "         1.0806e+02, 1.0000e-01, 1.0000e-01, 1.0795e+02, 1.0804e+02, 1.0806e+02,\n",
      "         1.0000e-01, 1.0804e+02, 1.0806e+02, 1.0000e-01, 1.0795e+02, 1.0806e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 951 was 99.3%\n",
      "current params: tensor([107.9496, 108.0428, 107.9897, 108.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.8\n",
      "SLow rates:  tensor([[1.0805e+02, 1.0814e+02, 1.0809e+02, 1.0816e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0805e+02, 1.0805e+02, 1.0805e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0814e+02, 1.0814e+02, 1.0814e+02, 1.0000e-01, 1.0000e-01, 1.0814e+02,\n",
      "         1.0814e+02, 1.0000e-01, 1.0809e+02, 1.0809e+02, 1.0809e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0809e+02, 1.0809e+02, 1.0000e-01, 1.0809e+02, 1.0000e-01,\n",
      "         1.0809e+02, 1.0816e+02, 1.0816e+02, 1.0816e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0816e+02, 1.0816e+02, 1.0000e-01, 1.0816e+02, 1.0000e-01, 1.0816e+02,\n",
      "         1.0814e+02, 1.0816e+02, 1.0816e+02, 1.0816e+02, 1.0809e+02, 1.0816e+02,\n",
      "         1.0816e+02, 1.0816e+02, 1.0814e+02, 1.0816e+02, 1.0816e+02, 1.0816e+02,\n",
      "         1.0814e+02, 1.0809e+02, 1.0814e+02, 1.0814e+02, 1.0814e+02, 1.0000e-01,\n",
      "         1.0814e+02, 1.0809e+02, 1.0000e-01, 1.0809e+02, 1.0816e+02, 1.0000e-01,\n",
      "         1.0816e+02, 1.0816e+02, 1.0816e+02, 1.0814e+02, 1.0814e+02, 1.0000e-01,\n",
      "         1.0816e+02, 1.0000e-01, 1.0805e+02, 1.0805e+02, 1.0814e+02, 1.0816e+02,\n",
      "         1.0816e+02, 1.0000e-01, 1.0000e-01, 1.0805e+02, 1.0814e+02, 1.0816e+02,\n",
      "         1.0000e-01, 1.0814e+02, 1.0816e+02, 1.0000e-01, 1.0805e+02, 1.0816e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 952 was 99.3%\n",
      "current params: tensor([108.0496, 108.1428, 108.0897, 108.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.8\n",
      "SLow rates:  tensor([[1.0815e+02, 1.0824e+02, 1.0819e+02, 1.0826e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0815e+02, 1.0815e+02, 1.0815e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0824e+02, 1.0824e+02, 1.0824e+02, 1.0000e-01, 1.0000e-01, 1.0824e+02,\n",
      "         1.0824e+02, 1.0000e-01, 1.0819e+02, 1.0819e+02, 1.0819e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0819e+02, 1.0819e+02, 1.0000e-01, 1.0819e+02, 1.0000e-01,\n",
      "         1.0819e+02, 1.0826e+02, 1.0826e+02, 1.0826e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0826e+02, 1.0826e+02, 1.0000e-01, 1.0826e+02, 1.0000e-01, 1.0826e+02,\n",
      "         1.0824e+02, 1.0826e+02, 1.0826e+02, 1.0826e+02, 1.0819e+02, 1.0826e+02,\n",
      "         1.0826e+02, 1.0826e+02, 1.0824e+02, 1.0826e+02, 1.0826e+02, 1.0826e+02,\n",
      "         1.0824e+02, 1.0819e+02, 1.0824e+02, 1.0824e+02, 1.0824e+02, 1.0000e-01,\n",
      "         1.0824e+02, 1.0819e+02, 1.0000e-01, 1.0819e+02, 1.0826e+02, 1.0000e-01,\n",
      "         1.0826e+02, 1.0826e+02, 1.0826e+02, 1.0824e+02, 1.0824e+02, 1.0000e-01,\n",
      "         1.0826e+02, 1.0000e-01, 1.0815e+02, 1.0815e+02, 1.0824e+02, 1.0826e+02,\n",
      "         1.0826e+02, 1.0000e-01, 1.0000e-01, 1.0815e+02, 1.0824e+02, 1.0826e+02,\n",
      "         1.0000e-01, 1.0824e+02, 1.0826e+02, 1.0000e-01, 1.0815e+02, 1.0826e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 953 was 99.3%\n",
      "current params: tensor([108.1496, 108.2428, 108.1897, 108.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.8\n",
      "SLow rates:  tensor([[1.0825e+02, 1.0834e+02, 1.0829e+02, 1.0836e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0825e+02, 1.0825e+02, 1.0825e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0834e+02, 1.0834e+02, 1.0834e+02, 1.0000e-01, 1.0000e-01, 1.0834e+02,\n",
      "         1.0834e+02, 1.0000e-01, 1.0829e+02, 1.0829e+02, 1.0829e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0829e+02, 1.0829e+02, 1.0000e-01, 1.0829e+02, 1.0000e-01,\n",
      "         1.0829e+02, 1.0836e+02, 1.0836e+02, 1.0836e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0836e+02, 1.0836e+02, 1.0000e-01, 1.0836e+02, 1.0000e-01, 1.0836e+02,\n",
      "         1.0834e+02, 1.0836e+02, 1.0836e+02, 1.0836e+02, 1.0829e+02, 1.0836e+02,\n",
      "         1.0836e+02, 1.0836e+02, 1.0834e+02, 1.0836e+02, 1.0836e+02, 1.0836e+02,\n",
      "         1.0834e+02, 1.0829e+02, 1.0834e+02, 1.0834e+02, 1.0834e+02, 1.0000e-01,\n",
      "         1.0834e+02, 1.0829e+02, 1.0000e-01, 1.0829e+02, 1.0836e+02, 1.0000e-01,\n",
      "         1.0836e+02, 1.0836e+02, 1.0836e+02, 1.0834e+02, 1.0834e+02, 1.0000e-01,\n",
      "         1.0836e+02, 1.0000e-01, 1.0825e+02, 1.0825e+02, 1.0834e+02, 1.0836e+02,\n",
      "         1.0836e+02, 1.0000e-01, 1.0000e-01, 1.0825e+02, 1.0834e+02, 1.0836e+02,\n",
      "         1.0000e-01, 1.0834e+02, 1.0836e+02, 1.0000e-01, 1.0825e+02, 1.0836e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 954 was 99.3%\n",
      "current params: tensor([108.2496, 108.3429, 108.2897, 108.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.9\n",
      "SLow rates:  tensor([[1.0835e+02, 1.0844e+02, 1.0839e+02, 1.0846e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0835e+02, 1.0835e+02, 1.0835e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0844e+02, 1.0844e+02, 1.0844e+02, 1.0000e-01, 1.0000e-01, 1.0844e+02,\n",
      "         1.0844e+02, 1.0000e-01, 1.0839e+02, 1.0839e+02, 1.0839e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0839e+02, 1.0839e+02, 1.0000e-01, 1.0839e+02, 1.0000e-01,\n",
      "         1.0839e+02, 1.0846e+02, 1.0846e+02, 1.0846e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0846e+02, 1.0846e+02, 1.0000e-01, 1.0846e+02, 1.0000e-01, 1.0846e+02,\n",
      "         1.0844e+02, 1.0846e+02, 1.0846e+02, 1.0846e+02, 1.0839e+02, 1.0846e+02,\n",
      "         1.0846e+02, 1.0846e+02, 1.0844e+02, 1.0846e+02, 1.0846e+02, 1.0846e+02,\n",
      "         1.0844e+02, 1.0839e+02, 1.0844e+02, 1.0844e+02, 1.0844e+02, 1.0000e-01,\n",
      "         1.0844e+02, 1.0839e+02, 1.0000e-01, 1.0839e+02, 1.0846e+02, 1.0000e-01,\n",
      "         1.0846e+02, 1.0846e+02, 1.0846e+02, 1.0844e+02, 1.0844e+02, 1.0000e-01,\n",
      "         1.0846e+02, 1.0000e-01, 1.0835e+02, 1.0835e+02, 1.0844e+02, 1.0846e+02,\n",
      "         1.0846e+02, 1.0000e-01, 1.0000e-01, 1.0835e+02, 1.0844e+02, 1.0846e+02,\n",
      "         1.0000e-01, 1.0844e+02, 1.0846e+02, 1.0000e-01, 1.0835e+02, 1.0846e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 955 was 99.3%\n",
      "current params: tensor([108.3496, 108.4429, 108.3897, 108.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.9\n",
      "SLow rates:  tensor([[1.0845e+02, 1.0854e+02, 1.0849e+02, 1.0856e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0845e+02, 1.0845e+02, 1.0845e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0854e+02, 1.0854e+02, 1.0854e+02, 1.0000e-01, 1.0000e-01, 1.0854e+02,\n",
      "         1.0854e+02, 1.0000e-01, 1.0849e+02, 1.0849e+02, 1.0849e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0849e+02, 1.0849e+02, 1.0000e-01, 1.0849e+02, 1.0000e-01,\n",
      "         1.0849e+02, 1.0856e+02, 1.0856e+02, 1.0856e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0856e+02, 1.0856e+02, 1.0000e-01, 1.0856e+02, 1.0000e-01, 1.0856e+02,\n",
      "         1.0854e+02, 1.0856e+02, 1.0856e+02, 1.0856e+02, 1.0849e+02, 1.0856e+02,\n",
      "         1.0856e+02, 1.0856e+02, 1.0854e+02, 1.0856e+02, 1.0856e+02, 1.0856e+02,\n",
      "         1.0854e+02, 1.0849e+02, 1.0854e+02, 1.0854e+02, 1.0854e+02, 1.0000e-01,\n",
      "         1.0854e+02, 1.0849e+02, 1.0000e-01, 1.0849e+02, 1.0856e+02, 1.0000e-01,\n",
      "         1.0856e+02, 1.0856e+02, 1.0856e+02, 1.0854e+02, 1.0854e+02, 1.0000e-01,\n",
      "         1.0856e+02, 1.0000e-01, 1.0845e+02, 1.0845e+02, 1.0854e+02, 1.0856e+02,\n",
      "         1.0856e+02, 1.0000e-01, 1.0000e-01, 1.0845e+02, 1.0854e+02, 1.0856e+02,\n",
      "         1.0000e-01, 1.0854e+02, 1.0856e+02, 1.0000e-01, 1.0845e+02, 1.0856e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 956 was 99.3%\n",
      "current params: tensor([108.4497, 108.5429, 108.4897, 108.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.9\n",
      "SLow rates:  tensor([[1.0855e+02, 1.0864e+02, 1.0859e+02, 1.0866e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0855e+02, 1.0855e+02, 1.0855e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0864e+02, 1.0864e+02, 1.0864e+02, 1.0000e-01, 1.0000e-01, 1.0864e+02,\n",
      "         1.0864e+02, 1.0000e-01, 1.0859e+02, 1.0859e+02, 1.0859e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0859e+02, 1.0859e+02, 1.0000e-01, 1.0859e+02, 1.0000e-01,\n",
      "         1.0859e+02, 1.0866e+02, 1.0866e+02, 1.0866e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0866e+02, 1.0866e+02, 1.0000e-01, 1.0866e+02, 1.0000e-01, 1.0866e+02,\n",
      "         1.0864e+02, 1.0866e+02, 1.0866e+02, 1.0866e+02, 1.0859e+02, 1.0866e+02,\n",
      "         1.0866e+02, 1.0866e+02, 1.0864e+02, 1.0866e+02, 1.0866e+02, 1.0866e+02,\n",
      "         1.0864e+02, 1.0859e+02, 1.0864e+02, 1.0864e+02, 1.0864e+02, 1.0000e-01,\n",
      "         1.0864e+02, 1.0859e+02, 1.0000e-01, 1.0859e+02, 1.0866e+02, 1.0000e-01,\n",
      "         1.0866e+02, 1.0866e+02, 1.0866e+02, 1.0864e+02, 1.0864e+02, 1.0000e-01,\n",
      "         1.0866e+02, 1.0000e-01, 1.0855e+02, 1.0855e+02, 1.0864e+02, 1.0866e+02,\n",
      "         1.0866e+02, 1.0000e-01, 1.0000e-01, 1.0855e+02, 1.0864e+02, 1.0866e+02,\n",
      "         1.0000e-01, 1.0864e+02, 1.0866e+02, 1.0000e-01, 1.0855e+02, 1.0866e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 957 was 99.3%\n",
      "current params: tensor([108.5497, 108.6429, 108.5897, 108.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.9\n",
      "SLow rates:  tensor([[1.0865e+02, 1.0874e+02, 1.0869e+02, 1.0876e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0865e+02, 1.0865e+02, 1.0865e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0874e+02, 1.0874e+02, 1.0874e+02, 1.0000e-01, 1.0000e-01, 1.0874e+02,\n",
      "         1.0874e+02, 1.0000e-01, 1.0869e+02, 1.0869e+02, 1.0869e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0869e+02, 1.0869e+02, 1.0000e-01, 1.0869e+02, 1.0000e-01,\n",
      "         1.0869e+02, 1.0876e+02, 1.0876e+02, 1.0876e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0876e+02, 1.0876e+02, 1.0000e-01, 1.0876e+02, 1.0000e-01, 1.0876e+02,\n",
      "         1.0874e+02, 1.0876e+02, 1.0876e+02, 1.0876e+02, 1.0869e+02, 1.0876e+02,\n",
      "         1.0876e+02, 1.0876e+02, 1.0874e+02, 1.0876e+02, 1.0876e+02, 1.0876e+02,\n",
      "         1.0874e+02, 1.0869e+02, 1.0874e+02, 1.0874e+02, 1.0874e+02, 1.0000e-01,\n",
      "         1.0874e+02, 1.0869e+02, 1.0000e-01, 1.0869e+02, 1.0876e+02, 1.0000e-01,\n",
      "         1.0876e+02, 1.0876e+02, 1.0876e+02, 1.0874e+02, 1.0874e+02, 1.0000e-01,\n",
      "         1.0876e+02, 1.0000e-01, 1.0865e+02, 1.0865e+02, 1.0874e+02, 1.0876e+02,\n",
      "         1.0876e+02, 1.0000e-01, 1.0000e-01, 1.0865e+02, 1.0874e+02, 1.0876e+02,\n",
      "         1.0000e-01, 1.0874e+02, 1.0876e+02, 1.0000e-01, 1.0865e+02, 1.0876e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 958 was 99.3%\n",
      "current params: tensor([108.6497, 108.7429, 108.6897, 108.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  23.9\n",
      "SLow rates:  tensor([[1.0875e+02, 1.0884e+02, 1.0879e+02, 1.0886e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0875e+02, 1.0875e+02, 1.0875e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0884e+02, 1.0884e+02, 1.0884e+02, 1.0000e-01, 1.0000e-01, 1.0884e+02,\n",
      "         1.0884e+02, 1.0000e-01, 1.0879e+02, 1.0879e+02, 1.0879e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0879e+02, 1.0879e+02, 1.0000e-01, 1.0879e+02, 1.0000e-01,\n",
      "         1.0879e+02, 1.0886e+02, 1.0886e+02, 1.0886e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0886e+02, 1.0886e+02, 1.0000e-01, 1.0886e+02, 1.0000e-01, 1.0886e+02,\n",
      "         1.0884e+02, 1.0886e+02, 1.0886e+02, 1.0886e+02, 1.0879e+02, 1.0886e+02,\n",
      "         1.0886e+02, 1.0886e+02, 1.0884e+02, 1.0886e+02, 1.0886e+02, 1.0886e+02,\n",
      "         1.0884e+02, 1.0879e+02, 1.0884e+02, 1.0884e+02, 1.0884e+02, 1.0000e-01,\n",
      "         1.0884e+02, 1.0879e+02, 1.0000e-01, 1.0879e+02, 1.0886e+02, 1.0000e-01,\n",
      "         1.0886e+02, 1.0886e+02, 1.0886e+02, 1.0884e+02, 1.0884e+02, 1.0000e-01,\n",
      "         1.0886e+02, 1.0000e-01, 1.0875e+02, 1.0875e+02, 1.0884e+02, 1.0886e+02,\n",
      "         1.0886e+02, 1.0000e-01, 1.0000e-01, 1.0875e+02, 1.0884e+02, 1.0886e+02,\n",
      "         1.0000e-01, 1.0884e+02, 1.0886e+02, 1.0000e-01, 1.0875e+02, 1.0886e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 959 was 99.3%\n",
      "current params: tensor([108.7497, 108.8429, 108.7898, 108.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.0\n",
      "SLow rates:  tensor([[1.0885e+02, 1.0894e+02, 1.0889e+02, 1.0896e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0885e+02, 1.0885e+02, 1.0885e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0894e+02, 1.0894e+02, 1.0894e+02, 1.0000e-01, 1.0000e-01, 1.0894e+02,\n",
      "         1.0894e+02, 1.0000e-01, 1.0889e+02, 1.0889e+02, 1.0889e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0889e+02, 1.0889e+02, 1.0000e-01, 1.0889e+02, 1.0000e-01,\n",
      "         1.0889e+02, 1.0896e+02, 1.0896e+02, 1.0896e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0896e+02, 1.0896e+02, 1.0000e-01, 1.0896e+02, 1.0000e-01, 1.0896e+02,\n",
      "         1.0894e+02, 1.0896e+02, 1.0896e+02, 1.0896e+02, 1.0889e+02, 1.0896e+02,\n",
      "         1.0896e+02, 1.0896e+02, 1.0894e+02, 1.0896e+02, 1.0896e+02, 1.0896e+02,\n",
      "         1.0894e+02, 1.0889e+02, 1.0894e+02, 1.0894e+02, 1.0894e+02, 1.0000e-01,\n",
      "         1.0894e+02, 1.0889e+02, 1.0000e-01, 1.0889e+02, 1.0896e+02, 1.0000e-01,\n",
      "         1.0896e+02, 1.0896e+02, 1.0896e+02, 1.0894e+02, 1.0894e+02, 1.0000e-01,\n",
      "         1.0896e+02, 1.0000e-01, 1.0885e+02, 1.0885e+02, 1.0894e+02, 1.0896e+02,\n",
      "         1.0896e+02, 1.0000e-01, 1.0000e-01, 1.0885e+02, 1.0894e+02, 1.0896e+02,\n",
      "         1.0000e-01, 1.0894e+02, 1.0896e+02, 1.0000e-01, 1.0885e+02, 1.0896e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 960 was 99.3%\n",
      "current params: tensor([108.8497, 108.9429, 108.8898, 108.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.0\n",
      "SLow rates:  tensor([[1.0895e+02, 1.0904e+02, 1.0899e+02, 1.0906e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0895e+02, 1.0895e+02, 1.0895e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0904e+02, 1.0904e+02, 1.0904e+02, 1.0000e-01, 1.0000e-01, 1.0904e+02,\n",
      "         1.0904e+02, 1.0000e-01, 1.0899e+02, 1.0899e+02, 1.0899e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0899e+02, 1.0899e+02, 1.0000e-01, 1.0899e+02, 1.0000e-01,\n",
      "         1.0899e+02, 1.0906e+02, 1.0906e+02, 1.0906e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0906e+02, 1.0906e+02, 1.0000e-01, 1.0906e+02, 1.0000e-01, 1.0906e+02,\n",
      "         1.0904e+02, 1.0906e+02, 1.0906e+02, 1.0906e+02, 1.0899e+02, 1.0906e+02,\n",
      "         1.0906e+02, 1.0906e+02, 1.0904e+02, 1.0906e+02, 1.0906e+02, 1.0906e+02,\n",
      "         1.0904e+02, 1.0899e+02, 1.0904e+02, 1.0904e+02, 1.0904e+02, 1.0000e-01,\n",
      "         1.0904e+02, 1.0899e+02, 1.0000e-01, 1.0899e+02, 1.0906e+02, 1.0000e-01,\n",
      "         1.0906e+02, 1.0906e+02, 1.0906e+02, 1.0904e+02, 1.0904e+02, 1.0000e-01,\n",
      "         1.0906e+02, 1.0000e-01, 1.0895e+02, 1.0895e+02, 1.0904e+02, 1.0906e+02,\n",
      "         1.0906e+02, 1.0000e-01, 1.0000e-01, 1.0895e+02, 1.0904e+02, 1.0906e+02,\n",
      "         1.0000e-01, 1.0904e+02, 1.0906e+02, 1.0000e-01, 1.0895e+02, 1.0906e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 961 was 99.3%\n",
      "current params: tensor([108.9497, 109.0429, 108.9898, 109.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.0\n",
      "SLow rates:  tensor([[1.0905e+02, 1.0914e+02, 1.0909e+02, 1.0916e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0905e+02, 1.0905e+02, 1.0905e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0914e+02, 1.0914e+02, 1.0914e+02, 1.0000e-01, 1.0000e-01, 1.0914e+02,\n",
      "         1.0914e+02, 1.0000e-01, 1.0909e+02, 1.0909e+02, 1.0909e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0909e+02, 1.0909e+02, 1.0000e-01, 1.0909e+02, 1.0000e-01,\n",
      "         1.0909e+02, 1.0916e+02, 1.0916e+02, 1.0916e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0916e+02, 1.0916e+02, 1.0000e-01, 1.0916e+02, 1.0000e-01, 1.0916e+02,\n",
      "         1.0914e+02, 1.0916e+02, 1.0916e+02, 1.0916e+02, 1.0909e+02, 1.0916e+02,\n",
      "         1.0916e+02, 1.0916e+02, 1.0914e+02, 1.0916e+02, 1.0916e+02, 1.0916e+02,\n",
      "         1.0914e+02, 1.0909e+02, 1.0914e+02, 1.0914e+02, 1.0914e+02, 1.0000e-01,\n",
      "         1.0914e+02, 1.0909e+02, 1.0000e-01, 1.0909e+02, 1.0916e+02, 1.0000e-01,\n",
      "         1.0916e+02, 1.0916e+02, 1.0916e+02, 1.0914e+02, 1.0914e+02, 1.0000e-01,\n",
      "         1.0916e+02, 1.0000e-01, 1.0905e+02, 1.0905e+02, 1.0914e+02, 1.0916e+02,\n",
      "         1.0916e+02, 1.0000e-01, 1.0000e-01, 1.0905e+02, 1.0914e+02, 1.0916e+02,\n",
      "         1.0000e-01, 1.0914e+02, 1.0916e+02, 1.0000e-01, 1.0905e+02, 1.0916e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 962 was 99.3%\n",
      "current params: tensor([109.0497, 109.1429, 109.0898, 109.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.0\n",
      "SLow rates:  tensor([[1.0915e+02, 1.0924e+02, 1.0919e+02, 1.0926e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0915e+02, 1.0915e+02, 1.0915e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0924e+02, 1.0924e+02, 1.0924e+02, 1.0000e-01, 1.0000e-01, 1.0924e+02,\n",
      "         1.0924e+02, 1.0000e-01, 1.0919e+02, 1.0919e+02, 1.0919e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0919e+02, 1.0919e+02, 1.0000e-01, 1.0919e+02, 1.0000e-01,\n",
      "         1.0919e+02, 1.0926e+02, 1.0926e+02, 1.0926e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0926e+02, 1.0926e+02, 1.0000e-01, 1.0926e+02, 1.0000e-01, 1.0926e+02,\n",
      "         1.0924e+02, 1.0926e+02, 1.0926e+02, 1.0926e+02, 1.0919e+02, 1.0926e+02,\n",
      "         1.0926e+02, 1.0926e+02, 1.0924e+02, 1.0926e+02, 1.0926e+02, 1.0926e+02,\n",
      "         1.0924e+02, 1.0919e+02, 1.0924e+02, 1.0924e+02, 1.0924e+02, 1.0000e-01,\n",
      "         1.0924e+02, 1.0919e+02, 1.0000e-01, 1.0919e+02, 1.0926e+02, 1.0000e-01,\n",
      "         1.0926e+02, 1.0926e+02, 1.0926e+02, 1.0924e+02, 1.0924e+02, 1.0000e-01,\n",
      "         1.0926e+02, 1.0000e-01, 1.0915e+02, 1.0915e+02, 1.0924e+02, 1.0926e+02,\n",
      "         1.0926e+02, 1.0000e-01, 1.0000e-01, 1.0915e+02, 1.0924e+02, 1.0926e+02,\n",
      "         1.0000e-01, 1.0924e+02, 1.0926e+02, 1.0000e-01, 1.0915e+02, 1.0926e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 963 was 99.3%\n",
      "current params: tensor([109.1497, 109.2429, 109.1898, 109.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.0\n",
      "SLow rates:  tensor([[1.0925e+02, 1.0934e+02, 1.0929e+02, 1.0936e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0925e+02, 1.0925e+02, 1.0925e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0934e+02, 1.0934e+02, 1.0934e+02, 1.0000e-01, 1.0000e-01, 1.0934e+02,\n",
      "         1.0934e+02, 1.0000e-01, 1.0929e+02, 1.0929e+02, 1.0929e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0929e+02, 1.0929e+02, 1.0000e-01, 1.0929e+02, 1.0000e-01,\n",
      "         1.0929e+02, 1.0936e+02, 1.0936e+02, 1.0936e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0936e+02, 1.0936e+02, 1.0000e-01, 1.0936e+02, 1.0000e-01, 1.0936e+02,\n",
      "         1.0934e+02, 1.0936e+02, 1.0936e+02, 1.0936e+02, 1.0929e+02, 1.0936e+02,\n",
      "         1.0936e+02, 1.0936e+02, 1.0934e+02, 1.0936e+02, 1.0936e+02, 1.0936e+02,\n",
      "         1.0934e+02, 1.0929e+02, 1.0934e+02, 1.0934e+02, 1.0934e+02, 1.0000e-01,\n",
      "         1.0934e+02, 1.0929e+02, 1.0000e-01, 1.0929e+02, 1.0936e+02, 1.0000e-01,\n",
      "         1.0936e+02, 1.0936e+02, 1.0936e+02, 1.0934e+02, 1.0934e+02, 1.0000e-01,\n",
      "         1.0936e+02, 1.0000e-01, 1.0925e+02, 1.0925e+02, 1.0934e+02, 1.0936e+02,\n",
      "         1.0936e+02, 1.0000e-01, 1.0000e-01, 1.0925e+02, 1.0934e+02, 1.0936e+02,\n",
      "         1.0000e-01, 1.0934e+02, 1.0936e+02, 1.0000e-01, 1.0925e+02, 1.0936e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 964 was 99.3%\n",
      "current params: tensor([109.2497, 109.3429, 109.2898, 109.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.1\n",
      "SLow rates:  tensor([[1.0935e+02, 1.0944e+02, 1.0939e+02, 1.0946e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0935e+02, 1.0935e+02, 1.0935e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0944e+02, 1.0944e+02, 1.0944e+02, 1.0000e-01, 1.0000e-01, 1.0944e+02,\n",
      "         1.0944e+02, 1.0000e-01, 1.0939e+02, 1.0939e+02, 1.0939e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0939e+02, 1.0939e+02, 1.0000e-01, 1.0939e+02, 1.0000e-01,\n",
      "         1.0939e+02, 1.0946e+02, 1.0946e+02, 1.0946e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0946e+02, 1.0946e+02, 1.0000e-01, 1.0946e+02, 1.0000e-01, 1.0946e+02,\n",
      "         1.0944e+02, 1.0946e+02, 1.0946e+02, 1.0946e+02, 1.0939e+02, 1.0946e+02,\n",
      "         1.0946e+02, 1.0946e+02, 1.0944e+02, 1.0946e+02, 1.0946e+02, 1.0946e+02,\n",
      "         1.0944e+02, 1.0939e+02, 1.0944e+02, 1.0944e+02, 1.0944e+02, 1.0000e-01,\n",
      "         1.0944e+02, 1.0939e+02, 1.0000e-01, 1.0939e+02, 1.0946e+02, 1.0000e-01,\n",
      "         1.0946e+02, 1.0946e+02, 1.0946e+02, 1.0944e+02, 1.0944e+02, 1.0000e-01,\n",
      "         1.0946e+02, 1.0000e-01, 1.0935e+02, 1.0935e+02, 1.0944e+02, 1.0946e+02,\n",
      "         1.0946e+02, 1.0000e-01, 1.0000e-01, 1.0935e+02, 1.0944e+02, 1.0946e+02,\n",
      "         1.0000e-01, 1.0944e+02, 1.0946e+02, 1.0000e-01, 1.0935e+02, 1.0946e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 965 was 99.3%\n",
      "current params: tensor([109.3497, 109.4429, 109.3898, 109.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.1\n",
      "SLow rates:  tensor([[1.0945e+02, 1.0954e+02, 1.0949e+02, 1.0956e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0945e+02, 1.0945e+02, 1.0945e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0954e+02, 1.0954e+02, 1.0954e+02, 1.0000e-01, 1.0000e-01, 1.0954e+02,\n",
      "         1.0954e+02, 1.0000e-01, 1.0949e+02, 1.0949e+02, 1.0949e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0949e+02, 1.0949e+02, 1.0000e-01, 1.0949e+02, 1.0000e-01,\n",
      "         1.0949e+02, 1.0956e+02, 1.0956e+02, 1.0956e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0956e+02, 1.0956e+02, 1.0000e-01, 1.0956e+02, 1.0000e-01, 1.0956e+02,\n",
      "         1.0954e+02, 1.0956e+02, 1.0956e+02, 1.0956e+02, 1.0949e+02, 1.0956e+02,\n",
      "         1.0956e+02, 1.0956e+02, 1.0954e+02, 1.0956e+02, 1.0956e+02, 1.0956e+02,\n",
      "         1.0954e+02, 1.0949e+02, 1.0954e+02, 1.0954e+02, 1.0954e+02, 1.0000e-01,\n",
      "         1.0954e+02, 1.0949e+02, 1.0000e-01, 1.0949e+02, 1.0956e+02, 1.0000e-01,\n",
      "         1.0956e+02, 1.0956e+02, 1.0956e+02, 1.0954e+02, 1.0954e+02, 1.0000e-01,\n",
      "         1.0956e+02, 1.0000e-01, 1.0945e+02, 1.0945e+02, 1.0954e+02, 1.0956e+02,\n",
      "         1.0956e+02, 1.0000e-01, 1.0000e-01, 1.0945e+02, 1.0954e+02, 1.0956e+02,\n",
      "         1.0000e-01, 1.0954e+02, 1.0956e+02, 1.0000e-01, 1.0945e+02, 1.0956e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 966 was 99.3%\n",
      "current params: tensor([109.4497, 109.5429, 109.4898, 109.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.1\n",
      "SLow rates:  tensor([[1.0955e+02, 1.0964e+02, 1.0959e+02, 1.0966e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0955e+02, 1.0955e+02, 1.0955e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0964e+02, 1.0964e+02, 1.0964e+02, 1.0000e-01, 1.0000e-01, 1.0964e+02,\n",
      "         1.0964e+02, 1.0000e-01, 1.0959e+02, 1.0959e+02, 1.0959e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0959e+02, 1.0959e+02, 1.0000e-01, 1.0959e+02, 1.0000e-01,\n",
      "         1.0959e+02, 1.0966e+02, 1.0966e+02, 1.0966e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0966e+02, 1.0966e+02, 1.0000e-01, 1.0966e+02, 1.0000e-01, 1.0966e+02,\n",
      "         1.0964e+02, 1.0966e+02, 1.0966e+02, 1.0966e+02, 1.0959e+02, 1.0966e+02,\n",
      "         1.0966e+02, 1.0966e+02, 1.0964e+02, 1.0966e+02, 1.0966e+02, 1.0966e+02,\n",
      "         1.0964e+02, 1.0959e+02, 1.0964e+02, 1.0964e+02, 1.0964e+02, 1.0000e-01,\n",
      "         1.0964e+02, 1.0959e+02, 1.0000e-01, 1.0959e+02, 1.0966e+02, 1.0000e-01,\n",
      "         1.0966e+02, 1.0966e+02, 1.0966e+02, 1.0964e+02, 1.0964e+02, 1.0000e-01,\n",
      "         1.0966e+02, 1.0000e-01, 1.0955e+02, 1.0955e+02, 1.0964e+02, 1.0966e+02,\n",
      "         1.0966e+02, 1.0000e-01, 1.0000e-01, 1.0955e+02, 1.0964e+02, 1.0966e+02,\n",
      "         1.0000e-01, 1.0964e+02, 1.0966e+02, 1.0000e-01, 1.0955e+02, 1.0966e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 967 was 99.3%\n",
      "current params: tensor([109.5497, 109.6429, 109.5898, 109.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.1\n",
      "SLow rates:  tensor([[1.0965e+02, 1.0974e+02, 1.0969e+02, 1.0976e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0965e+02, 1.0965e+02, 1.0965e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0974e+02, 1.0974e+02, 1.0974e+02, 1.0000e-01, 1.0000e-01, 1.0974e+02,\n",
      "         1.0974e+02, 1.0000e-01, 1.0969e+02, 1.0969e+02, 1.0969e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0969e+02, 1.0969e+02, 1.0000e-01, 1.0969e+02, 1.0000e-01,\n",
      "         1.0969e+02, 1.0976e+02, 1.0976e+02, 1.0976e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0976e+02, 1.0976e+02, 1.0000e-01, 1.0976e+02, 1.0000e-01, 1.0976e+02,\n",
      "         1.0974e+02, 1.0976e+02, 1.0976e+02, 1.0976e+02, 1.0969e+02, 1.0976e+02,\n",
      "         1.0976e+02, 1.0976e+02, 1.0974e+02, 1.0976e+02, 1.0976e+02, 1.0976e+02,\n",
      "         1.0974e+02, 1.0969e+02, 1.0974e+02, 1.0974e+02, 1.0974e+02, 1.0000e-01,\n",
      "         1.0974e+02, 1.0969e+02, 1.0000e-01, 1.0969e+02, 1.0976e+02, 1.0000e-01,\n",
      "         1.0976e+02, 1.0976e+02, 1.0976e+02, 1.0974e+02, 1.0974e+02, 1.0000e-01,\n",
      "         1.0976e+02, 1.0000e-01, 1.0965e+02, 1.0965e+02, 1.0974e+02, 1.0976e+02,\n",
      "         1.0976e+02, 1.0000e-01, 1.0000e-01, 1.0965e+02, 1.0974e+02, 1.0976e+02,\n",
      "         1.0000e-01, 1.0974e+02, 1.0976e+02, 1.0000e-01, 1.0965e+02, 1.0976e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 968 was 99.3%\n",
      "current params: tensor([109.6497, 109.7429, 109.6898, 109.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.1\n",
      "SLow rates:  tensor([[1.0975e+02, 1.0984e+02, 1.0979e+02, 1.0986e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0975e+02, 1.0975e+02, 1.0975e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0984e+02, 1.0984e+02, 1.0984e+02, 1.0000e-01, 1.0000e-01, 1.0984e+02,\n",
      "         1.0984e+02, 1.0000e-01, 1.0979e+02, 1.0979e+02, 1.0979e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0979e+02, 1.0979e+02, 1.0000e-01, 1.0979e+02, 1.0000e-01,\n",
      "         1.0979e+02, 1.0986e+02, 1.0986e+02, 1.0986e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0986e+02, 1.0986e+02, 1.0000e-01, 1.0986e+02, 1.0000e-01, 1.0986e+02,\n",
      "         1.0984e+02, 1.0986e+02, 1.0986e+02, 1.0986e+02, 1.0979e+02, 1.0986e+02,\n",
      "         1.0986e+02, 1.0986e+02, 1.0984e+02, 1.0986e+02, 1.0986e+02, 1.0986e+02,\n",
      "         1.0984e+02, 1.0979e+02, 1.0984e+02, 1.0984e+02, 1.0984e+02, 1.0000e-01,\n",
      "         1.0984e+02, 1.0979e+02, 1.0000e-01, 1.0979e+02, 1.0986e+02, 1.0000e-01,\n",
      "         1.0986e+02, 1.0986e+02, 1.0986e+02, 1.0984e+02, 1.0984e+02, 1.0000e-01,\n",
      "         1.0986e+02, 1.0000e-01, 1.0975e+02, 1.0975e+02, 1.0984e+02, 1.0986e+02,\n",
      "         1.0986e+02, 1.0000e-01, 1.0000e-01, 1.0975e+02, 1.0984e+02, 1.0986e+02,\n",
      "         1.0000e-01, 1.0984e+02, 1.0986e+02, 1.0000e-01, 1.0975e+02, 1.0986e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 969 was 99.3%\n",
      "current params: tensor([109.7497, 109.8429, 109.7898, 109.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.1\n",
      "SLow rates:  tensor([[1.0985e+02, 1.0994e+02, 1.0989e+02, 1.0996e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0985e+02, 1.0985e+02, 1.0985e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0994e+02, 1.0994e+02, 1.0994e+02, 1.0000e-01, 1.0000e-01, 1.0994e+02,\n",
      "         1.0994e+02, 1.0000e-01, 1.0989e+02, 1.0989e+02, 1.0989e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0989e+02, 1.0989e+02, 1.0000e-01, 1.0989e+02, 1.0000e-01,\n",
      "         1.0989e+02, 1.0996e+02, 1.0996e+02, 1.0996e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0996e+02, 1.0996e+02, 1.0000e-01, 1.0996e+02, 1.0000e-01, 1.0996e+02,\n",
      "         1.0994e+02, 1.0996e+02, 1.0996e+02, 1.0996e+02, 1.0989e+02, 1.0996e+02,\n",
      "         1.0996e+02, 1.0996e+02, 1.0994e+02, 1.0996e+02, 1.0996e+02, 1.0996e+02,\n",
      "         1.0994e+02, 1.0989e+02, 1.0994e+02, 1.0994e+02, 1.0994e+02, 1.0000e-01,\n",
      "         1.0994e+02, 1.0989e+02, 1.0000e-01, 1.0989e+02, 1.0996e+02, 1.0000e-01,\n",
      "         1.0996e+02, 1.0996e+02, 1.0996e+02, 1.0994e+02, 1.0994e+02, 1.0000e-01,\n",
      "         1.0996e+02, 1.0000e-01, 1.0985e+02, 1.0985e+02, 1.0994e+02, 1.0996e+02,\n",
      "         1.0996e+02, 1.0000e-01, 1.0000e-01, 1.0985e+02, 1.0994e+02, 1.0996e+02,\n",
      "         1.0000e-01, 1.0994e+02, 1.0996e+02, 1.0000e-01, 1.0985e+02, 1.0996e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 970 was 99.3%\n",
      "current params: tensor([109.8497, 109.9429, 109.8898, 109.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.2\n",
      "SLow rates:  tensor([[1.0995e+02, 1.1004e+02, 1.0999e+02, 1.1006e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.0995e+02, 1.0995e+02, 1.0995e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1004e+02, 1.1004e+02, 1.1004e+02, 1.0000e-01, 1.0000e-01, 1.1004e+02,\n",
      "         1.1004e+02, 1.0000e-01, 1.0999e+02, 1.0999e+02, 1.0999e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.0999e+02, 1.0999e+02, 1.0000e-01, 1.0999e+02, 1.0000e-01,\n",
      "         1.0999e+02, 1.1006e+02, 1.1006e+02, 1.1006e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1006e+02, 1.1006e+02, 1.0000e-01, 1.1006e+02, 1.0000e-01, 1.1006e+02,\n",
      "         1.1004e+02, 1.1006e+02, 1.1006e+02, 1.1006e+02, 1.0999e+02, 1.1006e+02,\n",
      "         1.1006e+02, 1.1006e+02, 1.1004e+02, 1.1006e+02, 1.1006e+02, 1.1006e+02,\n",
      "         1.1004e+02, 1.0999e+02, 1.1004e+02, 1.1004e+02, 1.1004e+02, 1.0000e-01,\n",
      "         1.1004e+02, 1.0999e+02, 1.0000e-01, 1.0999e+02, 1.1006e+02, 1.0000e-01,\n",
      "         1.1006e+02, 1.1006e+02, 1.1006e+02, 1.1004e+02, 1.1004e+02, 1.0000e-01,\n",
      "         1.1006e+02, 1.0000e-01, 1.0995e+02, 1.0995e+02, 1.1004e+02, 1.1006e+02,\n",
      "         1.1006e+02, 1.0000e-01, 1.0000e-01, 1.0995e+02, 1.1004e+02, 1.1006e+02,\n",
      "         1.0000e-01, 1.1004e+02, 1.1006e+02, 1.0000e-01, 1.0995e+02, 1.1006e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 971 was 99.3%\n",
      "current params: tensor([109.9497, 110.0429, 109.9898, 110.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.2\n",
      "SLow rates:  tensor([[1.1005e+02, 1.1014e+02, 1.1009e+02, 1.1016e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1005e+02, 1.1005e+02, 1.1005e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1014e+02, 1.1014e+02, 1.1014e+02, 1.0000e-01, 1.0000e-01, 1.1014e+02,\n",
      "         1.1014e+02, 1.0000e-01, 1.1009e+02, 1.1009e+02, 1.1009e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1009e+02, 1.1009e+02, 1.0000e-01, 1.1009e+02, 1.0000e-01,\n",
      "         1.1009e+02, 1.1016e+02, 1.1016e+02, 1.1016e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1016e+02, 1.1016e+02, 1.0000e-01, 1.1016e+02, 1.0000e-01, 1.1016e+02,\n",
      "         1.1014e+02, 1.1016e+02, 1.1016e+02, 1.1016e+02, 1.1009e+02, 1.1016e+02,\n",
      "         1.1016e+02, 1.1016e+02, 1.1014e+02, 1.1016e+02, 1.1016e+02, 1.1016e+02,\n",
      "         1.1014e+02, 1.1009e+02, 1.1014e+02, 1.1014e+02, 1.1014e+02, 1.0000e-01,\n",
      "         1.1014e+02, 1.1009e+02, 1.0000e-01, 1.1009e+02, 1.1016e+02, 1.0000e-01,\n",
      "         1.1016e+02, 1.1016e+02, 1.1016e+02, 1.1014e+02, 1.1014e+02, 1.0000e-01,\n",
      "         1.1016e+02, 1.0000e-01, 1.1005e+02, 1.1005e+02, 1.1014e+02, 1.1016e+02,\n",
      "         1.1016e+02, 1.0000e-01, 1.0000e-01, 1.1005e+02, 1.1014e+02, 1.1016e+02,\n",
      "         1.0000e-01, 1.1014e+02, 1.1016e+02, 1.0000e-01, 1.1005e+02, 1.1016e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 972 was 99.3%\n",
      "current params: tensor([110.0497, 110.1429, 110.0898, 110.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.2\n",
      "SLow rates:  tensor([[1.1015e+02, 1.1024e+02, 1.1019e+02, 1.1026e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1015e+02, 1.1015e+02, 1.1015e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1024e+02, 1.1024e+02, 1.1024e+02, 1.0000e-01, 1.0000e-01, 1.1024e+02,\n",
      "         1.1024e+02, 1.0000e-01, 1.1019e+02, 1.1019e+02, 1.1019e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1019e+02, 1.1019e+02, 1.0000e-01, 1.1019e+02, 1.0000e-01,\n",
      "         1.1019e+02, 1.1026e+02, 1.1026e+02, 1.1026e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1026e+02, 1.1026e+02, 1.0000e-01, 1.1026e+02, 1.0000e-01, 1.1026e+02,\n",
      "         1.1024e+02, 1.1026e+02, 1.1026e+02, 1.1026e+02, 1.1019e+02, 1.1026e+02,\n",
      "         1.1026e+02, 1.1026e+02, 1.1024e+02, 1.1026e+02, 1.1026e+02, 1.1026e+02,\n",
      "         1.1024e+02, 1.1019e+02, 1.1024e+02, 1.1024e+02, 1.1024e+02, 1.0000e-01,\n",
      "         1.1024e+02, 1.1019e+02, 1.0000e-01, 1.1019e+02, 1.1026e+02, 1.0000e-01,\n",
      "         1.1026e+02, 1.1026e+02, 1.1026e+02, 1.1024e+02, 1.1024e+02, 1.0000e-01,\n",
      "         1.1026e+02, 1.0000e-01, 1.1015e+02, 1.1015e+02, 1.1024e+02, 1.1026e+02,\n",
      "         1.1026e+02, 1.0000e-01, 1.0000e-01, 1.1015e+02, 1.1024e+02, 1.1026e+02,\n",
      "         1.0000e-01, 1.1024e+02, 1.1026e+02, 1.0000e-01, 1.1015e+02, 1.1026e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 973 was 99.3%\n",
      "current params: tensor([110.1497, 110.2429, 110.1898, 110.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.2\n",
      "SLow rates:  tensor([[1.1025e+02, 1.1034e+02, 1.1029e+02, 1.1036e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1025e+02, 1.1025e+02, 1.1025e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1034e+02, 1.1034e+02, 1.1034e+02, 1.0000e-01, 1.0000e-01, 1.1034e+02,\n",
      "         1.1034e+02, 1.0000e-01, 1.1029e+02, 1.1029e+02, 1.1029e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1029e+02, 1.1029e+02, 1.0000e-01, 1.1029e+02, 1.0000e-01,\n",
      "         1.1029e+02, 1.1036e+02, 1.1036e+02, 1.1036e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1036e+02, 1.1036e+02, 1.0000e-01, 1.1036e+02, 1.0000e-01, 1.1036e+02,\n",
      "         1.1034e+02, 1.1036e+02, 1.1036e+02, 1.1036e+02, 1.1029e+02, 1.1036e+02,\n",
      "         1.1036e+02, 1.1036e+02, 1.1034e+02, 1.1036e+02, 1.1036e+02, 1.1036e+02,\n",
      "         1.1034e+02, 1.1029e+02, 1.1034e+02, 1.1034e+02, 1.1034e+02, 1.0000e-01,\n",
      "         1.1034e+02, 1.1029e+02, 1.0000e-01, 1.1029e+02, 1.1036e+02, 1.0000e-01,\n",
      "         1.1036e+02, 1.1036e+02, 1.1036e+02, 1.1034e+02, 1.1034e+02, 1.0000e-01,\n",
      "         1.1036e+02, 1.0000e-01, 1.1025e+02, 1.1025e+02, 1.1034e+02, 1.1036e+02,\n",
      "         1.1036e+02, 1.0000e-01, 1.0000e-01, 1.1025e+02, 1.1034e+02, 1.1036e+02,\n",
      "         1.0000e-01, 1.1034e+02, 1.1036e+02, 1.0000e-01, 1.1025e+02, 1.1036e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 974 was 99.3%\n",
      "current params: tensor([110.2497, 110.3429, 110.2898, 110.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.2\n",
      "SLow rates:  tensor([[1.1035e+02, 1.1044e+02, 1.1039e+02, 1.1046e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1035e+02, 1.1035e+02, 1.1035e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1044e+02, 1.1044e+02, 1.1044e+02, 1.0000e-01, 1.0000e-01, 1.1044e+02,\n",
      "         1.1044e+02, 1.0000e-01, 1.1039e+02, 1.1039e+02, 1.1039e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1039e+02, 1.1039e+02, 1.0000e-01, 1.1039e+02, 1.0000e-01,\n",
      "         1.1039e+02, 1.1046e+02, 1.1046e+02, 1.1046e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1046e+02, 1.1046e+02, 1.0000e-01, 1.1046e+02, 1.0000e-01, 1.1046e+02,\n",
      "         1.1044e+02, 1.1046e+02, 1.1046e+02, 1.1046e+02, 1.1039e+02, 1.1046e+02,\n",
      "         1.1046e+02, 1.1046e+02, 1.1044e+02, 1.1046e+02, 1.1046e+02, 1.1046e+02,\n",
      "         1.1044e+02, 1.1039e+02, 1.1044e+02, 1.1044e+02, 1.1044e+02, 1.0000e-01,\n",
      "         1.1044e+02, 1.1039e+02, 1.0000e-01, 1.1039e+02, 1.1046e+02, 1.0000e-01,\n",
      "         1.1046e+02, 1.1046e+02, 1.1046e+02, 1.1044e+02, 1.1044e+02, 1.0000e-01,\n",
      "         1.1046e+02, 1.0000e-01, 1.1035e+02, 1.1035e+02, 1.1044e+02, 1.1046e+02,\n",
      "         1.1046e+02, 1.0000e-01, 1.0000e-01, 1.1035e+02, 1.1044e+02, 1.1046e+02,\n",
      "         1.0000e-01, 1.1044e+02, 1.1046e+02, 1.0000e-01, 1.1035e+02, 1.1046e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 975 was 99.3%\n",
      "current params: tensor([110.3497, 110.4429, 110.3898, 110.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.3\n",
      "SLow rates:  tensor([[1.1045e+02, 1.1054e+02, 1.1049e+02, 1.1056e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1045e+02, 1.1045e+02, 1.1045e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1054e+02, 1.1054e+02, 1.1054e+02, 1.0000e-01, 1.0000e-01, 1.1054e+02,\n",
      "         1.1054e+02, 1.0000e-01, 1.1049e+02, 1.1049e+02, 1.1049e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1049e+02, 1.1049e+02, 1.0000e-01, 1.1049e+02, 1.0000e-01,\n",
      "         1.1049e+02, 1.1056e+02, 1.1056e+02, 1.1056e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1056e+02, 1.1056e+02, 1.0000e-01, 1.1056e+02, 1.0000e-01, 1.1056e+02,\n",
      "         1.1054e+02, 1.1056e+02, 1.1056e+02, 1.1056e+02, 1.1049e+02, 1.1056e+02,\n",
      "         1.1056e+02, 1.1056e+02, 1.1054e+02, 1.1056e+02, 1.1056e+02, 1.1056e+02,\n",
      "         1.1054e+02, 1.1049e+02, 1.1054e+02, 1.1054e+02, 1.1054e+02, 1.0000e-01,\n",
      "         1.1054e+02, 1.1049e+02, 1.0000e-01, 1.1049e+02, 1.1056e+02, 1.0000e-01,\n",
      "         1.1056e+02, 1.1056e+02, 1.1056e+02, 1.1054e+02, 1.1054e+02, 1.0000e-01,\n",
      "         1.1056e+02, 1.0000e-01, 1.1045e+02, 1.1045e+02, 1.1054e+02, 1.1056e+02,\n",
      "         1.1056e+02, 1.0000e-01, 1.0000e-01, 1.1045e+02, 1.1054e+02, 1.1056e+02,\n",
      "         1.0000e-01, 1.1054e+02, 1.1056e+02, 1.0000e-01, 1.1045e+02, 1.1056e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 976 was 99.3%\n",
      "current params: tensor([110.4497, 110.5429, 110.4898, 110.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.3\n",
      "SLow rates:  tensor([[1.1055e+02, 1.1064e+02, 1.1059e+02, 1.1066e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1055e+02, 1.1055e+02, 1.1055e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1064e+02, 1.1064e+02, 1.1064e+02, 1.0000e-01, 1.0000e-01, 1.1064e+02,\n",
      "         1.1064e+02, 1.0000e-01, 1.1059e+02, 1.1059e+02, 1.1059e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1059e+02, 1.1059e+02, 1.0000e-01, 1.1059e+02, 1.0000e-01,\n",
      "         1.1059e+02, 1.1066e+02, 1.1066e+02, 1.1066e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1066e+02, 1.1066e+02, 1.0000e-01, 1.1066e+02, 1.0000e-01, 1.1066e+02,\n",
      "         1.1064e+02, 1.1066e+02, 1.1066e+02, 1.1066e+02, 1.1059e+02, 1.1066e+02,\n",
      "         1.1066e+02, 1.1066e+02, 1.1064e+02, 1.1066e+02, 1.1066e+02, 1.1066e+02,\n",
      "         1.1064e+02, 1.1059e+02, 1.1064e+02, 1.1064e+02, 1.1064e+02, 1.0000e-01,\n",
      "         1.1064e+02, 1.1059e+02, 1.0000e-01, 1.1059e+02, 1.1066e+02, 1.0000e-01,\n",
      "         1.1066e+02, 1.1066e+02, 1.1066e+02, 1.1064e+02, 1.1064e+02, 1.0000e-01,\n",
      "         1.1066e+02, 1.0000e-01, 1.1055e+02, 1.1055e+02, 1.1064e+02, 1.1066e+02,\n",
      "         1.1066e+02, 1.0000e-01, 1.0000e-01, 1.1055e+02, 1.1064e+02, 1.1066e+02,\n",
      "         1.0000e-01, 1.1064e+02, 1.1066e+02, 1.0000e-01, 1.1055e+02, 1.1066e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 977 was 99.3%\n",
      "current params: tensor([110.5497, 110.6429, 110.5898, 110.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.3\n",
      "SLow rates:  tensor([[1.1065e+02, 1.1074e+02, 1.1069e+02, 1.1076e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1065e+02, 1.1065e+02, 1.1065e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1074e+02, 1.1074e+02, 1.1074e+02, 1.0000e-01, 1.0000e-01, 1.1074e+02,\n",
      "         1.1074e+02, 1.0000e-01, 1.1069e+02, 1.1069e+02, 1.1069e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1069e+02, 1.1069e+02, 1.0000e-01, 1.1069e+02, 1.0000e-01,\n",
      "         1.1069e+02, 1.1076e+02, 1.1076e+02, 1.1076e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1076e+02, 1.1076e+02, 1.0000e-01, 1.1076e+02, 1.0000e-01, 1.1076e+02,\n",
      "         1.1074e+02, 1.1076e+02, 1.1076e+02, 1.1076e+02, 1.1069e+02, 1.1076e+02,\n",
      "         1.1076e+02, 1.1076e+02, 1.1074e+02, 1.1076e+02, 1.1076e+02, 1.1076e+02,\n",
      "         1.1074e+02, 1.1069e+02, 1.1074e+02, 1.1074e+02, 1.1074e+02, 1.0000e-01,\n",
      "         1.1074e+02, 1.1069e+02, 1.0000e-01, 1.1069e+02, 1.1076e+02, 1.0000e-01,\n",
      "         1.1076e+02, 1.1076e+02, 1.1076e+02, 1.1074e+02, 1.1074e+02, 1.0000e-01,\n",
      "         1.1076e+02, 1.0000e-01, 1.1065e+02, 1.1065e+02, 1.1074e+02, 1.1076e+02,\n",
      "         1.1076e+02, 1.0000e-01, 1.0000e-01, 1.1065e+02, 1.1074e+02, 1.1076e+02,\n",
      "         1.0000e-01, 1.1074e+02, 1.1076e+02, 1.0000e-01, 1.1065e+02, 1.1076e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 978 was 99.3%\n",
      "current params: tensor([110.6497, 110.7429, 110.6898, 110.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.3\n",
      "SLow rates:  tensor([[1.1075e+02, 1.1084e+02, 1.1079e+02, 1.1086e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1075e+02, 1.1075e+02, 1.1075e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1084e+02, 1.1084e+02, 1.1084e+02, 1.0000e-01, 1.0000e-01, 1.1084e+02,\n",
      "         1.1084e+02, 1.0000e-01, 1.1079e+02, 1.1079e+02, 1.1079e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1079e+02, 1.1079e+02, 1.0000e-01, 1.1079e+02, 1.0000e-01,\n",
      "         1.1079e+02, 1.1086e+02, 1.1086e+02, 1.1086e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1086e+02, 1.1086e+02, 1.0000e-01, 1.1086e+02, 1.0000e-01, 1.1086e+02,\n",
      "         1.1084e+02, 1.1086e+02, 1.1086e+02, 1.1086e+02, 1.1079e+02, 1.1086e+02,\n",
      "         1.1086e+02, 1.1086e+02, 1.1084e+02, 1.1086e+02, 1.1086e+02, 1.1086e+02,\n",
      "         1.1084e+02, 1.1079e+02, 1.1084e+02, 1.1084e+02, 1.1084e+02, 1.0000e-01,\n",
      "         1.1084e+02, 1.1079e+02, 1.0000e-01, 1.1079e+02, 1.1086e+02, 1.0000e-01,\n",
      "         1.1086e+02, 1.1086e+02, 1.1086e+02, 1.1084e+02, 1.1084e+02, 1.0000e-01,\n",
      "         1.1086e+02, 1.0000e-01, 1.1075e+02, 1.1075e+02, 1.1084e+02, 1.1086e+02,\n",
      "         1.1086e+02, 1.0000e-01, 1.0000e-01, 1.1075e+02, 1.1084e+02, 1.1086e+02,\n",
      "         1.0000e-01, 1.1084e+02, 1.1086e+02, 1.0000e-01, 1.1075e+02, 1.1086e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 979 was 99.3%\n",
      "current params: tensor([110.7497, 110.8429, 110.7898, 110.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.3\n",
      "SLow rates:  tensor([[1.1085e+02, 1.1094e+02, 1.1089e+02, 1.1096e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1085e+02, 1.1085e+02, 1.1085e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1094e+02, 1.1094e+02, 1.1094e+02, 1.0000e-01, 1.0000e-01, 1.1094e+02,\n",
      "         1.1094e+02, 1.0000e-01, 1.1089e+02, 1.1089e+02, 1.1089e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1089e+02, 1.1089e+02, 1.0000e-01, 1.1089e+02, 1.0000e-01,\n",
      "         1.1089e+02, 1.1096e+02, 1.1096e+02, 1.1096e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1096e+02, 1.1096e+02, 1.0000e-01, 1.1096e+02, 1.0000e-01, 1.1096e+02,\n",
      "         1.1094e+02, 1.1096e+02, 1.1096e+02, 1.1096e+02, 1.1089e+02, 1.1096e+02,\n",
      "         1.1096e+02, 1.1096e+02, 1.1094e+02, 1.1096e+02, 1.1096e+02, 1.1096e+02,\n",
      "         1.1094e+02, 1.1089e+02, 1.1094e+02, 1.1094e+02, 1.1094e+02, 1.0000e-01,\n",
      "         1.1094e+02, 1.1089e+02, 1.0000e-01, 1.1089e+02, 1.1096e+02, 1.0000e-01,\n",
      "         1.1096e+02, 1.1096e+02, 1.1096e+02, 1.1094e+02, 1.1094e+02, 1.0000e-01,\n",
      "         1.1096e+02, 1.0000e-01, 1.1085e+02, 1.1085e+02, 1.1094e+02, 1.1096e+02,\n",
      "         1.1096e+02, 1.0000e-01, 1.0000e-01, 1.1085e+02, 1.1094e+02, 1.1096e+02,\n",
      "         1.0000e-01, 1.1094e+02, 1.1096e+02, 1.0000e-01, 1.1085e+02, 1.1096e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 980 was 99.3%\n",
      "current params: tensor([110.8497, 110.9429, 110.8898, 110.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.4\n",
      "SLow rates:  tensor([[1.1095e+02, 1.1104e+02, 1.1099e+02, 1.1106e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1095e+02, 1.1095e+02, 1.1095e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1104e+02, 1.1104e+02, 1.1104e+02, 1.0000e-01, 1.0000e-01, 1.1104e+02,\n",
      "         1.1104e+02, 1.0000e-01, 1.1099e+02, 1.1099e+02, 1.1099e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1099e+02, 1.1099e+02, 1.0000e-01, 1.1099e+02, 1.0000e-01,\n",
      "         1.1099e+02, 1.1106e+02, 1.1106e+02, 1.1106e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1106e+02, 1.1106e+02, 1.0000e-01, 1.1106e+02, 1.0000e-01, 1.1106e+02,\n",
      "         1.1104e+02, 1.1106e+02, 1.1106e+02, 1.1106e+02, 1.1099e+02, 1.1106e+02,\n",
      "         1.1106e+02, 1.1106e+02, 1.1104e+02, 1.1106e+02, 1.1106e+02, 1.1106e+02,\n",
      "         1.1104e+02, 1.1099e+02, 1.1104e+02, 1.1104e+02, 1.1104e+02, 1.0000e-01,\n",
      "         1.1104e+02, 1.1099e+02, 1.0000e-01, 1.1099e+02, 1.1106e+02, 1.0000e-01,\n",
      "         1.1106e+02, 1.1106e+02, 1.1106e+02, 1.1104e+02, 1.1104e+02, 1.0000e-01,\n",
      "         1.1106e+02, 1.0000e-01, 1.1095e+02, 1.1095e+02, 1.1104e+02, 1.1106e+02,\n",
      "         1.1106e+02, 1.0000e-01, 1.0000e-01, 1.1095e+02, 1.1104e+02, 1.1106e+02,\n",
      "         1.0000e-01, 1.1104e+02, 1.1106e+02, 1.0000e-01, 1.1095e+02, 1.1106e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 981 was 99.3%\n",
      "current params: tensor([110.9497, 111.0429, 110.9898, 111.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.4\n",
      "SLow rates:  tensor([[1.1105e+02, 1.1114e+02, 1.1109e+02, 1.1116e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1105e+02, 1.1105e+02, 1.1105e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1114e+02, 1.1114e+02, 1.1114e+02, 1.0000e-01, 1.0000e-01, 1.1114e+02,\n",
      "         1.1114e+02, 1.0000e-01, 1.1109e+02, 1.1109e+02, 1.1109e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1109e+02, 1.1109e+02, 1.0000e-01, 1.1109e+02, 1.0000e-01,\n",
      "         1.1109e+02, 1.1116e+02, 1.1116e+02, 1.1116e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1116e+02, 1.1116e+02, 1.0000e-01, 1.1116e+02, 1.0000e-01, 1.1116e+02,\n",
      "         1.1114e+02, 1.1116e+02, 1.1116e+02, 1.1116e+02, 1.1109e+02, 1.1116e+02,\n",
      "         1.1116e+02, 1.1116e+02, 1.1114e+02, 1.1116e+02, 1.1116e+02, 1.1116e+02,\n",
      "         1.1114e+02, 1.1109e+02, 1.1114e+02, 1.1114e+02, 1.1114e+02, 1.0000e-01,\n",
      "         1.1114e+02, 1.1109e+02, 1.0000e-01, 1.1109e+02, 1.1116e+02, 1.0000e-01,\n",
      "         1.1116e+02, 1.1116e+02, 1.1116e+02, 1.1114e+02, 1.1114e+02, 1.0000e-01,\n",
      "         1.1116e+02, 1.0000e-01, 1.1105e+02, 1.1105e+02, 1.1114e+02, 1.1116e+02,\n",
      "         1.1116e+02, 1.0000e-01, 1.0000e-01, 1.1105e+02, 1.1114e+02, 1.1116e+02,\n",
      "         1.0000e-01, 1.1114e+02, 1.1116e+02, 1.0000e-01, 1.1105e+02, 1.1116e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 982 was 99.3%\n",
      "current params: tensor([111.0497, 111.1429, 111.0898, 111.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.4\n",
      "SLow rates:  tensor([[1.1115e+02, 1.1124e+02, 1.1119e+02, 1.1126e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1115e+02, 1.1115e+02, 1.1115e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1124e+02, 1.1124e+02, 1.1124e+02, 1.0000e-01, 1.0000e-01, 1.1124e+02,\n",
      "         1.1124e+02, 1.0000e-01, 1.1119e+02, 1.1119e+02, 1.1119e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1119e+02, 1.1119e+02, 1.0000e-01, 1.1119e+02, 1.0000e-01,\n",
      "         1.1119e+02, 1.1126e+02, 1.1126e+02, 1.1126e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1126e+02, 1.1126e+02, 1.0000e-01, 1.1126e+02, 1.0000e-01, 1.1126e+02,\n",
      "         1.1124e+02, 1.1126e+02, 1.1126e+02, 1.1126e+02, 1.1119e+02, 1.1126e+02,\n",
      "         1.1126e+02, 1.1126e+02, 1.1124e+02, 1.1126e+02, 1.1126e+02, 1.1126e+02,\n",
      "         1.1124e+02, 1.1119e+02, 1.1124e+02, 1.1124e+02, 1.1124e+02, 1.0000e-01,\n",
      "         1.1124e+02, 1.1119e+02, 1.0000e-01, 1.1119e+02, 1.1126e+02, 1.0000e-01,\n",
      "         1.1126e+02, 1.1126e+02, 1.1126e+02, 1.1124e+02, 1.1124e+02, 1.0000e-01,\n",
      "         1.1126e+02, 1.0000e-01, 1.1115e+02, 1.1115e+02, 1.1124e+02, 1.1126e+02,\n",
      "         1.1126e+02, 1.0000e-01, 1.0000e-01, 1.1115e+02, 1.1124e+02, 1.1126e+02,\n",
      "         1.0000e-01, 1.1124e+02, 1.1126e+02, 1.0000e-01, 1.1115e+02, 1.1126e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 983 was 99.3%\n",
      "current params: tensor([111.1497, 111.2429, 111.1898, 111.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.4\n",
      "SLow rates:  tensor([[1.1125e+02, 1.1134e+02, 1.1129e+02, 1.1136e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1125e+02, 1.1125e+02, 1.1125e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1134e+02, 1.1134e+02, 1.1134e+02, 1.0000e-01, 1.0000e-01, 1.1134e+02,\n",
      "         1.1134e+02, 1.0000e-01, 1.1129e+02, 1.1129e+02, 1.1129e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1129e+02, 1.1129e+02, 1.0000e-01, 1.1129e+02, 1.0000e-01,\n",
      "         1.1129e+02, 1.1136e+02, 1.1136e+02, 1.1136e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1136e+02, 1.1136e+02, 1.0000e-01, 1.1136e+02, 1.0000e-01, 1.1136e+02,\n",
      "         1.1134e+02, 1.1136e+02, 1.1136e+02, 1.1136e+02, 1.1129e+02, 1.1136e+02,\n",
      "         1.1136e+02, 1.1136e+02, 1.1134e+02, 1.1136e+02, 1.1136e+02, 1.1136e+02,\n",
      "         1.1134e+02, 1.1129e+02, 1.1134e+02, 1.1134e+02, 1.1134e+02, 1.0000e-01,\n",
      "         1.1134e+02, 1.1129e+02, 1.0000e-01, 1.1129e+02, 1.1136e+02, 1.0000e-01,\n",
      "         1.1136e+02, 1.1136e+02, 1.1136e+02, 1.1134e+02, 1.1134e+02, 1.0000e-01,\n",
      "         1.1136e+02, 1.0000e-01, 1.1125e+02, 1.1125e+02, 1.1134e+02, 1.1136e+02,\n",
      "         1.1136e+02, 1.0000e-01, 1.0000e-01, 1.1125e+02, 1.1134e+02, 1.1136e+02,\n",
      "         1.0000e-01, 1.1134e+02, 1.1136e+02, 1.0000e-01, 1.1125e+02, 1.1136e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 984 was 99.3%\n",
      "current params: tensor([111.2497, 111.3429, 111.2898, 111.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.4\n",
      "SLow rates:  tensor([[1.1135e+02, 1.1144e+02, 1.1139e+02, 1.1146e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1135e+02, 1.1135e+02, 1.1135e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1144e+02, 1.1144e+02, 1.1144e+02, 1.0000e-01, 1.0000e-01, 1.1144e+02,\n",
      "         1.1144e+02, 1.0000e-01, 1.1139e+02, 1.1139e+02, 1.1139e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1139e+02, 1.1139e+02, 1.0000e-01, 1.1139e+02, 1.0000e-01,\n",
      "         1.1139e+02, 1.1146e+02, 1.1146e+02, 1.1146e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1146e+02, 1.1146e+02, 1.0000e-01, 1.1146e+02, 1.0000e-01, 1.1146e+02,\n",
      "         1.1144e+02, 1.1146e+02, 1.1146e+02, 1.1146e+02, 1.1139e+02, 1.1146e+02,\n",
      "         1.1146e+02, 1.1146e+02, 1.1144e+02, 1.1146e+02, 1.1146e+02, 1.1146e+02,\n",
      "         1.1144e+02, 1.1139e+02, 1.1144e+02, 1.1144e+02, 1.1144e+02, 1.0000e-01,\n",
      "         1.1144e+02, 1.1139e+02, 1.0000e-01, 1.1139e+02, 1.1146e+02, 1.0000e-01,\n",
      "         1.1146e+02, 1.1146e+02, 1.1146e+02, 1.1144e+02, 1.1144e+02, 1.0000e-01,\n",
      "         1.1146e+02, 1.0000e-01, 1.1135e+02, 1.1135e+02, 1.1144e+02, 1.1146e+02,\n",
      "         1.1146e+02, 1.0000e-01, 1.0000e-01, 1.1135e+02, 1.1144e+02, 1.1146e+02,\n",
      "         1.0000e-01, 1.1144e+02, 1.1146e+02, 1.0000e-01, 1.1135e+02, 1.1146e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 985 was 99.3%\n",
      "current params: tensor([111.3497, 111.4429, 111.3898, 111.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.5\n",
      "SLow rates:  tensor([[1.1145e+02, 1.1154e+02, 1.1149e+02, 1.1156e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1145e+02, 1.1145e+02, 1.1145e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1154e+02, 1.1154e+02, 1.1154e+02, 1.0000e-01, 1.0000e-01, 1.1154e+02,\n",
      "         1.1154e+02, 1.0000e-01, 1.1149e+02, 1.1149e+02, 1.1149e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1149e+02, 1.1149e+02, 1.0000e-01, 1.1149e+02, 1.0000e-01,\n",
      "         1.1149e+02, 1.1156e+02, 1.1156e+02, 1.1156e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1156e+02, 1.1156e+02, 1.0000e-01, 1.1156e+02, 1.0000e-01, 1.1156e+02,\n",
      "         1.1154e+02, 1.1156e+02, 1.1156e+02, 1.1156e+02, 1.1149e+02, 1.1156e+02,\n",
      "         1.1156e+02, 1.1156e+02, 1.1154e+02, 1.1156e+02, 1.1156e+02, 1.1156e+02,\n",
      "         1.1154e+02, 1.1149e+02, 1.1154e+02, 1.1154e+02, 1.1154e+02, 1.0000e-01,\n",
      "         1.1154e+02, 1.1149e+02, 1.0000e-01, 1.1149e+02, 1.1156e+02, 1.0000e-01,\n",
      "         1.1156e+02, 1.1156e+02, 1.1156e+02, 1.1154e+02, 1.1154e+02, 1.0000e-01,\n",
      "         1.1156e+02, 1.0000e-01, 1.1145e+02, 1.1145e+02, 1.1154e+02, 1.1156e+02,\n",
      "         1.1156e+02, 1.0000e-01, 1.0000e-01, 1.1145e+02, 1.1154e+02, 1.1156e+02,\n",
      "         1.0000e-01, 1.1154e+02, 1.1156e+02, 1.0000e-01, 1.1145e+02, 1.1156e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 986 was 99.3%\n",
      "current params: tensor([111.4497, 111.5429, 111.4898, 111.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.5\n",
      "SLow rates:  tensor([[1.1155e+02, 1.1164e+02, 1.1159e+02, 1.1166e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1155e+02, 1.1155e+02, 1.1155e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1164e+02, 1.1164e+02, 1.1164e+02, 1.0000e-01, 1.0000e-01, 1.1164e+02,\n",
      "         1.1164e+02, 1.0000e-01, 1.1159e+02, 1.1159e+02, 1.1159e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1159e+02, 1.1159e+02, 1.0000e-01, 1.1159e+02, 1.0000e-01,\n",
      "         1.1159e+02, 1.1166e+02, 1.1166e+02, 1.1166e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1166e+02, 1.1166e+02, 1.0000e-01, 1.1166e+02, 1.0000e-01, 1.1166e+02,\n",
      "         1.1164e+02, 1.1166e+02, 1.1166e+02, 1.1166e+02, 1.1159e+02, 1.1166e+02,\n",
      "         1.1166e+02, 1.1166e+02, 1.1164e+02, 1.1166e+02, 1.1166e+02, 1.1166e+02,\n",
      "         1.1164e+02, 1.1159e+02, 1.1164e+02, 1.1164e+02, 1.1164e+02, 1.0000e-01,\n",
      "         1.1164e+02, 1.1159e+02, 1.0000e-01, 1.1159e+02, 1.1166e+02, 1.0000e-01,\n",
      "         1.1166e+02, 1.1166e+02, 1.1166e+02, 1.1164e+02, 1.1164e+02, 1.0000e-01,\n",
      "         1.1166e+02, 1.0000e-01, 1.1155e+02, 1.1155e+02, 1.1164e+02, 1.1166e+02,\n",
      "         1.1166e+02, 1.0000e-01, 1.0000e-01, 1.1155e+02, 1.1164e+02, 1.1166e+02,\n",
      "         1.0000e-01, 1.1164e+02, 1.1166e+02, 1.0000e-01, 1.1155e+02, 1.1166e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 987 was 99.3%\n",
      "current params: tensor([111.5497, 111.6429, 111.5898, 111.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.5\n",
      "SLow rates:  tensor([[1.1165e+02, 1.1174e+02, 1.1169e+02, 1.1176e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1165e+02, 1.1165e+02, 1.1165e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1174e+02, 1.1174e+02, 1.1174e+02, 1.0000e-01, 1.0000e-01, 1.1174e+02,\n",
      "         1.1174e+02, 1.0000e-01, 1.1169e+02, 1.1169e+02, 1.1169e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1169e+02, 1.1169e+02, 1.0000e-01, 1.1169e+02, 1.0000e-01,\n",
      "         1.1169e+02, 1.1176e+02, 1.1176e+02, 1.1176e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1176e+02, 1.1176e+02, 1.0000e-01, 1.1176e+02, 1.0000e-01, 1.1176e+02,\n",
      "         1.1174e+02, 1.1176e+02, 1.1176e+02, 1.1176e+02, 1.1169e+02, 1.1176e+02,\n",
      "         1.1176e+02, 1.1176e+02, 1.1174e+02, 1.1176e+02, 1.1176e+02, 1.1176e+02,\n",
      "         1.1174e+02, 1.1169e+02, 1.1174e+02, 1.1174e+02, 1.1174e+02, 1.0000e-01,\n",
      "         1.1174e+02, 1.1169e+02, 1.0000e-01, 1.1169e+02, 1.1176e+02, 1.0000e-01,\n",
      "         1.1176e+02, 1.1176e+02, 1.1176e+02, 1.1174e+02, 1.1174e+02, 1.0000e-01,\n",
      "         1.1176e+02, 1.0000e-01, 1.1165e+02, 1.1165e+02, 1.1174e+02, 1.1176e+02,\n",
      "         1.1176e+02, 1.0000e-01, 1.0000e-01, 1.1165e+02, 1.1174e+02, 1.1176e+02,\n",
      "         1.0000e-01, 1.1174e+02, 1.1176e+02, 1.0000e-01, 1.1165e+02, 1.1176e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 988 was 99.3%\n",
      "current params: tensor([111.6497, 111.7429, 111.6898, 111.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.5\n",
      "SLow rates:  tensor([[1.1175e+02, 1.1184e+02, 1.1179e+02, 1.1186e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1175e+02, 1.1175e+02, 1.1175e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1184e+02, 1.1184e+02, 1.1184e+02, 1.0000e-01, 1.0000e-01, 1.1184e+02,\n",
      "         1.1184e+02, 1.0000e-01, 1.1179e+02, 1.1179e+02, 1.1179e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1179e+02, 1.1179e+02, 1.0000e-01, 1.1179e+02, 1.0000e-01,\n",
      "         1.1179e+02, 1.1186e+02, 1.1186e+02, 1.1186e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1186e+02, 1.1186e+02, 1.0000e-01, 1.1186e+02, 1.0000e-01, 1.1186e+02,\n",
      "         1.1184e+02, 1.1186e+02, 1.1186e+02, 1.1186e+02, 1.1179e+02, 1.1186e+02,\n",
      "         1.1186e+02, 1.1186e+02, 1.1184e+02, 1.1186e+02, 1.1186e+02, 1.1186e+02,\n",
      "         1.1184e+02, 1.1179e+02, 1.1184e+02, 1.1184e+02, 1.1184e+02, 1.0000e-01,\n",
      "         1.1184e+02, 1.1179e+02, 1.0000e-01, 1.1179e+02, 1.1186e+02, 1.0000e-01,\n",
      "         1.1186e+02, 1.1186e+02, 1.1186e+02, 1.1184e+02, 1.1184e+02, 1.0000e-01,\n",
      "         1.1186e+02, 1.0000e-01, 1.1175e+02, 1.1175e+02, 1.1184e+02, 1.1186e+02,\n",
      "         1.1186e+02, 1.0000e-01, 1.0000e-01, 1.1175e+02, 1.1184e+02, 1.1186e+02,\n",
      "         1.0000e-01, 1.1184e+02, 1.1186e+02, 1.0000e-01, 1.1175e+02, 1.1186e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 989 was 99.3%\n",
      "current params: tensor([111.7497, 111.8429, 111.7898, 111.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.5\n",
      "SLow rates:  tensor([[1.1185e+02, 1.1194e+02, 1.1189e+02, 1.1196e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1185e+02, 1.1185e+02, 1.1185e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1194e+02, 1.1194e+02, 1.1194e+02, 1.0000e-01, 1.0000e-01, 1.1194e+02,\n",
      "         1.1194e+02, 1.0000e-01, 1.1189e+02, 1.1189e+02, 1.1189e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1189e+02, 1.1189e+02, 1.0000e-01, 1.1189e+02, 1.0000e-01,\n",
      "         1.1189e+02, 1.1196e+02, 1.1196e+02, 1.1196e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1196e+02, 1.1196e+02, 1.0000e-01, 1.1196e+02, 1.0000e-01, 1.1196e+02,\n",
      "         1.1194e+02, 1.1196e+02, 1.1196e+02, 1.1196e+02, 1.1189e+02, 1.1196e+02,\n",
      "         1.1196e+02, 1.1196e+02, 1.1194e+02, 1.1196e+02, 1.1196e+02, 1.1196e+02,\n",
      "         1.1194e+02, 1.1189e+02, 1.1194e+02, 1.1194e+02, 1.1194e+02, 1.0000e-01,\n",
      "         1.1194e+02, 1.1189e+02, 1.0000e-01, 1.1189e+02, 1.1196e+02, 1.0000e-01,\n",
      "         1.1196e+02, 1.1196e+02, 1.1196e+02, 1.1194e+02, 1.1194e+02, 1.0000e-01,\n",
      "         1.1196e+02, 1.0000e-01, 1.1185e+02, 1.1185e+02, 1.1194e+02, 1.1196e+02,\n",
      "         1.1196e+02, 1.0000e-01, 1.0000e-01, 1.1185e+02, 1.1194e+02, 1.1196e+02,\n",
      "         1.0000e-01, 1.1194e+02, 1.1196e+02, 1.0000e-01, 1.1185e+02, 1.1196e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 990 was 99.3%\n",
      "current params: tensor([111.8497, 111.9429, 111.8898, 111.9596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.5\n",
      "SLow rates:  tensor([[1.1195e+02, 1.1204e+02, 1.1199e+02, 1.1206e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1195e+02, 1.1195e+02, 1.1195e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1204e+02, 1.1204e+02, 1.1204e+02, 1.0000e-01, 1.0000e-01, 1.1204e+02,\n",
      "         1.1204e+02, 1.0000e-01, 1.1199e+02, 1.1199e+02, 1.1199e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1199e+02, 1.1199e+02, 1.0000e-01, 1.1199e+02, 1.0000e-01,\n",
      "         1.1199e+02, 1.1206e+02, 1.1206e+02, 1.1206e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1206e+02, 1.1206e+02, 1.0000e-01, 1.1206e+02, 1.0000e-01, 1.1206e+02,\n",
      "         1.1204e+02, 1.1206e+02, 1.1206e+02, 1.1206e+02, 1.1199e+02, 1.1206e+02,\n",
      "         1.1206e+02, 1.1206e+02, 1.1204e+02, 1.1206e+02, 1.1206e+02, 1.1206e+02,\n",
      "         1.1204e+02, 1.1199e+02, 1.1204e+02, 1.1204e+02, 1.1204e+02, 1.0000e-01,\n",
      "         1.1204e+02, 1.1199e+02, 1.0000e-01, 1.1199e+02, 1.1206e+02, 1.0000e-01,\n",
      "         1.1206e+02, 1.1206e+02, 1.1206e+02, 1.1204e+02, 1.1204e+02, 1.0000e-01,\n",
      "         1.1206e+02, 1.0000e-01, 1.1195e+02, 1.1195e+02, 1.1204e+02, 1.1206e+02,\n",
      "         1.1206e+02, 1.0000e-01, 1.0000e-01, 1.1195e+02, 1.1204e+02, 1.1206e+02,\n",
      "         1.0000e-01, 1.1204e+02, 1.1206e+02, 1.0000e-01, 1.1195e+02, 1.1206e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 991 was 99.3%\n",
      "current params: tensor([111.9497, 112.0429, 111.9898, 112.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.6\n",
      "SLow rates:  tensor([[1.1205e+02, 1.1214e+02, 1.1209e+02, 1.1216e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1205e+02, 1.1205e+02, 1.1205e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1214e+02, 1.1214e+02, 1.1214e+02, 1.0000e-01, 1.0000e-01, 1.1214e+02,\n",
      "         1.1214e+02, 1.0000e-01, 1.1209e+02, 1.1209e+02, 1.1209e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1209e+02, 1.1209e+02, 1.0000e-01, 1.1209e+02, 1.0000e-01,\n",
      "         1.1209e+02, 1.1216e+02, 1.1216e+02, 1.1216e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1216e+02, 1.1216e+02, 1.0000e-01, 1.1216e+02, 1.0000e-01, 1.1216e+02,\n",
      "         1.1214e+02, 1.1216e+02, 1.1216e+02, 1.1216e+02, 1.1209e+02, 1.1216e+02,\n",
      "         1.1216e+02, 1.1216e+02, 1.1214e+02, 1.1216e+02, 1.1216e+02, 1.1216e+02,\n",
      "         1.1214e+02, 1.1209e+02, 1.1214e+02, 1.1214e+02, 1.1214e+02, 1.0000e-01,\n",
      "         1.1214e+02, 1.1209e+02, 1.0000e-01, 1.1209e+02, 1.1216e+02, 1.0000e-01,\n",
      "         1.1216e+02, 1.1216e+02, 1.1216e+02, 1.1214e+02, 1.1214e+02, 1.0000e-01,\n",
      "         1.1216e+02, 1.0000e-01, 1.1205e+02, 1.1205e+02, 1.1214e+02, 1.1216e+02,\n",
      "         1.1216e+02, 1.0000e-01, 1.0000e-01, 1.1205e+02, 1.1214e+02, 1.1216e+02,\n",
      "         1.0000e-01, 1.1214e+02, 1.1216e+02, 1.0000e-01, 1.1205e+02, 1.1216e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 992 was 99.3%\n",
      "current params: tensor([112.0497, 112.1429, 112.0898, 112.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.6\n",
      "SLow rates:  tensor([[1.1215e+02, 1.1224e+02, 1.1219e+02, 1.1226e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1215e+02, 1.1215e+02, 1.1215e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1224e+02, 1.1224e+02, 1.1224e+02, 1.0000e-01, 1.0000e-01, 1.1224e+02,\n",
      "         1.1224e+02, 1.0000e-01, 1.1219e+02, 1.1219e+02, 1.1219e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1219e+02, 1.1219e+02, 1.0000e-01, 1.1219e+02, 1.0000e-01,\n",
      "         1.1219e+02, 1.1226e+02, 1.1226e+02, 1.1226e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1226e+02, 1.1226e+02, 1.0000e-01, 1.1226e+02, 1.0000e-01, 1.1226e+02,\n",
      "         1.1224e+02, 1.1226e+02, 1.1226e+02, 1.1226e+02, 1.1219e+02, 1.1226e+02,\n",
      "         1.1226e+02, 1.1226e+02, 1.1224e+02, 1.1226e+02, 1.1226e+02, 1.1226e+02,\n",
      "         1.1224e+02, 1.1219e+02, 1.1224e+02, 1.1224e+02, 1.1224e+02, 1.0000e-01,\n",
      "         1.1224e+02, 1.1219e+02, 1.0000e-01, 1.1219e+02, 1.1226e+02, 1.0000e-01,\n",
      "         1.1226e+02, 1.1226e+02, 1.1226e+02, 1.1224e+02, 1.1224e+02, 1.0000e-01,\n",
      "         1.1226e+02, 1.0000e-01, 1.1215e+02, 1.1215e+02, 1.1224e+02, 1.1226e+02,\n",
      "         1.1226e+02, 1.0000e-01, 1.0000e-01, 1.1215e+02, 1.1224e+02, 1.1226e+02,\n",
      "         1.0000e-01, 1.1224e+02, 1.1226e+02, 1.0000e-01, 1.1215e+02, 1.1226e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 993 was 99.3%\n",
      "current params: tensor([112.1497, 112.2429, 112.1898, 112.2596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.6\n",
      "SLow rates:  tensor([[1.1225e+02, 1.1234e+02, 1.1229e+02, 1.1236e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1225e+02, 1.1225e+02, 1.1225e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1234e+02, 1.1234e+02, 1.1234e+02, 1.0000e-01, 1.0000e-01, 1.1234e+02,\n",
      "         1.1234e+02, 1.0000e-01, 1.1229e+02, 1.1229e+02, 1.1229e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1229e+02, 1.1229e+02, 1.0000e-01, 1.1229e+02, 1.0000e-01,\n",
      "         1.1229e+02, 1.1236e+02, 1.1236e+02, 1.1236e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1236e+02, 1.1236e+02, 1.0000e-01, 1.1236e+02, 1.0000e-01, 1.1236e+02,\n",
      "         1.1234e+02, 1.1236e+02, 1.1236e+02, 1.1236e+02, 1.1229e+02, 1.1236e+02,\n",
      "         1.1236e+02, 1.1236e+02, 1.1234e+02, 1.1236e+02, 1.1236e+02, 1.1236e+02,\n",
      "         1.1234e+02, 1.1229e+02, 1.1234e+02, 1.1234e+02, 1.1234e+02, 1.0000e-01,\n",
      "         1.1234e+02, 1.1229e+02, 1.0000e-01, 1.1229e+02, 1.1236e+02, 1.0000e-01,\n",
      "         1.1236e+02, 1.1236e+02, 1.1236e+02, 1.1234e+02, 1.1234e+02, 1.0000e-01,\n",
      "         1.1236e+02, 1.0000e-01, 1.1225e+02, 1.1225e+02, 1.1234e+02, 1.1236e+02,\n",
      "         1.1236e+02, 1.0000e-01, 1.0000e-01, 1.1225e+02, 1.1234e+02, 1.1236e+02,\n",
      "         1.0000e-01, 1.1234e+02, 1.1236e+02, 1.0000e-01, 1.1225e+02, 1.1236e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 994 was 99.3%\n",
      "current params: tensor([112.2497, 112.3429, 112.2898, 112.3596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.6\n",
      "SLow rates:  tensor([[1.1235e+02, 1.1244e+02, 1.1239e+02, 1.1246e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1235e+02, 1.1235e+02, 1.1235e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1244e+02, 1.1244e+02, 1.1244e+02, 1.0000e-01, 1.0000e-01, 1.1244e+02,\n",
      "         1.1244e+02, 1.0000e-01, 1.1239e+02, 1.1239e+02, 1.1239e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1239e+02, 1.1239e+02, 1.0000e-01, 1.1239e+02, 1.0000e-01,\n",
      "         1.1239e+02, 1.1246e+02, 1.1246e+02, 1.1246e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1246e+02, 1.1246e+02, 1.0000e-01, 1.1246e+02, 1.0000e-01, 1.1246e+02,\n",
      "         1.1244e+02, 1.1246e+02, 1.1246e+02, 1.1246e+02, 1.1239e+02, 1.1246e+02,\n",
      "         1.1246e+02, 1.1246e+02, 1.1244e+02, 1.1246e+02, 1.1246e+02, 1.1246e+02,\n",
      "         1.1244e+02, 1.1239e+02, 1.1244e+02, 1.1244e+02, 1.1244e+02, 1.0000e-01,\n",
      "         1.1244e+02, 1.1239e+02, 1.0000e-01, 1.1239e+02, 1.1246e+02, 1.0000e-01,\n",
      "         1.1246e+02, 1.1246e+02, 1.1246e+02, 1.1244e+02, 1.1244e+02, 1.0000e-01,\n",
      "         1.1246e+02, 1.0000e-01, 1.1235e+02, 1.1235e+02, 1.1244e+02, 1.1246e+02,\n",
      "         1.1246e+02, 1.0000e-01, 1.0000e-01, 1.1235e+02, 1.1244e+02, 1.1246e+02,\n",
      "         1.0000e-01, 1.1244e+02, 1.1246e+02, 1.0000e-01, 1.1235e+02, 1.1246e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 995 was 99.3%\n",
      "current params: tensor([112.3497, 112.4429, 112.3898, 112.4596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.6\n",
      "SLow rates:  tensor([[1.1245e+02, 1.1254e+02, 1.1249e+02, 1.1256e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1245e+02, 1.1245e+02, 1.1245e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1254e+02, 1.1254e+02, 1.1254e+02, 1.0000e-01, 1.0000e-01, 1.1254e+02,\n",
      "         1.1254e+02, 1.0000e-01, 1.1249e+02, 1.1249e+02, 1.1249e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1249e+02, 1.1249e+02, 1.0000e-01, 1.1249e+02, 1.0000e-01,\n",
      "         1.1249e+02, 1.1256e+02, 1.1256e+02, 1.1256e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1256e+02, 1.1256e+02, 1.0000e-01, 1.1256e+02, 1.0000e-01, 1.1256e+02,\n",
      "         1.1254e+02, 1.1256e+02, 1.1256e+02, 1.1256e+02, 1.1249e+02, 1.1256e+02,\n",
      "         1.1256e+02, 1.1256e+02, 1.1254e+02, 1.1256e+02, 1.1256e+02, 1.1256e+02,\n",
      "         1.1254e+02, 1.1249e+02, 1.1254e+02, 1.1254e+02, 1.1254e+02, 1.0000e-01,\n",
      "         1.1254e+02, 1.1249e+02, 1.0000e-01, 1.1249e+02, 1.1256e+02, 1.0000e-01,\n",
      "         1.1256e+02, 1.1256e+02, 1.1256e+02, 1.1254e+02, 1.1254e+02, 1.0000e-01,\n",
      "         1.1256e+02, 1.0000e-01, 1.1245e+02, 1.1245e+02, 1.1254e+02, 1.1256e+02,\n",
      "         1.1256e+02, 1.0000e-01, 1.0000e-01, 1.1245e+02, 1.1254e+02, 1.1256e+02,\n",
      "         1.0000e-01, 1.1254e+02, 1.1256e+02, 1.0000e-01, 1.1245e+02, 1.1256e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 996 was 99.3%\n",
      "current params: tensor([112.4497, 112.5429, 112.4898, 112.5596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.7\n",
      "SLow rates:  tensor([[1.1255e+02, 1.1264e+02, 1.1259e+02, 1.1266e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1255e+02, 1.1255e+02, 1.1255e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1264e+02, 1.1264e+02, 1.1264e+02, 1.0000e-01, 1.0000e-01, 1.1264e+02,\n",
      "         1.1264e+02, 1.0000e-01, 1.1259e+02, 1.1259e+02, 1.1259e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1259e+02, 1.1259e+02, 1.0000e-01, 1.1259e+02, 1.0000e-01,\n",
      "         1.1259e+02, 1.1266e+02, 1.1266e+02, 1.1266e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1266e+02, 1.1266e+02, 1.0000e-01, 1.1266e+02, 1.0000e-01, 1.1266e+02,\n",
      "         1.1264e+02, 1.1266e+02, 1.1266e+02, 1.1266e+02, 1.1259e+02, 1.1266e+02,\n",
      "         1.1266e+02, 1.1266e+02, 1.1264e+02, 1.1266e+02, 1.1266e+02, 1.1266e+02,\n",
      "         1.1264e+02, 1.1259e+02, 1.1264e+02, 1.1264e+02, 1.1264e+02, 1.0000e-01,\n",
      "         1.1264e+02, 1.1259e+02, 1.0000e-01, 1.1259e+02, 1.1266e+02, 1.0000e-01,\n",
      "         1.1266e+02, 1.1266e+02, 1.1266e+02, 1.1264e+02, 1.1264e+02, 1.0000e-01,\n",
      "         1.1266e+02, 1.0000e-01, 1.1255e+02, 1.1255e+02, 1.1264e+02, 1.1266e+02,\n",
      "         1.1266e+02, 1.0000e-01, 1.0000e-01, 1.1255e+02, 1.1264e+02, 1.1266e+02,\n",
      "         1.0000e-01, 1.1264e+02, 1.1266e+02, 1.0000e-01, 1.1255e+02, 1.1266e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 997 was 99.3%\n",
      "current params: tensor([112.5497, 112.6429, 112.5898, 112.6596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.7\n",
      "SLow rates:  tensor([[1.1265e+02, 1.1274e+02, 1.1269e+02, 1.1276e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1265e+02, 1.1265e+02, 1.1265e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1274e+02, 1.1274e+02, 1.1274e+02, 1.0000e-01, 1.0000e-01, 1.1274e+02,\n",
      "         1.1274e+02, 1.0000e-01, 1.1269e+02, 1.1269e+02, 1.1269e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1269e+02, 1.1269e+02, 1.0000e-01, 1.1269e+02, 1.0000e-01,\n",
      "         1.1269e+02, 1.1276e+02, 1.1276e+02, 1.1276e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1276e+02, 1.1276e+02, 1.0000e-01, 1.1276e+02, 1.0000e-01, 1.1276e+02,\n",
      "         1.1274e+02, 1.1276e+02, 1.1276e+02, 1.1276e+02, 1.1269e+02, 1.1276e+02,\n",
      "         1.1276e+02, 1.1276e+02, 1.1274e+02, 1.1276e+02, 1.1276e+02, 1.1276e+02,\n",
      "         1.1274e+02, 1.1269e+02, 1.1274e+02, 1.1274e+02, 1.1274e+02, 1.0000e-01,\n",
      "         1.1274e+02, 1.1269e+02, 1.0000e-01, 1.1269e+02, 1.1276e+02, 1.0000e-01,\n",
      "         1.1276e+02, 1.1276e+02, 1.1276e+02, 1.1274e+02, 1.1274e+02, 1.0000e-01,\n",
      "         1.1276e+02, 1.0000e-01, 1.1265e+02, 1.1265e+02, 1.1274e+02, 1.1276e+02,\n",
      "         1.1276e+02, 1.0000e-01, 1.0000e-01, 1.1265e+02, 1.1274e+02, 1.1276e+02,\n",
      "         1.0000e-01, 1.1274e+02, 1.1276e+02, 1.0000e-01, 1.1265e+02, 1.1276e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 998 was 99.3%\n",
      "current params: tensor([112.6497, 112.7429, 112.6898, 112.7596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.7\n",
      "SLow rates:  tensor([[1.1275e+02, 1.1284e+02, 1.1279e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1275e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01, 1.0000e-01, 1.1284e+02,\n",
      "         1.1284e+02, 1.0000e-01, 1.1279e+02, 1.1279e+02, 1.1279e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1279e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.0000e-01,\n",
      "         1.1279e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.0000e-01, 1.1286e+02, 1.0000e-01, 1.1286e+02,\n",
      "         1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1279e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02,\n",
      "         1.1284e+02, 1.1279e+02, 1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1284e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.1286e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.0000e-01, 1.0000e-01, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.0000e-01, 1.1284e+02, 1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1286e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1.0271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 999 was 99.3%\n",
      "optimization complete\n",
      "Final params: tensor([112.6497, 112.7429, 112.6898, 112.7596], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<steric_free_simulator.vectorized_rxn_net.VectorizedRxnNet at 0x1493de581240>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=1000,\n",
    "                  learning_rate=1e-1,\n",
    "                  device='cpu',method=\"RMSprop\")\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1,conc_thresh=1,max_thresh=10,mod_bool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9933, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor([112.6497, 112.7429, 112.6898, 112.7596], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(optim.final_yields[-1])\n",
    "print(optim.final_solns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var(v1,v2):\n",
    "    sq_sum=0\n",
    "    for i in range(len(v1)):\n",
    "        sq_sum=(v1[i]-v2[i])**2+sq_sum\n",
    "    \n",
    "    sq_sum = ((sq_sum)**0.5)/(len(v1)-1)\n",
    "    return(sq_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Yield:  0.9932993310989174 \n",
      "Params:  [112.64971692565294, 112.74287323787904, 112.68978974482913, 112.75959220283309, 0.1, 0.1, 0.1, 112.64971692565294, 112.64971692565294, 112.64971692565294, 0.1, 0.1, 112.74287323787904, 112.74287323787904, 112.74287323787904, 0.1, 0.1, 112.74287323787904, 112.74287323787904, 0.1, 112.68978974482913, 112.68978974482913, 112.68978974482913, 0.1, 0.1, 112.68978974482913, 112.68978974482913, 0.1, 112.68978974482913, 0.1, 112.68978974482913, 112.75959220283309, 112.75959220283309, 112.75959220283309, 0.1, 0.1, 112.75959220283309, 112.75959220283309, 0.1, 112.75959220283309, 0.1, 112.75959220283309, 112.74287323787904, 112.75959220283309, 112.75959220283309, 112.75959220283309, 112.68978974482913, 112.75959220283309, 112.75959220283309, 112.75959220283309, 112.74287323787904, 112.75959220283309, 112.75959220283309, 112.75959220283309, 112.74287323787904, 112.68978974482913, 112.74287323787904, 112.74287323787904, 112.74287323787904, 0.1, 112.74287323787904, 112.68978974482913, 0.1, 112.68978974482913, 112.75959220283309, 0.1, 112.75959220283309, 112.75959220283309, 112.75959220283309, 112.74287323787904, 112.74287323787904, 0.1, 112.75959220283309, 0.1, 112.64971692565294, 112.64971692565294, 112.74287323787904, 112.75959220283309, 112.75959220283309, 0.1, 0.1, 112.64971692565294, 112.74287323787904, 112.75959220283309, 0.1, 112.74287323787904, 112.75959220283309, 0.1, 112.64971692565294, 112.75959220283309]\n"
     ]
    }
   ],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "asymm = []\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    coupled_params=np.zeros(len(vec_rn.kon))\n",
    "    if vec_rn.partial_opt:\n",
    "        for j in range(len(vec_rn.kon)):\n",
    "            if j in vec_rn.rx_cid.keys():\n",
    "                all_rates=[]\n",
    "                for rate in vec_rn.rx_cid[j]:\n",
    "                    if rate in vec_rn.optim_rates:\n",
    "                        all_rates.append(optim.final_solns[i][vec_rn.coup_map[rate]])\n",
    "                    else:\n",
    "                        all_rates.append(vec_rn.kon[rate])\n",
    "                coupled_params[j] = max(all_rates)\n",
    "            else:\n",
    "                if j in vec_rn.optim_rates:\n",
    "                    coupled_params[j] = optim.final_solns[i][vec_rn.coup_map[j]]\n",
    "                else:\n",
    "                    coupled_params[j] = vec_rn.kon[j]\n",
    "    else:\n",
    "        for j in range(len(vec_rn.kon)):\n",
    "            if j in vec_rn.rx_cid.keys():\n",
    "                #new_kon[i] = 1.0\n",
    "                coupled_params[j] = max(optim.final_solns[i].numpy()[vec_rn.coup_map[rate]] for rate in vec_rn.rx_cid[j])\n",
    "                # print(\"Max rate for reaction %s chosen as %.3f\" %(i,self.coupled_kon[i]))\n",
    "            else:\n",
    "                coupled_params[j] = optim.final_solns[i].numpy()[vec_rn.coup_map[j]]\n",
    "    final_params.append(coupled_params)\n",
    "    \n",
    "    if type(optim.final_t50[i])==int:\n",
    "        final_t50.append(1) \n",
    "    else:\n",
    "        final_t50.append(optim.final_t50[i].item()) \n",
    "    if type(optim.final_t85[i])==int:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i].item()) \n",
    "    if type(optim.final_t95[i])==int:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i].item())\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)#[sort_indx]\n",
    "sorted_params = np.array(final_params)#[sort_indx]\n",
    "\n",
    "sorted_t50 = np.array(final_t50)#[sort_indx]\n",
    "sorted_t85 = np.array(final_t85)#[sort_indx]\n",
    "sorted_t95 = np.array(final_t95)#[sort_indx]\n",
    "\n",
    "\n",
    "# print(\"Yield: \",sorted_yields[arg_indx[0]],\"\\nParams: \",sorted_params[arg_indx[0]])\n",
    "\n",
    "# print(\"Yield: \",sorted_yields[arg_indx[-1]],\"\\nParams: \",sorted_params[arg_indx[-1]])\n",
    "print(\"Max Yield: \",sorted_yields[-1],\"\\nParams: \",list(sorted_params[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing all solutions to a file\n",
    "\n",
    "klabels=['k'+str(i) for i in range(len(vec_rn.kon))]\n",
    "header = '#Yield\\t' + \"\\t\".join(klabels) + \"\\tt50\\tt85\\tt95\\n\"\n",
    "\n",
    "\n",
    "with open(\"Solutions_Pentamer_Coupled_4Interfaces_20kT\",'w') as fl:\n",
    "    fl.write(header)\n",
    "    for i in range(len(sorted_yields)):\n",
    "        fl.write(\"%f\" %(sorted_yields[i]))\n",
    "        \n",
    "        for j in range((sorted_params[i].shape[0])):\n",
    "            \n",
    "            fl.write(\"\\t%f\" %(sorted_params[i][j]))\n",
    "        fl.write(\"\\t%f\\t%f\\t%f\\n\" %(sorted_t50[i],sorted_t85[i],sorted_t95[i]))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "PQ\n",
      "PR\n",
      "PS\n",
      "PT\n",
      "QR\n",
      "QS\n",
      "QT\n",
      "PQR\n",
      "PQS\n",
      "PQT\n",
      "RS\n",
      "RT\n",
      "PRS\n",
      "PRT\n",
      "QRS\n",
      "QRT\n",
      "PQRS\n",
      "PQRT\n",
      "ST\n",
      "PST\n",
      "QST\n",
      "PQST\n",
      "RST\n",
      "PRST\n",
      "QRST\n",
      "PQRST\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'S'}, {'P', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'S'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'R'}, {'P', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'R'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'Q', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'T'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'Q', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'S'}, {'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'Q', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'T'}, {'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q', 'T'}, {'P', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q', 'R'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q', 'S'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'T', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'T', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'Q', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'T', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q', 'T'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'R'}, {'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'T', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-120.], dtype=torch.float64), 'koff': 7.66764807372196e-48}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q', 'T', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'T'}), 'kon': 0.10000000000000002, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.00020611536224385545}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'P', 'Q'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'T'}), 'kon': 0.10000000000000002, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.00020611536224385545}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'R'}, {'S'}), 'kon': 0.10000000000000002, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.00020611536224385545}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'T'}), 'kon': 0.10000000000000002, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.00020611536224385545}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'S'}), 'kon': 0.10000000000000002, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.00020611536224385545}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'R'}), 'kon': 0.10000000000000002, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.00020611536224385545}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'Q'}, {'P', 'T', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P', 'Q'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'Q', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'S', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'Q', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'Q'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-80.], dtype=torch.float64), 'koff': 1.804851387845406e-30}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'Q', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'T', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q', 'T'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'S'}, {'P', 'Q', 'R'}), 'kon': 0.10000000000000002, 'score': tensor([-60.], dtype=torch.float64), 'koff': 8.756510762696539e-22}\n",
      "tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'T'}, {'P', 'S'}), 'kon': 0.10000000000000002, 'score': tensor([-40.], dtype=torch.float64), 'koff': 4.2483542552915974e-13}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'T'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'S'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'R'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557}\n",
      "tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'P'}, {'Q'}), 'kon': 1.0, 'score': tensor([-20.], dtype=torch.float64), 'koff': 0.002061153622438557}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off']}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['P', 'PQ', 'PQR', 'PQRS', 'PQRST'], ['Q', 'PQ', 'PQR', 'PQRS', 'PQRST'], ['R', 'PR', 'PQR', 'PQRS', 'PQRST'], ['S', 'PS', 'PQS', 'PQRS', 'PQRST'], ['T', 'PT', 'PQT', 'PQRT', 'PQRST'], ['PQ', 'PQR', 'PQRS', 'PQRST'], ['PR', 'PQR', 'PQRS', 'PQRST'], ['PS', 'PQS', 'PQRS', 'PQRST'], ['PT', 'PQT', 'PQRT', 'PQRST'], ['QR', 'QRS', 'QRST', 'PQRST'], ['QS', 'QRS', 'QRST', 'PQRST'], ['QT', 'QRT', 'QRST', 'PQRST'], ['PQR', 'PQRS', 'PQRST'], ['PQS', 'PQRS', 'PQRST'], ['PQT', 'PQRT', 'PQRST'], ['RS', 'RST', 'PQRST'], ['RT', 'RST', 'PQRST'], ['PRS', 'PRST', 'PQRST'], ['PRT', 'PRST', 'PQRST'], ['QRS', 'QRST', 'PQRST'], ['QRT', 'QRST', 'PQRST'], ['PQRS', 'PQRST'], ['PQRT', 'PQRST'], ['ST', 'PQST', 'PQRST'], ['PST', 'PQRST'], ['QST', 'PQRST'], ['PQST', 'PQRST'], ['RST', 'PQRST'], ['PRST', 'PQRST'], ['QRST', 'PQRST'], ['PQRST']]\n",
      "[1.3000000000000003, 1.3000000000000003, 1.3000000000000003, 1.3000000000000003, 1.3000000000000003, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0]\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "#             #Calculate k_off also\n",
    "#             std_c = Tensor([1.])\n",
    "#             l_kon = torch.log(temp_kon)\n",
    "#             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQRS  :  0.1\n",
      "PQRT  :  0.1\n",
      "QRST  :  0.1\n",
      "PRST  :  0.1\n",
      "PQST  :  0.1\n",
      "PQR  :  0.30000000000000004\n",
      "PQS  :  0.30000000000000004\n",
      "PQT  :  0.30000000000000004\n",
      "QRS  :  0.30000000000000004\n",
      "QRT  :  0.30000000000000004\n",
      "RST  :  0.30000000000000004\n",
      "PRS  :  0.30000000000000004\n",
      "PRT  :  0.30000000000000004\n",
      "PST  :  0.30000000000000004\n",
      "QST  :  0.30000000000000004\n",
      "PQ  :  0.7\n",
      "PR  :  0.7\n",
      "PS  :  0.7\n",
      "PT  :  0.7\n",
      "QR  :  0.7\n",
      "QS  :  0.7\n",
      "QT  :  0.7\n",
      "RS  :  0.7\n",
      "RT  :  0.7\n",
      "ST  :  0.7\n",
      "Q  :  2.4000000000000012\n",
      "R  :  2.4000000000000012\n",
      "S  :  2.4000000000000012\n",
      "T  :  2.4000000000000012\n",
      "P  :  5.099999999999996\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes_list = ['A','B','S','M','AB','BMS','ABS','AMS','ABMS','AM','AS']\n",
    "#nodes_list = ['A','B','ABMS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Start of simulation: memory Used:  24.7\n",
      "SLow rates:  tensor([[1.1275e+02, 1.1284e+02, 1.1279e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1275e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01, 1.0000e-01, 1.1284e+02,\n",
      "         1.1284e+02, 1.0000e-01, 1.1279e+02, 1.1279e+02, 1.1279e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1279e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.0000e-01,\n",
      "         1.1279e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.0000e-01, 1.1286e+02, 1.0000e-01, 1.1286e+02,\n",
      "         1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1279e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02,\n",
      "         1.1284e+02, 1.1279e+02, 1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1284e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.1286e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.0000e-01, 1.0000e-01, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.0000e-01, 1.1284e+02, 1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1286e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1020.0690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.7\n",
      "SLow rates:  tensor([[1.1275e+02, 1.1284e+02, 1.1279e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1275e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01, 1.0000e-01, 1.1284e+02,\n",
      "         1.1284e+02, 1.0000e-01, 1.1279e+02, 1.1279e+02, 1.1279e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1279e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.0000e-01,\n",
      "         1.1279e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.0000e-01, 1.1286e+02, 1.0000e-01, 1.1286e+02,\n",
      "         1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1279e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02,\n",
      "         1.1284e+02, 1.1279e+02, 1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1284e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.1286e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.0000e-01, 1.0000e-01, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.0000e-01, 1.1284e+02, 1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1286e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1020.0690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  24.7\n",
      "SLow rates:  tensor([[1.1275e+02, 1.1284e+02, 1.1279e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1275e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01, 1.0000e-01, 1.1284e+02,\n",
      "         1.1284e+02, 1.0000e-01, 1.1279e+02, 1.1279e+02, 1.1279e+02, 1.0000e-01,\n",
      "         1.0000e-01, 1.1279e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.0000e-01,\n",
      "         1.1279e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.0000e-01, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.0000e-01, 1.1286e+02, 1.0000e-01, 1.1286e+02,\n",
      "         1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1279e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1286e+02, 1.1286e+02, 1.1286e+02,\n",
      "         1.1284e+02, 1.1279e+02, 1.1284e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1284e+02, 1.1279e+02, 1.0000e-01, 1.1279e+02, 1.1286e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.1286e+02, 1.1286e+02, 1.1284e+02, 1.1284e+02, 1.0000e-01,\n",
      "         1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.1286e+02, 1.0000e-01, 1.0000e-01, 1.1275e+02, 1.1284e+02, 1.1286e+02,\n",
      "         1.0000e-01, 1.1284e+02, 1.1286e+02, 1.0000e-01, 1.1275e+02, 1.1286e+02]],\n",
      "       dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Next time:  tensor(1020.0690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "{'P': 0, 'Q': 1, 'R': 2, 'S': 3, 'T': 4, 'PQ': 5, 'PR': 6, 'PS': 7, 'PT': 8, 'QR': 9, 'QS': 10, 'QT': 11, 'PQR': 12, 'PQS': 13, 'PQT': 14, 'RS': 15, 'RT': 16, 'PRS': 17, 'PRT': 18, 'QRS': 19, 'QRT': 20, 'PQRS': 21, 'PQRT': 22, 'ST': 23, 'PST': 24, 'QST': 25, 'PQST': 26, 'RST': 27, 'PRST': 28, 'QRST': 29, 'PQRST': 30}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([1, 8, 64]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i],)\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 0, 'Q': 1, 'R': 2, 'S': 3, 'T': 4, 'PQ': 5, 'PR': 6, 'PS': 7, 'PT': 8, 'QR': 9, 'QS': 10, 'QT': 11, 'PQR': 12, 'PQS': 13, 'PQT': 14, 'RS': 15, 'RT': 16, 'PRS': 17, 'PRT': 18, 'QRS': 19, 'QRT': 20, 'PQRS': 21, 'PQRT': 22, 'ST': 23, 'PST': 24, 'QST': 25, 'PQST': 26, 'RST': 27, 'PRST': 28, 'QRST': 29, 'PQRST': 30}\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  P + Q  ->  PQ\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  P + R  ->  PR\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  P + S  ->  PS\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  P + T  ->  PT\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  P + QR  ->  PQR\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 58}\n",
      "Reaction:  P + QS  ->  PQS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 61}\n",
      "Reaction:  P + QT  ->  PQT\n",
      "Net flux:  tensor([1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "Reaction:  P + RS  ->  PRS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 70}\n",
      "Reaction:  P + RT  ->  PRT\n",
      "Net flux:  tensor([1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 72}\n",
      "Reaction:  P + QRS  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 76}\n",
      "Reaction:  P + QRT  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 77}\n",
      "Reaction:  P + ST  ->  PST\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 78}\n",
      "Reaction:  P + QST  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 83}\n",
      "Reaction:  P + RST  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 86}\n",
      "Reaction:  P + QRST  ->  PQRST\n",
      "Net flux:  tensor([9.6210], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 89}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  Q + P  ->  PQ\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  Q + R  ->  QR\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  Q + S  ->  QS\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  Q + T  ->  QT\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "Reaction:  Q + PR  ->  PQR\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 7}\n",
      "Reaction:  Q + PS  ->  PQS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "Reaction:  Q + PT  ->  PQT\n",
      "Net flux:  tensor([1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "Reaction:  Q + RS  ->  QRS\n",
      "Net flux:  tensor([7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 71}\n",
      "Reaction:  Q + RT  ->  QRT\n",
      "Net flux:  tensor([7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 73}\n",
      "Reaction:  Q + PRS  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 74}\n",
      "Reaction:  Q + PRT  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 75}\n",
      "Reaction:  Q + ST  ->  QST\n",
      "Net flux:  tensor([7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 79}\n",
      "Reaction:  Q + PST  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 81}\n",
      "Reaction:  Q + RST  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 87}\n",
      "Reaction:  Q + PRST  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 88}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  R + P  ->  PR\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  R + Q  ->  QR\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  R + S  ->  RS\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "Reaction:  R + T  ->  RT\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "Reaction:  R + PQ  ->  PQR\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "Reaction:  R + PS  ->  PRS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "Reaction:  R + PT  ->  PRT\n",
      "Net flux:  tensor([1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "Reaction:  R + QS  ->  QRS\n",
      "Net flux:  tensor([7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 15}\n",
      "Reaction:  R + QT  ->  QRT\n",
      "Net flux:  tensor([7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "Reaction:  R + PQS  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 17}\n",
      "Reaction:  R + PQT  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 18}\n",
      "Reaction:  R + ST  ->  RST\n",
      "Net flux:  tensor([7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 80}\n",
      "Reaction:  R + PST  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 82}\n",
      "Reaction:  R + QST  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 84}\n",
      "Reaction:  R + PQST  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 85}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  S + P  ->  PS\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  S + Q  ->  QS\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  S + R  ->  RS\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "Reaction:  S + T  ->  ST\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "Reaction:  S + PQ  ->  PQS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "Reaction:  S + PR  ->  PRS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "Reaction:  S + PT  ->  PST\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "Reaction:  S + QR  ->  QRS\n",
      "Net flux:  tensor([7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "Reaction:  S + QT  ->  QST\n",
      "Net flux:  tensor([7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction:  S + PQR  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 25}\n",
      "Reaction:  S + PQT  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 26}\n",
      "Reaction:  S + RT  ->  RST\n",
      "Net flux:  tensor([7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "Reaction:  S + PRT  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 28}\n",
      "Reaction:  S + QRT  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 29}\n",
      "Reaction:  S + PQRT  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 30}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  T + P  ->  PT\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  T + Q  ->  QT\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "Reaction:  T + R  ->  RT\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "Reaction:  T + S  ->  ST\n",
      "Net flux:  tensor([-0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "Reaction:  T + PQ  ->  PQT\n",
      "Net flux:  tensor([1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 31}\n",
      "Reaction:  T + PR  ->  PRT\n",
      "Net flux:  tensor([1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 32}\n",
      "Reaction:  T + PS  ->  PST\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 33}\n",
      "Reaction:  T + QR  ->  QRT\n",
      "Net flux:  tensor([7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 34}\n",
      "Reaction:  T + QS  ->  QST\n",
      "Net flux:  tensor([7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "Reaction:  T + PQR  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 36}\n",
      "Reaction:  T + PQS  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 37}\n",
      "Reaction:  T + RS  ->  RST\n",
      "Net flux:  tensor([7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "Reaction:  T + PRS  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction:  T + QRS  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 40}\n",
      "Reaction:  T + PQRS  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 41}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQ + R  ->  PQR\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "Reaction:  PQ + S  ->  PQS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "Reaction:  PQ + T  ->  PQT\n",
      "Net flux:  tensor([1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 31}\n",
      "Reaction:  PQ + RS  ->  PQRS\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 42}\n",
      "Reaction:  PQ + RT  ->  PQRT\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 43}\n",
      "Reaction:  PQ + ST  ->  PQST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 44}\n",
      "Reaction:  PQ + RST  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 45}\n",
      "Reaction:  PQ  ->  P + Q\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PR + Q  ->  PQR\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 7}\n",
      "Reaction:  PR + S  ->  PRS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "Reaction:  PR + T  ->  PRT\n",
      "Net flux:  tensor([1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 32}\n",
      "Reaction:  PR + QS  ->  PQRS\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 46}\n",
      "Reaction:  PR + QT  ->  PQRT\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 47}\n",
      "Reaction:  PR + ST  ->  PRST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 48}\n",
      "Reaction:  PR + QST  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 49}\n",
      "Reaction:  PR  ->  P + R\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PS + Q  ->  PQS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "Reaction:  PS + R  ->  PRS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "Reaction:  PS + T  ->  PST\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 33}\n",
      "Reaction:  PS + QR  ->  PQRS\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 50}\n",
      "Reaction:  PS + QT  ->  PQST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 51}\n",
      "Reaction:  PS + RT  ->  PRST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 52}\n",
      "Reaction:  PS + QRT  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 53}\n",
      "Reaction:  PS  ->  P + S\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PT + Q  ->  PQT\n",
      "Net flux:  tensor([1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "Reaction:  PT + R  ->  PRT\n",
      "Net flux:  tensor([1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "Reaction:  PT + S  ->  PST\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "Reaction:  PT + QR  ->  PQRT\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 54}\n",
      "Reaction:  PT + QS  ->  PQST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 55}\n",
      "Reaction:  PT + RS  ->  PRST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 56}\n",
      "Reaction:  PT + QRS  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 57}\n",
      "Reaction:  PT  ->  P + T\n",
      "Net flux:  tensor([0.], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.9912], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 1.0, 'k_off': 0.002061153622438557, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QR + S  ->  QRS\n",
      "Net flux:  tensor([7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "Reaction:  QR + T  ->  QRT\n",
      "Net flux:  tensor([7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 34}\n",
      "Reaction:  QR + PS  ->  PQRS\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 50}\n",
      "Reaction:  QR + PT  ->  PQRT\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 54}\n",
      "Reaction:  QR + P  ->  PQR\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 58}\n",
      "Reaction:  QR + ST  ->  QRST\n",
      "Net flux:  tensor([0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 59}\n",
      "Reaction:  QR + PST  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 60}\n",
      "Reaction:  QR  ->  Q + R\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QS + R  ->  QRS\n",
      "Net flux:  tensor([7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 15}\n",
      "Reaction:  QS + T  ->  QST\n",
      "Net flux:  tensor([7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "Reaction:  QS + PR  ->  PQRS\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 46}\n",
      "Reaction:  QS + PT  ->  PQST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 55}\n",
      "Reaction:  QS + P  ->  PQS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 61}\n",
      "Reaction:  QS + RT  ->  QRST\n",
      "Net flux:  tensor([0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 62}\n",
      "Reaction:  QS + PRT  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 63}\n",
      "Reaction:  QS  ->  Q + S\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QT + R  ->  QRT\n",
      "Net flux:  tensor([7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "Reaction:  QT + S  ->  QST\n",
      "Net flux:  tensor([7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction:  QT + PR  ->  PQRT\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 47}\n",
      "Reaction:  QT + PS  ->  PQST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 51}\n",
      "Reaction:  QT + P  ->  PQT\n",
      "Net flux:  tensor([1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "Reaction:  QT + RS  ->  QRST\n",
      "Net flux:  tensor([0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 65}\n",
      "Reaction:  QT + PRS  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 66}\n",
      "Reaction:  QT  ->  Q + T\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQR + S  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 25}\n",
      "Reaction:  PQR + T  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 36}\n",
      "Reaction:  PQR + ST  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 67}\n",
      "Reaction:  PQR  ->  Q + PR\n",
      "Net flux:  tensor([-1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 7}\n",
      "Reaction:  PQR  ->  R + PQ\n",
      "Net flux:  tensor([-1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "Reaction:  PQR  ->  QR + P\n",
      "Net flux:  tensor([-1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 58}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQS + R  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 17}\n",
      "Reaction:  PQS + T  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 37}\n",
      "Reaction:  PQS + RT  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 68}\n",
      "Reaction:  PQS  ->  Q + PS\n",
      "Net flux:  tensor([-1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "Reaction:  PQS  ->  S + PQ\n",
      "Net flux:  tensor([-1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "Reaction:  PQS  ->  QS + P\n",
      "Net flux:  tensor([-1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 61}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQT + R  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 18}\n",
      "Reaction:  PQT + S  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 26}\n",
      "Reaction:  PQT + RS  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction:  PQT  ->  Q + PT\n",
      "Net flux:  tensor([-1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "Reaction:  PQT  ->  T + PQ\n",
      "Net flux:  tensor([-1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 31}\n",
      "Reaction:  PQT  ->  QT + P\n",
      "Net flux:  tensor([-1.0843e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  RS + T  ->  RST\n",
      "Net flux:  tensor([7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "Reaction:  RS + PQ  ->  PQRS\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 42}\n",
      "Reaction:  RS + PT  ->  PRST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 56}\n",
      "Reaction:  RS + QT  ->  QRST\n",
      "Net flux:  tensor([0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 65}\n",
      "Reaction:  RS + PQT  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction:  RS + P  ->  PRS\n",
      "Net flux:  tensor([1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 70}\n",
      "Reaction:  RS + Q  ->  QRS\n",
      "Net flux:  tensor([7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 71}\n",
      "Reaction:  RS  ->  R + S\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  RT + S  ->  RST\n",
      "Net flux:  tensor([7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "Reaction:  RT + PQ  ->  PQRT\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 43}\n",
      "Reaction:  RT + PS  ->  PRST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 52}\n",
      "Reaction:  RT + QS  ->  QRST\n",
      "Net flux:  tensor([0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 62}\n",
      "Reaction:  RT + PQS  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 68}\n",
      "Reaction:  RT + P  ->  PRT\n",
      "Net flux:  tensor([1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 72}\n",
      "Reaction:  RT + Q  ->  QRT\n",
      "Net flux:  tensor([7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 73}\n",
      "Reaction:  RT  ->  R + T\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PRS + T  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction:  PRS + QT  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 66}\n",
      "Reaction:  PRS + Q  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 74}\n",
      "Reaction:  PRS  ->  R + PS\n",
      "Net flux:  tensor([-1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "Reaction:  PRS  ->  S + PR\n",
      "Net flux:  tensor([-1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "Reaction:  PRS  ->  RS + P\n",
      "Net flux:  tensor([-1.0841e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 70}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PRT + S  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 28}\n",
      "Reaction:  PRT + QS  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 63}\n",
      "Reaction:  PRT + Q  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 75}\n",
      "Reaction:  PRT  ->  R + PT\n",
      "Net flux:  tensor([-1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "Reaction:  PRT  ->  T + PR\n",
      "Net flux:  tensor([-1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 32}\n",
      "Reaction:  PRT  ->  RT + P\n",
      "Net flux:  tensor([-1.0840e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 72}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QRS + T  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 40}\n",
      "Reaction:  QRS + PT  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 57}\n",
      "Reaction:  QRS + P  ->  PQRS\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 76}\n",
      "Reaction:  QRS  ->  R + QS\n",
      "Net flux:  tensor([-7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 15}\n",
      "Reaction:  QRS  ->  S + QR\n",
      "Net flux:  tensor([-7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "Reaction:  QRS  ->  RS + Q\n",
      "Net flux:  tensor([-7.6097e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 71}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QRT + S  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 29}\n",
      "Reaction:  QRT + PS  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 53}\n",
      "Reaction:  QRT + P  ->  PQRT\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 77}\n",
      "Reaction:  QRT  ->  R + QT\n",
      "Net flux:  tensor([-7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "Reaction:  QRT  ->  T + QR\n",
      "Net flux:  tensor([-7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 34}\n",
      "Reaction:  QRT  ->  RT + Q\n",
      "Net flux:  tensor([-7.6066e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 73}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQRS + T  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 41}\n",
      "Reaction:  PQRS  ->  R + PQS\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 17}\n",
      "Reaction:  PQRS  ->  S + PQR\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 25}\n",
      "Reaction:  PQRS  ->  PQ + RS\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 42}\n",
      "Reaction:  PQRS  ->  PR + QS\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 46}\n",
      "Reaction:  PQRS  ->  PS + QR\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 50}\n",
      "Reaction:  PQRS  ->  PRS + Q\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 74}\n",
      "Reaction:  PQRS  ->  QRS + P\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 76}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQRT + S  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 30}\n",
      "Reaction:  PQRT  ->  R + PQT\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 18}\n",
      "Reaction:  PQRT  ->  T + PQR\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 36}\n",
      "Reaction:  PQRT  ->  PQ + RT\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 43}\n",
      "Reaction:  PQRT  ->  PR + QT\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 47}\n",
      "Reaction:  PQRT  ->  PT + QR\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 54}\n",
      "Reaction:  PQRT  ->  PRT + Q\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 75}\n",
      "Reaction:  PQRT  ->  QRT + P\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 77}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  ST + PQ  ->  PQST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 44}\n",
      "Reaction:  ST + PR  ->  PRST\n",
      "Net flux:  tensor([0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 48}\n",
      "Reaction:  ST + QR  ->  QRST\n",
      "Net flux:  tensor([0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 59}\n",
      "Reaction:  ST + PQR  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 67}\n",
      "Reaction:  ST + P  ->  PST\n",
      "Net flux:  tensor([1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 78}\n",
      "Reaction:  ST + Q  ->  QST\n",
      "Net flux:  tensor([7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 79}\n",
      "Reaction:  ST + R  ->  RST\n",
      "Net flux:  tensor([7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 80}\n",
      "Reaction:  ST  ->  S + T\n",
      "Net flux:  tensor([0.0001], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0991], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 0.00020611536224385545, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PST + QR  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 60}\n",
      "Reaction:  PST + Q  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 81}\n",
      "Reaction:  PST + R  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 82}\n",
      "Reaction:  PST  ->  S + PT\n",
      "Net flux:  tensor([-1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "Reaction:  PST  ->  T + PS\n",
      "Net flux:  tensor([-1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 33}\n",
      "Reaction:  PST  ->  ST + P\n",
      "Net flux:  tensor([-1.0842e-11], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 78}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QST + PR  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 49}\n",
      "Reaction:  QST + P  ->  PQST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 83}\n",
      "Reaction:  QST + R  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 84}\n",
      "Reaction:  QST  ->  S + QT\n",
      "Net flux:  tensor([-7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction:  QST  ->  T + QS\n",
      "Net flux:  tensor([-7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "Reaction:  QST  ->  ST + Q\n",
      "Net flux:  tensor([-7.6088e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 79}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQST + R  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 85}\n",
      "Reaction:  PQST  ->  S + PQT\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 26}\n",
      "Reaction:  PQST  ->  T + PQS\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 37}\n",
      "Reaction:  PQST  ->  PQ + ST\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 44}\n",
      "Reaction:  PQST  ->  PS + QT\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 51}\n",
      "Reaction:  PQST  ->  PT + QS\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 55}\n",
      "Reaction:  PQST  ->  PST + Q\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 81}\n",
      "Reaction:  PQST  ->  QST + P\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 83}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  RST + PQ  ->  PQRST\n",
      "Net flux:  tensor([9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 45}\n",
      "Reaction:  RST + P  ->  PRST\n",
      "Net flux:  tensor([0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 86}\n",
      "Reaction:  RST + Q  ->  QRST\n",
      "Net flux:  tensor([0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 87}\n",
      "Reaction:  RST  ->  S + RT\n",
      "Net flux:  tensor([-7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "Reaction:  RST  ->  T + RS\n",
      "Net flux:  tensor([-7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "Reaction:  RST  ->  ST + R\n",
      "Net flux:  tensor([-7.6052e-05], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0983], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 4.2483542552915974e-13, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 80}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PRST + Q  ->  PQRST\n",
      "Net flux:  tensor([9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 88}\n",
      "Reaction:  PRST  ->  S + PRT\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 28}\n",
      "Reaction:  PRST  ->  T + PRS\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction:  PRST  ->  PR + ST\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 48}\n",
      "Reaction:  PRST  ->  PS + RT\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 52}\n",
      "Reaction:  PRST  ->  PT + RS\n",
      "Net flux:  tensor([-0.0082], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 56}\n",
      "Reaction:  PRST  ->  PST + R\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 82}\n",
      "Reaction:  PRST  ->  RST + P\n",
      "Net flux:  tensor([-0.0083], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 86}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  QRST + P  ->  PQRST\n",
      "Net flux:  tensor([9.6210], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 89}\n",
      "Reaction:  QRST  ->  S + QRT\n",
      "Net flux:  tensor([-0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 29}\n",
      "Reaction:  QRST  ->  T + QRS\n",
      "Net flux:  tensor([-0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 40}\n",
      "Reaction:  QRST  ->  QR + ST\n",
      "Net flux:  tensor([-0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 59}\n",
      "Reaction:  QRST  ->  QS + RT\n",
      "Net flux:  tensor([-0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 62}\n",
      "Reaction:  QRST  ->  QT + RS\n",
      "Net flux:  tensor([-0.0898], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 65}\n",
      "Reaction:  QRST  ->  QST + R\n",
      "Net flux:  tensor([-0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 84}\n",
      "Reaction:  QRST  ->  RST + Q\n",
      "Net flux:  tensor([-0.0906], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0974], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 8.756510762696539e-22, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 87}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  PQRST  ->  S + PQRT\n",
      "Net flux:  tensor([-9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 30}\n",
      "Reaction:  PQRST  ->  T + PQRS\n",
      "Net flux:  tensor([-9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 41}\n",
      "Reaction:  PQRST  ->  PQ + RST\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 45}\n",
      "Reaction:  PQRST  ->  PR + QST\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 49}\n",
      "Reaction:  PQRST  ->  PS + QRT\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 53}\n",
      "Reaction:  PQRST  ->  PT + QRS\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 57}\n",
      "Reaction:  PQRST  ->  QR + PST\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 60}\n",
      "Reaction:  PQRST  ->  QS + PRT\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 63}\n",
      "Reaction:  PQRST  ->  QT + PRS\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 66}\n",
      "Reaction:  PQRST  ->  PQR + ST\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 67}\n",
      "Reaction:  PQRST  ->  PQS + RT\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 68}\n",
      "Reaction:  PQRST  ->  PQT + RS\n",
      "Net flux:  tensor([-9.4530], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0949], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 7.66764807372196e-48, 'lcf': 1, 'rxn_score': tensor([-120.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction:  PQRST  ->  PQST + R\n",
      "Net flux:  tensor([-9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 85}\n",
      "Reaction:  PQRST  ->  PRST + Q\n",
      "Net flux:  tensor([-9.6207], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 88}\n",
      "Reaction:  PQRST  ->  QRST + P\n",
      "Net flux:  tensor([-9.6210], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([0.0965], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 0.10000000000000002, 'k_off': 1.804851387845406e-30, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 89}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "[['P', 'PQ', 'PQR', 'PQRS', 'PQRST'], ['Q', 'PQ', 'PQR', 'PQRS', 'PQRST'], ['R', 'PR', 'PQR', 'PQRS', 'PQRST'], ['S', 'PS', 'PQS', 'PQRS', 'PQRST'], ['T', 'PT', 'PQT', 'PQRT', 'PQRST'], ['PQ', 'PQR', 'PQRS', 'PQRST'], ['PR', 'PQR', 'PQRS', 'PQRST'], ['PS', 'PQS', 'PQRS', 'PQRST'], ['PT', 'PQT', 'PQRT', 'PQRST'], ['QR', 'QRS', 'QRST', 'PQRST'], ['QS', 'QRS', 'QRST', 'PQRST'], ['QT', 'QRT', 'QRST', 'PQRST'], ['PQR', 'PQRS', 'PQRST'], ['PQS', 'PQRS', 'PQRST'], ['PQT', 'PQRT', 'PQRST'], ['RS', 'RST', 'PQRST'], ['RT', 'RST', 'PQRST'], ['PRS', 'PRST', 'PQRST'], ['PRT', 'PRST', 'PQRST'], ['QRS', 'QRST', 'PQRST'], ['QRT', 'QRST', 'PQRST'], ['PQRS', 'PQRST'], ['PQRT', 'PQRST'], ['ST', 'PQST', 'PQRST'], ['PST', 'PQRST'], ['QST', 'PQRST'], ['PQST', 'PQRST'], ['RST', 'PQRST'], ['PRST', 'PQRST'], ['QRST', 'PQRST'], ['PQRST']]\n",
      "[1.3000000000000003, 1.3000000000000003, 1.3000000000000003, 1.3000000000000003, 1.3000000000000003, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0]\n"
     ]
    }
   ],
   "source": [
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQRST  :  tensor([-142.6336], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QRST  :  tensor([8.9890], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PRS  :  tensor([9.4696], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PRT  :  tensor([9.4696], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PST  :  tensor([9.4696], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQR  :  tensor([9.4696], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQS  :  tensor([9.4696], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQT  :  tensor([9.4696], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PR  :  tensor([9.4777], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PS  :  tensor([9.4777], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PT  :  tensor([9.4777], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQ  :  tensor([9.4777], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RST  :  tensor([9.5517], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QRS  :  tensor([9.5517], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QST  :  tensor([9.5517], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QRT  :  tensor([9.5517], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RS  :  tensor([9.5596], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RT  :  tensor([9.5596], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "ST  :  tensor([9.5596], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QR  :  tensor([9.5596], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QS  :  tensor([9.5596], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "QT  :  tensor([9.5596], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQST  :  tensor([9.5627], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQRT  :  tensor([9.5627], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PQRS  :  tensor([9.5627], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "PRST  :  tensor([9.5627], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "P  :  tensor([9.6542], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "S  :  tensor([9.7361], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "R  :  tensor([9.7361], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "T  :  tensor([9.7361], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Q  :  tensor([9.7361], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.0000e+00, 3.4784e-02, 3.4776e-02, 3.4782e-02, 3.4774e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.1035e-10, 1.1034e-10, 1.1036e-10, 0.0000e+00, 0.0000e+00, 1.1034e-10,\n",
      "        1.1033e-10, 7.7449e-04, 7.7417e-04, 8.5334e-02, 8.5336e-02, 0.0000e+00,\n",
      "        1.1034e-10, 7.7440e-04, 8.5336e-02, 7.7404e-04, 8.5329e-02, 9.3051e-01,\n",
      "        9.9659e+01], dtype=torch.float64, grad_fn=<MaxBackward2>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(solution)\n",
    "# poly_system = EquilibriumSolver(rn)\n",
    "# solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "# #solution = poly_system.solve(verifyBool = False)\n",
    "# if solution == None:\n",
    "#     print(\"No Equilibrium solution\")\n",
    "# else:\n",
    "#     print(solution)\n",
    "#     print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "# print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Steric_free_sim",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
