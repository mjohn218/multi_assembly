{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156a0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7f71c1c18cc0>\n"
     ]
    }
   ],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy\n",
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1e64bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['B']\n",
      "['C']\n",
      "-----\n",
      "{'A'}\n",
      "{'A'}\n",
      "set()\n",
      "-----\n",
      "{'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'B']\n",
      "Connected Edges:  [('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'B']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3]\n",
      "-----\n",
      "{'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'C']\n",
      "Connected Edges:  [('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A']\n",
      "Connected Edges:  [('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'B'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'C']\n",
      "Connected Edges:  [('B', 'C')]\n",
      "New node added--1\n",
      "['B', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "-----\n",
      "{'B'}\n",
      "{'A', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "New node added--1\n",
      "['B', 'A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A']\n",
      "Connected Edges:  [('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'B']\n",
      "Connected Edges:  [('C', 'B')]\n",
      "-----\n",
      "{'C'}\n",
      "{'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('C', 'B'), ('A', 'B')]\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B'), ('C', 'B')]\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'C'}\n",
      "set()\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A'), ('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'C', 'B'}\n",
      "{'A', 'C', 'B'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n"
     ]
    }
   ],
   "source": [
    "base_input = '../../input_files/trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89daec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 3): 0, (0, 4): 1, (0, 6): 5, (1, 3): 0, (1, 5): 2, (1, 6): 3, (2, 4): 1, (2, 5): 2, (2, 6): 4, (3, 6): 4, (4, 6): 3, (5, 6): 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ca3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "def get_max_edge(vec_rn,n,node_map):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "def get_node_flux(vec_rn,n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "#             print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "#             print(\"Net flux: \",edge_flux)\n",
    "#             print(\"kon : \",temp_kon)\n",
    "#             print(\"koff: \",koff)\n",
    "#             print(\"Reaction data OUTWARD: \")\n",
    "#             print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "#             print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "#             print(\"Net flux: \",edge_flux_in)\n",
    "#             print(\"kon : \",temp_kon)\n",
    "#             print(\"koff: \",koff)\n",
    "#             print(\"Raction data INWARD: \")\n",
    "#             print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "\n",
    "def do_flux_analysis(vec_rn,node_map):\n",
    "    pathway = []\n",
    "    kon_sumarray = []\n",
    "    total_con_rate = {}\n",
    "    net_flux = {}\n",
    "    for n in rn.network.nodes():\n",
    "\n",
    "        n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "\n",
    "        paths = [n_str]\n",
    "        kon_sum = 0\n",
    "        temp_node = n\n",
    "        max_edge = True\n",
    "        consumption_rate = 0\n",
    "        if n < len(rn.network.nodes()):#num_monomers:\n",
    "    #         print(\"Current node: \")\n",
    "    #         print(n_str)\n",
    "            while max_edge:\n",
    "                max_edge = get_max_edge(vec_rn,temp_node,node_map)\n",
    "                if max_edge:\n",
    "                    total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                    temp_node = max_edge[1]\n",
    "                    kon_sum += max_edge[0].item()\n",
    "\n",
    "\n",
    "    #                 print(\"Next node: \")\n",
    "    #                 print(temp_node)\n",
    "\n",
    "                    paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "                else:\n",
    "                    break\n",
    "            pathway.append(paths)\n",
    "            kon_sumarray.append(kon_sum)\n",
    "            paths=[]\n",
    "            \n",
    "        net_flux[gtostr(rn.network.nodes[n]['struct'])] = get_node_flux(vec_rn,n)\n",
    "\n",
    "    #print(pathway)\n",
    "    #print(kon_sumarray)\n",
    "    \n",
    "    return(total_con_rate,net_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Optimization with the following on rates: \n",
      "Parameter containing:\n",
      "tensor([10., 10., 10., 10., 10., 10.], dtype=torch.float64, requires_grad=True)\n",
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([10., 10., 10., 10., 10., 10.], dtype=torch.float64, requires_grad=True)]\n",
      "Using CPU\n",
      "Current time:  tensor(4.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 0 was 50.3%\n",
      "current params: tensor([ 9.9900,  9.9900,  9.9900, 10.0100, 10.0100, 10.0100],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 1 was 50.4%\n",
      "current params: tensor([ 9.9800,  9.9800,  9.9800, 10.0200, 10.0200, 10.0200],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 2 was 50.4%\n",
      "current params: tensor([ 9.9700,  9.9700,  9.9700, 10.0300, 10.0300, 10.0300],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 3 was 50.4%\n",
      "current params: tensor([ 9.9600,  9.9600,  9.9600, 10.0400, 10.0400, 10.0400],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 4 was 50.5%\n",
      "current params: tensor([ 9.9500,  9.9500,  9.9500, 10.0500, 10.0500, 10.0500],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 5 was 50.5%\n",
      "current params: tensor([ 9.9400,  9.9400,  9.9400, 10.0600, 10.0600, 10.0600],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 6 was 50.6%\n",
      "current params: tensor([ 9.9300,  9.9300,  9.9299, 10.0700, 10.0700, 10.0700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 7 was 50.6%\n",
      "current params: tensor([ 9.9200,  9.9200,  9.9199, 10.0800, 10.0800, 10.0801],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 8 was 50.7%\n",
      "current params: tensor([ 9.9100,  9.9100,  9.9099, 10.0900, 10.0900, 10.0901],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 9 was 50.7%\n",
      "current params: tensor([ 9.9000,  9.9000,  9.8999, 10.0999, 10.0999, 10.1001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 10 was 50.7%\n",
      "current params: tensor([ 9.8900,  9.8900,  9.8899, 10.1099, 10.1099, 10.1101],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 11 was 50.8%\n",
      "current params: tensor([ 9.8800,  9.8800,  9.8799, 10.1199, 10.1199, 10.1201],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 12 was 50.8%\n",
      "current params: tensor([ 9.8699,  9.8699,  9.8698, 10.1299, 10.1299, 10.1301],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 13 was 50.9%\n",
      "current params: tensor([ 9.8599,  9.8599,  9.8598, 10.1399, 10.1399, 10.1400],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 14 was 50.9%\n",
      "current params: tensor([ 9.8499,  9.8499,  9.8498, 10.1499, 10.1499, 10.1500],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 15 was 50.9%\n",
      "current params: tensor([ 9.8399,  9.8399,  9.8398, 10.1598, 10.1598, 10.1600],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 16 was 51.0%\n",
      "current params: tensor([ 9.8299,  9.8299,  9.8297, 10.1698, 10.1698, 10.1700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 17 was 51.0%\n",
      "current params: tensor([ 9.8199,  9.8199,  9.8197, 10.1798, 10.1798, 10.1800],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 18 was 51.1%\n",
      "current params: tensor([ 9.8098,  9.8098,  9.8097, 10.1897, 10.1897, 10.1900],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 19 was 51.1%\n",
      "current params: tensor([ 9.7998,  9.7998,  9.7996, 10.1997, 10.1997, 10.1999],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 20 was 51.1%\n",
      "current params: tensor([ 9.7898,  9.7898,  9.7896, 10.2096, 10.2096, 10.2099],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 21 was 51.2%\n",
      "current params: tensor([ 9.7797,  9.7797,  9.7796, 10.2196, 10.2196, 10.2199],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 22 was 51.2%\n",
      "current params: tensor([ 9.7697,  9.7697,  9.7695, 10.2295, 10.2295, 10.2299],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 23 was 51.3%\n",
      "current params: tensor([ 9.7597,  9.7597,  9.7595, 10.2395, 10.2395, 10.2398],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 24 was 51.3%\n",
      "current params: tensor([ 9.7496,  9.7496,  9.7494, 10.2494, 10.2494, 10.2498],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 25 was 51.3%\n",
      "current params: tensor([ 9.7396,  9.7396,  9.7394, 10.2594, 10.2594, 10.2597],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 26 was 51.4%\n",
      "current params: tensor([ 9.7295,  9.7295,  9.7293, 10.2693, 10.2693, 10.2697],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 27 was 51.4%\n",
      "current params: tensor([ 9.7195,  9.7195,  9.7193, 10.2792, 10.2792, 10.2796],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 28 was 51.5%\n",
      "current params: tensor([ 9.7094,  9.7094,  9.7092, 10.2891, 10.2891, 10.2896],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 29 was 51.5%\n",
      "current params: tensor([ 9.6994,  9.6994,  9.6991, 10.2991, 10.2991, 10.2995],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 30 was 51.5%\n",
      "current params: tensor([ 9.6893,  9.6893,  9.6891, 10.3090, 10.3090, 10.3094],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 31 was 51.6%\n",
      "current params: tensor([ 9.6793,  9.6793,  9.6790, 10.3189, 10.3189, 10.3193],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 32 was 51.6%\n",
      "current params: tensor([ 9.6692,  9.6692,  9.6689, 10.3288, 10.3288, 10.3293],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 33 was 51.7%\n",
      "current params: tensor([ 9.6591,  9.6591,  9.6588, 10.3387, 10.3387, 10.3392],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 34 was 51.7%\n",
      "current params: tensor([ 9.6491,  9.6491,  9.6487, 10.3486, 10.3486, 10.3491],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 35 was 51.8%\n",
      "current params: tensor([ 9.6390,  9.6390,  9.6387, 10.3585, 10.3585, 10.3590],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 36 was 51.8%\n",
      "current params: tensor([ 9.6289,  9.6289,  9.6286, 10.3683, 10.3683, 10.3689],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 37 was 51.8%\n",
      "current params: tensor([ 9.6188,  9.6188,  9.6185, 10.3782, 10.3782, 10.3788],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 38 was 51.9%\n",
      "current params: tensor([ 9.6087,  9.6087,  9.6084, 10.3881, 10.3881, 10.3887],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 39 was 51.9%\n",
      "current params: tensor([ 9.5987,  9.5987,  9.5983, 10.3980, 10.3980, 10.3986],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 40 was 52.0%\n",
      "current params: tensor([ 9.5886,  9.5886,  9.5882, 10.4078, 10.4078, 10.4085],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 41 was 52.0%\n",
      "current params: tensor([ 9.5785,  9.5785,  9.5781, 10.4177, 10.4177, 10.4183],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 42 was 52.0%\n",
      "current params: tensor([ 9.5684,  9.5684,  9.5679, 10.4275, 10.4275, 10.4282],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 43 was 52.1%\n",
      "current params: tensor([ 9.5583,  9.5583,  9.5578, 10.4374, 10.4374, 10.4381],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 44 was 52.1%\n",
      "current params: tensor([ 9.5482,  9.5482,  9.5477, 10.4472, 10.4472, 10.4479],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 45 was 52.2%\n",
      "current params: tensor([ 9.5380,  9.5380,  9.5376, 10.4570, 10.4570, 10.4578],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9989, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 46 was 52.2%\n",
      "current params: tensor([ 9.5279,  9.5279,  9.5274, 10.4669, 10.4669, 10.4677],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 47 was 52.2%\n",
      "current params: tensor([ 9.5178,  9.5178,  9.5173, 10.4767, 10.4767, 10.4775],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 48 was 52.3%\n",
      "current params: tensor([ 9.5077,  9.5077,  9.5072, 10.4865, 10.4865, 10.4874],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 49 was 52.3%\n",
      "current params: tensor([ 9.4976,  9.4976,  9.4970, 10.4963, 10.4963, 10.4972],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 50 was 52.4%\n",
      "current params: tensor([ 9.4874,  9.4874,  9.4869, 10.5061, 10.5061, 10.5070],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 51 was 52.4%\n",
      "current params: tensor([ 9.4773,  9.4773,  9.4767, 10.5159, 10.5159, 10.5169],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 52 was 52.4%\n",
      "current params: tensor([ 9.4672,  9.4672,  9.4666, 10.5257, 10.5257, 10.5267],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 53 was 52.5%\n",
      "current params: tensor([ 9.4570,  9.4570,  9.4564, 10.5355, 10.5355, 10.5365],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 54 was 52.5%\n",
      "current params: tensor([ 9.4469,  9.4469,  9.4462, 10.5453, 10.5453, 10.5463],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 55 was 52.6%\n",
      "current params: tensor([ 9.4367,  9.4367,  9.4361, 10.5551, 10.5551, 10.5561],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 56 was 52.6%\n",
      "current params: tensor([ 9.4266,  9.4266,  9.4259, 10.5649, 10.5649, 10.5659],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 57 was 52.6%\n",
      "current params: tensor([ 9.4164,  9.4164,  9.4157, 10.5746, 10.5746, 10.5757],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 58 was 52.7%\n",
      "current params: tensor([ 9.4062,  9.4062,  9.4055, 10.5844, 10.5844, 10.5855],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 59 was 52.7%\n",
      "current params: tensor([ 9.3961,  9.3961,  9.3953, 10.5941, 10.5941, 10.5953],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 60 was 52.8%\n",
      "current params: tensor([ 9.3859,  9.3859,  9.3852, 10.6039, 10.6039, 10.6051],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 61 was 52.8%\n",
      "current params: tensor([ 9.3757,  9.3757,  9.3750, 10.6136, 10.6136, 10.6149],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 62 was 52.8%\n",
      "current params: tensor([ 9.3655,  9.3655,  9.3648, 10.6234, 10.6234, 10.6246],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 63 was 52.9%\n",
      "current params: tensor([ 9.3554,  9.3554,  9.3546, 10.6331, 10.6331, 10.6344],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 64 was 52.9%\n",
      "current params: tensor([ 9.3452,  9.3452,  9.3443, 10.6428, 10.6428, 10.6442],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9918, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 65 was 53.0%\n",
      "current params: tensor([ 9.3350,  9.3350,  9.3341, 10.6526, 10.6526, 10.6539],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 66 was 53.0%\n",
      "current params: tensor([ 9.3248,  9.3248,  9.3239, 10.6623, 10.6623, 10.6637],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 67 was 53.0%\n",
      "current params: tensor([ 9.3146,  9.3146,  9.3137, 10.6720, 10.6720, 10.6734],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 68 was 53.1%\n",
      "current params: tensor([ 9.3044,  9.3044,  9.3035, 10.6817, 10.6817, 10.6831],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 69 was 53.1%\n",
      "current params: tensor([ 9.2942,  9.2942,  9.2932, 10.6914, 10.6914, 10.6929],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 70 was 53.2%\n",
      "current params: tensor([ 9.2840,  9.2840,  9.2830, 10.7011, 10.7011, 10.7026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 71 was 53.2%\n",
      "current params: tensor([ 9.2737,  9.2737,  9.2727, 10.7108, 10.7108, 10.7123],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9990, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 72 was 53.2%\n",
      "current params: tensor([ 9.2635,  9.2635,  9.2625, 10.7205, 10.7205, 10.7221],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 73 was 53.3%\n",
      "current params: tensor([ 9.2533,  9.2533,  9.2523, 10.7302, 10.7302, 10.7318],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 74 was 53.3%\n",
      "current params: tensor([ 9.2431,  9.2431,  9.2420, 10.7398, 10.7398, 10.7415],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 75 was 53.4%\n",
      "current params: tensor([ 9.2328,  9.2328,  9.2317, 10.7495, 10.7495, 10.7512],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 76 was 53.4%\n",
      "current params: tensor([ 9.2226,  9.2226,  9.2215, 10.7592, 10.7592, 10.7609],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 77 was 53.5%\n",
      "current params: tensor([ 9.2124,  9.2124,  9.2112, 10.7688, 10.7688, 10.7706],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 78 was 53.5%\n",
      "current params: tensor([ 9.2021,  9.2021,  9.2009, 10.7785, 10.7785, 10.7803],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 79 was 53.5%\n",
      "current params: tensor([ 9.1919,  9.1919,  9.1907, 10.7881, 10.7881, 10.7900],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 80 was 53.6%\n",
      "current params: tensor([ 9.1816,  9.1816,  9.1804, 10.7978, 10.7978, 10.7996],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 81 was 53.6%\n",
      "current params: tensor([ 9.1713,  9.1713,  9.1701, 10.8074, 10.8074, 10.8093],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 82 was 53.7%\n",
      "current params: tensor([ 9.1611,  9.1611,  9.1598, 10.8170, 10.8170, 10.8190],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 83 was 53.7%\n",
      "current params: tensor([ 9.1508,  9.1508,  9.1495, 10.8266, 10.8266, 10.8287],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 84 was 53.7%\n",
      "current params: tensor([ 9.1405,  9.1405,  9.1392, 10.8363, 10.8363, 10.8383],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 85 was 53.8%\n",
      "current params: tensor([ 9.1303,  9.1303,  9.1289, 10.8459, 10.8459, 10.8480],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 86 was 53.8%\n",
      "current params: tensor([ 9.1200,  9.1200,  9.1186, 10.8555, 10.8555, 10.8576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 87 was 53.9%\n",
      "current params: tensor([ 9.1097,  9.1097,  9.1083, 10.8651, 10.8651, 10.8673],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 88 was 53.9%\n",
      "current params: tensor([ 9.0994,  9.0994,  9.0979, 10.8747, 10.8747, 10.8769],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 89 was 53.9%\n",
      "current params: tensor([ 9.0891,  9.0891,  9.0876, 10.8843, 10.8843, 10.8865],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 90 was 54.0%\n",
      "current params: tensor([ 9.0788,  9.0788,  9.0773, 10.8938, 10.8938, 10.8962],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 91 was 54.0%\n",
      "current params: tensor([ 9.0685,  9.0685,  9.0670, 10.9034, 10.9034, 10.9058],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 92 was 54.1%\n",
      "current params: tensor([ 9.0582,  9.0582,  9.0566, 10.9130, 10.9130, 10.9154],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 93 was 54.1%\n",
      "current params: tensor([ 9.0479,  9.0479,  9.0463, 10.9226, 10.9226, 10.9250],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 94 was 54.1%\n",
      "current params: tensor([ 9.0376,  9.0376,  9.0359, 10.9321, 10.9321, 10.9346],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 95 was 54.2%\n",
      "current params: tensor([ 9.0273,  9.0273,  9.0256, 10.9417, 10.9417, 10.9442],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 96 was 54.2%\n",
      "current params: tensor([ 9.0169,  9.0169,  9.0152, 10.9512, 10.9512, 10.9538],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 97 was 54.3%\n",
      "current params: tensor([ 9.0066,  9.0066,  9.0049, 10.9608, 10.9608, 10.9634],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 98 was 54.3%\n",
      "current params: tensor([ 8.9963,  8.9963,  8.9945, 10.9703, 10.9703, 10.9730],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 99 was 54.3%\n",
      "current params: tensor([ 8.9860,  8.9860,  8.9841, 10.9799, 10.9799, 10.9826],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 100 was 54.4%\n",
      "current params: tensor([ 8.9756,  8.9756,  8.9737, 10.9894, 10.9894, 10.9922],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 101 was 54.4%\n",
      "current params: tensor([ 8.9653,  8.9653,  8.9634, 10.9989, 10.9989, 11.0018],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 102 was 54.5%\n",
      "current params: tensor([ 8.9549,  8.9549,  8.9530, 11.0084, 11.0084, 11.0113],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 103 was 54.5%\n",
      "current params: tensor([ 8.9446,  8.9446,  8.9426, 11.0180, 11.0180, 11.0209],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 104 was 54.5%\n",
      "current params: tensor([ 8.9342,  8.9342,  8.9322, 11.0275, 11.0275, 11.0305],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 105 was 54.6%\n",
      "current params: tensor([ 8.9238,  8.9238,  8.9218, 11.0370, 11.0370, 11.0400],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 106 was 54.6%\n",
      "current params: tensor([ 8.9135,  8.9135,  8.9114, 11.0465, 11.0465, 11.0496],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 107 was 54.7%\n",
      "current params: tensor([ 8.9031,  8.9031,  8.9010, 11.0560, 11.0560, 11.0591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 108 was 54.7%\n",
      "current params: tensor([ 8.8927,  8.8927,  8.8906, 11.0654, 11.0654, 11.0687],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 109 was 54.7%\n",
      "current params: tensor([ 8.8823,  8.8823,  8.8801, 11.0749, 11.0749, 11.0782],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 110 was 54.8%\n",
      "current params: tensor([ 8.8720,  8.8720,  8.8697, 11.0844, 11.0844, 11.0877],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 111 was 54.8%\n",
      "current params: tensor([ 8.8616,  8.8616,  8.8593, 11.0939, 11.0939, 11.0973],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 112 was 54.9%\n",
      "current params: tensor([ 8.8512,  8.8512,  8.8489, 11.1033, 11.1033, 11.1068],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 113 was 54.9%\n",
      "current params: tensor([ 8.8408,  8.8408,  8.8384, 11.1128, 11.1128, 11.1163],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 114 was 54.9%\n",
      "current params: tensor([ 8.8304,  8.8304,  8.8280, 11.1222, 11.1222, 11.1258],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 115 was 55.0%\n",
      "current params: tensor([ 8.8200,  8.8200,  8.8175, 11.1317, 11.1317, 11.1353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 116 was 55.0%\n",
      "current params: tensor([ 8.8095,  8.8095,  8.8071, 11.1411, 11.1411, 11.1448],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 117 was 55.1%\n",
      "current params: tensor([ 8.7991,  8.7991,  8.7966, 11.1506, 11.1506, 11.1543],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 118 was 55.1%\n",
      "current params: tensor([ 8.7887,  8.7887,  8.7862, 11.1600, 11.1600, 11.1638],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 119 was 55.1%\n",
      "current params: tensor([ 8.7783,  8.7783,  8.7757, 11.1694, 11.1694, 11.1733],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 120 was 55.2%\n",
      "current params: tensor([ 8.7679,  8.7679,  8.7652, 11.1789, 11.1789, 11.1828],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 121 was 55.2%\n",
      "current params: tensor([ 8.7574,  8.7574,  8.7547, 11.1883, 11.1883, 11.1923],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 122 was 55.3%\n",
      "current params: tensor([ 8.7470,  8.7470,  8.7443, 11.1977, 11.1977, 11.2017],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 123 was 55.3%\n",
      "current params: tensor([ 8.7365,  8.7365,  8.7338, 11.2071, 11.2071, 11.2112],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9928, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 124 was 55.4%\n",
      "current params: tensor([ 8.7261,  8.7261,  8.7233, 11.2165, 11.2165, 11.2207],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9931, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 125 was 55.4%\n",
      "current params: tensor([ 8.7156,  8.7156,  8.7128, 11.2259, 11.2259, 11.2301],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 126 was 55.4%\n",
      "current params: tensor([ 8.7052,  8.7052,  8.7023, 11.2353, 11.2353, 11.2396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 127 was 55.5%\n",
      "current params: tensor([ 8.6947,  8.6947,  8.6918, 11.2447, 11.2447, 11.2490],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9942, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 128 was 55.5%\n",
      "current params: tensor([ 8.6843,  8.6843,  8.6813, 11.2541, 11.2541, 11.2585],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 129 was 55.6%\n",
      "current params: tensor([ 8.6738,  8.6738,  8.6707, 11.2634, 11.2634, 11.2679],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9949, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 130 was 55.6%\n",
      "current params: tensor([ 8.6633,  8.6633,  8.6602, 11.2728, 11.2728, 11.2773],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 131 was 55.6%\n",
      "current params: tensor([ 8.6528,  8.6528,  8.6497, 11.2822, 11.2822, 11.2868],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 132 was 55.7%\n",
      "current params: tensor([ 8.6423,  8.6423,  8.6392, 11.2915, 11.2915, 11.2962],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 133 was 55.7%\n",
      "current params: tensor([ 8.6319,  8.6319,  8.6286, 11.3009, 11.3009, 11.3056],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9965, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 134 was 55.8%\n",
      "current params: tensor([ 8.6214,  8.6214,  8.6181, 11.3102, 11.3102, 11.3150],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 135 was 55.8%\n",
      "current params: tensor([ 8.6109,  8.6109,  8.6075, 11.3196, 11.3196, 11.3244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 136 was 55.8%\n",
      "current params: tensor([ 8.6004,  8.6004,  8.5970, 11.3289, 11.3289, 11.3338],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 137 was 55.9%\n",
      "current params: tensor([ 8.5898,  8.5898,  8.5864, 11.3383, 11.3383, 11.3432],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 138 was 55.9%\n",
      "current params: tensor([ 8.5793,  8.5793,  8.5759, 11.3476, 11.3476, 11.3526],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 139 was 56.0%\n",
      "current params: tensor([ 8.5688,  8.5688,  8.5653, 11.3569, 11.3569, 11.3620],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 140 was 56.0%\n",
      "current params: tensor([ 8.5583,  8.5583,  8.5547, 11.3662, 11.3662, 11.3714],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9997, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 141 was 56.0%\n",
      "current params: tensor([ 8.5478,  8.5478,  8.5441, 11.3755, 11.3755, 11.3808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 142 was 56.1%\n",
      "current params: tensor([ 8.5372,  8.5372,  8.5336, 11.3848, 11.3848, 11.3902],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9918, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 143 was 56.1%\n",
      "current params: tensor([ 8.5267,  8.5267,  8.5230, 11.3941, 11.3941, 11.3995],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 144 was 56.2%\n",
      "current params: tensor([ 8.5162,  8.5162,  8.5124, 11.4034, 11.4034, 11.4089],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 145 was 56.2%\n",
      "current params: tensor([ 8.5056,  8.5056,  8.5018, 11.4127, 11.4127, 11.4183],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 146 was 56.2%\n",
      "current params: tensor([ 8.4951,  8.4951,  8.4912, 11.4220, 11.4220, 11.4276],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 147 was 56.3%\n",
      "current params: tensor([ 8.4845,  8.4845,  8.4806, 11.4313, 11.4313, 11.4370],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 148 was 56.3%\n",
      "current params: tensor([ 8.4740,  8.4740,  8.4700, 11.4406, 11.4406, 11.4463],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 149 was 56.4%\n",
      "current params: tensor([ 8.4634,  8.4634,  8.4593, 11.4499, 11.4499, 11.4557],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 150 was 56.4%\n",
      "current params: tensor([ 8.4528,  8.4528,  8.4487, 11.4591, 11.4591, 11.4650],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 151 was 56.4%\n",
      "current params: tensor([ 8.4423,  8.4423,  8.4381, 11.4684, 11.4684, 11.4743],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 152 was 56.5%\n",
      "current params: tensor([ 8.4317,  8.4317,  8.4275, 11.4776, 11.4776, 11.4837],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 153 was 56.5%\n",
      "current params: tensor([ 8.4211,  8.4211,  8.4168, 11.4869, 11.4869, 11.4930],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 154 was 56.6%\n",
      "current params: tensor([ 8.4105,  8.4105,  8.4062, 11.4961, 11.4961, 11.5023],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 155 was 56.6%\n",
      "current params: tensor([ 8.3999,  8.3999,  8.3955, 11.5054, 11.5054, 11.5116],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9995, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 156 was 56.7%\n",
      "current params: tensor([ 8.3893,  8.3893,  8.3849, 11.5146, 11.5146, 11.5209],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 157 was 56.7%\n",
      "current params: tensor([ 8.3787,  8.3787,  8.3742, 11.5238, 11.5238, 11.5302],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 158 was 56.7%\n",
      "current params: tensor([ 8.3681,  8.3681,  8.3636, 11.5331, 11.5331, 11.5395],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 159 was 56.8%\n",
      "current params: tensor([ 8.3575,  8.3575,  8.3529, 11.5423, 11.5423, 11.5488],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 160 was 56.8%\n",
      "current params: tensor([ 8.3469,  8.3469,  8.3422, 11.5515, 11.5515, 11.5581],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 161 was 56.9%\n",
      "current params: tensor([ 8.3363,  8.3363,  8.3315, 11.5607, 11.5607, 11.5674],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 162 was 56.9%\n",
      "current params: tensor([ 8.3256,  8.3256,  8.3208, 11.5699, 11.5699, 11.5767],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 163 was 56.9%\n",
      "current params: tensor([ 8.3150,  8.3150,  8.3102, 11.5791, 11.5791, 11.5860],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 164 was 57.0%\n",
      "current params: tensor([ 8.3044,  8.3044,  8.2995, 11.5883, 11.5883, 11.5953],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 165 was 57.0%\n",
      "current params: tensor([ 8.2937,  8.2937,  8.2888, 11.5975, 11.5975, 11.6045],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 166 was 57.1%\n",
      "current params: tensor([ 8.2831,  8.2831,  8.2781, 11.6067, 11.6067, 11.6138],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 167 was 57.1%\n",
      "current params: tensor([ 8.2724,  8.2724,  8.2673, 11.6159, 11.6159, 11.6230],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 168 was 57.1%\n",
      "current params: tensor([ 8.2618,  8.2618,  8.2566, 11.6250, 11.6250, 11.6323],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 169 was 57.2%\n",
      "current params: tensor([ 8.2511,  8.2511,  8.2459, 11.6342, 11.6342, 11.6415],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 170 was 57.2%\n",
      "current params: tensor([ 8.2405,  8.2405,  8.2352, 11.6434, 11.6434, 11.6508],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 171 was 57.3%\n",
      "current params: tensor([ 8.2298,  8.2298,  8.2245, 11.6525, 11.6525, 11.6600],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 172 was 57.3%\n",
      "current params: tensor([ 8.2191,  8.2191,  8.2137, 11.6617, 11.6617, 11.6693],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 173 was 57.3%\n",
      "current params: tensor([ 8.2084,  8.2084,  8.2030, 11.6708, 11.6708, 11.6785],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 174 was 57.4%\n",
      "current params: tensor([ 8.1978,  8.1978,  8.1922, 11.6800, 11.6800, 11.6877],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 175 was 57.4%\n",
      "current params: tensor([ 8.1871,  8.1871,  8.1815, 11.6891, 11.6891, 11.6969],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 176 was 57.5%\n",
      "current params: tensor([ 8.1764,  8.1764,  8.1707, 11.6982, 11.6982, 11.7062],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 177 was 57.5%\n",
      "current params: tensor([ 8.1657,  8.1657,  8.1600, 11.7074, 11.7074, 11.7154],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 178 was 57.6%\n",
      "current params: tensor([ 8.1550,  8.1550,  8.1492, 11.7165, 11.7165, 11.7246],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 179 was 57.6%\n",
      "current params: tensor([ 8.1443,  8.1443,  8.1384, 11.7256, 11.7256, 11.7338],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 180 was 57.6%\n",
      "current params: tensor([ 8.1335,  8.1335,  8.1276, 11.7347, 11.7347, 11.7430],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 181 was 57.7%\n",
      "current params: tensor([ 8.1228,  8.1228,  8.1168, 11.7438, 11.7438, 11.7522],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 182 was 57.7%\n",
      "current params: tensor([ 8.1121,  8.1121,  8.1061, 11.7529, 11.7529, 11.7614],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 183 was 57.8%\n",
      "current params: tensor([ 8.1014,  8.1014,  8.0953, 11.7620, 11.7620, 11.7705],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 184 was 57.8%\n",
      "current params: tensor([ 8.0906,  8.0906,  8.0845, 11.7711, 11.7711, 11.7797],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 185 was 57.8%\n",
      "current params: tensor([ 8.0799,  8.0799,  8.0737, 11.7802, 11.7802, 11.7889],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 186 was 57.9%\n",
      "current params: tensor([ 8.0692,  8.0692,  8.0628, 11.7893, 11.7893, 11.7981],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 187 was 57.9%\n",
      "current params: tensor([ 8.0584,  8.0584,  8.0520, 11.7984, 11.7984, 11.8072],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 188 was 58.0%\n",
      "current params: tensor([ 8.0477,  8.0477,  8.0412, 11.8074, 11.8074, 11.8164],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 189 was 58.0%\n",
      "current params: tensor([ 8.0369,  8.0369,  8.0304, 11.8165, 11.8165, 11.8255],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 190 was 58.0%\n",
      "current params: tensor([ 8.0261,  8.0261,  8.0195, 11.8256, 11.8256, 11.8347],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 191 was 58.1%\n",
      "current params: tensor([ 8.0154,  8.0154,  8.0087, 11.8346, 11.8346, 11.8438],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 192 was 58.1%\n",
      "current params: tensor([ 8.0046,  8.0046,  7.9979, 11.8437, 11.8437, 11.8530],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 193 was 58.2%\n",
      "current params: tensor([ 7.9938,  7.9938,  7.9870, 11.8527, 11.8527, 11.8621],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 194 was 58.2%\n",
      "current params: tensor([ 7.9830,  7.9830,  7.9762, 11.8618, 11.8618, 11.8712],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 195 was 58.3%\n",
      "current params: tensor([ 7.9723,  7.9723,  7.9653, 11.8708, 11.8708, 11.8804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 196 was 58.3%\n",
      "current params: tensor([ 7.9615,  7.9615,  7.9544, 11.8798, 11.8798, 11.8895],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 197 was 58.3%\n",
      "current params: tensor([ 7.9507,  7.9507,  7.9436, 11.8889, 11.8889, 11.8986],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9921, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 198 was 58.4%\n",
      "current params: tensor([ 7.9399,  7.9399,  7.9327, 11.8979, 11.8979, 11.9077],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 199 was 58.4%\n",
      "current params: tensor([ 7.9291,  7.9291,  7.9218, 11.9069, 11.9069, 11.9168],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 200 was 58.5%\n",
      "current params: tensor([ 7.9182,  7.9182,  7.9109, 11.9159, 11.9159, 11.9259],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 201 was 58.5%\n",
      "current params: tensor([ 7.9074,  7.9074,  7.9000, 11.9249, 11.9249, 11.9350],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 202 was 58.5%\n",
      "current params: tensor([ 7.8966,  7.8966,  7.8891, 11.9339, 11.9339, 11.9441],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 203 was 58.6%\n",
      "current params: tensor([ 7.8858,  7.8858,  7.8782, 11.9429, 11.9429, 11.9532],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 204 was 58.6%\n",
      "current params: tensor([ 7.8749,  7.8749,  7.8673, 11.9519, 11.9519, 11.9623],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 205 was 58.7%\n",
      "current params: tensor([ 7.8641,  7.8641,  7.8564, 11.9609, 11.9609, 11.9714],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 206 was 58.7%\n",
      "current params: tensor([ 7.8533,  7.8533,  7.8455, 11.9699, 11.9699, 11.9805],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9937, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 207 was 58.7%\n",
      "current params: tensor([ 7.8424,  7.8424,  7.8346, 11.9789, 11.9789, 11.9895],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 208 was 58.8%\n",
      "current params: tensor([ 7.8316,  7.8316,  7.8236, 11.9878, 11.9878, 11.9986],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9962, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 209 was 58.8%\n",
      "current params: tensor([ 7.8207,  7.8207,  7.8127, 11.9968, 11.9968, 12.0077],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9975, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 210 was 58.9%\n",
      "current params: tensor([ 7.8098,  7.8098,  7.8017, 12.0058, 12.0058, 12.0167],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 211 was 58.9%\n",
      "current params: tensor([ 7.7990,  7.7990,  7.7908, 12.0147, 12.0147, 12.0258],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 212 was 59.0%\n",
      "current params: tensor([ 7.7881,  7.7881,  7.7798, 12.0237, 12.0237, 12.0348],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 213 was 59.0%\n",
      "current params: tensor([ 7.7772,  7.7772,  7.7689, 12.0326, 12.0326, 12.0439],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9936, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 214 was 59.0%\n",
      "current params: tensor([ 7.7663,  7.7663,  7.7579, 12.0415, 12.0415, 12.0529],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 215 was 59.1%\n",
      "current params: tensor([ 7.7554,  7.7554,  7.7469, 12.0505, 12.0505, 12.0619],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9963, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 216 was 59.1%\n",
      "current params: tensor([ 7.7445,  7.7445,  7.7360, 12.0594, 12.0594, 12.0710],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9977, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 217 was 59.2%\n",
      "current params: tensor([ 7.7336,  7.7336,  7.7250, 12.0683, 12.0683, 12.0800],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9990, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 218 was 59.2%\n",
      "current params: tensor([ 7.7227,  7.7227,  7.7140, 12.0773, 12.0773, 12.0890],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 219 was 59.2%\n",
      "current params: tensor([ 7.7118,  7.7118,  7.7030, 12.0862, 12.0862, 12.0980],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 220 was 59.3%\n",
      "current params: tensor([ 7.7009,  7.7009,  7.6920, 12.0951, 12.0951, 12.1070],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 221 was 59.3%\n",
      "current params: tensor([ 7.6900,  7.6900,  7.6810, 12.1040, 12.1040, 12.1160],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 222 was 59.4%\n",
      "current params: tensor([ 7.6791,  7.6791,  7.6700, 12.1129, 12.1129, 12.1250],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 223 was 59.4%\n",
      "current params: tensor([ 7.6681,  7.6681,  7.6590, 12.1218, 12.1218, 12.1340],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 224 was 59.5%\n",
      "current params: tensor([ 7.6572,  7.6572,  7.6479, 12.1307, 12.1307, 12.1430],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 225 was 59.5%\n",
      "current params: tensor([ 7.6462,  7.6462,  7.6369, 12.1396, 12.1396, 12.1520],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 226 was 59.5%\n",
      "current params: tensor([ 7.6353,  7.6353,  7.6259, 12.1485, 12.1485, 12.1610],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 227 was 59.6%\n",
      "current params: tensor([ 7.6243,  7.6243,  7.6148, 12.1573, 12.1573, 12.1700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9952, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 228 was 59.6%\n",
      "current params: tensor([ 7.6134,  7.6134,  7.6038, 12.1662, 12.1662, 12.1789],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time:  tensor(4.9967, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 229 was 59.7%\n",
      "current params: tensor([ 7.6024,  7.6024,  7.5927, 12.1751, 12.1751, 12.1879],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 230 was 59.7%\n",
      "current params: tensor([ 7.5915,  7.5915,  7.5817, 12.1839, 12.1839, 12.1969],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9998, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 231 was 59.7%\n",
      "current params: tensor([ 7.5805,  7.5805,  7.5706, 12.1928, 12.1928, 12.2058],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 232 was 59.8%\n",
      "current params: tensor([ 7.5695,  7.5695,  7.5596, 12.2016, 12.2016, 12.2148],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 233 was 59.8%\n",
      "current params: tensor([ 7.5585,  7.5585,  7.5485, 12.2105, 12.2105, 12.2237],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 234 was 59.9%\n",
      "current params: tensor([ 7.5475,  7.5475,  7.5374, 12.2193, 12.2193, 12.2327],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 235 was 59.9%\n",
      "current params: tensor([ 7.5365,  7.5365,  7.5263, 12.2282, 12.2282, 12.2416],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 236 was 60.0%\n",
      "current params: tensor([ 7.5255,  7.5255,  7.5152, 12.2370, 12.2370, 12.2505],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 237 was 60.0%\n",
      "current params: tensor([ 7.5145,  7.5145,  7.5041, 12.2458, 12.2458, 12.2595],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 238 was 60.0%\n",
      "current params: tensor([ 7.5035,  7.5035,  7.4930, 12.2546, 12.2546, 12.2684],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9943, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 239 was 60.1%\n",
      "current params: tensor([ 7.4925,  7.4925,  7.4819, 12.2635, 12.2635, 12.2773],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Current time:  tensor(4.9959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(5.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "yield on sim iteration 240 was 60.1%\n",
      "current params: tensor([ 7.4815,  7.4815,  7.4708, 12.2723, 12.2723, 12.2862],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "## Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "kon_list = [10.0,100.0]# uM-1 s-1\n",
    "\n",
    "final_yield = {kon : [] for kon in kon_list}\n",
    "optimized_rates = {kon : [] for kon in kon_list}\n",
    "observables = {kon : dict() for kon in kon_list} \n",
    "flux_data = {kon : [] for kon in kon_list}\n",
    "cons_data = {kon : [] for kon in kon_list}\n",
    "final_copies = {kon : [] for kon in kon_list}\n",
    "\n",
    "for new_kon in kon_list:\n",
    "\n",
    "    nx.set_edge_attributes(rn.network,new_kon,'k_on')\n",
    "    \n",
    "    \n",
    "    vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "    vec_rn.reset(reset_params=True)\n",
    "    \n",
    "    ### Start Optimization\n",
    "    print(\"Running Optimization with the following on rates: \")\n",
    "    print(vec_rn.kon)\n",
    "    optim = Optimizer(reaction_network=vec_rn,\n",
    "                      sim_runtime=5,\n",
    "                      optim_iterations=10000,\n",
    "                      learning_rate=new_kon/1000,\n",
    "                      device='cpu')\n",
    "    optim.rn.update_reaction_net(rn)\n",
    "    optim.optimize()\n",
    "    \n",
    "    final_yield[new_kon] = optim.yield_per_iter\n",
    "    optimized_rates[new_kon] = vec_rn.kon\n",
    "    \n",
    "    ###Run simulation with optimized parameters\n",
    "    print(\"Running simulation with optimized parameters\")\n",
    "    optim_rn = optim.rn\n",
    "    for i, runtime in enumerate([1, 50, 100,1000]):\n",
    "        optim_rn.reset()\n",
    "        sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "        y = sim.simulate()\n",
    "        \n",
    "        observables[new_kon][runtime] = (sim.steps.copy(),sim.observables.copy())\n",
    "        print(\"Length of observables: \", len(sim.observables[0][1]))\n",
    "    \n",
    "    ##Calculate the net flux in across each node/species\n",
    "    print(\"Doing flux analysis\")\n",
    "    cons_rate,flux = do_flux_analysis(vec_rn,node_map)\n",
    "    \n",
    "    flux_data[new_kon].append(flux)\n",
    "    cons_data[new_kon].append(cons_rate)\n",
    "    final_copies[new_kon].append(vec_rn.copies_vec)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plotting yield for each optimized rates\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, len(kon_list))\n",
    "i= 0\n",
    "for kon,val in final_yield.items():\n",
    "    ax[i].plot(val)\n",
    "    ax[i].set_title(\"Initial kon = \" + str(kon))\n",
    "    i+=1\n",
    "\n",
    "txt = fig.suptitle(\"Yield after optimization\")\n",
    "fig.set_size_inches(24, 6)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 4\n",
    "fig,ax = plt.subplots(len(kon_list),times)\n",
    "i=0\n",
    "nodes_list = ['A','B','C','AB','BC','AC','ABC']\n",
    "for kon,runtimes in observables.items():\n",
    "    for time,val in runtimes.items():\n",
    "        #print(time)\n",
    "        for key in val[1].keys():\n",
    "            if val[1][key][0] in nodes_list:\n",
    "                row = int(i/times)\n",
    "                col = i%times\n",
    "                #print(val[1][key][1][:5])\n",
    "                #print(len(val[1][key][1]))\n",
    "                ax[row,col].plot(val[0],val[1][key][1],label=val[1][key][0])\n",
    "        ax[row,col].set_title(\"runtime: \" + str(time) + \" seconds\")\n",
    "        i+=1\n",
    "lgnd = plt.legend(loc='best')\n",
    "fig.set_size_inches(18, 24)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(4/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adf55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kon,flux in flux_data.items():\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Starting on rate: \", kon)\n",
    "    print(\"Final copies: \", final_copies[kon])\n",
    "    print(\"Optimzied parameters: \", optimized_rates[kon])\n",
    "    \n",
    "    print(\"Flux: \")\n",
    "    for k,v in sorted(flux[0].items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
