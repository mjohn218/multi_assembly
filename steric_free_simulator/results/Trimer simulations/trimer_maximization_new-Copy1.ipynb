{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7efefa7a2e10>\n"
     ]
    }
   ],
   "source": [
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['B']\n",
      "['C']\n",
      "-----\n",
      "{'A'}\n",
      "{'A'}\n",
      "set()\n",
      "-----\n",
      "{'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'B']\n",
      "Connected Edges:  [('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'B']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3]\n",
      "-----\n",
      "{'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'C']\n",
      "Connected Edges:  [('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A']\n",
      "Connected Edges:  [('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'B'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'C']\n",
      "Connected Edges:  [('B', 'C')]\n",
      "New node added--1\n",
      "['B', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "-----\n",
      "{'B'}\n",
      "{'B', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "New node added--1\n",
      "['B', 'A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A']\n",
      "Connected Edges:  [('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'B']\n",
      "Connected Edges:  [('C', 'B')]\n",
      "-----\n",
      "{'C'}\n",
      "{'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('C', 'B'), ('A', 'B')]\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'B', 'A'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "{'B', 'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'B', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'B', 'A'}\n",
      "{'C', 'B', 'A'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "{'C', 'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B'), ('C', 'B')]\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'C', 'A'}\n",
      "set()\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'C', 'A'}\n",
      "{'C', 'B', 'A'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A'), ('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "{('A', 'B'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-50000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C', 'B', 'A'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'B'}\n",
      "{'C', 'A'}\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'C'}\n",
      "{'B', 'A'}\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'B', 'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'C', 'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'C', 'B', 'A'}\n",
      "{'C', 'B', 'A'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n"
     ]
    }
   ],
   "source": [
    "base_input = '../../input_files/trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 3): 0, (0, 4): 1, (0, 6): 5, (1, 3): 0, (1, 5): 2, (1, 6): 3, (2, 4): 1, (2, 5): 2, (2, 6): 4, (3, 6): 4, (4, 6): 3, (5, 6): 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = [1000.0,1000.0,1000.0,1000.0,1000.0,1000.0]*np.array([1e0])  #Poor yield Simruntime = 1sec\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu',coupling=True,cid={0:4})\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Equilibrium Solution ##\n",
    "First we will find the equilibrium solution for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No aceeptable solution found\n",
      "No Equilibrium solution\n",
      "tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "vec_rn.update_reaction_net(rn,1)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve()\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 0}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 1}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 2}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C', 'A'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 3}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'C'}, {'B', 'A'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 4}\n",
      "tensor(1000., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C', 'B'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'AB': 3, 'AC': 4, 'BC': 5, 'ABC': 6}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*solution[edge[1]] - temp_kon*(solution[edge[0]])*(solution[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Free Energy: \",vec_rn.rxn_score_vec[uid])\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(solution[edge[0]])*(solution[node_map[react]])- koff*solution[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "\n",
    "if solution != None:\n",
    "    for n in rn.network.nodes():\n",
    "\n",
    "        n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "\n",
    "        paths = [n_str]\n",
    "        kon_sum = 0\n",
    "        temp_node = n\n",
    "        max_edge = True\n",
    "        consumption_rate = 0\n",
    "        if n < len(rn.network.nodes()):#num_monomers:\n",
    "    #         print(\"Current node: \")\n",
    "    #         print(n_str)\n",
    "            while max_edge:\n",
    "                max_edge = get_max_edge(temp_node)\n",
    "                if max_edge:\n",
    "                    total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                    temp_node = max_edge[1]\n",
    "                    kon_sum += max_edge[0].item()\n",
    "\n",
    "\n",
    "    #                 print(\"Next node: \")\n",
    "    #                 print(temp_node)\n",
    "\n",
    "                    paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "                else:\n",
    "                    break\n",
    "            pathway.append(paths)\n",
    "            kon_sumarray.append(kon_sum)\n",
    "            paths=[]\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"|                                                                             |\")\n",
    "        node_flux = get_node_flux(n)\n",
    "        net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "        print(\"|                                                                             |\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(pathway)\n",
    "    print(kon_sumarray)\n",
    "    #print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if solution != None:\n",
    "    for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if solution !=None:\n",
    "    for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer with a 1 second simulation runtime ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1000., 1000., 1000., 1000., 1000.], dtype=torch.float64,\n",
      "       requires_grad=True)]\n",
      "Using CPU\n",
      "Next time:  tensor(163297.0706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 0 was 57.0%\n",
      "Previous reaction rates:  tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64)\n",
      "New reaction rates: tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64)\n",
      "current params: tensor([1000., 1000., 1000., 1000., 1000.], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(163297.0706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 1 was 57.0%\n",
      "Previous reaction rates:  tensor([1000., 1000., 1000., 1000., 1000., 1000.], dtype=torch.float64)\n",
      "New reaction rates: tensor([ 999.0427,  999.0001,  999.0001, 1000.9999,  999.0427, 1000.9999],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 999.0001,  999.0001, 1000.9999,  999.0427, 1000.9999],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(163548.3682, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 2 was 57.0%\n",
      "Previous reaction rates:  tensor([ 999.0427,  999.0001,  999.0001, 1000.9999,  999.0427, 1000.9999],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 998.0915,  998.0003,  998.0003, 1001.9997,  998.0915, 1001.9997],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 998.0003,  998.0003, 1001.9997,  998.0915, 1001.9997],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(163799.9541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 3 was 57.0%\n",
      "Previous reaction rates:  tensor([ 998.0915,  998.0003,  998.0003, 1001.9997,  998.0915, 1001.9997],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 997.1316,  997.0004,  997.0003, 1002.9995,  997.1316, 1002.9996],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 997.0004,  997.0003, 1002.9995,  997.1316, 1002.9996],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(164052.6342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 4 was 57.1%\n",
      "Previous reaction rates:  tensor([ 997.1316,  997.0004,  997.0003, 1002.9995,  997.1316, 1002.9996],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 996.1634,  996.0005,  996.0004, 1003.9992,  996.1634, 1003.9994],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 996.0005,  996.0004, 1003.9992,  996.1634, 1003.9994],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(164306.3985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 5 was 57.1%\n",
      "Previous reaction rates:  tensor([ 996.1634,  996.0005,  996.0004, 1003.9992,  996.1634, 1003.9994],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 995.1870,  995.0005,  995.0004, 1004.9989,  995.1870, 1004.9992],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 995.0005,  995.0004, 1004.9989,  995.1870, 1004.9992],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(164561.2515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 6 was 57.1%\n",
      "Previous reaction rates:  tensor([ 995.1870,  995.0005,  995.0004, 1004.9989,  995.1870, 1004.9992],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 994.2019,  994.0004,  994.0003, 1005.9985,  994.2019, 1005.9989],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 994.0004,  994.0003, 1005.9985,  994.2019, 1005.9989],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(164817.2161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 7 was 57.2%\n",
      "Previous reaction rates:  tensor([ 994.2019,  994.0004,  994.0003, 1005.9985,  994.2019, 1005.9989],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 993.2079,  993.0004,  993.0002, 1006.9981,  993.2079, 1006.9985],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 993.0004,  993.0002, 1006.9981,  993.2079, 1006.9985],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(165074.3231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 8 was 57.2%\n",
      "Previous reaction rates:  tensor([ 993.2079,  993.0004,  993.0002, 1006.9981,  993.2079, 1006.9985],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 992.2044,  992.0002,  992.0000, 1007.9975,  992.2044, 1007.9980],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 992.0002,  992.0000, 1007.9975,  992.2044, 1007.9980],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(165332.6060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 9 was 57.2%\n",
      "Previous reaction rates:  tensor([ 992.2044,  992.0002,  992.0000, 1007.9975,  992.2044, 1007.9980],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 991.1910,  990.9999,  990.9997, 1008.9968,  991.1910, 1008.9974],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 990.9999,  990.9997, 1008.9968,  991.1910, 1008.9974],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(165592.0980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 10 was 57.2%\n",
      "Previous reaction rates:  tensor([ 991.1910,  990.9999,  990.9997, 1008.9968,  991.1910, 1008.9974],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 990.1673,  989.9996,  989.9993, 1009.9960,  990.1673, 1009.9966],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 989.9996,  989.9993, 1009.9960,  990.1673, 1009.9966],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(165852.8311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 11 was 57.3%\n",
      "Previous reaction rates:  tensor([ 990.1673,  989.9996,  989.9993, 1009.9960,  990.1673, 1009.9966],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 989.1330,  988.9992,  988.9989, 1010.9951,  989.1330, 1010.9958],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 988.9992,  988.9989, 1010.9951,  989.1330, 1010.9958],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(166114.8351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 12 was 57.3%\n",
      "Previous reaction rates:  tensor([ 989.1330,  988.9992,  988.9989, 1010.9951,  989.1330, 1010.9958],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 988.0876,  987.9987,  987.9983, 1011.9940,  988.0876, 1011.9948],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 987.9987,  987.9983, 1011.9940,  988.0876, 1011.9948],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(166378.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 13 was 57.3%\n",
      "Previous reaction rates:  tensor([ 988.0876,  987.9987,  987.9983, 1011.9940,  988.0876, 1011.9948],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 987.0309,  986.9981,  986.9977, 1012.9927,  987.0309, 1012.9936],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 986.9981,  986.9977, 1012.9927,  987.0309, 1012.9936],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(166642.7648, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 14 was 57.3%\n",
      "Previous reaction rates:  tensor([ 987.0309,  986.9981,  986.9977, 1012.9927,  987.0309, 1012.9936],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 985.9626,  985.9973,  985.9969, 1013.9913,  985.9626, 1013.9923],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 985.9973,  985.9969, 1013.9913,  985.9626, 1013.9923],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(166908.7396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 15 was 57.4%\n",
      "Previous reaction rates:  tensor([ 985.9626,  985.9973,  985.9969, 1013.9913,  985.9626, 1013.9923],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 984.8825,  984.9965,  984.9960, 1014.9897,  984.8825, 1014.9908],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 984.9965,  984.9960, 1014.9897,  984.8825, 1014.9908],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(167176.0836, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 16 was 57.4%\n",
      "Previous reaction rates:  tensor([ 984.8825,  984.9965,  984.9960, 1014.9897,  984.8825, 1014.9908],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 983.7905,  983.9956,  983.9951, 1015.9880,  983.7905, 1015.9892],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 983.9956,  983.9951, 1015.9880,  983.7905, 1015.9892],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(167444.8170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 17 was 57.4%\n",
      "Previous reaction rates:  tensor([ 983.7905,  983.9956,  983.9951, 1015.9880,  983.7905, 1015.9892],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 982.6864,  982.9945,  982.9940, 1016.9860,  982.6864, 1016.9873],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 982.9945,  982.9940, 1016.9860,  982.6864, 1016.9873],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(167714.9574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 18 was 57.5%\n",
      "Previous reaction rates:  tensor([ 982.6864,  982.9945,  982.9940, 1016.9860,  982.6864, 1016.9873],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 981.5700,  981.9933,  981.9928, 1017.9839,  981.5700, 1017.9852],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 981.9933,  981.9928, 1017.9839,  981.5700, 1017.9852],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(167986.5213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 19 was 57.5%\n",
      "Previous reaction rates:  tensor([ 981.5700,  981.9933,  981.9928, 1017.9839,  981.5700, 1017.9852],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 980.4413,  980.9921,  980.9914, 1018.9815,  980.4413, 1018.9830],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 980.9921,  980.9914, 1018.9815,  980.4413, 1018.9830],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(168259.5240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 20 was 57.5%\n",
      "Previous reaction rates:  tensor([ 980.4413,  980.9921,  980.9914, 1018.9815,  980.4413, 1018.9830],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 979.3003,  979.9907,  979.9900, 1019.9789,  979.3003, 1019.9805],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 979.9907,  979.9900, 1019.9789,  979.3003, 1019.9805],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(168533.9788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 21 was 57.5%\n",
      "Previous reaction rates:  tensor([ 979.3003,  979.9907,  979.9900, 1019.9789,  979.3003, 1019.9805],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 978.1468,  978.9892,  978.9884, 1020.9761,  978.1468, 1020.9778],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 978.9892,  978.9884, 1020.9761,  978.1468, 1020.9778],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(168809.8979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 22 was 57.6%\n",
      "Previous reaction rates:  tensor([ 978.1468,  978.9892,  978.9884, 1020.9761,  978.1468, 1020.9778],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 976.9809,  977.9876,  977.9868, 1021.9731,  976.9809, 1021.9749],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 977.9876,  977.9868, 1021.9731,  976.9809, 1021.9749],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(169087.2927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 23 was 57.6%\n",
      "Previous reaction rates:  tensor([ 976.9809,  977.9876,  977.9868, 1021.9731,  976.9809, 1021.9749],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 975.8025,  976.9859,  976.9850, 1022.9698,  975.8025, 1022.9717],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 976.9859,  976.9850, 1022.9698,  975.8025, 1022.9717],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(169366.1728, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 24 was 57.6%\n",
      "Previous reaction rates:  tensor([ 975.8025,  976.9859,  976.9850, 1022.9698,  975.8025, 1022.9717],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 974.6118,  975.9840,  975.9831, 1023.9663,  974.6118, 1023.9683],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 975.9840,  975.9831, 1023.9663,  974.6118, 1023.9683],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(169646.5472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 25 was 57.7%\n",
      "Previous reaction rates:  tensor([ 974.6118,  975.9840,  975.9831, 1023.9663,  974.6118, 1023.9683],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 973.4087,  974.9821,  974.9812, 1024.9626,  973.4087, 1024.9647],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 974.9821,  974.9812, 1024.9626,  973.4087, 1024.9647],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(169928.4237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 26 was 57.7%\n",
      "Previous reaction rates:  tensor([ 973.4087,  974.9821,  974.9812, 1024.9626,  973.4087, 1024.9647],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 972.1933,  973.9801,  973.9791, 1025.9586,  972.1933, 1025.9608],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 973.9801,  973.9791, 1025.9586,  972.1933, 1025.9608],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(170211.8091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 27 was 57.7%\n",
      "Previous reaction rates:  tensor([ 972.1933,  973.9801,  973.9791, 1025.9586,  972.1933, 1025.9608],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 970.9656,  972.9780,  972.9769, 1026.9543,  970.9656, 1026.9566],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 972.9780,  972.9769, 1026.9543,  970.9656, 1026.9566],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(170496.7096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 28 was 57.7%\n",
      "Previous reaction rates:  tensor([ 970.9656,  972.9780,  972.9769, 1026.9543,  970.9656, 1026.9566],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 969.7258,  971.9759,  971.9747, 1027.9498,  969.7258, 1027.9522],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 971.9759,  971.9747, 1027.9498,  969.7258, 1027.9522],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(170783.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 29 was 57.8%\n",
      "Previous reaction rates:  tensor([ 969.7258,  971.9759,  971.9747, 1027.9498,  969.7258, 1027.9522],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 968.4739,  970.9736,  970.9724, 1028.9451,  968.4739, 1028.9476],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 970.9736,  970.9724, 1028.9451,  968.4739, 1028.9476],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(171071.0758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 30 was 57.8%\n",
      "Previous reaction rates:  tensor([ 968.4739,  970.9736,  970.9724, 1028.9451,  968.4739, 1028.9476],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 967.2101,  969.9713,  969.9700, 1029.9401,  967.2101, 1029.9427],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 969.9713,  969.9700, 1029.9401,  967.2101, 1029.9427],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(171360.5496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 31 was 57.8%\n",
      "Previous reaction rates:  tensor([ 967.2101,  969.9713,  969.9700, 1029.9401,  967.2101, 1029.9427],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 965.9345,  968.9689,  968.9675, 1030.9348,  965.9345, 1030.9375],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 968.9689,  968.9675, 1030.9348,  965.9345, 1030.9375],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(171651.5551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 32 was 57.8%\n",
      "Previous reaction rates:  tensor([ 965.9345,  968.9689,  968.9675, 1030.9348,  965.9345, 1030.9375],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 964.6471,  967.9665,  967.9650, 1031.9292,  964.6471, 1031.9321],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 967.9665,  967.9650, 1031.9292,  964.6471, 1031.9321],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(171944.0946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 33 was 57.9%\n",
      "Previous reaction rates:  tensor([ 964.6471,  967.9665,  967.9650, 1031.9292,  964.6471, 1031.9321],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 963.3482,  966.9640,  966.9625, 1032.9234,  963.3482, 1032.9264],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 966.9640,  966.9625, 1032.9234,  963.3482, 1032.9264],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(172238.1702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 34 was 57.9%\n",
      "Previous reaction rates:  tensor([ 963.3482,  966.9640,  966.9625, 1032.9234,  963.3482, 1032.9264],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 962.0379,  965.9615,  965.9599, 1033.9173,  962.0379, 1033.9204],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 965.9615,  965.9599, 1033.9173,  962.0379, 1033.9204],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(172533.7832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 35 was 57.9%\n",
      "Previous reaction rates:  tensor([ 962.0379,  965.9615,  965.9599, 1033.9173,  962.0379, 1033.9204],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 960.7163,  964.9590,  964.9573, 1034.9110,  960.7163, 1034.9142],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 964.9590,  964.9573, 1034.9110,  960.7163, 1034.9142],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(172830.9346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 36 was 58.0%\n",
      "Previous reaction rates:  tensor([ 960.7163,  964.9590,  964.9573, 1034.9110,  960.7163, 1034.9142],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 959.3836,  963.9565,  963.9547, 1035.9043,  959.3836, 1035.9077],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 963.9565,  963.9547, 1035.9043,  959.3836, 1035.9077],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(173129.6250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 37 was 58.0%\n",
      "Previous reaction rates:  tensor([ 959.3836,  963.9565,  963.9547, 1035.9043,  959.3836, 1035.9077],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 958.0400,  962.9539,  962.9520, 1036.8974,  958.0400, 1036.9009],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 962.9539,  962.9520, 1036.8974,  958.0400, 1036.9009],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(173429.8546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 38 was 58.0%\n",
      "Previous reaction rates:  tensor([ 958.0400,  962.9539,  962.9520, 1036.8974,  958.0400, 1036.9009],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 956.6856,  961.9514,  961.9494, 1037.8903,  956.6856, 1037.8938],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 961.9514,  961.9494, 1037.8903,  956.6856, 1037.8938],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(173731.6233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 39 was 58.0%\n",
      "Previous reaction rates:  tensor([ 956.6856,  961.9514,  961.9494, 1037.8903,  956.6856, 1037.8938],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 955.3206,  960.9489,  960.9468, 1038.8828,  955.3206, 1038.8865],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 960.9489,  960.9468, 1038.8828,  955.3206, 1038.8865],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(174034.9306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 40 was 58.1%\n",
      "Previous reaction rates:  tensor([ 955.3206,  960.9489,  960.9468, 1038.8828,  955.3206, 1038.8865],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 953.9452,  959.9464,  959.9442, 1039.8751,  953.9452, 1039.8789],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 959.9464,  959.9442, 1039.8751,  953.9452, 1039.8789],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(174339.7758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 41 was 58.1%\n",
      "Previous reaction rates:  tensor([ 953.9452,  959.9464,  959.9442, 1039.8751,  953.9452, 1039.8789],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 952.5595,  958.9439,  958.9416, 1040.8671,  952.5595, 1040.8711],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 958.9439,  958.9416, 1040.8671,  952.5595, 1040.8711],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(174646.1579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 42 was 58.1%\n",
      "Previous reaction rates:  tensor([ 952.5595,  958.9439,  958.9416, 1040.8671,  952.5595, 1040.8711],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 951.1638,  957.9415,  957.9391, 1041.8589,  951.1638, 1041.8629],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 957.9415,  957.9391, 1041.8589,  951.1638, 1041.8629],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(174954.0759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 43 was 58.2%\n",
      "Previous reaction rates:  tensor([ 951.1638,  957.9415,  957.9391, 1041.8589,  951.1638, 1041.8629],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 949.7581,  956.9391,  956.9366, 1042.8504,  949.7581, 1042.8545],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 956.9391,  956.9366, 1042.8504,  949.7581, 1042.8545],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(175263.5285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 44 was 58.2%\n",
      "Previous reaction rates:  tensor([ 949.7581,  956.9391,  956.9366, 1042.8504,  949.7581, 1042.8545],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 948.3428,  955.9369,  955.9342, 1043.8416,  948.3428, 1043.8459],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 955.9369,  955.9342, 1043.8416,  948.3428, 1043.8459],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(175574.5141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 45 was 58.2%\n",
      "Previous reaction rates:  tensor([ 948.3428,  955.9369,  955.9342, 1043.8416,  948.3428, 1043.8459],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 946.9179,  954.9346,  954.9319, 1044.8325,  946.9179, 1044.8369],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 954.9346,  954.9319, 1044.8325,  946.9179, 1044.8369],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(175887.0314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 46 was 58.2%\n",
      "Previous reaction rates:  tensor([ 946.9179,  954.9346,  954.9319, 1044.8325,  946.9179, 1044.8369],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 945.4837,  953.9325,  953.9296, 1045.8232,  945.4837, 1045.8277],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 953.9325,  953.9296, 1045.8232,  945.4837, 1045.8277],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(176201.0786, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 47 was 58.3%\n",
      "Previous reaction rates:  tensor([ 945.4837,  953.9325,  953.9296, 1045.8232,  945.4837, 1045.8277],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 944.0403,  952.9305,  952.9275, 1046.8136,  944.0403, 1046.8182],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 952.9305,  952.9275, 1046.8136,  944.0403, 1046.8182],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(176516.6543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 48 was 58.3%\n",
      "Previous reaction rates:  tensor([ 944.0403,  952.9305,  952.9275, 1046.8136,  944.0403, 1046.8182],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 942.5880,  951.9286,  951.9254, 1047.8037,  942.5880, 1047.8085],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 951.9286,  951.9254, 1047.8037,  942.5880, 1047.8085],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(176833.7563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 49 was 58.3%\n",
      "Previous reaction rates:  tensor([ 942.5880,  951.9286,  951.9254, 1047.8037,  942.5880, 1047.8085],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 941.1268,  950.9268,  950.9235, 1048.7936,  941.1268, 1048.7985],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 950.9268,  950.9235, 1048.7936,  941.1268, 1048.7985],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(177152.3832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 50 was 58.3%\n",
      "Previous reaction rates:  tensor([ 941.1268,  950.9268,  950.9235, 1048.7936,  941.1268, 1048.7985],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 939.6571,  949.9252,  949.9217, 1049.7832,  939.6571, 1049.7882],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 949.9252,  949.9217, 1049.7832,  939.6571, 1049.7882],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(177472.5332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 51 was 58.4%\n",
      "Previous reaction rates:  tensor([ 939.6571,  949.9252,  949.9217, 1049.7832,  939.6571, 1049.7882],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 938.1789,  948.9237,  948.9201, 1050.7726,  938.1789, 1050.7777],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 948.9237,  948.9201, 1050.7726,  938.1789, 1050.7777],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(177794.2045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 52 was 58.4%\n",
      "Previous reaction rates:  tensor([ 938.1789,  948.9237,  948.9201, 1050.7726,  938.1789, 1050.7777],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 936.6924,  947.9224,  947.9186, 1051.7617,  936.6924, 1051.7669],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 947.9224,  947.9186, 1051.7617,  936.6924, 1051.7669],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(178117.3955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 53 was 58.4%\n",
      "Previous reaction rates:  tensor([ 936.6924,  947.9224,  947.9186, 1051.7617,  936.6924, 1051.7669],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 935.1978,  946.9213,  946.9173, 1052.7505,  935.1978, 1052.7558],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 946.9213,  946.9173, 1052.7505,  935.1978, 1052.7558],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(178442.1045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 54 was 58.5%\n",
      "Previous reaction rates:  tensor([ 935.1978,  946.9213,  946.9173, 1052.7505,  935.1978, 1052.7558],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 933.6953,  945.9203,  945.9162, 1053.7391,  933.6953, 1053.7445],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 945.9203,  945.9162, 1053.7391,  933.6953, 1053.7445],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(178768.3300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 55 was 58.5%\n",
      "Previous reaction rates:  tensor([ 933.6953,  945.9203,  945.9162, 1053.7391,  933.6953, 1053.7445],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 932.1851,  944.9195,  944.9153, 1054.7275,  932.1851, 1054.7330],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 944.9195,  944.9153, 1054.7275,  932.1851, 1054.7330],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(179096.0704, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 56 was 58.5%\n",
      "Previous reaction rates:  tensor([ 932.1851,  944.9195,  944.9153, 1054.7275,  932.1851, 1054.7330],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 930.6672,  943.9190,  943.9145, 1055.7156,  930.6672, 1055.7212],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 943.9190,  943.9145, 1055.7156,  930.6672, 1055.7212],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(179425.3244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 57 was 58.5%\n",
      "Previous reaction rates:  tensor([ 930.6672,  943.9190,  943.9145, 1055.7156,  930.6672, 1055.7212],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 929.1420,  942.9186,  942.9140, 1056.7034,  929.1420, 1056.7091],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 942.9186,  942.9140, 1056.7034,  929.1420, 1056.7091],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(179756.0905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 58 was 58.6%\n",
      "Previous reaction rates:  tensor([ 929.1420,  942.9186,  942.9140, 1056.7034,  929.1420, 1056.7091],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 927.6095,  941.9185,  941.9137, 1057.6910,  927.6095, 1057.6968],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 941.9185,  941.9137, 1057.6910,  927.6095, 1057.6968],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(180088.3678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 59 was 58.6%\n",
      "Previous reaction rates:  tensor([ 927.6095,  941.9185,  941.9137, 1057.6910,  927.6095, 1057.6968],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 926.0699,  940.9186,  940.9136, 1058.6783,  926.0699, 1058.6842],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 940.9186,  940.9136, 1058.6783,  926.0699, 1058.6842],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(180422.1548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 60 was 58.6%\n",
      "Previous reaction rates:  tensor([ 926.0699,  940.9186,  940.9136, 1058.6783,  926.0699, 1058.6842],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 924.5234,  939.9190,  939.9138, 1059.6654,  924.5234, 1059.6714],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 939.9190,  939.9138, 1059.6654,  924.5234, 1059.6714],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(180757.4509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 61 was 58.7%\n",
      "Previous reaction rates:  tensor([ 924.5234,  939.9190,  939.9138, 1059.6654,  924.5234, 1059.6714],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 922.9700,  938.9196,  938.9142, 1060.6523,  922.9700, 1060.6583],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 938.9196,  938.9142, 1060.6523,  922.9700, 1060.6583],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(181094.2552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 62 was 58.7%\n",
      "Previous reaction rates:  tensor([ 922.9700,  938.9196,  938.9142, 1060.6523,  922.9700, 1060.6583],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 921.4101,  937.9205,  937.9149, 1061.6389,  921.4101, 1061.6450],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 937.9205,  937.9149, 1061.6389,  921.4101, 1061.6450],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(181432.5668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 63 was 58.7%\n",
      "Previous reaction rates:  tensor([ 921.4101,  937.9205,  937.9149, 1061.6389,  921.4101, 1061.6450],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 919.8436,  936.9217,  936.9159, 1062.6253,  919.8436, 1062.6315],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 936.9217,  936.9159, 1062.6253,  919.8436, 1062.6315],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(181772.3853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 64 was 58.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous reaction rates:  tensor([ 919.8436,  936.9217,  936.9159, 1062.6253,  919.8436, 1062.6315],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 918.2708,  935.9232,  935.9172, 1063.6115,  918.2708, 1063.6177],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 935.9232,  935.9172, 1063.6115,  918.2708, 1063.6177],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(182113.7102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 65 was 58.8%\n",
      "Previous reaction rates:  tensor([ 918.2708,  935.9232,  935.9172, 1063.6115,  918.2708, 1063.6177],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 916.6918,  934.9250,  934.9187, 1064.5974,  916.6918, 1064.6037],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 934.9250,  934.9187, 1064.5974,  916.6918, 1064.6037],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(182456.5414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 66 was 58.8%\n",
      "Previous reaction rates:  tensor([ 916.6918,  934.9250,  934.9187, 1064.5974,  916.6918, 1064.6037],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 915.1067,  933.9271,  933.9206, 1065.5830,  915.1067, 1065.5894],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 933.9271,  933.9206, 1065.5830,  915.1067, 1065.5894],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(182800.8786, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 67 was 58.8%\n",
      "Previous reaction rates:  tensor([ 915.1067,  933.9271,  933.9206, 1065.5830,  915.1067, 1065.5894],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 913.5157,  932.9295,  932.9228, 1066.5685,  913.5157, 1066.5749],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 932.9295,  932.9228, 1066.5685,  913.5157, 1066.5749],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(183146.7219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 68 was 58.9%\n",
      "Previous reaction rates:  tensor([ 913.5157,  932.9295,  932.9228, 1066.5685,  913.5157, 1066.5749],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 911.9189,  931.9323,  931.9254, 1067.5537,  911.9189, 1067.5602],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 931.9323,  931.9254, 1067.5537,  911.9189, 1067.5602],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(183494.0715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 69 was 58.9%\n",
      "Previous reaction rates:  tensor([ 911.9189,  931.9323,  931.9254, 1067.5537,  911.9189, 1067.5602],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 910.3164,  930.9354,  930.9282, 1068.5387,  910.3164, 1068.5453],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 930.9354,  930.9282, 1068.5387,  910.3164, 1068.5453],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(183842.9278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 70 was 58.9%\n",
      "Previous reaction rates:  tensor([ 910.3164,  930.9354,  930.9282, 1068.5387,  910.3164, 1068.5453],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 908.7083,  929.9389,  929.9314, 1069.5235,  908.7083, 1069.5301],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 929.9389,  929.9314, 1069.5235,  908.7083, 1069.5301],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(184193.2914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 71 was 58.9%\n",
      "Previous reaction rates:  tensor([ 908.7083,  929.9389,  929.9314, 1069.5235,  908.7083, 1069.5301],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 907.0949,  928.9427,  928.9350, 1070.5080,  907.0949, 1070.5147],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 928.9427,  928.9350, 1070.5080,  907.0949, 1070.5147],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(184545.1629, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 72 was 59.0%\n",
      "Previous reaction rates:  tensor([ 907.0949,  928.9427,  928.9350, 1070.5080,  907.0949, 1070.5147],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 905.4761,  927.9469,  927.9390, 1071.4923,  905.4761, 1071.4990],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 927.9469,  927.9390, 1071.4923,  905.4761, 1071.4990],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(184898.5431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 73 was 59.0%\n",
      "Previous reaction rates:  tensor([ 905.4761,  927.9469,  927.9390, 1071.4923,  905.4761, 1071.4990],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 903.8521,  926.9515,  926.9433, 1072.4764,  903.8521, 1072.4832],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 926.9515,  926.9433, 1072.4764,  903.8521, 1072.4832],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(185253.4332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 74 was 59.0%\n",
      "Previous reaction rates:  tensor([ 903.8521,  926.9515,  926.9433, 1072.4764,  903.8521, 1072.4832],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 902.2231,  925.9566,  925.9480, 1073.4603,  902.2231, 1073.4671],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 925.9566,  925.9480, 1073.4603,  902.2231, 1073.4671],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(185609.8342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 75 was 59.1%\n",
      "Previous reaction rates:  tensor([ 902.2231,  925.9566,  925.9480, 1073.4603,  902.2231, 1073.4671],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 900.5891,  924.9620,  924.9532, 1074.4439,  900.5891, 1074.4508],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 924.9620,  924.9532, 1074.4439,  900.5891, 1074.4508],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(185967.7476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 76 was 59.1%\n",
      "Previous reaction rates:  tensor([ 900.5891,  924.9620,  924.9532, 1074.4439,  900.5891, 1074.4508],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 898.9502,  923.9678,  923.9587, 1075.4274,  898.9502, 1075.4342],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 923.9678,  923.9587, 1075.4274,  898.9502, 1075.4342],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(186327.1749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 77 was 59.1%\n",
      "Previous reaction rates:  tensor([ 898.9502,  923.9678,  923.9587, 1075.4274,  898.9502, 1075.4342],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 897.3066,  922.9741,  922.9647, 1076.4106,  897.3066, 1076.4175],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 922.9741,  922.9647, 1076.4106,  897.3066, 1076.4175],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(186688.1176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 78 was 59.1%\n",
      "Previous reaction rates:  tensor([ 897.3066,  922.9741,  922.9647, 1076.4106,  897.3066, 1076.4175],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 895.6583,  921.9808,  921.9711, 1077.3936,  895.6583, 1077.4005],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 921.9808,  921.9711, 1077.3936,  895.6583, 1077.4005],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(187050.5779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 79 was 59.2%\n",
      "Previous reaction rates:  tensor([ 895.6583,  921.9808,  921.9711, 1077.3936,  895.6583, 1077.4005],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 894.0055,  920.9879,  920.9779, 1078.3764,  894.0055, 1078.3833],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 920.9879,  920.9779, 1078.3764,  894.0055, 1078.3833],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(187414.5577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 80 was 59.2%\n",
      "Previous reaction rates:  tensor([ 894.0055,  920.9879,  920.9779, 1078.3764,  894.0055, 1078.3833],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 892.3482,  919.9955,  919.9852, 1079.3590,  892.3482, 1079.3659],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 919.9955,  919.9852, 1079.3590,  892.3482, 1079.3659],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(187780.0591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 81 was 59.2%\n",
      "Previous reaction rates:  tensor([ 892.3482,  919.9955,  919.9852, 1079.3590,  892.3482, 1079.3659],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 890.6865,  919.0036,  918.9929, 1080.3414,  890.6865, 1080.3483],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 919.0036,  918.9929, 1080.3414,  890.6865, 1080.3483],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(188147.0844, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 82 was 59.3%\n",
      "Previous reaction rates:  tensor([ 890.6865,  919.0036,  918.9929, 1080.3414,  890.6865, 1080.3483],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 889.0206,  918.0121,  918.0011, 1081.3236,  889.0206, 1081.3305],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 918.0121,  918.0011, 1081.3236,  889.0206, 1081.3305],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(188515.6362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 83 was 59.3%\n",
      "Previous reaction rates:  tensor([ 889.0206,  918.0121,  918.0011, 1081.3236,  889.0206, 1081.3305],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 887.3505,  917.0212,  917.0098, 1082.3056,  887.3505, 1082.3124],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 917.0212,  917.0098, 1082.3056,  887.3505, 1082.3124],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(188885.7172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 84 was 59.3%\n",
      "Previous reaction rates:  tensor([ 887.3505,  917.0212,  917.0098, 1082.3056,  887.3505, 1082.3124],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 885.6763,  916.0307,  916.0189, 1083.2873,  885.6763, 1083.2942],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 916.0307,  916.0189, 1083.2873,  885.6763, 1083.2942],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(189257.3303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 85 was 59.4%\n",
      "Previous reaction rates:  tensor([ 885.6763,  916.0307,  916.0189, 1083.2873,  885.6763, 1083.2942],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 883.9981,  915.0407,  915.0286, 1084.2689,  883.9981, 1084.2757],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 915.0407,  915.0286, 1084.2689,  883.9981, 1084.2757],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(189630.4784, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 86 was 59.4%\n",
      "Previous reaction rates:  tensor([ 883.9981,  915.0407,  915.0286, 1084.2689,  883.9981, 1084.2757],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 882.3159,  914.0513,  914.0388, 1085.2503,  882.3159, 1085.2571],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 914.0513,  914.0388, 1085.2503,  882.3159, 1085.2571],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(190005.1646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 87 was 59.4%\n",
      "Previous reaction rates:  tensor([ 882.3159,  914.0513,  914.0388, 1085.2503,  882.3159, 1085.2571],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 880.6299,  913.0623,  913.0494, 1086.2314,  880.6299, 1086.2382],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 913.0623,  913.0494, 1086.2314,  880.6299, 1086.2382],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(190381.3923, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 88 was 59.4%\n",
      "Previous reaction rates:  tensor([ 880.6299,  913.0623,  913.0494, 1086.2314,  880.6299, 1086.2382],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 878.9402,  912.0739,  912.0606, 1087.2124,  878.9402, 1087.2191],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 912.0739,  912.0606, 1087.2124,  878.9402, 1087.2191],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(190759.1650, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 89 was 59.5%\n",
      "Previous reaction rates:  tensor([ 878.9402,  912.0739,  912.0606, 1087.2124,  878.9402, 1087.2191],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 877.2467,  911.0861,  911.0724, 1088.1931,  877.2467, 1088.1999],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 911.0861,  911.0724, 1088.1931,  877.2467, 1088.1999],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(191138.4862, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 90 was 59.5%\n",
      "Previous reaction rates:  tensor([ 877.2467,  911.0861,  911.0724, 1088.1931,  877.2467, 1088.1999],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 875.5496,  910.0988,  910.0846, 1089.1737,  875.5496, 1089.1804],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 910.0988,  910.0846, 1089.1737,  875.5496, 1089.1804],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(191519.3598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 91 was 59.5%\n",
      "Previous reaction rates:  tensor([ 875.5496,  910.0988,  910.0846, 1089.1737,  875.5496, 1089.1804],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 873.8489,  909.1120,  909.0975, 1090.1541,  873.8489, 1090.1607],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 909.1120,  909.0975, 1090.1541,  873.8489, 1090.1607],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(191901.7896, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 92 was 59.6%\n",
      "Previous reaction rates:  tensor([ 873.8489,  909.1120,  909.0975, 1090.1541,  873.8489, 1090.1607],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 872.1447,  908.1258,  908.1108, 1091.1342,  872.1447, 1091.1408],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 908.1258,  908.1108, 1091.1342,  872.1447, 1091.1408],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(192285.7798, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 93 was 59.6%\n",
      "Previous reaction rates:  tensor([ 872.1447,  908.1258,  908.1108, 1091.1342,  872.1447, 1091.1408],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 870.4371,  907.1402,  907.1248, 1092.1142,  870.4371, 1092.1208],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 907.1402,  907.1248, 1092.1142,  870.4371, 1092.1208],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(192671.3344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 94 was 59.6%\n",
      "Previous reaction rates:  tensor([ 870.4371,  907.1402,  907.1248, 1092.1142,  870.4371, 1092.1208],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 868.7262,  906.1552,  906.1393, 1093.0940,  868.7262, 1093.1005],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 906.1552,  906.1393, 1093.0940,  868.7262, 1093.1005],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(193058.4581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 95 was 59.6%\n",
      "Previous reaction rates:  tensor([ 868.7262,  906.1552,  906.1393, 1093.0940,  868.7262, 1093.1005],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 867.0119,  905.1708,  905.1544, 1094.0736,  867.0119, 1094.0800],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 905.1708,  905.1544, 1094.0736,  867.0119, 1094.0800],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(193447.1552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 96 was 59.7%\n",
      "Previous reaction rates:  tensor([ 867.0119,  905.1708,  905.1544, 1094.0736,  867.0119, 1094.0800],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 865.2944,  904.1870,  904.1701, 1095.0530,  865.2944, 1095.0593],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 904.1870,  904.1701, 1095.0530,  865.2944, 1095.0593],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(193837.4304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 97 was 59.7%\n",
      "Previous reaction rates:  tensor([ 865.2944,  904.1870,  904.1701, 1095.0530,  865.2944, 1095.0593],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 863.5738,  903.2038,  903.1864, 1096.0322,  863.5738, 1096.0385],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 903.2038,  903.1864, 1096.0322,  863.5738, 1096.0385],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(194229.2885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 98 was 59.7%\n",
      "Previous reaction rates:  tensor([ 863.5738,  903.2038,  903.1864, 1096.0322,  863.5738, 1096.0385],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 861.8500,  902.2212,  902.2033, 1097.0112,  861.8500, 1097.0174],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 902.2212,  902.2033, 1097.0112,  861.8500, 1097.0174],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(194622.7345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 99 was 59.8%\n",
      "Previous reaction rates:  tensor([ 861.8500,  902.2212,  902.2033, 1097.0112,  861.8500, 1097.0174],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 860.1231,  901.2392,  901.2209, 1097.9901,  860.1231, 1097.9962],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 901.2392,  901.2209, 1097.9901,  860.1231, 1097.9962],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(195017.7734, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 100 was 59.8%\n",
      "Previous reaction rates:  tensor([ 860.1231,  901.2392,  901.2209, 1097.9901,  860.1231, 1097.9962],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 858.3932,  900.2579,  900.2390, 1098.9687,  858.3932, 1098.9747],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 900.2579,  900.2390, 1098.9687,  858.3932, 1098.9747],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(195414.4104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 101 was 59.8%\n",
      "Previous reaction rates:  tensor([ 858.3932,  900.2579,  900.2390, 1098.9687,  858.3932, 1098.9747],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 856.6604,  899.2773,  899.2578, 1099.9472,  856.6604, 1099.9531],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 899.2773,  899.2578, 1099.9472,  856.6604, 1099.9531],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(195812.6510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 102 was 59.9%\n",
      "Previous reaction rates:  tensor([ 856.6604,  899.2773,  899.2578, 1099.9472,  856.6604, 1099.9531],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 854.9246,  898.2973,  898.2773, 1100.9254,  854.9246, 1100.9312],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 898.2973,  898.2773, 1100.9254,  854.9246, 1100.9312],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(196212.5005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 103 was 59.9%\n",
      "Previous reaction rates:  tensor([ 854.9246,  898.2973,  898.2773, 1100.9254,  854.9246, 1100.9312],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 853.1860,  897.3179,  897.2974, 1101.9035,  853.1860, 1101.9092],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 897.3179,  897.2974, 1101.9035,  853.1860, 1101.9092],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(196613.9647, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 104 was 59.9%\n",
      "Previous reaction rates:  tensor([ 853.1860,  897.3179,  897.2974, 1101.9035,  853.1860, 1101.9092],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 851.4446,  896.3393,  896.3181, 1102.8814,  851.4446, 1102.8870],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 896.3393,  896.3181, 1102.8814,  851.4446, 1102.8870],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(197017.0495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 105 was 60.0%\n",
      "Previous reaction rates:  tensor([ 851.4446,  896.3393,  896.3181, 1102.8814,  851.4446, 1102.8870],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 849.7003,  895.3613,  895.3396, 1103.8591,  849.7003, 1103.8646],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 895.3613,  895.3396, 1103.8591,  849.7003, 1103.8646],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(197421.7604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 106 was 60.0%\n",
      "Previous reaction rates:  tensor([ 849.7003,  895.3613,  895.3396, 1103.8591,  849.7003, 1103.8646],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 847.9534,  894.3840,  894.3617, 1104.8367,  847.9534, 1104.8420],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 894.3840,  894.3617, 1104.8367,  847.9534, 1104.8420],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(197828.1037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 107 was 60.0%\n",
      "Previous reaction rates:  tensor([ 847.9534,  894.3840,  894.3617, 1104.8367,  847.9534, 1104.8420],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 846.2038,  893.4075,  893.3845, 1105.8140,  846.2038, 1105.8193],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 893.4075,  893.3845, 1105.8140,  846.2038, 1105.8193],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(198236.0856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 108 was 60.0%\n",
      "Previous reaction rates:  tensor([ 846.2038,  893.4075,  893.3845, 1105.8140,  846.2038, 1105.8193],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 844.4515,  892.4316,  892.4080, 1106.7912,  844.4515, 1106.7963],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 892.4316,  892.4080, 1106.7912,  844.4515, 1106.7963],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(198645.7122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 109 was 60.1%\n",
      "Previous reaction rates:  tensor([ 844.4515,  892.4316,  892.4080, 1106.7912,  844.4515, 1106.7963],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 842.6966,  891.4565,  891.4322, 1107.7682,  842.6966, 1107.7732],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 891.4565,  891.4322, 1107.7682,  842.6966, 1107.7732],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(199056.9900, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 110 was 60.1%\n",
      "Previous reaction rates:  tensor([ 842.6966,  891.4565,  891.4322, 1107.7682,  842.6966, 1107.7732],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 840.9392,  890.4821,  890.4572, 1108.7450,  840.9392, 1108.7498],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 890.4821,  890.4572, 1108.7450,  840.9392, 1108.7498],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(199469.9258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 111 was 60.1%\n",
      "Previous reaction rates:  tensor([ 840.9392,  890.4821,  890.4572, 1108.7450,  840.9392, 1108.7498],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 839.1792,  889.5084,  889.4828, 1109.7216,  839.1792, 1109.7263],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 889.5084,  889.4828, 1109.7216,  839.1792, 1109.7263],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(199884.5258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 112 was 60.2%\n",
      "Previous reaction rates:  tensor([ 839.1792,  889.5084,  889.4828, 1109.7216,  839.1792, 1109.7263],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 837.4168,  888.5355,  888.5092, 1110.6980,  837.4168, 1110.7026],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 888.5355,  888.5092, 1110.6980,  837.4168, 1110.7026],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(200300.7972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 113 was 60.2%\n",
      "Previous reaction rates:  tensor([ 837.4168,  888.5355,  888.5092, 1110.6980,  837.4168, 1110.7026],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 835.6518,  887.5633,  887.5364, 1111.6743,  835.6518, 1111.6787],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 887.5633,  887.5364, 1111.6743,  835.6518, 1111.6787],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(200718.7468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 114 was 60.2%\n",
      "Previous reaction rates:  tensor([ 835.6518,  887.5633,  887.5364, 1111.6743,  835.6518, 1111.6787],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 833.8845,  886.5920,  886.5642, 1112.6504,  833.8845, 1112.6547],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 886.5920,  886.5642, 1112.6504,  833.8845, 1112.6547],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(201138.3817, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 115 was 60.3%\n",
      "Previous reaction rates:  tensor([ 833.8845,  886.5920,  886.5642, 1112.6504,  833.8845, 1112.6547],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 832.1148,  885.6213,  885.5929, 1113.6263,  832.1148, 1113.6304],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 885.6213,  885.5929, 1113.6263,  832.1148, 1113.6304],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(201559.7089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 116 was 60.3%\n",
      "Previous reaction rates:  tensor([ 832.1148,  885.6213,  885.5929, 1113.6263,  832.1148, 1113.6304],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 830.3427,  884.6515,  884.6223, 1114.6020,  830.3427, 1114.6060],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 884.6515,  884.6223, 1114.6020,  830.3427, 1114.6060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(201982.7360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 117 was 60.3%\n",
      "Previous reaction rates:  tensor([ 830.3427,  884.6515,  884.6223, 1114.6020,  830.3427, 1114.6060],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 828.5683,  883.6825,  883.6525, 1115.5776,  828.5683, 1115.5814],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 883.6825,  883.6525, 1115.5776,  828.5683, 1115.5814],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(202407.4702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 118 was 60.3%\n",
      "Previous reaction rates:  tensor([ 828.5683,  883.6825,  883.6525, 1115.5776,  828.5683, 1115.5814],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 826.7916,  882.7143,  882.6835, 1116.5530,  826.7916, 1116.5566],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 882.7143,  882.6835, 1116.5530,  826.7916, 1116.5566],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(202833.9191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 119 was 60.4%\n",
      "Previous reaction rates:  tensor([ 826.7916,  882.7143,  882.6835, 1116.5530,  826.7916, 1116.5566],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 825.0126,  881.7469,  881.7153, 1117.5282,  825.0126, 1117.5316],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 881.7469,  881.7153, 1117.5282,  825.0126, 1117.5316],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(203262.0904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 120 was 60.4%\n",
      "Previous reaction rates:  tensor([ 825.0126,  881.7469,  881.7153, 1117.5282,  825.0126, 1117.5316],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 823.2314,  880.7803,  880.7479, 1118.5032,  823.2314, 1118.5065],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 880.7803,  880.7479, 1118.5032,  823.2314, 1118.5065],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(203691.9919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 121 was 60.4%\n",
      "Previous reaction rates:  tensor([ 823.2314,  880.7803,  880.7479, 1118.5032,  823.2314, 1118.5065],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 821.4480,  879.8145,  879.7813, 1119.4780,  821.4480, 1119.4811],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 879.8145,  879.7813, 1119.4780,  821.4480, 1119.4811],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(204123.6315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 122 was 60.5%\n",
      "Previous reaction rates:  tensor([ 821.4480,  879.8145,  879.7813, 1119.4780,  821.4480, 1119.4811],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 819.6624,  878.8496,  878.8155, 1120.4527,  819.6624, 1120.4556],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 878.8496,  878.8155, 1120.4527,  819.6624, 1120.4556],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(204557.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 123 was 60.5%\n",
      "Previous reaction rates:  tensor([ 819.6624,  878.8496,  878.8155, 1120.4527,  819.6624, 1120.4556],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 817.8747,  877.8856,  877.8506, 1121.4272,  817.8747, 1121.4299],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 877.8856,  877.8506, 1121.4272,  817.8747, 1121.4299],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(204992.1573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 124 was 60.5%\n",
      "Previous reaction rates:  tensor([ 817.8747,  877.8856,  877.8506, 1121.4272,  817.8747, 1121.4299],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 816.0848,  876.9224,  876.8865, 1122.4015,  816.0848, 1122.4041],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 876.9224,  876.8865, 1122.4015,  816.0848, 1122.4041],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(205429.0598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 125 was 60.6%\n",
      "Previous reaction rates:  tensor([ 816.0848,  876.9224,  876.8865, 1122.4015,  816.0848, 1122.4041],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 814.2928,  875.9601,  875.9233, 1123.3757,  814.2928, 1123.3780],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 875.9601,  875.9233, 1123.3757,  814.2928, 1123.3780],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(205867.7335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 126 was 60.6%\n",
      "Previous reaction rates:  tensor([ 814.2928,  875.9601,  875.9233, 1123.3757,  814.2928, 1123.3780],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 812.4987,  874.9987,  874.9609, 1124.3496,  812.4987, 1124.3518],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 874.9987,  874.9609, 1124.3496,  812.4987, 1124.3518],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(206308.1865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 127 was 60.6%\n",
      "Previous reaction rates:  tensor([ 812.4987,  874.9987,  874.9609, 1124.3496,  812.4987, 1124.3518],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 810.7025,  874.0381,  873.9994, 1125.3234,  810.7025, 1125.3254],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 874.0381,  873.9994, 1125.3234,  810.7025, 1125.3254],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(206750.4277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 128 was 60.7%\n",
      "Previous reaction rates:  tensor([ 810.7025,  874.0381,  873.9994, 1125.3234,  810.7025, 1125.3254],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 808.9043,  873.0785,  873.0388, 1126.2970,  808.9043, 1126.2988],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 873.0785,  873.0388, 1126.2970,  808.9043, 1126.2988],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(207194.4657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 129 was 60.7%\n",
      "Previous reaction rates:  tensor([ 808.9043,  873.0785,  873.0388, 1126.2970,  808.9043, 1126.2988],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 807.1041,  872.1198,  872.0791, 1127.2705,  807.1041, 1127.2720],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 872.1198,  872.0791, 1127.2705,  807.1041, 1127.2720],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(207640.3096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 130 was 60.7%\n",
      "Previous reaction rates:  tensor([ 807.1041,  872.1198,  872.0791, 1127.2705,  807.1041, 1127.2720],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 805.3019,  871.1620,  871.1203, 1128.2438,  805.3019, 1128.2451],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 871.1620,  871.1203, 1128.2438,  805.3019, 1128.2451],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(208087.9681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 131 was 60.8%\n",
      "Previous reaction rates:  tensor([ 805.3019,  871.1620,  871.1203, 1128.2438,  805.3019, 1128.2451],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 803.4976,  870.2051,  870.1624, 1129.2169,  803.4976, 1129.2180],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 870.2051,  870.1624, 1129.2169,  803.4976, 1129.2180],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(208537.4505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 132 was 60.8%\n",
      "Previous reaction rates:  tensor([ 803.4976,  870.2051,  870.1624, 1129.2169,  803.4976, 1129.2180],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 801.6914,  869.2492,  869.2054, 1130.1898,  801.6914, 1130.1907],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 869.2492,  869.2054, 1130.1898,  801.6914, 1130.1907],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(208988.7660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 133 was 60.8%\n",
      "Previous reaction rates:  tensor([ 801.6914,  869.2492,  869.2054, 1130.1898,  801.6914, 1130.1907],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 799.8833,  868.2943,  868.2494, 1131.1625,  799.8833, 1131.1632],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 868.2943,  868.2494, 1131.1625,  799.8833, 1131.1632],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(209441.9239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 134 was 60.9%\n",
      "Previous reaction rates:  tensor([ 799.8833,  868.2943,  868.2494, 1131.1625,  799.8833, 1131.1632],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 798.0732,  867.3403,  867.2943, 1132.1351,  798.0732, 1132.1356],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 867.3403,  867.2943, 1132.1351,  798.0732, 1132.1356],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(209896.9338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 135 was 60.9%\n",
      "Previous reaction rates:  tensor([ 798.0732,  867.3403,  867.2943, 1132.1351,  798.0732, 1132.1356],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 796.2613,  866.3872,  866.3401, 1133.1075,  796.2613, 1133.1078],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 866.3872,  866.3401, 1133.1075,  796.2613, 1133.1078],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(210353.8051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 136 was 60.9%\n",
      "Previous reaction rates:  tensor([ 796.2613,  866.3872,  866.3401, 1133.1075,  796.2613, 1133.1078],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 794.4474,  865.4352,  865.3869, 1134.0798,  794.4474, 1134.0798],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 865.4352,  865.3869, 1134.0798,  794.4474, 1134.0798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(210812.5478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 137 was 61.0%\n",
      "Previous reaction rates:  tensor([ 794.4474,  865.4352,  865.3869, 1134.0798,  794.4474, 1134.0798],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 792.6316,  864.4842,  864.4347, 1135.0518,  792.6316, 1135.0516],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 864.4842,  864.4347, 1135.0518,  792.6316, 1135.0516],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(211273.1714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 138 was 61.0%\n",
      "Previous reaction rates:  tensor([ 792.6316,  864.4842,  864.4347, 1135.0518,  792.6316, 1135.0516],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 790.8140,  863.5341,  863.4835, 1136.0237,  790.8140, 1136.0233],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 863.5341,  863.4835, 1136.0237,  790.8140, 1136.0233],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(211735.6860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 139 was 61.0%\n",
      "Previous reaction rates:  tensor([ 790.8140,  863.5341,  863.4835, 1136.0237,  790.8140, 1136.0233],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 788.9945,  862.5851,  862.5332, 1136.9954,  788.9945, 1136.9948],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 862.5851,  862.5332, 1136.9954,  788.9945, 1136.9948],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(212200.1017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 140 was 61.0%\n",
      "Previous reaction rates:  tensor([ 788.9945,  862.5851,  862.5332, 1136.9954,  788.9945, 1136.9948],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 787.1731,  861.6372,  861.5840, 1137.9669,  787.1731, 1137.9661],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 861.6372,  861.5840, 1137.9669,  787.1731, 1137.9661],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(212666.4287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 141 was 61.1%\n",
      "Previous reaction rates:  tensor([ 787.1731,  861.6372,  861.5840, 1137.9669,  787.1731, 1137.9661],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 785.3500,  860.6902,  860.6358, 1138.9383,  785.3500, 1138.9372],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 860.6902,  860.6358, 1138.9383,  785.3500, 1138.9372],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(213134.6774, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 142 was 61.1%\n",
      "Previous reaction rates:  tensor([ 785.3500,  860.6902,  860.6358, 1138.9383,  785.3500, 1138.9372],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 783.5250,  859.7443,  859.6886, 1139.9095,  783.5250, 1139.9082],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 859.7443,  859.6886, 1139.9095,  783.5250, 1139.9082],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(213604.8579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 143 was 61.1%\n",
      "Previous reaction rates:  tensor([ 783.5250,  859.7443,  859.6886, 1139.9095,  783.5250, 1139.9082],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 781.6982,  858.7995,  858.7424, 1140.8805,  781.6982, 1140.8790],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 858.7995,  858.7424, 1140.8805,  781.6982, 1140.8790],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(214076.9810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 144 was 61.2%\n",
      "Previous reaction rates:  tensor([ 781.6982,  858.7995,  858.7424, 1140.8805,  781.6982, 1140.8790],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 779.8696,  857.8558,  857.7973, 1141.8514,  779.8696, 1141.8496],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 857.8558,  857.7973, 1141.8514,  779.8696, 1141.8496],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(214551.0575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 145 was 61.2%\n",
      "Previous reaction rates:  tensor([ 779.8696,  857.8558,  857.7973, 1141.8514,  779.8696, 1141.8496],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 778.0393,  856.9131,  856.8532, 1142.8220,  778.0393, 1142.8200],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 856.9131,  856.8532, 1142.8220,  778.0393, 1142.8200],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(215027.0981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 146 was 61.2%\n",
      "Previous reaction rates:  tensor([ 778.0393,  856.9131,  856.8532, 1142.8220,  778.0393, 1142.8200],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 776.2072,  855.9715,  855.9102, 1143.7925,  776.2072, 1143.7903],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 855.9715,  855.9102, 1143.7925,  776.2072, 1143.7903],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(215505.1135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 147 was 61.3%\n",
      "Previous reaction rates:  tensor([ 776.2072,  855.9715,  855.9102, 1143.7925,  776.2072, 1143.7903],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 774.3733,  855.0311,  854.9683, 1144.7628,  774.3733, 1144.7604],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 855.0311,  854.9683, 1144.7628,  774.3733, 1144.7604],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(215985.1151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 148 was 61.3%\n",
      "Previous reaction rates:  tensor([ 774.3733,  855.0311,  854.9683, 1144.7628,  774.3733, 1144.7604],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 772.5376,  854.0917,  854.0275, 1145.7330,  772.5376, 1145.7303],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 854.0917,  854.0275, 1145.7330,  772.5376, 1145.7303],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(216467.1139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 149 was 61.3%\n",
      "Previous reaction rates:  tensor([ 772.5376,  854.0917,  854.0275, 1145.7330,  772.5376, 1145.7303],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 770.7003,  853.1535,  853.0878, 1146.7030,  770.7003, 1146.7000],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 853.1535,  853.0878, 1146.7030,  770.7003, 1146.7000],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(216951.1212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 150 was 61.4%\n",
      "Previous reaction rates:  tensor([ 770.7003,  853.1535,  853.0878, 1146.7030,  770.7003, 1146.7000],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 768.8612,  852.2165,  852.1492, 1147.6728,  768.8612, 1147.6696],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 852.2165,  852.1492, 1147.6728,  768.8612, 1147.6696],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(217437.1486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 151 was 61.4%\n",
      "Previous reaction rates:  tensor([ 768.8612,  852.2165,  852.1492, 1147.6728,  768.8612, 1147.6696],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 767.0203,  851.2806,  851.2118, 1148.6424,  767.0203, 1148.6390],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 851.2806,  851.2118, 1148.6424,  767.0203, 1148.6390],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(217925.2075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 152 was 61.4%\n",
      "Previous reaction rates:  tensor([ 767.0203,  851.2806,  851.2118, 1148.6424,  767.0203, 1148.6390],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 765.1778,  850.3459,  850.2754, 1149.6118,  765.1778, 1149.6082],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 850.3459,  850.2754, 1149.6118,  765.1778, 1149.6082],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(218415.3094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 153 was 61.5%\n",
      "Previous reaction rates:  tensor([ 765.1778,  850.3459,  850.2754, 1149.6118,  765.1778, 1149.6082],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 763.3335,  849.4123,  849.3403, 1150.5811,  763.3335, 1150.5772],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 849.4123,  849.3403, 1150.5811,  763.3335, 1150.5772],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(218907.4665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 154 was 61.5%\n",
      "Previous reaction rates:  tensor([ 763.3335,  849.4123,  849.3403, 1150.5811,  763.3335, 1150.5772],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 761.4876,  848.4800,  848.4062, 1151.5502,  761.4876, 1151.5461],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 848.4800,  848.4062, 1151.5502,  761.4876, 1151.5461],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(219401.6906, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 155 was 61.5%\n",
      "Previous reaction rates:  tensor([ 761.4876,  848.4800,  848.4062, 1151.5502,  761.4876, 1151.5461],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 759.6400,  847.5488,  847.4734, 1152.5191,  759.6400, 1152.5148],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 847.5488,  847.4734, 1152.5191,  759.6400, 1152.5148],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(219897.9938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 156 was 61.6%\n",
      "Previous reaction rates:  tensor([ 759.6400,  847.5488,  847.4734, 1152.5191,  759.6400, 1152.5148],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 757.7906,  846.6189,  846.5417, 1153.4879,  757.7906, 1153.4833],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 846.6189,  846.5417, 1153.4879,  757.7906, 1153.4833],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(220396.3882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 157 was 61.6%\n",
      "Previous reaction rates:  tensor([ 757.7906,  846.6189,  846.5417, 1153.4879,  757.7906, 1153.4833],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 755.9396,  845.6902,  845.6113, 1154.4564,  755.9396, 1154.4517],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 845.6902,  845.6113, 1154.4564,  755.9396, 1154.4517],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(220896.8861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 158 was 61.6%\n",
      "Previous reaction rates:  tensor([ 755.9396,  845.6902,  845.6113, 1154.4564,  755.9396, 1154.4517],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 754.0869,  844.7628,  844.6820, 1155.4248,  754.0869, 1155.4198],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 844.7628,  844.6820, 1155.4248,  754.0869, 1155.4198],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(221399.5003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 159 was 61.7%\n",
      "Previous reaction rates:  tensor([ 754.0869,  844.7628,  844.6820, 1155.4248,  754.0869, 1155.4198],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 752.2326,  843.8366,  843.7540, 1156.3930,  752.2326, 1156.3878],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 843.8366,  843.7540, 1156.3930,  752.2326, 1156.3878],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(221904.2431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 160 was 61.7%\n",
      "Previous reaction rates:  tensor([ 752.2326,  843.8366,  843.7540, 1156.3930,  752.2326, 1156.3878],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 750.3766,  842.9117,  842.8272, 1157.3610,  750.3766, 1157.3556],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 842.9117,  842.8272, 1157.3610,  750.3766, 1157.3556],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(222411.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 161 was 61.7%\n",
      "Previous reaction rates:  tensor([ 750.3766,  842.9117,  842.8272, 1157.3610,  750.3766, 1157.3556],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 748.5189,  841.9881,  841.9017, 1158.3289,  748.5189, 1158.3233],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 841.9881,  841.9017, 1158.3289,  748.5189, 1158.3233],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(222920.1659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 162 was 61.8%\n",
      "Previous reaction rates:  tensor([ 748.5189,  841.9881,  841.9017, 1158.3289,  748.5189, 1158.3233],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 746.6596,  841.0657,  840.9774, 1159.2966,  746.6596, 1159.2907],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 841.0657,  840.9774, 1159.2966,  746.6596, 1159.2907],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(223431.3719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 163 was 61.8%\n",
      "Previous reaction rates:  tensor([ 746.6596,  841.0657,  840.9774, 1159.2966,  746.6596, 1159.2907],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 744.7987,  840.1447,  840.0544, 1160.2641,  744.7987, 1160.2580],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 840.1447,  840.0544, 1160.2641,  744.7987, 1160.2580],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(223944.7583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 164 was 61.9%\n",
      "Previous reaction rates:  tensor([ 744.7987,  840.1447,  840.0544, 1160.2641,  744.7987, 1160.2580],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 742.9360,  839.2251,  839.1327, 1161.2314,  742.9360, 1161.2251],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 839.2251,  839.1327, 1161.2314,  742.9360, 1161.2251],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(224460.3386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 165 was 61.9%\n",
      "Previous reaction rates:  tensor([ 742.9360,  839.2251,  839.1327, 1161.2314,  742.9360, 1161.2251],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 741.0718,  838.3067,  838.2123, 1162.1985,  741.0718, 1162.1921],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 838.3067,  838.2123, 1162.1985,  741.0718, 1162.1921],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(224978.1262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 166 was 61.9%\n",
      "Previous reaction rates:  tensor([ 741.0718,  838.3067,  838.2123, 1162.1985,  741.0718, 1162.1921],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 739.2059,  837.3897,  837.2932, 1163.1655,  739.2059, 1163.1588],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 837.3897,  837.2932, 1163.1655,  739.2059, 1163.1588],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(225498.1345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 167 was 62.0%\n",
      "Previous reaction rates:  tensor([ 739.2059,  837.3897,  837.2932, 1163.1655,  739.2059, 1163.1588],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 737.3384,  836.4741,  836.3754, 1164.1322,  737.3384, 1164.1254],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 836.4741,  836.3754, 1164.1322,  737.3384, 1164.1254],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(226020.3775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 168 was 62.0%\n",
      "Previous reaction rates:  tensor([ 737.3384,  836.4741,  836.3754, 1164.1322,  737.3384, 1164.1254],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 735.4693,  835.5599,  835.4590, 1165.0988,  735.4693, 1165.0918],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 835.5599,  835.4590, 1165.0988,  735.4693, 1165.0918],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(226544.8690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 169 was 62.0%\n",
      "Previous reaction rates:  tensor([ 735.4693,  835.5599,  835.4590, 1165.0988,  735.4693, 1165.0918],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 733.5985,  834.6470,  834.5439, 1166.0652,  733.5985, 1166.0580],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 834.6470,  834.5439, 1166.0652,  733.5985, 1166.0580],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(227071.6229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 170 was 62.1%\n",
      "Previous reaction rates:  tensor([ 733.5985,  834.6470,  834.5439, 1166.0652,  733.5985, 1166.0580],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 731.7261,  833.7356,  833.6302, 1167.0315,  731.7261, 1167.0241],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 833.7356,  833.6302, 1167.0315,  731.7261, 1167.0241],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(227600.6535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 171 was 62.1%\n",
      "Previous reaction rates:  tensor([ 731.7261,  833.7356,  833.6302, 1167.0315,  731.7261, 1167.0241],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 729.8521,  832.8256,  832.7179, 1167.9975,  729.8521, 1167.9899],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 832.8256,  832.7179, 1167.9975,  729.8521, 1167.9899],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(228131.9751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 172 was 62.1%\n",
      "Previous reaction rates:  tensor([ 729.8521,  832.8256,  832.7179, 1167.9975,  729.8521, 1167.9899],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 727.9765,  831.9171,  831.8070, 1168.9633,  727.9765, 1168.9556],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 831.9171,  831.8070, 1168.9633,  727.9765, 1168.9556],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(228665.6024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 173 was 62.2%\n",
      "Previous reaction rates:  tensor([ 727.9765,  831.9171,  831.8070, 1168.9633,  727.9765, 1168.9556],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 726.0992,  831.0100,  830.8975, 1169.9290,  726.0992, 1169.9211],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 831.0100,  830.8975, 1169.9290,  726.0992, 1169.9211],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(229201.5496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 174 was 62.2%\n",
      "Previous reaction rates:  tensor([ 726.0992,  831.0100,  830.8975, 1169.9290,  726.0992, 1169.9211],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 724.2204,  830.1044,  829.9894, 1170.8945,  724.2204, 1170.8864],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 830.1044,  829.9894, 1170.8945,  724.2204, 1170.8864],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(229739.8317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 175 was 62.2%\n",
      "Previous reaction rates:  tensor([ 724.2204,  830.1044,  829.9894, 1170.8945,  724.2204, 1170.8864],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 722.3399,  829.2003,  829.0827, 1171.8598,  722.3399, 1171.8516],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 829.2003,  829.0827, 1171.8598,  722.3399, 1171.8516],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(230280.4637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 176 was 62.3%\n",
      "Previous reaction rates:  tensor([ 722.3399,  829.2003,  829.0827, 1171.8598,  722.3399, 1171.8516],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 720.4578,  828.2976,  828.1775, 1172.8249,  720.4578, 1172.8165],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 828.2976,  828.1775, 1172.8249,  720.4578, 1172.8165],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(230823.4608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 177 was 62.3%\n",
      "Previous reaction rates:  tensor([ 720.4578,  828.2976,  828.1775, 1172.8249,  720.4578, 1172.8165],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 718.5742,  827.3965,  827.2738, 1173.7898,  718.5742, 1173.7813],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 827.3965,  827.2738, 1173.7898,  718.5742, 1173.7813],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(231368.8379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 178 was 62.3%\n",
      "Previous reaction rates:  tensor([ 718.5742,  827.3965,  827.2738, 1173.7898,  718.5742, 1173.7813],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 716.6889,  826.4970,  826.3716, 1174.7545,  716.6889, 1174.7459],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 826.4970,  826.3716, 1174.7545,  716.6889, 1174.7459],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(231916.6108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 179 was 62.4%\n",
      "Previous reaction rates:  tensor([ 716.6889,  826.4970,  826.3716, 1174.7545,  716.6889, 1174.7459],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 714.8020,  825.5990,  825.4709, 1175.7191,  714.8020, 1175.7103],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 825.5990,  825.4709, 1175.7191,  714.8020, 1175.7103],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(232466.7950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 180 was 62.4%\n",
      "Previous reaction rates:  tensor([ 714.8020,  825.5990,  825.4709, 1175.7191,  714.8020, 1175.7103],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 712.9134,  824.7025,  824.5717, 1176.6834,  712.9134, 1176.6745],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 824.7025,  824.5717, 1176.6834,  712.9134, 1176.6745],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(233019.4061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 181 was 62.5%\n",
      "Previous reaction rates:  tensor([ 712.9134,  824.7025,  824.5717, 1176.6834,  712.9134, 1176.6745],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 711.0233,  823.8077,  823.6740, 1177.6476,  711.0233, 1177.6386],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 823.8077,  823.6740, 1177.6476,  711.0233, 1177.6386],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(233574.4604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 182 was 62.5%\n",
      "Previous reaction rates:  tensor([ 711.0233,  823.8077,  823.6740, 1177.6476,  711.0233, 1177.6386],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 709.1316,  822.9144,  822.7779, 1178.6115,  709.1316, 1178.6025],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 822.9144,  822.7779, 1178.6115,  709.1316, 1178.6025],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(234131.9737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 183 was 62.5%\n",
      "Previous reaction rates:  tensor([ 709.1316,  822.9144,  822.7779, 1178.6115,  709.1316, 1178.6025],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 707.2382,  822.0228,  821.8833, 1179.5753,  707.2382, 1179.5661],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 822.0228,  821.8833, 1179.5753,  707.2382, 1179.5661],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(234691.9623, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 184 was 62.6%\n",
      "Previous reaction rates:  tensor([ 707.2382,  822.0228,  821.8833, 1179.5753,  707.2382, 1179.5661],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 705.3433,  821.1328,  820.9903, 1180.5389,  705.3433, 1180.5296],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 821.1328,  820.9903, 1180.5389,  705.3433, 1180.5296],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(235254.4427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 185 was 62.6%\n",
      "Previous reaction rates:  tensor([ 705.3433,  821.1328,  820.9903, 1180.5389,  705.3433, 1180.5296],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 703.4467,  820.2445,  820.0990, 1181.5022,  703.4467, 1181.4929],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 820.2445,  820.0990, 1181.5022,  703.4467, 1181.4929],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(235819.4316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 186 was 62.6%\n",
      "Previous reaction rates:  tensor([ 703.4467,  820.2445,  820.0990, 1181.5022,  703.4467, 1181.4929],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 701.5486,  819.3578,  819.2092, 1182.4654,  701.5486, 1182.4560],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 819.3578,  819.2092, 1182.4654,  701.5486, 1182.4560],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(236386.9456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 187 was 62.7%\n",
      "Previous reaction rates:  tensor([ 701.5486,  819.3578,  819.2092, 1182.4654,  701.5486, 1182.4560],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 699.6488,  818.4728,  818.3210, 1183.4284,  699.6488, 1183.4190],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 818.4728,  818.3210, 1183.4284,  699.6488, 1183.4190],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(236957.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 188 was 62.7%\n",
      "Previous reaction rates:  tensor([ 699.6488,  818.4728,  818.3210, 1183.4284,  699.6488, 1183.4190],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 697.7474,  817.5896,  817.4346, 1184.3912,  697.7474, 1184.3817],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 817.5896,  817.4346, 1184.3912,  697.7474, 1184.3817],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(237529.6178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 189 was 62.7%\n",
      "Previous reaction rates:  tensor([ 697.7474,  817.5896,  817.4346, 1184.3912,  697.7474, 1184.3817],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 695.8445,  816.7080,  816.5497, 1185.3538,  695.8445, 1185.3443],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 816.7080,  816.5497, 1185.3538,  695.8445, 1185.3443],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(238104.8104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 190 was 62.8%\n",
      "Previous reaction rates:  tensor([ 695.8445,  816.7080,  816.5497, 1185.3538,  695.8445, 1185.3443],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 693.9399,  815.8282,  815.6666, 1186.3162,  693.9399, 1186.3066],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 815.8282,  815.6666, 1186.3162,  693.9399, 1186.3066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(238682.5973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 191 was 62.8%\n",
      "Previous reaction rates:  tensor([ 693.9399,  815.8282,  815.6666, 1186.3162,  693.9399, 1186.3066],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 692.0336,  814.9502,  814.7851, 1187.2783,  692.0336, 1187.2688],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 814.9502,  814.7851, 1187.2783,  692.0336, 1187.2688],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(239262.9964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 192 was 62.9%\n",
      "Previous reaction rates:  tensor([ 692.0336,  814.9502,  814.7851, 1187.2783,  692.0336, 1187.2688],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 690.1258,  814.0739,  813.9054, 1188.2403,  690.1258, 1188.2307],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 814.0739,  813.9054, 1188.2403,  690.1258, 1188.2307],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(239846.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 193 was 62.9%\n",
      "Previous reaction rates:  tensor([ 690.1258,  814.0739,  813.9054, 1188.2403,  690.1258, 1188.2307],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 688.2164,  813.1995,  813.0274, 1189.2021,  688.2164, 1189.1925],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 813.1995,  813.0274, 1189.2021,  688.2164, 1189.1925],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(240431.7030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 194 was 62.9%\n",
      "Previous reaction rates:  tensor([ 688.2164,  813.1995,  813.0274, 1189.2021,  688.2164, 1189.1925],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 686.3053,  812.3268,  812.1511, 1190.1637,  686.3053, 1190.1541],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 812.3268,  812.1511, 1190.1637,  686.3053, 1190.1541],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(241020.0469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 195 was 63.0%\n",
      "Previous reaction rates:  tensor([ 686.3053,  812.3268,  812.1511, 1190.1637,  686.3053, 1190.1541],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 684.3926,  811.4560,  811.2767, 1191.1250,  684.3926, 1191.1155],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 811.4560,  811.2767, 1191.1250,  684.3926, 1191.1155],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(241611.0758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 196 was 63.0%\n",
      "Previous reaction rates:  tensor([ 684.3926,  811.4560,  811.2767, 1191.1250,  684.3926, 1191.1155],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 682.4783,  810.5871,  810.4040, 1192.0862,  682.4783, 1192.0767],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 810.5871,  810.4040, 1192.0862,  682.4783, 1192.0767],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(242204.8087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 197 was 63.0%\n",
      "Previous reaction rates:  tensor([ 682.4783,  810.5871,  810.4040, 1192.0862,  682.4783, 1192.0767],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 680.5624,  809.7200,  809.5331, 1193.0471,  680.5624, 1193.0377],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 809.7200,  809.5331, 1193.0471,  680.5624, 1193.0377],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(242801.2644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 198 was 63.1%\n",
      "Previous reaction rates:  tensor([ 680.5624,  809.7200,  809.5331, 1193.0471,  680.5624, 1193.0377],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 678.6448,  808.8548,  808.6640, 1194.0078,  678.6448, 1193.9985],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 808.8548,  808.6640, 1194.0078,  678.6448, 1193.9985],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(243400.4620, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 199 was 63.1%\n",
      "Previous reaction rates:  tensor([ 678.6448,  808.8548,  808.6640, 1194.0078,  678.6448, 1193.9985],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 676.7257,  807.9916,  807.7968, 1194.9683,  676.7257, 1194.9591],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 807.9916,  807.7968, 1194.9683,  676.7257, 1194.9591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(244002.4211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 200 was 63.2%\n",
      "Previous reaction rates:  tensor([ 676.7257,  807.9916,  807.7968, 1194.9683,  676.7257, 1194.9591],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 674.8049,  807.1303,  806.9315, 1195.9287,  674.8049, 1195.9195],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 807.1303,  806.9315, 1195.9287,  674.8049, 1195.9195],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(244607.1611, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 201 was 63.2%\n",
      "Previous reaction rates:  tensor([ 674.8049,  807.1303,  806.9315, 1195.9287,  674.8049, 1195.9195],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 672.8824,  806.2709,  806.0680, 1196.8887,  672.8824, 1196.8797],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 806.2709,  806.0680, 1196.8887,  672.8824, 1196.8797],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(245214.7021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 202 was 63.2%\n",
      "Previous reaction rates:  tensor([ 672.8824,  806.2709,  806.0680, 1196.8887,  672.8824, 1196.8797],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 670.9583,  805.4135,  805.2064, 1197.8486,  670.9583, 1197.8397],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 805.4135,  805.2064, 1197.8486,  670.9583, 1197.8397],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(245825.0638, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 203 was 63.3%\n",
      "Previous reaction rates:  tensor([ 670.9583,  805.4135,  805.2064, 1197.8486,  670.9583, 1197.8397],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 669.0326,  804.5581,  804.3468, 1198.8083,  669.0326, 1198.7995],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 804.5581,  804.3468, 1198.8083,  669.0326, 1198.7995],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(246438.2668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 204 was 63.3%\n",
      "Previous reaction rates:  tensor([ 669.0326,  804.5581,  804.3468, 1198.8083,  669.0326, 1198.7995],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 667.1053,  803.7048,  803.4891, 1199.7677,  667.1053, 1199.7591],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 803.7048,  803.4891, 1199.7677,  667.1053, 1199.7591],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(247054.3314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 205 was 63.4%\n",
      "Previous reaction rates:  tensor([ 667.1053,  803.7048,  803.4891, 1199.7677,  667.1053, 1199.7591],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 665.1763,  802.8535,  802.6333, 1200.7269,  665.1763, 1200.7185],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 802.8535,  802.6333, 1200.7269,  665.1763, 1200.7185],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(247673.2785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 206 was 63.4%\n",
      "Previous reaction rates:  tensor([ 665.1763,  802.8535,  802.6333, 1200.7269,  665.1763, 1200.7185],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 663.2456,  802.0042,  801.7796, 1201.6859,  663.2456, 1201.6777],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 802.0042,  801.7796, 1201.6859,  663.2456, 1201.6777],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(248295.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 207 was 63.4%\n",
      "Previous reaction rates:  tensor([ 663.2456,  802.0042,  801.7796, 1201.6859,  663.2456, 1201.6777],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 661.3133,  801.1570,  800.9278, 1202.6447,  661.3133, 1202.6366],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 801.1570,  800.9278, 1202.6447,  661.3133, 1202.6366],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(248919.9042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 208 was 63.5%\n",
      "Previous reaction rates:  tensor([ 661.3133,  801.1570,  800.9278, 1202.6447,  661.3133, 1202.6366],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 659.3794,  800.3120,  800.0781, 1203.6032,  659.3794, 1203.5954],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 800.3120,  800.0781, 1203.6032,  659.3794, 1203.5954],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(249547.6257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 209 was 63.5%\n",
      "Previous reaction rates:  tensor([ 659.3794,  800.3120,  800.0781, 1203.6032,  659.3794, 1203.5954],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 657.4437,  799.4690,  799.2304, 1204.5615,  657.4437, 1204.5540],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 799.4690,  799.2304, 1204.5615,  657.4437, 1204.5540],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(250178.3151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 210 was 63.5%\n",
      "Previous reaction rates:  tensor([ 657.4437,  799.4690,  799.2304, 1204.5615,  657.4437, 1204.5540],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 655.5065,  798.6283,  798.3847, 1205.5196,  655.5065, 1205.5123],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 798.6283,  798.3847, 1205.5196,  655.5065, 1205.5123],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(250811.9945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 211 was 63.6%\n",
      "Previous reaction rates:  tensor([ 655.5065,  798.6283,  798.3847, 1205.5196,  655.5065, 1205.5123],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 653.5675,  797.7897,  797.5412, 1206.4774,  653.5675, 1206.4704],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 797.7897,  797.5412, 1206.4774,  653.5675, 1206.4704],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(251448.6860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 212 was 63.6%\n",
      "Previous reaction rates:  tensor([ 653.5675,  797.7897,  797.5412, 1206.4774,  653.5675, 1206.4704],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 651.6269,  796.9533,  796.6997, 1207.4350,  651.6269, 1207.4283],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 796.9533,  796.6997, 1207.4350,  651.6269, 1207.4283],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(252088.4123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 213 was 63.7%\n",
      "Previous reaction rates:  tensor([ 651.6269,  796.9533,  796.6997, 1207.4350,  651.6269, 1207.4283],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 649.6847,  796.1191,  795.8604, 1208.3924,  649.6847, 1208.3860],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 796.1191,  795.8604, 1208.3924,  649.6847, 1208.3860],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(252731.1962, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 214 was 63.7%\n",
      "Previous reaction rates:  tensor([ 649.6847,  796.1191,  795.8604, 1208.3924,  649.6847, 1208.3860],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 647.7407,  795.2871,  795.0233, 1209.3496,  647.7407, 1209.3435],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 795.2871,  795.0233, 1209.3496,  647.7407, 1209.3435],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(253377.0606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 215 was 63.7%\n",
      "Previous reaction rates:  tensor([ 647.7407,  795.2871,  795.0233, 1209.3496,  647.7407, 1209.3435],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 645.7951,  794.4575,  794.1883, 1210.3065,  645.7951, 1210.3008],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 794.4575,  794.1883, 1210.3065,  645.7951, 1210.3008],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(254026.0289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 216 was 63.8%\n",
      "Previous reaction rates:  tensor([ 645.7951,  794.4575,  794.1883, 1210.3065,  645.7951, 1210.3008],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 643.8478,  793.6301,  793.3555, 1211.2631,  643.8478, 1211.2578],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 793.6301,  793.3555, 1211.2631,  643.8478, 1211.2578],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(254678.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 217 was 63.8%\n",
      "Previous reaction rates:  tensor([ 643.8478,  793.6301,  793.3555, 1211.2631,  643.8478, 1211.2578],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 641.8988,  792.8051,  792.5249, 1212.2195,  641.8988, 1212.2146],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 792.8051,  792.5249, 1212.2195,  641.8988, 1212.2146],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(255333.3723, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 218 was 63.9%\n",
      "Previous reaction rates:  tensor([ 641.8988,  792.8051,  792.5249, 1212.2195,  641.8988, 1212.2146],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 639.9481,  791.9824,  791.6966, 1213.1757,  639.9481, 1213.1712],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 791.9824,  791.6966, 1213.1757,  639.9481, 1213.1712],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(255991.7954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 219 was 63.9%\n",
      "Previous reaction rates:  tensor([ 639.9481,  791.9824,  791.6966, 1213.1757,  639.9481, 1213.1712],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 637.9957,  791.1620,  790.8706, 1214.1316,  637.9957, 1214.1276],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 791.1620,  790.8706, 1214.1316,  637.9957, 1214.1276],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(256653.4186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 220 was 64.0%\n",
      "Previous reaction rates:  tensor([ 637.9957,  791.1620,  790.8706, 1214.1316,  637.9957, 1214.1276],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 636.0416,  790.3441,  790.0468, 1215.0873,  636.0416, 1215.0837],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 790.3441,  790.0468, 1215.0873,  636.0416, 1215.0837],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(257318.2667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 221 was 64.0%\n",
      "Previous reaction rates:  tensor([ 636.0416,  790.3441,  790.0468, 1215.0873,  636.0416, 1215.0837],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 634.0858,  789.5286,  789.2253, 1216.0427,  634.0858, 1216.0396],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 789.5286,  789.2253, 1216.0427,  634.0858, 1216.0396],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(257986.3649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 222 was 64.0%\n",
      "Previous reaction rates:  tensor([ 634.0858,  789.5286,  789.2253, 1216.0427,  634.0858, 1216.0396],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 632.1283,  788.7155,  788.4062, 1216.9979,  632.1283, 1216.9953],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 788.7155,  788.4062, 1216.9979,  632.1283, 1216.9953],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(258657.7389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 223 was 64.1%\n",
      "Previous reaction rates:  tensor([ 632.1283,  788.7155,  788.4062, 1216.9979,  632.1283, 1216.9953],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 630.1691,  787.9049,  787.5895, 1217.9528,  630.1691, 1217.9508],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 787.9049,  787.5895, 1217.9528,  630.1691, 1217.9508],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Next time:  tensor(259332.4139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 224 was 64.1%\n",
      "Previous reaction rates:  tensor([ 630.1691,  787.9049,  787.5895, 1217.9528,  630.1691, 1217.9508],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 628.2082,  787.0968,  786.7751, 1218.9074,  628.2082, 1218.9060],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 787.0968,  786.7751, 1218.9074,  628.2082, 1218.9060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(260010.4165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 225 was 64.2%\n",
      "Previous reaction rates:  tensor([ 628.2082,  787.0968,  786.7751, 1218.9074,  628.2082, 1218.9060],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 626.2455,  786.2912,  785.9631, 1219.8618,  626.2455, 1219.8609],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 786.2912,  785.9631, 1219.8618,  626.2455, 1219.8609],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(260691.7727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 226 was 64.2%\n",
      "Previous reaction rates:  tensor([ 626.2455,  786.2912,  785.9631, 1219.8618,  626.2455, 1219.8609],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 624.2811,  785.4882,  785.1536, 1220.8160,  624.2811, 1220.8157],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 785.4882,  785.1536, 1220.8160,  624.2811, 1220.8157],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(261376.5095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 227 was 64.2%\n",
      "Previous reaction rates:  tensor([ 624.2811,  785.4882,  785.1536, 1220.8160,  624.2811, 1220.8157],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 622.3150,  784.6877,  784.3465, 1221.7698,  622.3150, 1221.7702],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 784.6877,  784.3465, 1221.7698,  622.3150, 1221.7702],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(262064.6538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 228 was 64.3%\n",
      "Previous reaction rates:  tensor([ 622.3150,  784.6877,  784.3465, 1221.7698,  622.3150, 1221.7702],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 620.3471,  783.8899,  783.5419, 1222.7234,  620.3471, 1222.7244],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 783.8899,  783.5419, 1222.7234,  620.3471, 1222.7244],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(262756.2333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 229 was 64.3%\n",
      "Previous reaction rates:  tensor([ 620.3471,  783.8899,  783.5419, 1222.7234,  620.3471, 1222.7244],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 618.3775,  783.0946,  782.7399, 1223.6767,  618.3775, 1223.6784],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 783.0946,  782.7399, 1223.6767,  618.3775, 1223.6784],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(263451.2756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 230 was 64.4%\n",
      "Previous reaction rates:  tensor([ 618.3775,  783.0946,  782.7399, 1223.6767,  618.3775, 1223.6784],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 616.4062,  782.3021,  781.9403, 1224.6298,  616.4062, 1224.6322],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 782.3021,  781.9403, 1224.6298,  616.4062, 1224.6322],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(264149.8089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 231 was 64.4%\n",
      "Previous reaction rates:  tensor([ 616.4062,  782.3021,  781.9403, 1224.6298,  616.4062, 1224.6322],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 614.4331,  781.5122,  781.1434, 1225.5825,  614.4331, 1225.5857],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 781.5122,  781.1434, 1225.5825,  614.4331, 1225.5857],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(264851.8616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 232 was 64.5%\n",
      "Previous reaction rates:  tensor([ 614.4331,  781.5122,  781.1434, 1225.5825,  614.4331, 1225.5857],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 612.4583,  780.7251,  780.3490, 1226.5350,  612.4583, 1226.5390],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 780.7251,  780.3490, 1226.5350,  612.4583, 1226.5390],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(265557.4630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 233 was 64.5%\n",
      "Previous reaction rates:  tensor([ 612.4583,  780.7251,  780.3490, 1226.5350,  612.4583, 1226.5390],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 610.4816,  779.9407,  779.5572, 1227.4872,  610.4816, 1227.4920],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 779.9407,  779.5572, 1227.4872,  610.4816, 1227.4920],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(266266.6420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 234 was 64.5%\n",
      "Previous reaction rates:  tensor([ 610.4816,  779.9407,  779.5572, 1227.4872,  610.4816, 1227.4920],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 608.5033,  779.1591,  778.7681, 1228.4391,  608.5033, 1228.4447],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 779.1591,  778.7681, 1228.4391,  608.5033, 1228.4447],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(266979.4281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 235 was 64.6%\n",
      "Previous reaction rates:  tensor([ 608.5033,  779.1591,  778.7681, 1228.4391,  608.5033, 1228.4447],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 606.5231,  778.3803,  777.9817, 1229.3907,  606.5231, 1229.3972],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 778.3803,  777.9817, 1229.3907,  606.5231, 1229.3972],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(267695.8520, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 236 was 64.6%\n",
      "Previous reaction rates:  tensor([ 606.5231,  778.3803,  777.9817, 1229.3907,  606.5231, 1229.3972],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 604.5412,  777.6043,  777.1980, 1230.3421,  604.5412, 1230.3494],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 777.6043,  777.1980, 1230.3421,  604.5412, 1230.3494],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(268415.9439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 237 was 64.7%\n",
      "Previous reaction rates:  tensor([ 604.5412,  777.6043,  777.1980, 1230.3421,  604.5412, 1230.3494],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 602.5575,  776.8312,  776.4169, 1231.2931,  602.5575, 1231.3014],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 776.8312,  776.4169, 1231.2931,  602.5575, 1231.3014],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(269139.7344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 238 was 64.7%\n",
      "Previous reaction rates:  tensor([ 602.5575,  776.8312,  776.4169, 1231.2931,  602.5575, 1231.3014],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 600.5719,  776.0611,  775.6387, 1232.2439,  600.5719, 1232.2531],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 776.0611,  775.6387, 1232.2439,  600.5719, 1232.2531],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(269867.2552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 239 was 64.8%\n",
      "Previous reaction rates:  tensor([ 600.5719,  776.0611,  775.6387, 1232.2439,  600.5719, 1232.2531],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 598.5846,  775.2938,  774.8632, 1233.1943,  598.5846, 1233.2046],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 775.2938,  774.8632, 1233.1943,  598.5846, 1233.2046],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(270598.5381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 240 was 64.8%\n",
      "Previous reaction rates:  tensor([ 598.5846,  775.2938,  774.8632, 1233.1943,  598.5846, 1233.2046],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 596.5955,  774.5295,  774.0906, 1234.1445,  596.5955, 1234.1557],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 774.5295,  774.0906, 1234.1445,  596.5955, 1234.1557],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(271333.6151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 241 was 64.9%\n",
      "Previous reaction rates:  tensor([ 596.5955,  774.5295,  774.0906, 1234.1445,  596.5955, 1234.1557],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 594.6046,  773.7682,  773.3207, 1235.0943,  594.6046, 1235.1066],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 773.7682,  773.3207, 1235.0943,  594.6046, 1235.1066],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(272072.5189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 242 was 64.9%\n",
      "Previous reaction rates:  tensor([ 594.6046,  773.7682,  773.3207, 1235.0943,  594.6046, 1235.1066],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 592.6119,  773.0099,  772.5538, 1236.0438,  592.6119, 1236.0572],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 773.0099,  772.5538, 1236.0438,  592.6119, 1236.0572],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(272815.2827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 243 was 64.9%\n",
      "Previous reaction rates:  tensor([ 592.6119,  773.0099,  772.5538, 1236.0438,  592.6119, 1236.0572],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 590.6174,  772.2547,  771.7898, 1236.9930,  590.6174, 1237.0076],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 772.2547,  771.7898, 1236.9930,  590.6174, 1237.0076],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(273561.9398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 244 was 65.0%\n",
      "Previous reaction rates:  tensor([ 590.6174,  772.2547,  771.7898, 1236.9930,  590.6174, 1237.0076],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 588.6210,  771.5025,  771.0287, 1237.9419,  588.6210, 1237.9576],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 771.5025,  771.0287, 1237.9419,  588.6210, 1237.9576],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(274312.5244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 245 was 65.0%\n",
      "Previous reaction rates:  tensor([ 588.6210,  771.5025,  771.0287, 1237.9419,  588.6210, 1237.9576],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 586.6228,  770.7535,  770.2705, 1238.8905,  586.6228, 1238.9074],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 770.7535,  770.2705, 1238.8905,  586.6228, 1238.9074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(275067.0709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 246 was 65.1%\n",
      "Previous reaction rates:  tensor([ 586.6228,  770.7535,  770.2705, 1238.8905,  586.6228, 1238.9074],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 584.6228,  770.0077,  769.5154, 1239.8387,  584.6228, 1239.8569],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 770.0077,  769.5154, 1239.8387,  584.6228, 1239.8569],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(275825.6148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 247 was 65.1%\n",
      "Previous reaction rates:  tensor([ 584.6228,  770.0077,  769.5154, 1239.8387,  584.6228, 1239.8569],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 582.6210,  769.2650,  768.7632, 1240.7866,  582.6210, 1240.8061],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 769.2650,  768.7632, 1240.7866,  582.6210, 1240.8061],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(276588.1912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 248 was 65.2%\n",
      "Previous reaction rates:  tensor([ 582.6210,  769.2650,  768.7632, 1240.7866,  582.6210, 1240.8061],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 580.6173,  768.5256,  768.0142, 1241.7342,  580.6173, 1241.7550],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 768.5256,  768.0142, 1241.7342,  580.6173, 1241.7550],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(277354.8361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 249 was 65.2%\n",
      "Previous reaction rates:  tensor([ 580.6173,  768.5256,  768.0142, 1241.7342,  580.6173, 1241.7550],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 578.6117,  767.7894,  767.2682, 1242.6814,  578.6117, 1242.7036],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 767.7894,  767.2682, 1242.6814,  578.6117, 1242.7036],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(278125.5862, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 250 was 65.3%\n",
      "Previous reaction rates:  tensor([ 578.6117,  767.7894,  767.2682, 1242.6814,  578.6117, 1242.7036],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 576.6043,  767.0565,  766.5253, 1243.6284,  576.6043, 1243.6519],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 767.0565,  766.5253, 1243.6284,  576.6043, 1243.6519],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(278900.4785, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 251 was 65.3%\n",
      "Previous reaction rates:  tensor([ 576.6043,  767.0565,  766.5253, 1243.6284,  576.6043, 1243.6519],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 574.5950,  766.3269,  765.7856, 1244.5749,  574.5950, 1244.5999],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 766.3269,  765.7856, 1244.5749,  574.5950, 1244.5999],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(279679.5512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Type/class of yield:  <class 'torch.Tensor'>\n",
      "yield on sim iteration 252 was 65.4%\n",
      "Previous reaction rates:  tensor([ 574.5950,  766.3269,  765.7856, 1244.5749,  574.5950, 1244.5999],\n",
      "       dtype=torch.float64)\n",
      "New reaction rates: tensor([ 572.5839,  765.6008,  765.0491, 1245.5211,  572.5839, 1245.5476],\n",
      "       dtype=torch.float64)\n",
      "current params: tensor([ 765.6008,  765.0491, 1245.5211,  572.5839, 1245.5476],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<steric_free_simulator.vectorized_rxn_net.VectorizedRxnNet at 0x7efe54dd11d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=10000,\n",
    "                  learning_rate=1,\n",
    "                  device='cpu')\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6540759470671368\n"
     ]
    }
   ],
   "source": [
    "print(optim.yield_per_iter[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 0}\n",
      "tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'C'}, {'B', 'A'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 4}\n",
      "tensor(765.0491, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 2}\n",
      "tensor(765.6008, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C'}), 'kon': 999.9999999999998, 'score': tensor([-50000.], dtype=torch.float64), 'koff': 2.7423593919635816e-07, 'uid': 1}\n",
      "tensor(1245.5211, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C', 'A'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 3}\n",
      "tensor(1245.5476, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C', 'B'}), 'kon': 999.9999999999998, 'score': tensor([-100000.], dtype=torch.float64), 'koff': 7.520535034690868e-17, 'uid': 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'AB': 3, 'AC': 4, 'BC': 5, 'ABC': 6}\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  A + B  ->  AB\n",
      "Net flux:  tensor([2.7159e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([1.5702e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  A + C  ->  AC\n",
      "Net flux:  tensor([3.6314e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(765.6008, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([2.0996e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  A + BC  ->  ABC\n",
      "Net flux:  tensor([-6.3652e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1245.5476, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([9.3672e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  B + A  ->  AB\n",
      "Net flux:  tensor([2.7159e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([1.5702e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "Reaction:  B + C  ->  BC\n",
      "Net flux:  tensor([3.6288e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(765.0491, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([2.0980e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  B + AC  ->  ABC\n",
      "Net flux:  tensor([-6.3626e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1245.5211, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([9.3670e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  C + A  ->  AC\n",
      "Net flux:  tensor([3.6314e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(765.6008, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([2.0996e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "Reaction:  C + B  ->  BC\n",
      "Net flux:  tensor([3.6288e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(765.0491, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([2.0980e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "Reaction:  C + AB  ->  ABC\n",
      "Net flux:  tensor([-6.8782e-08], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([4.3061e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  AB + C  ->  ABC\n",
      "Net flux:  tensor([-6.8782e-08], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([4.3061e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  AB  ->  A + B\n",
      "Net flux:  tensor([-2.7159e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([1.5702e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 0}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  AC + B  ->  ABC\n",
      "Net flux:  tensor([-6.3626e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1245.5211, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([9.3670e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  AC  ->  A + C\n",
      "Net flux:  tensor([-3.6314e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(765.6008, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([2.0996e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 1}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  BC + A  ->  ABC\n",
      "Net flux:  tensor([-6.3652e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1245.5476, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([9.3672e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Reaction data OUTWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "Reaction:  BC  ->  B + C\n",
      "Net flux:  tensor([-3.6288e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(765.0491, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([2.0980e-07], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 2.7423593919635816e-07, 'lcf': 1, 'rxn_score': tensor([-50000.], dtype=torch.float64), 'uid': 2}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "|                                                                             |\n",
      "Reaction:  ABC  ->  B + AC\n",
      "Net flux:  tensor([6.3626e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1245.5211, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([9.3670e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 3}\n",
      "Reaction:  ABC  ->  C + AB\n",
      "Net flux:  tensor([6.8782e-08], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(572.5839, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([4.3061e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 4}\n",
      "Reaction:  ABC  ->  BC + A\n",
      "Net flux:  tensor([6.3652e-07], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "kon :  tensor(1245.5476, dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "koff:  tensor([9.3672e-17], dtype=torch.float64, grad_fn=<ExpBackward>)\n",
      "Raction data INWARD: \n",
      "{'k_on': 999.9999999999998, 'k_off': 7.520535034690868e-17, 'lcf': 1, 'rxn_score': tensor([-100000.], dtype=torch.float64), 'uid': 5}\n",
      "|                                                                             |\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "[['A', 'ABC'], ['B', 'ABC'], ['C', 'AC', 'ABC'], ['AB', 'ABC'], ['AC', 'ABC'], ['BC', 'ABC'], ['ABC']]\n",
      "[1245.547564520932, 1245.5211250612556, 2011.1218762732021, 572.5838688995566, 1245.5211250612556, 1245.547564520932, 0]\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB  :  572.5838688995566\n",
      "AC  :  1245.5211250612556\n",
      "BC  :  1245.547564520932\n",
      "C  :  2103.233693120377\n",
      "B  :  2583.1540669696865\n",
      "A  :  2583.732184632435\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC  :  tensor([-9.9940e-07], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "BC  :  tensor([-9.9940e-07], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AB  :  tensor([-3.4037e-07], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "B  :  tensor([-1.7849e-09], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "A  :  tensor([-1.7844e-09], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "C  :  tensor([6.5724e-07], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "ABC  :  tensor([1.3416e-06], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([2.9546e-10, 2.9535e-10, 6.9452e-11, 1.7296e+00, 1.7296e+00, 1.7296e+00,\n",
      "        6.5408e+00], dtype=torch.float64, grad_fn=<MaxBackward2>)\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  :  0\n",
      "B  :  1\n",
      "C  :  2\n",
      "AB  :  3\n",
      "AC  :  4\n",
      "BC  :  5\n",
      "ABC  :  6\n"
     ]
    }
   ],
   "source": [
    "for n in rn.network.nodes():\n",
    "    print(gtostr(rn.network.nodes[n]['struct']), \" : \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes_list = ['A','B','C','ABC','AB','BC','AC']\n",
    "#nodes_list = ['AB','BMS','ABS','AMS','ABMS','AM','BM','MS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f56842b70c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_yield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/multi_assembly/multi_assembly/steric_free_simulator/optimizer.py\u001b[0m in \u001b[0;36mplot_yield\u001b[0;34m(self, flux)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mflux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflux_per_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Yield'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mflux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflux\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Flux'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#plt.ylim((0, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([1, 5, 10]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i])\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
