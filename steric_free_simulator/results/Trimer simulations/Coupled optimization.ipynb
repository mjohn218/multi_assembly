{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156a0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7f80ef25c128>\n"
     ]
    }
   ],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy\n",
    "from steric_free_simulator import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1e64bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['B']\n",
      "['C']\n",
      "-----\n",
      "{'A'}\n",
      "{'A'}\n",
      "set()\n",
      "-----\n",
      "{'A'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'B']\n",
      "Connected Edges:  [('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'B']\n",
      "{('A', 'B'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3]\n",
      "-----\n",
      "{'A'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'C']\n",
      "Connected Edges:  [('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "New node added--1\n",
      "['A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A']\n",
      "Connected Edges:  [('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'B'}\n",
      "{'B'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'C']\n",
      "Connected Edges:  [('B', 'C')]\n",
      "New node added--1\n",
      "['B', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "-----\n",
      "{'B'}\n",
      "{'A', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['B', 'A', 'C']\n",
      "Connected Edges:  [('B', 'A'), ('B', 'C'), ('A', 'C')]\n",
      "New node added--1\n",
      "['B', 'A', 'C']\n",
      "{('A', 'B'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)]}\n",
      "New node added--2\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A']\n",
      "Connected Edges:  [('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'B']\n",
      "Connected Edges:  [('C', 'B')]\n",
      "-----\n",
      "{'C'}\n",
      "{'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['C', 'A', 'B']\n",
      "Connected Edges:  [('C', 'A'), ('C', 'B'), ('A', 'B')]\n",
      "{('A', 'B'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'C'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'C'}\n",
      "{'A', 'B', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A'}\n",
      "{'B'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'B', 'C']\n",
      "Connected Edges:  [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'B'}\n",
      "{'A', 'B', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A'}\n",
      "{'C'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "Connected Nodes:  ['A', 'C', 'B']\n",
      "Connected Edges:  [('A', 'C'), ('A', 'B'), ('C', 'B')]\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'C'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'C'}\n",
      "set()\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'C'}\n",
      "{'A', 'B', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "False\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A')]\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Connected Nodes:  ['B', 'C', 'A']\n",
      "Connected Edges:  [('B', 'C'), ('B', 'A'), ('C', 'A')]\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "{('A', 'B'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('A', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)], ('B', 'C'): [None, None, 1, tensor([-20000.], dtype=torch.float64)]}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'C', 'B'}\n",
      "set()\n",
      "-----\n",
      "{'C', 'B'}\n",
      "{'A', 'B', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'A'}\n",
      "{'C', 'B'}\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'B'}\n",
      "{'A', 'C'}\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'C'}\n",
      "{'A', 'B'}\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'A', 'B'}\n",
      "{'C'}\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'A', 'C'}\n",
      "{'B'}\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'C', 'B'}\n",
      "{'A'}\n",
      "-----\n",
      "{'A', 'B', 'C'}\n",
      "{'A', 'B', 'C'}\n",
      "set()\n",
      "Allowed edges: \n",
      "('A', 'B')\n",
      "Allowed edges: \n",
      "('A', 'C')\n",
      "Allowed edges: \n",
      "('B', 'C')\n"
     ]
    }
   ],
   "source": [
    "base_input = '../../input_files/trimer_coup.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89daec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 3): 0, (0, 4): 1, (0, 6): 5, (1, 3): 0, (1, 5): 2, (1, 6): 3, (2, 4): 1, (2, 5): 2, (2, 6): 4, (3, 6): 4, (4, 6): 3, (5, 6): 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ca3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "import torch\n",
    "\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "def get_max_edge(vec_rn,n,node_map):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "def get_node_flux(vec_rn,n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "#             print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "#             print(\"Net flux: \",edge_flux)\n",
    "#             print(\"kon : \",temp_kon)\n",
    "#             print(\"koff: \",koff)\n",
    "#             print(\"Reaction data OUTWARD: \")\n",
    "#             print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "#             print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "#             print(\"Net flux: \",edge_flux_in)\n",
    "#             print(\"kon : \",temp_kon)\n",
    "#             print(\"koff: \",koff)\n",
    "#             print(\"Raction data INWARD: \")\n",
    "#             print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "\n",
    "def do_flux_analysis(vec_rn,node_map):\n",
    "    pathway = []\n",
    "    kon_sumarray = []\n",
    "    total_con_rate = {}\n",
    "    net_flux = {}\n",
    "    for n in rn.network.nodes():\n",
    "\n",
    "        n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "\n",
    "        paths = [n_str]\n",
    "        kon_sum = 0\n",
    "        temp_node = n\n",
    "        max_edge = True\n",
    "        consumption_rate = 0\n",
    "        if n < len(rn.network.nodes()):#num_monomers:\n",
    "    #         print(\"Current node: \")\n",
    "    #         print(n_str)\n",
    "            while max_edge:\n",
    "                max_edge = get_max_edge(vec_rn,temp_node,node_map)\n",
    "                if max_edge:\n",
    "                    total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                    temp_node = max_edge[1]\n",
    "                    kon_sum += max_edge[0].item()\n",
    "\n",
    "\n",
    "    #                 print(\"Next node: \")\n",
    "    #                 print(temp_node)\n",
    "\n",
    "                    paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "                else:\n",
    "                    break\n",
    "            pathway.append(paths)\n",
    "            kon_sumarray.append(kon_sum)\n",
    "            paths=[]\n",
    "            \n",
    "        net_flux[gtostr(rn.network.nodes[n]['struct'])] = get_node_flux(vec_rn,n)\n",
    "\n",
    "    #print(pathway)\n",
    "    #print(kon_sumarray)\n",
    "    \n",
    "    return(total_con_rate,net_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeff386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "Running Optimization with the following on rates: \n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Using CPU\n",
      "Next time:  tensor(1.0606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 0 was 49.7%\n",
      "current params: tensor([1.0001, 1.0001, 1.0001, 1.0001], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1 was 49.7%\n",
      "current params: tensor([1.0000, 1.0002, 1.0002, 1.0002], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2 was 49.7%\n",
      "current params: tensor([0.9999, 1.0003, 1.0003, 1.0003], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 3 was 49.7%\n",
      "current params: tensor([0.9999, 1.0003, 1.0003, 1.0003], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0603, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 4 was 49.7%\n",
      "current params: tensor([0.9998, 1.0004, 1.0004, 1.0004], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 5 was 49.7%\n",
      "current params: tensor([0.9997, 1.0005, 1.0005, 1.0005], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 6 was 49.7%\n",
      "current params: tensor([0.9996, 1.0006, 1.0006, 1.0006], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 7 was 49.7%\n",
      "current params: tensor([0.9995, 1.0007, 1.0007, 1.0007], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 8 was 49.7%\n",
      "current params: tensor([0.9994, 1.0008, 1.0008, 1.0008], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 9 was 49.7%\n",
      "current params: tensor([0.9993, 1.0009, 1.0009, 1.0009], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0600, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 10 was 49.7%\n",
      "current params: tensor([0.9992, 1.0010, 1.0010, 1.0010], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 11 was 49.7%\n",
      "current params: tensor([0.9991, 1.0011, 1.0011, 1.0011], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 12 was 49.7%\n",
      "current params: tensor([0.9990, 1.0012, 1.0012, 1.0012], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 13 was 49.7%\n",
      "current params: tensor([0.9989, 1.0013, 1.0013, 1.0012], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 14 was 49.7%\n",
      "current params: tensor([0.9988, 1.0014, 1.0013, 1.0013], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 15 was 49.7%\n",
      "current params: tensor([0.9987, 1.0014, 1.0014, 1.0014], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 16 was 49.7%\n",
      "current params: tensor([0.9986, 1.0015, 1.0015, 1.0015], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 17 was 49.7%\n",
      "current params: tensor([0.9985, 1.0016, 1.0016, 1.0016], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0595, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 18 was 49.8%\n",
      "current params: tensor([0.9984, 1.0017, 1.0017, 1.0017], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 19 was 49.8%\n",
      "current params: tensor([0.9983, 1.0018, 1.0018, 1.0018], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0594, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 20 was 49.8%\n",
      "current params: tensor([0.9982, 1.0019, 1.0019, 1.0019], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 21 was 49.8%\n",
      "current params: tensor([0.9981, 1.0020, 1.0020, 1.0020], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 22 was 49.8%\n",
      "current params: tensor([0.9980, 1.0021, 1.0021, 1.0021], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 23 was 49.8%\n",
      "current params: tensor([0.9979, 1.0022, 1.0022, 1.0022], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 24 was 49.8%\n",
      "current params: tensor([0.9978, 1.0023, 1.0023, 1.0023], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 25 was 49.8%\n",
      "current params: tensor([0.9977, 1.0024, 1.0024, 1.0024], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 26 was 49.8%\n",
      "current params: tensor([0.9976, 1.0025, 1.0025, 1.0025], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 27 was 49.8%\n",
      "current params: tensor([0.9975, 1.0026, 1.0026, 1.0026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 28 was 49.8%\n",
      "current params: tensor([0.9974, 1.0026, 1.0027, 1.0026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 29 was 49.8%\n",
      "current params: tensor([0.9973, 1.0027, 1.0027, 1.0027], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 30 was 49.8%\n",
      "current params: tensor([0.9972, 1.0028, 1.0028, 1.0028], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 31 was 49.8%\n",
      "current params: tensor([0.9971, 1.0029, 1.0029, 1.0029], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 32 was 49.8%\n",
      "current params: tensor([0.9970, 1.0030, 1.0030, 1.0030], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 33 was 49.8%\n",
      "current params: tensor([0.9969, 1.0031, 1.0031, 1.0031], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 34 was 49.8%\n",
      "current params: tensor([0.9968, 1.0032, 1.0032, 1.0032], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0585, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 35 was 49.8%\n",
      "current params: tensor([0.9966, 1.0033, 1.0033, 1.0033], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 36 was 49.8%\n",
      "current params: tensor([0.9965, 1.0034, 1.0034, 1.0034], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 37 was 49.8%\n",
      "current params: tensor([0.9964, 1.0035, 1.0035, 1.0035], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 38 was 49.8%\n",
      "current params: tensor([0.9963, 1.0036, 1.0036, 1.0036], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0583, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 39 was 49.8%\n",
      "current params: tensor([0.9962, 1.0037, 1.0037, 1.0037], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0582, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 40 was 49.8%\n",
      "current params: tensor([0.9961, 1.0038, 1.0038, 1.0038], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 41 was 49.8%\n",
      "current params: tensor([0.9960, 1.0039, 1.0039, 1.0039], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 42 was 49.8%\n",
      "current params: tensor([0.9959, 1.0039, 1.0040, 1.0040], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 43 was 49.8%\n",
      "current params: tensor([0.9958, 1.0040, 1.0040, 1.0040], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 44 was 49.8%\n",
      "current params: tensor([0.9957, 1.0041, 1.0041, 1.0041], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 45 was 49.9%\n",
      "current params: tensor([0.9956, 1.0042, 1.0042, 1.0042], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 46 was 49.9%\n",
      "current params: tensor([0.9955, 1.0043, 1.0043, 1.0043], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 47 was 49.9%\n",
      "current params: tensor([0.9954, 1.0044, 1.0044, 1.0044], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 48 was 49.9%\n",
      "current params: tensor([0.9953, 1.0045, 1.0045, 1.0045], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 49 was 49.9%\n",
      "current params: tensor([0.9952, 1.0046, 1.0046, 1.0046], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 50 was 49.9%\n",
      "current params: tensor([0.9951, 1.0047, 1.0047, 1.0047], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0576, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 51 was 49.9%\n",
      "current params: tensor([0.9950, 1.0048, 1.0048, 1.0048], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 52 was 49.9%\n",
      "current params: tensor([0.9949, 1.0049, 1.0049, 1.0049], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 53 was 49.9%\n",
      "current params: tensor([0.9948, 1.0050, 1.0050, 1.0050], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 54 was 49.9%\n",
      "current params: tensor([0.9947, 1.0051, 1.0051, 1.0051], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 55 was 49.9%\n",
      "current params: tensor([0.9946, 1.0052, 1.0052, 1.0052], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 56 was 49.9%\n",
      "current params: tensor([0.9945, 1.0052, 1.0053, 1.0053], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 57 was 49.9%\n",
      "current params: tensor([0.9944, 1.0053, 1.0053, 1.0054], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0572, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 58 was 49.9%\n",
      "current params: tensor([0.9943, 1.0054, 1.0054, 1.0054], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0571, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 59 was 49.9%\n",
      "current params: tensor([0.9942, 1.0055, 1.0055, 1.0055], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 60 was 49.9%\n",
      "current params: tensor([0.9941, 1.0056, 1.0056, 1.0056], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 61 was 49.9%\n",
      "current params: tensor([0.9940, 1.0057, 1.0057, 1.0057], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0570, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 62 was 49.9%\n",
      "current params: tensor([0.9939, 1.0058, 1.0058, 1.0058], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 63 was 49.9%\n",
      "current params: tensor([0.9938, 1.0059, 1.0059, 1.0059], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 64 was 49.9%\n",
      "current params: tensor([0.9937, 1.0060, 1.0060, 1.0060], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 65 was 49.9%\n",
      "current params: tensor([0.9936, 1.0061, 1.0061, 1.0061], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 66 was 49.9%\n",
      "current params: tensor([0.9935, 1.0062, 1.0062, 1.0062], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 67 was 49.9%\n",
      "current params: tensor([0.9934, 1.0063, 1.0063, 1.0063], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0566, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 68 was 49.9%\n",
      "current params: tensor([0.9933, 1.0064, 1.0064, 1.0064], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 69 was 49.9%\n",
      "current params: tensor([0.9932, 1.0065, 1.0065, 1.0064], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 70 was 49.9%\n",
      "current params: tensor([0.9931, 1.0066, 1.0065, 1.0065], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 71 was 49.9%\n",
      "current params: tensor([0.9930, 1.0067, 1.0066, 1.0066], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 72 was 50.0%\n",
      "current params: tensor([0.9929, 1.0067, 1.0067, 1.0067], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 73 was 50.0%\n",
      "current params: tensor([0.9928, 1.0068, 1.0068, 1.0068], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 74 was 50.0%\n",
      "current params: tensor([0.9927, 1.0069, 1.0069, 1.0069], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 75 was 50.0%\n",
      "current params: tensor([0.9926, 1.0070, 1.0070, 1.0070], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 76 was 50.0%\n",
      "current params: tensor([0.9925, 1.0071, 1.0071, 1.0071], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0561, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 77 was 50.0%\n",
      "current params: tensor([0.9924, 1.0072, 1.0072, 1.0072], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 78 was 50.0%\n",
      "current params: tensor([0.9923, 1.0073, 1.0073, 1.0073], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0560, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 79 was 50.0%\n",
      "current params: tensor([0.9922, 1.0074, 1.0074, 1.0074], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 80 was 50.0%\n",
      "current params: tensor([0.9921, 1.0075, 1.0075, 1.0075], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 81 was 50.0%\n",
      "current params: tensor([0.9920, 1.0076, 1.0076, 1.0076], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 82 was 50.0%\n",
      "current params: tensor([0.9919, 1.0077, 1.0077, 1.0077], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 83 was 50.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9918, 1.0077, 1.0077, 1.0078], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0557, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 84 was 50.0%\n",
      "current params: tensor([0.9917, 1.0078, 1.0078, 1.0079], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 85 was 50.0%\n",
      "current params: tensor([0.9916, 1.0079, 1.0079, 1.0079], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 86 was 50.0%\n",
      "current params: tensor([0.9915, 1.0080, 1.0080, 1.0080], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0555, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 87 was 50.0%\n",
      "current params: tensor([0.9914, 1.0081, 1.0081, 1.0081], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0555, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 88 was 50.0%\n",
      "current params: tensor([0.9913, 1.0082, 1.0082, 1.0082], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 89 was 50.0%\n",
      "current params: tensor([0.9912, 1.0083, 1.0083, 1.0083], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 90 was 50.0%\n",
      "current params: tensor([0.9911, 1.0084, 1.0084, 1.0084], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 91 was 50.0%\n",
      "current params: tensor([0.9910, 1.0085, 1.0085, 1.0085], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 92 was 50.0%\n",
      "current params: tensor([0.9909, 1.0086, 1.0086, 1.0086], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 93 was 50.0%\n",
      "current params: tensor([0.9908, 1.0087, 1.0087, 1.0087], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 94 was 50.0%\n",
      "current params: tensor([0.9907, 1.0088, 1.0088, 1.0088], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 95 was 50.0%\n",
      "current params: tensor([0.9906, 1.0089, 1.0089, 1.0089], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 96 was 50.0%\n",
      "current params: tensor([0.9905, 1.0089, 1.0089, 1.0090], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 97 was 50.0%\n",
      "current params: tensor([0.9904, 1.0090, 1.0090, 1.0090], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 98 was 50.0%\n",
      "current params: tensor([0.9903, 1.0091, 1.0091, 1.0091], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0549, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 99 was 50.1%\n",
      "current params: tensor([0.9902, 1.0092, 1.0092, 1.0092], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 100 was 50.1%\n",
      "current params: tensor([0.9901, 1.0093, 1.0093, 1.0093], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 101 was 50.1%\n",
      "current params: tensor([0.9900, 1.0094, 1.0094, 1.0094], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 102 was 50.1%\n",
      "current params: tensor([0.9899, 1.0095, 1.0095, 1.0095], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 103 was 50.1%\n",
      "current params: tensor([0.9898, 1.0096, 1.0096, 1.0096], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0546, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 104 was 50.1%\n",
      "current params: tensor([0.9897, 1.0097, 1.0097, 1.0097], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 105 was 50.1%\n",
      "current params: tensor([0.9896, 1.0098, 1.0098, 1.0098], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 106 was 50.1%\n",
      "current params: tensor([0.9895, 1.0099, 1.0099, 1.0099], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 107 was 50.1%\n",
      "current params: tensor([0.9894, 1.0100, 1.0100, 1.0100], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 108 was 50.1%\n",
      "current params: tensor([0.9893, 1.0100, 1.0101, 1.0101], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 109 was 50.1%\n",
      "current params: tensor([0.9892, 1.0101, 1.0102, 1.0102], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 110 was 50.1%\n",
      "current params: tensor([0.9891, 1.0102, 1.0103, 1.0102], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0542, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 111 was 50.1%\n",
      "current params: tensor([0.9890, 1.0103, 1.0103, 1.0103], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 112 was 50.1%\n",
      "current params: tensor([0.9889, 1.0104, 1.0104, 1.0104], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 113 was 50.1%\n",
      "current params: tensor([0.9888, 1.0105, 1.0105, 1.0105], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 114 was 50.1%\n",
      "current params: tensor([0.9887, 1.0106, 1.0106, 1.0106], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 115 was 50.1%\n",
      "current params: tensor([0.9886, 1.0107, 1.0107, 1.0107], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 116 was 50.1%\n",
      "current params: tensor([0.9885, 1.0108, 1.0108, 1.0108], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 117 was 50.1%\n",
      "current params: tensor([0.9884, 1.0109, 1.0109, 1.0109], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 118 was 50.1%\n",
      "current params: tensor([0.9883, 1.0110, 1.0110, 1.0110], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 119 was 50.1%\n",
      "current params: tensor([0.9882, 1.0111, 1.0111, 1.0111], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0537, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 120 was 50.1%\n",
      "current params: tensor([0.9881, 1.0112, 1.0112, 1.0112], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 121 was 50.1%\n",
      "current params: tensor([0.9880, 1.0113, 1.0112, 1.0113], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 122 was 50.1%\n",
      "current params: tensor([0.9879, 1.0113, 1.0113, 1.0113], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 123 was 50.1%\n",
      "current params: tensor([0.9878, 1.0114, 1.0114, 1.0114], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0535, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 124 was 50.1%\n",
      "current params: tensor([0.9877, 1.0115, 1.0115, 1.0115], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 125 was 50.1%\n",
      "current params: tensor([0.9876, 1.0116, 1.0116, 1.0116], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 126 was 50.2%\n",
      "current params: tensor([0.9875, 1.0117, 1.0117, 1.0117], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 127 was 50.2%\n",
      "current params: tensor([0.9874, 1.0118, 1.0118, 1.0118], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0533, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 128 was 50.2%\n",
      "current params: tensor([0.9873, 1.0119, 1.0119, 1.0119], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 129 was 50.2%\n",
      "current params: tensor([0.9872, 1.0120, 1.0120, 1.0120], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 130 was 50.2%\n",
      "current params: tensor([0.9871, 1.0121, 1.0121, 1.0121], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 131 was 50.2%\n",
      "current params: tensor([0.9870, 1.0122, 1.0122, 1.0122], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 132 was 50.2%\n",
      "current params: tensor([0.9869, 1.0123, 1.0123, 1.0123], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 133 was 50.2%\n",
      "current params: tensor([0.9868, 1.0124, 1.0124, 1.0124], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 134 was 50.2%\n",
      "current params: tensor([0.9867, 1.0124, 1.0124, 1.0124], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 135 was 50.2%\n",
      "current params: tensor([0.9866, 1.0125, 1.0125, 1.0125], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 136 was 50.2%\n",
      "current params: tensor([0.9865, 1.0126, 1.0126, 1.0126], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0528, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 137 was 50.2%\n",
      "current params: tensor([0.9864, 1.0127, 1.0127, 1.0127], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 138 was 50.2%\n",
      "current params: tensor([0.9863, 1.0128, 1.0128, 1.0128], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 139 was 50.2%\n",
      "current params: tensor([0.9862, 1.0129, 1.0129, 1.0129], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 140 was 50.2%\n",
      "current params: tensor([0.9861, 1.0130, 1.0130, 1.0130], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 141 was 50.2%\n",
      "current params: tensor([0.9860, 1.0131, 1.0131, 1.0131], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 142 was 50.2%\n",
      "current params: tensor([0.9859, 1.0132, 1.0132, 1.0132], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 143 was 50.2%\n",
      "current params: tensor([0.9858, 1.0133, 1.0133, 1.0133], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 144 was 50.2%\n",
      "current params: tensor([0.9857, 1.0134, 1.0134, 1.0134], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 145 was 50.2%\n",
      "current params: tensor([0.9856, 1.0135, 1.0135, 1.0135], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 146 was 50.2%\n",
      "current params: tensor([0.9855, 1.0135, 1.0135, 1.0136], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 147 was 50.2%\n",
      "current params: tensor([0.9854, 1.0136, 1.0136, 1.0136], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0522, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 148 was 50.2%\n",
      "current params: tensor([0.9853, 1.0137, 1.0137, 1.0137], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 149 was 50.2%\n",
      "current params: tensor([0.9852, 1.0138, 1.0138, 1.0138], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 150 was 50.2%\n",
      "current params: tensor([0.9851, 1.0139, 1.0139, 1.0139], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0520, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 151 was 50.2%\n",
      "current params: tensor([0.9850, 1.0140, 1.0140, 1.0140], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0520, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 152 was 50.2%\n",
      "current params: tensor([0.9849, 1.0141, 1.0141, 1.0141], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 153 was 50.3%\n",
      "current params: tensor([0.9848, 1.0142, 1.0142, 1.0142], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0518, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 154 was 50.3%\n",
      "current params: tensor([0.9846, 1.0143, 1.0143, 1.0143], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0518, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 155 was 50.3%\n",
      "current params: tensor([0.9845, 1.0144, 1.0144, 1.0144], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 156 was 50.3%\n",
      "current params: tensor([0.9844, 1.0145, 1.0145, 1.0145], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 157 was 50.3%\n",
      "current params: tensor([0.9843, 1.0146, 1.0146, 1.0145], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 158 was 50.3%\n",
      "current params: tensor([0.9842, 1.0147, 1.0146, 1.0146], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 159 was 50.3%\n",
      "current params: tensor([0.9841, 1.0148, 1.0147, 1.0147], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 160 was 50.3%\n",
      "current params: tensor([0.9840, 1.0148, 1.0148, 1.0148], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 161 was 50.3%\n",
      "current params: tensor([0.9839, 1.0149, 1.0149, 1.0149], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 162 was 50.3%\n",
      "current params: tensor([0.9838, 1.0150, 1.0150, 1.0150], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 163 was 50.3%\n",
      "current params: tensor([0.9837, 1.0151, 1.0151, 1.0151], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 164 was 50.3%\n",
      "current params: tensor([0.9836, 1.0152, 1.0152, 1.0152], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 165 was 50.3%\n",
      "current params: tensor([0.9835, 1.0153, 1.0153, 1.0153], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 166 was 50.3%\n",
      "current params: tensor([0.9834, 1.0154, 1.0154, 1.0154], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 167 was 50.3%\n",
      "current params: tensor([0.9833, 1.0155, 1.0155, 1.0155], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 168 was 50.3%\n",
      "current params: tensor([0.9832, 1.0156, 1.0156, 1.0156], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 169 was 50.3%\n",
      "current params: tensor([0.9831, 1.0157, 1.0157, 1.0157], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0510, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 170 was 50.3%\n",
      "current params: tensor([0.9830, 1.0157, 1.0157, 1.0157], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 171 was 50.3%\n",
      "current params: tensor([0.9829, 1.0158, 1.0158, 1.0158], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 172 was 50.3%\n",
      "current params: tensor([0.9828, 1.0159, 1.0159, 1.0159], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 173 was 50.3%\n",
      "current params: tensor([0.9827, 1.0160, 1.0160, 1.0160], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0508, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 174 was 50.3%\n",
      "current params: tensor([0.9826, 1.0161, 1.0161, 1.0161], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 175 was 50.3%\n",
      "current params: tensor([0.9825, 1.0162, 1.0162, 1.0162], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 176 was 50.3%\n",
      "current params: tensor([0.9824, 1.0163, 1.0163, 1.0163], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 177 was 50.3%\n",
      "current params: tensor([0.9823, 1.0164, 1.0164, 1.0164], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 178 was 50.3%\n",
      "current params: tensor([0.9822, 1.0165, 1.0165, 1.0165], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 179 was 50.3%\n",
      "current params: tensor([0.9821, 1.0166, 1.0166, 1.0166], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 180 was 50.4%\n",
      "current params: tensor([0.9820, 1.0167, 1.0167, 1.0167], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 181 was 50.4%\n",
      "current params: tensor([0.9819, 1.0168, 1.0168, 1.0167], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 182 was 50.4%\n",
      "current params: tensor([0.9818, 1.0168, 1.0168, 1.0168], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 183 was 50.4%\n",
      "current params: tensor([0.9817, 1.0169, 1.0169, 1.0169], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 184 was 50.4%\n",
      "current params: tensor([0.9816, 1.0170, 1.0170, 1.0170], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0502, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 185 was 50.4%\n",
      "current params: tensor([0.9815, 1.0171, 1.0171, 1.0171], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0501, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 186 was 50.4%\n",
      "current params: tensor([0.9814, 1.0172, 1.0172, 1.0172], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 187 was 50.4%\n",
      "current params: tensor([0.9813, 1.0173, 1.0173, 1.0173], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 188 was 50.4%\n",
      "current params: tensor([0.9812, 1.0174, 1.0174, 1.0174], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 189 was 50.4%\n",
      "current params: tensor([0.9811, 1.0175, 1.0175, 1.0175], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 190 was 50.4%\n",
      "current params: tensor([0.9810, 1.0176, 1.0176, 1.0176], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 191 was 50.4%\n",
      "current params: tensor([0.9809, 1.0177, 1.0177, 1.0176], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 192 was 50.4%\n",
      "current params: tensor([0.9808, 1.0178, 1.0178, 1.0177], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 193 was 50.4%\n",
      "current params: tensor([0.9807, 1.0179, 1.0179, 1.0178], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 194 was 50.4%\n",
      "current params: tensor([0.9806, 1.0179, 1.0180, 1.0179], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 195 was 50.4%\n",
      "current params: tensor([0.9805, 1.0180, 1.0180, 1.0180], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 196 was 50.4%\n",
      "current params: tensor([0.9804, 1.0181, 1.0181, 1.0181], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 197 was 50.4%\n",
      "current params: tensor([0.9803, 1.0182, 1.0182, 1.0182], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0495, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 198 was 50.4%\n",
      "current params: tensor([0.9802, 1.0183, 1.0183, 1.0183], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 199 was 50.4%\n",
      "current params: tensor([0.9801, 1.0184, 1.0184, 1.0184], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 200 was 50.4%\n",
      "current params: tensor([0.9800, 1.0185, 1.0185, 1.0185], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 201 was 50.4%\n",
      "current params: tensor([0.9799, 1.0186, 1.0186, 1.0186], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 202 was 50.4%\n",
      "current params: tensor([0.9798, 1.0187, 1.0187, 1.0187], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0492, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 203 was 50.4%\n",
      "current params: tensor([0.9797, 1.0188, 1.0188, 1.0188], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0492, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 204 was 50.4%\n",
      "current params: tensor([0.9796, 1.0189, 1.0189, 1.0189], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 205 was 50.4%\n",
      "current params: tensor([0.9795, 1.0189, 1.0189, 1.0189], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 206 was 50.4%\n",
      "current params: tensor([0.9794, 1.0190, 1.0190, 1.0190], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 207 was 50.4%\n",
      "current params: tensor([0.9793, 1.0191, 1.0191, 1.0191], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 208 was 50.5%\n",
      "current params: tensor([0.9792, 1.0192, 1.0192, 1.0192], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 209 was 50.5%\n",
      "current params: tensor([0.9791, 1.0193, 1.0193, 1.0193], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 210 was 50.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9790, 1.0194, 1.0194, 1.0194], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 211 was 50.5%\n",
      "current params: tensor([0.9789, 1.0195, 1.0195, 1.0195], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 212 was 50.5%\n",
      "current params: tensor([0.9788, 1.0196, 1.0196, 1.0196], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0487, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 213 was 50.5%\n",
      "current params: tensor([0.9787, 1.0197, 1.0197, 1.0197], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 214 was 50.5%\n",
      "current params: tensor([0.9786, 1.0198, 1.0198, 1.0197], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 215 was 50.5%\n",
      "current params: tensor([0.9785, 1.0199, 1.0199, 1.0198], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 216 was 50.5%\n",
      "current params: tensor([0.9784, 1.0200, 1.0200, 1.0199], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0485, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 217 was 50.5%\n",
      "current params: tensor([0.9783, 1.0201, 1.0200, 1.0200], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 218 was 50.5%\n",
      "current params: tensor([0.9782, 1.0201, 1.0201, 1.0201], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 219 was 50.5%\n",
      "current params: tensor([0.9781, 1.0202, 1.0202, 1.0202], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 220 was 50.5%\n",
      "current params: tensor([0.9780, 1.0203, 1.0203, 1.0203], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 221 was 50.5%\n",
      "current params: tensor([0.9779, 1.0204, 1.0204, 1.0204], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 222 was 50.5%\n",
      "current params: tensor([0.9778, 1.0205, 1.0205, 1.0205], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 223 was 50.5%\n",
      "current params: tensor([0.9777, 1.0206, 1.0206, 1.0206], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 224 was 50.5%\n",
      "current params: tensor([0.9776, 1.0207, 1.0207, 1.0207], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 225 was 50.5%\n",
      "current params: tensor([0.9775, 1.0208, 1.0208, 1.0208], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 226 was 50.5%\n",
      "current params: tensor([0.9774, 1.0209, 1.0209, 1.0209], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 227 was 50.5%\n",
      "current params: tensor([0.9773, 1.0210, 1.0209, 1.0210], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 228 was 50.5%\n",
      "current params: tensor([0.9772, 1.0210, 1.0210, 1.0211], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 229 was 50.5%\n",
      "current params: tensor([0.9771, 1.0211, 1.0211, 1.0211], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 230 was 50.5%\n",
      "current params: tensor([0.9770, 1.0212, 1.0212, 1.0212], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 231 was 50.5%\n",
      "current params: tensor([0.9769, 1.0213, 1.0213, 1.0213], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0477, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 232 was 50.5%\n",
      "current params: tensor([0.9768, 1.0214, 1.0214, 1.0214], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 233 was 50.5%\n",
      "current params: tensor([0.9767, 1.0215, 1.0215, 1.0215], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 234 was 50.5%\n",
      "current params: tensor([0.9766, 1.0216, 1.0216, 1.0216], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 235 was 50.6%\n",
      "current params: tensor([0.9765, 1.0217, 1.0217, 1.0217], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 236 was 50.6%\n",
      "current params: tensor([0.9764, 1.0218, 1.0218, 1.0218], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 237 was 50.6%\n",
      "current params: tensor([0.9763, 1.0219, 1.0219, 1.0219], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 238 was 50.6%\n",
      "current params: tensor([0.9762, 1.0220, 1.0220, 1.0220], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 239 was 50.6%\n",
      "current params: tensor([0.9761, 1.0220, 1.0220, 1.0221], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 240 was 50.6%\n",
      "current params: tensor([0.9760, 1.0221, 1.0221, 1.0222], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 241 was 50.6%\n",
      "current params: tensor([0.9759, 1.0222, 1.0222, 1.0222], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 242 was 50.6%\n",
      "current params: tensor([0.9758, 1.0223, 1.0223, 1.0223], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 243 was 50.6%\n",
      "current params: tensor([0.9757, 1.0224, 1.0224, 1.0224], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 244 was 50.6%\n",
      "current params: tensor([0.9756, 1.0225, 1.0225, 1.0225], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 245 was 50.6%\n",
      "current params: tensor([0.9755, 1.0226, 1.0226, 1.0226], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 246 was 50.6%\n",
      "current params: tensor([0.9754, 1.0227, 1.0227, 1.0227], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 247 was 50.6%\n",
      "current params: tensor([0.9753, 1.0228, 1.0228, 1.0228], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 248 was 50.6%\n",
      "current params: tensor([0.9752, 1.0229, 1.0229, 1.0228], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 249 was 50.6%\n",
      "current params: tensor([0.9751, 1.0230, 1.0230, 1.0229], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 250 was 50.6%\n",
      "current params: tensor([0.9750, 1.0231, 1.0231, 1.0230], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 251 was 50.6%\n",
      "current params: tensor([0.9749, 1.0231, 1.0231, 1.0231], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0467, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 252 was 50.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9748, 1.0232, 1.0232, 1.0232], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 253 was 50.6%\n",
      "current params: tensor([0.9747, 1.0233, 1.0233, 1.0233], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 254 was 50.6%\n",
      "current params: tensor([0.9746, 1.0234, 1.0234, 1.0234], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 255 was 50.6%\n",
      "current params: tensor([0.9745, 1.0235, 1.0235, 1.0235], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 256 was 50.6%\n",
      "current params: tensor([0.9743, 1.0236, 1.0236, 1.0236], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 257 was 50.6%\n",
      "current params: tensor([0.9742, 1.0237, 1.0237, 1.0237], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 258 was 50.6%\n",
      "current params: tensor([0.9741, 1.0238, 1.0238, 1.0238], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 259 was 50.6%\n",
      "current params: tensor([0.9740, 1.0239, 1.0239, 1.0239], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 260 was 50.6%\n",
      "current params: tensor([0.9739, 1.0240, 1.0240, 1.0239], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0462, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 261 was 50.6%\n",
      "current params: tensor([0.9738, 1.0241, 1.0240, 1.0240], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 262 was 50.7%\n",
      "current params: tensor([0.9737, 1.0241, 1.0241, 1.0241], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 263 was 50.7%\n",
      "current params: tensor([0.9736, 1.0242, 1.0242, 1.0242], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 264 was 50.7%\n",
      "current params: tensor([0.9735, 1.0243, 1.0243, 1.0243], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 265 was 50.7%\n",
      "current params: tensor([0.9734, 1.0244, 1.0244, 1.0244], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 266 was 50.7%\n",
      "current params: tensor([0.9733, 1.0245, 1.0245, 1.0245], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 267 was 50.7%\n",
      "current params: tensor([0.9732, 1.0246, 1.0246, 1.0246], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 268 was 50.7%\n",
      "current params: tensor([0.9731, 1.0247, 1.0247, 1.0247], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 269 was 50.7%\n",
      "current params: tensor([0.9730, 1.0248, 1.0248, 1.0248], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 270 was 50.7%\n",
      "current params: tensor([0.9729, 1.0249, 1.0249, 1.0249], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 271 was 50.7%\n",
      "current params: tensor([0.9728, 1.0250, 1.0250, 1.0250], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0457, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 272 was 50.7%\n",
      "current params: tensor([0.9727, 1.0250, 1.0250, 1.0251], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 273 was 50.7%\n",
      "current params: tensor([0.9726, 1.0251, 1.0251, 1.0251], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 274 was 50.7%\n",
      "current params: tensor([0.9725, 1.0252, 1.0252, 1.0252], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 275 was 50.7%\n",
      "current params: tensor([0.9724, 1.0253, 1.0253, 1.0253], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 276 was 50.7%\n",
      "current params: tensor([0.9723, 1.0254, 1.0254, 1.0254], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 277 was 50.7%\n",
      "current params: tensor([0.9722, 1.0255, 1.0255, 1.0255], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 278 was 50.7%\n",
      "current params: tensor([0.9721, 1.0256, 1.0256, 1.0256], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 279 was 50.7%\n",
      "current params: tensor([0.9720, 1.0257, 1.0257, 1.0257], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 280 was 50.7%\n",
      "current params: tensor([0.9719, 1.0258, 1.0258, 1.0258], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 281 was 50.7%\n",
      "current params: tensor([0.9718, 1.0259, 1.0259, 1.0259], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 282 was 50.7%\n",
      "current params: tensor([0.9717, 1.0260, 1.0260, 1.0260], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0451, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 283 was 50.7%\n",
      "current params: tensor([0.9716, 1.0260, 1.0261, 1.0260], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 284 was 50.7%\n",
      "current params: tensor([0.9715, 1.0261, 1.0261, 1.0261], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 285 was 50.7%\n",
      "current params: tensor([0.9714, 1.0262, 1.0262, 1.0262], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 286 was 50.7%\n",
      "current params: tensor([0.9713, 1.0263, 1.0263, 1.0263], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 287 was 50.7%\n",
      "current params: tensor([0.9712, 1.0264, 1.0264, 1.0264], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0449, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 288 was 50.7%\n",
      "current params: tensor([0.9711, 1.0265, 1.0265, 1.0265], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 289 was 50.8%\n",
      "current params: tensor([0.9710, 1.0266, 1.0266, 1.0266], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 290 was 50.8%\n",
      "current params: tensor([0.9709, 1.0267, 1.0267, 1.0267], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 291 was 50.8%\n",
      "current params: tensor([0.9708, 1.0268, 1.0268, 1.0268], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 292 was 50.8%\n",
      "current params: tensor([0.9707, 1.0269, 1.0269, 1.0269], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 293 was 50.8%\n",
      "current params: tensor([0.9706, 1.0270, 1.0270, 1.0270], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 294 was 50.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9705, 1.0270, 1.0271, 1.0270], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 295 was 50.8%\n",
      "current params: tensor([0.9704, 1.0271, 1.0271, 1.0271], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 296 was 50.8%\n",
      "current params: tensor([0.9703, 1.0272, 1.0272, 1.0272], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 297 was 50.8%\n",
      "current params: tensor([0.9702, 1.0273, 1.0273, 1.0273], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 298 was 50.8%\n",
      "current params: tensor([0.9701, 1.0274, 1.0274, 1.0274], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 299 was 50.8%\n",
      "current params: tensor([0.9700, 1.0275, 1.0275, 1.0275], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 300 was 50.8%\n",
      "current params: tensor([0.9699, 1.0276, 1.0276, 1.0276], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 301 was 50.8%\n",
      "current params: tensor([0.9698, 1.0277, 1.0277, 1.0277], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 302 was 50.8%\n",
      "current params: tensor([0.9697, 1.0278, 1.0278, 1.0278], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0441, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 303 was 50.8%\n",
      "current params: tensor([0.9696, 1.0279, 1.0279, 1.0279], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 304 was 50.8%\n",
      "current params: tensor([0.9695, 1.0279, 1.0280, 1.0280], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 305 was 50.8%\n",
      "current params: tensor([0.9694, 1.0280, 1.0281, 1.0280], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 306 was 50.8%\n",
      "current params: tensor([0.9693, 1.0281, 1.0281, 1.0281], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0439, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 307 was 50.8%\n",
      "current params: tensor([0.9692, 1.0282, 1.0282, 1.0282], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0438, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 308 was 50.8%\n",
      "current params: tensor([0.9691, 1.0283, 1.0283, 1.0283], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0438, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 309 was 50.8%\n",
      "current params: tensor([0.9690, 1.0284, 1.0284, 1.0284], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0437, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 310 was 50.8%\n",
      "current params: tensor([0.9689, 1.0285, 1.0285, 1.0285], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0437, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 311 was 50.8%\n",
      "current params: tensor([0.9688, 1.0286, 1.0286, 1.0286], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 312 was 50.8%\n",
      "current params: tensor([0.9687, 1.0287, 1.0287, 1.0287], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 313 was 50.8%\n",
      "current params: tensor([0.9686, 1.0288, 1.0288, 1.0288], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 314 was 50.8%\n",
      "current params: tensor([0.9685, 1.0289, 1.0288, 1.0289], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 315 was 50.8%\n",
      "current params: tensor([0.9684, 1.0289, 1.0289, 1.0290], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 316 was 50.9%\n",
      "current params: tensor([0.9683, 1.0290, 1.0290, 1.0290], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 317 was 50.9%\n",
      "current params: tensor([0.9682, 1.0291, 1.0291, 1.0291], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 318 was 50.9%\n",
      "current params: tensor([0.9681, 1.0292, 1.0292, 1.0292], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 319 was 50.9%\n",
      "current params: tensor([0.9680, 1.0293, 1.0293, 1.0293], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 320 was 50.9%\n",
      "current params: tensor([0.9679, 1.0294, 1.0294, 1.0294], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 321 was 50.9%\n",
      "current params: tensor([0.9678, 1.0295, 1.0295, 1.0295], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 322 was 50.9%\n",
      "current params: tensor([0.9677, 1.0296, 1.0296, 1.0296], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0431, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 323 was 50.9%\n",
      "current params: tensor([0.9676, 1.0297, 1.0297, 1.0297], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 324 was 50.9%\n",
      "current params: tensor([0.9675, 1.0298, 1.0297, 1.0298], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 325 was 50.9%\n",
      "current params: tensor([0.9674, 1.0299, 1.0298, 1.0299], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 326 was 50.9%\n",
      "current params: tensor([0.9673, 1.0300, 1.0299, 1.0299], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 327 was 50.9%\n",
      "current params: tensor([0.9672, 1.0300, 1.0300, 1.0300], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 328 was 50.9%\n",
      "current params: tensor([0.9671, 1.0301, 1.0301, 1.0301], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 329 was 50.9%\n",
      "current params: tensor([0.9670, 1.0302, 1.0302, 1.0302], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 330 was 50.9%\n",
      "current params: tensor([0.9669, 1.0303, 1.0303, 1.0303], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 331 was 50.9%\n",
      "current params: tensor([0.9668, 1.0304, 1.0304, 1.0304], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 332 was 50.9%\n",
      "current params: tensor([0.9667, 1.0305, 1.0305, 1.0305], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 333 was 50.9%\n",
      "current params: tensor([0.9666, 1.0306, 1.0306, 1.0306], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 334 was 50.9%\n",
      "current params: tensor([0.9665, 1.0307, 1.0307, 1.0307], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 335 was 50.9%\n",
      "current params: tensor([0.9663, 1.0308, 1.0308, 1.0308], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0425, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 336 was 50.9%\n",
      "current params: tensor([0.9662, 1.0308, 1.0308, 1.0309], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 337 was 50.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9661, 1.0309, 1.0309, 1.0309], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 338 was 50.9%\n",
      "current params: tensor([0.9660, 1.0310, 1.0310, 1.0310], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 339 was 50.9%\n",
      "current params: tensor([0.9659, 1.0311, 1.0311, 1.0311], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0423, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 340 was 50.9%\n",
      "current params: tensor([0.9658, 1.0312, 1.0312, 1.0312], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 341 was 50.9%\n",
      "current params: tensor([0.9657, 1.0313, 1.0313, 1.0313], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 342 was 50.9%\n",
      "current params: tensor([0.9656, 1.0314, 1.0314, 1.0314], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 343 was 50.9%\n",
      "current params: tensor([0.9655, 1.0315, 1.0315, 1.0315], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 344 was 51.0%\n",
      "current params: tensor([0.9654, 1.0316, 1.0316, 1.0316], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 345 was 51.0%\n",
      "current params: tensor([0.9653, 1.0317, 1.0317, 1.0317], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 346 was 51.0%\n",
      "current params: tensor([0.9652, 1.0318, 1.0318, 1.0317], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 347 was 51.0%\n",
      "current params: tensor([0.9651, 1.0318, 1.0319, 1.0318], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 348 was 51.0%\n",
      "current params: tensor([0.9650, 1.0319, 1.0319, 1.0319], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 349 was 51.0%\n",
      "current params: tensor([0.9649, 1.0320, 1.0320, 1.0320], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 350 was 51.0%\n",
      "current params: tensor([0.9648, 1.0321, 1.0321, 1.0321], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 351 was 51.0%\n",
      "current params: tensor([0.9647, 1.0322, 1.0322, 1.0322], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 352 was 51.0%\n",
      "current params: tensor([0.9646, 1.0323, 1.0323, 1.0323], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 353 was 51.0%\n",
      "current params: tensor([0.9645, 1.0324, 1.0324, 1.0324], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 354 was 51.0%\n",
      "current params: tensor([0.9644, 1.0325, 1.0325, 1.0325], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 355 was 51.0%\n",
      "current params: tensor([0.9643, 1.0326, 1.0326, 1.0326], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 356 was 51.0%\n",
      "current params: tensor([0.9642, 1.0327, 1.0327, 1.0326], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 357 was 51.0%\n",
      "current params: tensor([0.9641, 1.0328, 1.0328, 1.0327], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 358 was 51.0%\n",
      "current params: tensor([0.9640, 1.0328, 1.0328, 1.0328], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 359 was 51.0%\n",
      "current params: tensor([0.9639, 1.0329, 1.0329, 1.0329], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 360 was 51.0%\n",
      "current params: tensor([0.9638, 1.0330, 1.0330, 1.0330], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 361 was 51.0%\n",
      "current params: tensor([0.9637, 1.0331, 1.0331, 1.0331], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 362 was 51.0%\n",
      "current params: tensor([0.9636, 1.0332, 1.0332, 1.0332], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 363 was 51.0%\n",
      "current params: tensor([0.9635, 1.0333, 1.0333, 1.0333], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 364 was 51.0%\n",
      "current params: tensor([0.9634, 1.0334, 1.0334, 1.0334], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 365 was 51.0%\n",
      "current params: tensor([0.9633, 1.0335, 1.0335, 1.0335], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 366 was 51.0%\n",
      "current params: tensor([0.9632, 1.0336, 1.0336, 1.0336], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 367 was 51.0%\n",
      "current params: tensor([0.9631, 1.0337, 1.0337, 1.0337], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0409, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 368 was 51.0%\n",
      "current params: tensor([0.9630, 1.0337, 1.0337, 1.0337], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 369 was 51.0%\n",
      "current params: tensor([0.9629, 1.0338, 1.0338, 1.0338], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 370 was 51.0%\n",
      "current params: tensor([0.9628, 1.0339, 1.0339, 1.0339], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 371 was 51.1%\n",
      "current params: tensor([0.9627, 1.0340, 1.0340, 1.0340], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 372 was 51.1%\n",
      "current params: tensor([0.9626, 1.0341, 1.0341, 1.0341], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 373 was 51.1%\n",
      "current params: tensor([0.9625, 1.0342, 1.0342, 1.0342], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 374 was 51.1%\n",
      "current params: tensor([0.9624, 1.0343, 1.0343, 1.0343], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 375 was 51.1%\n",
      "current params: tensor([0.9623, 1.0344, 1.0344, 1.0344], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 376 was 51.1%\n",
      "current params: tensor([0.9622, 1.0345, 1.0345, 1.0344], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 377 was 51.1%\n",
      "current params: tensor([0.9621, 1.0346, 1.0346, 1.0345], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 378 was 51.1%\n",
      "current params: tensor([0.9620, 1.0346, 1.0347, 1.0346], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 379 was 51.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9619, 1.0347, 1.0347, 1.0347], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 380 was 51.1%\n",
      "current params: tensor([0.9618, 1.0348, 1.0348, 1.0348], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 381 was 51.1%\n",
      "current params: tensor([0.9617, 1.0349, 1.0349, 1.0349], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 382 was 51.1%\n",
      "current params: tensor([0.9616, 1.0350, 1.0350, 1.0350], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 383 was 51.1%\n",
      "current params: tensor([0.9615, 1.0351, 1.0351, 1.0351], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 384 was 51.1%\n",
      "current params: tensor([0.9614, 1.0352, 1.0352, 1.0352], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 385 was 51.1%\n",
      "current params: tensor([0.9613, 1.0353, 1.0353, 1.0353], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 386 was 51.1%\n",
      "current params: tensor([0.9612, 1.0354, 1.0354, 1.0353], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 387 was 51.1%\n",
      "current params: tensor([0.9611, 1.0355, 1.0355, 1.0354], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 388 was 51.1%\n",
      "current params: tensor([0.9610, 1.0356, 1.0356, 1.0355], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 389 was 51.1%\n",
      "current params: tensor([0.9609, 1.0356, 1.0356, 1.0356], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 390 was 51.1%\n",
      "current params: tensor([0.9608, 1.0357, 1.0357, 1.0357], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 391 was 51.1%\n",
      "current params: tensor([0.9607, 1.0358, 1.0358, 1.0358], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0397, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 392 was 51.1%\n",
      "current params: tensor([0.9606, 1.0359, 1.0359, 1.0359], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0397, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 393 was 51.1%\n",
      "current params: tensor([0.9605, 1.0360, 1.0360, 1.0360], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 394 was 51.1%\n",
      "current params: tensor([0.9604, 1.0361, 1.0361, 1.0361], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0396, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 395 was 51.1%\n",
      "current params: tensor([0.9603, 1.0362, 1.0362, 1.0362], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 396 was 51.1%\n",
      "current params: tensor([0.9602, 1.0363, 1.0362, 1.0363], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0395, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 397 was 51.1%\n",
      "current params: tensor([0.9601, 1.0364, 1.0363, 1.0364], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 398 was 51.2%\n",
      "current params: tensor([0.9600, 1.0365, 1.0364, 1.0364], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 399 was 51.2%\n",
      "current params: tensor([0.9599, 1.0366, 1.0365, 1.0365], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 400 was 51.2%\n",
      "current params: tensor([0.9597, 1.0366, 1.0366, 1.0366], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 401 was 51.2%\n",
      "current params: tensor([0.9596, 1.0367, 1.0367, 1.0367], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 402 was 51.2%\n",
      "current params: tensor([0.9595, 1.0368, 1.0368, 1.0368], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 403 was 51.2%\n",
      "current params: tensor([0.9594, 1.0369, 1.0369, 1.0369], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 404 was 51.2%\n",
      "current params: tensor([0.9593, 1.0370, 1.0370, 1.0370], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 405 was 51.2%\n",
      "current params: tensor([0.9592, 1.0371, 1.0371, 1.0371], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 406 was 51.2%\n",
      "current params: tensor([0.9591, 1.0372, 1.0372, 1.0372], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 407 was 51.2%\n",
      "current params: tensor([0.9590, 1.0373, 1.0372, 1.0373], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 408 was 51.2%\n",
      "current params: tensor([0.9589, 1.0374, 1.0373, 1.0374], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 409 was 51.2%\n",
      "current params: tensor([0.9588, 1.0375, 1.0374, 1.0374], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 410 was 51.2%\n",
      "current params: tensor([0.9587, 1.0376, 1.0375, 1.0375], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 411 was 51.2%\n",
      "current params: tensor([0.9586, 1.0376, 1.0376, 1.0376], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 412 was 51.2%\n",
      "current params: tensor([0.9585, 1.0377, 1.0377, 1.0377], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 413 was 51.2%\n",
      "current params: tensor([0.9584, 1.0378, 1.0378, 1.0378], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 414 was 51.2%\n",
      "current params: tensor([0.9583, 1.0379, 1.0379, 1.0379], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 415 was 51.2%\n",
      "current params: tensor([0.9582, 1.0380, 1.0380, 1.0380], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 416 was 51.2%\n",
      "current params: tensor([0.9581, 1.0381, 1.0381, 1.0381], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 417 was 51.2%\n",
      "current params: tensor([0.9580, 1.0382, 1.0382, 1.0382], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 418 was 51.2%\n",
      "current params: tensor([0.9579, 1.0382, 1.0382, 1.0383], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 419 was 51.2%\n",
      "current params: tensor([0.9578, 1.0383, 1.0383, 1.0383], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 420 was 51.2%\n",
      "current params: tensor([0.9577, 1.0384, 1.0384, 1.0384], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 421 was 51.2%\n",
      "current params: tensor([0.9576, 1.0385, 1.0385, 1.0385], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 422 was 51.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9575, 1.0386, 1.0386, 1.0386], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 423 was 51.2%\n",
      "current params: tensor([0.9574, 1.0387, 1.0387, 1.0387], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 424 was 51.2%\n",
      "current params: tensor([0.9573, 1.0388, 1.0388, 1.0388], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 425 was 51.3%\n",
      "current params: tensor([0.9572, 1.0389, 1.0389, 1.0389], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 426 was 51.3%\n",
      "current params: tensor([0.9571, 1.0390, 1.0390, 1.0390], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 427 was 51.3%\n",
      "current params: tensor([0.9570, 1.0391, 1.0391, 1.0391], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 428 was 51.3%\n",
      "current params: tensor([0.9569, 1.0392, 1.0391, 1.0392], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 429 was 51.3%\n",
      "current params: tensor([0.9568, 1.0392, 1.0392, 1.0392], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 430 was 51.3%\n",
      "current params: tensor([0.9567, 1.0393, 1.0393, 1.0393], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 431 was 51.3%\n",
      "current params: tensor([0.9566, 1.0394, 1.0394, 1.0394], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 432 was 51.3%\n",
      "current params: tensor([0.9565, 1.0395, 1.0395, 1.0395], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 433 was 51.3%\n",
      "current params: tensor([0.9564, 1.0396, 1.0396, 1.0396], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0378, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 434 was 51.3%\n",
      "current params: tensor([0.9563, 1.0397, 1.0397, 1.0397], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 435 was 51.3%\n",
      "current params: tensor([0.9562, 1.0398, 1.0398, 1.0398], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 436 was 51.3%\n",
      "current params: tensor([0.9561, 1.0399, 1.0399, 1.0399], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 437 was 51.3%\n",
      "current params: tensor([0.9560, 1.0400, 1.0400, 1.0400], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 438 was 51.3%\n",
      "current params: tensor([0.9559, 1.0401, 1.0400, 1.0401], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 439 was 51.3%\n",
      "current params: tensor([0.9558, 1.0401, 1.0401, 1.0401], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 440 was 51.3%\n",
      "current params: tensor([0.9557, 1.0402, 1.0402, 1.0402], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 441 was 51.3%\n",
      "current params: tensor([0.9556, 1.0403, 1.0403, 1.0403], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 442 was 51.3%\n",
      "current params: tensor([0.9555, 1.0404, 1.0404, 1.0404], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 443 was 51.3%\n",
      "current params: tensor([0.9554, 1.0405, 1.0405, 1.0405], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 444 was 51.3%\n",
      "current params: tensor([0.9553, 1.0406, 1.0406, 1.0406], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 445 was 51.3%\n",
      "current params: tensor([0.9552, 1.0407, 1.0407, 1.0407], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 446 was 51.3%\n",
      "current params: tensor([0.9551, 1.0408, 1.0408, 1.0408], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 447 was 51.3%\n",
      "current params: tensor([0.9550, 1.0408, 1.0409, 1.0409], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 448 was 51.3%\n",
      "current params: tensor([0.9549, 1.0409, 1.0409, 1.0410], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 449 was 51.3%\n",
      "current params: tensor([0.9548, 1.0410, 1.0410, 1.0410], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 450 was 51.3%\n",
      "current params: tensor([0.9547, 1.0411, 1.0411, 1.0411], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 451 was 51.3%\n",
      "current params: tensor([0.9546, 1.0412, 1.0412, 1.0412], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 452 was 51.4%\n",
      "current params: tensor([0.9545, 1.0413, 1.0413, 1.0413], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0369, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 453 was 51.4%\n",
      "current params: tensor([0.9544, 1.0414, 1.0414, 1.0414], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 454 was 51.4%\n",
      "current params: tensor([0.9543, 1.0415, 1.0415, 1.0415], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0368, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 455 was 51.4%\n",
      "current params: tensor([0.9542, 1.0416, 1.0416, 1.0416], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 456 was 51.4%\n",
      "current params: tensor([0.9541, 1.0417, 1.0417, 1.0417], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 457 was 51.4%\n",
      "current params: tensor([0.9539, 1.0418, 1.0418, 1.0418], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 458 was 51.4%\n",
      "current params: tensor([0.9538, 1.0418, 1.0418, 1.0418], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 459 was 51.4%\n",
      "current params: tensor([0.9537, 1.0419, 1.0419, 1.0419], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 460 was 51.4%\n",
      "current params: tensor([0.9536, 1.0420, 1.0420, 1.0420], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 461 was 51.4%\n",
      "current params: tensor([0.9535, 1.0421, 1.0421, 1.0421], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 462 was 51.4%\n",
      "current params: tensor([0.9534, 1.0422, 1.0422, 1.0422], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 463 was 51.4%\n",
      "current params: tensor([0.9533, 1.0423, 1.0423, 1.0423], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 464 was 51.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9532, 1.0424, 1.0424, 1.0424], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 465 was 51.4%\n",
      "current params: tensor([0.9531, 1.0425, 1.0425, 1.0425], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0363, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 466 was 51.4%\n",
      "current params: tensor([0.9530, 1.0426, 1.0426, 1.0426], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 467 was 51.4%\n",
      "current params: tensor([0.9529, 1.0427, 1.0427, 1.0426], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 468 was 51.4%\n",
      "current params: tensor([0.9528, 1.0427, 1.0427, 1.0427], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 469 was 51.4%\n",
      "current params: tensor([0.9527, 1.0428, 1.0428, 1.0428], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0361, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 470 was 51.4%\n",
      "current params: tensor([0.9526, 1.0429, 1.0429, 1.0429], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 471 was 51.4%\n",
      "current params: tensor([0.9525, 1.0430, 1.0430, 1.0430], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 472 was 51.4%\n",
      "current params: tensor([0.9524, 1.0431, 1.0431, 1.0431], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0360, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 473 was 51.4%\n",
      "current params: tensor([0.9523, 1.0432, 1.0432, 1.0432], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 474 was 51.4%\n",
      "current params: tensor([0.9522, 1.0433, 1.0433, 1.0433], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 475 was 51.4%\n",
      "current params: tensor([0.9521, 1.0434, 1.0434, 1.0434], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 476 was 51.4%\n",
      "current params: tensor([0.9520, 1.0435, 1.0435, 1.0435], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 477 was 51.4%\n",
      "current params: tensor([0.9519, 1.0436, 1.0435, 1.0436], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 478 was 51.4%\n",
      "current params: tensor([0.9518, 1.0436, 1.0436, 1.0436], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 479 was 51.4%\n",
      "current params: tensor([0.9517, 1.0437, 1.0437, 1.0437], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 480 was 51.5%\n",
      "current params: tensor([0.9516, 1.0438, 1.0438, 1.0438], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 481 was 51.5%\n",
      "current params: tensor([0.9515, 1.0439, 1.0439, 1.0439], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 482 was 51.5%\n",
      "current params: tensor([0.9514, 1.0440, 1.0440, 1.0440], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 483 was 51.5%\n",
      "current params: tensor([0.9513, 1.0441, 1.0441, 1.0441], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 484 was 51.5%\n",
      "current params: tensor([0.9512, 1.0442, 1.0442, 1.0442], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 485 was 51.5%\n",
      "current params: tensor([0.9511, 1.0443, 1.0443, 1.0443], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 486 was 51.5%\n",
      "current params: tensor([0.9510, 1.0444, 1.0444, 1.0444], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 487 was 51.5%\n",
      "current params: tensor([0.9509, 1.0444, 1.0444, 1.0444], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 488 was 51.5%\n",
      "current params: tensor([0.9508, 1.0445, 1.0445, 1.0445], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 489 was 51.5%\n",
      "current params: tensor([0.9507, 1.0446, 1.0446, 1.0446], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 490 was 51.5%\n",
      "current params: tensor([0.9506, 1.0447, 1.0447, 1.0447], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 491 was 51.5%\n",
      "current params: tensor([0.9505, 1.0448, 1.0448, 1.0448], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 492 was 51.5%\n",
      "current params: tensor([0.9504, 1.0449, 1.0449, 1.0449], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 493 was 51.5%\n",
      "current params: tensor([0.9503, 1.0450, 1.0450, 1.0450], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 494 was 51.5%\n",
      "current params: tensor([0.9502, 1.0451, 1.0451, 1.0451], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 495 was 51.5%\n",
      "current params: tensor([0.9501, 1.0452, 1.0452, 1.0452], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 496 was 51.5%\n",
      "current params: tensor([0.9500, 1.0453, 1.0452, 1.0453], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 497 was 51.5%\n",
      "current params: tensor([0.9499, 1.0453, 1.0453, 1.0453], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 498 was 51.5%\n",
      "current params: tensor([0.9498, 1.0454, 1.0454, 1.0454], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0348, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 499 was 51.5%\n",
      "current params: tensor([0.9497, 1.0455, 1.0455, 1.0455], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 500 was 51.5%\n",
      "current params: tensor([0.9496, 1.0456, 1.0456, 1.0456], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0347, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 501 was 51.5%\n",
      "current params: tensor([0.9495, 1.0457, 1.0457, 1.0457], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 502 was 51.5%\n",
      "current params: tensor([0.9494, 1.0458, 1.0458, 1.0458], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 503 was 51.5%\n",
      "current params: tensor([0.9493, 1.0459, 1.0459, 1.0459], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 504 was 51.5%\n",
      "current params: tensor([0.9492, 1.0460, 1.0460, 1.0460], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 505 was 51.5%\n",
      "current params: tensor([0.9491, 1.0461, 1.0461, 1.0460], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 506 was 51.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9490, 1.0462, 1.0461, 1.0461], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 507 was 51.6%\n",
      "current params: tensor([0.9489, 1.0462, 1.0462, 1.0462], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 508 was 51.6%\n",
      "current params: tensor([0.9487, 1.0463, 1.0463, 1.0463], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 509 was 51.6%\n",
      "current params: tensor([0.9486, 1.0464, 1.0464, 1.0464], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 510 was 51.6%\n",
      "current params: tensor([0.9485, 1.0465, 1.0465, 1.0465], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 511 was 51.6%\n",
      "current params: tensor([0.9484, 1.0466, 1.0466, 1.0466], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 512 was 51.6%\n",
      "current params: tensor([0.9483, 1.0467, 1.0467, 1.0467], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 513 was 51.6%\n",
      "current params: tensor([0.9482, 1.0468, 1.0468, 1.0468], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 514 was 51.6%\n",
      "current params: tensor([0.9481, 1.0469, 1.0469, 1.0469], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 515 was 51.6%\n",
      "current params: tensor([0.9480, 1.0470, 1.0469, 1.0470], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 516 was 51.6%\n",
      "current params: tensor([0.9479, 1.0470, 1.0470, 1.0470], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 517 was 51.6%\n",
      "current params: tensor([0.9478, 1.0471, 1.0471, 1.0471], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 518 was 51.6%\n",
      "current params: tensor([0.9477, 1.0472, 1.0472, 1.0472], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 519 was 51.6%\n",
      "current params: tensor([0.9476, 1.0473, 1.0473, 1.0473], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 520 was 51.6%\n",
      "current params: tensor([0.9475, 1.0474, 1.0474, 1.0474], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 521 was 51.6%\n",
      "current params: tensor([0.9474, 1.0475, 1.0475, 1.0475], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 522 was 51.6%\n",
      "current params: tensor([0.9473, 1.0476, 1.0476, 1.0476], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 523 was 51.6%\n",
      "current params: tensor([0.9472, 1.0477, 1.0477, 1.0477], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 524 was 51.6%\n",
      "current params: tensor([0.9471, 1.0477, 1.0478, 1.0478], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 525 was 51.6%\n",
      "current params: tensor([0.9470, 1.0478, 1.0478, 1.0479], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 526 was 51.6%\n",
      "current params: tensor([0.9469, 1.0479, 1.0479, 1.0479], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 527 was 51.6%\n",
      "current params: tensor([0.9468, 1.0480, 1.0480, 1.0480], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 528 was 51.6%\n",
      "current params: tensor([0.9467, 1.0481, 1.0481, 1.0481], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 529 was 51.6%\n",
      "current params: tensor([0.9466, 1.0482, 1.0482, 1.0482], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 530 was 51.6%\n",
      "current params: tensor([0.9465, 1.0483, 1.0483, 1.0483], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 531 was 51.6%\n",
      "current params: tensor([0.9464, 1.0484, 1.0484, 1.0484], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 532 was 51.6%\n",
      "current params: tensor([0.9463, 1.0485, 1.0485, 1.0485], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 533 was 51.6%\n",
      "current params: tensor([0.9462, 1.0486, 1.0486, 1.0486], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 534 was 51.7%\n",
      "current params: tensor([0.9461, 1.0487, 1.0487, 1.0486], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 535 was 51.7%\n",
      "current params: tensor([0.9460, 1.0487, 1.0488, 1.0487], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 536 was 51.7%\n",
      "current params: tensor([0.9459, 1.0488, 1.0488, 1.0488], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 537 was 51.7%\n",
      "current params: tensor([0.9458, 1.0489, 1.0489, 1.0489], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 538 was 51.7%\n",
      "current params: tensor([0.9457, 1.0490, 1.0490, 1.0490], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0330, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 539 was 51.7%\n",
      "current params: tensor([0.9456, 1.0491, 1.0491, 1.0491], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 540 was 51.7%\n",
      "current params: tensor([0.9455, 1.0492, 1.0492, 1.0492], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 541 was 51.7%\n",
      "current params: tensor([0.9454, 1.0493, 1.0493, 1.0493], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 542 was 51.7%\n",
      "current params: tensor([0.9453, 1.0494, 1.0494, 1.0494], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 543 was 51.7%\n",
      "current params: tensor([0.9452, 1.0495, 1.0494, 1.0495], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 544 was 51.7%\n",
      "current params: tensor([0.9451, 1.0496, 1.0495, 1.0495], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 545 was 51.7%\n",
      "current params: tensor([0.9450, 1.0496, 1.0496, 1.0496], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 546 was 51.7%\n",
      "current params: tensor([0.9449, 1.0497, 1.0497, 1.0497], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 547 was 51.7%\n",
      "current params: tensor([0.9448, 1.0498, 1.0498, 1.0498], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 548 was 51.7%\n",
      "current params: tensor([0.9447, 1.0499, 1.0499, 1.0499], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 549 was 51.7%\n",
      "current params: tensor([0.9446, 1.0500, 1.0500, 1.0500], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 550 was 51.7%\n",
      "current params: tensor([0.9445, 1.0501, 1.0501, 1.0501], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 551 was 51.7%\n",
      "current params: tensor([0.9444, 1.0502, 1.0502, 1.0502], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 552 was 51.7%\n",
      "current params: tensor([0.9443, 1.0503, 1.0503, 1.0503], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 553 was 51.7%\n",
      "current params: tensor([0.9442, 1.0504, 1.0504, 1.0503], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 554 was 51.7%\n",
      "current params: tensor([0.9441, 1.0504, 1.0504, 1.0504], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 555 was 51.7%\n",
      "current params: tensor([0.9439, 1.0505, 1.0505, 1.0505], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 556 was 51.7%\n",
      "current params: tensor([0.9438, 1.0506, 1.0506, 1.0506], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 557 was 51.7%\n",
      "current params: tensor([0.9437, 1.0507, 1.0507, 1.0507], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 558 was 51.7%\n",
      "current params: tensor([0.9436, 1.0508, 1.0508, 1.0508], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 559 was 51.7%\n",
      "current params: tensor([0.9435, 1.0509, 1.0509, 1.0509], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 560 was 51.7%\n",
      "current params: tensor([0.9434, 1.0510, 1.0510, 1.0510], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 561 was 51.8%\n",
      "current params: tensor([0.9433, 1.0511, 1.0511, 1.0511], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 562 was 51.8%\n",
      "current params: tensor([0.9432, 1.0511, 1.0512, 1.0512], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 563 was 51.8%\n",
      "current params: tensor([0.9431, 1.0512, 1.0513, 1.0512], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 564 was 51.8%\n",
      "current params: tensor([0.9430, 1.0513, 1.0513, 1.0513], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 565 was 51.8%\n",
      "current params: tensor([0.9429, 1.0514, 1.0514, 1.0514], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 566 was 51.8%\n",
      "current params: tensor([0.9428, 1.0515, 1.0515, 1.0515], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 567 was 51.8%\n",
      "current params: tensor([0.9427, 1.0516, 1.0516, 1.0516], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 568 was 51.8%\n",
      "current params: tensor([0.9426, 1.0517, 1.0517, 1.0517], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 569 was 51.8%\n",
      "current params: tensor([0.9425, 1.0518, 1.0518, 1.0518], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 570 was 51.8%\n",
      "current params: tensor([0.9424, 1.0519, 1.0519, 1.0519], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 571 was 51.8%\n",
      "current params: tensor([0.9423, 1.0519, 1.0520, 1.0520], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 572 was 51.8%\n",
      "current params: tensor([0.9422, 1.0520, 1.0520, 1.0521], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 573 was 51.8%\n",
      "current params: tensor([0.9421, 1.0521, 1.0521, 1.0521], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 574 was 51.8%\n",
      "current params: tensor([0.9420, 1.0522, 1.0522, 1.0522], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 575 was 51.8%\n",
      "current params: tensor([0.9419, 1.0523, 1.0523, 1.0523], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 576 was 51.8%\n",
      "current params: tensor([0.9418, 1.0524, 1.0524, 1.0524], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 577 was 51.8%\n",
      "current params: tensor([0.9417, 1.0525, 1.0525, 1.0525], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 578 was 51.8%\n",
      "current params: tensor([0.9416, 1.0526, 1.0526, 1.0526], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 579 was 51.8%\n",
      "current params: tensor([0.9415, 1.0527, 1.0527, 1.0527], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 580 was 51.8%\n",
      "current params: tensor([0.9414, 1.0528, 1.0528, 1.0528], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 581 was 51.8%\n",
      "current params: tensor([0.9413, 1.0528, 1.0528, 1.0529], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 582 was 51.8%\n",
      "current params: tensor([0.9412, 1.0529, 1.0529, 1.0529], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 583 was 51.8%\n",
      "current params: tensor([0.9411, 1.0530, 1.0530, 1.0530], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 584 was 51.8%\n",
      "current params: tensor([0.9410, 1.0531, 1.0531, 1.0531], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 585 was 51.8%\n",
      "current params: tensor([0.9409, 1.0532, 1.0532, 1.0532], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 586 was 51.8%\n",
      "current params: tensor([0.9408, 1.0533, 1.0533, 1.0533], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 587 was 51.8%\n",
      "current params: tensor([0.9407, 1.0534, 1.0534, 1.0534], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 588 was 51.8%\n",
      "current params: tensor([0.9406, 1.0535, 1.0535, 1.0535], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 589 was 51.9%\n",
      "current params: tensor([0.9405, 1.0536, 1.0536, 1.0536], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 590 was 51.9%\n",
      "current params: tensor([0.9404, 1.0537, 1.0536, 1.0536], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 591 was 51.9%\n",
      "current params: tensor([0.9403, 1.0537, 1.0537, 1.0537], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 592 was 51.9%\n",
      "current params: tensor([0.9402, 1.0538, 1.0538, 1.0538], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 593 was 51.9%\n",
      "current params: tensor([0.9401, 1.0539, 1.0539, 1.0539], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 594 was 51.9%\n",
      "current params: tensor([0.9400, 1.0540, 1.0540, 1.0540], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 595 was 51.9%\n",
      "current params: tensor([0.9399, 1.0541, 1.0541, 1.0541], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 596 was 51.9%\n",
      "current params: tensor([0.9398, 1.0542, 1.0542, 1.0542], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 597 was 51.9%\n",
      "current params: tensor([0.9397, 1.0543, 1.0543, 1.0543], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 598 was 51.9%\n",
      "current params: tensor([0.9396, 1.0544, 1.0544, 1.0544], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 599 was 51.9%\n",
      "current params: tensor([0.9394, 1.0544, 1.0544, 1.0545], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 600 was 51.9%\n",
      "current params: tensor([0.9393, 1.0545, 1.0545, 1.0545], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 601 was 51.9%\n",
      "current params: tensor([0.9392, 1.0546, 1.0546, 1.0546], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 602 was 51.9%\n",
      "current params: tensor([0.9391, 1.0547, 1.0547, 1.0547], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 603 was 51.9%\n",
      "current params: tensor([0.9390, 1.0548, 1.0548, 1.0548], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 604 was 51.9%\n",
      "current params: tensor([0.9389, 1.0549, 1.0549, 1.0549], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 605 was 51.9%\n",
      "current params: tensor([0.9388, 1.0550, 1.0550, 1.0550], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 606 was 51.9%\n",
      "current params: tensor([0.9387, 1.0551, 1.0551, 1.0551], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 607 was 51.9%\n",
      "current params: tensor([0.9386, 1.0552, 1.0552, 1.0552], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 608 was 51.9%\n",
      "current params: tensor([0.9385, 1.0552, 1.0552, 1.0553], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 609 was 51.9%\n",
      "current params: tensor([0.9384, 1.0553, 1.0553, 1.0553], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 610 was 51.9%\n",
      "current params: tensor([0.9383, 1.0554, 1.0554, 1.0554], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 611 was 51.9%\n",
      "current params: tensor([0.9382, 1.0555, 1.0555, 1.0555], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 612 was 51.9%\n",
      "current params: tensor([0.9381, 1.0556, 1.0556, 1.0556], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 613 was 51.9%\n",
      "current params: tensor([0.9380, 1.0557, 1.0557, 1.0557], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 614 was 51.9%\n",
      "current params: tensor([0.9379, 1.0558, 1.0558, 1.0558], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 615 was 51.9%\n",
      "current params: tensor([0.9378, 1.0559, 1.0559, 1.0559], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 616 was 52.0%\n",
      "current params: tensor([0.9377, 1.0560, 1.0560, 1.0560], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 617 was 52.0%\n",
      "current params: tensor([0.9376, 1.0561, 1.0560, 1.0561], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 618 was 52.0%\n",
      "current params: tensor([0.9375, 1.0561, 1.0561, 1.0561], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 619 was 52.0%\n",
      "current params: tensor([0.9374, 1.0562, 1.0562, 1.0562], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 620 was 52.0%\n",
      "current params: tensor([0.9373, 1.0563, 1.0563, 1.0563], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 621 was 52.0%\n",
      "current params: tensor([0.9372, 1.0564, 1.0564, 1.0564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 622 was 52.0%\n",
      "current params: tensor([0.9371, 1.0565, 1.0565, 1.0565], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 623 was 52.0%\n",
      "current params: tensor([0.9370, 1.0566, 1.0566, 1.0566], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 624 was 52.0%\n",
      "current params: tensor([0.9369, 1.0567, 1.0567, 1.0567], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 625 was 52.0%\n",
      "current params: tensor([0.9368, 1.0568, 1.0568, 1.0568], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 626 was 52.0%\n",
      "current params: tensor([0.9367, 1.0568, 1.0569, 1.0569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 627 was 52.0%\n",
      "current params: tensor([0.9366, 1.0569, 1.0569, 1.0569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 628 was 52.0%\n",
      "current params: tensor([0.9365, 1.0570, 1.0570, 1.0570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 629 was 52.0%\n",
      "current params: tensor([0.9364, 1.0571, 1.0571, 1.0571], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 630 was 52.0%\n",
      "current params: tensor([0.9363, 1.0572, 1.0572, 1.0572], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 631 was 52.0%\n",
      "current params: tensor([0.9362, 1.0573, 1.0573, 1.0573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 632 was 52.0%\n",
      "current params: tensor([0.9361, 1.0574, 1.0574, 1.0574], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 633 was 52.0%\n",
      "current params: tensor([0.9360, 1.0575, 1.0575, 1.0575], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 634 was 52.0%\n",
      "current params: tensor([0.9359, 1.0576, 1.0576, 1.0576], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 635 was 52.0%\n",
      "current params: tensor([0.9358, 1.0576, 1.0576, 1.0577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 636 was 52.0%\n",
      "current params: tensor([0.9357, 1.0577, 1.0577, 1.0577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 637 was 52.0%\n",
      "current params: tensor([0.9356, 1.0578, 1.0578, 1.0578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 638 was 52.0%\n",
      "current params: tensor([0.9355, 1.0579, 1.0579, 1.0579], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 639 was 52.0%\n",
      "current params: tensor([0.9354, 1.0580, 1.0580, 1.0580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 640 was 52.0%\n",
      "current params: tensor([0.9352, 1.0581, 1.0581, 1.0581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 641 was 52.0%\n",
      "current params: tensor([0.9351, 1.0582, 1.0582, 1.0582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 642 was 52.0%\n",
      "current params: tensor([0.9350, 1.0583, 1.0583, 1.0583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 643 was 52.1%\n",
      "current params: tensor([0.9349, 1.0584, 1.0584, 1.0584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 644 was 52.1%\n",
      "current params: tensor([0.9348, 1.0584, 1.0584, 1.0585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 645 was 52.1%\n",
      "current params: tensor([0.9347, 1.0585, 1.0585, 1.0585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 646 was 52.1%\n",
      "current params: tensor([0.9346, 1.0586, 1.0586, 1.0586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 647 was 52.1%\n",
      "current params: tensor([0.9345, 1.0587, 1.0587, 1.0587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 648 was 52.1%\n",
      "current params: tensor([0.9344, 1.0588, 1.0588, 1.0588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 649 was 52.1%\n",
      "current params: tensor([0.9343, 1.0589, 1.0589, 1.0589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 650 was 52.1%\n",
      "current params: tensor([0.9342, 1.0590, 1.0590, 1.0590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 651 was 52.1%\n",
      "current params: tensor([0.9341, 1.0591, 1.0591, 1.0591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 652 was 52.1%\n",
      "current params: tensor([0.9340, 1.0592, 1.0592, 1.0592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 653 was 52.1%\n",
      "current params: tensor([0.9339, 1.0592, 1.0592, 1.0593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 654 was 52.1%\n",
      "current params: tensor([0.9338, 1.0593, 1.0593, 1.0594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 655 was 52.1%\n",
      "current params: tensor([0.9337, 1.0594, 1.0594, 1.0594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 656 was 52.1%\n",
      "current params: tensor([0.9336, 1.0595, 1.0595, 1.0595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 657 was 52.1%\n",
      "current params: tensor([0.9335, 1.0596, 1.0596, 1.0596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 658 was 52.1%\n",
      "current params: tensor([0.9334, 1.0597, 1.0597, 1.0597], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 659 was 52.1%\n",
      "current params: tensor([0.9333, 1.0598, 1.0598, 1.0598], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 660 was 52.1%\n",
      "current params: tensor([0.9332, 1.0599, 1.0599, 1.0599], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 661 was 52.1%\n",
      "current params: tensor([0.9331, 1.0600, 1.0600, 1.0600], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 662 was 52.1%\n",
      "current params: tensor([0.9330, 1.0601, 1.0600, 1.0600], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 663 was 52.1%\n",
      "current params: tensor([0.9329, 1.0601, 1.0601, 1.0601], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 664 was 52.1%\n",
      "current params: tensor([0.9328, 1.0602, 1.0602, 1.0602], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 665 was 52.1%\n",
      "current params: tensor([0.9327, 1.0603, 1.0603, 1.0603], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 666 was 52.1%\n",
      "current params: tensor([0.9326, 1.0604, 1.0604, 1.0604], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 667 was 52.1%\n",
      "current params: tensor([0.9325, 1.0605, 1.0605, 1.0605], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 668 was 52.1%\n",
      "current params: tensor([0.9324, 1.0606, 1.0606, 1.0606], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 669 was 52.1%\n",
      "current params: tensor([0.9323, 1.0607, 1.0607, 1.0607], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 670 was 52.2%\n",
      "current params: tensor([0.9322, 1.0607, 1.0608, 1.0607], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 671 was 52.2%\n",
      "current params: tensor([0.9321, 1.0608, 1.0609, 1.0608], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 672 was 52.2%\n",
      "current params: tensor([0.9320, 1.0609, 1.0609, 1.0609], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 673 was 52.2%\n",
      "current params: tensor([0.9319, 1.0610, 1.0610, 1.0610], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 674 was 52.2%\n",
      "current params: tensor([0.9318, 1.0611, 1.0611, 1.0611], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 675 was 52.2%\n",
      "current params: tensor([0.9317, 1.0612, 1.0612, 1.0612], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 676 was 52.2%\n",
      "current params: tensor([0.9316, 1.0613, 1.0613, 1.0613], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 677 was 52.2%\n",
      "current params: tensor([0.9315, 1.0614, 1.0614, 1.0614], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 678 was 52.2%\n",
      "current params: tensor([0.9313, 1.0615, 1.0615, 1.0615], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 679 was 52.2%\n",
      "current params: tensor([0.9312, 1.0615, 1.0616, 1.0616], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 680 was 52.2%\n",
      "current params: tensor([0.9311, 1.0616, 1.0617, 1.0616], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 681 was 52.2%\n",
      "current params: tensor([0.9310, 1.0617, 1.0617, 1.0617], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 682 was 52.2%\n",
      "current params: tensor([0.9309, 1.0618, 1.0618, 1.0618], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 683 was 52.2%\n",
      "current params: tensor([0.9308, 1.0619, 1.0619, 1.0619], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 684 was 52.2%\n",
      "current params: tensor([0.9307, 1.0620, 1.0620, 1.0620], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 685 was 52.2%\n",
      "current params: tensor([0.9306, 1.0621, 1.0621, 1.0621], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 686 was 52.2%\n",
      "current params: tensor([0.9305, 1.0622, 1.0622, 1.0622], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 687 was 52.2%\n",
      "current params: tensor([0.9304, 1.0623, 1.0623, 1.0623], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 688 was 52.2%\n",
      "current params: tensor([0.9303, 1.0623, 1.0624, 1.0623], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 689 was 52.2%\n",
      "current params: tensor([0.9302, 1.0624, 1.0625, 1.0624], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 690 was 52.2%\n",
      "current params: tensor([0.9301, 1.0625, 1.0625, 1.0625], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 691 was 52.2%\n",
      "current params: tensor([0.9300, 1.0626, 1.0626, 1.0626], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 692 was 52.2%\n",
      "current params: tensor([0.9299, 1.0627, 1.0627, 1.0627], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 693 was 52.2%\n",
      "current params: tensor([0.9298, 1.0628, 1.0628, 1.0628], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 694 was 52.2%\n",
      "current params: tensor([0.9297, 1.0629, 1.0629, 1.0629], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 695 was 52.2%\n",
      "current params: tensor([0.9296, 1.0630, 1.0630, 1.0630], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 696 was 52.2%\n",
      "current params: tensor([0.9295, 1.0631, 1.0631, 1.0631], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 697 was 52.2%\n",
      "current params: tensor([0.9294, 1.0631, 1.0632, 1.0631], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 698 was 52.3%\n",
      "current params: tensor([0.9293, 1.0632, 1.0632, 1.0632], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 699 was 52.3%\n",
      "current params: tensor([0.9292, 1.0633, 1.0633, 1.0633], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 700 was 52.3%\n",
      "current params: tensor([0.9291, 1.0634, 1.0634, 1.0634], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 701 was 52.3%\n",
      "current params: tensor([0.9290, 1.0635, 1.0635, 1.0635], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 702 was 52.3%\n",
      "current params: tensor([0.9289, 1.0636, 1.0636, 1.0636], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 703 was 52.3%\n",
      "current params: tensor([0.9288, 1.0637, 1.0637, 1.0637], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 704 was 52.3%\n",
      "current params: tensor([0.9287, 1.0638, 1.0638, 1.0638], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 705 was 52.3%\n",
      "current params: tensor([0.9286, 1.0639, 1.0639, 1.0639], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 706 was 52.3%\n",
      "current params: tensor([0.9285, 1.0639, 1.0640, 1.0639], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 707 was 52.3%\n",
      "current params: tensor([0.9284, 1.0640, 1.0640, 1.0640], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 708 was 52.3%\n",
      "current params: tensor([0.9283, 1.0641, 1.0641, 1.0641], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 709 was 52.3%\n",
      "current params: tensor([0.9282, 1.0642, 1.0642, 1.0642], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 710 was 52.3%\n",
      "current params: tensor([0.9281, 1.0643, 1.0643, 1.0643], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 711 was 52.3%\n",
      "current params: tensor([0.9280, 1.0644, 1.0644, 1.0644], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 712 was 52.3%\n",
      "current params: tensor([0.9279, 1.0645, 1.0645, 1.0645], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 713 was 52.3%\n",
      "current params: tensor([0.9278, 1.0646, 1.0646, 1.0646], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 714 was 52.3%\n",
      "current params: tensor([0.9277, 1.0647, 1.0647, 1.0647], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 715 was 52.3%\n",
      "current params: tensor([0.9275, 1.0647, 1.0647, 1.0647], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 716 was 52.3%\n",
      "current params: tensor([0.9274, 1.0648, 1.0648, 1.0648], dtype=torch.float64)\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(1.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 717 was 52.3%\n",
      "current params: tensor([0.9273, 1.0649, 1.0649, 1.0649], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 718 was 52.3%\n",
      "current params: tensor([0.9272, 1.0650, 1.0650, 1.0650], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 719 was 52.3%\n",
      "current params: tensor([0.9271, 1.0651, 1.0651, 1.0651], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 720 was 52.3%\n",
      "current params: tensor([0.9270, 1.0652, 1.0652, 1.0652], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 721 was 52.3%\n",
      "current params: tensor([0.9269, 1.0653, 1.0653, 1.0653], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 722 was 52.3%\n",
      "current params: tensor([0.9268, 1.0654, 1.0654, 1.0654], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 723 was 52.3%\n",
      "current params: tensor([0.9267, 1.0654, 1.0655, 1.0655], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 724 was 52.3%\n",
      "current params: tensor([0.9266, 1.0655, 1.0655, 1.0655], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 725 was 52.4%\n",
      "current params: tensor([0.9265, 1.0656, 1.0656, 1.0656], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 726 was 52.4%\n",
      "current params: tensor([0.9264, 1.0657, 1.0657, 1.0657], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 727 was 52.4%\n",
      "current params: tensor([0.9263, 1.0658, 1.0658, 1.0658], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 728 was 52.4%\n",
      "current params: tensor([0.9262, 1.0659, 1.0659, 1.0659], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 729 was 52.4%\n",
      "current params: tensor([0.9261, 1.0660, 1.0660, 1.0660], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 730 was 52.4%\n",
      "current params: tensor([0.9260, 1.0661, 1.0661, 1.0661], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 731 was 52.4%\n",
      "current params: tensor([0.9259, 1.0662, 1.0661, 1.0662], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 732 was 52.4%\n",
      "current params: tensor([0.9258, 1.0662, 1.0662, 1.0662], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 733 was 52.4%\n",
      "current params: tensor([0.9257, 1.0663, 1.0663, 1.0663], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 734 was 52.4%\n",
      "current params: tensor([0.9256, 1.0664, 1.0664, 1.0664], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 735 was 52.4%\n",
      "current params: tensor([0.9255, 1.0665, 1.0665, 1.0665], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 736 was 52.4%\n",
      "current params: tensor([0.9254, 1.0666, 1.0666, 1.0666], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 737 was 52.4%\n",
      "current params: tensor([0.9253, 1.0667, 1.0667, 1.0667], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 738 was 52.4%\n",
      "current params: tensor([0.9252, 1.0668, 1.0668, 1.0668], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 739 was 52.4%\n",
      "current params: tensor([0.9251, 1.0669, 1.0669, 1.0669], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 740 was 52.4%\n",
      "current params: tensor([0.9250, 1.0670, 1.0669, 1.0669], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 741 was 52.4%\n",
      "current params: tensor([0.9249, 1.0670, 1.0670, 1.0670], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 742 was 52.4%\n",
      "current params: tensor([0.9248, 1.0671, 1.0671, 1.0671], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 743 was 52.4%\n",
      "current params: tensor([0.9247, 1.0672, 1.0672, 1.0672], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 744 was 52.4%\n",
      "current params: tensor([0.9246, 1.0673, 1.0673, 1.0673], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 745 was 52.4%\n",
      "current params: tensor([0.9245, 1.0674, 1.0674, 1.0674], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 746 was 52.4%\n",
      "current params: tensor([0.9244, 1.0675, 1.0675, 1.0675], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 747 was 52.4%\n",
      "current params: tensor([0.9243, 1.0676, 1.0676, 1.0676], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 748 was 52.4%\n",
      "current params: tensor([0.9242, 1.0677, 1.0677, 1.0676], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 749 was 52.4%\n",
      "current params: tensor([0.9241, 1.0678, 1.0677, 1.0677], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 750 was 52.4%\n",
      "current params: tensor([0.9239, 1.0678, 1.0678, 1.0678], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 751 was 52.4%\n",
      "current params: tensor([0.9238, 1.0679, 1.0679, 1.0679], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 752 was 52.5%\n",
      "current params: tensor([0.9237, 1.0680, 1.0680, 1.0680], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 753 was 52.5%\n",
      "current params: tensor([0.9236, 1.0681, 1.0681, 1.0681], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 754 was 52.5%\n",
      "current params: tensor([0.9235, 1.0682, 1.0682, 1.0682], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 755 was 52.5%\n",
      "current params: tensor([0.9234, 1.0683, 1.0683, 1.0683], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 756 was 52.5%\n",
      "current params: tensor([0.9233, 1.0683, 1.0684, 1.0684], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 757 was 52.5%\n",
      "current params: tensor([0.9232, 1.0684, 1.0685, 1.0684], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 758 was 52.5%\n",
      "current params: tensor([0.9231, 1.0685, 1.0686, 1.0685], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 759 was 52.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9230, 1.0686, 1.0686, 1.0686], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 760 was 52.5%\n",
      "current params: tensor([0.9229, 1.0687, 1.0687, 1.0687], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 761 was 52.5%\n",
      "current params: tensor([0.9228, 1.0688, 1.0688, 1.0688], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 762 was 52.5%\n",
      "current params: tensor([0.9227, 1.0689, 1.0689, 1.0689], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 763 was 52.5%\n",
      "current params: tensor([0.9226, 1.0690, 1.0690, 1.0690], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 764 was 52.5%\n",
      "current params: tensor([0.9225, 1.0691, 1.0691, 1.0691], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 765 was 52.5%\n",
      "current params: tensor([0.9224, 1.0692, 1.0692, 1.0692], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 766 was 52.5%\n",
      "current params: tensor([0.9223, 1.0692, 1.0693, 1.0692], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 767 was 52.5%\n",
      "current params: tensor([0.9222, 1.0693, 1.0693, 1.0693], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 768 was 52.5%\n",
      "current params: tensor([0.9221, 1.0694, 1.0694, 1.0694], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 769 was 52.5%\n",
      "current params: tensor([0.9220, 1.0695, 1.0695, 1.0695], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 770 was 52.5%\n",
      "current params: tensor([0.9219, 1.0696, 1.0696, 1.0696], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 771 was 52.5%\n",
      "current params: tensor([0.9218, 1.0697, 1.0697, 1.0697], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 772 was 52.5%\n",
      "current params: tensor([0.9217, 1.0698, 1.0698, 1.0698], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 773 was 52.5%\n",
      "current params: tensor([0.9216, 1.0699, 1.0699, 1.0699], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 774 was 52.5%\n",
      "current params: tensor([0.9215, 1.0699, 1.0699, 1.0700], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 775 was 52.5%\n",
      "current params: tensor([0.9214, 1.0700, 1.0700, 1.0701], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 776 was 52.5%\n",
      "current params: tensor([0.9213, 1.0701, 1.0701, 1.0701], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 777 was 52.5%\n",
      "current params: tensor([0.9212, 1.0702, 1.0702, 1.0702], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 778 was 52.5%\n",
      "current params: tensor([0.9211, 1.0703, 1.0703, 1.0703], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 779 was 52.6%\n",
      "current params: tensor([0.9210, 1.0704, 1.0704, 1.0704], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 780 was 52.6%\n",
      "current params: tensor([0.9209, 1.0705, 1.0705, 1.0705], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 781 was 52.6%\n",
      "current params: tensor([0.9208, 1.0706, 1.0706, 1.0706], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 782 was 52.6%\n",
      "current params: tensor([0.9207, 1.0707, 1.0707, 1.0707], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 783 was 52.6%\n",
      "current params: tensor([0.9206, 1.0707, 1.0707, 1.0707], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 784 was 52.6%\n",
      "current params: tensor([0.9204, 1.0708, 1.0708, 1.0708], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 785 was 52.6%\n",
      "current params: tensor([0.9203, 1.0709, 1.0709, 1.0709], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 786 was 52.6%\n",
      "current params: tensor([0.9202, 1.0710, 1.0710, 1.0710], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 787 was 52.6%\n",
      "current params: tensor([0.9201, 1.0711, 1.0711, 1.0711], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 788 was 52.6%\n",
      "current params: tensor([0.9200, 1.0712, 1.0712, 1.0712], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 789 was 52.6%\n",
      "current params: tensor([0.9199, 1.0713, 1.0713, 1.0713], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 790 was 52.6%\n",
      "current params: tensor([0.9198, 1.0714, 1.0714, 1.0714], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 791 was 52.6%\n",
      "current params: tensor([0.9197, 1.0714, 1.0715, 1.0714], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 792 was 52.6%\n",
      "current params: tensor([0.9196, 1.0715, 1.0715, 1.0715], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 793 was 52.6%\n",
      "current params: tensor([0.9195, 1.0716, 1.0716, 1.0716], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 794 was 52.6%\n",
      "current params: tensor([0.9194, 1.0717, 1.0717, 1.0717], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 795 was 52.6%\n",
      "current params: tensor([0.9193, 1.0718, 1.0718, 1.0718], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 796 was 52.6%\n",
      "current params: tensor([0.9192, 1.0719, 1.0719, 1.0719], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 797 was 52.6%\n",
      "current params: tensor([0.9191, 1.0720, 1.0720, 1.0720], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 798 was 52.6%\n",
      "current params: tensor([0.9190, 1.0721, 1.0721, 1.0721], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 799 was 52.6%\n",
      "current params: tensor([0.9189, 1.0721, 1.0722, 1.0722], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 800 was 52.6%\n",
      "current params: tensor([0.9188, 1.0722, 1.0722, 1.0722], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 801 was 52.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9187, 1.0723, 1.0723, 1.0723], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 802 was 52.6%\n",
      "current params: tensor([0.9186, 1.0724, 1.0724, 1.0724], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 803 was 52.6%\n",
      "current params: tensor([0.9185, 1.0725, 1.0725, 1.0725], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 804 was 52.6%\n",
      "current params: tensor([0.9184, 1.0726, 1.0726, 1.0726], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 805 was 52.6%\n",
      "current params: tensor([0.9183, 1.0727, 1.0727, 1.0727], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 806 was 52.6%\n",
      "current params: tensor([0.9182, 1.0728, 1.0728, 1.0728], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 807 was 52.7%\n",
      "current params: tensor([0.9181, 1.0729, 1.0729, 1.0729], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 808 was 52.7%\n",
      "current params: tensor([0.9180, 1.0729, 1.0730, 1.0729], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 809 was 52.7%\n",
      "current params: tensor([0.9179, 1.0730, 1.0730, 1.0730], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 810 was 52.7%\n",
      "current params: tensor([0.9178, 1.0731, 1.0731, 1.0731], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 811 was 52.7%\n",
      "current params: tensor([0.9177, 1.0732, 1.0732, 1.0732], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 812 was 52.7%\n",
      "current params: tensor([0.9176, 1.0733, 1.0733, 1.0733], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 813 was 52.7%\n",
      "current params: tensor([0.9175, 1.0734, 1.0734, 1.0734], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 814 was 52.7%\n",
      "current params: tensor([0.9174, 1.0735, 1.0735, 1.0735], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 815 was 52.7%\n",
      "current params: tensor([0.9173, 1.0736, 1.0736, 1.0736], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 816 was 52.7%\n",
      "current params: tensor([0.9171, 1.0737, 1.0737, 1.0736], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 817 was 52.7%\n",
      "current params: tensor([0.9170, 1.0737, 1.0737, 1.0737], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 818 was 52.7%\n",
      "current params: tensor([0.9169, 1.0738, 1.0738, 1.0738], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 819 was 52.7%\n",
      "current params: tensor([0.9168, 1.0739, 1.0739, 1.0739], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 820 was 52.7%\n",
      "current params: tensor([0.9167, 1.0740, 1.0740, 1.0740], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 821 was 52.7%\n",
      "current params: tensor([0.9166, 1.0741, 1.0741, 1.0741], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 822 was 52.7%\n",
      "current params: tensor([0.9165, 1.0742, 1.0742, 1.0742], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0215, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 823 was 52.7%\n",
      "current params: tensor([0.9164, 1.0743, 1.0743, 1.0743], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 824 was 52.7%\n",
      "current params: tensor([0.9163, 1.0744, 1.0744, 1.0743], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 825 was 52.7%\n",
      "current params: tensor([0.9162, 1.0744, 1.0744, 1.0744], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 826 was 52.7%\n",
      "current params: tensor([0.9161, 1.0745, 1.0745, 1.0745], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 827 was 52.7%\n",
      "current params: tensor([0.9160, 1.0746, 1.0746, 1.0746], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 828 was 52.7%\n",
      "current params: tensor([0.9159, 1.0747, 1.0747, 1.0747], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 829 was 52.7%\n",
      "current params: tensor([0.9158, 1.0748, 1.0748, 1.0748], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 830 was 52.7%\n",
      "current params: tensor([0.9157, 1.0749, 1.0749, 1.0749], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 831 was 52.7%\n",
      "current params: tensor([0.9156, 1.0750, 1.0750, 1.0750], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 832 was 52.7%\n",
      "current params: tensor([0.9155, 1.0751, 1.0751, 1.0751], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0211, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 833 was 52.7%\n",
      "current params: tensor([0.9154, 1.0751, 1.0751, 1.0751], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 834 was 52.8%\n",
      "current params: tensor([0.9153, 1.0752, 1.0752, 1.0752], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 835 was 52.8%\n",
      "current params: tensor([0.9152, 1.0753, 1.0753, 1.0753], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 836 was 52.8%\n",
      "current params: tensor([0.9151, 1.0754, 1.0754, 1.0754], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 837 was 52.8%\n",
      "current params: tensor([0.9150, 1.0755, 1.0755, 1.0755], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 838 was 52.8%\n",
      "current params: tensor([0.9149, 1.0756, 1.0756, 1.0756], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 839 was 52.8%\n",
      "current params: tensor([0.9148, 1.0757, 1.0757, 1.0757], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 840 was 52.8%\n",
      "current params: tensor([0.9147, 1.0758, 1.0758, 1.0758], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 841 was 52.8%\n",
      "current params: tensor([0.9146, 1.0758, 1.0759, 1.0758], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 842 was 52.8%\n",
      "current params: tensor([0.9145, 1.0759, 1.0759, 1.0759], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 843 was 52.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9144, 1.0760, 1.0760, 1.0760], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 844 was 52.8%\n",
      "current params: tensor([0.9143, 1.0761, 1.0761, 1.0761], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 845 was 52.8%\n",
      "current params: tensor([0.9142, 1.0762, 1.0762, 1.0762], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 846 was 52.8%\n",
      "current params: tensor([0.9141, 1.0763, 1.0763, 1.0763], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 847 was 52.8%\n",
      "current params: tensor([0.9140, 1.0764, 1.0764, 1.0764], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 848 was 52.8%\n",
      "current params: tensor([0.9138, 1.0765, 1.0765, 1.0765], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 849 was 52.8%\n",
      "current params: tensor([0.9137, 1.0765, 1.0765, 1.0766], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 850 was 52.8%\n",
      "current params: tensor([0.9136, 1.0766, 1.0766, 1.0766], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0204, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 851 was 52.8%\n",
      "current params: tensor([0.9135, 1.0767, 1.0767, 1.0767], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0204, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 852 was 52.8%\n",
      "current params: tensor([0.9134, 1.0768, 1.0768, 1.0768], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 853 was 52.8%\n",
      "current params: tensor([0.9133, 1.0769, 1.0769, 1.0769], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 854 was 52.8%\n",
      "current params: tensor([0.9132, 1.0770, 1.0770, 1.0770], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 855 was 52.8%\n",
      "current params: tensor([0.9131, 1.0771, 1.0771, 1.0771], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 856 was 52.8%\n",
      "current params: tensor([0.9130, 1.0772, 1.0772, 1.0772], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0202, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 857 was 52.8%\n",
      "current params: tensor([0.9129, 1.0772, 1.0773, 1.0773], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 858 was 52.8%\n",
      "current params: tensor([0.9128, 1.0773, 1.0773, 1.0773], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 859 was 52.8%\n",
      "current params: tensor([0.9127, 1.0774, 1.0774, 1.0774], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 860 was 52.8%\n",
      "current params: tensor([0.9126, 1.0775, 1.0775, 1.0775], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 861 was 52.9%\n",
      "current params: tensor([0.9125, 1.0776, 1.0776, 1.0776], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 862 was 52.9%\n",
      "current params: tensor([0.9124, 1.0777, 1.0777, 1.0777], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 863 was 52.9%\n",
      "current params: tensor([0.9123, 1.0778, 1.0778, 1.0778], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 864 was 52.9%\n",
      "current params: tensor([0.9122, 1.0779, 1.0779, 1.0779], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 865 was 52.9%\n",
      "current params: tensor([0.9121, 1.0779, 1.0780, 1.0780], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 866 was 52.9%\n",
      "current params: tensor([0.9120, 1.0780, 1.0780, 1.0780], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 867 was 52.9%\n",
      "current params: tensor([0.9119, 1.0781, 1.0781, 1.0781], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 868 was 52.9%\n",
      "current params: tensor([0.9118, 1.0782, 1.0782, 1.0782], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 869 was 52.9%\n",
      "current params: tensor([0.9117, 1.0783, 1.0783, 1.0783], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 870 was 52.9%\n",
      "current params: tensor([0.9116, 1.0784, 1.0784, 1.0784], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 871 was 52.9%\n",
      "current params: tensor([0.9115, 1.0785, 1.0785, 1.0785], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 872 was 52.9%\n",
      "current params: tensor([0.9114, 1.0786, 1.0785, 1.0786], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 873 was 52.9%\n",
      "current params: tensor([0.9113, 1.0787, 1.0786, 1.0787], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 874 was 52.9%\n",
      "current params: tensor([0.9112, 1.0787, 1.0787, 1.0788], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 875 was 52.9%\n",
      "current params: tensor([0.9111, 1.0788, 1.0788, 1.0788], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 876 was 52.9%\n",
      "current params: tensor([0.9110, 1.0789, 1.0789, 1.0789], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 877 was 52.9%\n",
      "current params: tensor([0.9109, 1.0790, 1.0790, 1.0790], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 878 was 52.9%\n",
      "current params: tensor([0.9107, 1.0791, 1.0791, 1.0791], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 879 was 52.9%\n",
      "current params: tensor([0.9106, 1.0792, 1.0792, 1.0792], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 880 was 52.9%\n",
      "current params: tensor([0.9105, 1.0793, 1.0793, 1.0792], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 881 was 52.9%\n",
      "current params: tensor([0.9104, 1.0794, 1.0794, 1.0793], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 882 was 52.9%\n",
      "current params: tensor([0.9103, 1.0795, 1.0794, 1.0794], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 883 was 52.9%\n",
      "current params: tensor([0.9102, 1.0795, 1.0795, 1.0795], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 884 was 52.9%\n",
      "current params: tensor([0.9101, 1.0796, 1.0796, 1.0796], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 885 was 52.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9100, 1.0797, 1.0797, 1.0797], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 886 was 52.9%\n",
      "current params: tensor([0.9099, 1.0798, 1.0798, 1.0798], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 887 was 52.9%\n",
      "current params: tensor([0.9098, 1.0799, 1.0799, 1.0799], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 888 was 53.0%\n",
      "current params: tensor([0.9097, 1.0800, 1.0800, 1.0800], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 889 was 53.0%\n",
      "current params: tensor([0.9096, 1.0801, 1.0801, 1.0801], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 890 was 53.0%\n",
      "current params: tensor([0.9095, 1.0802, 1.0802, 1.0801], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0190, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 891 was 53.0%\n",
      "current params: tensor([0.9094, 1.0802, 1.0802, 1.0802], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 892 was 53.0%\n",
      "current params: tensor([0.9093, 1.0803, 1.0803, 1.0803], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 893 was 53.0%\n",
      "current params: tensor([0.9092, 1.0804, 1.0804, 1.0804], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 894 was 53.0%\n",
      "current params: tensor([0.9091, 1.0805, 1.0805, 1.0805], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 895 was 53.0%\n",
      "current params: tensor([0.9090, 1.0806, 1.0806, 1.0806], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 896 was 53.0%\n",
      "current params: tensor([0.9089, 1.0807, 1.0807, 1.0807], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 897 was 53.0%\n",
      "current params: tensor([0.9088, 1.0808, 1.0807, 1.0808], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 898 was 53.0%\n",
      "current params: tensor([0.9087, 1.0808, 1.0808, 1.0809], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 899 was 53.0%\n",
      "current params: tensor([0.9086, 1.0809, 1.0809, 1.0809], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 900 was 53.0%\n",
      "current params: tensor([0.9085, 1.0810, 1.0810, 1.0810], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 901 was 53.0%\n",
      "current params: tensor([0.9084, 1.0811, 1.0811, 1.0811], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 902 was 53.0%\n",
      "current params: tensor([0.9083, 1.0812, 1.0812, 1.0812], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 903 was 53.0%\n",
      "current params: tensor([0.9082, 1.0813, 1.0813, 1.0813], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 904 was 53.0%\n",
      "current params: tensor([0.9081, 1.0814, 1.0814, 1.0814], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 905 was 53.0%\n",
      "current params: tensor([0.9080, 1.0815, 1.0815, 1.0815], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 906 was 53.0%\n",
      "current params: tensor([0.9079, 1.0815, 1.0815, 1.0815], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 907 was 53.0%\n",
      "current params: tensor([0.9077, 1.0816, 1.0816, 1.0816], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 908 was 53.0%\n",
      "current params: tensor([0.9076, 1.0817, 1.0817, 1.0817], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 909 was 53.0%\n",
      "current params: tensor([0.9075, 1.0818, 1.0818, 1.0818], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 910 was 53.0%\n",
      "current params: tensor([0.9074, 1.0819, 1.0819, 1.0819], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 911 was 53.0%\n",
      "current params: tensor([0.9073, 1.0820, 1.0820, 1.0820], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 912 was 53.0%\n",
      "current params: tensor([0.9072, 1.0821, 1.0821, 1.0821], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 913 was 53.0%\n",
      "current params: tensor([0.9071, 1.0821, 1.0822, 1.0822], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 914 was 53.0%\n",
      "current params: tensor([0.9070, 1.0822, 1.0823, 1.0823], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 915 was 53.0%\n",
      "current params: tensor([0.9069, 1.0823, 1.0823, 1.0823], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 916 was 53.1%\n",
      "current params: tensor([0.9068, 1.0824, 1.0824, 1.0824], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 917 was 53.1%\n",
      "current params: tensor([0.9067, 1.0825, 1.0825, 1.0825], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 918 was 53.1%\n",
      "current params: tensor([0.9066, 1.0826, 1.0826, 1.0826], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 919 was 53.1%\n",
      "current params: tensor([0.9065, 1.0827, 1.0827, 1.0827], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 920 was 53.1%\n",
      "current params: tensor([0.9064, 1.0828, 1.0828, 1.0828], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 921 was 53.1%\n",
      "current params: tensor([0.9063, 1.0829, 1.0828, 1.0829], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 922 was 53.1%\n",
      "current params: tensor([0.9062, 1.0830, 1.0829, 1.0829], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 923 was 53.1%\n",
      "current params: tensor([0.9061, 1.0830, 1.0830, 1.0830], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 924 was 53.1%\n",
      "current params: tensor([0.9060, 1.0831, 1.0831, 1.0831], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 925 was 53.1%\n",
      "current params: tensor([0.9059, 1.0832, 1.0832, 1.0832], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 926 was 53.1%\n",
      "current params: tensor([0.9058, 1.0833, 1.0833, 1.0833], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 927 was 53.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9057, 1.0834, 1.0834, 1.0834], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 928 was 53.1%\n",
      "current params: tensor([0.9056, 1.0835, 1.0835, 1.0835], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 929 was 53.1%\n",
      "current params: tensor([0.9055, 1.0836, 1.0836, 1.0835], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 930 was 53.1%\n",
      "current params: tensor([0.9054, 1.0836, 1.0837, 1.0836], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 931 was 53.1%\n",
      "current params: tensor([0.9053, 1.0837, 1.0837, 1.0837], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 932 was 53.1%\n",
      "current params: tensor([0.9052, 1.0838, 1.0838, 1.0838], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0175, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 933 was 53.1%\n",
      "current params: tensor([0.9051, 1.0839, 1.0839, 1.0839], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 934 was 53.1%\n",
      "current params: tensor([0.9050, 1.0840, 1.0840, 1.0840], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 935 was 53.1%\n",
      "current params: tensor([0.9049, 1.0841, 1.0841, 1.0841], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 936 was 53.1%\n",
      "current params: tensor([0.9047, 1.0842, 1.0842, 1.0842], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 937 was 53.1%\n",
      "current params: tensor([0.9046, 1.0843, 1.0842, 1.0843], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 938 was 53.1%\n",
      "current params: tensor([0.9045, 1.0843, 1.0843, 1.0843], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 939 was 53.1%\n",
      "current params: tensor([0.9044, 1.0844, 1.0844, 1.0844], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 940 was 53.1%\n",
      "current params: tensor([0.9043, 1.0845, 1.0845, 1.0845], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 941 was 53.1%\n",
      "current params: tensor([0.9042, 1.0846, 1.0846, 1.0846], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 942 was 53.1%\n",
      "current params: tensor([0.9041, 1.0847, 1.0847, 1.0847], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 943 was 53.2%\n",
      "current params: tensor([0.9040, 1.0848, 1.0848, 1.0848], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 944 was 53.2%\n",
      "current params: tensor([0.9039, 1.0849, 1.0849, 1.0849], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 945 was 53.2%\n",
      "current params: tensor([0.9038, 1.0850, 1.0849, 1.0850], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 946 was 53.2%\n",
      "current params: tensor([0.9037, 1.0850, 1.0850, 1.0851], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0170, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 947 was 53.2%\n",
      "current params: tensor([0.9036, 1.0851, 1.0851, 1.0851], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 948 was 53.2%\n",
      "current params: tensor([0.9035, 1.0852, 1.0852, 1.0852], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 949 was 53.2%\n",
      "current params: tensor([0.9034, 1.0853, 1.0853, 1.0853], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 950 was 53.2%\n",
      "current params: tensor([0.9033, 1.0854, 1.0854, 1.0854], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 951 was 53.2%\n",
      "current params: tensor([0.9032, 1.0855, 1.0855, 1.0855], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 952 was 53.2%\n",
      "current params: tensor([0.9031, 1.0856, 1.0856, 1.0856], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 953 was 53.2%\n",
      "current params: tensor([0.9030, 1.0857, 1.0856, 1.0857], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 954 was 53.2%\n",
      "current params: tensor([0.9029, 1.0857, 1.0857, 1.0857], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 955 was 53.2%\n",
      "current params: tensor([0.9028, 1.0858, 1.0858, 1.0858], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 956 was 53.2%\n",
      "current params: tensor([0.9027, 1.0859, 1.0859, 1.0859], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 957 was 53.2%\n",
      "current params: tensor([0.9026, 1.0860, 1.0860, 1.0860], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 958 was 53.2%\n",
      "current params: tensor([0.9025, 1.0861, 1.0861, 1.0861], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 959 was 53.2%\n",
      "current params: tensor([0.9024, 1.0862, 1.0862, 1.0862], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 960 was 53.2%\n",
      "current params: tensor([0.9023, 1.0863, 1.0863, 1.0863], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 961 was 53.2%\n",
      "current params: tensor([0.9022, 1.0864, 1.0863, 1.0864], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 962 was 53.2%\n",
      "current params: tensor([0.9021, 1.0864, 1.0864, 1.0864], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 963 was 53.2%\n",
      "current params: tensor([0.9020, 1.0865, 1.0865, 1.0865], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 964 was 53.2%\n",
      "current params: tensor([0.9018, 1.0866, 1.0866, 1.0866], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 965 was 53.2%\n",
      "current params: tensor([0.9017, 1.0867, 1.0867, 1.0867], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 966 was 53.2%\n",
      "current params: tensor([0.9016, 1.0868, 1.0868, 1.0868], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 967 was 53.2%\n",
      "current params: tensor([0.9015, 1.0869, 1.0869, 1.0869], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 968 was 53.2%\n",
      "current params: tensor([0.9014, 1.0870, 1.0870, 1.0870], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 969 was 53.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.9013, 1.0871, 1.0871, 1.0870], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 970 was 53.3%\n",
      "current params: tensor([0.9012, 1.0871, 1.0871, 1.0871], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 971 was 53.3%\n",
      "current params: tensor([0.9011, 1.0872, 1.0872, 1.0872], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 972 was 53.3%\n",
      "current params: tensor([0.9010, 1.0873, 1.0873, 1.0873], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 973 was 53.3%\n",
      "current params: tensor([0.9009, 1.0874, 1.0874, 1.0874], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 974 was 53.3%\n",
      "current params: tensor([0.9008, 1.0875, 1.0875, 1.0875], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 975 was 53.3%\n",
      "current params: tensor([0.9007, 1.0876, 1.0876, 1.0876], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 976 was 53.3%\n",
      "current params: tensor([0.9006, 1.0877, 1.0877, 1.0877], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 977 was 53.3%\n",
      "current params: tensor([0.9005, 1.0877, 1.0877, 1.0878], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 978 was 53.3%\n",
      "current params: tensor([0.9004, 1.0878, 1.0878, 1.0878], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 979 was 53.3%\n",
      "current params: tensor([0.9003, 1.0879, 1.0879, 1.0879], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 980 was 53.3%\n",
      "current params: tensor([0.9002, 1.0880, 1.0880, 1.0880], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 981 was 53.3%\n",
      "current params: tensor([0.9001, 1.0881, 1.0881, 1.0881], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 982 was 53.3%\n",
      "current params: tensor([0.9000, 1.0882, 1.0882, 1.0882], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 983 was 53.3%\n",
      "current params: tensor([0.8999, 1.0882, 1.0883, 1.0883], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 984 was 53.3%\n",
      "current params: tensor([0.8998, 1.0883, 1.0884, 1.0884], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 985 was 53.3%\n",
      "current params: tensor([0.8997, 1.0884, 1.0885, 1.0884], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 986 was 53.3%\n",
      "current params: tensor([0.8996, 1.0885, 1.0885, 1.0885], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 987 was 53.3%\n",
      "current params: tensor([0.8995, 1.0886, 1.0886, 1.0886], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 988 was 53.3%\n",
      "current params: tensor([0.8994, 1.0887, 1.0887, 1.0887], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 989 was 53.3%\n",
      "current params: tensor([0.8993, 1.0888, 1.0888, 1.0888], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 990 was 53.3%\n",
      "current params: tensor([0.8992, 1.0889, 1.0889, 1.0889], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 991 was 53.3%\n",
      "current params: tensor([0.8990, 1.0890, 1.0889, 1.0890], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 992 was 53.3%\n",
      "current params: tensor([0.8989, 1.0891, 1.0890, 1.0891], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 993 was 53.3%\n",
      "current params: tensor([0.8988, 1.0891, 1.0891, 1.0891], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 994 was 53.3%\n",
      "current params: tensor([0.8987, 1.0892, 1.0892, 1.0892], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 995 was 53.3%\n",
      "current params: tensor([0.8986, 1.0893, 1.0893, 1.0893], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 996 was 53.3%\n",
      "current params: tensor([0.8985, 1.0894, 1.0894, 1.0894], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 997 was 53.4%\n",
      "current params: tensor([0.8984, 1.0895, 1.0895, 1.0895], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 998 was 53.4%\n",
      "current params: tensor([0.8983, 1.0896, 1.0896, 1.0896], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 999 was 53.4%\n",
      "current params: tensor([0.8982, 1.0897, 1.0897, 1.0897], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1000 was 53.4%\n",
      "current params: tensor([0.8981, 1.0898, 1.0898, 1.0897], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1001 was 53.4%\n",
      "current params: tensor([0.8980, 1.0898, 1.0898, 1.0898], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1002 was 53.4%\n",
      "current params: tensor([0.8979, 1.0899, 1.0899, 1.0899], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1003 was 53.4%\n",
      "current params: tensor([0.8978, 1.0900, 1.0900, 1.0900], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1004 was 53.4%\n",
      "current params: tensor([0.8977, 1.0901, 1.0901, 1.0901], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1005 was 53.4%\n",
      "current params: tensor([0.8976, 1.0902, 1.0902, 1.0902], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1006 was 53.4%\n",
      "current params: tensor([0.8975, 1.0903, 1.0903, 1.0903], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1007 was 53.4%\n",
      "current params: tensor([0.8974, 1.0904, 1.0904, 1.0904], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1008 was 53.4%\n",
      "current params: tensor([0.8973, 1.0905, 1.0905, 1.0904], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1009 was 53.4%\n",
      "current params: tensor([0.8972, 1.0906, 1.0905, 1.0905], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1010 was 53.4%\n",
      "current params: tensor([0.8971, 1.0906, 1.0906, 1.0906], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1011 was 53.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8970, 1.0907, 1.0907, 1.0907], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1012 was 53.4%\n",
      "current params: tensor([0.8969, 1.0908, 1.0908, 1.0908], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1013 was 53.4%\n",
      "current params: tensor([0.8968, 1.0909, 1.0909, 1.0909], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1014 was 53.4%\n",
      "current params: tensor([0.8967, 1.0910, 1.0910, 1.0910], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1015 was 53.4%\n",
      "current params: tensor([0.8966, 1.0910, 1.0911, 1.0911], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1016 was 53.4%\n",
      "current params: tensor([0.8965, 1.0911, 1.0912, 1.0911], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1017 was 53.4%\n",
      "current params: tensor([0.8963, 1.0912, 1.0912, 1.0912], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1018 was 53.4%\n",
      "current params: tensor([0.8962, 1.0913, 1.0913, 1.0913], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1019 was 53.4%\n",
      "current params: tensor([0.8961, 1.0914, 1.0914, 1.0914], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1020 was 53.4%\n",
      "current params: tensor([0.8960, 1.0915, 1.0915, 1.0915], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1021 was 53.4%\n",
      "current params: tensor([0.8959, 1.0916, 1.0916, 1.0916], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1022 was 53.4%\n",
      "current params: tensor([0.8958, 1.0917, 1.0917, 1.0917], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1023 was 53.4%\n",
      "current params: tensor([0.8957, 1.0918, 1.0918, 1.0917], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1024 was 53.5%\n",
      "current params: tensor([0.8956, 1.0918, 1.0918, 1.0918], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1025 was 53.5%\n",
      "current params: tensor([0.8955, 1.0919, 1.0919, 1.0919], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1026 was 53.5%\n",
      "current params: tensor([0.8954, 1.0920, 1.0920, 1.0920], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1027 was 53.5%\n",
      "current params: tensor([0.8953, 1.0921, 1.0921, 1.0921], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1028 was 53.5%\n",
      "current params: tensor([0.8952, 1.0922, 1.0922, 1.0922], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1029 was 53.5%\n",
      "current params: tensor([0.8951, 1.0923, 1.0923, 1.0923], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1030 was 53.5%\n",
      "current params: tensor([0.8950, 1.0923, 1.0924, 1.0924], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1031 was 53.5%\n",
      "current params: tensor([0.8949, 1.0924, 1.0925, 1.0924], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1032 was 53.5%\n",
      "current params: tensor([0.8948, 1.0925, 1.0925, 1.0925], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1033 was 53.5%\n",
      "current params: tensor([0.8947, 1.0926, 1.0926, 1.0926], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1034 was 53.5%\n",
      "current params: tensor([0.8946, 1.0927, 1.0927, 1.0927], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1035 was 53.5%\n",
      "current params: tensor([0.8945, 1.0928, 1.0928, 1.0928], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1036 was 53.5%\n",
      "current params: tensor([0.8944, 1.0929, 1.0929, 1.0929], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1037 was 53.5%\n",
      "current params: tensor([0.8943, 1.0930, 1.0930, 1.0930], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1038 was 53.5%\n",
      "current params: tensor([0.8942, 1.0931, 1.0931, 1.0931], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1039 was 53.5%\n",
      "current params: tensor([0.8941, 1.0931, 1.0931, 1.0931], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1040 was 53.5%\n",
      "current params: tensor([0.8940, 1.0932, 1.0932, 1.0932], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1041 was 53.5%\n",
      "current params: tensor([0.8939, 1.0933, 1.0933, 1.0933], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1042 was 53.5%\n",
      "current params: tensor([0.8938, 1.0934, 1.0934, 1.0934], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1043 was 53.5%\n",
      "current params: tensor([0.8936, 1.0935, 1.0935, 1.0935], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1044 was 53.5%\n",
      "current params: tensor([0.8935, 1.0936, 1.0936, 1.0935], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1045 was 53.5%\n",
      "current params: tensor([0.8934, 1.0937, 1.0937, 1.0936], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1046 was 53.5%\n",
      "current params: tensor([0.8933, 1.0938, 1.0938, 1.0937], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1047 was 53.5%\n",
      "current params: tensor([0.8932, 1.0938, 1.0938, 1.0938], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1048 was 53.5%\n",
      "current params: tensor([0.8931, 1.0939, 1.0939, 1.0939], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1049 was 53.5%\n",
      "current params: tensor([0.8930, 1.0940, 1.0940, 1.0940], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1050 was 53.5%\n",
      "current params: tensor([0.8929, 1.0941, 1.0941, 1.0941], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1051 was 53.6%\n",
      "current params: tensor([0.8928, 1.0942, 1.0942, 1.0942], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1052 was 53.6%\n",
      "current params: tensor([0.8927, 1.0943, 1.0943, 1.0943], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1053 was 53.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8926, 1.0944, 1.0944, 1.0944], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1054 was 53.6%\n",
      "current params: tensor([0.8925, 1.0944, 1.0945, 1.0944], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1055 was 53.6%\n",
      "current params: tensor([0.8924, 1.0945, 1.0945, 1.0945], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1056 was 53.6%\n",
      "current params: tensor([0.8923, 1.0946, 1.0946, 1.0946], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1057 was 53.6%\n",
      "current params: tensor([0.8922, 1.0947, 1.0947, 1.0947], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1058 was 53.6%\n",
      "current params: tensor([0.8921, 1.0948, 1.0948, 1.0948], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1059 was 53.6%\n",
      "current params: tensor([0.8920, 1.0949, 1.0949, 1.0949], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1060 was 53.6%\n",
      "current params: tensor([0.8919, 1.0950, 1.0950, 1.0950], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1061 was 53.6%\n",
      "current params: tensor([0.8918, 1.0951, 1.0951, 1.0950], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1062 was 53.6%\n",
      "current params: tensor([0.8917, 1.0952, 1.0951, 1.0951], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1063 was 53.6%\n",
      "current params: tensor([0.8916, 1.0952, 1.0952, 1.0952], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1064 was 53.6%\n",
      "current params: tensor([0.8915, 1.0953, 1.0953, 1.0953], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1065 was 53.6%\n",
      "current params: tensor([0.8914, 1.0954, 1.0954, 1.0954], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1066 was 53.6%\n",
      "current params: tensor([0.8913, 1.0955, 1.0955, 1.0955], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1067 was 53.6%\n",
      "current params: tensor([0.8912, 1.0956, 1.0956, 1.0956], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1068 was 53.6%\n",
      "current params: tensor([0.8910, 1.0957, 1.0957, 1.0957], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1069 was 53.6%\n",
      "current params: tensor([0.8909, 1.0958, 1.0957, 1.0957], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1070 was 53.6%\n",
      "current params: tensor([0.8908, 1.0958, 1.0958, 1.0958], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1071 was 53.6%\n",
      "current params: tensor([0.8907, 1.0959, 1.0959, 1.0959], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1072 was 53.6%\n",
      "current params: tensor([0.8906, 1.0960, 1.0960, 1.0960], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1073 was 53.6%\n",
      "current params: tensor([0.8905, 1.0961, 1.0961, 1.0961], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1074 was 53.6%\n",
      "current params: tensor([0.8904, 1.0962, 1.0962, 1.0962], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1075 was 53.6%\n",
      "current params: tensor([0.8903, 1.0963, 1.0963, 1.0963], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1076 was 53.6%\n",
      "current params: tensor([0.8902, 1.0964, 1.0964, 1.0964], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1077 was 53.6%\n",
      "current params: tensor([0.8901, 1.0964, 1.0964, 1.0964], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1078 was 53.6%\n",
      "current params: tensor([0.8900, 1.0965, 1.0965, 1.0965], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1079 was 53.7%\n",
      "current params: tensor([0.8899, 1.0966, 1.0966, 1.0966], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1080 was 53.7%\n",
      "current params: tensor([0.8898, 1.0967, 1.0967, 1.0967], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1081 was 53.7%\n",
      "current params: tensor([0.8897, 1.0968, 1.0968, 1.0968], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1082 was 53.7%\n",
      "current params: tensor([0.8896, 1.0969, 1.0969, 1.0969], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1083 was 53.7%\n",
      "current params: tensor([0.8895, 1.0970, 1.0970, 1.0970], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1084 was 53.7%\n",
      "current params: tensor([0.8894, 1.0971, 1.0970, 1.0970], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1085 was 53.7%\n",
      "current params: tensor([0.8893, 1.0971, 1.0971, 1.0971], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1086 was 53.7%\n",
      "current params: tensor([0.8892, 1.0972, 1.0972, 1.0972], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1087 was 53.7%\n",
      "current params: tensor([0.8891, 1.0973, 1.0973, 1.0973], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1088 was 53.7%\n",
      "current params: tensor([0.8890, 1.0974, 1.0974, 1.0974], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1089 was 53.7%\n",
      "current params: tensor([0.8889, 1.0975, 1.0975, 1.0975], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1090 was 53.7%\n",
      "current params: tensor([0.8888, 1.0976, 1.0976, 1.0976], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1091 was 53.7%\n",
      "current params: tensor([0.8887, 1.0977, 1.0977, 1.0977], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1092 was 53.7%\n",
      "current params: tensor([0.8886, 1.0977, 1.0977, 1.0977], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1093 was 53.7%\n",
      "current params: tensor([0.8884, 1.0978, 1.0978, 1.0978], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1094 was 53.7%\n",
      "current params: tensor([0.8883, 1.0979, 1.0979, 1.0979], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1095 was 53.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8882, 1.0980, 1.0980, 1.0980], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1096 was 53.7%\n",
      "current params: tensor([0.8881, 1.0981, 1.0981, 1.0981], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1097 was 53.7%\n",
      "current params: tensor([0.8880, 1.0982, 1.0982, 1.0982], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1098 was 53.7%\n",
      "current params: tensor([0.8879, 1.0983, 1.0983, 1.0983], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1099 was 53.7%\n",
      "current params: tensor([0.8878, 1.0983, 1.0983, 1.0983], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1100 was 53.7%\n",
      "current params: tensor([0.8877, 1.0984, 1.0984, 1.0984], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1101 was 53.7%\n",
      "current params: tensor([0.8876, 1.0985, 1.0985, 1.0985], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1102 was 53.7%\n",
      "current params: tensor([0.8875, 1.0986, 1.0986, 1.0986], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1103 was 53.7%\n",
      "current params: tensor([0.8874, 1.0987, 1.0987, 1.0987], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1104 was 53.7%\n",
      "current params: tensor([0.8873, 1.0988, 1.0988, 1.0988], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1105 was 53.7%\n",
      "current params: tensor([0.8872, 1.0989, 1.0989, 1.0989], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1106 was 53.8%\n",
      "current params: tensor([0.8871, 1.0989, 1.0990, 1.0990], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1107 was 53.8%\n",
      "current params: tensor([0.8870, 1.0990, 1.0990, 1.0990], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1108 was 53.8%\n",
      "current params: tensor([0.8869, 1.0991, 1.0991, 1.0991], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1109 was 53.8%\n",
      "current params: tensor([0.8868, 1.0992, 1.0992, 1.0992], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1110 was 53.8%\n",
      "current params: tensor([0.8867, 1.0993, 1.0993, 1.0993], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1111 was 53.8%\n",
      "current params: tensor([0.8866, 1.0994, 1.0994, 1.0994], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1112 was 53.8%\n",
      "current params: tensor([0.8865, 1.0995, 1.0995, 1.0995], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1113 was 53.8%\n",
      "current params: tensor([0.8864, 1.0996, 1.0996, 1.0996], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1114 was 53.8%\n",
      "current params: tensor([0.8863, 1.0996, 1.0997, 1.0997], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1115 was 53.8%\n",
      "current params: tensor([0.8862, 1.0997, 1.0997, 1.0997], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1116 was 53.8%\n",
      "current params: tensor([0.8861, 1.0998, 1.0998, 1.0998], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1117 was 53.8%\n",
      "current params: tensor([0.8860, 1.0999, 1.0999, 1.0999], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1118 was 53.8%\n",
      "current params: tensor([0.8858, 1.1000, 1.1000, 1.1000], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1119 was 53.8%\n",
      "current params: tensor([0.8857, 1.1001, 1.1001, 1.1001], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1120 was 53.8%\n",
      "current params: tensor([0.8856, 1.1002, 1.1002, 1.1002], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1121 was 53.8%\n",
      "current params: tensor([0.8855, 1.1003, 1.1002, 1.1002], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1122 was 53.8%\n",
      "current params: tensor([0.8854, 1.1004, 1.1003, 1.1003], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1123 was 53.8%\n",
      "current params: tensor([0.8853, 1.1004, 1.1004, 1.1004], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1124 was 53.8%\n",
      "current params: tensor([0.8852, 1.1005, 1.1005, 1.1005], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1125 was 53.8%\n",
      "current params: tensor([0.8851, 1.1006, 1.1006, 1.1006], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1126 was 53.8%\n",
      "current params: tensor([0.8850, 1.1007, 1.1007, 1.1007], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1127 was 53.8%\n",
      "current params: tensor([0.8849, 1.1008, 1.1008, 1.1008], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1128 was 53.8%\n",
      "current params: tensor([0.8848, 1.1008, 1.1009, 1.1009], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1129 was 53.8%\n",
      "current params: tensor([0.8847, 1.1009, 1.1010, 1.1009], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1130 was 53.8%\n",
      "current params: tensor([0.8846, 1.1010, 1.1010, 1.1010], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1131 was 53.8%\n",
      "current params: tensor([0.8845, 1.1011, 1.1011, 1.1011], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1132 was 53.8%\n",
      "current params: tensor([0.8844, 1.1012, 1.1012, 1.1012], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1133 was 53.9%\n",
      "current params: tensor([0.8843, 1.1013, 1.1013, 1.1013], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1134 was 53.9%\n",
      "current params: tensor([0.8842, 1.1014, 1.1014, 1.1014], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1135 was 53.9%\n",
      "current params: tensor([0.8841, 1.1015, 1.1015, 1.1015], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1136 was 53.9%\n",
      "current params: tensor([0.8840, 1.1016, 1.1015, 1.1016], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1137 was 53.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8839, 1.1016, 1.1016, 1.1016], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1138 was 53.9%\n",
      "current params: tensor([0.8838, 1.1017, 1.1017, 1.1017], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1139 was 53.9%\n",
      "current params: tensor([0.8837, 1.1018, 1.1018, 1.1018], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1140 was 53.9%\n",
      "current params: tensor([0.8836, 1.1019, 1.1019, 1.1019], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1141 was 53.9%\n",
      "current params: tensor([0.8834, 1.1020, 1.1020, 1.1020], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1142 was 53.9%\n",
      "current params: tensor([0.8833, 1.1021, 1.1021, 1.1021], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1143 was 53.9%\n",
      "current params: tensor([0.8832, 1.1022, 1.1021, 1.1022], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1144 was 53.9%\n",
      "current params: tensor([0.8831, 1.1022, 1.1022, 1.1022], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1145 was 53.9%\n",
      "current params: tensor([0.8830, 1.1023, 1.1023, 1.1023], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1146 was 53.9%\n",
      "current params: tensor([0.8829, 1.1024, 1.1024, 1.1024], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1147 was 53.9%\n",
      "current params: tensor([0.8828, 1.1025, 1.1025, 1.1025], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1148 was 53.9%\n",
      "current params: tensor([0.8827, 1.1026, 1.1026, 1.1026], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1149 was 53.9%\n",
      "current params: tensor([0.8826, 1.1027, 1.1027, 1.1027], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1150 was 53.9%\n",
      "current params: tensor([0.8825, 1.1028, 1.1028, 1.1028], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1151 was 53.9%\n",
      "current params: tensor([0.8824, 1.1029, 1.1028, 1.1029], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1152 was 53.9%\n",
      "current params: tensor([0.8823, 1.1029, 1.1029, 1.1029], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1153 was 53.9%\n",
      "current params: tensor([0.8822, 1.1030, 1.1030, 1.1030], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1154 was 53.9%\n",
      "current params: tensor([0.8821, 1.1031, 1.1031, 1.1031], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1155 was 53.9%\n",
      "current params: tensor([0.8820, 1.1032, 1.1032, 1.1032], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1156 was 53.9%\n",
      "current params: tensor([0.8819, 1.1033, 1.1033, 1.1033], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1157 was 53.9%\n",
      "current params: tensor([0.8818, 1.1034, 1.1034, 1.1034], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1158 was 53.9%\n",
      "current params: tensor([0.8817, 1.1035, 1.1035, 1.1034], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1159 was 53.9%\n",
      "current params: tensor([0.8816, 1.1035, 1.1035, 1.1035], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1160 was 54.0%\n",
      "current params: tensor([0.8815, 1.1036, 1.1036, 1.1036], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1161 was 54.0%\n",
      "current params: tensor([0.8814, 1.1037, 1.1037, 1.1037], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1162 was 54.0%\n",
      "current params: tensor([0.8813, 1.1038, 1.1038, 1.1038], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1163 was 54.0%\n",
      "current params: tensor([0.8812, 1.1039, 1.1039, 1.1039], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1164 was 54.0%\n",
      "current params: tensor([0.8811, 1.1040, 1.1040, 1.1040], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1165 was 54.0%\n",
      "current params: tensor([0.8809, 1.1041, 1.1041, 1.1041], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1166 was 54.0%\n",
      "current params: tensor([0.8808, 1.1041, 1.1041, 1.1042], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1167 was 54.0%\n",
      "current params: tensor([0.8807, 1.1042, 1.1042, 1.1042], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1168 was 54.0%\n",
      "current params: tensor([0.8806, 1.1043, 1.1043, 1.1043], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1169 was 54.0%\n",
      "current params: tensor([0.8805, 1.1044, 1.1044, 1.1044], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1170 was 54.0%\n",
      "current params: tensor([0.8804, 1.1045, 1.1045, 1.1045], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1171 was 54.0%\n",
      "current params: tensor([0.8803, 1.1046, 1.1046, 1.1046], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1172 was 54.0%\n",
      "current params: tensor([0.8802, 1.1047, 1.1047, 1.1046], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1173 was 54.0%\n",
      "current params: tensor([0.8801, 1.1048, 1.1048, 1.1047], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1174 was 54.0%\n",
      "current params: tensor([0.8800, 1.1048, 1.1048, 1.1048], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1175 was 54.0%\n",
      "current params: tensor([0.8799, 1.1049, 1.1049, 1.1049], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1176 was 54.0%\n",
      "current params: tensor([0.8798, 1.1050, 1.1050, 1.1050], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1177 was 54.0%\n",
      "current params: tensor([0.8797, 1.1051, 1.1051, 1.1051], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1178 was 54.0%\n",
      "current params: tensor([0.8796, 1.1052, 1.1052, 1.1052], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1179 was 54.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8795, 1.1052, 1.1053, 1.1053], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1180 was 54.0%\n",
      "current params: tensor([0.8794, 1.1053, 1.1054, 1.1054], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1181 was 54.0%\n",
      "current params: tensor([0.8793, 1.1054, 1.1055, 1.1054], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1182 was 54.0%\n",
      "current params: tensor([0.8792, 1.1055, 1.1055, 1.1055], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1183 was 54.0%\n",
      "current params: tensor([0.8791, 1.1056, 1.1056, 1.1056], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1184 was 54.0%\n",
      "current params: tensor([0.8790, 1.1057, 1.1057, 1.1057], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1185 was 54.0%\n",
      "current params: tensor([0.8789, 1.1058, 1.1058, 1.1058], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1186 was 54.0%\n",
      "current params: tensor([0.8788, 1.1059, 1.1059, 1.1059], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1187 was 54.1%\n",
      "current params: tensor([0.8787, 1.1060, 1.1060, 1.1060], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1188 was 54.1%\n",
      "current params: tensor([0.8785, 1.1060, 1.1060, 1.1060], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1189 was 54.1%\n",
      "current params: tensor([0.8784, 1.1061, 1.1061, 1.1061], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1190 was 54.1%\n",
      "current params: tensor([0.8783, 1.1062, 1.1062, 1.1062], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1191 was 54.1%\n",
      "current params: tensor([0.8782, 1.1063, 1.1063, 1.1063], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1192 was 54.1%\n",
      "current params: tensor([0.8781, 1.1064, 1.1064, 1.1064], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1193 was 54.1%\n",
      "current params: tensor([0.8780, 1.1065, 1.1065, 1.1065], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1194 was 54.1%\n",
      "current params: tensor([0.8779, 1.1066, 1.1066, 1.1066], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1195 was 54.1%\n",
      "current params: tensor([0.8778, 1.1066, 1.1066, 1.1067], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1196 was 54.1%\n",
      "current params: tensor([0.8777, 1.1067, 1.1067, 1.1067], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1197 was 54.1%\n",
      "current params: tensor([0.8776, 1.1068, 1.1068, 1.1068], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1198 was 54.1%\n",
      "current params: tensor([0.8775, 1.1069, 1.1069, 1.1069], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1199 was 54.1%\n",
      "current params: tensor([0.8774, 1.1070, 1.1070, 1.1070], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1200 was 54.1%\n",
      "current params: tensor([0.8773, 1.1071, 1.1071, 1.1071], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1201 was 54.1%\n",
      "current params: tensor([0.8772, 1.1072, 1.1072, 1.1072], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1202 was 54.1%\n",
      "current params: tensor([0.8771, 1.1073, 1.1072, 1.1072], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1203 was 54.1%\n",
      "current params: tensor([0.8770, 1.1073, 1.1073, 1.1073], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1204 was 54.1%\n",
      "current params: tensor([0.8769, 1.1074, 1.1074, 1.1074], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1205 was 54.1%\n",
      "current params: tensor([0.8768, 1.1075, 1.1075, 1.1075], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1206 was 54.1%\n",
      "current params: tensor([0.8767, 1.1076, 1.1076, 1.1076], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1207 was 54.1%\n",
      "current params: tensor([0.8766, 1.1077, 1.1077, 1.1077], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1208 was 54.1%\n",
      "current params: tensor([0.8765, 1.1078, 1.1078, 1.1078], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1209 was 54.1%\n",
      "current params: tensor([0.8764, 1.1078, 1.1079, 1.1078], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1210 was 54.1%\n",
      "current params: tensor([0.8763, 1.1079, 1.1079, 1.1079], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1211 was 54.1%\n",
      "current params: tensor([0.8761, 1.1080, 1.1080, 1.1080], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1212 was 54.1%\n",
      "current params: tensor([0.8760, 1.1081, 1.1081, 1.1081], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1213 was 54.1%\n",
      "current params: tensor([0.8759, 1.1082, 1.1082, 1.1082], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1214 was 54.2%\n",
      "current params: tensor([0.8758, 1.1083, 1.1083, 1.1083], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1215 was 54.2%\n",
      "current params: tensor([0.8757, 1.1084, 1.1084, 1.1084], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1216 was 54.2%\n",
      "current params: tensor([0.8756, 1.1085, 1.1085, 1.1085], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1217 was 54.2%\n",
      "current params: tensor([0.8755, 1.1085, 1.1085, 1.1085], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1218 was 54.2%\n",
      "current params: tensor([0.8754, 1.1086, 1.1086, 1.1086], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1219 was 54.2%\n",
      "current params: tensor([0.8753, 1.1087, 1.1087, 1.1087], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1220 was 54.2%\n",
      "current params: tensor([0.8752, 1.1088, 1.1088, 1.1088], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1221 was 54.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8751, 1.1089, 1.1089, 1.1089], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1222 was 54.2%\n",
      "current params: tensor([0.8750, 1.1090, 1.1090, 1.1090], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1223 was 54.2%\n",
      "current params: tensor([0.8749, 1.1091, 1.1091, 1.1091], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1224 was 54.2%\n",
      "current params: tensor([0.8748, 1.1092, 1.1091, 1.1091], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1225 was 54.2%\n",
      "current params: tensor([0.8747, 1.1092, 1.1092, 1.1092], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1226 was 54.2%\n",
      "current params: tensor([0.8746, 1.1093, 1.1093, 1.1093], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1227 was 54.2%\n",
      "current params: tensor([0.8745, 1.1094, 1.1094, 1.1094], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1228 was 54.2%\n",
      "current params: tensor([0.8744, 1.1095, 1.1095, 1.1095], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1229 was 54.2%\n",
      "current params: tensor([0.8743, 1.1096, 1.1096, 1.1096], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1230 was 54.2%\n",
      "current params: tensor([0.8742, 1.1097, 1.1097, 1.1097], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1231 was 54.2%\n",
      "current params: tensor([0.8741, 1.1098, 1.1097, 1.1097], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1232 was 54.2%\n",
      "current params: tensor([0.8740, 1.1098, 1.1098, 1.1098], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1233 was 54.2%\n",
      "current params: tensor([0.8738, 1.1099, 1.1099, 1.1099], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1234 was 54.2%\n",
      "current params: tensor([0.8737, 1.1100, 1.1100, 1.1100], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1235 was 54.2%\n",
      "current params: tensor([0.8736, 1.1101, 1.1101, 1.1101], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1236 was 54.2%\n",
      "current params: tensor([0.8735, 1.1102, 1.1102, 1.1102], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1237 was 54.2%\n",
      "current params: tensor([0.8734, 1.1102, 1.1103, 1.1103], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1238 was 54.2%\n",
      "current params: tensor([0.8733, 1.1103, 1.1104, 1.1104], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1239 was 54.2%\n",
      "current params: tensor([0.8732, 1.1104, 1.1104, 1.1104], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1240 was 54.2%\n",
      "current params: tensor([0.8731, 1.1105, 1.1105, 1.1105], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1241 was 54.3%\n",
      "current params: tensor([0.8730, 1.1106, 1.1106, 1.1106], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1242 was 54.3%\n",
      "current params: tensor([0.8729, 1.1107, 1.1107, 1.1107], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1243 was 54.3%\n",
      "current params: tensor([0.8728, 1.1108, 1.1108, 1.1108], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1244 was 54.3%\n",
      "current params: tensor([0.8727, 1.1109, 1.1109, 1.1109], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1245 was 54.3%\n",
      "current params: tensor([0.8726, 1.1110, 1.1110, 1.1109], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1246 was 54.3%\n",
      "current params: tensor([0.8725, 1.1110, 1.1110, 1.1110], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1247 was 54.3%\n",
      "current params: tensor([0.8724, 1.1111, 1.1111, 1.1111], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1248 was 54.3%\n",
      "current params: tensor([0.8723, 1.1112, 1.1112, 1.1112], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1249 was 54.3%\n",
      "current params: tensor([0.8722, 1.1113, 1.1113, 1.1113], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1250 was 54.3%\n",
      "current params: tensor([0.8721, 1.1114, 1.1114, 1.1114], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1251 was 54.3%\n",
      "current params: tensor([0.8720, 1.1115, 1.1115, 1.1115], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1252 was 54.3%\n",
      "current params: tensor([0.8719, 1.1116, 1.1116, 1.1116], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1253 was 54.3%\n",
      "current params: tensor([0.8718, 1.1116, 1.1116, 1.1116], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1254 was 54.3%\n",
      "current params: tensor([0.8717, 1.1117, 1.1117, 1.1117], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1255 was 54.3%\n",
      "current params: tensor([0.8715, 1.1118, 1.1118, 1.1118], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1256 was 54.3%\n",
      "current params: tensor([0.8714, 1.1119, 1.1119, 1.1119], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1257 was 54.3%\n",
      "current params: tensor([0.8713, 1.1120, 1.1120, 1.1120], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1258 was 54.3%\n",
      "current params: tensor([0.8712, 1.1121, 1.1121, 1.1121], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1259 was 54.3%\n",
      "current params: tensor([0.8711, 1.1121, 1.1122, 1.1122], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1260 was 54.3%\n",
      "current params: tensor([0.8710, 1.1122, 1.1122, 1.1122], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1261 was 54.3%\n",
      "current params: tensor([0.8709, 1.1123, 1.1123, 1.1123], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1262 was 54.3%\n",
      "current params: tensor([0.8708, 1.1124, 1.1124, 1.1124], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1263 was 54.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8707, 1.1125, 1.1125, 1.1125], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1264 was 54.3%\n",
      "current params: tensor([0.8706, 1.1126, 1.1126, 1.1126], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1265 was 54.3%\n",
      "current params: tensor([0.8705, 1.1127, 1.1127, 1.1127], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1266 was 54.3%\n",
      "current params: tensor([0.8704, 1.1128, 1.1128, 1.1128], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1267 was 54.3%\n",
      "current params: tensor([0.8703, 1.1128, 1.1128, 1.1128], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1268 was 54.4%\n",
      "current params: tensor([0.8702, 1.1129, 1.1129, 1.1129], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1269 was 54.4%\n",
      "current params: tensor([0.8701, 1.1130, 1.1130, 1.1130], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1270 was 54.4%\n",
      "current params: tensor([0.8700, 1.1131, 1.1131, 1.1131], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1271 was 54.4%\n",
      "current params: tensor([0.8699, 1.1132, 1.1132, 1.1132], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1272 was 54.4%\n",
      "current params: tensor([0.8698, 1.1133, 1.1133, 1.1133], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1273 was 54.4%\n",
      "current params: tensor([0.8697, 1.1134, 1.1134, 1.1134], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1274 was 54.4%\n",
      "current params: tensor([0.8696, 1.1134, 1.1134, 1.1134], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1275 was 54.4%\n",
      "current params: tensor([0.8695, 1.1135, 1.1135, 1.1135], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1276 was 54.4%\n",
      "current params: tensor([0.8694, 1.1136, 1.1136, 1.1136], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1277 was 54.4%\n",
      "current params: tensor([0.8692, 1.1137, 1.1137, 1.1137], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1278 was 54.4%\n",
      "current params: tensor([0.8691, 1.1138, 1.1138, 1.1138], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1279 was 54.4%\n",
      "current params: tensor([0.8690, 1.1139, 1.1139, 1.1139], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1280 was 54.4%\n",
      "current params: tensor([0.8689, 1.1140, 1.1140, 1.1140], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1281 was 54.4%\n",
      "current params: tensor([0.8688, 1.1140, 1.1140, 1.1140], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1282 was 54.4%\n",
      "current params: tensor([0.8687, 1.1141, 1.1141, 1.1141], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1283 was 54.4%\n",
      "current params: tensor([0.8686, 1.1142, 1.1142, 1.1142], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1284 was 54.4%\n",
      "current params: tensor([0.8685, 1.1143, 1.1143, 1.1143], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1285 was 54.4%\n",
      "current params: tensor([0.8684, 1.1144, 1.1144, 1.1144], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1286 was 54.4%\n",
      "current params: tensor([0.8683, 1.1145, 1.1145, 1.1145], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1287 was 54.4%\n",
      "current params: tensor([0.8682, 1.1146, 1.1146, 1.1146], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1288 was 54.4%\n",
      "current params: tensor([0.8681, 1.1146, 1.1146, 1.1146], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1289 was 54.4%\n",
      "current params: tensor([0.8680, 1.1147, 1.1147, 1.1147], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1290 was 54.4%\n",
      "current params: tensor([0.8679, 1.1148, 1.1148, 1.1148], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1291 was 54.4%\n",
      "current params: tensor([0.8678, 1.1149, 1.1149, 1.1149], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1292 was 54.4%\n",
      "current params: tensor([0.8677, 1.1150, 1.1150, 1.1150], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1293 was 54.4%\n",
      "current params: tensor([0.8676, 1.1151, 1.1151, 1.1151], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1294 was 54.4%\n",
      "current params: tensor([0.8675, 1.1152, 1.1152, 1.1152], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1295 was 54.4%\n",
      "current params: tensor([0.8674, 1.1152, 1.1152, 1.1152], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1296 was 54.5%\n",
      "current params: tensor([0.8673, 1.1153, 1.1153, 1.1153], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1297 was 54.5%\n",
      "current params: tensor([0.8672, 1.1154, 1.1154, 1.1154], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1298 was 54.5%\n",
      "current params: tensor([0.8670, 1.1155, 1.1155, 1.1155], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1299 was 54.5%\n",
      "current params: tensor([0.8669, 1.1156, 1.1156, 1.1156], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1300 was 54.5%\n",
      "current params: tensor([0.8668, 1.1157, 1.1157, 1.1157], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1301 was 54.5%\n",
      "current params: tensor([0.8667, 1.1158, 1.1158, 1.1158], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1302 was 54.5%\n",
      "current params: tensor([0.8666, 1.1158, 1.1158, 1.1158], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1303 was 54.5%\n",
      "current params: tensor([0.8665, 1.1159, 1.1159, 1.1159], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1304 was 54.5%\n",
      "current params: tensor([0.8664, 1.1160, 1.1160, 1.1160], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1305 was 54.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8663, 1.1161, 1.1161, 1.1161], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1306 was 54.5%\n",
      "current params: tensor([0.8662, 1.1162, 1.1162, 1.1162], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1307 was 54.5%\n",
      "current params: tensor([0.8661, 1.1163, 1.1163, 1.1163], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1308 was 54.5%\n",
      "current params: tensor([0.8660, 1.1164, 1.1164, 1.1164], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1309 was 54.5%\n",
      "current params: tensor([0.8659, 1.1164, 1.1164, 1.1164], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1310 was 54.5%\n",
      "current params: tensor([0.8658, 1.1165, 1.1165, 1.1165], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1311 was 54.5%\n",
      "current params: tensor([0.8657, 1.1166, 1.1166, 1.1166], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1312 was 54.5%\n",
      "current params: tensor([0.8656, 1.1167, 1.1167, 1.1167], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1313 was 54.5%\n",
      "current params: tensor([0.8655, 1.1168, 1.1168, 1.1168], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1314 was 54.5%\n",
      "current params: tensor([0.8654, 1.1169, 1.1169, 1.1169], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1315 was 54.5%\n",
      "current params: tensor([0.8653, 1.1170, 1.1170, 1.1169], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1316 was 54.5%\n",
      "current params: tensor([0.8652, 1.1171, 1.1170, 1.1170], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1317 was 54.5%\n",
      "current params: tensor([0.8651, 1.1171, 1.1171, 1.1171], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1318 was 54.5%\n",
      "current params: tensor([0.8650, 1.1172, 1.1172, 1.1172], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1319 was 54.5%\n",
      "current params: tensor([0.8648, 1.1173, 1.1173, 1.1173], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1320 was 54.5%\n",
      "current params: tensor([0.8647, 1.1174, 1.1174, 1.1174], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1321 was 54.5%\n",
      "current params: tensor([0.8646, 1.1175, 1.1175, 1.1175], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1322 was 54.5%\n",
      "current params: tensor([0.8645, 1.1176, 1.1176, 1.1175], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1323 was 54.6%\n",
      "current params: tensor([0.8644, 1.1176, 1.1177, 1.1176], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1324 was 54.6%\n",
      "current params: tensor([0.8643, 1.1177, 1.1177, 1.1177], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1325 was 54.6%\n",
      "current params: tensor([0.8642, 1.1178, 1.1178, 1.1178], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1326 was 54.6%\n",
      "current params: tensor([0.8641, 1.1179, 1.1179, 1.1179], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1327 was 54.6%\n",
      "current params: tensor([0.8640, 1.1180, 1.1180, 1.1180], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1328 was 54.6%\n",
      "current params: tensor([0.8639, 1.1181, 1.1181, 1.1181], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1329 was 54.6%\n",
      "current params: tensor([0.8638, 1.1182, 1.1181, 1.1182], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1330 was 54.6%\n",
      "current params: tensor([0.8637, 1.1183, 1.1182, 1.1183], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1331 was 54.6%\n",
      "current params: tensor([0.8636, 1.1183, 1.1183, 1.1183], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1332 was 54.6%\n",
      "current params: tensor([0.8635, 1.1184, 1.1184, 1.1184], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1333 was 54.6%\n",
      "current params: tensor([0.8634, 1.1185, 1.1185, 1.1185], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1334 was 54.6%\n",
      "current params: tensor([0.8633, 1.1186, 1.1186, 1.1186], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1335 was 54.6%\n",
      "current params: tensor([0.8632, 1.1187, 1.1187, 1.1187], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1336 was 54.6%\n",
      "current params: tensor([0.8631, 1.1188, 1.1188, 1.1188], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1337 was 54.6%\n",
      "current params: tensor([0.8630, 1.1189, 1.1188, 1.1188], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1338 was 54.6%\n",
      "current params: tensor([0.8629, 1.1189, 1.1189, 1.1189], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1339 was 54.6%\n",
      "current params: tensor([0.8628, 1.1190, 1.1190, 1.1190], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1340 was 54.6%\n",
      "current params: tensor([0.8626, 1.1191, 1.1191, 1.1191], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1341 was 54.6%\n",
      "current params: tensor([0.8625, 1.1192, 1.1192, 1.1192], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1342 was 54.6%\n",
      "current params: tensor([0.8624, 1.1193, 1.1193, 1.1193], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1343 was 54.6%\n",
      "current params: tensor([0.8623, 1.1194, 1.1194, 1.1193], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1344 was 54.6%\n",
      "current params: tensor([0.8622, 1.1195, 1.1195, 1.1194], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1345 was 54.6%\n",
      "current params: tensor([0.8621, 1.1195, 1.1195, 1.1195], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1346 was 54.6%\n",
      "current params: tensor([0.8620, 1.1196, 1.1196, 1.1196], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1347 was 54.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8619, 1.1197, 1.1197, 1.1197], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1348 was 54.6%\n",
      "current params: tensor([0.8618, 1.1198, 1.1198, 1.1198], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1349 was 54.6%\n",
      "current params: tensor([0.8617, 1.1199, 1.1199, 1.1199], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1350 was 54.7%\n",
      "current params: tensor([0.8616, 1.1200, 1.1200, 1.1200], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1351 was 54.7%\n",
      "current params: tensor([0.8615, 1.1200, 1.1200, 1.1200], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1352 was 54.7%\n",
      "current params: tensor([0.8614, 1.1201, 1.1201, 1.1201], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1353 was 54.7%\n",
      "current params: tensor([0.8613, 1.1202, 1.1202, 1.1202], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1354 was 54.7%\n",
      "current params: tensor([0.8612, 1.1203, 1.1203, 1.1203], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1355 was 54.7%\n",
      "current params: tensor([0.8611, 1.1204, 1.1204, 1.1204], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1356 was 54.7%\n",
      "current params: tensor([0.8610, 1.1205, 1.1205, 1.1205], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1357 was 54.7%\n",
      "current params: tensor([0.8609, 1.1206, 1.1206, 1.1206], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1358 was 54.7%\n",
      "current params: tensor([0.8608, 1.1206, 1.1206, 1.1206], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1359 was 54.7%\n",
      "current params: tensor([0.8607, 1.1207, 1.1207, 1.1207], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1360 was 54.7%\n",
      "current params: tensor([0.8605, 1.1208, 1.1208, 1.1208], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1361 was 54.7%\n",
      "current params: tensor([0.8604, 1.1209, 1.1209, 1.1209], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1362 was 54.7%\n",
      "current params: tensor([0.8603, 1.1210, 1.1210, 1.1210], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1363 was 54.7%\n",
      "current params: tensor([0.8602, 1.1211, 1.1211, 1.1211], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1364 was 54.7%\n",
      "current params: tensor([0.8601, 1.1212, 1.1212, 1.1212], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1365 was 54.7%\n",
      "current params: tensor([0.8600, 1.1212, 1.1212, 1.1212], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1366 was 54.7%\n",
      "current params: tensor([0.8599, 1.1213, 1.1213, 1.1213], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1367 was 54.7%\n",
      "current params: tensor([0.8598, 1.1214, 1.1214, 1.1214], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1368 was 54.7%\n",
      "current params: tensor([0.8597, 1.1215, 1.1215, 1.1215], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1369 was 54.7%\n",
      "current params: tensor([0.8596, 1.1216, 1.1216, 1.1216], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1370 was 54.7%\n",
      "current params: tensor([0.8595, 1.1217, 1.1217, 1.1217], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1371 was 54.7%\n",
      "current params: tensor([0.8594, 1.1218, 1.1217, 1.1218], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1372 was 54.7%\n",
      "current params: tensor([0.8593, 1.1218, 1.1218, 1.1218], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1373 was 54.7%\n",
      "current params: tensor([0.8592, 1.1219, 1.1219, 1.1219], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1374 was 54.7%\n",
      "current params: tensor([0.8591, 1.1220, 1.1220, 1.1220], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1375 was 54.7%\n",
      "current params: tensor([0.8590, 1.1221, 1.1221, 1.1221], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1376 was 54.7%\n",
      "current params: tensor([0.8589, 1.1222, 1.1222, 1.1222], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1377 was 54.8%\n",
      "current params: tensor([0.8588, 1.1223, 1.1223, 1.1223], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1378 was 54.8%\n",
      "current params: tensor([0.8587, 1.1224, 1.1223, 1.1224], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1379 was 54.8%\n",
      "current params: tensor([0.8586, 1.1224, 1.1224, 1.1224], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1380 was 54.8%\n",
      "current params: tensor([0.8585, 1.1225, 1.1225, 1.1225], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1381 was 54.8%\n",
      "current params: tensor([0.8583, 1.1226, 1.1226, 1.1226], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1382 was 54.8%\n",
      "current params: tensor([0.8582, 1.1227, 1.1227, 1.1227], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1383 was 54.8%\n",
      "current params: tensor([0.8581, 1.1228, 1.1228, 1.1228], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1384 was 54.8%\n",
      "current params: tensor([0.8580, 1.1229, 1.1229, 1.1229], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1385 was 54.8%\n",
      "current params: tensor([0.8579, 1.1230, 1.1229, 1.1229], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1386 was 54.8%\n",
      "current params: tensor([0.8578, 1.1230, 1.1230, 1.1230], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1387 was 54.8%\n",
      "current params: tensor([0.8577, 1.1231, 1.1231, 1.1231], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1388 was 54.8%\n",
      "current params: tensor([0.8576, 1.1232, 1.1232, 1.1232], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1389 was 54.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8575, 1.1233, 1.1233, 1.1233], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1390 was 54.8%\n",
      "current params: tensor([0.8574, 1.1234, 1.1234, 1.1234], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1391 was 54.8%\n",
      "current params: tensor([0.8573, 1.1234, 1.1235, 1.1235], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1392 was 54.8%\n",
      "current params: tensor([0.8572, 1.1235, 1.1235, 1.1235], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1393 was 54.8%\n",
      "current params: tensor([0.8571, 1.1236, 1.1236, 1.1236], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1394 was 54.8%\n",
      "current params: tensor([0.8570, 1.1237, 1.1237, 1.1237], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1395 was 54.8%\n",
      "current params: tensor([0.8569, 1.1238, 1.1238, 1.1238], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1396 was 54.8%\n",
      "current params: tensor([0.8568, 1.1239, 1.1239, 1.1239], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1397 was 54.8%\n",
      "current params: tensor([0.8567, 1.1240, 1.1240, 1.1240], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1398 was 54.8%\n",
      "current params: tensor([0.8566, 1.1241, 1.1241, 1.1241], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1399 was 54.8%\n",
      "current params: tensor([0.8565, 1.1241, 1.1241, 1.1241], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1400 was 54.8%\n",
      "current params: tensor([0.8564, 1.1242, 1.1242, 1.1242], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1401 was 54.8%\n",
      "current params: tensor([0.8562, 1.1243, 1.1243, 1.1243], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0035, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1402 was 54.8%\n",
      "current params: tensor([0.8561, 1.1244, 1.1244, 1.1244], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1403 was 54.8%\n",
      "current params: tensor([0.8560, 1.1245, 1.1245, 1.1245], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1404 was 54.9%\n",
      "current params: tensor([0.8559, 1.1246, 1.1246, 1.1246], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1405 was 54.9%\n",
      "current params: tensor([0.8558, 1.1247, 1.1247, 1.1246], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1406 was 54.9%\n",
      "current params: tensor([0.8557, 1.1247, 1.1247, 1.1247], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1407 was 54.9%\n",
      "current params: tensor([0.8556, 1.1248, 1.1248, 1.1248], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1408 was 54.9%\n",
      "current params: tensor([0.8555, 1.1249, 1.1249, 1.1249], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1409 was 54.9%\n",
      "current params: tensor([0.8554, 1.1250, 1.1250, 1.1250], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1410 was 54.9%\n",
      "current params: tensor([0.8553, 1.1251, 1.1251, 1.1251], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1411 was 54.9%\n",
      "current params: tensor([0.8552, 1.1252, 1.1252, 1.1252], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1412 was 54.9%\n",
      "current params: tensor([0.8551, 1.1252, 1.1253, 1.1253], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1413 was 54.9%\n",
      "current params: tensor([0.8550, 1.1253, 1.1253, 1.1253], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1414 was 54.9%\n",
      "current params: tensor([0.8549, 1.1254, 1.1254, 1.1254], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1415 was 54.9%\n",
      "current params: tensor([0.8548, 1.1255, 1.1255, 1.1255], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1416 was 54.9%\n",
      "current params: tensor([0.8547, 1.1256, 1.1256, 1.1256], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0031, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1417 was 54.9%\n",
      "current params: tensor([0.8546, 1.1257, 1.1257, 1.1256], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1418 was 54.9%\n",
      "current params: tensor([0.8545, 1.1258, 1.1258, 1.1257], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1419 was 54.9%\n",
      "current params: tensor([0.8544, 1.1259, 1.1259, 1.1258], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1420 was 54.9%\n",
      "current params: tensor([0.8542, 1.1259, 1.1259, 1.1259], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1421 was 54.9%\n",
      "current params: tensor([0.8541, 1.1260, 1.1260, 1.1260], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1422 was 54.9%\n",
      "current params: tensor([0.8540, 1.1261, 1.1261, 1.1261], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1423 was 54.9%\n",
      "current params: tensor([0.8539, 1.1262, 1.1262, 1.1262], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1424 was 54.9%\n",
      "current params: tensor([0.8538, 1.1263, 1.1262, 1.1263], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1425 was 54.9%\n",
      "current params: tensor([0.8537, 1.1264, 1.1263, 1.1264], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1426 was 54.9%\n",
      "current params: tensor([0.8536, 1.1265, 1.1264, 1.1265], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1427 was 54.9%\n",
      "current params: tensor([0.8535, 1.1265, 1.1265, 1.1265], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1428 was 54.9%\n",
      "current params: tensor([0.8534, 1.1266, 1.1266, 1.1266], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1429 was 54.9%\n",
      "current params: tensor([0.8533, 1.1267, 1.1267, 1.1267], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1430 was 54.9%\n",
      "current params: tensor([0.8532, 1.1268, 1.1268, 1.1268], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1431 was 55.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8531, 1.1269, 1.1269, 1.1269], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1432 was 55.0%\n",
      "current params: tensor([0.8530, 1.1270, 1.1270, 1.1269], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1433 was 55.0%\n",
      "current params: tensor([0.8529, 1.1270, 1.1271, 1.1270], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0027, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1434 was 55.0%\n",
      "current params: tensor([0.8528, 1.1271, 1.1271, 1.1271], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1435 was 55.0%\n",
      "current params: tensor([0.8527, 1.1272, 1.1272, 1.1272], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1436 was 55.0%\n",
      "current params: tensor([0.8526, 1.1273, 1.1273, 1.1273], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1437 was 55.0%\n",
      "current params: tensor([0.8525, 1.1274, 1.1274, 1.1274], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0026, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1438 was 55.0%\n",
      "current params: tensor([0.8524, 1.1275, 1.1275, 1.1275], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1439 was 55.0%\n",
      "current params: tensor([0.8523, 1.1275, 1.1275, 1.1276], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1440 was 55.0%\n",
      "current params: tensor([0.8521, 1.1276, 1.1276, 1.1277], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1441 was 55.0%\n",
      "current params: tensor([0.8520, 1.1277, 1.1277, 1.1277], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1442 was 55.0%\n",
      "current params: tensor([0.8519, 1.1278, 1.1278, 1.1278], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1443 was 55.0%\n",
      "current params: tensor([0.8518, 1.1279, 1.1279, 1.1279], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1444 was 55.0%\n",
      "current params: tensor([0.8517, 1.1280, 1.1280, 1.1280], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1445 was 55.0%\n",
      "current params: tensor([0.8516, 1.1281, 1.1281, 1.1280], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1446 was 55.0%\n",
      "current params: tensor([0.8515, 1.1282, 1.1282, 1.1281], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0024, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1447 was 55.0%\n",
      "current params: tensor([0.8514, 1.1282, 1.1282, 1.1282], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1448 was 55.0%\n",
      "current params: tensor([0.8513, 1.1283, 1.1283, 1.1283], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1449 was 55.0%\n",
      "current params: tensor([0.8512, 1.1284, 1.1284, 1.1284], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1450 was 55.0%\n",
      "current params: tensor([0.8511, 1.1285, 1.1285, 1.1285], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1451 was 55.0%\n",
      "current params: tensor([0.8510, 1.1286, 1.1286, 1.1286], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1452 was 55.0%\n",
      "current params: tensor([0.8509, 1.1287, 1.1287, 1.1287], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1453 was 55.0%\n",
      "current params: tensor([0.8508, 1.1287, 1.1288, 1.1287], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1454 was 55.0%\n",
      "current params: tensor([0.8507, 1.1288, 1.1288, 1.1288], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1455 was 55.0%\n",
      "current params: tensor([0.8506, 1.1289, 1.1289, 1.1289], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1456 was 55.0%\n",
      "current params: tensor([0.8505, 1.1290, 1.1290, 1.1290], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1457 was 55.0%\n",
      "current params: tensor([0.8504, 1.1291, 1.1291, 1.1291], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1458 was 55.1%\n",
      "current params: tensor([0.8503, 1.1292, 1.1292, 1.1292], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1459 was 55.1%\n",
      "current params: tensor([0.8501, 1.1293, 1.1293, 1.1293], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1460 was 55.1%\n",
      "current params: tensor([0.8500, 1.1293, 1.1293, 1.1293], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1461 was 55.1%\n",
      "current params: tensor([0.8499, 1.1294, 1.1294, 1.1294], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1462 was 55.1%\n",
      "current params: tensor([0.8498, 1.1295, 1.1295, 1.1295], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1463 was 55.1%\n",
      "current params: tensor([0.8497, 1.1296, 1.1296, 1.1296], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0020, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1464 was 55.1%\n",
      "current params: tensor([0.8496, 1.1297, 1.1297, 1.1297], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1465 was 55.1%\n",
      "current params: tensor([0.8495, 1.1298, 1.1298, 1.1298], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1466 was 55.1%\n",
      "current params: tensor([0.8494, 1.1299, 1.1299, 1.1298], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1467 was 55.1%\n",
      "current params: tensor([0.8493, 1.1299, 1.1299, 1.1299], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1468 was 55.1%\n",
      "current params: tensor([0.8492, 1.1300, 1.1300, 1.1300], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1469 was 55.1%\n",
      "current params: tensor([0.8491, 1.1301, 1.1301, 1.1301], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1470 was 55.1%\n",
      "current params: tensor([0.8490, 1.1302, 1.1302, 1.1302], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1471 was 55.1%\n",
      "current params: tensor([0.8489, 1.1303, 1.1303, 1.1303], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1472 was 55.1%\n",
      "current params: tensor([0.8488, 1.1304, 1.1304, 1.1304], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1473 was 55.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8487, 1.1305, 1.1304, 1.1305], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1474 was 55.1%\n",
      "current params: tensor([0.8486, 1.1305, 1.1305, 1.1305], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1475 was 55.1%\n",
      "current params: tensor([0.8485, 1.1306, 1.1306, 1.1306], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1476 was 55.1%\n",
      "current params: tensor([0.8484, 1.1307, 1.1307, 1.1307], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1477 was 55.1%\n",
      "current params: tensor([0.8483, 1.1308, 1.1308, 1.1308], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1478 was 55.1%\n",
      "current params: tensor([0.8482, 1.1309, 1.1309, 1.1309], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1479 was 55.1%\n",
      "current params: tensor([0.8480, 1.1310, 1.1310, 1.1309], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1480 was 55.1%\n",
      "current params: tensor([0.8479, 1.1310, 1.1310, 1.1310], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1481 was 55.1%\n",
      "current params: tensor([0.8478, 1.1311, 1.1311, 1.1311], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1482 was 55.1%\n",
      "current params: tensor([0.8477, 1.1312, 1.1312, 1.1312], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1483 was 55.1%\n",
      "current params: tensor([0.8476, 1.1313, 1.1313, 1.1313], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1484 was 55.1%\n",
      "current params: tensor([0.8475, 1.1314, 1.1314, 1.1314], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1485 was 55.2%\n",
      "current params: tensor([0.8474, 1.1315, 1.1315, 1.1315], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1486 was 55.2%\n",
      "current params: tensor([0.8473, 1.1316, 1.1316, 1.1315], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1487 was 55.2%\n",
      "current params: tensor([0.8472, 1.1316, 1.1316, 1.1316], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1488 was 55.2%\n",
      "current params: tensor([0.8471, 1.1317, 1.1317, 1.1317], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1489 was 55.2%\n",
      "current params: tensor([0.8470, 1.1318, 1.1318, 1.1318], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1490 was 55.2%\n",
      "current params: tensor([0.8469, 1.1319, 1.1319, 1.1319], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1491 was 55.2%\n",
      "current params: tensor([0.8468, 1.1320, 1.1320, 1.1320], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1492 was 55.2%\n",
      "current params: tensor([0.8467, 1.1321, 1.1321, 1.1321], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1493 was 55.2%\n",
      "current params: tensor([0.8466, 1.1321, 1.1322, 1.1322], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1494 was 55.2%\n",
      "current params: tensor([0.8465, 1.1322, 1.1322, 1.1322], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1495 was 55.2%\n",
      "current params: tensor([0.8464, 1.1323, 1.1323, 1.1323], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1496 was 55.2%\n",
      "current params: tensor([0.8463, 1.1324, 1.1324, 1.1324], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1497 was 55.2%\n",
      "current params: tensor([0.8462, 1.1325, 1.1325, 1.1325], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1498 was 55.2%\n",
      "current params: tensor([0.8460, 1.1326, 1.1326, 1.1326], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1499 was 55.2%\n",
      "current params: tensor([0.8459, 1.1327, 1.1327, 1.1327], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1500 was 55.2%\n",
      "current params: tensor([0.8458, 1.1327, 1.1328, 1.1327], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1501 was 55.2%\n",
      "current params: tensor([0.8457, 1.1328, 1.1328, 1.1328], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1502 was 55.2%\n",
      "current params: tensor([0.8456, 1.1329, 1.1329, 1.1329], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1503 was 55.2%\n",
      "current params: tensor([0.8455, 1.1330, 1.1330, 1.1330], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1504 was 55.2%\n",
      "current params: tensor([0.8454, 1.1331, 1.1331, 1.1331], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1505 was 55.2%\n",
      "current params: tensor([0.8453, 1.1331, 1.1332, 1.1332], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1506 was 55.2%\n",
      "current params: tensor([0.8452, 1.1332, 1.1333, 1.1333], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1507 was 55.2%\n",
      "current params: tensor([0.8451, 1.1333, 1.1333, 1.1333], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1508 was 55.2%\n",
      "current params: tensor([0.8450, 1.1334, 1.1334, 1.1334], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1509 was 55.2%\n",
      "current params: tensor([0.8449, 1.1335, 1.1335, 1.1335], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1510 was 55.2%\n",
      "current params: tensor([0.8448, 1.1336, 1.1336, 1.1336], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1511 was 55.2%\n",
      "current params: tensor([0.8447, 1.1337, 1.1336, 1.1337], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1512 was 55.3%\n",
      "current params: tensor([0.8446, 1.1338, 1.1337, 1.1338], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1513 was 55.3%\n",
      "current params: tensor([0.8445, 1.1339, 1.1338, 1.1339], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1514 was 55.3%\n",
      "current params: tensor([0.8444, 1.1339, 1.1339, 1.1340], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1515 was 55.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8443, 1.1340, 1.1340, 1.1340], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1516 was 55.3%\n",
      "current params: tensor([0.8441, 1.1341, 1.1341, 1.1341], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1517 was 55.3%\n",
      "current params: tensor([0.8440, 1.1342, 1.1342, 1.1342], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1518 was 55.3%\n",
      "current params: tensor([0.8439, 1.1343, 1.1343, 1.1343], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1519 was 55.3%\n",
      "current params: tensor([0.8438, 1.1344, 1.1344, 1.1343], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1520 was 55.3%\n",
      "current params: tensor([0.8437, 1.1345, 1.1344, 1.1344], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1521 was 55.3%\n",
      "current params: tensor([0.8436, 1.1345, 1.1345, 1.1345], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1522 was 55.3%\n",
      "current params: tensor([0.8435, 1.1346, 1.1346, 1.1346], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1523 was 55.3%\n",
      "current params: tensor([0.8434, 1.1347, 1.1347, 1.1347], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1524 was 55.3%\n",
      "current params: tensor([0.8433, 1.1348, 1.1348, 1.1348], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1525 was 55.3%\n",
      "current params: tensor([0.8432, 1.1349, 1.1349, 1.1349], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1526 was 55.3%\n",
      "current params: tensor([0.8431, 1.1349, 1.1350, 1.1350], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1527 was 55.3%\n",
      "current params: tensor([0.8430, 1.1350, 1.1350, 1.1351], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0005, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1528 was 55.3%\n",
      "current params: tensor([0.8429, 1.1351, 1.1351, 1.1351], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1529 was 55.3%\n",
      "current params: tensor([0.8428, 1.1352, 1.1352, 1.1352], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1530 was 55.3%\n",
      "current params: tensor([0.8427, 1.1353, 1.1353, 1.1353], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1531 was 55.3%\n",
      "current params: tensor([0.8426, 1.1354, 1.1354, 1.1354], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1532 was 55.3%\n",
      "current params: tensor([0.8425, 1.1355, 1.1355, 1.1354], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0004, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1533 was 55.3%\n",
      "current params: tensor([0.8424, 1.1356, 1.1355, 1.1355], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1534 was 55.3%\n",
      "current params: tensor([0.8423, 1.1356, 1.1356, 1.1356], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1535 was 55.3%\n",
      "current params: tensor([0.8421, 1.1357, 1.1357, 1.1357], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1536 was 55.3%\n",
      "current params: tensor([0.8420, 1.1358, 1.1358, 1.1358], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1537 was 55.3%\n",
      "current params: tensor([0.8419, 1.1359, 1.1359, 1.1359], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1538 was 55.3%\n",
      "current params: tensor([0.8418, 1.1360, 1.1360, 1.1360], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1539 was 55.4%\n",
      "current params: tensor([0.8417, 1.1360, 1.1361, 1.1361], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1540 was 55.4%\n",
      "current params: tensor([0.8416, 1.1361, 1.1361, 1.1362], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1541 was 55.4%\n",
      "current params: tensor([0.8415, 1.1362, 1.1362, 1.1362], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1542 was 55.4%\n",
      "current params: tensor([0.8414, 1.1363, 1.1363, 1.1363], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1543 was 55.4%\n",
      "current params: tensor([0.8413, 1.1364, 1.1364, 1.1364], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1544 was 55.4%\n",
      "current params: tensor([0.8412, 1.1365, 1.1365, 1.1365], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1545 was 55.4%\n",
      "current params: tensor([0.8411, 1.1366, 1.1366, 1.1365], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1546 was 55.4%\n",
      "current params: tensor([0.8410, 1.1367, 1.1366, 1.1366], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1547 was 55.4%\n",
      "current params: tensor([0.8409, 1.1367, 1.1367, 1.1367], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1548 was 55.4%\n",
      "current params: tensor([0.8408, 1.1368, 1.1368, 1.1368], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1549 was 55.4%\n",
      "current params: tensor([0.8407, 1.1369, 1.1369, 1.1369], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.0000, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1550 was 55.4%\n",
      "current params: tensor([0.8406, 1.1370, 1.1370, 1.1370], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1551 was 55.7%\n",
      "current params: tensor([0.8405, 1.1371, 1.1371, 1.1371], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1552 was 55.7%\n",
      "current params: tensor([0.8404, 1.1371, 1.1372, 1.1372], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1553 was 55.7%\n",
      "current params: tensor([0.8402, 1.1372, 1.1372, 1.1373], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1554 was 55.7%\n",
      "current params: tensor([0.8401, 1.1373, 1.1373, 1.1373], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1555 was 55.8%\n",
      "current params: tensor([0.8400, 1.1374, 1.1374, 1.1374], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1556 was 55.8%\n",
      "current params: tensor([0.8399, 1.1375, 1.1375, 1.1375], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1557 was 55.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8398, 1.1376, 1.1376, 1.1376], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1558 was 55.8%\n",
      "current params: tensor([0.8397, 1.1377, 1.1377, 1.1377], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1559 was 55.8%\n",
      "current params: tensor([0.8396, 1.1378, 1.1378, 1.1377], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1560 was 55.8%\n",
      "current params: tensor([0.8395, 1.1378, 1.1378, 1.1378], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1561 was 55.8%\n",
      "current params: tensor([0.8394, 1.1379, 1.1379, 1.1379], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1562 was 55.8%\n",
      "current params: tensor([0.8393, 1.1380, 1.1380, 1.1380], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1563 was 55.8%\n",
      "current params: tensor([0.8392, 1.1381, 1.1381, 1.1381], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1564 was 55.8%\n",
      "current params: tensor([0.8391, 1.1382, 1.1382, 1.1382], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1565 was 55.8%\n",
      "current params: tensor([0.8390, 1.1383, 1.1383, 1.1383], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1566 was 55.8%\n",
      "current params: tensor([0.8389, 1.1384, 1.1384, 1.1383], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1567 was 55.8%\n",
      "current params: tensor([0.8388, 1.1385, 1.1384, 1.1384], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1568 was 55.8%\n",
      "current params: tensor([0.8386, 1.1385, 1.1385, 1.1385], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1569 was 55.8%\n",
      "current params: tensor([0.8385, 1.1386, 1.1386, 1.1386], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1570 was 55.8%\n",
      "current params: tensor([0.8384, 1.1387, 1.1387, 1.1387], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1571 was 55.8%\n",
      "current params: tensor([0.8383, 1.1388, 1.1388, 1.1388], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1572 was 55.8%\n",
      "current params: tensor([0.8382, 1.1389, 1.1389, 1.1389], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1573 was 55.8%\n",
      "current params: tensor([0.8381, 1.1390, 1.1390, 1.1390], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1574 was 55.8%\n",
      "current params: tensor([0.8380, 1.1390, 1.1391, 1.1390], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1575 was 55.8%\n",
      "current params: tensor([0.8379, 1.1391, 1.1391, 1.1391], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1576 was 55.8%\n",
      "current params: tensor([0.8378, 1.1392, 1.1392, 1.1392], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1577 was 55.8%\n",
      "current params: tensor([0.8377, 1.1393, 1.1393, 1.1393], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1578 was 55.8%\n",
      "current params: tensor([0.8376, 1.1394, 1.1394, 1.1394], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1579 was 55.8%\n",
      "current params: tensor([0.8375, 1.1395, 1.1395, 1.1395], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1580 was 55.8%\n",
      "current params: tensor([0.8374, 1.1395, 1.1396, 1.1396], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1581 was 55.9%\n",
      "current params: tensor([0.8372, 1.1396, 1.1397, 1.1397], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1582 was 55.9%\n",
      "current params: tensor([0.8371, 1.1397, 1.1397, 1.1397], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1583 was 55.9%\n",
      "current params: tensor([0.8370, 1.1398, 1.1398, 1.1398], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1584 was 55.9%\n",
      "current params: tensor([0.8369, 1.1399, 1.1399, 1.1399], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1585 was 55.9%\n",
      "current params: tensor([0.8368, 1.1400, 1.1400, 1.1400], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1586 was 55.9%\n",
      "current params: tensor([0.8367, 1.1401, 1.1401, 1.1401], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1587 was 55.9%\n",
      "current params: tensor([0.8366, 1.1402, 1.1402, 1.1402], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1588 was 55.9%\n",
      "current params: tensor([0.8365, 1.1403, 1.1403, 1.1403], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1589 was 55.9%\n",
      "current params: tensor([0.8364, 1.1403, 1.1403, 1.1403], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1590 was 55.9%\n",
      "current params: tensor([0.8363, 1.1404, 1.1404, 1.1404], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1591 was 55.9%\n",
      "current params: tensor([0.8362, 1.1405, 1.1405, 1.1405], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1592 was 55.9%\n",
      "current params: tensor([0.8361, 1.1406, 1.1406, 1.1406], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1593 was 55.9%\n",
      "current params: tensor([0.8360, 1.1407, 1.1407, 1.1407], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1594 was 55.9%\n",
      "current params: tensor([0.8358, 1.1408, 1.1408, 1.1408], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1595 was 55.9%\n",
      "current params: tensor([0.8357, 1.1409, 1.1409, 1.1408], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1596 was 55.9%\n",
      "current params: tensor([0.8356, 1.1410, 1.1410, 1.1409], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1597 was 55.9%\n",
      "current params: tensor([0.8355, 1.1410, 1.1410, 1.1410], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1598 was 55.9%\n",
      "current params: tensor([0.8354, 1.1411, 1.1411, 1.1411], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1599 was 55.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8353, 1.1412, 1.1412, 1.1412], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1600 was 55.9%\n",
      "current params: tensor([0.8352, 1.1413, 1.1413, 1.1413], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1601 was 55.9%\n",
      "current params: tensor([0.8351, 1.1414, 1.1414, 1.1414], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1602 was 55.9%\n",
      "current params: tensor([0.8350, 1.1415, 1.1415, 1.1415], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1603 was 55.9%\n",
      "current params: tensor([0.8349, 1.1415, 1.1415, 1.1416], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1604 was 55.9%\n",
      "current params: tensor([0.8348, 1.1416, 1.1416, 1.1416], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1605 was 55.9%\n",
      "current params: tensor([0.8347, 1.1417, 1.1417, 1.1417], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1606 was 55.9%\n",
      "current params: tensor([0.8346, 1.1418, 1.1418, 1.1418], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1607 was 56.0%\n",
      "current params: tensor([0.8344, 1.1419, 1.1419, 1.1419], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1608 was 56.0%\n",
      "current params: tensor([0.8343, 1.1420, 1.1420, 1.1420], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1609 was 56.0%\n",
      "current params: tensor([0.8342, 1.1421, 1.1421, 1.1421], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1610 was 56.0%\n",
      "current params: tensor([0.8341, 1.1421, 1.1422, 1.1422], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1611 was 56.0%\n",
      "current params: tensor([0.8340, 1.1422, 1.1422, 1.1422], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1612 was 56.0%\n",
      "current params: tensor([0.8339, 1.1423, 1.1423, 1.1423], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1613 was 56.0%\n",
      "current params: tensor([0.8338, 1.1424, 1.1424, 1.1424], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1614 was 56.0%\n",
      "current params: tensor([0.8337, 1.1425, 1.1425, 1.1425], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1615 was 56.0%\n",
      "current params: tensor([0.8336, 1.1426, 1.1426, 1.1426], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1616 was 56.0%\n",
      "current params: tensor([0.8335, 1.1427, 1.1427, 1.1427], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1617 was 56.0%\n",
      "current params: tensor([0.8334, 1.1428, 1.1428, 1.1428], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1618 was 56.0%\n",
      "current params: tensor([0.8333, 1.1428, 1.1428, 1.1428], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1619 was 56.0%\n",
      "current params: tensor([0.8332, 1.1429, 1.1429, 1.1429], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1620 was 56.0%\n",
      "current params: tensor([0.8330, 1.1430, 1.1430, 1.1430], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1621 was 56.0%\n",
      "current params: tensor([0.8329, 1.1431, 1.1431, 1.1431], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1622 was 56.0%\n",
      "current params: tensor([0.8328, 1.1432, 1.1432, 1.1432], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1623 was 56.0%\n",
      "current params: tensor([0.8327, 1.1433, 1.1433, 1.1433], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1624 was 56.0%\n",
      "current params: tensor([0.8326, 1.1434, 1.1434, 1.1434], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1625 was 56.0%\n",
      "current params: tensor([0.8325, 1.1435, 1.1434, 1.1434], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1626 was 56.0%\n",
      "current params: tensor([0.8324, 1.1435, 1.1435, 1.1435], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1627 was 56.0%\n",
      "current params: tensor([0.8323, 1.1436, 1.1436, 1.1436], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1292, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1628 was 56.0%\n",
      "current params: tensor([0.8322, 1.1437, 1.1437, 1.1437], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1629 was 56.0%\n",
      "current params: tensor([0.8321, 1.1438, 1.1438, 1.1438], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1630 was 56.0%\n",
      "current params: tensor([0.8320, 1.1439, 1.1439, 1.1439], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1631 was 56.0%\n",
      "current params: tensor([0.8319, 1.1440, 1.1440, 1.1440], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1632 was 56.0%\n",
      "current params: tensor([0.8318, 1.1441, 1.1441, 1.1440], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1633 was 56.1%\n",
      "current params: tensor([0.8316, 1.1441, 1.1441, 1.1441], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1634 was 56.1%\n",
      "current params: tensor([0.8315, 1.1442, 1.1442, 1.1442], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1635 was 56.1%\n",
      "current params: tensor([0.8314, 1.1443, 1.1443, 1.1443], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1636 was 56.1%\n",
      "current params: tensor([0.8313, 1.1444, 1.1444, 1.1444], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1637 was 56.1%\n",
      "current params: tensor([0.8312, 1.1445, 1.1445, 1.1445], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1290, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1638 was 56.1%\n",
      "current params: tensor([0.8311, 1.1446, 1.1446, 1.1446], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1639 was 56.1%\n",
      "current params: tensor([0.8310, 1.1447, 1.1447, 1.1447], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1640 was 56.1%\n",
      "current params: tensor([0.8309, 1.1447, 1.1447, 1.1447], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1641 was 56.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8308, 1.1448, 1.1448, 1.1448], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1642 was 56.1%\n",
      "current params: tensor([0.8307, 1.1449, 1.1449, 1.1449], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1643 was 56.1%\n",
      "current params: tensor([0.8306, 1.1450, 1.1450, 1.1450], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1644 was 56.1%\n",
      "current params: tensor([0.8305, 1.1451, 1.1451, 1.1451], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1645 was 56.1%\n",
      "current params: tensor([0.8304, 1.1452, 1.1452, 1.1452], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1646 was 56.1%\n",
      "current params: tensor([0.8302, 1.1453, 1.1452, 1.1453], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1647 was 56.1%\n",
      "current params: tensor([0.8301, 1.1453, 1.1453, 1.1454], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1648 was 56.1%\n",
      "current params: tensor([0.8300, 1.1454, 1.1454, 1.1454], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1649 was 56.1%\n",
      "current params: tensor([0.8299, 1.1455, 1.1455, 1.1455], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1650 was 56.1%\n",
      "current params: tensor([0.8298, 1.1456, 1.1456, 1.1456], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1651 was 56.1%\n",
      "current params: tensor([0.8297, 1.1457, 1.1457, 1.1457], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1652 was 56.1%\n",
      "current params: tensor([0.8296, 1.1458, 1.1458, 1.1458], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1653 was 56.1%\n",
      "current params: tensor([0.8295, 1.1459, 1.1459, 1.1459], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1654 was 56.1%\n",
      "current params: tensor([0.8294, 1.1459, 1.1460, 1.1459], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1655 was 56.1%\n",
      "current params: tensor([0.8293, 1.1460, 1.1460, 1.1460], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1656 was 56.1%\n",
      "current params: tensor([0.8292, 1.1461, 1.1461, 1.1461], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1657 was 56.1%\n",
      "current params: tensor([0.8291, 1.1462, 1.1462, 1.1462], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1658 was 56.1%\n",
      "current params: tensor([0.8290, 1.1463, 1.1463, 1.1463], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1659 was 56.2%\n",
      "current params: tensor([0.8288, 1.1464, 1.1464, 1.1464], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1660 was 56.2%\n",
      "current params: tensor([0.8287, 1.1465, 1.1465, 1.1465], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1661 was 56.2%\n",
      "current params: tensor([0.8286, 1.1466, 1.1466, 1.1466], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1662 was 56.2%\n",
      "current params: tensor([0.8285, 1.1466, 1.1466, 1.1466], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1663 was 56.2%\n",
      "current params: tensor([0.8284, 1.1467, 1.1467, 1.1467], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1664 was 56.2%\n",
      "current params: tensor([0.8283, 1.1468, 1.1468, 1.1468], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1285, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1665 was 56.2%\n",
      "current params: tensor([0.8282, 1.1469, 1.1469, 1.1469], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1666 was 56.2%\n",
      "current params: tensor([0.8281, 1.1470, 1.1470, 1.1470], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1667 was 56.2%\n",
      "current params: tensor([0.8280, 1.1471, 1.1471, 1.1471], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1668 was 56.2%\n",
      "current params: tensor([0.8279, 1.1472, 1.1472, 1.1471], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1669 was 56.2%\n",
      "current params: tensor([0.8278, 1.1472, 1.1472, 1.1472], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1670 was 56.2%\n",
      "current params: tensor([0.8277, 1.1473, 1.1473, 1.1473], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1671 was 56.2%\n",
      "current params: tensor([0.8276, 1.1474, 1.1474, 1.1474], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1672 was 56.2%\n",
      "current params: tensor([0.8274, 1.1475, 1.1475, 1.1475], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1673 was 56.2%\n",
      "current params: tensor([0.8273, 1.1476, 1.1476, 1.1476], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1674 was 56.2%\n",
      "current params: tensor([0.8272, 1.1477, 1.1477, 1.1477], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1675 was 56.2%\n",
      "current params: tensor([0.8271, 1.1478, 1.1478, 1.1477], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1676 was 56.2%\n",
      "current params: tensor([0.8270, 1.1479, 1.1478, 1.1478], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1677 was 56.2%\n",
      "current params: tensor([0.8269, 1.1479, 1.1479, 1.1479], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1678 was 56.2%\n",
      "current params: tensor([0.8268, 1.1480, 1.1480, 1.1480], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1679 was 56.2%\n",
      "current params: tensor([0.8267, 1.1481, 1.1481, 1.1481], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1680 was 56.2%\n",
      "current params: tensor([0.8266, 1.1482, 1.1482, 1.1482], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1681 was 56.2%\n",
      "current params: tensor([0.8265, 1.1483, 1.1483, 1.1483], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1682 was 56.2%\n",
      "current params: tensor([0.8264, 1.1484, 1.1484, 1.1484], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1683 was 56.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8263, 1.1485, 1.1485, 1.1484], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1684 was 56.3%\n",
      "current params: tensor([0.8262, 1.1485, 1.1485, 1.1485], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1685 was 56.3%\n",
      "current params: tensor([0.8260, 1.1486, 1.1486, 1.1486], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1686 was 56.3%\n",
      "current params: tensor([0.8259, 1.1487, 1.1487, 1.1487], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1687 was 56.3%\n",
      "current params: tensor([0.8258, 1.1488, 1.1488, 1.1488], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1688 was 56.3%\n",
      "current params: tensor([0.8257, 1.1489, 1.1489, 1.1489], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1689 was 56.3%\n",
      "current params: tensor([0.8256, 1.1490, 1.1490, 1.1490], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1690 was 56.3%\n",
      "current params: tensor([0.8255, 1.1490, 1.1491, 1.1491], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1691 was 56.3%\n",
      "current params: tensor([0.8254, 1.1491, 1.1491, 1.1491], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1692 was 56.3%\n",
      "current params: tensor([0.8253, 1.1492, 1.1492, 1.1492], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1693 was 56.3%\n",
      "current params: tensor([0.8252, 1.1493, 1.1493, 1.1493], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1694 was 56.3%\n",
      "current params: tensor([0.8251, 1.1494, 1.1494, 1.1494], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1695 was 56.3%\n",
      "current params: tensor([0.8250, 1.1495, 1.1495, 1.1495], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1696 was 56.3%\n",
      "current params: tensor([0.8249, 1.1496, 1.1496, 1.1496], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1697 was 56.3%\n",
      "current params: tensor([0.8248, 1.1496, 1.1497, 1.1497], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1698 was 56.3%\n",
      "current params: tensor([0.8246, 1.1497, 1.1497, 1.1497], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1699 was 56.3%\n",
      "current params: tensor([0.8245, 1.1498, 1.1498, 1.1498], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1700 was 56.3%\n",
      "current params: tensor([0.8244, 1.1499, 1.1499, 1.1499], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1701 was 56.3%\n",
      "current params: tensor([0.8243, 1.1500, 1.1500, 1.1500], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1702 was 56.3%\n",
      "current params: tensor([0.8242, 1.1501, 1.1501, 1.1501], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1278, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1703 was 56.3%\n",
      "current params: tensor([0.8241, 1.1502, 1.1502, 1.1502], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1704 was 56.3%\n",
      "current params: tensor([0.8240, 1.1503, 1.1502, 1.1503], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1705 was 56.3%\n",
      "current params: tensor([0.8239, 1.1504, 1.1503, 1.1503], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1706 was 56.3%\n",
      "current params: tensor([0.8238, 1.1504, 1.1504, 1.1504], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1707 was 56.3%\n",
      "current params: tensor([0.8237, 1.1505, 1.1505, 1.1505], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1708 was 56.3%\n",
      "current params: tensor([0.8236, 1.1506, 1.1506, 1.1506], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1277, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1709 was 56.3%\n",
      "current params: tensor([0.8235, 1.1507, 1.1507, 1.1507], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1710 was 56.4%\n",
      "current params: tensor([0.8234, 1.1508, 1.1508, 1.1508], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1711 was 56.4%\n",
      "current params: tensor([0.8232, 1.1509, 1.1509, 1.1509], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1712 was 56.4%\n",
      "current params: tensor([0.8231, 1.1509, 1.1509, 1.1510], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1713 was 56.4%\n",
      "current params: tensor([0.8230, 1.1510, 1.1510, 1.1510], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1714 was 56.4%\n",
      "current params: tensor([0.8229, 1.1511, 1.1511, 1.1511], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1715 was 56.4%\n",
      "current params: tensor([0.8228, 1.1512, 1.1512, 1.1512], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1716 was 56.4%\n",
      "current params: tensor([0.8227, 1.1513, 1.1513, 1.1513], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1717 was 56.4%\n",
      "current params: tensor([0.8226, 1.1514, 1.1514, 1.1514], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1718 was 56.4%\n",
      "current params: tensor([0.8225, 1.1515, 1.1515, 1.1515], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1719 was 56.4%\n",
      "current params: tensor([0.8224, 1.1515, 1.1515, 1.1515], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1720 was 56.4%\n",
      "current params: tensor([0.8223, 1.1516, 1.1516, 1.1516], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1721 was 56.4%\n",
      "current params: tensor([0.8222, 1.1517, 1.1517, 1.1517], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1722 was 56.4%\n",
      "current params: tensor([0.8221, 1.1518, 1.1518, 1.1518], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1723 was 56.4%\n",
      "current params: tensor([0.8220, 1.1519, 1.1519, 1.1519], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1724 was 56.4%\n",
      "current params: tensor([0.8218, 1.1520, 1.1520, 1.1520], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1725 was 56.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8217, 1.1521, 1.1521, 1.1521], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1726 was 56.4%\n",
      "current params: tensor([0.8216, 1.1521, 1.1522, 1.1522], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1727 was 56.4%\n",
      "current params: tensor([0.8215, 1.1522, 1.1522, 1.1522], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1728 was 56.4%\n",
      "current params: tensor([0.8214, 1.1523, 1.1523, 1.1523], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1729 was 56.4%\n",
      "current params: tensor([0.8213, 1.1524, 1.1524, 1.1524], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1730 was 56.4%\n",
      "current params: tensor([0.8212, 1.1525, 1.1525, 1.1525], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1731 was 56.4%\n",
      "current params: tensor([0.8211, 1.1526, 1.1526, 1.1526], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1732 was 56.4%\n",
      "current params: tensor([0.8210, 1.1527, 1.1527, 1.1527], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1733 was 56.4%\n",
      "current params: tensor([0.8209, 1.1528, 1.1527, 1.1527], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1734 was 56.4%\n",
      "current params: tensor([0.8208, 1.1528, 1.1528, 1.1528], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1735 was 56.4%\n",
      "current params: tensor([0.8207, 1.1529, 1.1529, 1.1529], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1736 was 56.5%\n",
      "current params: tensor([0.8206, 1.1530, 1.1530, 1.1530], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1737 was 56.5%\n",
      "current params: tensor([0.8204, 1.1531, 1.1531, 1.1531], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1738 was 56.5%\n",
      "current params: tensor([0.8203, 1.1532, 1.1532, 1.1532], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1272, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1739 was 56.5%\n",
      "current params: tensor([0.8202, 1.1533, 1.1533, 1.1533], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1740 was 56.5%\n",
      "current params: tensor([0.8201, 1.1534, 1.1534, 1.1533], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1741 was 56.5%\n",
      "current params: tensor([0.8200, 1.1534, 1.1534, 1.1534], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1742 was 56.5%\n",
      "current params: tensor([0.8199, 1.1535, 1.1535, 1.1535], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1743 was 56.5%\n",
      "current params: tensor([0.8198, 1.1536, 1.1536, 1.1536], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1271, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1744 was 56.5%\n",
      "current params: tensor([0.8197, 1.1537, 1.1537, 1.1537], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1745 was 56.5%\n",
      "current params: tensor([0.8196, 1.1538, 1.1538, 1.1538], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1746 was 56.5%\n",
      "current params: tensor([0.8195, 1.1539, 1.1539, 1.1539], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1747 was 56.5%\n",
      "current params: tensor([0.8194, 1.1539, 1.1539, 1.1540], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1748 was 56.5%\n",
      "current params: tensor([0.8193, 1.1540, 1.1540, 1.1540], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1749 was 56.5%\n",
      "current params: tensor([0.8192, 1.1541, 1.1541, 1.1541], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1750 was 56.5%\n",
      "current params: tensor([0.8190, 1.1542, 1.1542, 1.1542], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1751 was 56.5%\n",
      "current params: tensor([0.8189, 1.1543, 1.1543, 1.1543], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1752 was 56.5%\n",
      "current params: tensor([0.8188, 1.1544, 1.1544, 1.1544], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1753 was 56.5%\n",
      "current params: tensor([0.8187, 1.1545, 1.1545, 1.1544], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1754 was 56.5%\n",
      "current params: tensor([0.8186, 1.1546, 1.1546, 1.1545], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1755 was 56.5%\n",
      "current params: tensor([0.8185, 1.1546, 1.1546, 1.1546], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1756 was 56.5%\n",
      "current params: tensor([0.8184, 1.1547, 1.1547, 1.1547], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1757 was 56.5%\n",
      "current params: tensor([0.8183, 1.1548, 1.1548, 1.1548], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1758 was 56.5%\n",
      "current params: tensor([0.8182, 1.1549, 1.1549, 1.1549], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1759 was 56.5%\n",
      "current params: tensor([0.8181, 1.1550, 1.1550, 1.1550], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1760 was 56.5%\n",
      "current params: tensor([0.8180, 1.1551, 1.1551, 1.1551], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1761 was 56.5%\n",
      "current params: tensor([0.8179, 1.1552, 1.1552, 1.1551], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1762 was 56.6%\n",
      "current params: tensor([0.8178, 1.1552, 1.1552, 1.1552], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1763 was 56.6%\n",
      "current params: tensor([0.8176, 1.1553, 1.1553, 1.1553], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1764 was 56.6%\n",
      "current params: tensor([0.8175, 1.1554, 1.1554, 1.1554], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1765 was 56.6%\n",
      "current params: tensor([0.8174, 1.1555, 1.1555, 1.1555], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1766 was 56.6%\n",
      "current params: tensor([0.8173, 1.1556, 1.1556, 1.1556], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1767 was 56.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8172, 1.1557, 1.1557, 1.1557], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1267, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1768 was 56.6%\n",
      "current params: tensor([0.8171, 1.1558, 1.1557, 1.1558], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1769 was 56.6%\n",
      "current params: tensor([0.8170, 1.1558, 1.1558, 1.1559], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1770 was 56.6%\n",
      "current params: tensor([0.8169, 1.1559, 1.1559, 1.1559], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1771 was 56.6%\n",
      "current params: tensor([0.8168, 1.1560, 1.1560, 1.1560], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1772 was 56.6%\n",
      "current params: tensor([0.8167, 1.1561, 1.1561, 1.1561], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1773 was 56.6%\n",
      "current params: tensor([0.8166, 1.1562, 1.1562, 1.1562], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1266, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1774 was 56.6%\n",
      "current params: tensor([0.8165, 1.1563, 1.1563, 1.1563], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1775 was 56.6%\n",
      "current params: tensor([0.8164, 1.1564, 1.1564, 1.1563], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1776 was 56.6%\n",
      "current params: tensor([0.8162, 1.1564, 1.1565, 1.1564], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1777 was 56.6%\n",
      "current params: tensor([0.8161, 1.1565, 1.1565, 1.1565], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1778 was 56.6%\n",
      "current params: tensor([0.8160, 1.1566, 1.1566, 1.1566], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1779 was 56.6%\n",
      "current params: tensor([0.8159, 1.1567, 1.1567, 1.1567], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1265, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1780 was 56.6%\n",
      "current params: tensor([0.8158, 1.1568, 1.1568, 1.1568], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1781 was 56.6%\n",
      "current params: tensor([0.8157, 1.1569, 1.1568, 1.1569], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1782 was 56.6%\n",
      "current params: tensor([0.8156, 1.1570, 1.1569, 1.1570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1783 was 56.6%\n",
      "current params: tensor([0.8155, 1.1571, 1.1570, 1.1570], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1784 was 56.6%\n",
      "current params: tensor([0.8154, 1.1571, 1.1571, 1.1571], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1785 was 56.6%\n",
      "current params: tensor([0.8153, 1.1572, 1.1572, 1.1572], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1786 was 56.6%\n",
      "current params: tensor([0.8152, 1.1573, 1.1573, 1.1573], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1787 was 56.7%\n",
      "current params: tensor([0.8151, 1.1574, 1.1574, 1.1574], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1788 was 56.7%\n",
      "current params: tensor([0.8150, 1.1575, 1.1575, 1.1575], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1789 was 56.7%\n",
      "current params: tensor([0.8148, 1.1575, 1.1576, 1.1576], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1790 was 56.7%\n",
      "current params: tensor([0.8147, 1.1576, 1.1577, 1.1576], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1791 was 56.7%\n",
      "current params: tensor([0.8146, 1.1577, 1.1577, 1.1577], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1792 was 56.7%\n",
      "current params: tensor([0.8145, 1.1578, 1.1578, 1.1578], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1793 was 56.7%\n",
      "current params: tensor([0.8144, 1.1579, 1.1579, 1.1579], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1794 was 56.7%\n",
      "current params: tensor([0.8143, 1.1580, 1.1580, 1.1580], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1795 was 56.7%\n",
      "current params: tensor([0.8142, 1.1581, 1.1580, 1.1581], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1796 was 56.7%\n",
      "current params: tensor([0.8141, 1.1582, 1.1581, 1.1582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1797 was 56.7%\n",
      "current params: tensor([0.8140, 1.1583, 1.1582, 1.1582], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1262, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1798 was 56.7%\n",
      "current params: tensor([0.8139, 1.1583, 1.1583, 1.1583], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1799 was 56.7%\n",
      "current params: tensor([0.8138, 1.1584, 1.1584, 1.1584], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1800 was 56.7%\n",
      "current params: tensor([0.8137, 1.1585, 1.1585, 1.1585], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1801 was 56.7%\n",
      "current params: tensor([0.8136, 1.1586, 1.1586, 1.1586], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1802 was 56.7%\n",
      "current params: tensor([0.8134, 1.1587, 1.1587, 1.1587], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1803 was 56.7%\n",
      "current params: tensor([0.8133, 1.1588, 1.1588, 1.1588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1804 was 56.7%\n",
      "current params: tensor([0.8132, 1.1588, 1.1588, 1.1588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1805 was 56.7%\n",
      "current params: tensor([0.8131, 1.1589, 1.1589, 1.1589], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1261, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1806 was 56.7%\n",
      "current params: tensor([0.8130, 1.1590, 1.1590, 1.1590], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1807 was 56.7%\n",
      "current params: tensor([0.8129, 1.1591, 1.1591, 1.1591], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1808 was 56.7%\n",
      "current params: tensor([0.8128, 1.1592, 1.1592, 1.1592], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1809 was 56.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8127, 1.1593, 1.1593, 1.1593], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1810 was 56.7%\n",
      "current params: tensor([0.8126, 1.1593, 1.1594, 1.1594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1811 was 56.7%\n",
      "current params: tensor([0.8125, 1.1594, 1.1595, 1.1594], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1812 was 56.7%\n",
      "current params: tensor([0.8124, 1.1595, 1.1595, 1.1595], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1813 was 56.8%\n",
      "current params: tensor([0.8123, 1.1596, 1.1596, 1.1596], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1260, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1814 was 56.8%\n",
      "current params: tensor([0.8122, 1.1597, 1.1597, 1.1597], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1815 was 56.8%\n",
      "current params: tensor([0.8120, 1.1598, 1.1598, 1.1598], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1816 was 56.8%\n",
      "current params: tensor([0.8119, 1.1599, 1.1599, 1.1599], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1817 was 56.8%\n",
      "current params: tensor([0.8118, 1.1600, 1.1599, 1.1600], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1818 was 56.8%\n",
      "current params: tensor([0.8117, 1.1600, 1.1600, 1.1600], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1819 was 56.8%\n",
      "current params: tensor([0.8116, 1.1601, 1.1601, 1.1601], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1820 was 56.8%\n",
      "current params: tensor([0.8115, 1.1602, 1.1602, 1.1602], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1821 was 56.8%\n",
      "current params: tensor([0.8114, 1.1603, 1.1603, 1.1603], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1822 was 56.8%\n",
      "current params: tensor([0.8113, 1.1604, 1.1604, 1.1604], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1823 was 56.8%\n",
      "current params: tensor([0.8112, 1.1605, 1.1605, 1.1605], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1824 was 56.8%\n",
      "current params: tensor([0.8111, 1.1605, 1.1606, 1.1606], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1825 was 56.8%\n",
      "current params: tensor([0.8110, 1.1606, 1.1606, 1.1606], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1826 was 56.8%\n",
      "current params: tensor([0.8109, 1.1607, 1.1607, 1.1607], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1827 was 56.8%\n",
      "current params: tensor([0.8108, 1.1608, 1.1608, 1.1608], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1828 was 56.8%\n",
      "current params: tensor([0.8106, 1.1609, 1.1609, 1.1609], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1829 was 56.8%\n",
      "current params: tensor([0.8105, 1.1610, 1.1610, 1.1610], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1830 was 56.8%\n",
      "current params: tensor([0.8104, 1.1611, 1.1611, 1.1611], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1831 was 56.8%\n",
      "current params: tensor([0.8103, 1.1611, 1.1612, 1.1612], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1832 was 56.8%\n",
      "current params: tensor([0.8102, 1.1612, 1.1613, 1.1612], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1257, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1833 was 56.8%\n",
      "current params: tensor([0.8101, 1.1613, 1.1613, 1.1613], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1834 was 56.8%\n",
      "current params: tensor([0.8100, 1.1614, 1.1614, 1.1614], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1835 was 56.8%\n",
      "current params: tensor([0.8099, 1.1615, 1.1615, 1.1615], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1836 was 56.8%\n",
      "current params: tensor([0.8098, 1.1616, 1.1616, 1.1616], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1837 was 56.8%\n",
      "current params: tensor([0.8097, 1.1617, 1.1617, 1.1617], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1838 was 56.8%\n",
      "current params: tensor([0.8096, 1.1618, 1.1617, 1.1618], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1839 was 56.9%\n",
      "current params: tensor([0.8095, 1.1618, 1.1618, 1.1618], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1256, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1840 was 56.9%\n",
      "current params: tensor([0.8094, 1.1619, 1.1619, 1.1619], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1841 was 56.9%\n",
      "current params: tensor([0.8092, 1.1620, 1.1620, 1.1620], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1842 was 56.9%\n",
      "current params: tensor([0.8091, 1.1621, 1.1621, 1.1621], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1843 was 56.9%\n",
      "current params: tensor([0.8090, 1.1622, 1.1622, 1.1622], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1844 was 56.9%\n",
      "current params: tensor([0.8089, 1.1623, 1.1623, 1.1623], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1845 was 56.9%\n",
      "current params: tensor([0.8088, 1.1624, 1.1624, 1.1624], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1846 was 56.9%\n",
      "current params: tensor([0.8087, 1.1624, 1.1624, 1.1624], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1847 was 56.9%\n",
      "current params: tensor([0.8086, 1.1625, 1.1625, 1.1625], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1848 was 56.9%\n",
      "current params: tensor([0.8085, 1.1626, 1.1626, 1.1626], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1849 was 56.9%\n",
      "current params: tensor([0.8084, 1.1627, 1.1627, 1.1627], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1850 was 56.9%\n",
      "current params: tensor([0.8083, 1.1628, 1.1628, 1.1628], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1851 was 56.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8082, 1.1629, 1.1629, 1.1629], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1852 was 56.9%\n",
      "current params: tensor([0.8081, 1.1630, 1.1630, 1.1629], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1853 was 56.9%\n",
      "current params: tensor([0.8080, 1.1630, 1.1630, 1.1630], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1254, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1854 was 56.9%\n",
      "current params: tensor([0.8078, 1.1631, 1.1631, 1.1631], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1855 was 56.9%\n",
      "current params: tensor([0.8077, 1.1632, 1.1632, 1.1632], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1856 was 56.9%\n",
      "current params: tensor([0.8076, 1.1633, 1.1633, 1.1633], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1857 was 56.9%\n",
      "current params: tensor([0.8075, 1.1634, 1.1634, 1.1634], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1858 was 56.9%\n",
      "current params: tensor([0.8074, 1.1635, 1.1635, 1.1635], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1859 was 56.9%\n",
      "current params: tensor([0.8073, 1.1636, 1.1635, 1.1636], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1860 was 56.9%\n",
      "current params: tensor([0.8072, 1.1636, 1.1636, 1.1636], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1861 was 56.9%\n",
      "current params: tensor([0.8071, 1.1637, 1.1637, 1.1637], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1862 was 56.9%\n",
      "current params: tensor([0.8070, 1.1638, 1.1638, 1.1638], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1863 was 56.9%\n",
      "current params: tensor([0.8069, 1.1639, 1.1639, 1.1639], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1864 was 56.9%\n",
      "current params: tensor([0.8068, 1.1640, 1.1640, 1.1640], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1865 was 57.0%\n",
      "current params: tensor([0.8067, 1.1641, 1.1641, 1.1641], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1866 was 57.0%\n",
      "current params: tensor([0.8065, 1.1642, 1.1642, 1.1641], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1867 was 57.0%\n",
      "current params: tensor([0.8064, 1.1642, 1.1642, 1.1642], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1868 was 57.0%\n",
      "current params: tensor([0.8063, 1.1643, 1.1643, 1.1643], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1869 was 57.0%\n",
      "current params: tensor([0.8062, 1.1644, 1.1644, 1.1644], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1870 was 57.0%\n",
      "current params: tensor([0.8061, 1.1645, 1.1645, 1.1645], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1871 was 57.0%\n",
      "current params: tensor([0.8060, 1.1646, 1.1646, 1.1646], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1872 was 57.0%\n",
      "current params: tensor([0.8059, 1.1647, 1.1647, 1.1647], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1873 was 57.0%\n",
      "current params: tensor([0.8058, 1.1648, 1.1647, 1.1647], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1874 was 57.0%\n",
      "current params: tensor([0.8057, 1.1648, 1.1648, 1.1648], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1875 was 57.0%\n",
      "current params: tensor([0.8056, 1.1649, 1.1649, 1.1649], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1876 was 57.0%\n",
      "current params: tensor([0.8055, 1.1650, 1.1650, 1.1650], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1877 was 57.0%\n",
      "current params: tensor([0.8054, 1.1651, 1.1651, 1.1651], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1878 was 57.0%\n",
      "current params: tensor([0.8053, 1.1652, 1.1652, 1.1652], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1879 was 57.0%\n",
      "current params: tensor([0.8051, 1.1653, 1.1653, 1.1653], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1880 was 57.0%\n",
      "current params: tensor([0.8050, 1.1654, 1.1653, 1.1654], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1881 was 57.0%\n",
      "current params: tensor([0.8049, 1.1654, 1.1654, 1.1654], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1882 was 57.0%\n",
      "current params: tensor([0.8048, 1.1655, 1.1655, 1.1655], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1883 was 57.0%\n",
      "current params: tensor([0.8047, 1.1656, 1.1656, 1.1656], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1884 was 57.0%\n",
      "current params: tensor([0.8046, 1.1657, 1.1657, 1.1657], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1885 was 57.0%\n",
      "current params: tensor([0.8045, 1.1658, 1.1658, 1.1658], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1886 was 57.0%\n",
      "current params: tensor([0.8044, 1.1659, 1.1659, 1.1659], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1887 was 57.0%\n",
      "current params: tensor([0.8043, 1.1659, 1.1659, 1.1659], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1888 was 57.0%\n",
      "current params: tensor([0.8042, 1.1660, 1.1660, 1.1660], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1889 was 57.0%\n",
      "current params: tensor([0.8041, 1.1661, 1.1661, 1.1661], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1890 was 57.1%\n",
      "current params: tensor([0.8040, 1.1662, 1.1662, 1.1662], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1891 was 57.1%\n",
      "current params: tensor([0.8039, 1.1663, 1.1663, 1.1663], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1892 was 57.1%\n",
      "current params: tensor([0.8037, 1.1664, 1.1664, 1.1664], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1893 was 57.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.8036, 1.1665, 1.1665, 1.1665], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1894 was 57.1%\n",
      "current params: tensor([0.8035, 1.1666, 1.1665, 1.1665], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1895 was 57.1%\n",
      "current params: tensor([0.8034, 1.1666, 1.1666, 1.1666], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1896 was 57.1%\n",
      "current params: tensor([0.8033, 1.1667, 1.1667, 1.1667], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1897 was 57.1%\n",
      "current params: tensor([0.8032, 1.1668, 1.1668, 1.1668], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1898 was 57.1%\n",
      "current params: tensor([0.8031, 1.1669, 1.1669, 1.1669], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1899 was 57.1%\n",
      "current params: tensor([0.8030, 1.1670, 1.1670, 1.1670], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1900 was 57.1%\n",
      "current params: tensor([0.8029, 1.1671, 1.1671, 1.1671], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1901 was 57.1%\n",
      "current params: tensor([0.8028, 1.1671, 1.1671, 1.1671], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1902 was 57.1%\n",
      "current params: tensor([0.8027, 1.1672, 1.1672, 1.1672], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1903 was 57.1%\n",
      "current params: tensor([0.8026, 1.1673, 1.1673, 1.1673], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1904 was 57.1%\n",
      "current params: tensor([0.8025, 1.1674, 1.1674, 1.1674], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1905 was 57.1%\n",
      "current params: tensor([0.8023, 1.1675, 1.1675, 1.1675], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1906 was 57.1%\n",
      "current params: tensor([0.8022, 1.1676, 1.1676, 1.1676], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1907 was 57.1%\n",
      "current params: tensor([0.8021, 1.1677, 1.1677, 1.1677], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1908 was 57.1%\n",
      "current params: tensor([0.8020, 1.1677, 1.1677, 1.1677], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1909 was 57.1%\n",
      "current params: tensor([0.8019, 1.1678, 1.1678, 1.1678], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1910 was 57.1%\n",
      "current params: tensor([0.8018, 1.1679, 1.1679, 1.1679], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1911 was 57.1%\n",
      "current params: tensor([0.8017, 1.1680, 1.1680, 1.1680], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1912 was 57.1%\n",
      "current params: tensor([0.8016, 1.1681, 1.1681, 1.1681], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1246, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1913 was 57.1%\n",
      "current params: tensor([0.8015, 1.1682, 1.1682, 1.1682], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1914 was 57.1%\n",
      "current params: tensor([0.8014, 1.1683, 1.1683, 1.1683], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1915 was 57.1%\n",
      "current params: tensor([0.8013, 1.1683, 1.1683, 1.1683], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1916 was 57.2%\n",
      "current params: tensor([0.8012, 1.1684, 1.1684, 1.1684], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1917 was 57.2%\n",
      "current params: tensor([0.8011, 1.1685, 1.1685, 1.1685], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1918 was 57.2%\n",
      "current params: tensor([0.8009, 1.1686, 1.1686, 1.1686], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1919 was 57.2%\n",
      "current params: tensor([0.8008, 1.1687, 1.1687, 1.1687], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1920 was 57.2%\n",
      "current params: tensor([0.8007, 1.1688, 1.1688, 1.1688], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1921 was 57.2%\n",
      "current params: tensor([0.8006, 1.1689, 1.1688, 1.1689], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1922 was 57.2%\n",
      "current params: tensor([0.8005, 1.1689, 1.1689, 1.1689], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1923 was 57.2%\n",
      "current params: tensor([0.8004, 1.1690, 1.1690, 1.1690], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1924 was 57.2%\n",
      "current params: tensor([0.8003, 1.1691, 1.1691, 1.1691], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1925 was 57.2%\n",
      "current params: tensor([0.8002, 1.1692, 1.1692, 1.1692], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1926 was 57.2%\n",
      "current params: tensor([0.8001, 1.1693, 1.1693, 1.1693], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1927 was 57.2%\n",
      "current params: tensor([0.8000, 1.1694, 1.1694, 1.1694], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1928 was 57.2%\n",
      "current params: tensor([0.7999, 1.1694, 1.1695, 1.1695], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1929 was 57.2%\n",
      "current params: tensor([0.7998, 1.1695, 1.1695, 1.1695], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1930 was 57.2%\n",
      "current params: tensor([0.7996, 1.1696, 1.1696, 1.1696], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1931 was 57.2%\n",
      "current params: tensor([0.7995, 1.1697, 1.1697, 1.1697], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1932 was 57.2%\n",
      "current params: tensor([0.7994, 1.1698, 1.1698, 1.1698], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1933 was 57.2%\n",
      "current params: tensor([0.7993, 1.1699, 1.1699, 1.1699], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1934 was 57.2%\n",
      "current params: tensor([0.7992, 1.1700, 1.1700, 1.1700], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1935 was 57.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.7991, 1.1701, 1.1700, 1.1700], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1936 was 57.2%\n",
      "current params: tensor([0.7990, 1.1701, 1.1701, 1.1701], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1937 was 57.2%\n",
      "current params: tensor([0.7989, 1.1702, 1.1702, 1.1702], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1938 was 57.2%\n",
      "current params: tensor([0.7988, 1.1703, 1.1703, 1.1703], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1939 was 57.2%\n",
      "current params: tensor([0.7987, 1.1704, 1.1704, 1.1704], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1940 was 57.2%\n",
      "current params: tensor([0.7986, 1.1705, 1.1705, 1.1705], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1941 was 57.2%\n",
      "current params: tensor([0.7985, 1.1706, 1.1706, 1.1705], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1942 was 57.3%\n",
      "current params: tensor([0.7984, 1.1706, 1.1707, 1.1706], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1943 was 57.3%\n",
      "current params: tensor([0.7982, 1.1707, 1.1707, 1.1707], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1944 was 57.3%\n",
      "current params: tensor([0.7981, 1.1708, 1.1708, 1.1708], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1945 was 57.3%\n",
      "current params: tensor([0.7980, 1.1709, 1.1709, 1.1709], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1946 was 57.3%\n",
      "current params: tensor([0.7979, 1.1710, 1.1710, 1.1710], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1947 was 57.3%\n",
      "current params: tensor([0.7978, 1.1711, 1.1711, 1.1711], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1948 was 57.3%\n",
      "current params: tensor([0.7977, 1.1712, 1.1711, 1.1712], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1949 was 57.3%\n",
      "current params: tensor([0.7976, 1.1712, 1.1712, 1.1712], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1950 was 57.3%\n",
      "current params: tensor([0.7975, 1.1713, 1.1713, 1.1713], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1951 was 57.3%\n",
      "current params: tensor([0.7974, 1.1714, 1.1714, 1.1714], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1952 was 57.3%\n",
      "current params: tensor([0.7973, 1.1715, 1.1715, 1.1715], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1953 was 57.3%\n",
      "current params: tensor([0.7972, 1.1716, 1.1716, 1.1716], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1954 was 57.3%\n",
      "current params: tensor([0.7971, 1.1717, 1.1717, 1.1717], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1955 was 57.3%\n",
      "current params: tensor([0.7970, 1.1718, 1.1717, 1.1718], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1956 was 57.3%\n",
      "current params: tensor([0.7968, 1.1718, 1.1718, 1.1718], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1957 was 57.3%\n",
      "current params: tensor([0.7967, 1.1719, 1.1719, 1.1719], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1958 was 57.3%\n",
      "current params: tensor([0.7966, 1.1720, 1.1720, 1.1720], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1959 was 57.3%\n",
      "current params: tensor([0.7965, 1.1721, 1.1721, 1.1721], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1960 was 57.3%\n",
      "current params: tensor([0.7964, 1.1722, 1.1722, 1.1722], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1961 was 57.3%\n",
      "current params: tensor([0.7963, 1.1723, 1.1723, 1.1723], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1962 was 57.3%\n",
      "current params: tensor([0.7962, 1.1723, 1.1724, 1.1723], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1963 was 57.3%\n",
      "current params: tensor([0.7961, 1.1724, 1.1724, 1.1724], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1964 was 57.3%\n",
      "current params: tensor([0.7960, 1.1725, 1.1725, 1.1725], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1965 was 57.3%\n",
      "current params: tensor([0.7959, 1.1726, 1.1726, 1.1726], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1966 was 57.3%\n",
      "current params: tensor([0.7958, 1.1727, 1.1727, 1.1727], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1967 was 57.4%\n",
      "current params: tensor([0.7957, 1.1728, 1.1728, 1.1728], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1239, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1968 was 57.4%\n",
      "current params: tensor([0.7956, 1.1729, 1.1729, 1.1729], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1969 was 57.4%\n",
      "current params: tensor([0.7954, 1.1729, 1.1729, 1.1729], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1970 was 57.4%\n",
      "current params: tensor([0.7953, 1.1730, 1.1730, 1.1730], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1971 was 57.4%\n",
      "current params: tensor([0.7952, 1.1731, 1.1731, 1.1731], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1972 was 57.4%\n",
      "current params: tensor([0.7951, 1.1732, 1.1732, 1.1732], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1973 was 57.4%\n",
      "current params: tensor([0.7950, 1.1733, 1.1733, 1.1733], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1974 was 57.4%\n",
      "current params: tensor([0.7949, 1.1734, 1.1734, 1.1734], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1975 was 57.4%\n",
      "current params: tensor([0.7948, 1.1735, 1.1735, 1.1735], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1976 was 57.4%\n",
      "current params: tensor([0.7947, 1.1735, 1.1735, 1.1736], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1977 was 57.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.7946, 1.1736, 1.1736, 1.1736], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1978 was 57.4%\n",
      "current params: tensor([0.7945, 1.1737, 1.1737, 1.1737], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1979 was 57.4%\n",
      "current params: tensor([0.7944, 1.1738, 1.1738, 1.1738], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1980 was 57.4%\n",
      "current params: tensor([0.7943, 1.1739, 1.1739, 1.1739], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1981 was 57.4%\n",
      "current params: tensor([0.7941, 1.1740, 1.1740, 1.1740], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1982 was 57.4%\n",
      "current params: tensor([0.7940, 1.1741, 1.1741, 1.1740], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1983 was 57.4%\n",
      "current params: tensor([0.7939, 1.1741, 1.1742, 1.1741], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1984 was 57.4%\n",
      "current params: tensor([0.7938, 1.1742, 1.1742, 1.1742], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1985 was 57.4%\n",
      "current params: tensor([0.7937, 1.1743, 1.1743, 1.1743], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1986 was 57.4%\n",
      "current params: tensor([0.7936, 1.1744, 1.1744, 1.1744], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1987 was 57.4%\n",
      "current params: tensor([0.7935, 1.1745, 1.1745, 1.1745], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1988 was 57.4%\n",
      "current params: tensor([0.7934, 1.1746, 1.1745, 1.1746], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1989 was 57.4%\n",
      "current params: tensor([0.7933, 1.1747, 1.1746, 1.1747], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1990 was 57.4%\n",
      "current params: tensor([0.7932, 1.1747, 1.1747, 1.1747], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1991 was 57.4%\n",
      "current params: tensor([0.7931, 1.1748, 1.1748, 1.1748], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1992 was 57.4%\n",
      "current params: tensor([0.7930, 1.1749, 1.1749, 1.1749], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1993 was 57.5%\n",
      "current params: tensor([0.7929, 1.1750, 1.1750, 1.1750], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1236, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1994 was 57.5%\n",
      "current params: tensor([0.7927, 1.1751, 1.1751, 1.1751], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1995 was 57.5%\n",
      "current params: tensor([0.7926, 1.1752, 1.1752, 1.1751], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1996 was 57.5%\n",
      "current params: tensor([0.7925, 1.1753, 1.1753, 1.1752], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1997 was 57.5%\n",
      "current params: tensor([0.7924, 1.1753, 1.1753, 1.1753], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1998 was 57.5%\n",
      "current params: tensor([0.7923, 1.1754, 1.1754, 1.1754], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 1999 was 57.5%\n",
      "current params: tensor([0.7922, 1.1755, 1.1755, 1.1755], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2000 was 57.5%\n",
      "current params: tensor([0.7921, 1.1756, 1.1756, 1.1756], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2001 was 57.5%\n",
      "current params: tensor([0.7920, 1.1757, 1.1757, 1.1757], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1235, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2002 was 57.5%\n",
      "current params: tensor([0.7919, 1.1757, 1.1758, 1.1758], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2003 was 57.5%\n",
      "current params: tensor([0.7918, 1.1758, 1.1758, 1.1759], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2004 was 57.5%\n",
      "current params: tensor([0.7917, 1.1759, 1.1759, 1.1759], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2005 was 57.5%\n",
      "current params: tensor([0.7916, 1.1760, 1.1760, 1.1760], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2006 was 57.5%\n",
      "current params: tensor([0.7915, 1.1761, 1.1761, 1.1761], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2007 was 57.5%\n",
      "current params: tensor([0.7913, 1.1762, 1.1762, 1.1762], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2008 was 57.5%\n",
      "current params: tensor([0.7912, 1.1763, 1.1763, 1.1763], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2009 was 57.5%\n",
      "current params: tensor([0.7911, 1.1764, 1.1763, 1.1764], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2010 was 57.5%\n",
      "current params: tensor([0.7910, 1.1764, 1.1764, 1.1764], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2011 was 57.5%\n",
      "current params: tensor([0.7909, 1.1765, 1.1765, 1.1765], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2012 was 57.5%\n",
      "current params: tensor([0.7908, 1.1766, 1.1766, 1.1766], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2013 was 57.5%\n",
      "current params: tensor([0.7907, 1.1767, 1.1767, 1.1767], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2014 was 57.5%\n",
      "current params: tensor([0.7906, 1.1768, 1.1768, 1.1768], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2015 was 57.5%\n",
      "current params: tensor([0.7905, 1.1769, 1.1769, 1.1769], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2016 was 57.5%\n",
      "current params: tensor([0.7904, 1.1769, 1.1769, 1.1769], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2017 was 57.5%\n",
      "current params: tensor([0.7903, 1.1770, 1.1770, 1.1770], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2018 was 57.6%\n",
      "current params: tensor([0.7902, 1.1771, 1.1771, 1.1771], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2019 was 57.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: tensor([0.7900, 1.1772, 1.1772, 1.1772], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2020 was 57.6%\n",
      "current params: tensor([0.7899, 1.1773, 1.1773, 1.1773], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2021 was 57.6%\n",
      "current params: tensor([0.7898, 1.1774, 1.1774, 1.1774], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2022 was 57.6%\n",
      "current params: tensor([0.7897, 1.1775, 1.1775, 1.1775], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2023 was 57.6%\n",
      "current params: tensor([0.7896, 1.1775, 1.1775, 1.1775], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2024 was 57.6%\n",
      "current params: tensor([0.7895, 1.1776, 1.1776, 1.1776], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2025 was 57.6%\n",
      "current params: tensor([0.7894, 1.1777, 1.1777, 1.1777], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2026 was 57.6%\n",
      "current params: tensor([0.7893, 1.1778, 1.1778, 1.1778], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2027 was 57.6%\n",
      "current params: tensor([0.7892, 1.1779, 1.1779, 1.1779], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2028 was 57.6%\n",
      "current params: tensor([0.7891, 1.1780, 1.1780, 1.1780], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2029 was 57.6%\n",
      "current params: tensor([0.7890, 1.1781, 1.1780, 1.1781], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1232, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2030 was 57.6%\n",
      "current params: tensor([0.7889, 1.1781, 1.1781, 1.1781], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2031 was 57.6%\n",
      "current params: tensor([0.7888, 1.1782, 1.1782, 1.1782], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2032 was 57.6%\n",
      "current params: tensor([0.7886, 1.1783, 1.1783, 1.1783], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2033 was 57.6%\n",
      "current params: tensor([0.7885, 1.1784, 1.1784, 1.1784], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2034 was 57.6%\n",
      "current params: tensor([0.7884, 1.1785, 1.1785, 1.1785], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2035 was 57.6%\n",
      "current params: tensor([0.7883, 1.1786, 1.1786, 1.1786], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2036 was 57.6%\n",
      "current params: tensor([0.7882, 1.1787, 1.1787, 1.1786], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2037 was 57.6%\n",
      "current params: tensor([0.7881, 1.1787, 1.1787, 1.1787], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2038 was 57.6%\n",
      "current params: tensor([0.7880, 1.1788, 1.1788, 1.1788], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2039 was 57.6%\n",
      "current params: tensor([0.7879, 1.1789, 1.1789, 1.1789], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2040 was 57.6%\n",
      "current params: tensor([0.7878, 1.1790, 1.1790, 1.1790], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2041 was 57.6%\n",
      "current params: tensor([0.7877, 1.1791, 1.1791, 1.1791], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2042 was 57.6%\n",
      "current params: tensor([0.7876, 1.1792, 1.1792, 1.1792], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2043 was 57.6%\n",
      "current params: tensor([0.7875, 1.1792, 1.1792, 1.1792], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2044 was 57.7%\n",
      "current params: tensor([0.7874, 1.1793, 1.1793, 1.1793], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2045 was 57.7%\n",
      "current params: tensor([0.7872, 1.1794, 1.1794, 1.1794], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2046 was 57.7%\n",
      "current params: tensor([0.7871, 1.1795, 1.1795, 1.1795], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2047 was 57.7%\n",
      "current params: tensor([0.7870, 1.1796, 1.1796, 1.1796], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2048 was 57.7%\n",
      "current params: tensor([0.7869, 1.1797, 1.1797, 1.1797], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2049 was 57.7%\n",
      "current params: tensor([0.7868, 1.1798, 1.1798, 1.1798], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2050 was 57.7%\n",
      "current params: tensor([0.7867, 1.1798, 1.1798, 1.1798], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2051 was 57.7%\n",
      "current params: tensor([0.7866, 1.1799, 1.1799, 1.1799], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2052 was 57.7%\n",
      "current params: tensor([0.7865, 1.1800, 1.1800, 1.1800], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2053 was 57.7%\n",
      "current params: tensor([0.7864, 1.1801, 1.1801, 1.1801], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2054 was 57.7%\n",
      "current params: tensor([0.7863, 1.1802, 1.1802, 1.1802], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2055 was 57.7%\n",
      "current params: tensor([0.7862, 1.1803, 1.1803, 1.1803], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2056 was 57.7%\n",
      "current params: tensor([0.7861, 1.1803, 1.1803, 1.1803], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2057 was 57.7%\n",
      "current params: tensor([0.7859, 1.1804, 1.1804, 1.1804], dtype=torch.float64)\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 2058 was 57.7%\n",
      "current params: tensor([0.7858, 1.1805, 1.1805, 1.1805], dtype=torch.float64)\n",
      "Killing optimization because too much RAM being used.\n",
      "0.49280548095703125\n",
      "Running simulation with optimized parameters\n",
      "Using CPU\n",
      "Next time:  tensor(1.1229, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Length of observables:  14\n",
      "Using CPU\n",
      "Next time:  tensor(2.0525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Length of observables:  21\n",
      "Using CPU\n",
      "Next time:  tensor(460.8947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Length of observables:  55\n",
      "Doing flux analysis\n",
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "Running Optimization with the following on rates: \n",
      "tensor([10., 10., 10., 10., 10., 10.], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n",
      "Using CPU\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([10., 10., 10., 10.], dtype=torch.float64, requires_grad=True)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next time:  tensor(30.4326, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "yield on sim iteration 0 was 57.1%\n",
      "current params: tensor([10.0010, 10.0010, 10.0010, 10.0010], dtype=torch.float64)\n",
      "Killing optimization because too much RAM being used.\n",
      "0.4553985595703125\n",
      "Running simulation with optimized parameters\n",
      "Using CPU\n",
      "Next time:  tensor(30.4295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Length of observables:  51\n",
      "Using CPU\n",
      "Next time:  tensor(30.4295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Length of observables:  51\n",
      "Using CPU\n",
      "Next time:  tensor(30.4295, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Length of observables:  51\n",
      "Doing flux analysis\n"
     ]
    }
   ],
   "source": [
    "## Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "kon_list = [1.0,10.0]# uM-1 s-1\n",
    "\n",
    "final_yield = {kon : [] for kon in kon_list}\n",
    "optimized_rates = {kon : [] for kon in kon_list}\n",
    "observables = {kon : dict() for kon in kon_list} \n",
    "flux_data = {kon : [] for kon in kon_list}\n",
    "cons_data = {kon : [] for kon in kon_list}\n",
    "final_copies = {kon : [] for kon in kon_list}\n",
    "\n",
    "for new_kon in kon_list:\n",
    "\n",
    "    nx.set_edge_attributes(rn.network,new_kon,'k_on')\n",
    "    \n",
    "    \n",
    "    vec_rn = VectorizedRxnNet(rn, dev='cpu',coupling=True,cid={1:0,2:0})\n",
    "    vec_rn.reset(reset_params=True)\n",
    "    \n",
    "    ### Start Optimization\n",
    "    print(\"Running Optimization with the following on rates: \")\n",
    "    print(vec_rn.kon)\n",
    "    optim = Optimizer(reaction_network=vec_rn,\n",
    "                      sim_runtime=1,\n",
    "                      optim_iterations=10000,\n",
    "                      learning_rate=new_kon/10000,\n",
    "                      device='cpu')\n",
    "    optim.rn.update_reaction_net(rn)\n",
    "    optim.optimize()\n",
    "    \n",
    "    final_yield[new_kon] = optim.yield_per_iter\n",
    "    optimized_rates[new_kon] = vec_rn.kon\n",
    "    \n",
    "    ###Run simulation with optimized parameters\n",
    "    print(\"Running simulation with optimized parameters\")\n",
    "    optim_rn = optim.rn\n",
    "    sim_times = [1,2,10]\n",
    "    for i, runtime in enumerate(sim_times):\n",
    "        optim_rn.reset()\n",
    "        sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "        y = sim.simulate()\n",
    "        \n",
    "        observables[new_kon][runtime] = (sim.steps.copy(),sim.observables.copy())\n",
    "        print(\"Length of observables: \", len(sim.observables[0][1]))\n",
    "    \n",
    "    ##Calculate the net flux in across each node/species\n",
    "    print(\"Doing flux analysis\")\n",
    "    cons_rate,flux = do_flux_analysis(vec_rn,node_map)\n",
    "    \n",
    "    flux_data[new_kon].append(flux)\n",
    "    cons_data[new_kon].append(cons_rate)\n",
    "    final_copies[new_kon].append(vec_rn.copies_vec)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cfa5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Plotting yield for each optimized rates\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, len(kon_list))\n",
    "i= 0\n",
    "for kon,val in final_yield.items():\n",
    "    ax[i].plot(val)\n",
    "    ax[i].set_title(\"Initial kon = \" + str(kon))\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "txt = fig.suptitle(\"Yield after optimization\")\n",
    "fig.set_size_inches(24, 6)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182c3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = 3\n",
    "fig,ax = plt.subplots(len(kon_list),times)\n",
    "i=0\n",
    "nodes_list = ['A','B','C','AB','BC','AC','ABC']\n",
    "for kon,runtimes in observables.items():\n",
    "    for time,val in runtimes.items():\n",
    "        #print(time)\n",
    "        for key in val[1].keys():\n",
    "            if val[1][key][0] in nodes_list:\n",
    "                row = int(i/times)\n",
    "                col = i%times\n",
    "                #print(val[1][key][1][:5])\n",
    "                #print(len(val[1][key][1]))\n",
    "                ax[row,col].plot(val[0],val[1][key][1],label=val[1][key][0])\n",
    "        ax[row,col].set_title(\"runtime: \" + str(time) + \" seconds\")\n",
    "        i+=1\n",
    "lgnd = plt.legend(loc='best')\n",
    "fig.set_size_inches(18, 8)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d581fc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(int(4/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1adf55b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Starting on rate:  1.0\n",
      "Final copies:  [tensor([1.9631e-05, 1.9649e-05, 1.9661e-05, 1.7380e+00, 1.7380e+00, 1.7380e+00,\n",
      "        6.5240e+00], dtype=torch.float64, grad_fn=<MaxBackward2>)]\n",
      "Optimzied parameters:  tensor([0.7858, 0.7858, 0.7858, 1.1805, 1.1805, 1.1805], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n",
      "Flux: \n",
      "AB  :  tensor([-0.0002], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AC  :  tensor([-0.0002], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "BC  :  tensor([-0.0002], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "ABC  :  tensor([0.0001], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "C  :  tensor([0.0004], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "B  :  tensor([0.0004], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "A  :  tensor([0.0004], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "Starting on rate:  10.0\n",
      "Final copies:  [tensor([2.9890e-05, 2.9890e-05, 2.9890e-05, 2.1429e+00, 2.1429e+00, 2.1429e+00,\n",
      "        5.7141e+00], dtype=torch.float64, grad_fn=<MaxBackward2>)]\n",
      "Optimzied parameters:  tensor([10.0010, 10.0010, 10.0010, 10.0010, 10.0010, 10.0010],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "Flux: \n",
      "AB  :  tensor([-0.0038], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "AC  :  tensor([-0.0038], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "BC  :  tensor([-0.0038], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "ABC  :  tensor([0.0019], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "B  :  tensor([0.0058], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "C  :  tensor([0.0058], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "A  :  tensor([0.0058], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for kon,flux in flux_data.items():\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Starting on rate: \", kon)\n",
    "    print(\"Final copies: \", final_copies[kon])\n",
    "    print(\"Optimzied parameters: \", optimized_rates[kon])\n",
    "    \n",
    "    print(\"Flux: \")\n",
    "    for k,v in sorted(flux[0].items(),key=lambda x : x[1]):\n",
    "        print(k,\" : \", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a8afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "MAx numeber for {3: [0, 1]} is chosen as 30.00\n"
     ]
    }
   ],
   "source": [
    "#x = [3,4,5]\n",
    "d = {3:[0,1]}\n",
    "lis = [20,30,40,50]\n",
    "\n",
    "n = max(lis[i] for i in d[3])\n",
    "print(n)\n",
    "print(\"MAx numeber for %s is chosen as %.2f\" %(d,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e1fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.39630985  3.82323404  6.42034159 -0.57790467 -0.53203902 -0.53209776]\n",
      "14.997844033923245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k0 = np.array([ 1.0,  1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "kf = np.array([1.6677e-03, 2.1857e-02, 1.6281e-03, 1.7823e+00, 1.7024e+00, 1.7025e+00])\n",
    "\n",
    "delta_k = kf/k0\n",
    "\n",
    "delta_e = -np.log(delta_k)\n",
    "\n",
    "print(delta_e)\n",
    "print(np.sum(delta_e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
