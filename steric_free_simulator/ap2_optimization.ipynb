{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencerloggia/Projects/biphy/multi_assembly/steric_free_simulator/energy_space_explorer.py:8: UserWarning: Import of 'rosetta' as a top-level module is deprecated and may be removed in 2018, import via 'pyrosetta.rosetta'.\n",
      "  from rosetta.protocols.relax import *\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "\n",
    "from steric_free_simulator import Optimizer\n",
    "from steric_free_simulator import ReactionNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from steric_free_simulator import EnergyExplorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AP2 Network from scratch. We will build the one step network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-cafa853f409e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mbase_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'./input_files/ap2.bngl'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mrn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mReactionNetwork\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase_input\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mone_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/biphy/multi_assembly/steric_free_simulator/reaction_network.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, bngl_path, one_step)\u001B[0m\n\u001B[1;32m     89\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initial_copies\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_bngl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbngl_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 91\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresolve_tree\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mone_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     92\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m  \u001B[0;31m# gradient params\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_energy_set\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/biphy/multi_assembly/steric_free_simulator/reaction_network.py\u001B[0m in \u001B[0;36mresolve_tree\u001B[0;34m(self, is_one_step)\u001B[0m\n\u001B[1;32m    378\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservables\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mgtostr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'struct'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    379\u001B[0m         \u001B[0mfin_dex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 380\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservables\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfin_dex\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mgtostr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfin_dex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'struct'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    382\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/asm_stoich/lib/python3.7/site-packages/networkx/classes/reportviews.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nodes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m     \u001B[0;31m# Set methods\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: -1"
     ]
    }
   ],
   "source": [
    "base_input = './input_files/ap2.bngl'\n",
    "rn = ReactionNetwork(base_input, one_step=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an EnergyExplorer object to define the Rxn Energies on each edge. If relaxed poses are already defined in the subunit dir, will load them instead of recalculating. Otherwise will build all pdb states from monomer pdb files. Raw PDB names must match monomer labels in the reaction network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subunit_dir = './pdbs/AP2_subunits'\n",
    "en = EnergyExplorer(rn, subunit_dir)\n",
    "en.explore_network()\n",
    "\n",
    "# Dump the explored network to pickle binary for easy reuse.\n",
    "unoptimized_save_loc = './local_saves/ap2_en_net_vivo.pkl'\n",
    "with open(unoptimized_save_loc, 'wb') as f:\n",
    "    pk.dump(rn, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can skip the above two steps if load existing explore network pickle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unoptimized_save_loc = './local_saves/ap2_en_net_vivo.pkl'\n",
    "with open(unoptimized_save_loc, 'rb') as f:\n",
    "    rn = pk.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters to equal in the reaction network, and add them to the hash map tracking optimization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([447.], dtype=torch.float64), 1: tensor([606.], dtype=torch.float64), 2: tensor([585.], dtype=torch.float64), 3: tensor([845.], dtype=torch.float64), 4: tensor([0.], dtype=torch.float64), 5: tensor([0.], dtype=torch.float64), 6: tensor([0.], dtype=torch.float64), 7: tensor([0.], dtype=torch.float64), 8: tensor([0.], dtype=torch.float64), 9: tensor([0.], dtype=torch.float64), 10: tensor([0.], dtype=torch.float64), 11: tensor([0.], dtype=torch.float64), 12: tensor([0.], dtype=torch.float64), 13: tensor([0.], dtype=torch.float64), 14: tensor([0.], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "rn.reset()\n",
    "rn.intialize_activations()\n",
    "print(rn._initial_copies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer object to run many simulations on the energy defined reaction network, tuning association parameters at each iteration.\n",
    "\n",
    "Using the device parameter, we can choose which cpu or gpu to run the simulations and optimization with. For networks with less than about 100 possible reactions, runtime will likely be faster on a cpu.\n",
    "\n",
    "User Defined Parameters:\n",
    "\n",
    "- **sim_runtime**: time (in seconds) that the simulation will run for.\n",
    "- **optim_iterations**: number of simlations to run, optimizing parameters at each one.\n",
    "- **learning rate**: factor to multiply calculated gradients by.\n",
    "- **score_constant**: A coefficient applied to each rosetta calculated score, can be thought of a converting rosseta units to Joules. Since we have no idea what this really should be, it should be set to make $\\Delta G$ for each reaction realistic.\n",
    "- **freq_factor**: pre-exponential factor when calculating rate constants, physically a measure of the frequency of collisions between molecules.\n",
    "- **volume**: The volume of each simulation, used when calculating concentraions from copy numbers\n",
    "- **device**: The hardware device to run simulations and optimizations on.\n",
    "\n",
    "_Scroll past all of this optimization output to get to the plots_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Using CPU\n",
      "yield on sim iteration 0 was 46.9%\n",
      "current params: tensor([1.0100, 1.0100, 0.9900, 0.9900, 1.0100, 1.0100, 0.9900, 1.0100, 1.0100,\n",
      "        0.9900, 0.9900, 1.0100, 0.9900, 0.9900, 0.9900, 1.0100, 1.0100, 1.0100,\n",
      "        1.0100, 1.0100, 0.9900, 0.9900, 0.9900, 1.0100, 1.0100],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 1 was 47.0%\n",
      "current params: tensor([1.0200, 1.0200, 0.9800, 0.9800, 1.0200, 1.0200, 0.9800, 1.0200, 1.0200,\n",
      "        0.9800, 0.9800, 1.0200, 0.9800, 0.9800, 0.9800, 1.0200, 1.0200, 1.0200,\n",
      "        1.0200, 1.0200, 0.9800, 0.9800, 0.9800, 1.0200, 1.0200],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 2 was 47.2%\n",
      "current params: tensor([1.0300, 1.0300, 0.9700, 0.9700, 1.0300, 1.0300, 0.9700, 1.0300, 1.0300,\n",
      "        0.9700, 0.9700, 1.0300, 0.9700, 0.9700, 0.9700, 1.0300, 1.0300, 1.0300,\n",
      "        1.0300, 1.0300, 0.9700, 0.9700, 0.9700, 1.0300, 1.0300],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 3 was 47.4%\n",
      "current params: tensor([1.0401, 1.0401, 0.9601, 0.9600, 1.0400, 1.0400, 0.9600, 1.0401, 1.0400,\n",
      "        0.9600, 0.9600, 1.0399, 0.9600, 0.9600, 0.9600, 1.0400, 1.0400, 1.0400,\n",
      "        1.0399, 1.0400, 0.9600, 0.9600, 0.9600, 1.0399, 1.0399],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 4 was 47.6%\n",
      "current params: tensor([1.0502, 1.0502, 0.9501, 0.9500, 1.0500, 1.0499, 0.9500, 1.0501, 1.0499,\n",
      "        0.9500, 0.9499, 1.0499, 0.9499, 0.9499, 0.9500, 1.0500, 1.0500, 1.0500,\n",
      "        1.0499, 1.0499, 0.9499, 0.9499, 0.9499, 1.0499, 1.0499],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 5 was 47.8%\n",
      "current params: tensor([1.0604, 1.0603, 0.9402, 0.9400, 1.0601, 1.0599, 0.9400, 1.0602, 1.0599,\n",
      "        0.9400, 0.9399, 1.0598, 0.9399, 0.9399, 0.9400, 1.0600, 1.0600, 1.0600,\n",
      "        1.0598, 1.0599, 0.9399, 0.9399, 0.9399, 1.0598, 1.0598],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 6 was 48.0%\n",
      "current params: tensor([1.0706, 1.0704, 0.9302, 0.9299, 1.0701, 1.0699, 0.9301, 1.0703, 1.0699,\n",
      "        0.9301, 0.9298, 1.0697, 0.9298, 0.9298, 0.9300, 1.0700, 1.0701, 1.0701,\n",
      "        1.0697, 1.0698, 0.9298, 0.9298, 0.9298, 1.0697, 1.0697],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 7 was 48.2%\n",
      "current params: tensor([1.0808, 1.0806, 0.9203, 0.9199, 1.0802, 1.0798, 0.9201, 1.0804, 1.0798,\n",
      "        0.9201, 0.9198, 1.0795, 0.9197, 0.9198, 0.9200, 1.0800, 1.0801, 1.0801,\n",
      "        1.0796, 1.0797, 0.9197, 0.9197, 0.9198, 1.0795, 1.0796],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 8 was 48.4%\n",
      "current params: tensor([1.0912, 1.0908, 0.9105, 0.9099, 1.0902, 1.0897, 0.9101, 1.0905, 1.0897,\n",
      "        0.9101, 0.9096, 1.0894, 0.9096, 0.9097, 0.9100, 1.0900, 1.0901, 1.0902,\n",
      "        1.0894, 1.0895, 0.9096, 0.9096, 0.9097, 1.0894, 1.0894],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 9 was 48.6%\n",
      "current params: tensor([1.1016, 1.1011, 0.9006, 0.8998, 1.1003, 1.0996, 0.9002, 1.1006, 1.0996,\n",
      "        0.9002, 0.8995, 1.0991, 0.8995, 0.8996, 0.9000, 1.1000, 1.1002, 1.1002,\n",
      "        1.0992, 1.0994, 0.8994, 0.8994, 0.8995, 1.0991, 1.0992],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 10 was 48.8%\n",
      "current params: tensor([1.1120, 1.1114, 0.8907, 0.8898, 1.1103, 1.1094, 0.8902, 1.1107, 1.1094,\n",
      "        0.8902, 0.8894, 1.1089, 0.8894, 0.8894, 0.8899, 1.1100, 1.1103, 1.1103,\n",
      "        1.1090, 1.1092, 0.8893, 0.8892, 0.8894, 1.1089, 1.1090],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 11 was 49.0%\n",
      "current params: tensor([1.1226, 1.1218, 0.8809, 0.8797, 1.1204, 1.1193, 0.8803, 1.1209, 1.1193,\n",
      "        0.8803, 0.8792, 1.1185, 0.8792, 0.8792, 0.8799, 1.1200, 1.1203, 1.1204,\n",
      "        1.1187, 1.1189, 0.8790, 0.8790, 0.8792, 1.1185, 1.1187],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 12 was 49.2%\n",
      "current params: tensor([1.1332, 1.1322, 0.8710, 0.8697, 1.1305, 1.1291, 0.8703, 1.1311, 1.1291,\n",
      "        0.8703, 0.8690, 1.1282, 0.8690, 0.8690, 0.8699, 1.1300, 1.1304, 1.1305,\n",
      "        1.1284, 1.1287, 0.8688, 0.8688, 0.8690, 1.1282, 1.1284],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 13 was 49.4%\n",
      "current params: tensor([1.1439, 1.1427, 0.8612, 0.8597, 1.1405, 1.1388, 0.8604, 1.1413, 1.1389,\n",
      "        0.8604, 0.8587, 1.1378, 0.8587, 0.8588, 0.8598, 1.1400, 1.1405, 1.1406,\n",
      "        1.1380, 1.1383, 0.8585, 0.8585, 0.8587, 1.1377, 1.1380],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 14 was 49.6%\n",
      "current params: tensor([1.1547, 1.1532, 0.8513, 0.8496, 1.1506, 1.1486, 0.8505, 1.1515, 1.1486,\n",
      "        0.8505, 0.8484, 1.1473, 0.8484, 0.8485, 0.8498, 1.1500, 1.1506, 1.1507,\n",
      "        1.1476, 1.1480, 0.8481, 0.8481, 0.8484, 1.1472, 1.1476],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 15 was 49.8%\n",
      "current params: tensor([1.1656, 1.1638, 0.8414, 0.8396, 1.1607, 1.1582, 0.8406, 1.1617, 1.1583,\n",
      "        0.8406, 0.8381, 1.1567, 0.8381, 0.8383, 0.8397, 1.1600, 1.1608, 1.1608,\n",
      "        1.1572, 1.1575, 0.8378, 0.8377, 0.8381, 1.1567, 1.1572],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 16 was 49.9%\n",
      "current params: tensor([1.1765, 1.1745, 0.8315, 0.8295, 1.1707, 1.1679, 0.8307, 1.1718, 1.1679,\n",
      "        0.8307, 0.8277, 1.1661, 0.8278, 0.8279, 0.8296, 1.1700, 1.1709, 1.1710,\n",
      "        1.1666, 1.1671, 0.8273, 0.8273, 0.8278, 1.1661, 1.1666],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 17 was 50.1%\n",
      "current params: tensor([1.1875, 1.1852, 0.8215, 0.8195, 1.1808, 1.1775, 0.8208, 1.1820, 1.1775,\n",
      "        0.8208, 0.8173, 1.1754, 0.8174, 0.8175, 0.8195, 1.1801, 1.1811, 1.1812,\n",
      "        1.1761, 1.1765, 0.8168, 0.8168, 0.8173, 1.1754, 1.1761],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 18 was 50.3%\n",
      "current params: tensor([1.1987, 1.1960, 0.8115, 0.8095, 1.1908, 1.1870, 0.8109, 1.1922, 1.1871,\n",
      "        0.8110, 0.8069, 1.1847, 0.8069, 0.8071, 0.8094, 1.1901, 1.1913, 1.1914,\n",
      "        1.1855, 1.1859, 0.8063, 0.8062, 0.8069, 1.1846, 1.1854],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 19 was 50.5%\n",
      "current params: tensor([1.2099, 1.2069, 0.8015, 0.7995, 1.2008, 1.1965, 0.8011, 1.2024, 1.1966,\n",
      "        0.8011, 0.7964, 1.1939, 0.7964, 0.7967, 0.7993, 1.2002, 1.2015, 1.2016,\n",
      "        1.1948, 1.1953, 0.7957, 0.7956, 0.7964, 1.1938, 1.1948],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 20 was 50.7%\n",
      "current params: tensor([1.2211, 1.2178, 0.7913, 0.7895, 1.2108, 1.2060, 0.7912, 1.2125, 1.2061,\n",
      "        0.7913, 0.7858, 1.2030, 0.7859, 0.7862, 0.7892, 1.2102, 1.2117, 1.2118,\n",
      "        1.2041, 1.2046, 0.7850, 0.7850, 0.7858, 1.2029, 1.2040],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 21 was 50.9%\n",
      "current params: tensor([1.2325, 1.2288, 0.7811, 0.7796, 1.2208, 1.2154, 0.7814, 1.2227, 1.2155,\n",
      "        0.7814, 0.7752, 1.2120, 0.7753, 0.7756, 0.7790, 1.2203, 1.2219, 1.2221,\n",
      "        1.2133, 1.2138, 0.7743, 0.7742, 0.7752, 1.2119, 1.2132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 22 was 51.1%\n",
      "current params: tensor([1.2440, 1.2398, 0.7708, 0.7696, 1.2308, 1.2247, 0.7716, 1.2328, 1.2248,\n",
      "        0.7716, 0.7645, 1.2210, 0.7646, 0.7650, 0.7688, 1.2304, 1.2322, 1.2323,\n",
      "        1.2225, 1.2229, 0.7635, 0.7634, 0.7646, 1.2209, 1.2223],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 23 was 51.3%\n",
      "current params: tensor([1.2555, 1.2509, 0.7605, 0.7597, 1.2408, 1.2339, 0.7617, 1.2428, 1.2341,\n",
      "        0.7618, 0.7538, 1.2298, 0.7539, 0.7544, 0.7586, 1.2405, 1.2424, 1.2426,\n",
      "        1.2316, 1.2320, 0.7526, 0.7526, 0.7538, 1.2297, 1.2314],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 24 was 51.5%\n",
      "current params: tensor([1.2671, 1.2621, 0.7499, 0.7499, 1.2507, 1.2431, 0.7519, 1.2528, 1.2433,\n",
      "        0.7520, 0.7430, 1.2386, 0.7432, 0.7437, 0.7484, 1.2506, 1.2527, 1.2530,\n",
      "        1.2406, 1.2410, 0.7417, 0.7416, 0.7431, 1.2385, 1.2404],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 25 was 51.7%\n",
      "current params: tensor([1.2788, 1.2733, 0.7393, 0.7400, 1.2605, 1.2522, 0.7421, 1.2628, 1.2524,\n",
      "        0.7422, 0.7322, 1.2473, 0.7324, 0.7329, 0.7381, 1.2607, 1.2630, 1.2633,\n",
      "        1.2496, 1.2499, 0.7307, 0.7306, 0.7322, 1.2472, 1.2494],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 26 was 51.9%\n",
      "current params: tensor([1.2906, 1.2846, 0.7286, 0.7303, 1.2704, 1.2613, 0.7323, 1.2727, 1.2615,\n",
      "        0.7324, 0.7213, 1.2560, 0.7215, 0.7221, 0.7278, 1.2708, 1.2734, 1.2736,\n",
      "        1.2586, 1.2587, 0.7196, 0.7195, 0.7213, 1.2558, 1.2583],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 27 was 52.1%\n",
      "current params: tensor([1.3025, 1.2960, 0.7177, 0.7205, 1.2802, 1.2703, 0.7226, 1.2826, 1.2704,\n",
      "        0.7227, 0.7103, 1.2645, 0.7106, 0.7113, 0.7175, 1.2810, 1.2837, 1.2840,\n",
      "        1.2675, 1.2675, 0.7084, 0.7083, 0.7104, 1.2644, 1.2671],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 28 was 52.3%\n",
      "current params: tensor([1.3144, 1.3074, 0.7066, 0.7109, 1.2899, 1.2791, 0.7128, 1.2924, 1.2794,\n",
      "        0.7129, 0.6993, 1.2730, 0.6996, 0.7004, 0.7071, 1.2912, 1.2941, 1.2944,\n",
      "        1.2763, 1.2761, 0.6972, 0.6971, 0.6994, 1.2728, 1.2759],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 29 was 52.5%\n",
      "current params: tensor([1.3264, 1.3189, 0.6955, 0.7012, 1.2996, 1.2879, 0.7030, 1.3021, 1.2882,\n",
      "        0.7032, 0.6882, 1.2813, 0.6886, 0.6894, 0.6967, 1.3013, 1.3044, 1.3048,\n",
      "        1.2851, 1.2847, 0.6858, 0.6857, 0.6883, 1.2811, 1.2846],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 30 was 52.8%\n",
      "current params: tensor([1.3385, 1.3304, 0.6841, 0.6917, 1.3092, 1.2967, 0.6933, 1.3117, 1.2969,\n",
      "        0.6934, 0.6770, 1.2896, 0.6775, 0.6784, 0.6863, 1.3115, 1.3148, 1.3153,\n",
      "        1.2938, 1.2932, 0.6744, 0.6743, 0.6771, 1.2894, 1.2932],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 31 was 53.0%\n",
      "current params: tensor([1.3506, 1.3420, 0.6726, 0.6822, 1.3188, 1.3053, 0.6836, 1.3213, 1.3055,\n",
      "        0.6837, 0.6658, 1.2978, 0.6663, 0.6673, 0.6758, 1.3218, 1.3253, 1.3257,\n",
      "        1.3025, 1.3016, 0.6629, 0.6628, 0.6659, 1.2975, 1.3018],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 32 was 53.2%\n",
      "current params: tensor([1.3629, 1.3537, 0.6610, 0.6728, 1.3283, 1.3138, 0.6739, 1.3307, 1.3141,\n",
      "        0.6740, 0.6545, 1.3059, 0.6551, 0.6561, 0.6653, 1.3320, 1.3357, 1.3362,\n",
      "        1.3111, 1.3099, 0.6513, 0.6511, 0.6546, 1.3056, 1.3103],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 33 was 53.4%\n",
      "current params: tensor([1.3751, 1.3654, 0.6491, 0.6635, 1.3378, 1.3222, 0.6641, 1.3401, 1.3226,\n",
      "        0.6643, 0.6431, 1.3138, 0.6437, 0.6449, 0.6548, 1.3423, 1.3462, 1.3467,\n",
      "        1.3197, 1.3182, 0.6396, 0.6394, 0.6432, 1.3136, 1.3187],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 34 was 53.6%\n",
      "current params: tensor([1.3875, 1.3772, 0.6371, 0.6542, 1.3471, 1.3306, 0.6544, 1.3493, 1.3309,\n",
      "        0.6546, 0.6317, 1.3217, 0.6324, 0.6336, 0.6442, 1.3525, 1.3566, 1.3573,\n",
      "        1.3282, 1.3263, 0.6278, 0.6276, 0.6318, 1.3214, 1.3270],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 35 was 53.8%\n",
      "current params: tensor([1.3999, 1.3890, 0.6250, 0.6450, 1.3564, 1.3388, 0.6448, 1.3584, 1.3392,\n",
      "        0.6449, 0.6201, 1.3295, 0.6209, 0.6223, 0.6336, 1.3628, 1.3671, 1.3678,\n",
      "        1.3367, 1.3343, 0.6159, 0.6157, 0.6203, 1.3292, 1.3353],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 36 was 54.1%\n",
      "current params: tensor([1.4123, 1.4008, 0.6126, 0.6360, 1.3656, 1.3469, 0.6351, 1.3673, 1.3473,\n",
      "        0.6353, 0.6085, 1.3372, 0.6094, 0.6108, 0.6229, 1.3731, 1.3776, 1.3784,\n",
      "        1.3451, 1.3423, 0.6039, 0.6037, 0.6087, 1.3368, 1.3436],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 37 was 54.3%\n",
      "current params: tensor([1.4249, 1.4128, 0.6001, 0.6270, 1.3746, 1.3549, 0.6254, 1.3761, 1.3553,\n",
      "        0.6256, 0.5969, 1.3448, 0.5978, 0.5993, 0.6121, 1.3834, 1.3882, 1.3890,\n",
      "        1.3534, 1.3501, 0.5917, 0.5916, 0.5971, 1.3444, 1.3517],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 38 was 54.5%\n",
      "current params: tensor([1.4374, 1.4247, 0.5874, 0.6181, 1.3836, 1.3628, 0.6158, 1.3847, 1.3632,\n",
      "        0.6160, 0.5851, 1.3523, 0.5861, 0.5878, 0.6013, 1.3938, 1.3987, 1.3996,\n",
      "        1.3618, 1.3578, 0.5795, 0.5793, 0.5853, 1.3519, 1.3598],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 39 was 54.8%\n",
      "current params: tensor([1.4500, 1.4367, 0.5746, 0.6093, 1.3925, 1.3706, 0.6061, 1.3932, 1.3710,\n",
      "        0.6063, 0.5733, 1.3597, 0.5744, 0.5761, 0.5905, 1.4041, 1.4093, 1.4102,\n",
      "        1.3700, 1.3655, 0.5672, 0.5670, 0.5735, 1.3592, 1.3679],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 40 was 55.0%\n",
      "current params: tensor([1.4627, 1.4487, 0.5616, 0.6006, 1.4012, 1.3782, 0.5965, 1.4014, 1.3787,\n",
      "        0.5967, 0.5614, 1.3669, 0.5625, 0.5644, 0.5796, 1.4145, 1.4199, 1.4208,\n",
      "        1.3782, 1.3730, 0.5547, 0.5545, 0.5617, 1.3664, 1.3758],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 41 was 55.2%\n",
      "current params: tensor([1.4754, 1.4608, 0.5484, 0.5920, 1.4098, 1.3857, 0.5868, 1.4094, 1.3863,\n",
      "        0.5871, 0.5494, 1.3741, 0.5506, 0.5526, 0.5686, 1.4249, 1.4304, 1.4315,\n",
      "        1.3864, 1.3805, 0.5422, 0.5420, 0.5497, 1.3736, 1.3837],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 42 was 55.5%\n",
      "current params: tensor([1.4882, 1.4729, 0.5351, 0.5835, 1.4182, 1.3931, 0.5772, 1.4173, 1.3937,\n",
      "        0.5775, 0.5374, 1.3811, 0.5386, 0.5408, 0.5576, 1.4353, 1.4410, 1.4422,\n",
      "        1.3945, 1.3878, 0.5295, 0.5293, 0.5377, 1.3806, 1.3916],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 43 was 55.7%\n",
      "current params: tensor([1.5010, 1.4851, 0.5216, 0.5750, 1.4266, 1.4004, 0.5676, 1.4248, 1.4010,\n",
      "        0.5679, 0.5253, 1.3881, 0.5266, 0.5288, 0.5465, 1.4458, 1.4517, 1.4529,\n",
      "        1.4026, 1.3951, 0.5167, 0.5165, 0.5256, 1.3875, 1.3993],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 44 was 56.0%\n",
      "current params: tensor([1.5138, 1.4972, 0.5080, 0.5667, 1.4347, 1.4075, 0.5580, 1.4321, 1.4081,\n",
      "        0.5583, 0.5130, 1.3949, 0.5144, 0.5168, 0.5354, 1.4562, 1.4623, 1.4636,\n",
      "        1.4106, 1.4022, 0.5038, 0.5035, 0.5134, 1.3943, 1.4070],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 45 was 56.2%\n",
      "current params: tensor([1.5266, 1.5094, 0.4942, 0.5585, 1.4427, 1.4145, 0.5484, 1.4391, 1.4151,\n",
      "        0.5487, 0.5008, 1.4016, 0.5022, 0.5046, 0.5241, 1.4667, 1.4729, 1.4744,\n",
      "        1.4186, 1.4093, 0.4907, 0.4905, 0.5012, 1.4009, 1.4146],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 46 was 56.5%\n",
      "current params: tensor([1.5395, 1.5217, 0.4803, 0.5503, 1.4504, 1.4213, 0.5388, 1.4457, 1.4220,\n",
      "        0.5391, 0.4884, 1.4082, 0.4899, 0.4924, 0.5129, 1.4771, 1.4836, 1.4851,\n",
      "        1.4266, 1.4162, 0.4775, 0.4773, 0.4889, 1.4075, 1.4222],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 47 was 56.8%\n",
      "current params: tensor([1.5524, 1.5339, 0.4662, 0.5422, 1.4580, 1.4280, 0.5293, 1.4521, 1.4287,\n",
      "        0.5295, 0.4760, 1.4146, 0.4774, 0.4801, 0.5015, 1.4876, 1.4943, 1.4959,\n",
      "        1.4345, 1.4231, 0.4642, 0.4639, 0.4765, 1.4139, 1.4296],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 48 was 57.1%\n",
      "current params: tensor([1.5653, 1.5462, 0.4520, 0.5342, 1.4654, 1.4345, 0.5197, 1.4580, 1.4352,\n",
      "        0.5199, 0.4635, 1.4209, 0.4649, 0.4678, 0.4901, 1.4981, 1.5049, 1.5067,\n",
      "        1.4423, 1.4298, 0.4507, 0.4504, 0.4640, 1.4202, 1.4370],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 49 was 57.3%\n",
      "current params: tensor([1.5782, 1.5584, 0.4377, 0.5263, 1.4725, 1.4409, 0.5102, 1.4635, 1.4416,\n",
      "        0.5104, 0.4509, 1.4271, 0.4523, 0.4553, 0.4786, 1.5087, 1.5156, 1.5175,\n",
      "        1.4502, 1.4365, 0.4371, 0.4368, 0.4515, 1.4263, 1.4444],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 50 was 57.6%\n",
      "current params: tensor([1.5912, 1.5707, 0.4233, 0.5184, 1.4794, 1.4471, 0.5006, 1.4686, 1.4479,\n",
      "        0.5008, 0.4382, 1.4332, 0.4396, 0.4427, 0.4670, 1.5192, 1.5263, 1.5283,\n",
      "        1.4579, 1.4430, 0.4234, 0.4231, 0.4389, 1.4323, 1.4516],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 51 was 57.9%\n",
      "current params: tensor([1.6042, 1.5830, 0.4088, 0.5106, 1.4860, 1.4531, 0.4911, 1.4732, 1.4539,\n",
      "        0.4912, 0.4255, 1.4391, 0.4269, 0.4300, 0.4553, 1.5297, 1.5370, 1.5391,\n",
      "        1.4657, 1.4495, 0.4095, 0.4092, 0.4262, 1.4382, 1.4588],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 52 was 58.2%\n",
      "current params: tensor([1.6171, 1.5953, 0.3941, 0.5028, 1.4923, 1.4590, 0.4816, 1.4773, 1.4598,\n",
      "        0.4816, 0.4126, 1.4448, 0.4140, 0.4173, 0.4435, 1.5403, 1.5477, 1.5500,\n",
      "        1.4733, 1.4558, 0.3955, 0.3951, 0.4135, 1.4439, 1.4659],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 53 was 58.5%\n",
      "current params: tensor([1.6301, 1.6076, 0.3794, 0.4950, 1.4983, 1.4647, 0.4721, 1.4807, 1.4656,\n",
      "        0.4720, 0.3998, 1.4504, 0.4010, 0.4044, 0.4317, 1.5508, 1.5585, 1.5608,\n",
      "        1.4810, 1.4621, 0.3813, 0.3809, 0.4007, 1.4495, 1.4729],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 54 was 58.8%\n",
      "current params: tensor([1.6430, 1.6199, 0.3645, 0.4873, 1.5040, 1.4702, 0.4626, 1.4836, 1.4711,\n",
      "        0.4625, 0.3868, 1.4558, 0.3879, 0.3914, 0.4198, 1.5614, 1.5692, 1.5717,\n",
      "        1.4886, 1.4682, 0.3669, 0.3666, 0.3878, 1.4549, 1.4798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 55 was 59.2%\n",
      "current params: tensor([1.6560, 1.6322, 0.3496, 0.4795, 1.5093, 1.4755, 0.4531, 1.4857, 1.4764,\n",
      "        0.4529, 0.3738, 1.4611, 0.3747, 0.3783, 0.4078, 1.5720, 1.5799, 1.5825,\n",
      "        1.4962, 1.4743, 0.3524, 0.3520, 0.3749, 1.4601, 1.4867],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 56 was 59.5%\n",
      "current params: tensor([1.6689, 1.6445, 0.3345, 0.4718, 1.5142, 1.4807, 0.4436, 1.4870, 1.4816,\n",
      "        0.4433, 0.3607, 1.4662, 0.3614, 0.3651, 0.3957, 1.5826, 1.5906, 1.5934,\n",
      "        1.5037, 1.4802, 0.3378, 0.3374, 0.3619, 1.4652, 1.4934],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 57 was 59.8%\n",
      "current params: tensor([1.6818, 1.6568, 0.3194, 0.4641, 1.5187, 1.4856, 0.4341, 1.4876, 1.4865,\n",
      "        0.4337, 0.3475, 1.4711, 0.3480, 0.3518, 0.3835, 1.5932, 1.6013, 1.6043,\n",
      "        1.5112, 1.4860, 0.3229, 0.3225, 0.3489, 1.4701, 1.5001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 58 was 60.2%\n",
      "current params: tensor([1.6947, 1.6690, 0.3042, 0.4563, 1.5227, 1.4903, 0.4247, 1.4872, 1.4912,\n",
      "        0.4241, 0.3343, 1.4758, 0.3345, 0.3384, 0.3712, 1.6037, 1.6120, 1.6152,\n",
      "        1.5186, 1.4917, 0.3079, 0.3075, 0.3358, 1.4747, 1.5067],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 59 was 60.5%\n",
      "current params: tensor([1.7076, 1.6812, 0.2889, 0.4486, 1.5263, 1.4948, 0.4153, 1.4858, 1.4958,\n",
      "        0.4145, 0.3210, 1.4803, 0.3208, 0.3248, 0.3589, 1.6143, 1.6227, 1.6261,\n",
      "        1.5260, 1.4973, 0.2927, 0.2923, 0.3227, 1.4792, 1.5132],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 60 was 60.9%\n",
      "current params: tensor([1.7204, 1.6934, 0.2734, 0.4408, 1.5293, 1.4991, 0.4059, 1.4835, 1.5001,\n",
      "        0.4049, 0.3077, 1.4846, 0.3071, 0.3111, 0.3464, 1.6249, 1.6334, 1.6370,\n",
      "        1.5334, 1.5028, 0.2774, 0.2769, 0.3096, 1.4835, 1.5196],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 61 was 61.3%\n",
      "current params: tensor([1.7332, 1.7056, 0.2579, 0.4330, 1.5318, 1.5032, 0.3965, 1.4800, 1.5041,\n",
      "        0.3953, 0.2943, 1.4887, 0.2932, 0.2973, 0.3338, 1.6356, 1.6441, 1.6479,\n",
      "        1.5407, 1.5082, 0.2618, 0.2613, 0.2964, 1.4875, 1.5259],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 62 was 61.7%\n",
      "current params: tensor([1.7460, 1.7178, 0.2423, 0.4253, 1.5336, 1.5070, 0.3871, 1.4754, 1.5079,\n",
      "        0.3857, 0.2809, 1.4925, 0.2792, 0.2834, 0.3212, 1.6462, 1.6548, 1.6588,\n",
      "        1.5480, 1.5134, 0.2461, 0.2456, 0.2832, 1.4913, 1.5321],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 63 was 62.1%\n",
      "current params: tensor([1.7587, 1.7299, 0.2265, 0.4175, 1.5348, 1.5106, 0.3778, 1.4696, 1.5115,\n",
      "        0.3761, 0.2675, 1.4961, 0.2650, 0.2692, 0.3084, 1.6568, 1.6655, 1.6697,\n",
      "        1.5552, 1.5185, 0.2302, 0.2296, 0.2700, 1.4949, 1.5382],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 64 was 62.5%\n",
      "current params: tensor([1.7714, 1.7419, 0.2107, 0.4098, 1.5353, 1.5140, 0.3685, 1.4626, 1.5148,\n",
      "        0.3666, 0.2540, 1.4994, 0.2508, 0.2550, 0.2956, 1.6674, 1.6762, 1.6806,\n",
      "        1.5624, 1.5235, 0.2140, 0.2134, 0.2568, 1.4981, 1.5443],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 65 was 63.0%\n",
      "current params: tensor([1.7840, 1.7539, 0.1946, 0.4021, 1.5351, 1.5171, 0.3593, 1.4543, 1.5178,\n",
      "        0.3570, 0.2405, 1.5024, 0.2363, 0.2406, 0.2827, 1.6780, 1.6868, 1.6915,\n",
      "        1.5695, 1.5283, 0.1977, 0.1971, 0.2436, 1.5011, 1.5502],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 66 was 63.5%\n",
      "current params: tensor([1.7966, 1.7659, 0.1784, 0.3945, 1.5341, 1.5199, 0.3502, 1.4449, 1.5206,\n",
      "        0.3474, 0.2271, 1.5050, 0.2218, 0.2260, 0.2697, 1.6886, 1.6975, 1.7024,\n",
      "        1.5766, 1.5330, 0.1811, 0.1805, 0.2305, 1.5037, 1.5561],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 67 was 63.9%\n",
      "current params: tensor([1.8090, 1.7778, 0.1620, 0.3871, 1.5323, 1.5224, 0.3410, 1.4343, 1.5231,\n",
      "        0.3379, 0.2136, 1.5073, 0.2070, 0.2112, 0.2566, 1.6992, 1.7081, 1.7133,\n",
      "        1.5836, 1.5375, 0.1643, 0.1637, 0.2174, 1.5060, 1.5619],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 68 was 64.5%\n",
      "current params: tensor([1.8215, 1.7897, 0.1453, 0.3799, 1.5296, 1.5247, 0.3320, 1.4227, 1.5252,\n",
      "        0.3284, 0.2002, 1.5092, 0.1921, 0.1962, 0.2434, 1.7098, 1.7187, 1.7241,\n",
      "        1.5906, 1.5418, 0.1473, 0.1466, 0.2044, 1.5078, 1.5676],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 69 was 65.0%\n",
      "current params: tensor([1.8338, 1.8014, 0.1284, 0.3729, 1.5261, 1.5267, 0.3231, 1.4100, 1.5271,\n",
      "        0.3190, 0.1868, 1.5107, 0.1771, 0.1810, 0.2301, 1.7204, 1.7293, 1.7350,\n",
      "        1.5975, 1.5458, 0.1301, 0.1293, 0.1914, 1.5093, 1.5733],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 70 was 65.6%\n",
      "current params: tensor([1.8460, 1.8131, 0.1111, 0.3665, 1.5216, 1.5284, 0.3143, 1.3963, 1.5286,\n",
      "        0.3096, 0.1735, 1.5117, 0.1618, 0.1657, 0.2167, 1.7310, 1.7398, 1.7458,\n",
      "        1.6043, 1.5496, 0.1125, 0.1118, 0.1786, 1.5102, 1.5790],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 71 was 66.2%\n",
      "current params: tensor([1.8581, 1.8247, 0.0935, 0.3605, 1.5163, 1.5298, 0.3056, 1.3819, 1.5299,\n",
      "        0.3004, 0.1604, 1.5121, 0.1463, 0.1500, 0.2033, 1.7416, 1.7504, 1.7567,\n",
      "        1.6111, 1.5531, 0.0947, 0.0940, 0.1660, 1.5107, 1.5846],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 72 was 66.9%\n",
      "current params: tensor([1.8701, 1.8362, 0.1018, 0.3553, 1.5102, 1.5310, 0.2971, 1.3667, 1.5307,\n",
      "        0.2912, 0.1474, 1.5120, 0.1306, 0.1342, 0.1898, 1.7522, 1.7609, 1.7675,\n",
      "        1.6178, 1.5562, 0.1029, 0.1021, 0.1536, 1.5105, 1.5903],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 73 was 67.0%\n",
      "current params: tensor([1.8822, 1.8477, 0.1094, 0.3512, 1.5029, 1.5317, 0.2886, 1.3507, 1.5312,\n",
      "        0.2821, 0.1345, 1.5113, 0.1148, 0.1181, 0.1762, 1.7628, 1.7713, 1.7783,\n",
      "        1.6244, 1.5590, 0.1102, 0.1095, 0.1413, 1.5098, 1.5958],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 74 was 67.1%\n",
      "current params: tensor([1.8943, 1.8594, 0.1162, 0.3486, 1.4943, 1.5321, 0.2802, 1.3339, 1.5312,\n",
      "        0.2730, 0.1217, 1.5102, 0.0987, 0.1019, 0.1624, 1.7734, 1.7817, 1.7890,\n",
      "        1.6311, 1.5615, 0.1168, 0.1161, 0.1292, 1.5085, 1.6011],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 75 was 67.3%\n",
      "current params: tensor([1.9066, 1.8712, 0.1224, 0.3479, 1.4843, 1.5320, 0.2718, 1.3165, 1.5308,\n",
      "        0.2638, 0.1090, 1.5086, 0.1071, 0.0855, 0.1485, 1.7840, 1.7921, 1.7997,\n",
      "        1.6377, 1.5636, 0.1228, 0.1221, 0.1173, 1.5069, 1.6060],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 76 was 67.5%\n",
      "current params: tensor([1.9191, 1.8833, 0.1280, 0.3491, 1.4732, 1.5314, 0.2633, 1.2986, 1.5298,\n",
      "        0.2544, 0.0963, 1.5068, 0.1147, 0.0939, 0.1344, 1.7946, 1.8024, 1.8103,\n",
      "        1.6445, 1.5655, 0.1281, 0.1275, 0.1054, 1.5048, 1.6104],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 77 was 67.5%\n",
      "current params: tensor([1.9318, 1.8956, 0.1330, 0.3518, 1.4610, 1.5305, 0.2548, 1.2802, 1.5283,\n",
      "        0.2449, 0.1049, 1.5048, 0.1216, 0.1055, 0.1201, 1.8052, 1.8126, 1.8208,\n",
      "        1.6513, 1.5672, 0.1329, 0.1324, 0.0935, 1.5024, 1.6141],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 78 was 67.5%\n",
      "current params: tensor([1.9445, 1.9080, 0.1376, 0.3558, 1.4479, 1.5291, 0.2461, 1.2614, 1.5265,\n",
      "        0.2352, 0.1126, 1.5026, 0.1278, 0.1159, 0.1056, 1.8157, 1.8228, 1.8313,\n",
      "        1.6582, 1.5686, 0.1372, 0.1367, 0.1021, 1.4998, 1.6171],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 79 was 67.4%\n",
      "current params: tensor([1.9573, 1.9204, 0.1417, 0.3610, 1.4340, 1.5275, 0.2373, 1.2424, 1.5244,\n",
      "        0.2253, 0.1195, 1.5002, 0.1333, 0.1254, 0.0908, 1.8262, 1.8329, 1.8417,\n",
      "        1.6652, 1.5699, 0.1411, 0.1406, 0.1099, 1.4970, 1.6195],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 80 was 67.4%\n",
      "current params: tensor([1.9700, 1.9329, 0.1455, 0.3675, 1.4195, 1.5257, 0.2285, 1.2232, 1.5220,\n",
      "        0.2152, 0.1258, 1.4977, 0.1384, 0.1339, 0.0995, 1.8367, 1.8431, 1.8521,\n",
      "        1.6723, 1.5710, 0.1446, 0.1442, 0.1169, 1.4940, 1.6214],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 81 was 67.2%\n",
      "current params: tensor([1.9828, 1.9454, 0.1488, 0.3749, 1.4044, 1.5237, 0.2195, 1.2038, 1.5194,\n",
      "        0.2051, 0.1315, 1.4950, 0.1429, 0.1417, 0.1114, 1.8472, 1.8532, 1.8625,\n",
      "        1.6796, 1.5720, 0.1477, 0.1473, 0.1233, 1.4908, 1.6228],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 82 was 67.1%\n",
      "current params: tensor([1.9953, 1.9577, 0.1519, 0.3827, 1.3890, 1.5217, 0.2105, 1.1844, 1.5167,\n",
      "        0.1947, 0.1366, 1.4922, 0.1470, 0.1486, 0.1221, 1.8577, 1.8634, 1.8730,\n",
      "        1.6870, 1.5730, 0.1505, 0.1501, 0.1290, 1.4874, 1.6238],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 83 was 67.0%\n",
      "current params: tensor([2.0078, 1.9699, 0.1547, 0.3905, 1.3734, 1.5196, 0.2014, 1.1650, 1.5140,\n",
      "        0.1842, 0.1412, 1.4893, 0.1507, 0.1549, 0.1318, 1.8683, 1.8735, 1.8834,\n",
      "        1.6945, 1.5739, 0.1529, 0.1527, 0.1342, 1.4839, 1.6247],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 84 was 66.9%\n",
      "current params: tensor([2.0200, 1.9819, 0.1572, 0.3982, 1.3576, 1.5175, 0.1921, 1.1457, 1.5112,\n",
      "        0.1735, 0.1454, 1.4863, 0.1540, 0.1606, 0.1405, 1.8788, 1.8837, 1.8939,\n",
      "        1.7022, 1.5748, 0.1552, 0.1549, 0.1388, 1.4803, 1.6254],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 85 was 66.8%\n",
      "current params: tensor([2.0320, 1.9937, 0.1594, 0.4054, 1.3418, 1.5156, 0.1828, 1.1264, 1.5085,\n",
      "        0.1627, 0.1491, 1.4832, 0.1569, 0.1658, 0.1485, 1.8893, 1.8940, 1.9045,\n",
      "        1.7100, 1.5757, 0.1571, 0.1570, 0.1430, 1.4765, 1.6259],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 86 was 66.8%\n",
      "current params: tensor([2.0437, 2.0052, 0.1615, 0.4118, 1.3259, 1.5138, 0.1733, 1.1073, 1.5059,\n",
      "        0.1516, 0.1525, 1.4800, 0.1596, 0.1704, 0.1556, 1.8998, 1.9042, 1.9151,\n",
      "        1.7179, 1.5768, 0.1589, 0.1588, 0.1468, 1.4727, 1.6265],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 87 was 66.7%\n",
      "current params: tensor([2.0551, 2.0164, 0.1633, 0.4173, 1.3101, 1.5121, 0.1638, 1.0884, 1.5035,\n",
      "        0.1404, 0.1555, 1.4767, 0.1619, 0.1746, 0.1621, 1.9103, 1.9145, 1.9258,\n",
      "        1.7259, 1.5779, 0.1604, 0.1604, 0.1503, 1.4687, 1.6271],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 88 was 66.7%\n",
      "current params: tensor([2.0662, 2.0273, 0.1650, 0.4216, 1.2943, 1.5107, 0.1541, 1.0696, 1.5012,\n",
      "        0.1290, 0.1582, 1.4733, 0.1641, 0.1783, 0.1679, 1.9209, 1.9248, 1.9365,\n",
      "        1.7340, 1.5791, 0.1618, 0.1618, 0.1533, 1.4647, 1.6277],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 89 was 66.7%\n",
      "current params: tensor([2.0770, 2.0378, 0.1665, 0.4246, 1.2786, 1.5095, 0.1442, 1.0510, 1.4991,\n",
      "        0.1174, 0.1607, 1.4699, 0.1660, 0.1817, 0.1732, 1.9314, 1.9352, 1.9473,\n",
      "        1.7423, 1.5805, 0.1630, 0.1631, 0.1561, 1.4605, 1.6284],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 90 was 66.7%\n",
      "current params: tensor([2.0875, 2.0481, 0.1678, 0.4262, 1.2630, 1.5085, 0.1343, 1.0326, 1.4972,\n",
      "        0.1056, 0.1629, 1.4664, 0.1677, 0.1848, 0.1779, 1.9420, 1.9456, 1.9581,\n",
      "        1.7506, 1.5820, 0.1641, 0.1642, 0.1586, 1.4563, 1.6293],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 91 was 66.7%\n",
      "current params: tensor([2.0976, 2.0579, 0.1691, 0.4263, 1.2476, 1.5079, 0.1242, 1.0144, 1.4956,\n",
      "        0.0936, 0.1648, 1.4628, 0.1692, 0.1875, 0.1822, 1.9526, 1.9560, 1.9691,\n",
      "        1.7591, 1.5836, 0.1650, 0.1651, 0.1608, 1.4519, 1.6302],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 92 was 66.7%\n",
      "current params: tensor([2.1074, 2.0675, 0.1702, 0.4249, 1.2322, 1.5074, 0.1140, 0.9964, 1.4942,\n",
      "        0.1030, 0.1666, 1.4592, 0.1705, 0.1900, 0.1860, 1.9631, 1.9665, 1.9800,\n",
      "        1.7677, 1.5853, 0.1658, 0.1660, 0.1629, 1.4475, 1.6313],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 93 was 66.7%\n",
      "current params: tensor([2.1169, 2.0766, 0.1712, 0.4220, 1.2170, 1.5073, 0.1037, 0.9785, 1.4931,\n",
      "        0.1115, 0.1681, 1.4555, 0.1717, 0.1922, 0.1895, 1.9737, 1.9770, 1.9911,\n",
      "        1.7763, 1.5872, 0.1665, 0.1668, 0.1647, 1.4430, 1.6326],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 94 was 66.6%\n",
      "current params: tensor([2.1261, 2.0855, 0.1721, 0.4176, 1.2018, 1.5075, 0.0932, 0.9608, 1.4922,\n",
      "        0.1192, 0.1695, 1.4518, 0.1727, 0.1942, 0.1926, 1.9844, 1.9876, 2.0022,\n",
      "        1.7851, 1.5892, 0.1672, 0.1674, 0.1663, 1.4385, 1.6340],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 95 was 66.7%\n",
      "current params: tensor([2.1349, 2.0940, 0.1729, 0.4119, 1.1867, 1.5079, 0.1027, 0.9433, 1.4917,\n",
      "        0.1261, 0.1708, 1.4480, 0.1736, 0.1959, 0.1954, 1.9950, 1.9982, 2.0133,\n",
      "        1.7939, 1.5913, 0.1677, 0.1680, 0.1677, 1.4339, 1.6356],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 96 was 66.6%\n",
      "current params: tensor([2.1434, 2.1022, 0.1737, 0.4049, 1.1716, 1.5087, 0.1114, 0.9261, 1.4914,\n",
      "        0.1324, 0.1719, 1.4441, 0.1744, 0.1975, 0.1980, 2.0056, 2.0088, 2.0245,\n",
      "        1.8028, 1.5935, 0.1681, 0.1685, 0.1690, 1.4293, 1.6373],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 97 was 66.6%\n",
      "current params: tensor([2.1516, 2.1101, 0.1743, 0.3967, 1.1566, 1.5097, 0.1192, 0.9089, 1.4914,\n",
      "        0.1381, 0.1728, 1.4402, 0.1751, 0.1989, 0.2002, 2.0162, 2.0194, 2.0358,\n",
      "        1.8118, 1.5957, 0.1685, 0.1689, 0.1701, 1.4246, 1.6393],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 98 was 66.6%\n",
      "current params: tensor([2.1596, 2.1177, 0.1749, 0.3875, 1.1416, 1.5110, 0.1262, 0.8919, 1.4918,\n",
      "        0.1432, 0.1737, 1.4362, 0.1756, 0.2002, 0.2023, 2.0269, 2.0301, 2.0471,\n",
      "        1.8208, 1.5980, 0.1688, 0.1692, 0.1712, 1.4199, 1.6414],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 99 was 66.6%\n",
      "current params: tensor([2.1673, 2.1251, 0.1755, 0.3773, 1.1266, 1.5126, 0.1326, 0.8751, 1.4924,\n",
      "        0.1478, 0.1744, 1.4322, 0.1761, 0.2013, 0.2041, 2.0375, 2.0408, 2.0584,\n",
      "        1.8299, 1.6004, 0.1690, 0.1695, 0.1721, 1.4151, 1.6437],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 100 was 66.7%\n",
      "current params: tensor([2.1748, 2.1322, 0.1759, 0.3663, 1.1116, 1.5144, 0.1383, 0.8583, 1.4932,\n",
      "        0.1520, 0.1750, 1.4282, 0.1766, 0.2023, 0.2057, 2.0482, 2.0515, 2.0698,\n",
      "        1.8391, 1.6027, 0.1692, 0.1697, 0.1729, 1.4103, 1.6461],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 101 was 66.7%\n",
      "current params: tensor([2.1820, 2.1391, 0.1764, 0.3546, 1.0966, 1.5165, 0.1436, 0.8417, 1.4944,\n",
      "        0.1558, 0.1756, 1.4242, 0.1769, 0.2031, 0.2072, 2.0589, 2.0622, 2.0812,\n",
      "        1.8483, 1.6051, 0.1694, 0.1699, 0.1736, 1.4055, 1.6487],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 102 was 66.7%\n",
      "current params: tensor([2.1890, 2.1457, 0.1768, 0.3422, 1.0815, 1.5189, 0.1483, 0.8251, 1.4957,\n",
      "        0.1592, 0.1761, 1.4201, 0.1772, 0.2039, 0.2085, 2.0696, 2.0730, 2.0926,\n",
      "        1.8576, 1.6074, 0.1695, 0.1701, 0.1742, 1.4007, 1.6515],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 103 was 66.7%\n",
      "current params: tensor([2.1959, 2.1521, 0.1771, 0.3293, 1.0664, 1.5215, 0.1525, 0.8085, 1.4974,\n",
      "        0.1623, 0.1765, 1.4161, 0.1774, 0.2046, 0.2096, 2.0803, 2.0837, 2.1041,\n",
      "        1.8669, 1.6097, 0.1695, 0.1702, 0.1747, 1.3958, 1.6544],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 104 was 66.8%\n",
      "current params: tensor([2.2026, 2.1584, 0.1774, 0.3160, 1.0511, 1.5244, 0.1564, 0.7919, 1.4993,\n",
      "        0.1651, 0.1768, 1.4120, 0.1776, 0.2051, 0.2106, 2.0910, 2.0945, 2.1156,\n",
      "        1.8762, 1.6119, 0.1696, 0.1703, 0.1752, 1.3909, 1.6574],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 105 was 66.8%\n",
      "current params: tensor([2.2091, 2.1645, 0.1777, 0.3023, 1.0357, 1.5274, 0.1598, 0.7753, 1.5014,\n",
      "        0.1676, 0.1771, 1.4080, 0.1777, 0.2056, 0.2115, 2.1017, 2.1052, 2.1271,\n",
      "        1.8856, 1.6140, 0.1696, 0.1703, 0.1756, 1.3860, 1.6606],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 106 was 66.8%\n",
      "current params: tensor([2.2155, 2.1704, 0.1779, 0.2884, 1.0201, 1.5307, 0.1630, 0.7587, 1.5037,\n",
      "        0.1699, 0.1773, 1.4039, 0.1778, 0.2061, 0.2123, 2.1124, 2.1160, 2.1387,\n",
      "        1.8950, 1.6160, 0.1695, 0.1703, 0.1759, 1.3811, 1.6639],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 107 was 66.9%\n",
      "current params: tensor([2.2217, 2.1762, 0.1781, 0.2743, 1.0044, 1.5342, 0.1658, 0.7420, 1.5062,\n",
      "        0.1719, 0.1775, 1.3999, 0.1778, 0.2064, 0.2130, 2.1232, 2.1268, 2.1502,\n",
      "        1.9044, 1.6179, 0.1695, 0.1703, 0.1762, 1.3762, 1.6673],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 108 was 66.9%\n",
      "current params: tensor([2.2279, 2.1819, 0.1782, 0.2601, 0.9884, 1.5378, 0.1684, 0.7253, 1.5089,\n",
      "        0.1738, 0.1776, 1.3959, 0.1778, 0.2067, 0.2137, 2.1339, 2.1375, 2.1618,\n",
      "        1.9138, 1.6197, 0.1694, 0.1703, 0.1765, 1.3713, 1.6708],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 109 was 67.0%\n",
      "current params: tensor([2.2339, 2.1874, 0.1784, 0.2459, 0.9723, 1.5417, 0.1707, 0.7084, 1.5118,\n",
      "        0.1755, 0.1777, 1.3919, 0.1778, 0.2070, 0.2142, 2.1446, 2.1483, 2.1733,\n",
      "        1.9233, 1.6213, 0.1693, 0.1702, 0.1767, 1.3664, 1.6745],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 110 was 67.0%\n",
      "current params: tensor([2.2399, 2.1929, 0.1785, 0.2318, 0.9558, 1.5456, 0.1728, 0.6914, 1.5148,\n",
      "        0.1769, 0.1778, 1.3880, 0.1777, 0.2072, 0.2147, 2.1554, 2.1590, 2.1849,\n",
      "        1.9327, 1.6227, 0.1692, 0.1702, 0.1769, 1.3615, 1.6782],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 111 was 67.1%\n",
      "current params: tensor([2.2458, 2.1982, 0.1786, 0.2180, 0.9391, 1.5498, 0.1746, 0.6743, 1.5180,\n",
      "        0.1783, 0.1778, 1.3841, 0.1777, 0.2074, 0.2151, 2.1661, 2.1697, 2.1965,\n",
      "        1.9422, 1.6240, 0.1691, 0.1701, 0.1770, 1.3565, 1.6820],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 112 was 67.1%\n",
      "current params: tensor([2.2516, 2.2035, 0.1786, 0.2044, 0.9220, 1.5540, 0.1763, 0.6570, 1.5214,\n",
      "        0.1795, 0.1778, 1.3803, 0.1776, 0.2075, 0.2154, 2.1769, 2.1805, 2.2080,\n",
      "        1.9517, 1.6251, 0.1690, 0.1700, 0.1771, 1.3517, 1.6859],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 113 was 67.2%\n",
      "current params: tensor([2.2574, 2.2087, 0.1787, 0.1912, 0.9047, 1.5584, 0.1779, 0.6396, 1.5249,\n",
      "        0.1806, 0.1777, 1.3765, 0.1774, 0.2076, 0.2157, 2.1876, 2.1912, 2.2196,\n",
      "        1.9611, 1.6259, 0.1688, 0.1699, 0.1772, 1.3468, 1.6899],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 114 was 67.3%\n",
      "current params: tensor([2.2631, 2.2139, 0.1787, 0.1785, 0.8870, 1.5630, 0.1792, 0.6219, 1.5285,\n",
      "        0.1816, 0.1776, 1.3728, 0.1773, 0.2076, 0.2159, 2.1984, 2.2019, 2.2312,\n",
      "        1.9706, 1.6266, 0.1687, 0.1697, 0.1772, 1.3420, 1.6939],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 115 was 67.3%\n",
      "current params: tensor([2.2688, 2.2190, 0.1787, 0.1664, 0.8689, 1.5676, 0.1805, 0.6041, 1.5322,\n",
      "        0.1825, 0.1775, 1.3691, 0.1771, 0.2077, 0.2161, 2.2091, 2.2125, 2.2428,\n",
      "        1.9801, 1.6271, 0.1685, 0.1696, 0.1772, 1.3372, 1.6980],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 116 was 67.4%\n",
      "current params: tensor([2.2745, 2.2241, 0.1787, 0.1550, 0.8505, 1.5723, 0.1816, 0.5860, 1.5361,\n",
      "        0.1832, 0.1774, 1.3655, 0.1769, 0.2076, 0.2163, 2.2199, 2.2232, 2.2543,\n",
      "        1.9895, 1.6274, 0.1683, 0.1695, 0.1772, 1.3324, 1.7022],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 117 was 67.5%\n",
      "current params: tensor([2.2801, 2.2291, 0.1786, 0.1444, 0.8318, 1.5771, 0.1826, 0.5678, 1.5401,\n",
      "        0.1839, 0.1773, 1.3620, 0.1767, 0.2076, 0.2164, 2.2306, 2.2338, 2.2659,\n",
      "        1.9990, 1.6275, 0.1682, 0.1693, 0.1772, 1.3277, 1.7064],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 118 was 67.5%\n",
      "current params: tensor([2.2858, 2.2341, 0.1786, 0.1346, 0.8127, 1.5820, 0.1835, 0.5493, 1.5441,\n",
      "        0.1846, 0.1771, 1.3585, 0.1765, 0.2076, 0.2165, 2.2414, 2.2444, 2.2774,\n",
      "        2.0084, 1.6274, 0.1680, 0.1692, 0.1771, 1.3231, 1.7107],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 119 was 67.6%\n",
      "current params: tensor([2.2914, 2.2391, 0.1785, 0.1258, 0.7932, 1.5870, 0.1843, 0.5306, 1.5483,\n",
      "        0.1851, 0.1769, 1.3552, 0.1763, 0.2075, 0.2166, 2.2522, 2.2550, 2.2890,\n",
      "        2.0178, 1.6272, 0.1678, 0.1690, 0.1771, 1.3185, 1.7151],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 120 was 67.7%\n",
      "current params: tensor([2.2970, 2.2440, 0.1784, 0.1180, 0.7733, 1.5921, 0.1851, 0.5116, 1.5526,\n",
      "        0.1856, 0.1767, 1.3520, 0.1760, 0.2074, 0.2166, 2.2629, 2.2656, 2.3005,\n",
      "        2.0272, 1.6267, 0.1676, 0.1689, 0.1770, 1.3140, 1.7196],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 121 was 67.8%\n",
      "current params: tensor([2.3026, 2.2489, 0.1783, 0.1113, 0.7531, 1.5972, 0.1857, 0.4924, 1.5571,\n",
      "        0.1861, 0.1765, 1.3488, 0.1758, 0.2073, 0.2166, 2.2737, 2.2761, 2.3120,\n",
      "        2.0366, 1.6261, 0.1674, 0.1687, 0.1769, 1.3096, 1.7241],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 122 was 67.9%\n",
      "current params: tensor([2.3082, 2.2538, 0.1782, 0.1055, 0.7326, 1.6024, 0.1863, 0.4729, 1.5616,\n",
      "        0.1865, 0.1763, 1.3458, 0.1755, 0.2072, 0.2166, 2.2845, 2.2866, 2.3235,\n",
      "        2.0459, 1.6253, 0.1672, 0.1685, 0.1768, 1.3053, 1.7287],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 123 was 68.0%\n",
      "current params: tensor([2.3138, 2.2586, 0.1781, 0.1007, 0.7117, 1.6077, 0.1868, 0.4532, 1.5662,\n",
      "        0.1868, 0.1760, 1.3429, 0.1753, 0.2070, 0.2166, 2.2952, 2.2971, 2.3351,\n",
      "        2.0553, 1.6244, 0.1670, 0.1684, 0.1767, 1.3011, 1.7333],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 124 was 68.0%\n",
      "current params: tensor([2.3194, 2.2634, 0.1779, 0.0966, 0.6904, 1.6131, 0.1873, 0.4333, 1.5710,\n",
      "        0.1871, 0.1757, 1.3402, 0.1750, 0.2069, 0.2165, 2.3060, 2.3075, 2.3466,\n",
      "        2.0646, 1.6233, 0.1668, 0.1682, 0.1765, 1.2970, 1.7381],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 125 was 68.2%\n",
      "current params: tensor([2.3249, 2.2682, 0.1778, 0.1075, 0.6688, 1.6186, 0.1877, 0.4131, 1.5759,\n",
      "        0.1874, 0.1755, 1.3376, 0.1747, 0.2067, 0.2164, 2.3168, 2.3180, 2.3581,\n",
      "        2.0739, 1.6221, 0.1666, 0.1680, 0.1764, 1.2931, 1.7429],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 126 was 68.3%\n",
      "current params: tensor([2.3304, 2.2729, 0.1776, 0.1174, 0.6469, 1.6241, 0.1881, 0.3927, 1.5810,\n",
      "        0.1876, 0.1752, 1.3351, 0.1744, 0.2065, 0.2163, 2.3276, 2.3284, 2.3696,\n",
      "        2.0832, 1.6208, 0.1664, 0.1678, 0.1763, 1.2893, 1.7478],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 127 was 68.4%\n",
      "current params: tensor([2.3359, 2.2775, 0.1774, 0.1262, 0.6247, 1.6299, 0.1885, 0.3720, 1.5863,\n",
      "        0.1878, 0.1749, 1.3329, 0.1741, 0.2063, 0.2162, 2.3384, 2.3387, 2.3811,\n",
      "        2.0925, 1.6195, 0.1662, 0.1677, 0.1761, 1.2856, 1.7529],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 128 was 68.5%\n",
      "current params: tensor([2.3412, 2.2819, 0.1773, 0.1343, 0.6022, 1.6358, 0.1888, 0.3512, 1.5919,\n",
      "        0.1880, 0.1745, 1.3308, 0.1738, 0.2061, 0.2161, 2.3492, 2.3491, 2.3926,\n",
      "        2.1018, 1.6181, 0.1660, 0.1675, 0.1759, 1.2821, 1.7581],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 129 was 68.6%\n",
      "current params: tensor([2.3464, 2.2862, 0.1771, 0.1415, 0.5795, 1.6418, 0.1890, 0.3301, 1.5978,\n",
      "        0.1882, 0.1742, 1.3290, 0.1735, 0.2059, 0.2160, 2.3600, 2.3594, 2.4041,\n",
      "        2.1111, 1.6167, 0.1658, 0.1673, 0.1758, 1.2787, 1.7635],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 130 was 68.7%\n",
      "current params: tensor([2.3515, 2.2903, 0.1769, 0.1480, 0.5565, 1.6481, 0.1893, 0.3089, 1.6039,\n",
      "        0.1883, 0.1739, 1.3274, 0.1732, 0.2057, 0.2158, 2.3708, 2.3697, 2.4157,\n",
      "        2.1204, 1.6153, 0.1656, 0.1671, 0.1756, 1.2756, 1.7691],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 131 was 68.9%\n",
      "current params: tensor([2.3565, 2.2942, 0.1767, 0.1539, 0.5332, 1.6547, 0.1895, 0.2874, 1.6104,\n",
      "        0.1884, 0.1735, 1.3260, 0.1729, 0.2054, 0.2157, 2.3817, 2.3800, 2.4272,\n",
      "        2.1298, 1.6140, 0.1654, 0.1670, 0.1754, 1.2726, 1.7749],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 132 was 69.0%\n",
      "current params: tensor([2.3613, 2.2978, 0.1765, 0.1593, 0.5098, 1.6615, 0.1897, 0.2658, 1.6173,\n",
      "        0.1885, 0.1731, 1.3250, 0.1726, 0.2052, 0.2155, 2.3925, 2.3903, 2.4388,\n",
      "        2.1391, 1.6127, 0.1652, 0.1668, 0.1752, 1.2699, 1.7808],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 133 was 69.1%\n",
      "current params: tensor([2.3660, 2.3013, 0.1763, 0.1641, 0.4860, 1.6685, 0.1898, 0.2441, 1.6246,\n",
      "        0.1885, 0.1728, 1.3243, 0.1723, 0.2049, 0.2153, 2.4034, 2.4005, 2.4504,\n",
      "        2.1485, 1.6115, 0.1650, 0.1666, 0.1750, 1.2674, 1.7870],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 134 was 69.3%\n",
      "current params: tensor([2.3705, 2.3045, 0.1761, 0.1684, 0.4621, 1.6758, 0.1900, 0.2221, 1.6323,\n",
      "        0.1886, 0.1724, 1.3239, 0.1720, 0.2047, 0.2151, 2.4143, 2.4107, 2.4620,\n",
      "        2.1580, 1.6103, 0.1648, 0.1665, 0.1748, 1.2653, 1.7934],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 135 was 69.4%\n",
      "current params: tensor([2.3748, 2.3074, 0.1759, 0.1723, 0.4379, 1.6834, 0.1901, 0.2001, 1.6404,\n",
      "        0.1886, 0.1720, 1.3239, 0.1716, 0.2044, 0.2148, 2.4252, 2.4208, 2.4736,\n",
      "        2.1674, 1.6094, 0.1646, 0.1663, 0.1746, 1.2634, 1.8001],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 136 was 69.6%\n",
      "current params: tensor([2.3790, 2.3101, 0.1757, 0.1758, 0.4134, 1.6912, 0.1902, 0.1778, 1.6490,\n",
      "        0.1886, 0.1715, 1.3244, 0.1713, 0.2041, 0.2146, 2.4362, 2.4309, 2.4852,\n",
      "        2.1769, 1.6085, 0.1644, 0.1662, 0.1744, 1.2619, 1.8069],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 137 was 69.8%\n",
      "current params: tensor([2.3831, 2.3126, 0.1755, 0.1789, 0.3887, 1.6993, 0.1903, 0.1555, 1.6581,\n",
      "        0.1886, 0.1711, 1.3253, 0.1709, 0.2038, 0.2143, 2.4471, 2.4409, 2.4969,\n",
      "        2.1863, 1.6078, 0.1642, 0.1660, 0.1742, 1.2609, 1.8140],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 138 was 70.0%\n",
      "current params: tensor([2.3870, 2.3147, 0.1753, 0.1817, 0.3638, 1.7077, 0.1904, 0.1331, 1.6676,\n",
      "        0.1886, 0.1707, 1.3267, 0.1706, 0.2035, 0.2141, 2.4581, 2.4508, 2.5085,\n",
      "        2.1958, 1.6072, 0.1641, 0.1659, 0.1740, 1.2603, 1.8214],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 139 was 70.2%\n",
      "current params: tensor([2.3907, 2.3166, 0.1751, 0.1843, 0.3386, 1.7163, 0.1905, 0.1107, 1.6777,\n",
      "        0.1886, 0.1702, 1.3286, 0.1703, 0.2032, 0.2138, 2.4691, 2.4607, 2.5202,\n",
      "        2.2053, 1.6068, 0.1639, 0.1657, 0.1738, 1.2602, 1.8290],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 140 was 70.4%\n",
      "current params: tensor([2.3943, 2.3183, 0.1749, 0.1865, 0.3132, 1.7251, 0.1905, 0.0884, 1.6884,\n",
      "        0.1885, 0.1697, 1.3311, 0.1699, 0.2029, 0.2135, 2.4801, 2.4705, 2.5319,\n",
      "        2.2148, 1.6067, 0.1637, 0.1656, 0.1736, 1.2607, 1.8368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 141 was 70.6%\n",
      "current params: tensor([2.3977, 2.3196, 0.1748, 0.1885, 0.2876, 1.7342, 0.1906, 0.0998, 1.6996,\n",
      "        0.1885, 0.1692, 1.3342, 0.1696, 0.2025, 0.2132, 2.4912, 2.4801, 2.5436,\n",
      "        2.2243, 1.6067, 0.1636, 0.1655, 0.1735, 1.2619, 1.8449],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 142 was 70.8%\n",
      "current params: tensor([2.4010, 2.3207, 0.1746, 0.1903, 0.2618, 1.7435, 0.1906, 0.1152, 1.7113,\n",
      "        0.1884, 0.1687, 1.3380, 0.1692, 0.2022, 0.2128, 2.5022, 2.4897, 2.5552,\n",
      "        2.2337, 1.6069, 0.1634, 0.1653, 0.1733, 1.2637, 1.8531],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 143 was 70.9%\n",
      "current params: tensor([2.4040, 2.3217, 0.1744, 0.1919, 0.2358, 1.7529, 0.1906, 0.1291, 1.7232,\n",
      "        0.1883, 0.1682, 1.3422, 0.1688, 0.2018, 0.2125, 2.5133, 2.4992, 2.5668,\n",
      "        2.2432, 1.6073, 0.1633, 0.1652, 0.1731, 1.2661, 1.8616],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 144 was 71.0%\n",
      "current params: tensor([2.4069, 2.3224, 0.1742, 0.1932, 0.2099, 1.7624, 0.1906, 0.1416, 1.7352,\n",
      "        0.1882, 0.1677, 1.3468, 0.1685, 0.2015, 0.2121, 2.5244, 2.5088, 2.5783,\n",
      "        2.2527, 1.6079, 0.1631, 0.1651, 0.1728, 1.2690, 1.8701],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 145 was 71.1%\n",
      "current params: tensor([2.4094, 2.3230, 0.1741, 0.1945, 0.1839, 1.7721, 0.1906, 0.1529, 1.7473,\n",
      "        0.1882, 0.1672, 1.3519, 0.1681, 0.2011, 0.2117, 2.5355, 2.5183, 2.5897,\n",
      "        2.2622, 1.6087, 0.1630, 0.1650, 0.1726, 1.2724, 1.8788],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 146 was 71.2%\n",
      "current params: tensor([2.4117, 2.3235, 0.1739, 0.1955, 0.1580, 1.7819, 0.1906, 0.1631, 1.7592,\n",
      "        0.1881, 0.1667, 1.3573, 0.1677, 0.2008, 0.2114, 2.5466, 2.5279, 2.6009,\n",
      "        2.2717, 1.6097, 0.1628, 0.1649, 0.1724, 1.2764, 1.8876],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 147 was 71.3%\n",
      "current params: tensor([2.4138, 2.3239, 0.1737, 0.1964, 0.1323, 1.7919, 0.1906, 0.1723, 1.7711,\n",
      "        0.1880, 0.1662, 1.3631, 0.1673, 0.2004, 0.2110, 2.5577, 2.5375, 2.6120,\n",
      "        2.2812, 1.6108, 0.1627, 0.1648, 0.1722, 1.2808, 1.8964],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 148 was 71.5%\n",
      "current params: tensor([2.4155, 2.3243, 0.1736, 0.1972, 0.1067, 1.8021, 0.1906, 0.1805, 1.7828,\n",
      "        0.1879, 0.1657, 1.3693, 0.1669, 0.2001, 0.2106, 2.5688, 2.5472, 2.6228,\n",
      "        2.2907, 1.6121, 0.1625, 0.1646, 0.1719, 1.2857, 1.9054],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 149 was 71.5%\n",
      "current params: tensor([2.4170, 2.3246, 0.1734, 0.1979, 0.0815, 1.8124, 0.1906, 0.1879, 1.7942,\n",
      "        0.1878, 0.1652, 1.3758, 0.1664, 0.1998, 0.2101, 2.5799, 2.5571, 2.6335,\n",
      "        2.3001, 1.6135, 0.1624, 0.1645, 0.1716, 1.2911, 1.9144],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 150 was 71.6%\n",
      "current params: tensor([2.4181, 2.3250, 0.1733, 0.1984, 0.0930, 1.8231, 0.1905, 0.1945, 1.8054,\n",
      "        0.1877, 0.1647, 1.3827, 0.1660, 0.1995, 0.2097, 2.5910, 2.5670, 2.6440,\n",
      "        2.3096, 1.6151, 0.1623, 0.1644, 0.1713, 1.2969, 1.9235],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 151 was 71.5%\n",
      "current params: tensor([2.4189, 2.3253, 0.1731, 0.1989, 0.1088, 1.8340, 0.1904, 0.2005, 1.8164,\n",
      "        0.1876, 0.1643, 1.3899, 0.1655, 0.1991, 0.2093, 2.6021, 2.5770, 2.6543,\n",
      "        2.3190, 1.6168, 0.1622, 0.1643, 0.1710, 1.3032, 1.9327],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 152 was 71.4%\n",
      "current params: tensor([2.4196, 2.3257, 0.1730, 0.1993, 0.1230, 1.8450, 0.1904, 0.2058, 1.8271,\n",
      "        0.1875, 0.1639, 1.3972, 0.1650, 0.1988, 0.2088, 2.6132, 2.5871, 2.6644,\n",
      "        2.3285, 1.6186, 0.1620, 0.1642, 0.1706, 1.3097, 1.9420],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 153 was 71.3%\n",
      "current params: tensor([2.4201, 2.3260, 0.1729, 0.1996, 0.1358, 1.8560, 0.1903, 0.2106, 1.8376,\n",
      "        0.1875, 0.1635, 1.4045, 0.1645, 0.1985, 0.2084, 2.6243, 2.5972, 2.6744,\n",
      "        2.3379, 1.6204, 0.1619, 0.1641, 0.1702, 1.3164, 1.9513],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 154 was 71.1%\n",
      "current params: tensor([2.4204, 2.3264, 0.1727, 0.1998, 0.1473, 1.8670, 0.1902, 0.2149, 1.8479,\n",
      "        0.1874, 0.1631, 1.4118, 0.1639, 0.1982, 0.2079, 2.6353, 2.6074, 2.6843,\n",
      "        2.3474, 1.6222, 0.1618, 0.1640, 0.1699, 1.3231, 1.9606],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 155 was 71.1%\n",
      "current params: tensor([2.4206, 2.3267, 0.1726, 0.2000, 0.1577, 1.8779, 0.1901, 0.2187, 1.8580,\n",
      "        0.1873, 0.1627, 1.4191, 0.1634, 0.1979, 0.2074, 2.6463, 2.6176, 2.6941,\n",
      "        2.3568, 1.6241, 0.1617, 0.1639, 0.1695, 1.3299, 1.9700],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 156 was 71.0%\n",
      "current params: tensor([2.4208, 2.3270, 0.1724, 0.2001, 0.1671, 1.8887, 0.1900, 0.2222, 1.8678,\n",
      "        0.1872, 0.1623, 1.4263, 0.1628, 0.1977, 0.2070, 2.6572, 2.6278, 2.7038,\n",
      "        2.3663, 1.6259, 0.1616, 0.1638, 0.1691, 1.3366, 1.9793],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 157 was 70.9%\n",
      "current params: tensor([2.4208, 2.3273, 0.1723, 0.2002, 0.1755, 1.8993, 0.1899, 0.2252, 1.8775,\n",
      "        0.1871, 0.1619, 1.4333, 0.1623, 0.1974, 0.2065, 2.6681, 2.6380, 2.7135,\n",
      "        2.3758, 1.6277, 0.1614, 0.1638, 0.1687, 1.3432, 1.9887],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 158 was 70.8%\n",
      "current params: tensor([2.4208, 2.3275, 0.1722, 0.2002, 0.1831, 1.9098, 0.1898, 0.2280, 1.8869,\n",
      "        0.1871, 0.1615, 1.4401, 0.1617, 0.1971, 0.2060, 2.6790, 2.6482, 2.7232,\n",
      "        2.3853, 1.6295, 0.1613, 0.1636, 0.1683, 1.3498, 1.9981],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 159 was 70.8%\n",
      "current params: tensor([2.4208, 2.3278, 0.1720, 0.2002, 0.1899, 1.9201, 0.1897, 0.2304, 1.8961,\n",
      "        0.1870, 0.1611, 1.4468, 0.1612, 0.1968, 0.2055, 2.6898, 2.6584, 2.7327,\n",
      "        2.3948, 1.6312, 0.1612, 0.1635, 0.1679, 1.3562, 2.0075],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 160 was 70.7%\n",
      "current params: tensor([2.4208, 2.3280, 0.1719, 0.2002, 0.1960, 1.9302, 0.1896, 0.2326, 1.9051,\n",
      "        0.1869, 0.1607, 1.4533, 0.1606, 0.1965, 0.2051, 2.7006, 2.6686, 2.7423,\n",
      "        2.4044, 1.6329, 0.1611, 0.1634, 0.1675, 1.3625, 2.0168],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 161 was 70.7%\n",
      "current params: tensor([2.4207, 2.3282, 0.1717, 0.2002, 0.2015, 1.9401, 0.1895, 0.2346, 1.9138,\n",
      "        0.1868, 0.1603, 1.4595, 0.1601, 0.1962, 0.2046, 2.7113, 2.6788, 2.7518,\n",
      "        2.4139, 1.6345, 0.1609, 0.1633, 0.1671, 1.3687, 2.0262],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 162 was 70.7%\n",
      "current params: tensor([2.4206, 2.3284, 0.1716, 0.2001, 0.2065, 1.9498, 0.1894, 0.2363, 1.9224,\n",
      "        0.1867, 0.1599, 1.4656, 0.1595, 0.1959, 0.2041, 2.7220, 2.6890, 2.7613,\n",
      "        2.4235, 1.6360, 0.1608, 0.1632, 0.1667, 1.3746, 2.0355],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 163 was 70.6%\n",
      "current params: tensor([2.4206, 2.3286, 0.1715, 0.2000, 0.2109, 1.9593, 0.1892, 0.2378, 1.9308,\n",
      "        0.1866, 0.1595, 1.4714, 0.1590, 0.1956, 0.2036, 2.7326, 2.6991, 2.7707,\n",
      "        2.4331, 1.6375, 0.1607, 0.1631, 0.1663, 1.3804, 2.0448],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 164 was 70.6%\n",
      "current params: tensor([2.4205, 2.3288, 0.1713, 0.1999, 0.2149, 1.9687, 0.1891, 0.2392, 1.9389,\n",
      "        0.1866, 0.1591, 1.4770, 0.1584, 0.1954, 0.2031, 2.7432, 2.7092, 2.7801,\n",
      "        2.4426, 1.6388, 0.1606, 0.1630, 0.1659, 1.3860, 2.0541],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 165 was 70.6%\n",
      "current params: tensor([2.4204, 2.3290, 0.1712, 0.1998, 0.2185, 1.9778, 0.1890, 0.2404, 1.9469,\n",
      "        0.1865, 0.1587, 1.4824, 0.1579, 0.1951, 0.2026, 2.7537, 2.7192, 2.7896,\n",
      "        2.4522, 1.6401, 0.1604, 0.1629, 0.1655, 1.3914, 2.0634],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 166 was 70.5%\n",
      "current params: tensor([2.4204, 2.3292, 0.1710, 0.1996, 0.2217, 1.9867, 0.1889, 0.2414, 1.9546,\n",
      "        0.1864, 0.1583, 1.4876, 0.1573, 0.1948, 0.2021, 2.7642, 2.7293, 2.7989,\n",
      "        2.4618, 1.6413, 0.1603, 0.1628, 0.1651, 1.3967, 2.0726],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 167 was 70.5%\n",
      "current params: tensor([2.4203, 2.3293, 0.1709, 0.1995, 0.2245, 1.9954, 0.1888, 0.2423, 1.9622,\n",
      "        0.1863, 0.1579, 1.4926, 0.1568, 0.1945, 0.2016, 2.7747, 2.7393, 2.8083,\n",
      "        2.4714, 1.6424, 0.1601, 0.1627, 0.1646, 1.4017, 2.0819],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 168 was 70.5%\n",
      "current params: tensor([2.4203, 2.3295, 0.1707, 0.1993, 0.2271, 2.0039, 0.1887, 0.2431, 1.9696,\n",
      "        0.1862, 0.1575, 1.4974, 0.1562, 0.1942, 0.2011, 2.7851, 2.7492, 2.8176,\n",
      "        2.4811, 1.6434, 0.1600, 0.1626, 0.1642, 1.4066, 2.0911],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 169 was 70.5%\n",
      "current params: tensor([2.4203, 2.3296, 0.1706, 0.1992, 0.2294, 2.0123, 0.1886, 0.2438, 1.9768,\n",
      "        0.1861, 0.1571, 1.5020, 0.1556, 0.1939, 0.2006, 2.7954, 2.7592, 2.8270,\n",
      "        2.4907, 1.6443, 0.1599, 0.1624, 0.1638, 1.4113, 2.1003],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 170 was 70.5%\n",
      "current params: tensor([2.4203, 2.3297, 0.1704, 0.1990, 0.2314, 2.0204, 0.1884, 0.2444, 1.9839,\n",
      "        0.1860, 0.1567, 1.5064, 0.1551, 0.1936, 0.2001, 2.8057, 2.7691, 2.8363,\n",
      "        2.5003, 1.6451, 0.1597, 0.1623, 0.1634, 1.4158, 2.1094],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 171 was 70.5%\n",
      "current params: tensor([2.4203, 2.3298, 0.1703, 0.1988, 0.2332, 2.0283, 0.1883, 0.2449, 1.9907,\n",
      "        0.1859, 0.1563, 1.5106, 0.1545, 0.1934, 0.1996, 2.8160, 2.7789, 2.8455,\n",
      "        2.5099, 1.6458, 0.1596, 0.1622, 0.1630, 1.4202, 2.1186],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 172 was 70.5%\n",
      "current params: tensor([2.4203, 2.3300, 0.1701, 0.1986, 0.2348, 2.0361, 0.1882, 0.2454, 1.9974,\n",
      "        0.1859, 0.1559, 1.5146, 0.1540, 0.1931, 0.1991, 2.8262, 2.7887, 2.8548,\n",
      "        2.5196, 1.6465, 0.1594, 0.1621, 0.1626, 1.4244, 2.1277],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 173 was 70.5%\n",
      "current params: tensor([2.4204, 2.3301, 0.1700, 0.1984, 0.2362, 2.0437, 0.1881, 0.2458, 2.0039,\n",
      "        0.1858, 0.1555, 1.5184, 0.1535, 0.1928, 0.1986, 2.8364, 2.7985, 2.8641,\n",
      "        2.5292, 1.6470, 0.1593, 0.1620, 0.1622, 1.4284, 2.1368],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 174 was 70.5%\n",
      "current params: tensor([2.4204, 2.3302, 0.1698, 0.1982, 0.2375, 2.0511, 0.1880, 0.2461, 2.0103,\n",
      "        0.1857, 0.1551, 1.5221, 0.1529, 0.1925, 0.1981, 2.8466, 2.8083, 2.8733,\n",
      "        2.5388, 1.6474, 0.1591, 0.1618, 0.1618, 1.4323, 2.1459],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 175 was 70.5%\n",
      "current params: tensor([2.4205, 2.3303, 0.1697, 0.1980, 0.2386, 2.0583, 0.1879, 0.2463, 2.0165,\n",
      "        0.1856, 0.1547, 1.5256, 0.1524, 0.1922, 0.1976, 2.8567, 2.8180, 2.8825,\n",
      "        2.5485, 1.6478, 0.1590, 0.1617, 0.1614, 1.4360, 2.1549],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 176 was 70.5%\n",
      "current params: tensor([2.4206, 2.3303, 0.1695, 0.1978, 0.2396, 2.0654, 0.1878, 0.2465, 2.0225,\n",
      "        0.1855, 0.1543, 1.5289, 0.1518, 0.1919, 0.1971, 2.8668, 2.8277, 2.8917,\n",
      "        2.5581, 1.6481, 0.1588, 0.1616, 0.1610, 1.4396, 2.1640],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 177 was 70.5%\n",
      "current params: tensor([2.4207, 2.3304, 0.1694, 0.1976, 0.2404, 2.0723, 0.1877, 0.2467, 2.0284,\n",
      "        0.1854, 0.1539, 1.5321, 0.1513, 0.1916, 0.1966, 2.8768, 2.8373, 2.9009,\n",
      "        2.5677, 1.6482, 0.1587, 0.1615, 0.1606, 1.4430, 2.1730],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 178 was 70.5%\n",
      "current params: tensor([2.4208, 2.3305, 0.1692, 0.1974, 0.2412, 2.0791, 0.1875, 0.2468, 2.0341,\n",
      "        0.1853, 0.1535, 1.5351, 0.1507, 0.1913, 0.1961, 2.8868, 2.8469, 2.9100,\n",
      "        2.5774, 1.6483, 0.1585, 0.1613, 0.1602, 1.4463, 2.1820],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 179 was 70.5%\n",
      "current params: tensor([2.4209, 2.3305, 0.1690, 0.1972, 0.2418, 2.0857, 0.1874, 0.2469, 2.0397,\n",
      "        0.1852, 0.1530, 1.5380, 0.1502, 0.1911, 0.1956, 2.8968, 2.8565, 2.9191,\n",
      "        2.5870, 1.6483, 0.1583, 0.1612, 0.1598, 1.4495, 2.1909],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 180 was 70.5%\n",
      "current params: tensor([2.4210, 2.3306, 0.1689, 0.1970, 0.2424, 2.0921, 0.1873, 0.2469, 2.0452,\n",
      "        0.1851, 0.1526, 1.5407, 0.1497, 0.1908, 0.1951, 2.9067, 2.8660, 2.9282,\n",
      "        2.5966, 1.6482, 0.1582, 0.1611, 0.1594, 1.4525, 2.1999],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 181 was 70.5%\n",
      "current params: tensor([2.4211, 2.3307, 0.1687, 0.1968, 0.2429, 2.0984, 0.1872, 0.2469, 2.0505,\n",
      "        0.1850, 0.1522, 1.5433, 0.1491, 0.1905, 0.1945, 2.9166, 2.8755, 2.9373,\n",
      "        2.6063, 1.6480, 0.1580, 0.1609, 0.1590, 1.4554, 2.2088],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 182 was 70.5%\n",
      "current params: tensor([2.4213, 2.3307, 0.1686, 0.1965, 0.2433, 2.1046, 0.1871, 0.2469, 2.0557,\n",
      "        0.1849, 0.1518, 1.5458, 0.1486, 0.1902, 0.1940, 2.9265, 2.8850, 2.9464,\n",
      "        2.6159, 1.6477, 0.1579, 0.1608, 0.1586, 1.4582, 2.2178],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 183 was 70.5%\n",
      "current params: tensor([2.4214, 2.3307, 0.1684, 0.1963, 0.2436, 2.1106, 0.1870, 0.2468, 2.0607,\n",
      "        0.1848, 0.1514, 1.5481, 0.1480, 0.1899, 0.1935, 2.9363, 2.8945, 2.9555,\n",
      "        2.6255, 1.6474, 0.1577, 0.1607, 0.1582, 1.4608, 2.2267],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 184 was 70.5%\n",
      "current params: tensor([2.4216, 2.3308, 0.1682, 0.1961, 0.2439, 2.1165, 0.1869, 0.2468, 2.0657,\n",
      "        0.1847, 0.1509, 1.5504, 0.1475, 0.1896, 0.1930, 2.9461, 2.9039, 2.9645,\n",
      "        2.6351, 1.6469, 0.1575, 0.1605, 0.1578, 1.4634, 2.2356],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 185 was 70.5%\n",
      "current params: tensor([2.4217, 2.3308, 0.1681, 0.1959, 0.2441, 2.1223, 0.1867, 0.2467, 2.0705,\n",
      "        0.1846, 0.1505, 1.5524, 0.1470, 0.1893, 0.1925, 2.9559, 2.9132, 2.9735,\n",
      "        2.6447, 1.6464, 0.1574, 0.1604, 0.1574, 1.4658, 2.2444],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 186 was 70.5%\n",
      "current params: tensor([2.4219, 2.3308, 0.1679, 0.1957, 0.2443, 2.1279, 0.1866, 0.2466, 2.0751,\n",
      "        0.1845, 0.1501, 1.5544, 0.1464, 0.1890, 0.1919, 2.9656, 2.9226, 2.9825,\n",
      "        2.6544, 1.6457, 0.1572, 0.1603, 0.1570, 1.4682, 2.2533],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 187 was 70.5%\n",
      "current params: tensor([2.4221, 2.3308, 0.1677, 0.1955, 0.2444, 2.1335, 0.1865, 0.2465, 2.0797,\n",
      "        0.1844, 0.1496, 1.5563, 0.1459, 0.1887, 0.1914, 2.9753, 2.9319, 2.9915,\n",
      "        2.6640, 1.6450, 0.1570, 0.1601, 0.1566, 1.4704, 2.2621],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 188 was 70.5%\n",
      "current params: tensor([2.4222, 2.3308, 0.1676, 0.1952, 0.2445, 2.1389, 0.1864, 0.2463, 2.0841,\n",
      "        0.1843, 0.1492, 1.5580, 0.1453, 0.1884, 0.1909, 2.9850, 2.9412, 3.0004,\n",
      "        2.6736, 1.6443, 0.1568, 0.1600, 0.1562, 1.4726, 2.2710],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 189 was 70.6%\n",
      "current params: tensor([2.4224, 2.3308, 0.1674, 0.1950, 0.2445, 2.1441, 0.1863, 0.2462, 2.0885,\n",
      "        0.1842, 0.1488, 1.5596, 0.1448, 0.1881, 0.1903, 2.9946, 2.9505, 3.0094,\n",
      "        2.6832, 1.6434, 0.1567, 0.1598, 0.1558, 1.4746, 2.2798],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 190 was 70.6%\n",
      "current params: tensor([2.4226, 2.3308, 0.1672, 0.1948, 0.2445, 2.1493, 0.1862, 0.2460, 2.0927,\n",
      "        0.1842, 0.1483, 1.5612, 0.1443, 0.1879, 0.1898, 3.0042, 2.9597, 3.0183,\n",
      "        2.6928, 1.6424, 0.1565, 0.1597, 0.1554, 1.4766, 2.2886],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 191 was 70.6%\n",
      "current params: tensor([2.4227, 2.3307, 0.1670, 0.1946, 0.2445, 2.1544, 0.1861, 0.2458, 2.0968,\n",
      "        0.1841, 0.1479, 1.5626, 0.1437, 0.1876, 0.1893, 3.0138, 2.9689, 3.0272,\n",
      "        2.7023, 1.6414, 0.1563, 0.1595, 0.1550, 1.4784, 2.2974],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 192 was 70.6%\n",
      "current params: tensor([2.4229, 2.3307, 0.1669, 0.1944, 0.2445, 2.1593, 0.1859, 0.2456, 2.1008,\n",
      "        0.1840, 0.1475, 1.5639, 0.1432, 0.1873, 0.1887, 3.0234, 2.9781, 3.0361,\n",
      "        2.7119, 1.6403, 0.1561, 0.1594, 0.1545, 1.4802, 2.3062],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 193 was 70.6%\n",
      "current params: tensor([2.4231, 2.3306, 0.1667, 0.1942, 0.2444, 2.1641, 0.1858, 0.2454, 2.1047,\n",
      "        0.1839, 0.1470, 1.5651, 0.1427, 0.1870, 0.1882, 3.0329, 2.9872, 3.0449,\n",
      "        2.7215, 1.6391, 0.1560, 0.1593, 0.1541, 1.4819, 2.3149],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 194 was 70.6%\n",
      "current params: tensor([2.4232, 2.3306, 0.1665, 0.1939, 0.2443, 2.1689, 0.1857, 0.2452, 2.1084,\n",
      "        0.1838, 0.1466, 1.5662, 0.1421, 0.1867, 0.1876, 3.0424, 2.9963, 3.0538,\n",
      "        2.7311, 1.6378, 0.1558, 0.1591, 0.1537, 1.4835, 2.3237],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 195 was 70.6%\n",
      "current params: tensor([2.4234, 2.3305, 0.1663, 0.1937, 0.2442, 2.1735, 0.1856, 0.2450, 2.1121,\n",
      "        0.1837, 0.1462, 1.5672, 0.1416, 0.1864, 0.1871, 3.0519, 3.0054, 3.0626,\n",
      "        2.7406, 1.6364, 0.1556, 0.1590, 0.1533, 1.4850, 2.3324],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 196 was 70.6%\n",
      "current params: tensor([2.4236, 2.3304, 0.1662, 0.1935, 0.2441, 2.1780, 0.1855, 0.2448, 2.1157,\n",
      "        0.1836, 0.1457, 1.5681, 0.1410, 0.1861, 0.1865, 3.0614, 3.0145, 3.0714,\n",
      "        2.7502, 1.6350, 0.1554, 0.1588, 0.1529, 1.4864, 2.3412],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 197 was 70.7%\n",
      "current params: tensor([2.4237, 2.3303, 0.1660, 0.1933, 0.2439, 2.1825, 0.1854, 0.2446, 2.1192,\n",
      "        0.1835, 0.1453, 1.5690, 0.1405, 0.1858, 0.1860, 3.0708, 3.0236, 3.0802,\n",
      "        2.7598, 1.6335, 0.1552, 0.1587, 0.1525, 1.4878, 2.3499],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 198 was 70.7%\n",
      "current params: tensor([2.4239, 2.3302, 0.1658, 0.1931, 0.2438, 2.1868, 0.1853, 0.2443, 2.1226,\n",
      "        0.1833, 0.1448, 1.5697, 0.1400, 0.1855, 0.1854, 3.0802, 3.0326, 3.0889,\n",
      "        2.7693, 1.6319, 0.1551, 0.1585, 0.1521, 1.4891, 2.3586],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 199 was 70.7%\n",
      "optimization complete\n"
     ]
    },
    {
     "data": {
      "text/plain": "<steric_free_simulator.vectorized_rxn_net.VectorizedRxnNet at 0x7f7d72765748>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = Optimizer(reaction_network=rn,\n",
    "                  sim_runtime=.1,\n",
    "                  optim_iterations=200,\n",
    "                  learning_rate=.01,\n",
    "                  score_constant=.01,\n",
    "                  device='cpu')\n",
    "optim.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the finished optimizer in case we want to use it's data later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "with open('./local_saves/optimizer_ap2_vivo_stablerxn.pkl', 'wb') as f:\n",
    "    pk.dump(optim, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an optimizer that has already been run, make sure not to overwrite anything needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./local_saves/optimizer_ap2_vivo_stablerxn.pkl', 'rb') as f:\n",
    "    optim = pk.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot of Simulation before any optimization**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(iteration=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of Simulation after all optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(iteration=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot of simulation yield at each optimization iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final discovered activation energies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([38.9622, 37.1127,  2.0700,  1.7838,  1.7107, 34.3581, 16.9147,  2.4250,\n",
      "        37.6520, 18.4188,  2.1001, 32.6036,  1.7681,  1.8374,  1.8270, 26.2503,\n",
      "        29.7505, 30.5779, 24.0286, 28.2227,  7.2661,  7.5065,  2.2021, 32.4703,\n",
      "        17.4028], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(optim.rn.kon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}