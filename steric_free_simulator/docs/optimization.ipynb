{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Optimizing the Vectorized Simulations #\n",
    "\n",
    "Besides speed, the benefit of using the vectorized simulation based on the torch framework\n",
    "is that we can track all operations that happen across a simulation. This allows us to find\n",
    "the gradients with respect to any intermediate variable, and more importantly the gradient\n",
    "of the yield the final copies of some complex with respect to initial parameters.\n",
    "\n",
    "## An Introduction to Automatic Differentiation ##\n",
    "\n",
    "Automatic differentiation is a powerful technique based on a simple principle of calculus,\n",
    "the multivariable chain rule. Imagine we have function $ y = f(x, w)$ and we want to minimize $y$ by adjusting parameter $w$ we can\n",
    "this by computing $\\frac {\\partial y} {\\partial w}$. Automatic differentiation allows us to do this\n",
    "for arbitrary function $f$ without needing to know $f$ in advance.\n",
    "\n",
    "Whenever variable $u$ is involved in any operation, we create a new internal variable $v$ representing the result of\n",
    "the operation, pointer back to $w$ and any other variables, and the function describing the partial $\\frac {\\partial v} {\\partial u}$.\n",
    "In this way we construct a directed acyclic \"compuation graph\", where $w$ and other input variable $x$ are leaves and the final optimization\n",
    "target $y$ is the root.\n",
    "\n",
    "We can now calculate the partial of $y$ with respect to each intermediate variable, and eventually $w$ by repeatedly\n",
    "applying the chain rule of differentiation, $\\frac {\\partial y} {\\partial u} = \\frac {\\partial y} {\\partial v}  \\frac {\\partial v} {\\partial u}$\n",
    "\n",
    "## Applying to Our Use Case##\n",
    "\n",
    "We can easily write the simulator described in the `vectorized_network_simulation.ipynb` notebook as a function. Let's Define:\n",
    "\n",
    "- Simulator: $S$\n",
    "- Vector of association constants: $\\vec{k_{on}}$\n",
    "- Vector of Reaction $\\Delta G$s: $\\vec{G}$\n",
    "- Vector of initial copy numbers: $\\vec{C_o}$\n",
    "- Matrix mapping species to reactions: $\\textbf{M}$\n",
    "- Simulation run time: $t$\n",
    "- Final copies of complete complex: $Y$\n",
    "- maximum possible yield: $min(\\vec{C_o})$\n",
    "\n",
    "The simulator itself can be expressed as:\n",
    "\n",
    "$Y = S(\\vec{k_{on}}, \\vec{G}, \\vec{C_o}, \\textbf{M}, t)$\n",
    "\n",
    "From the yield $Y$ we can construct the full loss term:\n",
    "\n",
    "$L = \\frac{-Y}{min(\\vec{C_o})} + ReLU(-1*(k - min\\_constant))$\n",
    "\n",
    "Here the first term is the percent of the theoretical maximum possible complete complex yield,\n",
    "and the second term is designed to prevent the on or off association constants from getting unreasonably small\n",
    "or negative. The ReLU function is a piecewise function that will be a linear positive penalty when $k < min\\_constant$,\n",
    "and will equal $0$ otherwise. Minimizing the full objective $L$ w.r.t. $k_{on}$ will find values for $k_{on}$ that\n",
    "maximize full complex yield while still being physically reasonable.\n",
    "\n",
    "Automatic differentiation as described in the above section provide a method for doing this. We can run the simulation\n",
    "until completion, all the while constructing the computation graph. We can then compute all the gradients, and then\n",
    "step the parameter values in the direction of the gradient.\n",
    "\n",
    "In other words, we compute $\\frac{\\partial L}{\\partial \\vec{k_{on}}}$ via automatic differentiation,\n",
    "and then do $k_{on} = k_{on} + \\lambda * \\frac{\\partial L}{\\partial \\vec{k_{on}}}$.\n",
    "\n",
    "We preform a simulation then update the parameters in the direction of the gradient a set number of times\n",
    "before stopping.\n",
    "\n",
    "## Optimization Example With AP2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencerloggia/Projects/biphy/multi_assembly/steric_free_simulator/energy_space_explorer.py:8: UserWarning: Import of 'rosetta' as a top-level module is deprecated and may be removed in 2018, import via 'pyrosetta.rosetta'.\n",
      "  from rosetta.protocols.relax import *\n"
     ]
    }
   ],
   "source": [
    "# first we need to import the required modules\n",
    "# make sure jupyter path is correct for loading local modules\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from steric_free_simulator import Optimizer\n",
    "from steric_free_simulator import ReactionNetwork"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To begin, we need to generate the reaction network from the input files (see `reaction_network_building.ipynb`).\n",
    "We can't directly resolve a vectorized network from an input file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base_input = './input_files/ap2.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can feed the vanilla (networkx based) network into the optimizer and vectorized simulator, but it will be copied and\n",
    "converted to a vectorized network. Let's ensure the network is set to the proper initial conditions and then initialize the\n",
    "optimizer.\n",
    "\n",
    "**Optimization and Simulation Parameters**:\n",
    "\n",
    "- **sim_runtime**: time (in seconds) that the simulation will run for.\n",
    "- **optim_iterations**: number of simulations to run, optimizing parameters at each one.\n",
    "- **learning rate**: factor to multiply calculated gradients by.\n",
    "- **device**: The hardware device to run simulations and optimizations on.\n",
    "\n",
    "If the parameter is not specified at optimizer construction, it is given a default value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "rn.reset()\n",
    "optim = Optimizer(reaction_network=rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=500,\n",
    "                  learning_rate=.001,\n",
    "                  device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can run the optimization. After optimization, we write the new \"optimized\" parameters\n",
    "into a copy of a reaction network so that we can inspect them if desired."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "yield on sim iteration 0 was 28.9%\n",
      "current params: tensor([1.0010, 0.9990, 0.9990, 1.0010, 0.9990, 1.0010, 1.0010, 1.0010, 0.9990,\n",
      "        0.9990, 1.0010, 1.0010, 0.9990, 0.9990, 1.0010, 0.9990, 1.0010, 1.0010,\n",
      "        0.9990, 0.9990, 1.0010, 0.9990], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 1 was 28.9%\n",
      "current params: tensor([1.0020, 0.9980, 0.9980, 1.0020, 0.9980, 1.0020, 1.0020, 1.0020, 0.9980,\n",
      "        0.9980, 1.0020, 1.0020, 0.9980, 0.9980, 1.0020, 0.9980, 1.0020, 1.0020,\n",
      "        0.9980, 0.9980, 1.0020, 0.9980], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 2 was 28.9%\n",
      "current params: tensor([1.0030, 0.9970, 0.9970, 1.0030, 0.9970, 1.0030, 1.0030, 1.0030, 0.9970,\n",
      "        0.9970, 1.0030, 1.0030, 0.9970, 0.9970, 1.0030, 0.9970, 1.0030, 1.0030,\n",
      "        0.9970, 0.9970, 1.0030, 0.9970], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 3 was 28.9%\n",
      "current params: tensor([1.0040, 0.9960, 0.9960, 1.0040, 0.9960, 1.0040, 1.0040, 1.0040, 0.9960,\n",
      "        0.9960, 1.0040, 1.0040, 0.9960, 0.9960, 1.0040, 0.9960, 1.0040, 1.0040,\n",
      "        0.9960, 0.9960, 1.0040, 0.9960], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 4 was 28.9%\n",
      "current params: tensor([1.0050, 0.9950, 0.9950, 1.0050, 0.9950, 1.0050, 1.0050, 1.0050, 0.9950,\n",
      "        0.9950, 1.0050, 1.0050, 0.9950, 0.9950, 1.0050, 0.9950, 1.0050, 1.0050,\n",
      "        0.9950, 0.9950, 1.0050, 0.9950], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 5 was 28.9%\n",
      "current params: tensor([1.0060, 0.9940, 0.9940, 1.0060, 0.9940, 1.0060, 1.0060, 1.0060, 0.9940,\n",
      "        0.9940, 1.0060, 1.0060, 0.9940, 0.9940, 1.0060, 0.9940, 1.0060, 1.0060,\n",
      "        0.9940, 0.9940, 1.0060, 0.9940], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 6 was 28.9%\n",
      "current params: tensor([1.0070, 0.9930, 0.9930, 1.0070, 0.9930, 1.0070, 1.0070, 1.0070, 0.9930,\n",
      "        0.9930, 1.0070, 1.0070, 0.9930, 0.9930, 1.0070, 0.9930, 1.0070, 1.0070,\n",
      "        0.9930, 0.9930, 1.0070, 0.9930], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 7 was 28.9%\n",
      "current params: tensor([1.0081, 0.9920, 0.9920, 1.0080, 0.9920, 1.0080, 1.0080, 1.0080, 0.9920,\n",
      "        0.9920, 1.0080, 1.0080, 0.9920, 0.9920, 1.0080, 0.9920, 1.0080, 1.0080,\n",
      "        0.9920, 0.9920, 1.0080, 0.9920], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 8 was 29.0%\n",
      "current params: tensor([1.0091, 0.9910, 0.9910, 1.0090, 0.9910, 1.0090, 1.0090, 1.0090, 0.9910,\n",
      "        0.9910, 1.0090, 1.0090, 0.9910, 0.9910, 1.0090, 0.9910, 1.0090, 1.0090,\n",
      "        0.9910, 0.9910, 1.0090, 0.9910], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 9 was 29.0%\n",
      "current params: tensor([1.0101, 0.9900, 0.9900, 1.0099, 0.9900, 1.0100, 1.0100, 1.0100, 0.9900,\n",
      "        0.9899, 1.0100, 1.0100, 0.9900, 0.9900, 1.0100, 0.9900, 1.0100, 1.0100,\n",
      "        0.9900, 0.9900, 1.0100, 0.9900], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 10 was 29.0%\n",
      "current params: tensor([1.0112, 0.9890, 0.9890, 1.0109, 0.9890, 1.0110, 1.0110, 1.0110, 0.9890,\n",
      "        0.9889, 1.0110, 1.0110, 0.9890, 0.9889, 1.0110, 0.9890, 1.0110, 1.0110,\n",
      "        0.9890, 0.9890, 1.0110, 0.9890], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 11 was 29.0%\n",
      "current params: tensor([1.0123, 0.9880, 0.9880, 1.0119, 0.9880, 1.0120, 1.0120, 1.0120, 0.9880,\n",
      "        0.9879, 1.0120, 1.0120, 0.9880, 0.9879, 1.0120, 0.9880, 1.0120, 1.0120,\n",
      "        0.9881, 0.9880, 1.0120, 0.9880], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 12 was 29.0%\n",
      "current params: tensor([1.0133, 0.9870, 0.9870, 1.0129, 0.9870, 1.0130, 1.0130, 1.0130, 0.9870,\n",
      "        0.9869, 1.0130, 1.0130, 0.9870, 0.9869, 1.0130, 0.9870, 1.0130, 1.0130,\n",
      "        0.9871, 0.9870, 1.0130, 0.9870], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 13 was 29.0%\n",
      "current params: tensor([1.0144, 0.9860, 0.9860, 1.0138, 0.9860, 1.0140, 1.0140, 1.0140, 0.9861,\n",
      "        0.9858, 1.0140, 1.0140, 0.9860, 0.9859, 1.0140, 0.9860, 1.0140, 1.0140,\n",
      "        0.9861, 0.9860, 1.0140, 0.9860], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 14 was 29.0%\n",
      "current params: tensor([1.0155, 0.9850, 0.9850, 1.0148, 0.9849, 1.0150, 1.0150, 1.0150, 0.9851,\n",
      "        0.9848, 1.0150, 1.0150, 0.9850, 0.9849, 1.0150, 0.9850, 1.0150, 1.0150,\n",
      "        0.9851, 0.9851, 1.0150, 0.9850], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 15 was 29.0%\n",
      "current params: tensor([1.0166, 0.9840, 0.9840, 1.0158, 0.9839, 1.0160, 1.0160, 1.0160, 0.9841,\n",
      "        0.9838, 1.0160, 1.0160, 0.9840, 0.9839, 1.0160, 0.9840, 1.0160, 1.0160,\n",
      "        0.9841, 0.9841, 1.0160, 0.9840], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 16 was 29.0%\n",
      "current params: tensor([1.0177, 0.9830, 0.9830, 1.0167, 0.9829, 1.0170, 1.0170, 1.0170, 0.9831,\n",
      "        0.9827, 1.0170, 1.0170, 0.9830, 0.9828, 1.0170, 0.9830, 1.0170, 1.0170,\n",
      "        0.9831, 0.9831, 1.0170, 0.9830], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 17 was 29.1%\n",
      "current params: tensor([1.0188, 0.9820, 0.9820, 1.0177, 0.9819, 1.0180, 1.0180, 1.0179, 0.9821,\n",
      "        0.9817, 1.0180, 1.0180, 0.9821, 0.9818, 1.0180, 0.9820, 1.0179, 1.0180,\n",
      "        0.9822, 0.9821, 1.0180, 0.9820], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 18 was 29.1%\n",
      "current params: tensor([1.0199, 0.9811, 0.9810, 1.0186, 0.9809, 1.0190, 1.0190, 1.0189, 0.9811,\n",
      "        0.9806, 1.0190, 1.0189, 0.9811, 0.9808, 1.0190, 0.9810, 1.0189, 1.0190,\n",
      "        0.9812, 0.9811, 1.0190, 0.9810], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 19 was 29.1%\n",
      "current params: tensor([1.0211, 0.9801, 0.9800, 1.0196, 0.9799, 1.0200, 1.0200, 1.0199, 0.9802,\n",
      "        0.9795, 1.0199, 1.0199, 0.9801, 0.9797, 1.0200, 0.9800, 1.0199, 1.0200,\n",
      "        0.9802, 0.9801, 1.0200, 0.9800], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 20 was 29.1%\n",
      "current params: tensor([1.0222, 0.9791, 0.9790, 1.0205, 0.9789, 1.0209, 1.0210, 1.0209, 0.9792,\n",
      "        0.9785, 1.0209, 1.0209, 0.9791, 0.9787, 1.0209, 0.9790, 1.0209, 1.0210,\n",
      "        0.9793, 0.9792, 1.0210, 0.9790], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 21 was 29.1%\n",
      "current params: tensor([1.0234, 0.9781, 0.9780, 1.0214, 0.9778, 1.0219, 1.0219, 1.0219, 0.9782,\n",
      "        0.9774, 1.0219, 1.0219, 0.9781, 0.9776, 1.0219, 0.9780, 1.0219, 1.0220,\n",
      "        0.9783, 0.9782, 1.0220, 0.9780], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 22 was 29.1%\n",
      "current params: tensor([1.0246, 0.9771, 0.9770, 1.0223, 0.9768, 1.0229, 1.0229, 1.0229, 0.9772,\n",
      "        0.9763, 1.0229, 1.0229, 0.9771, 0.9766, 1.0229, 0.9770, 1.0229, 1.0230,\n",
      "        0.9774, 0.9772, 1.0230, 0.9770], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 23 was 29.1%\n",
      "current params: tensor([1.0257, 0.9761, 0.9760, 1.0232, 0.9758, 1.0239, 1.0239, 1.0239, 0.9763,\n",
      "        0.9753, 1.0239, 1.0239, 0.9761, 0.9755, 1.0239, 0.9760, 1.0239, 1.0240,\n",
      "        0.9764, 0.9762, 1.0240, 0.9760], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 24 was 29.1%\n",
      "current params: tensor([1.0269, 0.9751, 0.9750, 1.0241, 0.9748, 1.0249, 1.0249, 1.0249, 0.9753,\n",
      "        0.9742, 1.0249, 1.0249, 0.9751, 0.9745, 1.0249, 0.9750, 1.0249, 1.0250,\n",
      "        0.9755, 0.9753, 1.0250, 0.9750], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 25 was 29.1%\n",
      "current params: tensor([1.0281, 0.9741, 0.9740, 1.0250, 0.9737, 1.0259, 1.0259, 1.0259, 0.9743,\n",
      "        0.9731, 1.0259, 1.0259, 0.9741, 0.9734, 1.0259, 0.9739, 1.0258, 1.0260,\n",
      "        0.9745, 0.9743, 1.0260, 0.9740], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 26 was 29.2%\n",
      "current params: tensor([1.0293, 0.9731, 0.9730, 1.0259, 0.9727, 1.0269, 1.0269, 1.0268, 0.9734,\n",
      "        0.9720, 1.0269, 1.0269, 0.9732, 0.9724, 1.0269, 0.9729, 1.0268, 1.0270,\n",
      "        0.9736, 0.9733, 1.0270, 0.9729], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 27 was 29.2%\n",
      "current params: tensor([1.0305, 0.9722, 0.9720, 1.0268, 0.9717, 1.0279, 1.0279, 1.0278, 0.9724,\n",
      "        0.9709, 1.0279, 1.0278, 0.9722, 0.9713, 1.0279, 0.9719, 1.0278, 1.0279,\n",
      "        0.9726, 0.9724, 1.0280, 0.9719], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 28 was 29.2%\n",
      "current params: tensor([1.0318, 0.9712, 0.9710, 1.0276, 0.9706, 1.0289, 1.0289, 1.0288, 0.9715,\n",
      "        0.9698, 1.0288, 1.0288, 0.9712, 0.9702, 1.0289, 0.9709, 1.0288, 1.0289,\n",
      "        0.9717, 0.9714, 1.0290, 0.9709], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 29 was 29.2%\n",
      "current params: tensor([1.0330, 0.9702, 0.9700, 1.0285, 0.9696, 1.0298, 1.0299, 1.0298, 0.9705,\n",
      "        0.9687, 1.0298, 1.0298, 0.9702, 0.9692, 1.0298, 0.9699, 1.0298, 1.0299,\n",
      "        0.9708, 0.9705, 1.0300, 0.9699], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 30 was 29.2%\n",
      "current params: tensor([1.0342, 0.9692, 0.9690, 1.0293, 0.9686, 1.0308, 1.0309, 1.0308, 0.9696,\n",
      "        0.9675, 1.0308, 1.0308, 0.9692, 0.9681, 1.0308, 0.9689, 1.0307, 1.0309,\n",
      "        0.9699, 0.9695, 1.0310, 0.9689], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 31 was 29.2%\n",
      "current params: tensor([1.0355, 0.9682, 0.9680, 1.0302, 0.9675, 1.0318, 1.0318, 1.0317, 0.9686,\n",
      "        0.9664, 1.0318, 1.0318, 0.9683, 0.9670, 1.0318, 0.9679, 1.0317, 1.0319,\n",
      "        0.9690, 0.9685, 1.0320, 0.9679], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 32 was 29.2%\n",
      "current params: tensor([1.0367, 0.9672, 0.9671, 1.0310, 0.9665, 1.0328, 1.0328, 1.0327, 0.9677,\n",
      "        0.9653, 1.0328, 1.0328, 0.9673, 0.9659, 1.0328, 0.9669, 1.0327, 1.0329,\n",
      "        0.9680, 0.9676, 1.0330, 0.9669], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 33 was 29.2%\n",
      "current params: tensor([1.0380, 0.9663, 0.9661, 1.0318, 0.9655, 1.0338, 1.0338, 1.0337, 0.9667,\n",
      "        0.9642, 1.0338, 1.0337, 0.9663, 0.9648, 1.0338, 0.9659, 1.0337, 1.0339,\n",
      "        0.9671, 0.9667, 1.0340, 0.9659], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 34 was 29.2%\n",
      "current params: tensor([1.0393, 0.9653, 0.9651, 1.0326, 0.9644, 1.0348, 1.0348, 1.0347, 0.9658,\n",
      "        0.9630, 1.0347, 1.0347, 0.9653, 0.9637, 1.0348, 0.9649, 1.0346, 1.0349,\n",
      "        0.9662, 0.9657, 1.0350, 0.9649], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 35 was 29.3%\n",
      "current params: tensor([1.0406, 0.9643, 0.9641, 1.0334, 0.9634, 1.0357, 1.0358, 1.0356, 0.9649,\n",
      "        0.9619, 1.0357, 1.0357, 0.9644, 0.9626, 1.0357, 0.9639, 1.0356, 1.0359,\n",
      "        0.9653, 0.9648, 1.0360, 0.9639], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 36 was 29.3%\n",
      "current params: tensor([1.0419, 0.9633, 0.9631, 1.0342, 0.9623, 1.0367, 1.0368, 1.0366, 0.9639,\n",
      "        0.9607, 1.0367, 1.0367, 0.9634, 0.9615, 1.0367, 0.9629, 1.0366, 1.0369,\n",
      "        0.9645, 0.9638, 1.0370, 0.9629], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 37 was 29.3%\n",
      "current params: tensor([1.0432, 0.9624, 0.9621, 1.0349, 0.9613, 1.0377, 1.0378, 1.0376, 0.9630,\n",
      "        0.9596, 1.0377, 1.0376, 0.9624, 0.9604, 1.0377, 0.9619, 1.0375, 1.0379,\n",
      "        0.9636, 0.9629, 1.0380, 0.9619], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 38 was 29.3%\n",
      "current params: tensor([1.0445, 0.9614, 0.9611, 1.0357, 0.9602, 1.0387, 1.0387, 1.0386, 0.9621,\n",
      "        0.9584, 1.0387, 1.0386, 0.9615, 0.9593, 1.0387, 0.9608, 1.0385, 1.0389,\n",
      "        0.9627, 0.9620, 1.0389, 0.9609], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 39 was 29.3%\n",
      "current params: tensor([1.0458, 0.9604, 0.9601, 1.0364, 0.9592, 1.0397, 1.0397, 1.0395, 0.9612,\n",
      "        0.9572, 1.0396, 1.0396, 0.9605, 0.9582, 1.0397, 0.9598, 1.0395, 1.0399,\n",
      "        0.9618, 0.9610, 1.0399, 0.9598], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 40 was 29.3%\n",
      "current params: tensor([1.0471, 0.9595, 0.9591, 1.0371, 0.9581, 1.0406, 1.0407, 1.0405, 0.9603,\n",
      "        0.9561, 1.0406, 1.0405, 0.9595, 0.9571, 1.0406, 0.9588, 1.0404, 1.0408,\n",
      "        0.9610, 0.9601, 1.0409, 0.9588], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 41 was 29.3%\n",
      "current params: tensor([1.0484, 0.9585, 0.9581, 1.0379, 0.9570, 1.0416, 1.0417, 1.0415, 0.9594,\n",
      "        0.9549, 1.0416, 1.0415, 0.9586, 0.9560, 1.0416, 0.9578, 1.0414, 1.0418,\n",
      "        0.9601, 0.9592, 1.0419, 0.9578], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 42 was 29.3%\n",
      "current params: tensor([1.0497, 0.9575, 0.9571, 1.0385, 0.9560, 1.0426, 1.0427, 1.0424, 0.9584,\n",
      "        0.9537, 1.0426, 1.0425, 0.9576, 0.9548, 1.0426, 0.9568, 1.0424, 1.0428,\n",
      "        0.9593, 0.9583, 1.0429, 0.9568], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 43 was 29.3%\n",
      "current params: tensor([1.0511, 0.9566, 0.9561, 1.0392, 0.9549, 1.0436, 1.0436, 1.0434, 0.9575,\n",
      "        0.9525, 1.0435, 1.0435, 0.9567, 0.9537, 1.0436, 0.9558, 1.0433, 1.0438,\n",
      "        0.9584, 0.9574, 1.0439, 0.9558], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 44 was 29.4%\n",
      "current params: tensor([1.0524, 0.9556, 0.9551, 1.0399, 0.9539, 1.0445, 1.0446, 1.0443, 0.9566,\n",
      "        0.9513, 1.0445, 1.0444, 0.9557, 0.9526, 1.0445, 0.9548, 1.0443, 1.0448,\n",
      "        0.9576, 0.9565, 1.0449, 0.9548], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 45 was 29.2%\n",
      "current params: tensor([1.0538, 0.9546, 0.9541, 1.0405, 0.9528, 1.0455, 1.0456, 1.0453, 0.9557,\n",
      "        0.9501, 1.0455, 1.0454, 0.9547, 0.9514, 1.0455, 0.9538, 1.0453, 1.0458,\n",
      "        0.9568, 0.9556, 1.0459, 0.9538], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 46 was 29.2%\n",
      "current params: tensor([1.0551, 0.9536, 0.9531, 1.0410, 0.9517, 1.0465, 1.0466, 1.0463, 0.9548,\n",
      "        0.9488, 1.0465, 1.0464, 0.9538, 0.9502, 1.0465, 0.9528, 1.0462, 1.0468,\n",
      "        0.9559, 0.9547, 1.0469, 0.9527], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 47 was 29.2%\n",
      "current params: tensor([1.0565, 0.9527, 0.9521, 1.0415, 0.9506, 1.0475, 1.0476, 1.0473, 0.9539,\n",
      "        0.9476, 1.0475, 1.0473, 0.9528, 0.9490, 1.0475, 0.9517, 1.0472, 1.0478,\n",
      "        0.9551, 0.9538, 1.0479, 0.9517], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 48 was 29.2%\n",
      "current params: tensor([1.0579, 0.9517, 0.9511, 1.0420, 0.9494, 1.0485, 1.0486, 1.0483, 0.9530,\n",
      "        0.9462, 1.0485, 1.0483, 0.9518, 0.9478, 1.0485, 0.9507, 1.0482, 1.0488,\n",
      "        0.9543, 0.9529, 1.0489, 0.9507], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 49 was 29.2%\n",
      "current params: tensor([1.0592, 0.9507, 0.9501, 1.0423, 0.9483, 1.0495, 1.0496, 1.0493, 0.9521,\n",
      "        0.9449, 1.0495, 1.0493, 0.9508, 0.9466, 1.0495, 0.9497, 1.0492, 1.0498,\n",
      "        0.9536, 0.9520, 1.0499, 0.9496], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 50 was 29.2%\n",
      "current params: tensor([1.0606, 0.9497, 0.9491, 1.0427, 0.9471, 1.0506, 1.0506, 1.0503, 0.9511,\n",
      "        0.9436, 1.0505, 1.0503, 0.9498, 0.9453, 1.0505, 0.9487, 1.0501, 1.0509,\n",
      "        0.9528, 0.9511, 1.0509, 0.9486], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 51 was 29.3%\n",
      "current params: tensor([1.0620, 0.9487, 0.9481, 1.0430, 0.9460, 1.0516, 1.0516, 1.0513, 0.9502,\n",
      "        0.9422, 1.0515, 1.0513, 0.9488, 0.9441, 1.0515, 0.9477, 1.0511, 1.0519,\n",
      "        0.9520, 0.9502, 1.0519, 0.9475], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 52 was 29.3%\n",
      "current params: tensor([1.0634, 0.9478, 0.9470, 1.0432, 0.9448, 1.0526, 1.0526, 1.0523, 0.9493,\n",
      "        0.9408, 1.0525, 1.0523, 0.9478, 0.9428, 1.0525, 0.9467, 1.0521, 1.0529,\n",
      "        0.9513, 0.9494, 1.0529, 0.9464], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 53 was 29.3%\n",
      "current params: tensor([1.0648, 0.9468, 0.9460, 1.0434, 0.9436, 1.0537, 1.0536, 1.0534, 0.9484,\n",
      "        0.9394, 1.0535, 1.0533, 0.9468, 0.9415, 1.0535, 0.9457, 1.0531, 1.0539,\n",
      "        0.9505, 0.9485, 1.0539, 0.9454], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 54 was 29.3%\n",
      "current params: tensor([1.0662, 0.9458, 0.9450, 1.0435, 0.9425, 1.0547, 1.0547, 1.0544, 0.9475,\n",
      "        0.9380, 1.0545, 1.0542, 0.9458, 0.9403, 1.0545, 0.9447, 1.0541, 1.0550,\n",
      "        0.9498, 0.9477, 1.0549, 0.9443], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 55 was 29.3%\n",
      "current params: tensor([1.0676, 0.9448, 0.9440, 1.0436, 0.9413, 1.0557, 1.0557, 1.0554, 0.9465,\n",
      "        0.9366, 1.0556, 1.0552, 0.9448, 0.9390, 1.0555, 0.9437, 1.0551, 1.0560,\n",
      "        0.9491, 0.9468, 1.0559, 0.9433], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 56 was 29.3%\n",
      "current params: tensor([1.0691, 0.9438, 0.9429, 1.0437, 0.9401, 1.0568, 1.0567, 1.0564, 0.9456,\n",
      "        0.9352, 1.0566, 1.0562, 0.9438, 0.9377, 1.0566, 0.9427, 1.0561, 1.0570,\n",
      "        0.9484, 0.9460, 1.0569, 0.9422], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 57 was 29.3%\n",
      "current params: tensor([1.0705, 0.9428, 0.9419, 1.0437, 0.9389, 1.0578, 1.0577, 1.0575, 0.9447,\n",
      "        0.9338, 1.0576, 1.0572, 0.9428, 0.9364, 1.0576, 0.9417, 1.0571, 1.0581,\n",
      "        0.9477, 0.9451, 1.0579, 0.9411], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 58 was 29.4%\n",
      "current params: tensor([1.0719, 0.9418, 0.9409, 1.0437, 0.9377, 1.0589, 1.0587, 1.0585, 0.9438,\n",
      "        0.9324, 1.0586, 1.0582, 0.9418, 0.9351, 1.0586, 0.9407, 1.0581, 1.0591,\n",
      "        0.9470, 0.9443, 1.0589, 0.9400], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 59 was 29.4%\n",
      "current params: tensor([1.0733, 0.9409, 0.9399, 1.0436, 0.9365, 1.0599, 1.0598, 1.0595, 0.9429,\n",
      "        0.9310, 1.0597, 1.0592, 0.9408, 0.9338, 1.0596, 0.9397, 1.0591, 1.0602,\n",
      "        0.9463, 0.9435, 1.0599, 0.9390], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 60 was 29.4%\n",
      "current params: tensor([1.0748, 0.9399, 0.9388, 1.0435, 0.9353, 1.0609, 1.0608, 1.0605, 0.9420,\n",
      "        0.9296, 1.0607, 1.0602, 0.9397, 0.9325, 1.0606, 0.9387, 1.0600, 1.0612,\n",
      "        0.9456, 0.9427, 1.0609, 0.9379], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 61 was 29.4%\n",
      "current params: tensor([1.0762, 0.9389, 0.9378, 1.0433, 0.9341, 1.0620, 1.0618, 1.0616, 0.9411,\n",
      "        0.9282, 1.0617, 1.0612, 0.9387, 0.9312, 1.0616, 0.9377, 1.0610, 1.0622,\n",
      "        0.9450, 0.9418, 1.0619, 0.9368], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 62 was 29.4%\n",
      "current params: tensor([1.0777, 0.9379, 0.9368, 1.0431, 0.9329, 1.0630, 1.0628, 1.0626, 0.9402,\n",
      "        0.9267, 1.0627, 1.0622, 0.9377, 0.9298, 1.0626, 0.9384, 1.0620, 1.0633,\n",
      "        0.9444, 0.9410, 1.0629, 0.9357], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 63 was 29.4%\n",
      "current params: tensor([1.0791, 0.9369, 0.9357, 1.0429, 0.9317, 1.0641, 1.0638, 1.0636, 0.9393,\n",
      "        0.9253, 1.0637, 1.0631, 0.9367, 0.9285, 1.0637, 0.9395, 1.0630, 1.0643,\n",
      "        0.9437, 0.9402, 1.0639, 0.9347], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 64 was 29.4%\n",
      "current params: tensor([1.0806, 0.9359, 0.9347, 1.0426, 0.9305, 1.0651, 1.0649, 1.0646, 0.9384,\n",
      "        0.9239, 1.0648, 1.0641, 0.9357, 0.9272, 1.0647, 0.9404, 1.0640, 1.0653,\n",
      "        0.9431, 0.9394, 1.0649, 0.9336], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 65 was 29.4%\n",
      "current params: tensor([1.0821, 0.9350, 0.9337, 1.0423, 0.9292, 1.0662, 1.0659, 1.0657, 0.9375,\n",
      "        0.9224, 1.0658, 1.0651, 0.9347, 0.9259, 1.0657, 0.9412, 1.0650, 1.0664,\n",
      "        0.9425, 0.9386, 1.0659, 0.9325], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 66 was 29.5%\n",
      "current params: tensor([1.0835, 0.9340, 0.9327, 1.0419, 0.9280, 1.0672, 1.0669, 1.0667, 0.9366,\n",
      "        0.9210, 1.0668, 1.0661, 0.9337, 0.9246, 1.0667, 0.9419, 1.0660, 1.0674,\n",
      "        0.9419, 0.9378, 1.0669, 0.9314], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 67 was 29.5%\n",
      "current params: tensor([1.0850, 0.9330, 0.9316, 1.0415, 0.9268, 1.0682, 1.0679, 1.0677, 0.9357,\n",
      "        0.9196, 1.0678, 1.0671, 0.9327, 0.9232, 1.0677, 0.9426, 1.0670, 1.0684,\n",
      "        0.9413, 0.9370, 1.0679, 0.9303], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 68 was 29.5%\n",
      "current params: tensor([1.0865, 0.9320, 0.9306, 1.0410, 0.9256, 1.0693, 1.0689, 1.0687, 0.9349,\n",
      "        0.9182, 1.0689, 1.0681, 0.9317, 0.9219, 1.0687, 0.9432, 1.0679, 1.0695,\n",
      "        0.9408, 0.9363, 1.0689, 0.9293], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 69 was 29.5%\n",
      "current params: tensor([1.0880, 0.9311, 0.9296, 1.0405, 0.9244, 1.0703, 1.0700, 1.0697, 0.9340,\n",
      "        0.9167, 1.0699, 1.0690, 0.9308, 0.9206, 1.0697, 0.9437, 1.0689, 1.0705,\n",
      "        0.9402, 0.9355, 1.0699, 0.9282], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 70 was 29.5%\n",
      "current params: tensor([1.0895, 0.9301, 0.9286, 1.0400, 0.9232, 1.0714, 1.0710, 1.0708, 0.9331,\n",
      "        0.9153, 1.0709, 1.0700, 0.9298, 0.9192, 1.0707, 0.9442, 1.0699, 1.0715,\n",
      "        0.9397, 0.9347, 1.0709, 0.9271], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 71 was 29.5%\n",
      "current params: tensor([1.0910, 0.9291, 0.9275, 1.0394, 0.9219, 1.0724, 1.0720, 1.0718, 0.9323,\n",
      "        0.9139, 1.0719, 1.0710, 0.9288, 0.9179, 1.0717, 0.9446, 1.0709, 1.0726,\n",
      "        0.9391, 0.9340, 1.0719, 0.9260], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 72 was 29.5%\n",
      "current params: tensor([1.0924, 0.9282, 0.9265, 1.0388, 0.9207, 1.0734, 1.0730, 1.0728, 0.9314,\n",
      "        0.9124, 1.0729, 1.0720, 0.9278, 0.9166, 1.0727, 0.9450, 1.0718, 1.0736,\n",
      "        0.9386, 0.9332, 1.0729, 0.9249], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 73 was 29.5%\n",
      "current params: tensor([1.0939, 0.9272, 0.9255, 1.0382, 0.9195, 1.0745, 1.0740, 1.0738, 0.9306,\n",
      "        0.9110, 1.0739, 1.0729, 0.9268, 0.9152, 1.0738, 0.9453, 1.0728, 1.0746,\n",
      "        0.9381, 0.9325, 1.0739, 0.9238], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 74 was 29.6%\n",
      "current params: tensor([1.0954, 0.9263, 0.9245, 1.0375, 0.9183, 1.0755, 1.0750, 1.0748, 0.9297,\n",
      "        0.9096, 1.0750, 1.0739, 0.9258, 0.9139, 1.0748, 0.9456, 1.0738, 1.0757,\n",
      "        0.9376, 0.9317, 1.0749, 0.9227], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 75 was 29.6%\n",
      "current params: tensor([1.0969, 0.9253, 0.9234, 1.0368, 0.9170, 1.0765, 1.0761, 1.0758, 0.9289,\n",
      "        0.9082, 1.0760, 1.0749, 0.9248, 0.9126, 1.0758, 0.9459, 1.0748, 1.0767,\n",
      "        0.9371, 0.9310, 1.0759, 0.9217], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 76 was 29.6%\n",
      "current params: tensor([1.0985, 0.9243, 0.9224, 1.0360, 0.9158, 1.0776, 1.0771, 1.0768, 0.9281,\n",
      "        0.9067, 1.0770, 1.0759, 0.9239, 0.9112, 1.0768, 0.9461, 1.0757, 1.0777,\n",
      "        0.9367, 0.9303, 1.0769, 0.9206], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 77 was 29.6%\n",
      "current params: tensor([1.1000, 0.9234, 0.9214, 1.0352, 0.9146, 1.0786, 1.0781, 1.0778, 0.9273,\n",
      "        0.9053, 1.0780, 1.0768, 0.9229, 0.9099, 1.0777, 0.9463, 1.0767, 1.0788,\n",
      "        0.9362, 0.9295, 1.0779, 0.9195], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 78 was 29.6%\n",
      "current params: tensor([1.1015, 0.9224, 0.9204, 1.0344, 0.9133, 1.0796, 1.0791, 1.0788, 0.9265,\n",
      "        0.9039, 1.0790, 1.0778, 0.9219, 0.9085, 1.0787, 0.9465, 1.0777, 1.0798,\n",
      "        0.9358, 0.9288, 1.0789, 0.9184], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 79 was 29.6%\n",
      "current params: tensor([1.1030, 0.9215, 0.9194, 1.0335, 0.9121, 1.0806, 1.0801, 1.0799, 0.9256,\n",
      "        0.9024, 1.0800, 1.0787, 0.9209, 0.9072, 1.0797, 0.9467, 1.0786, 1.0808,\n",
      "        0.9354, 0.9281, 1.0799, 0.9173], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 80 was 29.6%\n",
      "current params: tensor([1.1045, 0.9205, 0.9183, 1.0326, 0.9109, 1.0817, 1.0811, 1.0809, 0.9248,\n",
      "        0.9010, 1.0810, 1.0797, 0.9200, 0.9059, 1.0807, 0.9468, 1.0796, 1.0818,\n",
      "        0.9350, 0.9274, 1.0809, 0.9162], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 81 was 29.6%\n",
      "current params: tensor([1.1060, 0.9196, 0.9173, 1.0317, 0.9096, 1.0827, 1.0821, 1.0819, 0.9241,\n",
      "        0.8996, 1.0820, 1.0807, 0.9190, 0.9045, 1.0817, 0.9469, 1.0806, 1.0829,\n",
      "        0.9346, 0.9267, 1.0819, 0.9151], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 82 was 29.7%\n",
      "current params: tensor([1.1076, 0.9187, 0.9163, 1.0307, 0.9084, 1.0837, 1.0832, 1.0828, 0.9233,\n",
      "        0.8981, 1.0830, 1.0816, 0.9180, 0.9032, 1.0827, 0.9470, 1.0815, 1.0839,\n",
      "        0.9342, 0.9260, 1.0829, 0.9140], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 83 was 29.7%\n",
      "current params: tensor([1.1091, 0.9177, 0.9153, 1.0297, 0.9072, 1.0847, 1.0842, 1.0838, 0.9225,\n",
      "        0.8967, 1.0840, 1.0826, 0.9171, 0.9018, 1.0837, 0.9471, 1.0825, 1.0849,\n",
      "        0.9338, 0.9253, 1.0839, 0.9129], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 84 was 29.7%\n",
      "current params: tensor([1.1106, 0.9168, 0.9143, 1.0286, 0.9059, 1.0858, 1.0852, 1.0848, 0.9217,\n",
      "        0.8953, 1.0850, 1.0835, 0.9161, 0.9005, 1.0847, 0.9472, 1.0834, 1.0859,\n",
      "        0.9335, 0.9247, 1.0849, 0.9118], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 85 was 29.7%\n",
      "current params: tensor([1.1121, 0.9158, 0.9132, 1.0275, 0.9047, 1.0868, 1.0862, 1.0858, 0.9209,\n",
      "        0.8938, 1.0860, 1.0845, 0.9152, 0.8991, 1.0857, 0.9472, 1.0844, 1.0869,\n",
      "        0.9332, 0.9240, 1.0859, 0.9107], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 86 was 29.7%\n",
      "current params: tensor([1.1137, 0.9149, 0.9122, 1.0264, 0.9035, 1.0878, 1.0872, 1.0868, 0.9202,\n",
      "        0.8924, 1.0870, 1.0855, 0.9142, 0.8978, 1.0867, 0.9473, 1.0853, 1.0880,\n",
      "        0.9329, 0.9233, 1.0869, 0.9097], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 87 was 29.7%\n",
      "current params: tensor([1.1152, 0.9140, 0.9112, 1.0253, 0.9022, 1.0888, 1.0882, 1.0878, 0.9194,\n",
      "        0.8910, 1.0880, 1.0864, 0.9133, 0.8964, 1.0876, 0.9473, 1.0863, 1.0890,\n",
      "        0.9326, 0.9227, 1.0879, 0.9086], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 88 was 29.7%\n",
      "current params: tensor([1.1167, 0.9130, 0.9102, 1.0241, 0.9010, 1.0898, 1.0892, 1.0888, 0.9187,\n",
      "        0.8895, 1.0891, 1.0874, 0.9123, 0.8951, 1.0886, 0.9473, 1.0872, 1.0900,\n",
      "        0.9323, 0.9220, 1.0889, 0.9075], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 89 was 29.7%\n",
      "current params: tensor([1.1183, 0.9121, 0.9092, 1.0229, 0.8997, 1.0908, 1.0902, 1.0898, 0.9179,\n",
      "        0.8881, 1.0901, 1.0883, 0.9114, 0.8937, 1.0896, 0.9473, 1.0882, 1.0910,\n",
      "        0.9320, 0.9214, 1.0899, 0.9064], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 90 was 29.8%\n",
      "current params: tensor([1.1198, 0.9112, 0.9082, 1.0217, 0.8985, 1.0918, 1.0912, 1.0908, 0.9172,\n",
      "        0.8867, 1.0910, 1.0893, 0.9104, 0.8924, 1.0906, 0.9473, 1.0891, 1.0920,\n",
      "        0.9318, 0.9207, 1.0909, 0.9053], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 91 was 29.8%\n",
      "current params: tensor([1.1214, 0.9103, 0.9072, 1.0205, 0.8972, 1.0929, 1.0922, 1.0917, 0.9165,\n",
      "        0.8852, 1.0920, 1.0902, 0.9095, 0.8910, 1.0916, 0.9473, 1.0901, 1.0930,\n",
      "        0.9316, 0.9201, 1.0919, 0.9042], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 92 was 29.8%\n",
      "current params: tensor([1.1229, 0.9094, 0.9062, 1.0192, 0.8960, 1.0939, 1.0932, 1.0927, 0.9158,\n",
      "        0.8838, 1.0930, 1.0911, 0.9085, 0.8897, 1.0925, 0.9473, 1.0910, 1.0941,\n",
      "        0.9313, 0.9195, 1.0929, 0.9031], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 93 was 29.8%\n",
      "current params: tensor([1.1245, 0.9084, 0.9051, 1.0179, 0.8948, 1.0949, 1.0942, 1.0937, 0.9151,\n",
      "        0.8824, 1.0940, 1.0921, 0.9076, 0.8883, 1.0935, 0.9473, 1.0920, 1.0951,\n",
      "        0.9311, 0.9189, 1.0939, 0.9020], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 94 was 29.8%\n",
      "current params: tensor([1.1260, 0.9075, 0.9041, 1.0165, 0.8935, 1.0959, 1.0952, 1.0947, 0.9144,\n",
      "        0.8809, 1.0950, 1.0930, 0.9067, 0.8869, 1.0945, 0.9473, 1.0929, 1.0961,\n",
      "        0.9310, 0.9183, 1.0949, 0.9009], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 95 was 29.8%\n",
      "current params: tensor([1.1276, 0.9066, 0.9031, 1.0152, 0.8922, 1.0969, 1.0963, 1.0957, 0.9137,\n",
      "        0.8795, 1.0960, 1.0940, 0.9057, 0.8856, 1.0954, 0.9473, 1.0939, 1.0971,\n",
      "        0.9308, 0.9177, 1.0959, 0.8998], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 96 was 29.8%\n",
      "current params: tensor([1.1291, 0.9057, 0.9021, 1.0138, 0.8910, 1.0979, 1.0973, 1.0966, 0.9130,\n",
      "        0.8780, 1.0970, 1.0949, 0.9048, 0.8842, 1.0964, 0.9472, 1.0948, 1.0981,\n",
      "        0.9307, 0.9171, 1.0969, 0.8987], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 97 was 29.8%\n",
      "current params: tensor([1.1307, 0.9048, 0.9011, 1.0124, 0.8897, 1.0989, 1.0983, 1.0976, 0.9123,\n",
      "        0.8766, 1.0980, 1.0958, 0.9039, 0.8829, 1.0974, 0.9472, 1.0957, 1.0991,\n",
      "        0.9306, 0.9165, 1.0979, 0.8976], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 98 was 29.9%\n",
      "current params: tensor([1.1322, 0.9039, 0.9001, 1.0110, 0.8885, 1.0999, 1.0993, 1.0986, 0.9116,\n",
      "        0.8751, 1.0990, 1.0968, 0.9030, 0.8815, 1.0984, 0.9472, 1.0967, 1.1001,\n",
      "        0.9305, 0.9160, 1.0989, 0.8965], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 99 was 29.9%\n",
      "current params: tensor([1.1338, 0.9030, 0.8991, 1.0095, 0.8872, 1.1009, 1.1003, 1.0995, 0.9110,\n",
      "        0.8737, 1.1000, 1.0977, 0.9020, 0.8801, 1.0993, 0.9471, 1.0976, 1.1011,\n",
      "        0.9304, 0.9154, 1.0998, 0.8954], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 100 was 29.9%\n",
      "current params: tensor([1.1353, 0.9021, 0.8981, 1.0081, 0.8860, 1.1019, 1.1013, 1.1005, 0.9103,\n",
      "        0.8722, 1.1010, 1.0986, 0.9011, 0.8788, 1.1003, 0.9471, 1.0985, 1.1021,\n",
      "        0.9303, 0.9149, 1.1008, 0.8943], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 101 was 29.9%\n",
      "current params: tensor([1.1369, 0.9012, 0.8971, 1.0066, 0.8847, 1.1029, 1.1023, 1.1015, 0.9097,\n",
      "        0.8708, 1.1020, 1.0996, 0.9002, 0.8774, 1.1012, 0.9470, 1.0995, 1.1031,\n",
      "        0.9303, 0.9143, 1.1018, 0.8932], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 102 was 29.9%\n",
      "current params: tensor([1.1384, 0.9003, 0.8961, 1.0051, 0.8834, 1.1039, 1.1033, 1.1024, 0.9090,\n",
      "        0.8693, 1.1030, 1.1005, 0.8993, 0.8760, 1.1022, 0.9470, 1.1004, 1.1041,\n",
      "        0.9302, 0.9138, 1.1028, 0.8921], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 103 was 29.9%\n",
      "current params: tensor([1.1400, 0.8994, 0.8951, 1.0036, 0.8822, 1.1049, 1.1043, 1.1034, 0.9084,\n",
      "        0.8679, 1.1040, 1.1014, 0.8984, 0.8747, 1.1032, 0.9469, 1.1013, 1.1051,\n",
      "        0.9302, 0.9133, 1.1038, 0.8910], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 104 was 29.9%\n",
      "current params: tensor([1.1416, 0.8985, 0.8941, 1.0021, 0.8809, 1.1059, 1.1053, 1.1044, 0.9078,\n",
      "        0.8664, 1.1049, 1.1023, 0.8975, 0.8733, 1.1041, 0.9468, 1.1023, 1.1061,\n",
      "        0.9302, 0.9127, 1.1048, 0.8898], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 105 was 29.9%\n",
      "current params: tensor([1.1431, 0.8976, 0.8930, 1.0005, 0.8796, 1.1069, 1.1063, 1.1053, 0.9072,\n",
      "        0.8650, 1.1059, 1.1033, 0.8966, 0.8719, 1.1051, 0.9468, 1.1032, 1.1071,\n",
      "        0.9303, 0.9122, 1.1058, 0.8887], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 106 was 30.0%\n",
      "current params: tensor([1.1447, 0.8968, 0.8920, 0.9989, 0.8784, 1.1079, 1.1073, 1.1063, 0.9066,\n",
      "        0.8635, 1.1069, 1.1042, 0.8957, 0.8705, 1.1060, 0.9467, 1.1041, 1.1081,\n",
      "        0.9303, 0.9117, 1.1068, 0.8876], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 107 was 30.0%\n",
      "current params: tensor([1.1462, 0.8959, 0.8910, 0.9974, 0.8771, 1.1089, 1.1083, 1.1072, 0.9060,\n",
      "        0.8621, 1.1079, 1.1051, 0.8948, 0.8692, 1.1070, 0.9466, 1.1050, 1.1091,\n",
      "        0.9304, 0.9113, 1.1078, 0.8865], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 108 was 30.0%\n",
      "current params: tensor([1.1478, 0.8950, 0.8900, 0.9958, 0.8758, 1.1099, 1.1093, 1.1082, 0.9054,\n",
      "        0.8606, 1.1089, 1.1060, 0.8939, 0.8678, 1.1079, 0.9466, 1.1060, 1.1101,\n",
      "        0.9305, 0.9108, 1.1088, 0.8854], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 109 was 30.0%\n",
      "current params: tensor([1.1494, 0.8941, 0.8890, 0.9942, 0.8746, 1.1108, 1.1103, 1.1092, 0.9048,\n",
      "        0.8592, 1.1099, 1.1069, 0.8930, 0.8664, 1.1089, 0.9465, 1.1069, 1.1111,\n",
      "        0.9306, 0.9103, 1.1098, 0.8843], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 110 was 30.0%\n",
      "current params: tensor([1.1509, 0.8932, 0.8880, 0.9925, 0.8733, 1.1118, 1.1113, 1.1101, 0.9042,\n",
      "        0.8577, 1.1109, 1.1079, 0.8921, 0.8650, 1.1098, 0.9464, 1.1078, 1.1121,\n",
      "        0.9308, 0.9099, 1.1108, 0.8832], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 111 was 30.0%\n",
      "current params: tensor([1.1525, 0.8924, 0.8870, 0.9909, 0.8720, 1.1128, 1.1123, 1.1111, 0.9037,\n",
      "        0.8562, 1.1118, 1.1088, 0.8912, 0.8636, 1.1108, 0.9464, 1.1087, 1.1131,\n",
      "        0.9309, 0.9094, 1.1118, 0.8821], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 112 was 30.0%\n",
      "current params: tensor([1.1541, 0.8915, 0.8860, 0.9893, 0.8707, 1.1138, 1.1133, 1.1120, 0.9031,\n",
      "        0.8548, 1.1128, 1.1097, 0.8903, 0.8623, 1.1117, 0.9463, 1.1096, 1.1141,\n",
      "        0.9311, 0.9090, 1.1128, 0.8810], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 113 was 30.0%\n",
      "current params: tensor([1.1556, 0.8906, 0.8850, 0.9876, 0.8694, 1.1148, 1.1143, 1.1130, 0.9026,\n",
      "        0.8533, 1.1138, 1.1106, 0.8894, 0.8609, 1.1127, 0.9462, 1.1106, 1.1151,\n",
      "        0.9313, 0.9085, 1.1138, 0.8798], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 114 was 30.1%\n",
      "current params: tensor([1.1572, 0.8898, 0.8840, 0.9859, 0.8681, 1.1158, 1.1153, 1.1139, 0.9020,\n",
      "        0.8518, 1.1148, 1.1115, 0.8885, 0.8595, 1.1136, 0.9462, 1.1115, 1.1161,\n",
      "        0.9316, 0.9081, 1.1148, 0.8787], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 115 was 30.1%\n",
      "current params: tensor([1.1588, 0.8889, 0.8830, 0.9843, 0.8669, 1.1168, 1.1163, 1.1149, 0.9015,\n",
      "        0.8504, 1.1158, 1.1124, 0.8877, 0.8581, 1.1146, 0.9461, 1.1124, 1.1171,\n",
      "        0.9318, 0.9077, 1.1158, 0.8776], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 116 was 30.1%\n",
      "current params: tensor([1.1604, 0.8881, 0.8820, 0.9826, 0.8656, 1.1178, 1.1173, 1.1158, 0.9010,\n",
      "        0.8489, 1.1168, 1.1133, 0.8868, 0.8567, 1.1155, 0.9460, 1.1133, 1.1181,\n",
      "        0.9321, 0.9073, 1.1168, 0.8765], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 117 was 30.1%\n",
      "current params: tensor([1.1619, 0.8872, 0.8810, 0.9809, 0.8643, 1.1187, 1.1183, 1.1167, 0.9005,\n",
      "        0.8474, 1.1177, 1.1142, 0.8859, 0.8553, 1.1165, 0.9459, 1.1142, 1.1191,\n",
      "        0.9324, 0.9069, 1.1177, 0.8754], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 118 was 30.1%\n",
      "current params: tensor([1.1635, 0.8864, 0.8800, 0.9792, 0.8630, 1.1197, 1.1193, 1.1177, 0.9000,\n",
      "        0.8459, 1.1187, 1.1151, 0.8850, 0.8539, 1.1174, 0.9458, 1.1151, 1.1201,\n",
      "        0.9327, 0.9066, 1.1187, 0.8743], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 119 was 30.1%\n",
      "current params: tensor([1.1651, 0.8855, 0.8790, 0.9774, 0.8617, 1.1207, 1.1203, 1.1186, 0.8995,\n",
      "        0.8445, 1.1197, 1.1160, 0.8842, 0.8526, 1.1183, 0.9458, 1.1160, 1.1211,\n",
      "        0.9330, 0.9062, 1.1197, 0.8731], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 120 was 30.1%\n",
      "current params: tensor([1.1666, 0.8847, 0.8780, 0.9757, 0.8604, 1.1217, 1.1213, 1.1196, 0.8990,\n",
      "        0.8430, 1.1207, 1.1170, 0.8833, 0.8512, 1.1193, 0.9457, 1.1169, 1.1220,\n",
      "        0.9334, 0.9059, 1.1207, 0.8720], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 121 was 30.1%\n",
      "current params: tensor([1.1682, 0.8838, 0.8771, 0.9740, 0.8591, 1.1227, 1.1223, 1.1205, 0.8986,\n",
      "        0.8415, 1.1217, 1.1179, 0.8824, 0.8498, 1.1202, 0.9456, 1.1178, 1.1230,\n",
      "        0.9338, 0.9055, 1.1217, 0.8709], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 122 was 30.2%\n",
      "current params: tensor([1.1698, 0.8830, 0.8761, 0.9722, 0.8578, 1.1236, 1.1233, 1.1214, 0.8981,\n",
      "        0.8400, 1.1226, 1.1188, 0.8816, 0.8484, 1.1211, 0.9455, 1.1187, 1.1240,\n",
      "        0.9342, 0.9052, 1.1227, 0.8698], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 123 was 30.2%\n",
      "current params: tensor([1.1714, 0.8822, 0.8751, 0.9705, 0.8565, 1.1246, 1.1243, 1.1224, 0.8977,\n",
      "        0.8385, 1.1236, 1.1197, 0.8807, 0.8470, 1.1221, 0.9454, 1.1197, 1.1250,\n",
      "        0.9346, 0.9049, 1.1237, 0.8686], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 124 was 30.2%\n",
      "current params: tensor([1.1729, 0.8813, 0.8741, 0.9687, 0.8552, 1.1256, 1.1253, 1.1233, 0.8972,\n",
      "        0.8370, 1.1246, 1.1205, 0.8799, 0.8456, 1.1230, 0.9453, 1.1206, 1.1260,\n",
      "        0.9351, 0.9046, 1.1247, 0.8675], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 125 was 30.2%\n",
      "current params: tensor([1.1745, 0.8805, 0.8731, 0.9670, 0.8539, 1.1266, 1.1263, 1.1243, 0.8968,\n",
      "        0.8356, 1.1256, 1.1214, 0.8790, 0.8442, 1.1239, 0.9453, 1.1215, 1.1270,\n",
      "        0.9356, 0.9043, 1.1257, 0.8664], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 126 was 30.2%\n",
      "current params: tensor([1.1761, 0.8797, 0.8721, 0.9652, 0.8526, 1.1276, 1.1273, 1.1252, 0.8964,\n",
      "        0.8341, 1.1265, 1.1223, 0.8782, 0.8428, 1.1249, 0.9452, 1.1224, 1.1280,\n",
      "        0.9361, 0.9040, 1.1267, 0.8653], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 127 was 30.2%\n",
      "current params: tensor([1.1777, 0.8788, 0.8711, 0.9634, 0.8513, 1.1285, 1.1283, 1.1261, 0.8960,\n",
      "        0.8326, 1.1275, 1.1232, 0.8773, 0.8414, 1.1258, 0.9451, 1.1233, 1.1289,\n",
      "        0.9366, 0.9037, 1.1277, 0.8641], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 128 was 30.2%\n",
      "current params: tensor([1.1792, 0.8780, 0.8701, 0.9616, 0.8499, 1.1295, 1.1293, 1.1271, 0.8956,\n",
      "        0.8311, 1.1285, 1.1241, 0.8765, 0.8400, 1.1267, 0.9450, 1.1242, 1.1299,\n",
      "        0.9371, 0.9035, 1.1287, 0.8630], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 129 was 30.2%\n",
      "current params: tensor([1.1808, 0.8772, 0.8691, 0.9599, 0.8486, 1.1305, 1.1303, 1.1280, 0.8952,\n",
      "        0.8296, 1.1295, 1.1250, 0.8756, 0.8385, 1.1277, 0.9449, 1.1251, 1.1309,\n",
      "        0.9377, 0.9032, 1.1297, 0.8619], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 130 was 30.3%\n",
      "current params: tensor([1.1824, 0.8764, 0.8681, 0.9581, 0.8473, 1.1315, 1.1313, 1.1289, 0.8949,\n",
      "        0.8281, 1.1305, 1.1259, 0.8748, 0.8371, 1.1286, 0.9448, 1.1260, 1.1319,\n",
      "        0.9383, 0.9030, 1.1307, 0.8607], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 131 was 30.3%\n",
      "current params: tensor([1.1840, 0.8756, 0.8671, 0.9563, 0.8460, 1.1324, 1.1323, 1.1298, 0.8945,\n",
      "        0.8266, 1.1314, 1.1268, 0.8739, 0.8357, 1.1295, 0.9447, 1.1269, 1.1329,\n",
      "        0.9389, 0.9028, 1.1316, 0.8596], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 132 was 30.3%\n",
      "current params: tensor([1.1856, 0.8748, 0.8661, 0.9545, 0.8447, 1.1334, 1.1333, 1.1308, 0.8942,\n",
      "        0.8251, 1.1324, 1.1277, 0.8731, 0.8343, 1.1304, 0.9447, 1.1278, 1.1338,\n",
      "        0.9396, 0.9026, 1.1326, 0.8584], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 133 was 30.3%\n",
      "current params: tensor([1.1871, 0.8740, 0.8651, 0.9527, 0.8433, 1.1344, 1.1343, 1.1317, 0.8938,\n",
      "        0.8236, 1.1334, 1.1286, 0.8723, 0.8329, 1.1314, 0.9446, 1.1286, 1.1348,\n",
      "        0.9403, 0.9024, 1.1336, 0.8573], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 134 was 30.3%\n",
      "current params: tensor([1.1887, 0.8732, 0.8641, 0.9509, 0.8420, 1.1354, 1.1353, 1.1326, 0.8935,\n",
      "        0.8221, 1.1344, 1.1294, 0.8714, 0.8315, 1.1323, 0.9445, 1.1295, 1.1358,\n",
      "        0.9410, 0.9022, 1.1346, 0.8562], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 135 was 30.3%\n",
      "current params: tensor([1.1903, 0.8724, 0.8632, 0.9490, 0.8407, 1.1363, 1.1363, 1.1335, 0.8932,\n",
      "        0.8206, 1.1353, 1.1303, 0.8706, 0.8301, 1.1332, 0.9444, 1.1304, 1.1368,\n",
      "        0.9417, 0.9021, 1.1356, 0.8550], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 136 was 30.3%\n",
      "current params: tensor([1.1919, 0.8716, 0.8622, 0.9472, 0.8393, 1.1373, 1.1373, 1.1345, 0.8929,\n",
      "        0.8191, 1.1363, 1.1312, 0.8698, 0.8287, 1.1341, 0.9443, 1.1313, 1.1378,\n",
      "        0.9424, 0.9019, 1.1366, 0.8539], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 137 was 30.3%\n",
      "current params: tensor([1.1934, 0.8708, 0.8612, 0.9454, 0.8380, 1.1383, 1.1383, 1.1354, 0.8926,\n",
      "        0.8175, 1.1373, 1.1321, 0.8690, 0.8272, 1.1350, 0.9442, 1.1322, 1.1387,\n",
      "        0.9432, 0.9018, 1.1376, 0.8527], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 138 was 30.4%\n",
      "current params: tensor([1.1950, 0.8700, 0.8602, 0.9436, 0.8367, 1.1392, 1.1393, 1.1363, 0.8923,\n",
      "        0.8160, 1.1383, 1.1330, 0.8682, 0.8258, 1.1359, 0.9441, 1.1331, 1.1397,\n",
      "        0.9440, 0.9016, 1.1386, 0.8516], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 139 was 30.4%\n",
      "current params: tensor([1.1966, 0.8692, 0.8592, 0.9417, 0.8353, 1.1402, 1.1403, 1.1372, 0.8921,\n",
      "        0.8145, 1.1392, 1.1338, 0.8673, 0.8244, 1.1369, 0.9440, 1.1340, 1.1407,\n",
      "        0.9448, 0.9015, 1.1396, 0.8505], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 140 was 30.4%\n",
      "current params: tensor([1.1982, 0.8684, 0.8582, 0.9399, 0.8340, 1.1412, 1.1413, 1.1381, 0.8918,\n",
      "        0.8130, 1.1402, 1.1347, 0.8665, 0.8230, 1.1378, 0.9439, 1.1349, 1.1417,\n",
      "        0.9456, 0.9015, 1.1406, 0.8493], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 141 was 30.4%\n",
      "current params: tensor([1.1998, 0.8677, 0.8572, 0.9380, 0.8326, 1.1421, 1.1423, 1.1391, 0.8916,\n",
      "        0.8115, 1.1412, 1.1356, 0.8657, 0.8215, 1.1387, 0.9438, 1.1358, 1.1426,\n",
      "        0.9465, 0.9014, 1.1416, 0.8482], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 142 was 30.4%\n",
      "current params: tensor([1.2013, 0.8669, 0.8562, 0.9362, 0.8313, 1.1431, 1.1433, 1.1400, 0.8914,\n",
      "        0.8099, 1.1422, 1.1365, 0.8649, 0.8201, 1.1396, 0.9437, 1.1367, 1.1436,\n",
      "        0.9474, 0.9013, 1.1426, 0.8470], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 143 was 30.4%\n",
      "current params: tensor([1.2029, 0.8661, 0.8553, 0.9344, 0.8300, 1.1441, 1.1443, 1.1409, 0.8911,\n",
      "        0.8084, 1.1431, 1.1373, 0.8641, 0.8187, 1.1405, 0.9436, 1.1375, 1.1446,\n",
      "        0.9483, 0.9013, 1.1436, 0.8459], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 144 was 30.4%\n",
      "current params: tensor([1.2045, 0.8653, 0.8543, 0.9325, 0.8286, 1.1450, 1.1453, 1.1418, 0.8909,\n",
      "        0.8069, 1.1441, 1.1382, 0.8633, 0.8172, 1.1414, 0.9436, 1.1384, 1.1455,\n",
      "        0.9492, 0.9012, 1.1445, 0.8447], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 145 was 30.5%\n",
      "current params: tensor([1.2061, 0.8646, 0.8533, 0.9307, 0.8272, 1.1460, 1.1463, 1.1427, 0.8908,\n",
      "        0.8054, 1.1451, 1.1391, 0.8625, 0.8158, 1.1423, 0.9435, 1.1393, 1.1465,\n",
      "        0.9502, 0.9012, 1.1455, 0.8435], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 146 was 30.5%\n",
      "current params: tensor([1.2077, 0.8638, 0.8523, 0.9288, 0.8259, 1.1470, 1.1473, 1.1436, 0.8906,\n",
      "        0.8038, 1.1461, 1.1399, 0.8617, 0.8144, 1.1432, 0.9434, 1.1402, 1.1475,\n",
      "        0.9512, 0.9012, 1.1465, 0.8424], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 147 was 30.5%\n",
      "current params: tensor([1.2092, 0.8631, 0.8513, 0.9269, 0.8245, 1.1479, 1.1483, 1.1445, 0.8904,\n",
      "        0.8023, 1.1470, 1.1408, 0.8609, 0.8129, 1.1442, 0.9433, 1.1411, 1.1485,\n",
      "        0.9522, 0.9012, 1.1475, 0.8412], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 148 was 30.5%\n",
      "current params: tensor([1.2108, 0.8623, 0.8503, 0.9251, 0.8232, 1.1489, 1.1493, 1.1455, 0.8903,\n",
      "        0.8008, 1.1480, 1.1417, 0.8601, 0.8115, 1.1451, 0.9432, 1.1420, 1.1494,\n",
      "        0.9532, 0.9013, 1.1485, 0.8401], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 149 was 30.5%\n",
      "current params: tensor([1.2124, 0.8616, 0.8494, 0.9232, 0.8218, 1.1499, 1.1503, 1.1464, 0.8901,\n",
      "        0.7992, 1.1490, 1.1425, 0.8594, 0.8100, 1.1460, 0.9431, 1.1428, 1.1504,\n",
      "        0.9543, 0.9013, 1.1495, 0.8389], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 150 was 30.5%\n",
      "current params: tensor([1.2140, 0.8608, 0.8484, 0.9213, 0.8204, 1.1508, 1.1513, 1.1473, 0.8900,\n",
      "        0.7977, 1.1500, 1.1434, 0.8586, 0.8086, 1.1469, 0.9430, 1.1437, 1.1514,\n",
      "        0.9553, 0.9014, 1.1505, 0.8377], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 151 was 30.5%\n",
      "current params: tensor([1.2156, 0.8601, 0.8474, 0.9195, 0.8191, 1.1518, 1.1523, 1.1482, 0.8899,\n",
      "        0.7961, 1.1509, 1.1443, 0.8578, 0.8072, 1.1478, 0.9429, 1.1446, 1.1523,\n",
      "        0.9564, 0.9015, 1.1515, 0.8366], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 152 was 30.5%\n",
      "current params: tensor([1.2172, 0.8593, 0.8464, 0.9176, 0.8177, 1.1528, 1.1533, 1.1491, 0.8898,\n",
      "        0.7946, 1.1519, 1.1451, 0.8570, 0.8057, 1.1487, 0.9428, 1.1455, 1.1533,\n",
      "        0.9576, 0.9016, 1.1525, 0.8354], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 153 was 30.5%\n",
      "current params: tensor([1.2188, 0.8586, 0.8454, 0.9156, 0.8163, 1.1537, 1.1544, 1.1500, 0.8897,\n",
      "        0.7930, 1.1529, 1.1460, 0.8562, 0.8042, 1.1496, 0.9427, 1.1464, 1.1543,\n",
      "        0.9588, 0.9017, 1.1535, 0.8342], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 154 was 30.5%\n",
      "current params: tensor([1.2204, 0.8578, 0.8444, 0.9136, 0.8148, 1.1548, 1.1554, 1.1510, 0.8896,\n",
      "        0.7913, 1.1539, 1.1469, 0.8554, 0.8027, 1.1506, 0.9426, 1.1473, 1.1553,\n",
      "        0.9600, 0.9019, 1.1545, 0.8330], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 155 was 30.6%\n",
      "current params: tensor([1.2220, 0.8571, 0.8434, 0.9116, 0.8134, 1.1558, 1.1564, 1.1520, 0.8895,\n",
      "        0.7897, 1.1549, 1.1478, 0.8546, 0.8012, 1.1515, 0.9425, 1.1482, 1.1563,\n",
      "        0.9613, 0.9020, 1.1555, 0.8318], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 156 was 30.6%\n",
      "current params: tensor([1.2237, 0.8563, 0.8424, 0.9096, 0.8119, 1.1568, 1.1575, 1.1529, 0.8894,\n",
      "        0.7880, 1.1560, 1.1487, 0.8537, 0.7997, 1.1524, 0.9424, 1.1491, 1.1573,\n",
      "        0.9626, 0.9023, 1.1565, 0.8306], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 157 was 30.6%\n",
      "current params: tensor([1.2253, 0.8556, 0.8414, 0.9075, 0.8104, 1.1578, 1.1585, 1.1539, 0.8893,\n",
      "        0.7864, 1.1570, 1.1496, 0.8529, 0.7981, 1.1534, 0.9423, 1.1500, 1.1583,\n",
      "        0.9639, 0.9025, 1.1575, 0.8294], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 158 was 30.6%\n",
      "current params: tensor([1.2270, 0.8548, 0.8404, 0.9054, 0.8090, 1.1589, 1.1596, 1.1549, 0.8892,\n",
      "        0.7847, 1.1580, 1.1505, 0.8521, 0.7966, 1.1543, 0.9422, 1.1509, 1.1593,\n",
      "        0.9653, 0.9028, 1.1585, 0.8281], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 159 was 30.6%\n",
      "current params: tensor([1.2287, 0.8541, 0.8394, 0.9033, 0.8075, 1.1599, 1.1607, 1.1559, 0.8891,\n",
      "        0.7830, 1.1591, 1.1514, 0.8512, 0.7950, 1.1553, 0.9421, 1.1518, 1.1603,\n",
      "        0.9667, 0.9030, 1.1595, 0.8269], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 160 was 30.6%\n",
      "current params: tensor([1.2303, 0.8533, 0.8384, 0.9012, 0.8059, 1.1610, 1.1617, 1.1569, 0.8890,\n",
      "        0.7813, 1.1601, 1.1523, 0.8504, 0.7935, 1.1563, 0.9420, 1.1528, 1.1614,\n",
      "        0.9681, 0.9033, 1.1605, 0.8256], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 161 was 30.7%\n",
      "current params: tensor([1.2320, 0.8526, 0.8374, 0.8991, 0.8044, 1.1620, 1.1628, 1.1579, 0.8889,\n",
      "        0.7795, 1.1612, 1.1532, 0.8495, 0.7919, 1.1572, 0.9419, 1.1537, 1.1624,\n",
      "        0.9696, 0.9037, 1.1615, 0.8244], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 162 was 30.7%\n",
      "current params: tensor([1.2337, 0.8518, 0.8364, 0.8970, 0.8029, 1.1631, 1.1639, 1.1589, 0.8888,\n",
      "        0.7778, 1.1622, 1.1541, 0.8487, 0.7903, 1.1582, 0.9418, 1.1546, 1.1634,\n",
      "        0.9710, 0.9040, 1.1625, 0.8231], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 163 was 30.7%\n",
      "current params: tensor([1.2354, 0.8511, 0.8354, 0.8949, 0.8014, 1.1642, 1.1649, 1.1599, 0.8888,\n",
      "        0.7761, 1.1633, 1.1550, 0.8479, 0.7887, 1.1592, 0.9417, 1.1556, 1.1644,\n",
      "        0.9725, 0.9044, 1.1635, 0.8218], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 164 was 30.7%\n",
      "current params: tensor([1.2370, 0.8503, 0.8343, 0.8928, 0.7998, 1.1652, 1.1660, 1.1609, 0.8887,\n",
      "        0.7744, 1.1643, 1.1559, 0.8470, 0.7872, 1.1602, 0.9416, 1.1565, 1.1655,\n",
      "        0.9741, 0.9048, 1.1645, 0.8206], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 165 was 30.7%\n",
      "current params: tensor([1.2387, 0.8496, 0.8333, 0.8907, 0.7983, 1.1663, 1.1671, 1.1619, 0.8887,\n",
      "        0.7726, 1.1654, 1.1568, 0.8462, 0.7856, 1.1611, 0.9415, 1.1574, 1.1665,\n",
      "        0.9756, 0.9052, 1.1655, 0.8193], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 166 was 30.7%\n",
      "current params: tensor([1.2404, 0.8489, 0.8323, 0.8885, 0.7967, 1.1674, 1.1682, 1.1630, 0.8887,\n",
      "        0.7709, 1.1665, 1.1577, 0.8453, 0.7840, 1.1621, 0.9414, 1.1583, 1.1675,\n",
      "        0.9772, 0.9057, 1.1665, 0.8180], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 167 was 30.8%\n",
      "current params: tensor([1.2421, 0.8481, 0.8313, 0.8864, 0.7952, 1.1684, 1.1693, 1.1640, 0.8887,\n",
      "        0.7691, 1.1675, 1.1586, 0.8445, 0.7824, 1.1631, 0.9413, 1.1593, 1.1686,\n",
      "        0.9788, 0.9061, 1.1675, 0.8167], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 168 was 30.8%\n",
      "current params: tensor([1.2438, 0.8474, 0.8303, 0.8843, 0.7936, 1.1695, 1.1704, 1.1650, 0.8887,\n",
      "        0.7674, 1.1686, 1.1595, 0.8436, 0.7808, 1.1641, 0.9412, 1.1602, 1.1696,\n",
      "        0.9804, 0.9066, 1.1685, 0.8154], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 169 was 30.8%\n",
      "current params: tensor([1.2455, 0.8467, 0.8293, 0.8822, 0.7921, 1.1706, 1.1715, 1.1660, 0.8887,\n",
      "        0.7656, 1.1697, 1.1605, 0.8428, 0.7792, 1.1651, 0.9411, 1.1611, 1.1706,\n",
      "        0.9820, 0.9072, 1.1695, 0.8141], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 170 was 30.8%\n",
      "current params: tensor([1.2472, 0.8460, 0.8283, 0.8800, 0.7905, 1.1717, 1.1726, 1.1671, 0.8887,\n",
      "        0.7638, 1.1708, 1.1614, 0.8419, 0.7776, 1.1660, 0.9410, 1.1621, 1.1717,\n",
      "        0.9836, 0.9077, 1.1705, 0.8128], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 171 was 30.8%\n",
      "current params: tensor([1.2489, 0.8452, 0.8273, 0.8779, 0.7889, 1.1728, 1.1736, 1.1681, 0.8888,\n",
      "        0.7621, 1.1718, 1.1623, 0.8411, 0.7760, 1.1670, 0.9409, 1.1630, 1.1727,\n",
      "        0.9853, 0.9082, 1.1715, 0.8116], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 172 was 30.8%\n",
      "current params: tensor([1.2506, 0.8445, 0.8262, 0.8758, 0.7874, 1.1739, 1.1747, 1.1691, 0.8889,\n",
      "        0.7603, 1.1729, 1.1632, 0.8403, 0.7743, 1.1680, 0.9408, 1.1639, 1.1737,\n",
      "        0.9870, 0.9088, 1.1725, 0.8103], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 173 was 30.9%\n",
      "current params: tensor([1.2523, 0.8438, 0.8252, 0.8737, 0.7858, 1.1749, 1.1758, 1.1701, 0.8889,\n",
      "        0.7586, 1.1740, 1.1641, 0.8394, 0.7727, 1.1690, 0.9407, 1.1649, 1.1748,\n",
      "        0.9887, 0.9094, 1.1735, 0.8089], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 174 was 30.9%\n",
      "current params: tensor([1.2540, 0.8431, 0.8242, 0.8716, 0.7842, 1.1760, 1.1769, 1.1712, 0.8890,\n",
      "        0.7568, 1.1751, 1.1650, 0.8386, 0.7711, 1.1700, 0.9406, 1.1658, 1.1758,\n",
      "        0.9904, 0.9101, 1.1745, 0.8076], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 175 was 30.9%\n",
      "current params: tensor([1.2557, 0.8424, 0.8232, 0.8694, 0.7826, 1.1771, 1.1780, 1.1722, 0.8892,\n",
      "        0.7550, 1.1761, 1.1659, 0.8377, 0.7695, 1.1709, 0.9405, 1.1667, 1.1768,\n",
      "        0.9921, 0.9107, 1.1755, 0.8063], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 176 was 30.9%\n",
      "current params: tensor([1.2574, 0.8417, 0.8222, 0.8673, 0.7810, 1.1782, 1.1791, 1.1732, 0.8893,\n",
      "        0.7533, 1.1772, 1.1668, 0.8369, 0.7679, 1.1719, 0.9404, 1.1677, 1.1779,\n",
      "        0.9938, 0.9114, 1.1765, 0.8050], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 177 was 30.9%\n",
      "current params: tensor([1.2591, 0.8410, 0.8212, 0.8652, 0.7795, 1.1793, 1.1802, 1.1742, 0.8894,\n",
      "        0.7515, 1.1783, 1.1677, 0.8361, 0.7663, 1.1729, 0.9403, 1.1686, 1.1789,\n",
      "        0.9955, 0.9121, 1.1775, 0.8037], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 178 was 30.9%\n",
      "current params: tensor([1.2608, 0.8404, 0.8202, 0.8631, 0.7779, 1.1804, 1.1813, 1.1753, 0.8896,\n",
      "        0.7497, 1.1794, 1.1686, 0.8353, 0.7647, 1.1739, 0.9402, 1.1695, 1.1800,\n",
      "        0.9973, 0.9128, 1.1785, 0.8024], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 179 was 31.0%\n",
      "current params: tensor([1.2624, 0.8397, 0.8192, 0.8610, 0.7763, 1.1814, 1.1824, 1.1763, 0.8898,\n",
      "        0.7479, 1.1805, 1.1695, 0.8345, 0.7630, 1.1749, 0.9400, 1.1705, 1.1810,\n",
      "        0.9991, 0.9135, 1.1795, 0.8011], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 180 was 31.0%\n",
      "current params: tensor([1.2641, 0.8390, 0.8182, 0.8589, 0.7747, 1.1825, 1.1835, 1.1773, 0.8900,\n",
      "        0.7462, 1.1816, 1.1705, 0.8336, 0.7614, 1.1758, 0.9399, 1.1714, 1.1820,\n",
      "        1.0008, 0.9143, 1.1805, 0.7998], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 181 was 31.0%\n",
      "current params: tensor([1.2658, 0.8383, 0.8171, 0.8568, 0.7731, 1.1836, 1.1846, 1.1783, 0.8902,\n",
      "        0.7444, 1.1826, 1.1714, 0.8328, 0.7598, 1.1768, 0.9398, 1.1723, 1.1831,\n",
      "        1.0026, 0.9151, 1.1815, 0.7984], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 182 was 31.0%\n",
      "current params: tensor([1.2675, 0.8377, 0.8161, 0.8547, 0.7715, 1.1847, 1.1857, 1.1794, 0.8905,\n",
      "        0.7426, 1.1837, 1.1723, 0.8320, 0.7582, 1.1778, 0.9397, 1.1733, 1.1841,\n",
      "        1.0044, 0.9159, 1.1825, 0.7971], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 183 was 31.0%\n",
      "current params: tensor([1.2692, 0.8370, 0.8151, 0.8526, 0.7699, 1.1858, 1.1868, 1.1804, 0.8907,\n",
      "        0.7409, 1.1848, 1.1732, 0.8312, 0.7565, 1.1788, 0.9396, 1.1742, 1.1851,\n",
      "        1.0062, 0.9167, 1.1835, 0.7958], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 184 was 31.1%\n",
      "current params: tensor([1.2709, 0.8364, 0.8141, 0.8505, 0.7683, 1.1869, 1.1879, 1.1814, 0.8910,\n",
      "        0.7391, 1.1859, 1.1741, 0.8304, 0.7549, 1.1798, 0.9395, 1.1751, 1.1862,\n",
      "        1.0080, 0.9175, 1.1845, 0.7945], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 185 was 31.1%\n",
      "current params: tensor([1.2726, 0.8357, 0.8131, 0.8484, 0.7667, 1.1880, 1.1890, 1.1824, 0.8913,\n",
      "        0.7373, 1.1870, 1.1750, 0.8296, 0.7533, 1.1807, 0.9394, 1.1760, 1.1872,\n",
      "        1.0099, 0.9184, 1.1855, 0.7931], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 186 was 31.1%\n",
      "current params: tensor([1.2743, 0.8351, 0.8121, 0.8463, 0.7651, 1.1890, 1.1901, 1.1835, 0.8916,\n",
      "        0.7355, 1.1881, 1.1759, 0.8288, 0.7517, 1.1817, 0.9393, 1.1770, 1.1882,\n",
      "        1.0117, 0.9193, 1.1865, 0.7918], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 187 was 31.1%\n",
      "current params: tensor([1.2760, 0.8344, 0.8111, 0.8443, 0.7635, 1.1901, 1.1912, 1.1845, 0.8920,\n",
      "        0.7338, 1.1891, 1.1768, 0.8280, 0.7500, 1.1827, 0.9392, 1.1779, 1.1893,\n",
      "        1.0135, 0.9202, 1.1875, 0.7905], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 188 was 31.1%\n",
      "current params: tensor([1.2777, 0.8338, 0.8101, 0.8422, 0.7619, 1.1912, 1.1923, 1.1855, 0.8923,\n",
      "        0.7320, 1.1902, 1.1777, 0.8272, 0.7484, 1.1837, 0.9391, 1.1788, 1.1903,\n",
      "        1.0154, 0.9211, 1.1885, 0.7891], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 189 was 31.1%\n",
      "current params: tensor([1.2793, 0.8332, 0.8091, 0.8401, 0.7603, 1.1923, 1.1935, 1.1865, 0.8927,\n",
      "        0.7302, 1.1913, 1.1786, 0.8265, 0.7468, 1.1846, 0.9390, 1.1797, 1.1913,\n",
      "        1.0173, 0.9221, 1.1895, 0.7878], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 190 was 31.2%\n",
      "current params: tensor([1.2810, 0.8326, 0.8081, 0.8380, 0.7587, 1.1934, 1.1946, 1.1875, 0.8931,\n",
      "        0.7284, 1.1924, 1.1794, 0.8257, 0.7451, 1.1856, 0.9389, 1.1807, 1.1924,\n",
      "        1.0191, 0.9231, 1.1905, 0.7864], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 191 was 31.2%\n",
      "current params: tensor([1.2827, 0.8320, 0.8071, 0.8359, 0.7571, 1.1944, 1.1957, 1.1885, 0.8935,\n",
      "        0.7267, 1.1935, 1.1803, 0.8249, 0.7435, 1.1866, 0.9387, 1.1816, 1.1934,\n",
      "        1.0210, 0.9240, 1.1915, 0.7851], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 192 was 31.2%\n",
      "current params: tensor([1.2844, 0.8314, 0.8061, 0.8339, 0.7555, 1.1955, 1.1968, 1.1896, 0.8940,\n",
      "        0.7249, 1.1946, 1.1812, 0.8241, 0.7419, 1.1875, 0.9386, 1.1825, 1.1944,\n",
      "        1.0229, 0.9251, 1.1925, 0.7837], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 193 was 31.2%\n",
      "current params: tensor([1.2861, 0.8308, 0.8051, 0.8318, 0.7538, 1.1966, 1.1979, 1.1906, 0.8944,\n",
      "        0.7231, 1.1956, 1.1821, 0.8234, 0.7402, 1.1885, 0.9385, 1.1834, 1.1954,\n",
      "        1.0248, 0.9261, 1.1935, 0.7824], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 194 was 31.2%\n",
      "current params: tensor([1.2877, 0.8302, 0.8041, 0.8297, 0.7522, 1.1977, 1.1990, 1.1916, 0.8949,\n",
      "        0.7213, 1.1967, 1.1830, 0.8226, 0.7386, 1.1895, 0.9384, 1.1843, 1.1965,\n",
      "        1.0267, 0.9272, 1.1945, 0.7810], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 195 was 31.3%\n",
      "current params: tensor([1.2894, 0.8296, 0.8031, 0.8277, 0.7506, 1.1988, 1.2001, 1.1926, 0.8954,\n",
      "        0.7195, 1.1978, 1.1839, 0.8218, 0.7370, 1.1905, 0.9391, 1.1852, 1.1975,\n",
      "        1.0286, 0.9282, 1.1955, 0.7797], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 196 was 31.3%\n",
      "current params: tensor([1.2911, 0.8290, 0.8022, 0.8256, 0.7490, 1.1998, 1.2012, 1.1936, 0.8959,\n",
      "        0.7178, 1.1989, 1.1848, 0.8211, 0.7353, 1.1914, 0.9398, 1.1862, 1.1985,\n",
      "        1.0305, 0.9293, 1.1965, 0.7783], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 197 was 31.3%\n",
      "current params: tensor([1.2928, 0.8284, 0.8012, 0.8235, 0.7474, 1.2009, 1.2023, 1.1946, 0.8965,\n",
      "        0.7160, 1.2000, 1.1857, 0.8203, 0.7337, 1.1924, 0.9403, 1.1871, 1.1996,\n",
      "        1.0324, 0.9305, 1.1975, 0.7770], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 198 was 31.3%\n",
      "current params: tensor([1.2945, 0.8279, 0.8002, 0.8215, 0.7458, 1.2020, 1.2034, 1.1956, 0.8970,\n",
      "        0.7142, 1.2011, 1.1866, 0.8196, 0.7320, 1.1934, 0.9409, 1.1880, 1.2006,\n",
      "        1.0343, 0.9316, 1.1985, 0.7756], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 199 was 31.3%\n",
      "current params: tensor([1.2961, 0.8273, 0.7992, 0.8194, 0.7441, 1.2031, 1.2045, 1.1966, 0.8976,\n",
      "        0.7124, 1.2022, 1.1874, 0.8188, 0.7304, 1.1943, 0.9413, 1.1889, 1.2016,\n",
      "        1.0363, 0.9327, 1.1995, 0.7743], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 200 was 31.4%\n",
      "current params: tensor([1.2978, 0.8268, 0.7982, 0.8173, 0.7425, 1.2041, 1.2056, 1.1977, 0.8982,\n",
      "        0.7106, 1.2032, 1.1883, 0.8181, 0.7287, 1.1953, 0.9417, 1.1898, 1.2026,\n",
      "        1.0382, 0.9339, 1.2005, 0.7729], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 201 was 31.4%\n",
      "current params: tensor([1.2995, 0.8262, 0.7972, 0.8153, 0.7409, 1.2052, 1.2067, 1.1987, 0.8989,\n",
      "        0.7089, 1.2043, 1.1892, 0.8174, 0.7271, 1.1962, 0.9420, 1.1907, 1.2037,\n",
      "        1.0401, 0.9351, 1.2015, 0.7715], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 202 was 31.4%\n",
      "current params: tensor([1.3012, 0.8257, 0.7962, 0.8132, 0.7393, 1.2063, 1.2078, 1.1997, 0.8995,\n",
      "        0.7071, 1.2054, 1.1901, 0.8166, 0.7254, 1.1972, 0.9423, 1.1916, 1.2047,\n",
      "        1.0421, 0.9363, 1.2025, 0.7702], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 203 was 31.4%\n",
      "current params: tensor([1.3028, 0.8251, 0.7952, 0.8111, 0.7376, 1.2073, 1.2089, 1.2007, 0.9002,\n",
      "        0.7053, 1.2065, 1.1910, 0.8159, 0.7238, 1.1982, 0.9426, 1.1926, 1.2057,\n",
      "        1.0440, 0.9376, 1.2035, 0.7688], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 204 was 31.4%\n",
      "current params: tensor([1.3045, 0.8246, 0.7943, 0.8091, 0.7360, 1.2084, 1.2100, 1.2017, 0.9009,\n",
      "        0.7035, 1.2076, 1.1918, 0.8152, 0.7221, 1.1991, 0.9428, 1.1935, 1.2067,\n",
      "        1.0460, 0.9388, 1.2045, 0.7674], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 205 was 31.5%\n",
      "current params: tensor([1.3062, 0.8241, 0.7933, 0.8070, 0.7344, 1.2095, 1.2111, 1.2027, 0.9016,\n",
      "        0.7017, 1.2087, 1.1927, 0.8145, 0.7205, 1.2001, 0.9430, 1.1944, 1.2078,\n",
      "        1.0480, 0.9401, 1.2055, 0.7660], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 206 was 31.5%\n",
      "current params: tensor([1.3078, 0.8236, 0.7923, 0.8050, 0.7327, 1.2106, 1.2122, 1.2037, 0.9023,\n",
      "        0.6999, 1.2098, 1.1936, 0.8138, 0.7188, 1.2011, 0.9432, 1.1953, 1.2088,\n",
      "        1.0499, 0.9414, 1.2065, 0.7646], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 207 was 31.5%\n",
      "current params: tensor([1.3095, 0.8231, 0.7913, 0.8029, 0.7311, 1.2116, 1.2133, 1.2047, 0.9031,\n",
      "        0.6981, 1.2109, 1.1945, 0.8131, 0.7172, 1.2020, 0.9433, 1.1962, 1.2098,\n",
      "        1.0519, 0.9427, 1.2075, 0.7633], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 208 was 31.5%\n",
      "current params: tensor([1.3112, 0.8226, 0.7903, 0.8009, 0.7295, 1.2127, 1.2144, 1.2057, 0.9039,\n",
      "        0.6963, 1.2119, 1.1953, 0.8124, 0.7155, 1.2030, 0.9435, 1.1971, 1.2108,\n",
      "        1.0539, 0.9440, 1.2085, 0.7619], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 209 was 31.5%\n",
      "current params: tensor([1.3128, 0.8221, 0.7894, 0.7988, 0.7278, 1.2138, 1.2156, 1.2067, 0.9047,\n",
      "        0.6945, 1.2130, 1.1962, 0.8117, 0.7139, 1.2039, 0.9436, 1.1980, 1.2119,\n",
      "        1.0559, 0.9454, 1.2095, 0.7605], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 210 was 31.6%\n",
      "current params: tensor([1.3145, 0.8216, 0.7884, 0.7968, 0.7262, 1.2148, 1.2167, 1.2077, 0.9055,\n",
      "        0.6928, 1.2141, 1.1971, 0.8110, 0.7122, 1.2049, 0.9436, 1.1989, 1.2129,\n",
      "        1.0579, 0.9467, 1.2105, 0.7591], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 211 was 31.6%\n",
      "current params: tensor([1.3162, 0.8212, 0.7874, 0.7947, 0.7246, 1.2159, 1.2178, 1.2087, 0.9063,\n",
      "        0.6910, 1.2152, 1.1979, 0.8103, 0.7106, 1.2058, 0.9437, 1.1998, 1.2139,\n",
      "        1.0598, 0.9481, 1.2115, 0.7577], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 212 was 31.6%\n",
      "current params: tensor([1.3178, 0.8207, 0.7864, 0.7926, 0.7229, 1.2170, 1.2189, 1.2097, 0.9072,\n",
      "        0.6892, 1.2163, 1.1988, 0.8096, 0.7089, 1.2068, 0.9437, 1.2007, 1.2149,\n",
      "        1.0618, 0.9495, 1.2125, 0.7563], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 213 was 31.6%\n",
      "current params: tensor([1.3195, 0.8202, 0.7855, 0.7906, 0.7213, 1.2180, 1.2200, 1.2107, 0.9081,\n",
      "        0.6874, 1.2174, 1.1997, 0.8089, 0.7072, 1.2078, 0.9438, 1.2016, 1.2159,\n",
      "        1.0638, 0.9509, 1.2135, 0.7549], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 214 was 31.6%\n",
      "current params: tensor([1.3212, 0.8198, 0.7845, 0.7885, 0.7196, 1.2191, 1.2211, 1.2117, 0.9090,\n",
      "        0.6856, 1.2185, 1.2005, 0.8083, 0.7056, 1.2087, 0.9438, 1.2025, 1.2170,\n",
      "        1.0658, 0.9523, 1.2145, 0.7535], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 215 was 31.7%\n",
      "current params: tensor([1.3228, 0.8194, 0.7835, 0.7865, 0.7180, 1.2202, 1.2222, 1.2127, 0.9099,\n",
      "        0.6838, 1.2196, 1.2014, 0.8076, 0.7039, 1.2097, 0.9438, 1.2034, 1.2180,\n",
      "        1.0679, 0.9538, 1.2156, 0.7521], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 216 was 31.7%\n",
      "current params: tensor([1.3245, 0.8189, 0.7826, 0.7844, 0.7163, 1.2212, 1.2233, 1.2137, 0.9109,\n",
      "        0.6820, 1.2207, 1.2023, 0.8069, 0.7022, 1.2106, 0.9438, 1.2043, 1.2190,\n",
      "        1.0699, 0.9552, 1.2166, 0.7507], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 217 was 31.7%\n",
      "current params: tensor([1.3262, 0.8185, 0.7816, 0.7824, 0.7147, 1.2223, 1.2244, 1.2147, 0.9118,\n",
      "        0.6802, 1.2218, 1.2031, 0.8063, 0.7005, 1.2116, 0.9438, 1.2052, 1.2200,\n",
      "        1.0719, 0.9567, 1.2176, 0.7493], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 218 was 31.7%\n",
      "current params: tensor([1.3278, 0.8181, 0.7806, 0.7803, 0.7130, 1.2234, 1.2255, 1.2157, 0.9128,\n",
      "        0.6783, 1.2229, 1.2040, 0.8056, 0.6989, 1.2125, 0.9438, 1.2061, 1.2210,\n",
      "        1.0739, 0.9582, 1.2186, 0.7479], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 219 was 31.7%\n",
      "current params: tensor([1.3295, 0.8177, 0.7797, 0.7783, 0.7114, 1.2244, 1.2266, 1.2167, 0.9138,\n",
      "        0.6765, 1.2239, 1.2048, 0.8050, 0.6972, 1.2135, 0.9437, 1.2070, 1.2221,\n",
      "        1.0759, 0.9597, 1.2196, 0.7465], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 220 was 31.8%\n",
      "current params: tensor([1.3311, 0.8173, 0.7787, 0.7762, 0.7097, 1.2255, 1.2277, 1.2177, 0.9148,\n",
      "        0.6747, 1.2250, 1.2057, 0.8043, 0.6955, 1.2144, 0.9437, 1.2079, 1.2231,\n",
      "        1.0779, 0.9612, 1.2206, 0.7451], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 221 was 31.8%\n",
      "current params: tensor([1.3328, 0.8169, 0.7778, 0.7742, 0.7081, 1.2266, 1.2288, 1.2187, 0.9159,\n",
      "        0.6729, 1.2261, 1.2066, 0.8037, 0.6938, 1.2154, 0.9437, 1.2088, 1.2241,\n",
      "        1.0800, 0.9628, 1.2216, 0.7436], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 222 was 31.8%\n",
      "current params: tensor([1.3344, 0.8165, 0.7768, 0.7721, 0.7064, 1.2276, 1.2299, 1.2197, 0.9170,\n",
      "        0.6711, 1.2272, 1.2074, 0.8030, 0.6922, 1.2163, 0.9436, 1.2097, 1.2251,\n",
      "        1.0820, 0.9643, 1.2226, 0.7422], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 223 was 31.8%\n",
      "current params: tensor([1.3361, 0.8161, 0.7758, 0.7700, 0.7047, 1.2287, 1.2311, 1.2207, 0.9181,\n",
      "        0.6693, 1.2283, 1.2083, 0.8024, 0.6905, 1.2173, 0.9436, 1.2106, 1.2261,\n",
      "        1.0840, 0.9659, 1.2236, 0.7408], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 224 was 31.8%\n",
      "current params: tensor([1.3378, 0.8158, 0.7749, 0.7680, 0.7031, 1.2298, 1.2322, 1.2217, 0.9192,\n",
      "        0.6675, 1.2294, 1.2091, 0.8018, 0.6888, 1.2182, 0.9435, 1.2115, 1.2272,\n",
      "        1.0861, 0.9674, 1.2246, 0.7394], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 225 was 31.9%\n",
      "current params: tensor([1.3394, 0.8154, 0.7739, 0.7659, 0.7014, 1.2308, 1.2333, 1.2227, 0.9203,\n",
      "        0.6657, 1.2305, 1.2100, 0.8012, 0.6871, 1.2192, 0.9434, 1.2124, 1.2282,\n",
      "        1.0881, 0.9690, 1.2256, 0.7379], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 226 was 31.9%\n",
      "current params: tensor([1.3411, 0.8151, 0.7730, 0.7639, 0.6997, 1.2319, 1.2344, 1.2236, 0.9214,\n",
      "        0.6638, 1.2316, 1.2108, 0.8006, 0.6854, 1.2201, 0.9434, 1.2133, 1.2292,\n",
      "        1.0901, 0.9706, 1.2266, 0.7365], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 227 was 31.9%\n",
      "current params: tensor([1.3427, 0.8147, 0.7720, 0.7618, 0.6981, 1.2329, 1.2355, 1.2246, 0.9226,\n",
      "        0.6620, 1.2327, 1.2117, 0.7999, 0.6837, 1.2211, 0.9433, 1.2142, 1.2302,\n",
      "        1.0922, 0.9722, 1.2276, 0.7351], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 228 was 31.9%\n",
      "current params: tensor([1.3444, 0.8144, 0.7711, 0.7598, 0.6964, 1.2340, 1.2366, 1.2256, 0.9238,\n",
      "        0.6602, 1.2338, 1.2125, 0.7993, 0.6820, 1.2220, 0.9432, 1.2151, 1.2312,\n",
      "        1.0942, 0.9739, 1.2286, 0.7336], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 229 was 32.0%\n",
      "current params: tensor([1.3460, 0.8141, 0.7701, 0.7577, 0.6947, 1.2351, 1.2377, 1.2266, 0.9250,\n",
      "        0.6584, 1.2349, 1.2134, 0.7987, 0.6803, 1.2230, 0.9432, 1.2160, 1.2322,\n",
      "        1.0963, 0.9755, 1.2296, 0.7322], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 230 was 32.0%\n",
      "current params: tensor([1.3477, 0.8138, 0.7692, 0.7556, 0.6930, 1.2361, 1.2388, 1.2276, 0.9262,\n",
      "        0.6565, 1.2360, 1.2142, 0.7981, 0.6786, 1.2239, 0.9431, 1.2169, 1.2333,\n",
      "        1.0983, 0.9771, 1.2306, 0.7307], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 231 was 32.0%\n",
      "current params: tensor([1.3493, 0.8135, 0.7682, 0.7536, 0.6914, 1.2372, 1.2399, 1.2286, 0.9275,\n",
      "        0.6547, 1.2371, 1.2151, 0.7976, 0.6769, 1.2249, 0.9430, 1.2177, 1.2343,\n",
      "        1.1004, 0.9788, 1.2316, 0.7293], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 232 was 32.0%\n",
      "current params: tensor([1.3510, 0.8132, 0.7673, 0.7515, 0.6897, 1.2383, 1.2410, 1.2296, 0.9287,\n",
      "        0.6529, 1.2382, 1.2159, 0.7970, 0.6752, 1.2258, 0.9429, 1.2186, 1.2353,\n",
      "        1.1024, 0.9805, 1.2326, 0.7278], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 233 was 32.0%\n",
      "current params: tensor([1.3526, 0.8129, 0.7663, 0.7495, 0.6880, 1.2393, 1.2421, 1.2306, 0.9300,\n",
      "        0.6511, 1.2393, 1.2168, 0.7964, 0.6735, 1.2268, 0.9428, 1.2195, 1.2363,\n",
      "        1.1045, 0.9822, 1.2336, 0.7264], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 234 was 32.1%\n",
      "current params: tensor([1.3543, 0.8126, 0.7654, 0.7474, 0.6863, 1.2404, 1.2432, 1.2316, 0.9313,\n",
      "        0.6492, 1.2404, 1.2176, 0.7958, 0.6718, 1.2277, 0.9427, 1.2204, 1.2373,\n",
      "        1.1065, 0.9839, 1.2346, 0.7249], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 235 was 32.1%\n",
      "current params: tensor([1.3559, 0.8124, 0.7645, 0.7453, 0.6846, 1.2414, 1.2444, 1.2326, 0.9326,\n",
      "        0.6474, 1.2415, 1.2185, 0.7953, 0.6701, 1.2287, 0.9427, 1.2213, 1.2383,\n",
      "        1.1086, 0.9856, 1.2356, 0.7235], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 236 was 32.1%\n",
      "current params: tensor([1.3576, 0.8121, 0.7635, 0.7433, 0.6830, 1.2425, 1.2455, 1.2336, 0.9339,\n",
      "        0.6455, 1.2426, 1.2193, 0.7947, 0.6684, 1.2296, 0.9426, 1.2222, 1.2394,\n",
      "        1.1107, 0.9873, 1.2366, 0.7220], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 237 was 32.1%\n",
      "current params: tensor([1.3592, 0.8119, 0.7626, 0.7412, 0.6813, 1.2436, 1.2466, 1.2346, 0.9353,\n",
      "        0.6437, 1.2437, 1.2202, 0.7941, 0.6667, 1.2306, 0.9425, 1.2231, 1.2404,\n",
      "        1.1127, 0.9890, 1.2376, 0.7205], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 238 was 32.2%\n",
      "current params: tensor([1.3609, 0.8116, 0.7616, 0.7391, 0.6796, 1.2446, 1.2477, 1.2356, 0.9366,\n",
      "        0.6419, 1.2448, 1.2210, 0.7936, 0.6650, 1.2315, 0.9424, 1.2240, 1.2414,\n",
      "        1.1148, 0.9907, 1.2386, 0.7191], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 239 was 32.2%\n",
      "current params: tensor([1.3625, 0.8114, 0.7607, 0.7371, 0.6779, 1.2457, 1.2488, 1.2366, 0.9380,\n",
      "        0.6400, 1.2459, 1.2219, 0.7930, 0.6632, 1.2325, 0.9423, 1.2248, 1.2424,\n",
      "        1.1169, 0.9925, 1.2396, 0.7176], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 240 was 32.2%\n",
      "current params: tensor([1.3641, 0.8112, 0.7598, 0.7350, 0.6762, 1.2467, 1.2499, 1.2375, 0.9394,\n",
      "        0.6382, 1.2470, 1.2227, 0.7925, 0.6615, 1.2334, 0.9422, 1.2257, 1.2434,\n",
      "        1.1189, 0.9942, 1.2406, 0.7161], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 241 was 32.2%\n",
      "current params: tensor([1.3658, 0.8110, 0.7589, 0.7329, 0.6745, 1.2478, 1.2510, 1.2385, 0.9408,\n",
      "        0.6363, 1.2481, 1.2235, 0.7920, 0.6598, 1.2343, 0.9421, 1.2266, 1.2444,\n",
      "        1.1210, 0.9960, 1.2416, 0.7146], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 242 was 32.3%\n",
      "current params: tensor([1.3674, 0.8108, 0.7579, 0.7309, 0.6728, 1.2488, 1.2521, 1.2395, 0.9423,\n",
      "        0.6345, 1.2493, 1.2244, 0.7914, 0.6581, 1.2353, 0.9420, 1.2275, 1.2455,\n",
      "        1.1231, 0.9978, 1.2426, 0.7131], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 243 was 32.3%\n",
      "current params: tensor([1.3691, 0.8106, 0.7570, 0.7288, 0.6711, 1.2499, 1.2532, 1.2405, 0.9437,\n",
      "        0.6326, 1.2504, 1.2252, 0.7909, 0.6563, 1.2362, 0.9419, 1.2284, 1.2465,\n",
      "        1.1252, 0.9995, 1.2436, 0.7117], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 244 was 32.3%\n",
      "current params: tensor([1.3707, 0.8105, 0.7561, 0.7267, 0.6694, 1.2510, 1.2544, 1.2415, 0.9452,\n",
      "        0.6307, 1.2515, 1.2260, 0.7904, 0.6546, 1.2372, 0.9418, 1.2293, 1.2475,\n",
      "        1.1272, 1.0013, 1.2446, 0.7102], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 245 was 32.3%\n",
      "current params: tensor([1.3724, 0.8103, 0.7552, 0.7246, 0.6677, 1.2520, 1.2555, 1.2425, 0.9466,\n",
      "        0.6289, 1.2526, 1.2269, 0.7899, 0.6529, 1.2381, 0.9417, 1.2301, 1.2485,\n",
      "        1.1293, 1.0031, 1.2456, 0.7087], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 246 was 32.4%\n",
      "current params: tensor([1.3740, 0.8102, 0.7542, 0.7226, 0.6660, 1.2531, 1.2566, 1.2435, 0.9481,\n",
      "        0.6270, 1.2537, 1.2277, 0.7894, 0.6512, 1.2391, 0.9416, 1.2310, 1.2495,\n",
      "        1.1314, 1.0049, 1.2466, 0.7072], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 247 was 32.4%\n",
      "current params: tensor([1.3756, 0.8100, 0.7533, 0.7205, 0.6643, 1.2541, 1.2577, 1.2445, 0.9496,\n",
      "        0.6252, 1.2548, 1.2286, 0.7889, 0.6494, 1.2400, 0.9415, 1.2319, 1.2505,\n",
      "        1.1335, 1.0067, 1.2476, 0.7057], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 248 was 32.4%\n",
      "current params: tensor([1.3773, 0.8099, 0.7524, 0.7184, 0.6626, 1.2552, 1.2588, 1.2455, 0.9512,\n",
      "        0.6233, 1.2559, 1.2294, 0.7884, 0.6477, 1.2410, 0.9414, 1.2328, 1.2515,\n",
      "        1.1356, 1.0086, 1.2486, 0.7042], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 249 was 32.4%\n",
      "current params: tensor([1.3789, 0.8098, 0.7515, 0.7163, 0.6609, 1.2563, 1.2599, 1.2465, 0.9527,\n",
      "        0.6214, 1.2570, 1.2302, 0.7879, 0.6459, 1.2419, 0.9413, 1.2337, 1.2526,\n",
      "        1.1376, 1.0104, 1.2496, 0.7027], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 250 was 32.5%\n",
      "current params: tensor([1.3806, 0.8097, 0.7506, 0.7142, 0.6591, 1.2573, 1.2610, 1.2475, 0.9542,\n",
      "        0.6195, 1.2582, 1.2311, 0.7874, 0.6442, 1.2429, 0.9412, 1.2345, 1.2536,\n",
      "        1.1397, 1.0122, 1.2506, 0.7011], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 251 was 32.5%\n",
      "current params: tensor([1.3822, 0.8096, 0.7497, 0.7121, 0.6574, 1.2584, 1.2621, 1.2485, 0.9558,\n",
      "        0.6177, 1.2593, 1.2319, 0.7870, 0.6424, 1.2438, 0.9411, 1.2354, 1.2546,\n",
      "        1.1418, 1.0141, 1.2516, 0.6996], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 252 was 32.5%\n",
      "current params: tensor([1.3838, 0.8095, 0.7488, 0.7101, 0.6557, 1.2594, 1.2632, 1.2495, 0.9574,\n",
      "        0.6158, 1.2604, 1.2327, 0.7865, 0.6407, 1.2447, 0.9410, 1.2363, 1.2556,\n",
      "        1.1439, 1.0159, 1.2526, 0.6981], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 253 was 32.5%\n",
      "current params: tensor([1.3855, 0.8094, 0.7479, 0.7080, 0.6540, 1.2605, 1.2644, 1.2504, 0.9590,\n",
      "        0.6139, 1.2615, 1.2335, 0.7860, 0.6389, 1.2457, 0.9409, 1.2372, 1.2566,\n",
      "        1.1460, 1.0178, 1.2536, 0.6966], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 254 was 32.6%\n",
      "current params: tensor([1.3871, 0.8094, 0.7469, 0.7059, 0.6523, 1.2615, 1.2655, 1.2514, 0.9606,\n",
      "        0.6120, 1.2626, 1.2344, 0.7856, 0.6372, 1.2466, 0.9408, 1.2381, 1.2576,\n",
      "        1.1481, 1.0196, 1.2546, 0.6951], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 255 was 32.6%\n",
      "current params: tensor([1.3888, 0.8093, 0.7460, 0.7038, 0.6505, 1.2626, 1.2666, 1.2524, 0.9622,\n",
      "        0.6101, 1.2637, 1.2352, 0.7851, 0.6354, 1.2476, 0.9407, 1.2389, 1.2586,\n",
      "        1.1502, 1.0215, 1.2556, 0.6935], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 256 was 32.6%\n",
      "current params: tensor([1.3904, 0.8093, 0.7451, 0.7017, 0.6488, 1.2637, 1.2677, 1.2534, 0.9638,\n",
      "        0.6083, 1.2649, 1.2360, 0.7847, 0.6337, 1.2485, 0.9405, 1.2398, 1.2597,\n",
      "        1.1523, 1.0234, 1.2566, 0.6920], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 257 was 32.6%\n",
      "current params: tensor([1.3920, 0.8093, 0.7443, 0.6996, 0.6471, 1.2647, 1.2688, 1.2544, 0.9654,\n",
      "        0.6064, 1.2660, 1.2369, 0.7842, 0.6319, 1.2495, 0.9404, 1.2407, 1.2607,\n",
      "        1.1543, 1.0252, 1.2576, 0.6905], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 258 was 32.7%\n",
      "current params: tensor([1.3937, 0.8093, 0.7434, 0.6975, 0.6454, 1.2658, 1.2699, 1.2554, 0.9671,\n",
      "        0.6045, 1.2671, 1.2377, 0.7838, 0.6301, 1.2504, 0.9403, 1.2416, 1.2617,\n",
      "        1.1564, 1.0271, 1.2586, 0.6889], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 259 was 32.7%\n",
      "current params: tensor([1.3953, 0.8093, 0.7425, 0.6954, 0.6436, 1.2668, 1.2710, 1.2564, 0.9687,\n",
      "        0.6026, 1.2682, 1.2385, 0.7834, 0.6284, 1.2514, 0.9402, 1.2424, 1.2627,\n",
      "        1.1585, 1.0290, 1.2596, 0.6874], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 260 was 32.7%\n",
      "current params: tensor([1.3969, 0.8093, 0.7416, 0.6933, 0.6419, 1.2679, 1.2721, 1.2574, 0.9704,\n",
      "        0.6007, 1.2694, 1.2393, 0.7830, 0.6266, 1.2523, 0.9401, 1.2433, 1.2637,\n",
      "        1.1606, 1.0309, 1.2606, 0.6858], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 261 was 32.8%\n",
      "current params: tensor([1.3986, 0.8094, 0.7407, 0.6912, 0.6402, 1.2689, 1.2732, 1.2584, 0.9721,\n",
      "        0.5988, 1.2705, 1.2402, 0.7826, 0.6248, 1.2533, 0.9400, 1.2442, 1.2647,\n",
      "        1.1627, 1.0328, 1.2616, 0.6843], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 262 was 32.8%\n",
      "current params: tensor([1.4002, 0.8094, 0.7398, 0.6891, 0.6384, 1.2700, 1.2744, 1.2594, 0.9738,\n",
      "        0.5969, 1.2716, 1.2410, 0.7822, 0.6231, 1.2542, 0.9399, 1.2451, 1.2657,\n",
      "        1.1648, 1.0347, 1.2626, 0.6827], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 263 was 32.8%\n",
      "current params: tensor([1.4018, 0.8095, 0.7389, 0.6870, 0.6367, 1.2711, 1.2755, 1.2604, 0.9755,\n",
      "        0.5950, 1.2727, 1.2418, 0.7818, 0.6213, 1.2552, 0.9398, 1.2459, 1.2668,\n",
      "        1.1669, 1.0366, 1.2636, 0.6812], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 264 was 32.8%\n",
      "current params: tensor([1.4035, 0.8095, 0.7380, 0.6849, 0.6349, 1.2721, 1.2766, 1.2614, 0.9772,\n",
      "        0.5931, 1.2739, 1.2426, 0.7814, 0.6195, 1.2561, 0.9397, 1.2468, 1.2678,\n",
      "        1.1690, 1.0385, 1.2646, 0.6796], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 265 was 32.9%\n",
      "current params: tensor([1.4051, 0.8096, 0.7372, 0.6828, 0.6332, 1.2732, 1.2777, 1.2624, 0.9789,\n",
      "        0.5911, 1.2750, 1.2435, 0.7810, 0.6177, 1.2570, 0.9396, 1.2477, 1.2688,\n",
      "        1.1711, 1.0404, 1.2656, 0.6780], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 266 was 32.9%\n",
      "current params: tensor([1.4067, 0.8097, 0.7363, 0.6807, 0.6314, 1.2742, 1.2788, 1.2634, 0.9806,\n",
      "        0.5892, 1.2761, 1.2443, 0.7806, 0.6159, 1.2580, 0.9394, 1.2486, 1.2698,\n",
      "        1.1732, 1.0424, 1.2666, 0.6765], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 267 was 32.9%\n",
      "current params: tensor([1.4084, 0.8098, 0.7354, 0.6786, 0.6297, 1.2753, 1.2799, 1.2644, 0.9824,\n",
      "        0.5873, 1.2773, 1.2451, 0.7802, 0.6142, 1.2589, 0.9393, 1.2494, 1.2708,\n",
      "        1.1753, 1.0443, 1.2676, 0.6749], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 268 was 33.0%\n",
      "current params: tensor([1.4100, 0.8099, 0.7345, 0.6764, 0.6279, 1.2763, 1.2810, 1.2654, 0.9841,\n",
      "        0.5854, 1.2784, 1.2459, 0.7799, 0.6124, 1.2599, 0.9392, 1.2503, 1.2718,\n",
      "        1.1774, 1.0462, 1.2686, 0.6733], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 269 was 33.0%\n",
      "current params: tensor([1.4116, 0.8101, 0.7337, 0.6743, 0.6262, 1.2774, 1.2821, 1.2664, 0.9859,\n",
      "        0.5835, 1.2795, 1.2467, 0.7795, 0.6106, 1.2608, 0.9391, 1.2512, 1.2729,\n",
      "        1.1795, 1.0482, 1.2697, 0.6717], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 270 was 33.0%\n",
      "current params: tensor([1.4133, 0.8102, 0.7328, 0.6722, 0.6244, 1.2784, 1.2833, 1.2674, 0.9877,\n",
      "        0.5815, 1.2807, 1.2476, 0.7792, 0.6088, 1.2618, 0.9390, 1.2520, 1.2739,\n",
      "        1.1816, 1.0501, 1.2707, 0.6701], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 271 was 33.0%\n",
      "current params: tensor([1.4149, 0.8104, 0.7319, 0.6701, 0.6227, 1.2795, 1.2844, 1.2684, 0.9894,\n",
      "        0.5796, 1.2818, 1.2484, 0.7788, 0.6070, 1.2627, 0.9389, 1.2529, 1.2749,\n",
      "        1.1837, 1.0520, 1.2717, 0.6685], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 272 was 33.1%\n",
      "current params: tensor([1.4165, 0.8106, 0.7311, 0.6680, 0.6209, 1.2806, 1.2855, 1.2694, 0.9912,\n",
      "        0.5777, 1.2829, 1.2492, 0.7785, 0.6052, 1.2637, 0.9388, 1.2538, 1.2759,\n",
      "        1.1858, 1.0540, 1.2727, 0.6670], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 273 was 33.1%\n",
      "current params: tensor([1.4182, 0.8108, 0.7302, 0.6658, 0.6192, 1.2816, 1.2866, 1.2704, 0.9930,\n",
      "        0.5757, 1.2841, 1.2500, 0.7782, 0.6034, 1.2646, 0.9387, 1.2546, 1.2769,\n",
      "        1.1879, 1.0559, 1.2737, 0.6654], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 274 was 33.1%\n",
      "current params: tensor([1.4198, 0.8110, 0.7294, 0.6637, 0.6174, 1.2827, 1.2877, 1.2714, 0.9948,\n",
      "        0.5738, 1.2852, 1.2508, 0.7779, 0.6016, 1.2656, 0.9385, 1.2555, 1.2779,\n",
      "        1.1900, 1.0579, 1.2747, 0.6638], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 275 was 33.2%\n",
      "current params: tensor([1.4214, 0.8112, 0.7285, 0.6616, 0.6156, 1.2837, 1.2888, 1.2724, 0.9966,\n",
      "        0.5719, 1.2863, 1.2517, 0.7776, 0.5998, 1.2665, 0.9384, 1.2564, 1.2789,\n",
      "        1.1921, 1.0598, 1.2757, 0.6621], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 276 was 33.2%\n",
      "current params: tensor([1.4230, 0.8114, 0.7277, 0.6594, 0.6139, 1.2848, 1.2899, 1.2734, 0.9984,\n",
      "        0.5699, 1.2875, 1.2525, 0.7773, 0.5980, 1.2675, 0.9392, 1.2573, 1.2800,\n",
      "        1.1942, 1.0618, 1.2767, 0.6605], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 277 was 33.2%\n",
      "current params: tensor([1.4247, 0.8117, 0.7268, 0.6573, 0.6121, 1.2858, 1.2910, 1.2744, 1.0003,\n",
      "        0.5680, 1.2886, 1.2533, 0.7770, 0.5961, 1.2684, 0.9398, 1.2581, 1.2810,\n",
      "        1.1964, 1.0638, 1.2777, 0.6589], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 278 was 33.3%\n",
      "current params: tensor([1.4263, 0.8119, 0.7260, 0.6552, 0.6103, 1.2869, 1.2922, 1.2754, 1.0021,\n",
      "        0.5660, 1.2898, 1.2541, 0.7767, 0.5943, 1.2694, 0.9404, 1.2590, 1.2820,\n",
      "        1.1985, 1.0657, 1.2787, 0.6573], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 279 was 33.3%\n",
      "current params: tensor([1.4279, 0.8122, 0.7251, 0.6530, 0.6085, 1.2880, 1.2933, 1.2764, 1.0039,\n",
      "        0.5641, 1.2909, 1.2549, 0.7764, 0.5925, 1.2703, 0.9409, 1.2599, 1.2830,\n",
      "        1.2006, 1.0677, 1.2797, 0.6557], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 280 was 33.3%\n",
      "current params: tensor([1.4295, 0.8125, 0.7243, 0.6509, 0.6068, 1.2890, 1.2944, 1.2774, 1.0058,\n",
      "        0.5621, 1.2921, 1.2557, 0.7761, 0.5907, 1.2713, 0.9414, 1.2607, 1.2840,\n",
      "        1.2027, 1.0697, 1.2807, 0.6541], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 281 was 33.3%\n",
      "current params: tensor([1.4312, 0.8128, 0.7235, 0.6487, 0.6050, 1.2901, 1.2955, 1.2784, 1.0076,\n",
      "        0.5602, 1.2932, 1.2565, 0.7758, 0.5889, 1.2722, 0.9418, 1.2616, 1.2850,\n",
      "        1.2048, 1.0716, 1.2817, 0.6524], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 282 was 33.4%\n",
      "current params: tensor([1.4328, 0.8132, 0.7226, 0.6466, 0.6032, 1.2911, 1.2966, 1.2794, 1.0095,\n",
      "        0.5582, 1.2944, 1.2574, 0.7756, 0.5870, 1.2732, 0.9421, 1.2625, 1.2861,\n",
      "        1.2069, 1.0736, 1.2827, 0.6508], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 283 was 33.4%\n",
      "current params: tensor([1.4344, 0.8135, 0.7218, 0.6445, 0.6014, 1.2922, 1.2977, 1.2804, 1.0113,\n",
      "        0.5562, 1.2955, 1.2582, 0.7753, 0.5852, 1.2741, 0.9424, 1.2633, 1.2871,\n",
      "        1.2090, 1.0756, 1.2837, 0.6492], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 284 was 33.4%\n",
      "current params: tensor([1.4360, 0.8139, 0.7210, 0.6423, 0.5996, 1.2932, 1.2988, 1.2814, 1.0132,\n",
      "        0.5543, 1.2967, 1.2590, 0.7751, 0.5834, 1.2751, 0.9427, 1.2642, 1.2881,\n",
      "        1.2111, 1.0776, 1.2847, 0.6475], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 285 was 33.5%\n",
      "current params: tensor([1.4377, 0.8142, 0.7202, 0.6402, 0.5978, 1.2943, 1.2999, 1.2824, 1.0151,\n",
      "        0.5523, 1.2978, 1.2598, 0.7749, 0.5815, 1.2760, 0.9429, 1.2651, 1.2891,\n",
      "        1.2132, 1.0796, 1.2857, 0.6459], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 286 was 33.5%\n",
      "current params: tensor([1.4393, 0.8146, 0.7194, 0.6380, 0.5961, 1.2954, 1.3010, 1.2834, 1.0170,\n",
      "        0.5503, 1.2990, 1.2606, 0.7746, 0.5797, 1.2770, 0.9431, 1.2659, 1.2901,\n",
      "        1.2153, 1.0815, 1.2867, 0.6442], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 287 was 33.5%\n",
      "current params: tensor([1.4409, 0.8150, 0.7185, 0.6358, 0.5943, 1.2964, 1.3022, 1.2844, 1.0189,\n",
      "        0.5483, 1.3001, 1.2614, 0.7744, 0.5779, 1.2780, 0.9433, 1.2668, 1.2911,\n",
      "        1.2174, 1.0835, 1.2877, 0.6426], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 288 was 33.6%\n",
      "current params: tensor([1.4425, 0.8154, 0.7177, 0.6337, 0.5925, 1.2975, 1.3033, 1.2855, 1.0207,\n",
      "        0.5464, 1.3013, 1.2622, 0.7742, 0.5760, 1.2789, 0.9434, 1.2677, 1.2921,\n",
      "        1.2195, 1.0855, 1.2887, 0.6409], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 289 was 33.6%\n",
      "current params: tensor([1.4442, 0.8159, 0.7169, 0.6315, 0.5907, 1.2985, 1.3044, 1.2865, 1.0226,\n",
      "        0.5444, 1.3024, 1.2630, 0.7740, 0.5742, 1.2799, 0.9435, 1.2685, 1.2932,\n",
      "        1.2216, 1.0875, 1.2897, 0.6392], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 290 was 33.6%\n",
      "current params: tensor([1.4458, 0.8163, 0.7161, 0.6294, 0.5889, 1.2996, 1.3055, 1.2875, 1.0245,\n",
      "        0.5424, 1.3036, 1.2638, 0.7738, 0.5723, 1.2808, 0.9436, 1.2694, 1.2942,\n",
      "        1.2238, 1.0895, 1.2907, 0.6376], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 291 was 33.7%\n",
      "current params: tensor([1.4474, 0.8168, 0.7153, 0.6272, 0.5871, 1.3007, 1.3066, 1.2885, 1.0264,\n",
      "        0.5404, 1.3047, 1.2647, 0.7736, 0.5705, 1.2818, 0.9437, 1.2702, 1.2952,\n",
      "        1.2259, 1.0915, 1.2917, 0.6359], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 292 was 33.7%\n",
      "current params: tensor([1.4490, 0.8173, 0.7145, 0.6250, 0.5853, 1.3017, 1.3077, 1.2895, 1.0284,\n",
      "        0.5384, 1.3059, 1.2655, 0.7735, 0.5686, 1.2827, 0.9437, 1.2711, 1.2962,\n",
      "        1.2280, 1.0935, 1.2927, 0.6342], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 293 was 33.7%\n",
      "current params: tensor([1.4506, 0.8178, 0.7137, 0.6229, 0.5835, 1.3028, 1.3088, 1.2905, 1.0303,\n",
      "        0.5364, 1.3071, 1.2663, 0.7733, 0.5668, 1.2837, 0.9438, 1.2720, 1.2972,\n",
      "        1.2301, 1.0955, 1.2937, 0.6325], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 294 was 33.8%\n",
      "current params: tensor([1.4523, 0.8183, 0.7130, 0.6207, 0.5817, 1.3038, 1.3099, 1.2915, 1.0322,\n",
      "        0.5344, 1.3082, 1.2671, 0.7731, 0.5649, 1.2847, 0.9438, 1.2728, 1.2982,\n",
      "        1.2322, 1.0975, 1.2947, 0.6308], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 295 was 33.8%\n",
      "current params: tensor([1.4539, 0.8188, 0.7122, 0.6185, 0.5799, 1.3049, 1.3110, 1.2925, 1.0341,\n",
      "        0.5324, 1.3094, 1.2679, 0.7730, 0.5630, 1.2856, 0.9438, 1.2737, 1.2993,\n",
      "        1.2343, 1.0995, 1.2957, 0.6292], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 296 was 33.9%\n",
      "current params: tensor([1.4555, 0.8194, 0.7114, 0.6163, 0.5780, 1.3059, 1.3122, 1.2936, 1.0360,\n",
      "        0.5304, 1.3105, 1.2687, 0.7728, 0.5612, 1.2866, 0.9438, 1.2746, 1.3003,\n",
      "        1.2364, 1.1015, 1.2967, 0.6275], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 297 was 33.9%\n",
      "current params: tensor([1.4571, 0.8199, 0.7106, 0.6141, 0.5762, 1.3070, 1.3133, 1.2946, 1.0380,\n",
      "        0.5284, 1.3117, 1.2695, 0.7727, 0.5593, 1.2875, 0.9438, 1.2754, 1.3013,\n",
      "        1.2385, 1.1035, 1.2978, 0.6258], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 298 was 33.9%\n",
      "current params: tensor([1.4587, 0.8205, 0.7098, 0.6120, 0.5744, 1.3081, 1.3144, 1.2956, 1.0399,\n",
      "        0.5264, 1.3129, 1.2703, 0.7726, 0.5574, 1.2885, 0.9438, 1.2763, 1.3023,\n",
      "        1.2406, 1.1055, 1.2988, 0.6241], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 299 was 34.0%\n",
      "current params: tensor([1.4604, 0.8211, 0.7091, 0.6098, 0.5726, 1.3091, 1.3155, 1.2966, 1.0418,\n",
      "        0.5244, 1.3140, 1.2711, 0.7725, 0.5556, 1.2895, 0.9438, 1.2771, 1.3033,\n",
      "        1.2427, 1.1075, 1.2998, 0.6224], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 300 was 34.0%\n",
      "current params: tensor([1.4620, 0.8217, 0.7083, 0.6076, 0.5708, 1.3102, 1.3166, 1.2976, 1.0438,\n",
      "        0.5224, 1.3152, 1.2719, 0.7724, 0.5537, 1.2904, 0.9437, 1.2780, 1.3044,\n",
      "        1.2448, 1.1095, 1.3008, 0.6206], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 301 was 34.0%\n",
      "current params: tensor([1.4636, 0.8223, 0.7076, 0.6054, 0.5690, 1.3112, 1.3177, 1.2986, 1.0457,\n",
      "        0.5204, 1.3164, 1.2727, 0.7723, 0.5518, 1.2914, 0.9437, 1.2789, 1.3054,\n",
      "        1.2469, 1.1115, 1.3018, 0.6189], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 302 was 34.1%\n",
      "current params: tensor([1.4652, 0.8230, 0.7068, 0.6032, 0.5671, 1.3123, 1.3188, 1.2997, 1.0477,\n",
      "        0.5183, 1.3176, 1.2735, 0.7722, 0.5499, 1.2923, 0.9436, 1.2797, 1.3064,\n",
      "        1.2491, 1.1135, 1.3028, 0.6172], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 303 was 34.1%\n",
      "current params: tensor([1.4668, 0.8236, 0.7060, 0.6010, 0.5653, 1.3133, 1.3199, 1.3007, 1.0496,\n",
      "        0.5163, 1.3187, 1.2743, 0.7721, 0.5481, 1.2933, 0.9436, 1.2806, 1.3074,\n",
      "        1.2512, 1.1155, 1.3038, 0.6155], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 304 was 34.1%\n",
      "current params: tensor([1.4685, 0.8243, 0.7053, 0.5988, 0.5635, 1.3144, 1.3210, 1.3017, 1.0516,\n",
      "        0.5143, 1.3199, 1.2751, 0.7720, 0.5462, 1.2943, 0.9435, 1.2815, 1.3084,\n",
      "        1.2533, 1.1175, 1.3048, 0.6138], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 305 was 34.2%\n",
      "current params: tensor([1.4701, 0.8250, 0.7046, 0.5966, 0.5616, 1.3155, 1.3221, 1.3027, 1.0535,\n",
      "        0.5122, 1.3211, 1.2759, 0.7720, 0.5443, 1.2952, 0.9435, 1.2823, 1.3094,\n",
      "        1.2554, 1.1195, 1.3058, 0.6120], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 306 was 34.2%\n",
      "current params: tensor([1.4717, 0.8257, 0.7038, 0.5944, 0.5598, 1.3165, 1.3232, 1.3037, 1.0555,\n",
      "        0.5102, 1.3223, 1.2767, 0.7719, 0.5424, 1.2962, 0.9434, 1.2832, 1.3105,\n",
      "        1.2575, 1.1215, 1.3068, 0.6103], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 307 was 34.3%\n",
      "current params: tensor([1.4733, 0.8265, 0.7031, 0.5922, 0.5580, 1.3176, 1.3243, 1.3048, 1.0575,\n",
      "        0.5082, 1.3234, 1.2775, 0.7719, 0.5405, 1.2972, 0.9433, 1.2840, 1.3115,\n",
      "        1.2596, 1.1236, 1.3078, 0.6085], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 308 was 34.3%\n",
      "current params: tensor([1.4749, 0.8272, 0.7024, 0.5900, 0.5561, 1.3186, 1.3255, 1.3058, 1.0594,\n",
      "        0.5061, 1.3246, 1.2783, 0.7719, 0.5386, 1.2981, 0.9432, 1.2849, 1.3125,\n",
      "        1.2617, 1.1256, 1.3088, 0.6068], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 309 was 34.3%\n",
      "current params: tensor([1.4765, 0.8280, 0.7016, 0.5878, 0.5543, 1.3197, 1.3266, 1.3068, 1.0614,\n",
      "        0.5041, 1.3258, 1.2791, 0.7719, 0.5367, 1.2991, 0.9432, 1.2857, 1.3135,\n",
      "        1.2638, 1.1276, 1.3098, 0.6050], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 310 was 34.4%\n",
      "current params: tensor([1.4781, 0.8287, 0.7009, 0.5856, 0.5525, 1.3208, 1.3277, 1.3078, 1.0634,\n",
      "        0.5020, 1.3270, 1.2799, 0.7718, 0.5348, 1.3001, 0.9431, 1.2866, 1.3145,\n",
      "        1.2659, 1.1296, 1.3108, 0.6033], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 311 was 34.4%\n",
      "current params: tensor([1.4798, 0.8295, 0.7002, 0.5834, 0.5506, 1.3218, 1.3288, 1.3089, 1.0653,\n",
      "        0.5000, 1.3282, 1.2807, 0.7718, 0.5329, 1.3010, 0.9430, 1.2875, 1.3156,\n",
      "        1.2680, 1.1316, 1.3118, 0.6015], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 312 was 34.5%\n",
      "current params: tensor([1.4814, 0.8304, 0.6995, 0.5811, 0.5488, 1.3229, 1.3299, 1.3099, 1.0673,\n",
      "        0.4979, 1.3293, 1.2815, 0.7719, 0.5310, 1.3020, 0.9429, 1.2883, 1.3166,\n",
      "        1.2701, 1.1336, 1.3128, 0.5998], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 313 was 34.5%\n",
      "current params: tensor([1.4830, 0.8312, 0.6988, 0.5789, 0.5469, 1.3239, 1.3310, 1.3109, 1.0693,\n",
      "        0.4959, 1.3305, 1.2824, 0.7719, 0.5291, 1.3030, 0.9428, 1.2892, 1.3176,\n",
      "        1.2722, 1.1356, 1.3138, 0.5980], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 314 was 34.5%\n",
      "current params: tensor([1.4846, 0.8320, 0.6981, 0.5767, 0.5451, 1.3250, 1.3321, 1.3119, 1.0713,\n",
      "        0.4938, 1.3317, 1.2832, 0.7719, 0.5272, 1.3040, 0.9427, 1.2900, 1.3186,\n",
      "        1.2743, 1.1376, 1.3148, 0.5962], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 315 was 34.6%\n",
      "current params: tensor([1.4862, 0.8329, 0.6974, 0.5745, 0.5432, 1.3260, 1.3332, 1.3130, 1.0733,\n",
      "        0.4918, 1.3329, 1.2840, 0.7719, 0.5253, 1.3049, 0.9426, 1.2909, 1.3196,\n",
      "        1.2764, 1.1397, 1.3158, 0.5944], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 316 was 34.6%\n",
      "current params: tensor([1.4878, 0.8338, 0.6967, 0.5722, 0.5414, 1.3271, 1.3343, 1.3140, 1.0752,\n",
      "        0.4897, 1.3341, 1.2848, 0.7720, 0.5234, 1.3059, 0.9425, 1.2918, 1.3206,\n",
      "        1.2785, 1.1417, 1.3169, 0.5927], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 317 was 34.7%\n",
      "current params: tensor([1.4894, 0.8347, 0.6960, 0.5700, 0.5395, 1.3282, 1.3354, 1.3150, 1.0772,\n",
      "        0.4876, 1.3353, 1.2856, 0.7720, 0.5214, 1.3069, 0.9424, 1.2926, 1.3217,\n",
      "        1.2806, 1.1437, 1.3179, 0.5909], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 318 was 34.7%\n",
      "current params: tensor([1.4910, 0.8356, 0.6953, 0.5678, 0.5377, 1.3292, 1.3365, 1.3161, 1.0792,\n",
      "        0.4856, 1.3365, 1.2864, 0.7721, 0.5195, 1.3079, 0.9423, 1.2935, 1.3227,\n",
      "        1.2827, 1.1457, 1.3189, 0.5891], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 319 was 34.8%\n",
      "current params: tensor([1.4926, 0.8365, 0.6947, 0.5655, 0.5358, 1.3303, 1.3376, 1.3171, 1.0812,\n",
      "        0.4835, 1.3377, 1.2871, 0.7722, 0.5176, 1.3088, 0.9422, 1.2943, 1.3237,\n",
      "        1.2848, 1.1477, 1.3199, 0.5873], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 320 was 34.8%\n",
      "current params: tensor([1.4942, 0.8375, 0.6940, 0.5633, 0.5339, 1.3313, 1.3387, 1.3181, 1.0832,\n",
      "        0.4814, 1.3389, 1.2879, 0.7723, 0.5157, 1.3098, 0.9421, 1.2952, 1.3247,\n",
      "        1.2869, 1.1497, 1.3209, 0.5855], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 321 was 34.8%\n",
      "current params: tensor([1.4959, 0.8384, 0.6933, 0.5610, 0.5321, 1.3324, 1.3398, 1.3192, 1.0852,\n",
      "        0.4793, 1.3401, 1.2887, 0.7724, 0.5137, 1.3108, 0.9420, 1.2960, 1.3257,\n",
      "        1.2890, 1.1517, 1.3219, 0.5837], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 322 was 34.9%\n",
      "current params: tensor([1.4975, 0.8394, 0.6927, 0.5588, 0.5302, 1.3334, 1.3409, 1.3202, 1.0872,\n",
      "        0.4773, 1.3412, 1.2895, 0.7725, 0.5118, 1.3118, 0.9419, 1.2969, 1.3268,\n",
      "        1.2911, 1.1537, 1.3229, 0.5819], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 323 was 34.9%\n",
      "current params: tensor([1.4991, 0.8404, 0.6920, 0.5566, 0.5283, 1.3345, 1.3420, 1.3212, 1.0891,\n",
      "        0.4752, 1.3424, 1.2903, 0.7726, 0.5099, 1.3127, 0.9418, 1.2977, 1.3278,\n",
      "        1.2932, 1.1558, 1.3239, 0.5801], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 324 was 35.0%\n",
      "current params: tensor([1.5007, 0.8414, 0.6914, 0.5543, 0.5265, 1.3356, 1.3431, 1.3223, 1.0911,\n",
      "        0.4731, 1.3436, 1.2911, 0.7728, 0.5079, 1.3137, 0.9417, 1.2986, 1.3288,\n",
      "        1.2953, 1.1578, 1.3249, 0.5782], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 325 was 35.0%\n",
      "current params: tensor([1.5023, 0.8425, 0.6907, 0.5520, 0.5246, 1.3366, 1.3442, 1.3233, 1.0931,\n",
      "        0.4710, 1.3448, 1.2919, 0.7729, 0.5060, 1.3147, 0.9416, 1.2994, 1.3298,\n",
      "        1.2974, 1.1598, 1.3259, 0.5764], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 326 was 35.1%\n",
      "current params: tensor([1.5039, 0.8435, 0.6901, 0.5498, 0.5227, 1.3377, 1.3453, 1.3243, 1.0951,\n",
      "        0.4689, 1.3460, 1.2927, 0.7731, 0.5041, 1.3157, 0.9415, 1.3003, 1.3308,\n",
      "        1.2995, 1.1618, 1.3269, 0.5746], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 327 was 35.1%\n",
      "current params: tensor([1.5055, 0.8446, 0.6895, 0.5475, 0.5208, 1.3387, 1.3464, 1.3254, 1.0971,\n",
      "        0.4668, 1.3472, 1.2935, 0.7732, 0.5021, 1.3167, 0.9414, 1.3012, 1.3319,\n",
      "        1.3016, 1.1638, 1.3279, 0.5728], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 328 was 35.2%\n",
      "current params: tensor([1.5071, 0.8457, 0.6888, 0.5453, 0.5190, 1.3398, 1.3475, 1.3264, 1.0991,\n",
      "        0.4647, 1.3485, 1.2943, 0.7734, 0.5002, 1.3177, 0.9413, 1.3020, 1.3329,\n",
      "        1.3037, 1.1658, 1.3289, 0.5709], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 329 was 35.2%\n",
      "current params: tensor([1.5087, 0.8468, 0.6882, 0.5430, 0.5171, 1.3408, 1.3486, 1.3275, 1.1011,\n",
      "        0.4626, 1.3497, 1.2951, 0.7736, 0.4982, 1.3186, 0.9412, 1.3029, 1.3339,\n",
      "        1.3058, 1.1678, 1.3299, 0.5691], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 330 was 35.3%\n",
      "current params: tensor([1.5103, 0.8479, 0.6876, 0.5407, 0.5152, 1.3419, 1.3497, 1.3285, 1.1031,\n",
      "        0.4605, 1.3509, 1.2959, 0.7738, 0.4963, 1.3196, 0.9411, 1.3037, 1.3349,\n",
      "        1.3078, 1.1698, 1.3310, 0.5672], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 331 was 35.3%\n",
      "current params: tensor([1.5119, 0.8490, 0.6870, 0.5385, 0.5133, 1.3429, 1.3508, 1.3295, 1.1051,\n",
      "        0.4584, 1.3521, 1.2967, 0.7740, 0.4943, 1.3206, 0.9409, 1.3046, 1.3359,\n",
      "        1.3099, 1.1718, 1.3320, 0.5654], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 332 was 35.3%\n",
      "current params: tensor([1.5135, 0.8501, 0.6864, 0.5362, 0.5114, 1.3440, 1.3519, 1.3306, 1.1071,\n",
      "        0.4563, 1.3533, 1.2975, 0.7742, 0.4924, 1.3216, 0.9408, 1.3054, 1.3370,\n",
      "        1.3120, 1.1738, 1.3330, 0.5635], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 333 was 35.4%\n",
      "current params: tensor([1.5151, 0.8513, 0.6858, 0.5339, 0.5095, 1.3451, 1.3530, 1.3316, 1.1091,\n",
      "        0.4542, 1.3545, 1.2983, 0.7745, 0.4904, 1.3226, 0.9407, 1.3063, 1.3380,\n",
      "        1.3141, 1.1759, 1.3340, 0.5617], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 334 was 35.4%\n",
      "current params: tensor([1.5167, 0.8525, 0.6852, 0.5316, 0.5076, 1.3461, 1.3541, 1.3327, 1.1111,\n",
      "        0.4520, 1.3557, 1.2991, 0.7747, 0.4885, 1.3236, 0.9406, 1.3071, 1.3390,\n",
      "        1.3162, 1.1779, 1.3350, 0.5598], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 335 was 35.5%\n",
      "current params: tensor([1.5183, 0.8537, 0.6846, 0.5294, 0.5057, 1.3472, 1.3552, 1.3337, 1.1131,\n",
      "        0.4499, 1.3569, 1.2999, 0.7750, 0.4865, 1.3246, 0.9405, 1.3080, 1.3400,\n",
      "        1.3183, 1.1799, 1.3360, 0.5579], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 336 was 35.5%\n",
      "current params: tensor([1.5199, 0.8549, 0.6841, 0.5271, 0.5038, 1.3482, 1.3563, 1.3348, 1.1151,\n",
      "        0.4478, 1.3581, 1.3007, 0.7752, 0.4845, 1.3256, 0.9404, 1.3088, 1.3411,\n",
      "        1.3203, 1.1819, 1.3370, 0.5561], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 337 was 35.6%\n",
      "current params: tensor([1.5215, 0.8561, 0.6835, 0.5248, 0.5019, 1.3493, 1.3574, 1.3358, 1.1171,\n",
      "        0.4457, 1.3593, 1.3015, 0.7755, 0.4826, 1.3266, 0.9403, 1.3097, 1.3421,\n",
      "        1.3224, 1.1839, 1.3380, 0.5542], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 338 was 35.6%\n",
      "current params: tensor([1.5231, 0.8574, 0.6829, 0.5225, 0.5000, 1.3503, 1.3585, 1.3368, 1.1191,\n",
      "        0.4435, 1.3606, 1.3023, 0.7758, 0.4806, 1.3276, 0.9401, 1.3105, 1.3431,\n",
      "        1.3245, 1.1859, 1.3390, 0.5523], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 339 was 35.7%\n",
      "current params: tensor([1.5247, 0.8586, 0.6824, 0.5202, 0.4981, 1.3514, 1.3596, 1.3379, 1.1211,\n",
      "        0.4414, 1.3618, 1.3031, 0.7761, 0.4786, 1.3286, 0.9400, 1.3114, 1.3441,\n",
      "        1.3266, 1.1879, 1.3400, 0.5504], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 340 was 35.7%\n",
      "current params: tensor([1.5263, 0.8599, 0.6818, 0.5179, 0.4962, 1.3524, 1.3607, 1.3389, 1.1231,\n",
      "        0.4393, 1.3630, 1.3039, 0.7764, 0.4766, 1.3295, 0.9399, 1.3122, 1.3451,\n",
      "        1.3287, 1.1899, 1.3410, 0.5485], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 341 was 35.8%\n",
      "current params: tensor([1.5279, 0.8612, 0.6813, 0.5156, 0.4943, 1.3535, 1.3618, 1.3400, 1.1251,\n",
      "        0.4371, 1.3642, 1.3047, 0.7767, 0.4747, 1.3305, 0.9398, 1.3130, 1.3462,\n",
      "        1.3307, 1.1919, 1.3420, 0.5466], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 342 was 35.8%\n",
      "current params: tensor([1.5295, 0.8625, 0.6807, 0.5133, 0.4924, 1.3545, 1.3629, 1.3410, 1.1271,\n",
      "        0.4350, 1.3654, 1.3055, 0.7771, 0.4727, 1.3315, 0.9397, 1.3139, 1.3472,\n",
      "        1.3328, 1.1939, 1.3431, 0.5447], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 343 was 35.9%\n",
      "current params: tensor([1.5311, 0.8638, 0.6802, 0.5110, 0.4905, 1.3556, 1.3640, 1.3421, 1.1291,\n",
      "        0.4329, 1.3667, 1.3063, 0.7774, 0.4707, 1.3325, 0.9396, 1.3147, 1.3482,\n",
      "        1.3349, 1.1959, 1.3441, 0.5428], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 344 was 35.9%\n",
      "current params: tensor([1.5326, 0.8651, 0.6797, 0.5087, 0.4886, 1.3566, 1.3651, 1.3431, 1.1311,\n",
      "        0.4307, 1.3679, 1.3071, 0.7778, 0.4687, 1.3335, 0.9394, 1.3156, 1.3492,\n",
      "        1.3369, 1.1979, 1.3451, 0.5409], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 345 was 36.0%\n",
      "current params: tensor([1.5342, 0.8664, 0.6792, 0.5064, 0.4867, 1.3577, 1.3662, 1.3442, 1.1331,\n",
      "        0.4286, 1.3691, 1.3079, 0.7781, 0.4667, 1.3345, 0.9393, 1.3164, 1.3502,\n",
      "        1.3390, 1.1999, 1.3461, 0.5390], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 346 was 36.1%\n",
      "current params: tensor([1.5358, 0.8678, 0.6787, 0.5041, 0.4847, 1.3587, 1.3673, 1.3452, 1.1351,\n",
      "        0.4264, 1.3703, 1.3087, 0.7785, 0.4648, 1.3355, 0.9392, 1.3173, 1.3513,\n",
      "        1.3411, 1.2018, 1.3471, 0.5371], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 347 was 36.1%\n",
      "current params: tensor([1.5374, 0.8692, 0.6782, 0.5018, 0.4828, 1.3598, 1.3684, 1.3463, 1.1371,\n",
      "        0.4243, 1.3716, 1.3095, 0.7789, 0.4628, 1.3366, 0.9391, 1.3181, 1.3523,\n",
      "        1.3431, 1.2038, 1.3481, 0.5352], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 348 was 36.2%\n",
      "current params: tensor([1.5390, 0.8705, 0.6777, 0.4995, 0.4809, 1.3608, 1.3694, 1.3473, 1.1391,\n",
      "        0.4221, 1.3728, 1.3102, 0.7793, 0.4608, 1.3376, 0.9390, 1.3189, 1.3533,\n",
      "        1.3452, 1.2058, 1.3491, 0.5333], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 349 was 36.2%\n",
      "current params: tensor([1.5406, 0.8719, 0.6772, 0.4972, 0.4790, 1.3619, 1.3705, 1.3484, 1.1410,\n",
      "        0.4200, 1.3740, 1.3110, 0.7798, 0.4588, 1.3386, 0.9389, 1.3198, 1.3543,\n",
      "        1.3473, 1.2078, 1.3501, 0.5313], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 350 was 36.3%\n",
      "current params: tensor([1.5422, 0.8734, 0.6767, 0.4948, 0.4770, 1.3629, 1.3716, 1.3494, 1.1430,\n",
      "        0.4178, 1.3752, 1.3118, 0.7802, 0.4568, 1.3396, 0.9387, 1.3206, 1.3553,\n",
      "        1.3493, 1.2098, 1.3511, 0.5294], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 351 was 36.3%\n",
      "current params: tensor([1.5438, 0.8748, 0.6762, 0.4925, 0.4751, 1.3640, 1.3727, 1.3505, 1.1450,\n",
      "        0.4156, 1.3765, 1.3126, 0.7806, 0.4548, 1.3406, 0.9386, 1.3215, 1.3564,\n",
      "        1.3514, 1.2118, 1.3521, 0.5275], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 352 was 36.4%\n",
      "current params: tensor([1.5453, 0.8762, 0.6758, 0.4902, 0.4732, 1.3650, 1.3738, 1.3515, 1.1470,\n",
      "        0.4135, 1.3777, 1.3134, 0.7811, 0.4528, 1.3416, 0.9385, 1.3223, 1.3574,\n",
      "        1.3534, 1.2138, 1.3532, 0.5255], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 353 was 36.4%\n",
      "current params: tensor([1.5469, 0.8777, 0.6753, 0.4878, 0.4712, 1.3661, 1.3749, 1.3526, 1.1490,\n",
      "        0.4113, 1.3789, 1.3142, 0.7816, 0.4508, 1.3426, 0.9384, 1.3231, 1.3584,\n",
      "        1.3555, 1.2157, 1.3542, 0.5236], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 354 was 36.5%\n",
      "current params: tensor([1.5485, 0.8791, 0.6748, 0.4855, 0.4693, 1.3671, 1.3760, 1.3537, 1.1510,\n",
      "        0.4091, 1.3802, 1.3150, 0.7820, 0.4488, 1.3436, 0.9391, 1.3240, 1.3594,\n",
      "        1.3575, 1.2177, 1.3552, 0.5216], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 355 was 36.6%\n",
      "current params: tensor([1.5501, 0.8806, 0.6744, 0.4832, 0.4674, 1.3681, 1.3771, 1.3547, 1.1530,\n",
      "        0.4070, 1.3814, 1.3158, 0.7825, 0.4468, 1.3446, 0.9398, 1.3248, 1.3605,\n",
      "        1.3596, 1.2197, 1.3562, 0.5197], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 356 was 36.6%\n",
      "current params: tensor([1.5517, 0.8821, 0.6740, 0.4808, 0.4654, 1.3692, 1.3782, 1.3558, 1.1550,\n",
      "        0.4048, 1.3826, 1.3166, 0.7830, 0.4448, 1.3456, 0.9403, 1.3257, 1.3615,\n",
      "        1.3616, 1.2217, 1.3572, 0.5177], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 357 was 36.7%\n",
      "current params: tensor([1.5532, 0.8836, 0.6735, 0.4785, 0.4635, 1.3702, 1.3792, 1.3568, 1.1570,\n",
      "        0.4026, 1.3839, 1.3174, 0.7836, 0.4428, 1.3467, 0.9408, 1.3265, 1.3625,\n",
      "        1.3637, 1.2237, 1.3582, 0.5157], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 358 was 36.7%\n",
      "current params: tensor([1.5548, 0.8851, 0.6731, 0.4762, 0.4615, 1.3713, 1.3803, 1.3579, 1.1590,\n",
      "        0.4004, 1.3851, 1.3182, 0.7841, 0.4408, 1.3477, 0.9413, 1.3273, 1.3635,\n",
      "        1.3657, 1.2256, 1.3592, 0.5138], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 359 was 36.8%\n",
      "current params: tensor([1.5564, 0.8866, 0.6727, 0.4738, 0.4596, 1.3723, 1.3814, 1.3589, 1.1609,\n",
      "        0.3982, 1.3864, 1.3190, 0.7846, 0.4387, 1.3487, 0.9417, 1.3282, 1.3645,\n",
      "        1.3678, 1.2276, 1.3602, 0.5118], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 360 was 36.9%\n",
      "current params: tensor([1.5580, 0.8882, 0.6723, 0.4715, 0.4576, 1.3733, 1.3825, 1.3600, 1.1629,\n",
      "        0.3961, 1.3876, 1.3198, 0.7852, 0.4367, 1.3497, 0.9420, 1.3290, 1.3656,\n",
      "        1.3698, 1.2296, 1.3613, 0.5098], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 361 was 36.9%\n",
      "current params: tensor([1.5595, 0.8897, 0.6719, 0.4691, 0.4557, 1.3744, 1.3836, 1.3610, 1.1649,\n",
      "        0.3939, 1.3888, 1.3206, 0.7857, 0.4347, 1.3507, 0.9423, 1.3298, 1.3666,\n",
      "        1.3718, 1.2315, 1.3623, 0.5078], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 362 was 37.0%\n",
      "current params: tensor([1.5611, 0.8913, 0.6715, 0.4668, 0.4537, 1.3754, 1.3847, 1.3621, 1.1669,\n",
      "        0.3917, 1.3901, 1.3214, 0.7863, 0.4327, 1.3517, 0.9426, 1.3306, 1.3676,\n",
      "        1.3739, 1.2335, 1.3633, 0.5058], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 363 was 37.0%\n",
      "current params: tensor([1.5627, 0.8928, 0.6711, 0.4644, 0.4518, 1.3764, 1.3858, 1.3632, 1.1689,\n",
      "        0.3895, 1.3913, 1.3222, 0.7869, 0.4307, 1.3528, 0.9428, 1.3315, 1.3686,\n",
      "        1.3759, 1.2355, 1.3643, 0.5038], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 364 was 37.1%\n",
      "current params: tensor([1.5643, 0.8944, 0.6707, 0.4620, 0.4498, 1.3775, 1.3868, 1.3642, 1.1709,\n",
      "        0.3873, 1.3926, 1.3230, 0.7875, 0.4287, 1.3538, 0.9430, 1.3323, 1.3696,\n",
      "        1.3779, 1.2374, 1.3653, 0.5018], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 365 was 37.2%\n",
      "current params: tensor([1.5658, 0.8960, 0.6704, 0.4597, 0.4478, 1.3785, 1.3879, 1.3653, 1.1728,\n",
      "        0.3851, 1.3938, 1.3238, 0.7881, 0.4266, 1.3548, 0.9432, 1.3331, 1.3707,\n",
      "        1.3800, 1.2394, 1.3663, 0.4998], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 366 was 37.2%\n",
      "current params: tensor([1.5674, 0.8976, 0.6700, 0.4573, 0.4459, 1.3795, 1.3890, 1.3663, 1.1748,\n",
      "        0.3829, 1.3951, 1.3246, 0.7888, 0.4246, 1.3558, 0.9433, 1.3339, 1.3717,\n",
      "        1.3820, 1.2413, 1.3673, 0.4978], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 367 was 37.3%\n",
      "current params: tensor([1.5690, 0.8992, 0.6697, 0.4549, 0.4439, 1.3806, 1.3901, 1.3674, 1.1768,\n",
      "        0.3807, 1.3963, 1.3254, 0.7894, 0.4226, 1.3569, 0.9434, 1.3348, 1.3727,\n",
      "        1.3840, 1.2433, 1.3683, 0.4958], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 368 was 37.4%\n",
      "current params: tensor([1.5705, 0.9008, 0.6693, 0.4526, 0.4419, 1.3816, 1.3912, 1.3685, 1.1788,\n",
      "        0.3785, 1.3976, 1.3262, 0.7901, 0.4206, 1.3579, 0.9435, 1.3356, 1.3737,\n",
      "        1.3860, 1.2452, 1.3694, 0.4938], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 369 was 37.4%\n",
      "current params: tensor([1.5721, 0.9025, 0.6690, 0.4502, 0.4400, 1.3826, 1.3923, 1.3695, 1.1807,\n",
      "        0.3763, 1.3988, 1.3270, 0.7907, 0.4185, 1.3589, 0.9435, 1.3364, 1.3747,\n",
      "        1.3880, 1.2472, 1.3704, 0.4918], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 370 was 37.5%\n",
      "current params: tensor([1.5737, 0.9041, 0.6687, 0.4478, 0.4380, 1.3837, 1.3933, 1.3706, 1.1827,\n",
      "        0.3741, 1.4001, 1.3278, 0.7914, 0.4165, 1.3600, 0.9436, 1.3372, 1.3758,\n",
      "        1.3900, 1.2491, 1.3714, 0.4898], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 371 was 37.6%\n",
      "current params: tensor([1.5752, 0.9057, 0.6683, 0.4454, 0.4360, 1.3847, 1.3944, 1.3716, 1.1847,\n",
      "        0.3719, 1.4013, 1.3285, 0.7921, 0.4145, 1.3610, 0.9436, 1.3381, 1.3768,\n",
      "        1.3920, 1.2511, 1.3724, 0.4878], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 372 was 37.6%\n",
      "current params: tensor([1.5768, 0.9074, 0.6680, 0.4431, 0.4341, 1.3857, 1.3955, 1.3727, 1.1866,\n",
      "        0.3697, 1.4026, 1.3293, 0.7928, 0.4124, 1.3620, 0.9436, 1.3389, 1.3778,\n",
      "        1.3941, 1.2530, 1.3734, 0.4857], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 373 was 37.7%\n",
      "current params: tensor([1.5783, 0.9091, 0.6677, 0.4407, 0.4321, 1.3867, 1.3966, 1.3738, 1.1886,\n",
      "        0.3674, 1.4038, 1.3301, 0.7935, 0.4104, 1.3631, 0.9436, 1.3397, 1.3788,\n",
      "        1.3961, 1.2549, 1.3744, 0.4837], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 374 was 37.8%\n",
      "current params: tensor([1.5799, 0.9107, 0.6674, 0.4383, 0.4301, 1.3878, 1.3977, 1.3748, 1.1906,\n",
      "        0.3652, 1.4051, 1.3309, 0.7942, 0.4083, 1.3641, 0.9436, 1.3405, 1.3798,\n",
      "        1.3981, 1.2569, 1.3754, 0.4817], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 375 was 37.8%\n",
      "current params: tensor([1.5814, 0.9124, 0.6672, 0.4359, 0.4281, 1.3888, 1.3987, 1.3759, 1.1925,\n",
      "        0.3630, 1.4063, 1.3317, 0.7950, 0.4063, 1.3651, 0.9436, 1.3413, 1.3809,\n",
      "        1.4001, 1.2588, 1.3765, 0.4796], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 376 was 37.9%\n",
      "current params: tensor([1.5830, 0.9141, 0.6669, 0.4335, 0.4261, 1.3898, 1.3998, 1.3769, 1.1945,\n",
      "        0.3608, 1.4076, 1.3325, 0.7957, 0.4043, 1.3662, 0.9436, 1.3421, 1.3819,\n",
      "        1.4020, 1.2607, 1.3775, 0.4776], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 377 was 38.0%\n",
      "current params: tensor([1.5845, 0.9158, 0.6666, 0.4311, 0.4241, 1.3908, 1.4009, 1.3780, 1.1965,\n",
      "        0.3586, 1.4088, 1.3333, 0.7965, 0.4022, 1.3672, 0.9436, 1.3429, 1.3829,\n",
      "        1.4040, 1.2626, 1.3785, 0.4755], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 378 was 38.0%\n",
      "current params: tensor([1.5861, 0.9175, 0.6663, 0.4287, 0.4221, 1.3918, 1.4020, 1.3790, 1.1984,\n",
      "        0.3564, 1.4101, 1.3341, 0.7973, 0.4002, 1.3683, 0.9435, 1.3437, 1.3839,\n",
      "        1.4060, 1.2646, 1.3795, 0.4735], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 379 was 38.1%\n",
      "current params: tensor([1.5876, 0.9192, 0.6661, 0.4263, 0.4202, 1.3929, 1.4030, 1.3801, 1.2004,\n",
      "        0.3541, 1.4114, 1.3349, 0.7980, 0.3981, 1.3693, 0.9435, 1.3445, 1.3849,\n",
      "        1.4080, 1.2665, 1.3805, 0.4714], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 380 was 38.2%\n",
      "current params: tensor([1.5892, 0.9209, 0.6659, 0.4239, 0.4182, 1.3939, 1.4041, 1.3812, 1.2023,\n",
      "        0.3519, 1.4126, 1.3357, 0.7988, 0.3961, 1.3703, 0.9434, 1.3453, 1.3859,\n",
      "        1.4100, 1.2684, 1.3815, 0.4693], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 381 was 38.2%\n",
      "current params: tensor([1.5907, 0.9227, 0.6656, 0.4215, 0.4162, 1.3949, 1.4052, 1.3822, 1.2043,\n",
      "        0.3497, 1.4139, 1.3365, 0.7997, 0.3940, 1.3714, 0.9433, 1.3461, 1.3870,\n",
      "        1.4120, 1.2703, 1.3826, 0.4673], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 382 was 38.3%\n",
      "current params: tensor([1.5923, 0.9244, 0.6654, 0.4191, 0.4142, 1.3959, 1.4063, 1.3833, 1.2062,\n",
      "        0.3474, 1.4151, 1.3373, 0.8005, 0.3920, 1.3724, 0.9433, 1.3469, 1.3880,\n",
      "        1.4139, 1.2722, 1.3836, 0.4652], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 383 was 38.4%\n",
      "current params: tensor([1.5938, 0.9261, 0.6652, 0.4167, 0.4122, 1.3969, 1.4073, 1.3843, 1.2082,\n",
      "        0.3452, 1.4164, 1.3381, 0.8013, 0.3899, 1.3735, 0.9432, 1.3477, 1.3890,\n",
      "        1.4159, 1.2741, 1.3846, 0.4631], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 384 was 38.5%\n",
      "current params: tensor([1.5954, 0.9279, 0.6650, 0.4143, 0.4102, 1.3979, 1.4084, 1.3854, 1.2101,\n",
      "        0.3430, 1.4177, 1.3389, 0.8022, 0.3879, 1.3745, 0.9431, 1.3485, 1.3900,\n",
      "        1.4179, 1.2760, 1.3856, 0.4611], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 385 was 38.5%\n",
      "current params: tensor([1.5969, 0.9296, 0.6648, 0.4119, 0.4082, 1.3989, 1.4095, 1.3865, 1.2120,\n",
      "        0.3407, 1.4189, 1.3397, 0.8030, 0.3858, 1.3756, 0.9430, 1.3493, 1.3910,\n",
      "        1.4198, 1.2779, 1.3866, 0.4590], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 386 was 38.6%\n",
      "current params: tensor([1.5984, 0.9314, 0.6646, 0.4094, 0.4062, 1.3999, 1.4106, 1.3875, 1.2140,\n",
      "        0.3385, 1.4202, 1.3405, 0.8039, 0.3838, 1.3766, 0.9429, 1.3501, 1.3920,\n",
      "        1.4218, 1.2798, 1.3876, 0.4569], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 387 was 38.7%\n",
      "current params: tensor([1.6000, 0.9332, 0.6644, 0.4070, 0.4041, 1.4009, 1.4116, 1.3886, 1.2159,\n",
      "        0.3363, 1.4215, 1.3413, 0.8048, 0.3817, 1.3777, 0.9428, 1.3509, 1.3930,\n",
      "        1.4237, 1.2817, 1.3887, 0.4548], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 388 was 38.8%\n",
      "current params: tensor([1.6015, 0.9349, 0.6642, 0.4046, 0.4021, 1.4019, 1.4127, 1.3896, 1.2179,\n",
      "        0.3340, 1.4227, 1.3421, 0.8057, 0.3797, 1.3787, 0.9427, 1.3517, 1.3941,\n",
      "        1.4257, 1.2836, 1.3897, 0.4527], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 389 was 38.8%\n",
      "current params: tensor([1.6030, 0.9367, 0.6641, 0.4022, 0.4001, 1.4029, 1.4138, 1.3907, 1.2198,\n",
      "        0.3318, 1.4240, 1.3429, 0.8066, 0.3776, 1.3798, 0.9427, 1.3525, 1.3951,\n",
      "        1.4276, 1.2855, 1.3907, 0.4506], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 390 was 38.9%\n",
      "current params: tensor([1.6046, 0.9385, 0.6639, 0.3997, 0.3981, 1.4039, 1.4148, 1.3917, 1.2217,\n",
      "        0.3295, 1.4253, 1.3437, 0.8075, 0.3756, 1.3809, 0.9426, 1.3533, 1.3961,\n",
      "        1.4296, 1.2874, 1.3917, 0.4485], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 391 was 39.0%\n",
      "current params: tensor([1.6061, 0.9403, 0.6638, 0.3973, 0.3961, 1.4049, 1.4159, 1.3928, 1.2236,\n",
      "        0.3273, 1.4265, 1.3445, 0.8084, 0.3735, 1.3819, 0.9425, 1.3540, 1.3971,\n",
      "        1.4315, 1.2893, 1.3927, 0.4464], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 392 was 39.1%\n",
      "current params: tensor([1.6076, 0.9421, 0.6636, 0.3949, 0.3941, 1.4059, 1.4170, 1.3938, 1.2256,\n",
      "        0.3250, 1.4278, 1.3453, 0.8093, 0.3715, 1.3830, 0.9423, 1.3548, 1.3981,\n",
      "        1.4334, 1.2911, 1.3937, 0.4443], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 393 was 39.2%\n",
      "current params: tensor([1.6091, 0.9439, 0.6635, 0.3924, 0.3920, 1.4069, 1.4181, 1.3949, 1.2275,\n",
      "        0.3228, 1.4291, 1.3461, 0.8103, 0.3694, 1.3840, 0.9422, 1.3556, 1.3991,\n",
      "        1.4354, 1.2930, 1.3948, 0.4422], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 394 was 39.2%\n",
      "current params: tensor([1.6106, 0.9457, 0.6634, 0.3900, 0.3900, 1.4079, 1.4191, 1.3959, 1.2294,\n",
      "        0.3205, 1.4303, 1.3469, 0.8112, 0.3673, 1.3851, 0.9421, 1.3564, 1.4001,\n",
      "        1.4373, 1.2949, 1.3958, 0.4401], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 395 was 39.3%\n",
      "current params: tensor([1.6122, 0.9475, 0.6633, 0.3876, 0.3880, 1.4088, 1.4202, 1.3970, 1.2313,\n",
      "        0.3183, 1.4316, 1.3477, 0.8122, 0.3653, 1.3862, 0.9420, 1.3571, 1.4011,\n",
      "        1.4392, 1.2967, 1.3968, 0.4380], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 396 was 39.4%\n",
      "current params: tensor([1.6137, 0.9493, 0.6632, 0.3851, 0.3860, 1.4098, 1.4213, 1.3980, 1.2332,\n",
      "        0.3160, 1.4329, 1.3485, 0.8132, 0.3632, 1.3872, 0.9419, 1.3579, 1.4021,\n",
      "        1.4411, 1.2986, 1.3978, 0.4358], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 397 was 39.5%\n",
      "current params: tensor([1.6152, 0.9511, 0.6631, 0.3827, 0.3839, 1.4108, 1.4223, 1.3991, 1.2352,\n",
      "        0.3138, 1.4341, 1.3494, 0.8142, 0.3611, 1.3883, 0.9418, 1.3587, 1.4031,\n",
      "        1.4430, 1.3004, 1.3988, 0.4337], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 398 was 39.6%\n",
      "current params: tensor([1.6167, 0.9529, 0.6630, 0.3802, 0.3819, 1.4118, 1.4234, 1.4001, 1.2371,\n",
      "        0.3115, 1.4354, 1.3502, 0.8152, 0.3608, 1.3894, 0.9417, 1.3594, 1.4042,\n",
      "        1.4449, 1.3023, 1.3999, 0.4316], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 399 was 39.6%\n",
      "current params: tensor([1.6182, 0.9547, 0.6629, 0.3778, 0.3799, 1.4128, 1.4245, 1.4012, 1.2390,\n",
      "        0.3093, 1.4367, 1.3510, 0.8162, 0.3614, 1.3904, 0.9416, 1.3602, 1.4052,\n",
      "        1.4468, 1.3041, 1.4009, 0.4295], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 400 was 39.7%\n",
      "current params: tensor([1.6197, 0.9566, 0.6629, 0.3753, 0.3778, 1.4137, 1.4255, 1.4022, 1.2409,\n",
      "        0.3070, 1.4380, 1.3518, 0.8172, 0.3628, 1.3915, 0.9415, 1.3609, 1.4062,\n",
      "        1.4487, 1.3060, 1.4019, 0.4273], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 401 was 39.8%\n",
      "current params: tensor([1.6212, 0.9584, 0.6628, 0.3728, 0.3758, 1.4147, 1.4266, 1.4033, 1.2428,\n",
      "        0.3048, 1.4392, 1.3526, 0.8183, 0.3646, 1.3926, 0.9413, 1.3617, 1.4072,\n",
      "        1.4506, 1.3078, 1.4029, 0.4252], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 402 was 39.8%\n",
      "current params: tensor([1.6227, 0.9602, 0.6628, 0.3704, 0.3738, 1.4157, 1.4277, 1.4043, 1.2447,\n",
      "        0.3025, 1.4405, 1.3534, 0.8193, 0.3662, 1.3937, 0.9412, 1.3624, 1.4082,\n",
      "        1.4525, 1.3096, 1.4040, 0.4230], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 403 was 39.9%\n",
      "current params: tensor([1.6242, 0.9620, 0.6627, 0.3679, 0.3717, 1.4166, 1.4287, 1.4054, 1.2466,\n",
      "        0.3002, 1.4418, 1.3542, 0.8204, 0.3675, 1.3947, 0.9411, 1.3632, 1.4092,\n",
      "        1.4543, 1.3115, 1.4050, 0.4209], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 404 was 40.0%\n",
      "current params: tensor([1.6257, 0.9639, 0.6627, 0.3654, 0.3697, 1.4176, 1.4298, 1.4064, 1.2485,\n",
      "        0.2980, 1.4430, 1.3550, 0.8214, 0.3685, 1.3958, 0.9410, 1.3639, 1.4102,\n",
      "        1.4562, 1.3133, 1.4060, 0.4187], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 405 was 40.1%\n",
      "current params: tensor([1.6272, 0.9657, 0.6627, 0.3629, 0.3676, 1.4186, 1.4309, 1.4075, 1.2503,\n",
      "        0.2957, 1.4443, 1.3558, 0.8225, 0.3693, 1.3969, 0.9409, 1.3647, 1.4112,\n",
      "        1.4581, 1.3151, 1.4070, 0.4166], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 406 was 40.1%\n",
      "current params: tensor([1.6287, 0.9676, 0.6627, 0.3604, 0.3656, 1.4195, 1.4320, 1.4085, 1.2522,\n",
      "        0.2934, 1.4456, 1.3566, 0.8236, 0.3700, 1.3980, 0.9407, 1.3654, 1.4122,\n",
      "        1.4599, 1.3169, 1.4080, 0.4144], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 407 was 40.2%\n",
      "current params: tensor([1.6302, 0.9694, 0.6626, 0.3579, 0.3636, 1.4205, 1.4330, 1.4095, 1.2541,\n",
      "        0.2912, 1.4469, 1.3574, 0.8247, 0.3704, 1.3990, 0.9406, 1.3661, 1.4131,\n",
      "        1.4617, 1.3187, 1.4091, 0.4123], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 408 was 40.3%\n",
      "current params: tensor([1.6317, 0.9712, 0.6627, 0.3554, 0.3615, 1.4214, 1.4341, 1.4106, 1.2560,\n",
      "        0.2889, 1.4482, 1.3583, 0.8258, 0.3706, 1.4001, 0.9405, 1.3669, 1.4141,\n",
      "        1.4635, 1.3205, 1.4101, 0.4101], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 409 was 40.4%\n",
      "current params: tensor([1.6332, 0.9731, 0.6627, 0.3528, 0.3615, 1.4224, 1.4352, 1.4116, 1.2579,\n",
      "        0.2867, 1.4494, 1.3591, 0.8269, 0.3708, 1.4012, 0.9404, 1.3676, 1.4151,\n",
      "        1.4654, 1.3223, 1.4111, 0.4080], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 410 was 40.5%\n",
      "current params: tensor([1.6347, 0.9749, 0.6627, 0.3503, 0.3625, 1.4233, 1.4363, 1.4126, 1.2597,\n",
      "        0.2844, 1.4507, 1.3599, 0.8280, 0.3707, 1.4023, 0.9402, 1.3683, 1.4161,\n",
      "        1.4672, 1.3241, 1.4121, 0.4058], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 411 was 40.5%\n",
      "current params: tensor([1.6362, 0.9768, 0.6627, 0.3478, 0.3642, 1.4242, 1.4374, 1.4137, 1.2616,\n",
      "        0.2821, 1.4520, 1.3607, 0.8292, 0.3706, 1.4034, 0.9401, 1.3690, 1.4171,\n",
      "        1.4689, 1.3259, 1.4132, 0.4037], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 412 was 40.6%\n",
      "current params: tensor([1.6376, 0.9787, 0.6627, 0.3452, 0.3656, 1.4252, 1.4384, 1.4147, 1.2635,\n",
      "        0.2799, 1.4533, 1.3616, 0.8303, 0.3704, 1.4045, 0.9400, 1.3698, 1.4180,\n",
      "        1.4707, 1.3277, 1.4142, 0.4015], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 413 was 40.7%\n",
      "current params: tensor([1.6391, 0.9805, 0.6628, 0.3426, 0.3668, 1.4261, 1.4395, 1.4157, 1.2653,\n",
      "        0.2776, 1.4545, 1.3624, 0.8315, 0.3700, 1.4055, 0.9399, 1.3705, 1.4190,\n",
      "        1.4725, 1.3295, 1.4152, 0.3993], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 414 was 40.8%\n",
      "current params: tensor([1.6406, 0.9824, 0.6628, 0.3401, 0.3677, 1.4270, 1.4406, 1.4167, 1.2672,\n",
      "        0.2753, 1.4558, 1.3632, 0.8327, 0.3696, 1.4066, 0.9397, 1.3712, 1.4200,\n",
      "        1.4742, 1.3313, 1.4163, 0.3972], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 415 was 40.8%\n",
      "current params: tensor([1.6421, 0.9842, 0.6629, 0.3375, 0.3684, 1.4279, 1.4417, 1.4177, 1.2690,\n",
      "        0.2730, 1.4571, 1.3641, 0.8338, 0.3691, 1.4077, 0.9396, 1.3719, 1.4209,\n",
      "        1.4760, 1.3331, 1.4173, 0.3950], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 416 was 40.9%\n",
      "current params: tensor([1.6436, 0.9861, 0.6629, 0.3349, 0.3690, 1.4288, 1.4428, 1.4188, 1.2709,\n",
      "        0.2707, 1.4584, 1.3649, 0.8350, 0.3686, 1.4088, 0.9395, 1.3727, 1.4219,\n",
      "        1.4777, 1.3349, 1.4183, 0.3928], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 417 was 41.0%\n",
      "current params: tensor([1.6451, 0.9879, 0.6630, 0.3324, 0.3694, 1.4297, 1.4439, 1.4198, 1.2727,\n",
      "        0.2684, 1.4597, 1.3658, 0.8362, 0.3679, 1.4099, 0.9394, 1.3734, 1.4228,\n",
      "        1.4794, 1.3366, 1.4193, 0.3907], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 418 was 41.1%\n",
      "current params: tensor([1.6465, 0.9898, 0.6631, 0.3298, 0.3696, 1.4306, 1.4450, 1.4208, 1.2746,\n",
      "        0.2661, 1.4609, 1.3666, 0.8374, 0.3672, 1.4110, 0.9392, 1.3741, 1.4238,\n",
      "        1.4811, 1.3384, 1.4204, 0.3885], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 419 was 41.2%\n",
      "current params: tensor([1.6480, 0.9917, 0.6632, 0.3272, 0.3697, 1.4315, 1.4461, 1.4218, 1.2764,\n",
      "        0.2638, 1.4622, 1.3675, 0.8386, 0.3665, 1.4121, 0.9391, 1.3749, 1.4247,\n",
      "        1.4828, 1.3402, 1.4214, 0.3863], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 420 was 41.2%\n",
      "current params: tensor([1.6495, 0.9935, 0.6632, 0.3246, 0.3697, 1.4324, 1.4472, 1.4228, 1.2782,\n",
      "        0.2615, 1.4635, 1.3683, 0.8398, 0.3657, 1.4132, 0.9390, 1.3756, 1.4257,\n",
      "        1.4845, 1.3419, 1.4224, 0.3842], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 421 was 41.3%\n",
      "current params: tensor([1.6510, 0.9954, 0.6633, 0.3220, 0.3696, 1.4333, 1.4483, 1.4238, 1.2801,\n",
      "        0.2592, 1.4648, 1.3692, 0.8410, 0.3649, 1.4143, 0.9388, 1.3763, 1.4266,\n",
      "        1.4862, 1.3437, 1.4234, 0.3820], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 422 was 41.4%\n",
      "current params: tensor([1.6524, 0.9972, 0.6634, 0.3195, 0.3694, 1.4342, 1.4494, 1.4248, 1.2819,\n",
      "        0.2569, 1.4661, 1.3700, 0.8422, 0.3640, 1.4153, 0.9387, 1.3771, 1.4276,\n",
      "        1.4878, 1.3455, 1.4245, 0.3798], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 423 was 41.5%\n",
      "current params: tensor([1.6539, 0.9991, 0.6635, 0.3169, 0.3690, 1.4350, 1.4505, 1.4258, 1.2837,\n",
      "        0.2546, 1.4674, 1.3709, 0.8434, 0.3631, 1.4164, 0.9386, 1.3778, 1.4285,\n",
      "        1.4894, 1.3472, 1.4255, 0.3776], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 424 was 41.6%\n",
      "current params: tensor([1.6554, 1.0009, 0.6636, 0.3143, 0.3686, 1.4359, 1.4516, 1.4267, 1.2855,\n",
      "        0.2522, 1.4686, 1.3717, 0.8447, 0.3622, 1.4175, 0.9384, 1.3786, 1.4294,\n",
      "        1.4911, 1.3490, 1.4265, 0.3754], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 425 was 41.7%\n",
      "current params: tensor([1.6568, 1.0028, 0.6637, 0.3117, 0.3682, 1.4368, 1.4527, 1.4277, 1.2873,\n",
      "        0.2499, 1.4699, 1.3726, 0.8459, 0.3621, 1.4186, 0.9392, 1.3793, 1.4304,\n",
      "        1.4927, 1.3507, 1.4276, 0.3732], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 426 was 41.8%\n",
      "current params: tensor([1.6583, 1.0047, 0.6638, 0.3091, 0.3676, 1.4376, 1.4538, 1.4287, 1.2892,\n",
      "        0.2476, 1.4712, 1.3734, 0.8471, 0.3627, 1.4197, 0.9398, 1.3801, 1.4313,\n",
      "        1.4943, 1.3525, 1.4286, 0.3711], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 427 was 41.8%\n",
      "current params: tensor([1.6597, 1.0065, 0.6640, 0.3065, 0.3671, 1.4384, 1.4550, 1.4297, 1.2910,\n",
      "        0.2452, 1.4725, 1.3743, 0.8484, 0.3638, 1.4208, 0.9404, 1.3808, 1.4322,\n",
      "        1.4958, 1.3542, 1.4296, 0.3689], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 428 was 41.9%\n",
      "current params: tensor([1.6612, 1.0084, 0.6641, 0.3039, 0.3664, 1.4393, 1.4561, 1.4307, 1.2928,\n",
      "        0.2429, 1.4738, 1.3752, 0.8496, 0.3648, 1.4219, 0.9409, 1.3816, 1.4331,\n",
      "        1.4974, 1.3560, 1.4306, 0.3667], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 429 was 42.0%\n",
      "current params: tensor([1.6627, 1.0102, 0.6642, 0.3013, 0.3657, 1.4401, 1.4572, 1.4316, 1.2946,\n",
      "        0.2405, 1.4751, 1.3761, 0.8509, 0.3655, 1.4230, 0.9413, 1.3824, 1.4340,\n",
      "        1.4990, 1.3577, 1.4317, 0.3645], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 430 was 42.1%\n",
      "current params: tensor([1.6641, 1.0121, 0.6644, 0.2987, 0.3650, 1.4409, 1.4583, 1.4326, 1.2963,\n",
      "        0.2381, 1.4764, 1.3769, 0.8521, 0.3660, 1.4241, 0.9417, 1.3831, 1.4350,\n",
      "        1.5005, 1.3595, 1.4327, 0.3623], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 431 was 42.2%\n",
      "current params: tensor([1.6656, 1.0139, 0.6645, 0.2961, 0.3642, 1.4417, 1.4594, 1.4335, 1.2981,\n",
      "        0.2358, 1.4776, 1.3778, 0.8534, 0.3664, 1.4252, 0.9420, 1.3839, 1.4359,\n",
      "        1.5020, 1.3612, 1.4337, 0.3601], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 432 was 42.3%\n",
      "current params: tensor([1.6670, 1.0158, 0.6646, 0.2935, 0.3634, 1.4425, 1.4606, 1.4345, 1.2999,\n",
      "        0.2334, 1.4789, 1.3787, 0.8546, 0.3667, 1.4263, 0.9423, 1.3846, 1.4368,\n",
      "        1.5035, 1.3629, 1.4348, 0.3579], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 433 was 42.4%\n",
      "current params: tensor([1.6685, 1.0176, 0.6648, 0.2909, 0.3626, 1.4433, 1.4617, 1.4354, 1.3017,\n",
      "        0.2311, 1.4802, 1.3796, 0.8559, 0.3668, 1.4274, 0.9425, 1.3854, 1.4377,\n",
      "        1.5050, 1.3646, 1.4358, 0.3557], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 434 was 42.5%\n",
      "current params: tensor([1.6699, 1.0195, 0.6649, 0.2883, 0.3627, 1.4441, 1.4628, 1.4364, 1.3035,\n",
      "        0.2287, 1.4815, 1.3805, 0.8572, 0.3668, 1.4285, 0.9427, 1.3862, 1.4385,\n",
      "        1.5065, 1.3664, 1.4368, 0.3535], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 435 was 42.6%\n",
      "current params: tensor([1.6713, 1.0213, 0.6651, 0.2857, 0.3636, 1.4449, 1.4640, 1.4373, 1.3052,\n",
      "        0.2263, 1.4828, 1.3813, 0.8584, 0.3668, 1.4296, 0.9429, 1.3869, 1.4394,\n",
      "        1.5079, 1.3681, 1.4379, 0.3513], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 436 was 42.7%\n",
      "current params: tensor([1.6728, 1.0232, 0.6653, 0.2831, 0.3642, 1.4457, 1.4651, 1.4383, 1.3070,\n",
      "        0.2239, 1.4841, 1.3822, 0.8597, 0.3666, 1.4307, 0.9430, 1.3877, 1.4403,\n",
      "        1.5094, 1.3698, 1.4389, 0.3491], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 437 was 42.7%\n",
      "current params: tensor([1.6742, 1.0250, 0.6654, 0.2804, 0.3648, 1.4464, 1.4663, 1.4392, 1.3088,\n",
      "        0.2215, 1.4854, 1.3831, 0.8610, 0.3664, 1.4318, 0.9432, 1.3885, 1.4412,\n",
      "        1.5108, 1.3715, 1.4399, 0.3469], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 438 was 42.8%\n",
      "current params: tensor([1.6756, 1.0268, 0.6656, 0.2778, 0.3651, 1.4472, 1.4674, 1.4401, 1.3105,\n",
      "        0.2191, 1.4866, 1.3840, 0.8623, 0.3660, 1.4329, 0.9433, 1.3893, 1.4421,\n",
      "        1.5122, 1.3732, 1.4410, 0.3447], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 439 was 42.9%\n",
      "current params: tensor([1.6771, 1.0287, 0.6658, 0.2752, 0.3654, 1.4479, 1.4686, 1.4410, 1.3123,\n",
      "        0.2167, 1.4879, 1.3849, 0.8636, 0.3657, 1.4340, 0.9433, 1.3900, 1.4429,\n",
      "        1.5136, 1.3749, 1.4420, 0.3425], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 440 was 43.0%\n",
      "current params: tensor([1.6785, 1.0305, 0.6660, 0.2725, 0.3655, 1.4487, 1.4697, 1.4419, 1.3140,\n",
      "        0.2143, 1.4892, 1.3858, 0.8649, 0.3652, 1.4351, 0.9434, 1.3908, 1.4438,\n",
      "        1.5150, 1.3766, 1.4430, 0.3403], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 441 was 43.1%\n",
      "current params: tensor([1.6799, 1.0323, 0.6661, 0.2699, 0.3655, 1.4494, 1.4709, 1.4428, 1.3158,\n",
      "        0.2119, 1.4905, 1.3867, 0.8662, 0.3647, 1.4362, 0.9434, 1.3916, 1.4447,\n",
      "        1.5163, 1.3783, 1.4441, 0.3381], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 442 was 43.2%\n",
      "current params: tensor([1.6813, 1.0342, 0.6663, 0.2673, 0.3654, 1.4501, 1.4720, 1.4437, 1.3175,\n",
      "        0.2095, 1.4918, 1.3877, 0.8675, 0.3642, 1.4373, 0.9434, 1.3924, 1.4455,\n",
      "        1.5177, 1.3800, 1.4451, 0.3359], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 443 was 43.3%\n",
      "current params: tensor([1.6828, 1.0360, 0.6665, 0.2646, 0.3653, 1.4508, 1.4732, 1.4446, 1.3192,\n",
      "        0.2071, 1.4931, 1.3886, 0.8688, 0.3636, 1.4384, 0.9434, 1.3932, 1.4464,\n",
      "        1.5190, 1.3817, 1.4461, 0.3337], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 444 was 43.4%\n",
      "current params: tensor([1.6842, 1.0378, 0.6667, 0.2620, 0.3650, 1.4515, 1.4743, 1.4455, 1.3209,\n",
      "        0.2047, 1.4944, 1.3895, 0.8701, 0.3630, 1.4395, 0.9434, 1.3939, 1.4472,\n",
      "        1.5203, 1.3834, 1.4472, 0.3314], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 445 was 43.5%\n",
      "current params: tensor([1.6856, 1.0396, 0.6669, 0.2593, 0.3647, 1.4522, 1.4755, 1.4464, 1.3227,\n",
      "        0.2023, 1.4956, 1.3904, 0.8714, 0.3631, 1.4406, 0.9434, 1.3947, 1.4481,\n",
      "        1.5216, 1.3851, 1.4482, 0.3292], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 446 was 43.6%\n",
      "current params: tensor([1.6870, 1.0414, 0.6671, 0.2567, 0.3643, 1.4529, 1.4767, 1.4473, 1.3244,\n",
      "        0.1998, 1.4969, 1.3913, 0.8727, 0.3630, 1.4417, 0.9434, 1.3955, 1.4489,\n",
      "        1.5229, 1.3868, 1.4492, 0.3270], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 447 was 43.7%\n",
      "current params: tensor([1.6884, 1.0432, 0.6673, 0.2540, 0.3639, 1.4536, 1.4779, 1.4482, 1.3261,\n",
      "        0.1974, 1.4982, 1.3923, 0.8740, 0.3629, 1.4428, 0.9433, 1.3963, 1.4497,\n",
      "        1.5241, 1.3884, 1.4503, 0.3248], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 448 was 43.8%\n",
      "current params: tensor([1.6898, 1.0451, 0.6675, 0.2514, 0.3634, 1.4543, 1.4790, 1.4490, 1.3278,\n",
      "        0.1950, 1.4995, 1.3932, 0.8753, 0.3633, 1.4439, 0.9433, 1.3971, 1.4506,\n",
      "        1.5253, 1.3901, 1.4513, 0.3226], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 449 was 43.9%\n",
      "current params: tensor([1.6912, 1.0469, 0.6677, 0.2487, 0.3629, 1.4549, 1.4802, 1.4499, 1.3295,\n",
      "        0.1925, 1.5008, 1.3941, 0.8766, 0.3637, 1.4450, 0.9432, 1.3979, 1.4514,\n",
      "        1.5265, 1.3918, 1.4523, 0.3204], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 450 was 44.0%\n",
      "current params: tensor([1.6926, 1.0487, 0.6679, 0.2460, 0.3631, 1.4556, 1.4814, 1.4507, 1.3312,\n",
      "        0.1901, 1.5021, 1.3951, 0.8779, 0.3639, 1.4461, 0.9431, 1.3987, 1.4522,\n",
      "        1.5277, 1.3934, 1.4534, 0.3181], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 451 was 44.1%\n",
      "current params: tensor([1.6940, 1.0505, 0.6681, 0.2434, 0.3633, 1.4562, 1.4826, 1.4516, 1.3329,\n",
      "        0.1876, 1.5033, 1.3960, 0.8792, 0.3640, 1.4472, 0.9431, 1.3995, 1.4530,\n",
      "        1.5289, 1.3951, 1.4544, 0.3159], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 452 was 44.3%\n",
      "current params: tensor([1.6953, 1.0522, 0.6684, 0.2407, 0.3633, 1.4568, 1.4838, 1.4524, 1.3346,\n",
      "        0.1852, 1.5046, 1.3969, 0.8805, 0.3640, 1.4483, 0.9430, 1.4003, 1.4538,\n",
      "        1.5301, 1.3967, 1.4554, 0.3137], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 453 was 44.4%\n",
      "current params: tensor([1.6967, 1.0540, 0.6686, 0.2381, 0.3632, 1.4574, 1.4850, 1.4532, 1.3363,\n",
      "        0.1827, 1.5059, 1.3979, 0.8818, 0.3639, 1.4495, 0.9429, 1.4011, 1.4546,\n",
      "        1.5312, 1.3984, 1.4565, 0.3114], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 454 was 44.5%\n",
      "current params: tensor([1.6981, 1.0558, 0.6688, 0.2354, 0.3631, 1.4580, 1.4861, 1.4540, 1.3379,\n",
      "        0.1803, 1.5072, 1.3988, 0.8831, 0.3637, 1.4506, 0.9428, 1.4019, 1.4554,\n",
      "        1.5323, 1.4000, 1.4575, 0.3092], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 455 was 44.6%\n",
      "current params: tensor([1.6995, 1.0576, 0.6690, 0.2327, 0.3629, 1.4586, 1.4873, 1.4549, 1.3396,\n",
      "        0.1778, 1.5085, 1.3998, 0.8844, 0.3635, 1.4517, 0.9427, 1.4027, 1.4562,\n",
      "        1.5334, 1.4017, 1.4585, 0.3070], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 456 was 44.7%\n",
      "current params: tensor([1.7008, 1.0594, 0.6692, 0.2300, 0.3634, 1.4592, 1.4885, 1.4557, 1.3413,\n",
      "        0.1753, 1.5098, 1.4007, 0.8857, 0.3632, 1.4528, 0.9426, 1.4035, 1.4570,\n",
      "        1.5345, 1.4033, 1.4596, 0.3047], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 457 was 44.8%\n",
      "current params: tensor([1.7022, 1.0611, 0.6695, 0.2273, 0.3637, 1.4598, 1.4898, 1.4565, 1.3429,\n",
      "        0.1729, 1.5110, 1.4017, 0.8870, 0.3629, 1.4539, 0.9425, 1.4044, 1.4578,\n",
      "        1.5355, 1.4049, 1.4606, 0.3025], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 458 was 44.9%\n",
      "current params: tensor([1.7036, 1.0629, 0.6697, 0.2247, 0.3639, 1.4604, 1.4910, 1.4572, 1.3446,\n",
      "        0.1704, 1.5123, 1.4027, 0.8883, 0.3631, 1.4550, 0.9424, 1.4052, 1.4586,\n",
      "        1.5365, 1.4065, 1.4617, 0.3003], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 459 was 45.0%\n",
      "current params: tensor([1.7049, 1.0647, 0.6699, 0.2220, 0.3640, 1.4609, 1.4922, 1.4580, 1.3462,\n",
      "        0.1679, 1.5136, 1.4036, 0.8896, 0.3633, 1.4561, 0.9423, 1.4060, 1.4593,\n",
      "        1.5375, 1.4082, 1.4627, 0.2980], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 460 was 45.1%\n",
      "current params: tensor([1.7063, 1.0664, 0.6702, 0.2193, 0.3641, 1.4614, 1.4934, 1.4588, 1.3478,\n",
      "        0.1654, 1.5149, 1.4046, 0.8909, 0.3633, 1.4572, 0.9422, 1.4068, 1.4601,\n",
      "        1.5385, 1.4098, 1.4637, 0.2958], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 461 was 45.2%\n",
      "current params: tensor([1.7076, 1.0682, 0.6704, 0.2166, 0.3640, 1.4620, 1.4946, 1.4596, 1.3495,\n",
      "        0.1629, 1.5162, 1.4056, 0.8922, 0.3633, 1.4583, 0.9420, 1.4076, 1.4609,\n",
      "        1.5395, 1.4114, 1.4648, 0.2936], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 462 was 45.4%\n",
      "current params: tensor([1.7089, 1.0699, 0.6706, 0.2139, 0.3639, 1.4625, 1.4958, 1.4603, 1.3511,\n",
      "        0.1604, 1.5174, 1.4065, 0.8935, 0.3632, 1.4595, 0.9419, 1.4084, 1.4616,\n",
      "        1.5404, 1.4130, 1.4658, 0.2913], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 463 was 45.5%\n",
      "current params: tensor([1.7103, 1.0717, 0.6708, 0.2112, 0.3636, 1.4630, 1.4971, 1.4611, 1.3527,\n",
      "        0.1579, 1.5187, 1.4075, 0.8947, 0.3630, 1.4606, 0.9418, 1.4093, 1.4624,\n",
      "        1.5413, 1.4146, 1.4669, 0.2891], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 464 was 45.6%\n",
      "current params: tensor([1.7116, 1.0734, 0.6711, 0.2085, 0.3634, 1.4635, 1.4983, 1.4618, 1.3543,\n",
      "        0.1554, 1.5200, 1.4085, 0.8960, 0.3633, 1.4617, 0.9417, 1.4101, 1.4631,\n",
      "        1.5422, 1.4162, 1.4679, 0.2868], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 465 was 45.7%\n",
      "current params: tensor([1.7129, 1.0751, 0.6713, 0.2058, 0.3630, 1.4640, 1.4995, 1.4625, 1.3560,\n",
      "        0.1529, 1.5213, 1.4095, 0.8973, 0.3636, 1.4628, 0.9415, 1.4109, 1.4638,\n",
      "        1.5431, 1.4178, 1.4689, 0.2846], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 466 was 45.8%\n",
      "current params: tensor([1.7142, 1.0769, 0.6715, 0.2031, 0.3627, 1.4644, 1.5008, 1.4632, 1.3576,\n",
      "        0.1504, 1.5225, 1.4105, 0.8986, 0.3637, 1.4639, 0.9414, 1.4117, 1.4646,\n",
      "        1.5439, 1.4194, 1.4700, 0.2823], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 467 was 45.9%\n",
      "current params: tensor([1.7155, 1.0786, 0.6718, 0.2004, 0.3630, 1.4649, 1.5020, 1.4639, 1.3592,\n",
      "        0.1479, 1.5238, 1.4115, 0.8999, 0.3638, 1.4650, 0.9413, 1.4126, 1.4653,\n",
      "        1.5447, 1.4209, 1.4710, 0.2801], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 468 was 46.1%\n",
      "current params: tensor([1.7169, 1.0803, 0.6720, 0.1977, 0.3638, 1.4653, 1.5033, 1.4646, 1.3607,\n",
      "        0.1454, 1.5251, 1.4125, 0.9011, 0.3638, 1.4662, 0.9412, 1.4134, 1.4660,\n",
      "        1.5455, 1.4225, 1.4721, 0.2778], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 469 was 46.2%\n",
      "current params: tensor([1.7182, 1.0820, 0.6723, 0.1950, 0.3645, 1.4657, 1.5045, 1.4653, 1.3623,\n",
      "        0.1429, 1.5264, 1.4135, 0.9024, 0.3637, 1.4673, 0.9410, 1.4142, 1.4667,\n",
      "        1.5462, 1.4241, 1.4731, 0.2756], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 470 was 46.3%\n",
      "current params: tensor([1.7194, 1.0837, 0.6725, 0.1922, 0.3651, 1.4661, 1.5058, 1.4660, 1.3639,\n",
      "        0.1403, 1.5276, 1.4145, 0.9037, 0.3635, 1.4684, 0.9409, 1.4151, 1.4674,\n",
      "        1.5470, 1.4257, 1.4742, 0.2733], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 471 was 46.4%\n",
      "current params: tensor([1.7207, 1.0854, 0.6727, 0.1895, 0.3655, 1.4665, 1.5070, 1.4666, 1.3655,\n",
      "        0.1378, 1.5289, 1.4155, 0.9049, 0.3633, 1.4695, 0.9408, 1.4159, 1.4681,\n",
      "        1.5477, 1.4272, 1.4752, 0.2710], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 472 was 46.5%\n",
      "current params: tensor([1.7220, 1.0871, 0.6729, 0.1868, 0.3658, 1.4669, 1.5083, 1.4673, 1.3670,\n",
      "        0.1353, 1.5302, 1.4165, 0.9062, 0.3631, 1.4706, 0.9406, 1.4167, 1.4688,\n",
      "        1.5483, 1.4288, 1.4763, 0.2688], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 473 was 46.7%\n",
      "current params: tensor([1.7233, 1.0887, 0.6732, 0.1841, 0.3660, 1.4673, 1.5095, 1.4679, 1.3686,\n",
      "        0.1327, 1.5314, 1.4175, 0.9074, 0.3627, 1.4718, 0.9405, 1.4176, 1.4695,\n",
      "        1.5490, 1.4303, 1.4773, 0.2665], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 474 was 46.8%\n",
      "current params: tensor([1.7246, 1.0904, 0.6734, 0.1813, 0.3661, 1.4676, 1.5108, 1.4686, 1.3701,\n",
      "        0.1302, 1.5327, 1.4185, 0.9087, 0.3630, 1.4729, 0.9403, 1.4184, 1.4702,\n",
      "        1.5496, 1.4319, 1.4783, 0.2643], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 475 was 46.9%\n",
      "current params: tensor([1.7258, 1.0921, 0.6736, 0.1786, 0.3661, 1.4680, 1.5121, 1.4692, 1.3717,\n",
      "        0.1276, 1.5340, 1.4196, 0.9099, 0.3637, 1.4740, 0.9402, 1.4193, 1.4708,\n",
      "        1.5502, 1.4334, 1.4794, 0.2620], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 476 was 47.1%\n",
      "current params: tensor([1.7271, 1.0937, 0.6739, 0.1759, 0.3660, 1.4683, 1.5134, 1.4698, 1.3732,\n",
      "        0.1251, 1.5352, 1.4206, 0.9111, 0.3643, 1.4751, 0.9401, 1.4201, 1.4715,\n",
      "        1.5507, 1.4349, 1.4804, 0.2597], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 477 was 47.2%\n",
      "current params: tensor([1.7283, 1.0954, 0.6741, 0.1731, 0.3659, 1.4686, 1.5146, 1.4704, 1.3747,\n",
      "        0.1225, 1.5365, 1.4216, 0.9123, 0.3647, 1.4762, 0.9399, 1.4210, 1.4721,\n",
      "        1.5512, 1.4364, 1.4815, 0.2575], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 478 was 47.3%\n",
      "current params: tensor([1.7296, 1.0970, 0.6743, 0.1704, 0.3657, 1.4689, 1.5159, 1.4710, 1.3763,\n",
      "        0.1200, 1.5377, 1.4226, 0.9136, 0.3650, 1.4774, 0.9398, 1.4218, 1.4728,\n",
      "        1.5517, 1.4380, 1.4825, 0.2552], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 479 was 47.4%\n",
      "current params: tensor([1.7308, 1.0987, 0.6745, 0.1677, 0.3654, 1.4692, 1.5172, 1.4715, 1.3778,\n",
      "        0.1174, 1.5390, 1.4237, 0.9148, 0.3653, 1.4785, 0.9396, 1.4227, 1.4734,\n",
      "        1.5522, 1.4395, 1.4836, 0.2529], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 480 was 47.6%\n",
      "current params: tensor([1.7320, 1.1003, 0.6747, 0.1649, 0.3651, 1.4694, 1.5185, 1.4721, 1.3793,\n",
      "        0.1148, 1.5403, 1.4247, 0.9160, 0.3654, 1.4796, 0.9395, 1.4235, 1.4741,\n",
      "        1.5526, 1.4410, 1.4846, 0.2507], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 481 was 47.7%\n",
      "current params: tensor([1.7332, 1.1019, 0.6750, 0.1622, 0.3648, 1.4697, 1.5198, 1.4726, 1.3808,\n",
      "        0.1123, 1.5415, 1.4258, 0.9172, 0.3655, 1.4807, 0.9393, 1.4244, 1.4747,\n",
      "        1.5530, 1.4425, 1.4857, 0.2484], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 482 was 47.8%\n",
      "current params: tensor([1.7344, 1.1035, 0.6752, 0.1594, 0.3644, 1.4699, 1.5211, 1.4732, 1.3823,\n",
      "        0.1097, 1.5428, 1.4268, 0.9184, 0.3655, 1.4819, 0.9392, 1.4252, 1.4753,\n",
      "        1.5534, 1.4440, 1.4867, 0.2461], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 483 was 48.0%\n",
      "current params: tensor([1.7356, 1.1051, 0.6754, 0.1567, 0.3640, 1.4701, 1.5224, 1.4737, 1.3838,\n",
      "        0.1071, 1.5440, 1.4279, 0.9195, 0.3654, 1.4830, 0.9390, 1.4261, 1.4759,\n",
      "        1.5537, 1.4455, 1.4878, 0.2438], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 484 was 48.1%\n",
      "current params: tensor([1.7368, 1.1067, 0.6756, 0.1539, 0.3635, 1.4703, 1.5238, 1.4742, 1.3852,\n",
      "        0.1045, 1.5453, 1.4289, 0.9207, 0.3653, 1.4841, 0.9389, 1.4270, 1.4765,\n",
      "        1.5540, 1.4469, 1.4888, 0.2416], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 485 was 48.3%\n",
      "current params: tensor([1.7380, 1.1083, 0.6758, 0.1511, 0.3630, 1.4705, 1.5251, 1.4747, 1.3867,\n",
      "        0.1019, 1.5465, 1.4300, 0.9219, 0.3651, 1.4852, 0.9387, 1.4278, 1.4771,\n",
      "        1.5543, 1.4484, 1.4899, 0.2393], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 486 was 48.4%\n",
      "current params: tensor([1.7392, 1.1099, 0.6760, 0.1484, 0.3625, 1.4706, 1.5264, 1.4751, 1.3882,\n",
      "        0.0993, 1.5478, 1.4311, 0.9230, 0.3649, 1.4864, 0.9386, 1.4287, 1.4777,\n",
      "        1.5545, 1.4499, 1.4909, 0.2370], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 487 was 48.5%\n",
      "current params: tensor([1.7404, 1.1115, 0.6762, 0.1456, 0.3626, 1.4707, 1.5277, 1.4756, 1.3896,\n",
      "        0.0967, 1.5490, 1.4321, 0.9242, 0.3646, 1.4875, 0.9384, 1.4295, 1.4783,\n",
      "        1.5547, 1.4513, 1.4920, 0.2347], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 488 was 48.7%\n",
      "current params: tensor([1.7415, 1.1130, 0.6764, 0.1428, 0.3633, 1.4709, 1.5291, 1.4760, 1.3910,\n",
      "        0.0941, 1.5502, 1.4332, 0.9253, 0.3643, 1.4886, 0.9391, 1.4304, 1.4788,\n",
      "        1.5548, 1.4528, 1.4930, 0.2324], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 489 was 48.8%\n",
      "current params: tensor([1.7427, 1.1146, 0.6766, 0.1400, 0.3638, 1.4710, 1.5304, 1.4765, 1.3925,\n",
      "        0.0915, 1.5515, 1.4343, 0.9264, 0.3639, 1.4897, 0.9397, 1.4312, 1.4794,\n",
      "        1.5549, 1.4542, 1.4941, 0.2301], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 490 was 49.0%\n",
      "current params: tensor([1.7438, 1.1161, 0.6768, 0.1372, 0.3642, 1.4710, 1.5317, 1.4769, 1.3939,\n",
      "        0.0889, 1.5527, 1.4354, 0.9276, 0.3636, 1.4909, 0.9403, 1.4321, 1.4800,\n",
      "        1.5550, 1.4557, 1.4952, 0.2278], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 491 was 49.1%\n",
      "current params: tensor([1.7450, 1.1177, 0.6770, 0.1345, 0.3645, 1.4711, 1.5331, 1.4773, 1.3953,\n",
      "        0.0863, 1.5540, 1.4364, 0.9287, 0.3632, 1.4920, 0.9407, 1.4329, 1.4805,\n",
      "        1.5550, 1.4571, 1.4962, 0.2256], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 492 was 49.3%\n",
      "current params: tensor([1.7461, 1.1192, 0.6772, 0.1317, 0.3647, 1.4711, 1.5344, 1.4776, 1.3967,\n",
      "        0.0837, 1.5552, 1.4375, 0.9298, 0.3628, 1.4931, 0.9412, 1.4338, 1.4810,\n",
      "        1.5550, 1.4585, 1.4973, 0.2233], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 493 was 49.4%\n",
      "current params: tensor([1.7472, 1.1207, 0.6773, 0.1289, 0.3648, 1.4712, 1.5358, 1.4780, 1.3981,\n",
      "        0.0811, 1.5564, 1.4386, 0.9308, 0.3629, 1.4943, 0.9415, 1.4347, 1.4816,\n",
      "        1.5550, 1.4599, 1.4983, 0.2210], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 494 was 49.6%\n",
      "current params: tensor([1.7483, 1.1222, 0.6775, 0.1261, 0.3649, 1.4712, 1.5371, 1.4783, 1.3995,\n",
      "        0.0785, 1.5576, 1.4397, 0.9319, 0.3635, 1.4954, 0.9418, 1.4355, 1.4821,\n",
      "        1.5549, 1.4613, 1.4994, 0.2187], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 495 was 49.7%\n",
      "current params: tensor([1.7494, 1.1237, 0.6777, 0.1233, 0.3648, 1.4711, 1.5385, 1.4787, 1.4009,\n",
      "        0.0758, 1.5589, 1.4408, 0.9330, 0.3640, 1.4965, 0.9421, 1.4364, 1.4826,\n",
      "        1.5548, 1.4627, 1.5004, 0.2164], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 496 was 49.9%\n",
      "current params: tensor([1.7505, 1.1252, 0.6778, 0.1205, 0.3647, 1.4711, 1.5399, 1.4790, 1.4023,\n",
      "        0.0732, 1.5601, 1.4419, 0.9340, 0.3644, 1.4977, 0.9423, 1.4372, 1.4831,\n",
      "        1.5546, 1.4641, 1.5015, 0.2141], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 497 was 50.0%\n",
      "current params: tensor([1.7515, 1.1266, 0.6780, 0.1177, 0.3645, 1.4710, 1.5413, 1.4793, 1.4036,\n",
      "        0.0706, 1.5613, 1.4430, 0.9351, 0.3646, 1.4988, 0.9425, 1.4381, 1.4836,\n",
      "        1.5544, 1.4655, 1.5026, 0.2118], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 498 was 50.2%\n",
      "current params: tensor([1.7526, 1.1281, 0.6781, 0.1149, 0.3643, 1.4709, 1.5426, 1.4795, 1.4050,\n",
      "        0.0679, 1.5625, 1.4441, 0.9361, 0.3648, 1.4999, 0.9426, 1.4390, 1.4840,\n",
      "        1.5541, 1.4669, 1.5036, 0.2095], dtype=torch.float64)\n",
      "Using CPU\n",
      "yield on sim iteration 499 was 50.3%\n",
      "optimization complete\n"
     ]
    },
    {
     "data": {
      "text/plain": "<steric_free_simulator.reaction_network.ReactionNetwork at 0x7f1b67fc9828>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.optimize()\n",
    "final_rn = copy.deepcopy(rn)\n",
    "optim.rn.update_reaction_net(final_rn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visulalize the reults. The Optimizer tracks observables across all simulation iterations,\n",
    "and thus we can use its `plot_observables` function to plot the results of a single simulation\n",
    "\n",
    "**Plot the first simulation, before any optimization:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(iteration=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot the final simulation, after all optimization iterations:**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(iteration=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the change in complex yield over time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clearly the optimizer was able to increase the total yield of the final complex at time 1 second.\n",
    "The explanation for this will be left to the results notebook.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}