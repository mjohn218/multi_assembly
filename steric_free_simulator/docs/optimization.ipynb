{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Optimizing the Vectorized Simulations #\n",
    "\n",
    "Besides speed, the benefit of using the vectorized simulation based on the torch framework\n",
    "is that we can track all operations that happen across a simulation. This allows us to find\n",
    "the gradients with respect to any intermediate variable, and more importantly the gradient\n",
    "of the yield the final copies of some complex with respect to initial parameters.\n",
    "\n",
    "## An Introduction to Automatic Differentiation ##\n",
    "\n",
    "Automatic differentiation is a powerful technique based on a simple principle of calculus,\n",
    "the multivariable chain rule. Imagine we have function $ y = f(x, w)$ and we want to minimize $y$ by adjusting parameter $w$ we can\n",
    "this by computing $\\frac {\\partial y} {\\partial w}$. Automatic differentiation allows us to do this\n",
    "for arbitrary function $f$ without needing to know $f$ in advance.\n",
    "\n",
    "Whenever variable $u$ is involved in any operation, we create a new internal variable $v$ representing the result of\n",
    "the operation, pointer back to $w$ and any other variables, and the function describing the partial $\\frac {\\partial v} {\\partial u}$.\n",
    "In this way we construct a directed acyclic \"compuation graph\", where $w$ and other input variable $x$ are leaves and the final optimization\n",
    "target $y$ is the root.\n",
    "\n",
    "We can now calculate the partial of $y$ with respect to each intermediate variable, and eventually $w$ by repeatedly\n",
    "applying the chain rule of differentiation, $\\frac {\\partial y} {\\partial u} = \\frac {\\partial y} {\\partial v}  \\frac {\\partial v} {\\partial u}$\n",
    "\n",
    "## Applying to Our Use Case##\n",
    "\n",
    "We can easily write the simulator described in the `vectorized_network_simulation.ipynb` notebook as a function. Let's Define:\n",
    "\n",
    "- Simulator: $S$\n",
    "- Vector of association constants: $\\vec{k_{on}}$\n",
    "- Vector of Reaction $\\Delta G$s: $\\vec{G}$\n",
    "- Vector of initial copy numbers: $\\vec{C_o}$\n",
    "- Matrix mapping species to reactions: $\\textbf{M}$\n",
    "- Simulation run time: $t$\n",
    "- Final copies of complete complex: $Y$\n",
    "- maximum possible yield: $min(\\vec{C_o})$\n",
    "\n",
    "The simulator itself can be expressed as:\n",
    "\n",
    "$Y = S(\\vec{k_{on}}, \\vec{G}, \\vec{C_o}, \\textbf{M}, t)$\n",
    "\n",
    "From the yield $Y$ we can construct the full loss term:\n",
    "\n",
    "$L = \\frac{-Y}{min(\\vec{C_o})} + ReLU(-1*(k - min\\_constant))$\n",
    "\n",
    "Here the first term is the percent of the theoretical maximum possible complete complex yield,\n",
    "and the second term is designed to prevent the on or off association constants from getting unreasonably small\n",
    "or negative. The ReLU function is a piecewise function that will be a linear positive penalty when $k < min\\_constant$,\n",
    "and will equal $0$ otherwise. Minimizing the full objective $L$ w.r.t. $k_{on}$ will find values for $k_{on}$ that\n",
    "maximize full complex yield while still being physically reasonable.\n",
    "\n",
    "Automatic differentiation as described in the above section provide a method for doing this. We can run the simulation\n",
    "until completion, all the while constructing the computation graph. We can then compute all the gradients, and then\n",
    "step the parameter values in the direction of the gradient.\n",
    "\n",
    "In other words, we compute $\\frac{\\partial L}{\\partial \\vec{k_{on}}}$ via automatic differentiation,\n",
    "and then do $k_{on} = k_{on} + \\lambda * \\frac{\\partial L}{\\partial \\vec{k_{on}}}$.\n",
    "\n",
    "We preform a simulation then update the parameters in the direction of the gradient a set number of times\n",
    "before stopping.\n",
    "\n",
    "## Optimization Example With AP2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first we need to import the required modules\n",
    "# make sure jupyter path is correct for loading local modules\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from steric_free_simulator import Optimizer\n",
    "from steric_free_simulator import ReactionNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we need to generate the reaction network from the input files (see `reaction_network_building.ipynb`).\n",
    "We can't directly resolve a vectorized network from an input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_input = '../input_files/ap2.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can feed the vanilla (networkx based) network into the optimizer and vectorized simulator, but it will be copied and\n",
    "converted to a vectorized network. Let's ensure the network is set to the proper initial conditions and then initialize the\n",
    "optimizer.\n",
    "\n",
    "**Optimization and Simulation Parameters**:\n",
    "\n",
    "- **sim_runtime**: time (in seconds) that the simulation will run for.\n",
    "- **optim_iterations**: number of simulations to run, optimizing parameters at each one.\n",
    "- **learning rate**: factor to multiply calculated gradients by.\n",
    "- **device**: The hardware device to run simulations and optimizations on.\n",
    "\n",
    "If the parameter is not specified at optimizer construction, it is given a default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "rn.reset()\n",
    "optim = Optimizer(reaction_network=rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=500,\n",
    "                  learning_rate=.001,\n",
    "                  device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can run the optimization. After optimization, we write the new \"optimized\" parameters\n",
    "into a copy of a reaction network so that we can inspect them if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "yield on sim iteration 0 was 8.72%\n",
      "current params: [tensor([1.0010, 0.9990, 0.9990, 0.9990, 1.0010, 1.0010, 1.0010, 0.9990, 0.9990,\n",
      "        0.9990, 1.0010, 1.0010, 1.0010, 1.0010, 1.0010, 0.9990, 1.0010, 1.0010,\n",
      "        1.0010, 0.9990, 1.0010, 1.0010], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 1 was 8.72%\n",
      "current params: [tensor([1.0020, 0.9980, 0.9980, 0.9980, 1.0020, 1.0020, 1.0020, 0.9980, 0.9980,\n",
      "        0.9980, 1.0020, 1.0020, 1.0020, 1.0020, 1.0020, 0.9980, 1.0020, 1.0020,\n",
      "        1.0020, 0.9980, 1.0020, 1.0020], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 2 was 8.72%\n",
      "current params: [tensor([1.0030, 0.9970, 0.9970, 0.9970, 1.0029, 1.0030, 1.0030, 0.9970, 0.9970,\n",
      "        0.9970, 1.0030, 1.0030, 1.0030, 1.0030, 1.0030, 0.9970, 1.0030, 1.0030,\n",
      "        1.0030, 0.9970, 1.0030, 1.0030], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 3 was 8.73%\n",
      "current params: [tensor([1.0040, 0.9960, 0.9960, 0.9960, 1.0039, 1.0040, 1.0040, 0.9960, 0.9960,\n",
      "        0.9960, 1.0040, 1.0040, 1.0040, 1.0040, 1.0040, 0.9960, 1.0040, 1.0040,\n",
      "        1.0040, 0.9960, 1.0040, 1.0040], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 4 was 8.73%\n",
      "current params: [tensor([1.0050, 0.9950, 0.9950, 0.9950, 1.0047, 1.0050, 1.0050, 0.9950, 0.9950,\n",
      "        0.9950, 1.0050, 1.0050, 1.0050, 1.0050, 1.0050, 0.9950, 1.0050, 1.0050,\n",
      "        1.0050, 0.9950, 1.0050, 1.0050], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 5 was 8.73%\n",
      "current params: [tensor([1.0060, 0.9940, 0.9940, 0.9940, 1.0054, 1.0060, 1.0060, 0.9940, 0.9940,\n",
      "        0.9940, 1.0060, 1.0060, 1.0060, 1.0060, 1.0060, 0.9940, 1.0060, 1.0060,\n",
      "        1.0060, 0.9940, 1.0060, 1.0060], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 6 was 8.73%\n",
      "current params: [tensor([1.0070, 0.9930, 0.9930, 0.9930, 1.0060, 1.0070, 1.0070, 0.9930, 0.9930,\n",
      "        0.9930, 1.0070, 1.0070, 1.0070, 1.0070, 1.0070, 0.9930, 1.0070, 1.0070,\n",
      "        1.0070, 0.9930, 1.0070, 1.0070], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 7 was 8.74%\n",
      "current params: [tensor([1.0080, 0.9920, 0.9920, 0.9920, 1.0064, 1.0080, 1.0080, 0.9920, 0.9920,\n",
      "        0.9920, 1.0080, 1.0080, 1.0080, 1.0080, 1.0080, 0.9920, 1.0080, 1.0080,\n",
      "        1.0080, 0.9920, 1.0080, 1.0080], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 8 was 8.74%\n",
      "current params: [tensor([1.0090, 0.9910, 0.9910, 0.9910, 1.0065, 1.0090, 1.0090, 0.9911, 0.9910,\n",
      "        0.9910, 1.0090, 1.0090, 1.0091, 1.0090, 1.0090, 0.9910, 1.0090, 1.0090,\n",
      "        1.0090, 0.9910, 1.0090, 1.0090], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 9 was 8.74%\n",
      "current params: [tensor([1.0100, 0.9900, 0.9900, 0.9900, 1.0064, 1.0100, 1.0100, 0.9901, 0.9900,\n",
      "        0.9900, 1.0100, 1.0100, 1.0101, 1.0100, 1.0100, 0.9900, 1.0100, 1.0100,\n",
      "        1.0101, 0.9900, 1.0100, 1.0100], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 10 was 8.74%\n",
      "current params: [tensor([1.0110, 0.9890, 0.9890, 0.9890, 1.0060, 1.0110, 1.0110, 0.9891, 0.9890,\n",
      "        0.9890, 1.0110, 1.0110, 1.0111, 1.0110, 1.0110, 0.9890, 1.0110, 1.0110,\n",
      "        1.0111, 0.9890, 1.0110, 1.0110], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 11 was 8.74%\n",
      "current params: [tensor([1.0120, 0.9880, 0.9880, 0.9880, 1.0055, 1.0120, 1.0120, 0.9881, 0.9881,\n",
      "        0.9880, 1.0120, 1.0120, 1.0121, 1.0120, 1.0120, 0.9880, 1.0120, 1.0120,\n",
      "        1.0121, 0.9880, 1.0120, 1.0120], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 12 was 8.75%\n",
      "current params: [tensor([1.0130, 0.9870, 0.9870, 0.9870, 1.0048, 1.0130, 1.0130, 0.9872, 0.9871,\n",
      "        0.9871, 1.0130, 1.0130, 1.0132, 1.0130, 1.0130, 0.9870, 1.0130, 1.0130,\n",
      "        1.0131, 0.9870, 1.0130, 1.0130], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 13 was 8.75%\n",
      "current params: [tensor([1.0140, 0.9860, 0.9860, 0.9860, 1.0041, 1.0140, 1.0140, 0.9862, 0.9861,\n",
      "        0.9861, 1.0140, 1.0140, 1.0142, 1.0140, 1.0140, 0.9860, 1.0140, 1.0140,\n",
      "        1.0142, 0.9861, 1.0140, 1.0140], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 14 was 8.75%\n",
      "current params: [tensor([1.0150, 0.9850, 0.9850, 0.9851, 1.0032, 1.0150, 1.0150, 0.9852, 0.9851,\n",
      "        0.9851, 1.0150, 1.0150, 1.0152, 1.0150, 1.0150, 0.9850, 1.0150, 1.0150,\n",
      "        1.0152, 0.9851, 1.0150, 1.0150], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 15 was 8.75%\n",
      "current params: [tensor([1.0160, 0.9840, 0.9840, 0.9841, 1.0023, 1.0160, 1.0160, 0.9843, 0.9841,\n",
      "        0.9841, 1.0160, 1.0160, 1.0163, 1.0160, 1.0160, 0.9840, 1.0160, 1.0160,\n",
      "        1.0162, 0.9841, 1.0160, 1.0160], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 16 was 8.75%\n",
      "current params: [tensor([1.0170, 0.9831, 0.9830, 0.9831, 1.0014, 1.0170, 1.0170, 0.9834, 0.9831,\n",
      "        0.9831, 1.0170, 1.0170, 1.0173, 1.0170, 1.0170, 0.9830, 1.0170, 1.0169,\n",
      "        1.0173, 0.9831, 1.0170, 1.0170], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 17 was 8.76%\n",
      "current params: [tensor([1.0180, 0.9821, 0.9820, 0.9821, 1.0004, 1.0180, 1.0179, 0.9824, 0.9822,\n",
      "        0.9822, 1.0180, 1.0180, 1.0184, 1.0180, 1.0179, 0.9820, 1.0180, 1.0179,\n",
      "        1.0183, 0.9821, 1.0179, 1.0180], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 18 was 8.76%\n",
      "current params: [tensor([1.0190, 0.9811, 0.9810, 0.9811, 0.9993, 1.0190, 1.0189, 0.9815, 0.9812,\n",
      "        0.9812, 1.0190, 1.0190, 1.0194, 1.0190, 1.0189, 0.9810, 1.0190, 1.0189,\n",
      "        1.0194, 0.9811, 1.0189, 1.0190], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 19 was 8.76%\n",
      "current params: [tensor([1.0200, 0.9801, 0.9800, 0.9801, 0.9983, 1.0201, 1.0199, 0.9806, 0.9802,\n",
      "        0.9802, 1.0200, 1.0200, 1.0205, 1.0199, 1.0199, 0.9800, 1.0200, 1.0199,\n",
      "        1.0205, 0.9801, 1.0199, 1.0200], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 20 was 8.76%\n",
      "current params: [tensor([1.0210, 0.9791, 0.9791, 0.9791, 0.9972, 1.0211, 1.0209, 0.9797, 0.9793,\n",
      "        0.9793, 1.0210, 1.0210, 1.0216, 1.0209, 1.0209, 0.9790, 1.0209, 1.0209,\n",
      "        1.0215, 0.9792, 1.0209, 1.0210], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 21 was 8.77%\n",
      "current params: [tensor([1.0220, 0.9781, 0.9781, 0.9782, 0.9960, 1.0221, 1.0219, 0.9788, 0.9783,\n",
      "        0.9783, 1.0219, 1.0220, 1.0226, 1.0219, 1.0219, 0.9780, 1.0219, 1.0219,\n",
      "        1.0226, 0.9782, 1.0219, 1.0220], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 22 was 8.77%\n",
      "current params: [tensor([1.0230, 0.9771, 0.9771, 0.9772, 0.9949, 1.0231, 1.0229, 0.9779, 0.9774,\n",
      "        0.9773, 1.0229, 1.0230, 1.0237, 1.0229, 1.0229, 0.9770, 1.0229, 1.0229,\n",
      "        1.0237, 0.9772, 1.0229, 1.0229], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 23 was 8.77%\n",
      "current params: [tensor([1.0240, 0.9762, 0.9761, 0.9762, 0.9937, 1.0241, 1.0239, 0.9770, 0.9764,\n",
      "        0.9764, 1.0239, 1.0239, 1.0248, 1.0239, 1.0239, 0.9760, 1.0239, 1.0239,\n",
      "        1.0248, 0.9762, 1.0239, 1.0239], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 24 was 8.77%\n",
      "current params: [tensor([1.0250, 0.9752, 0.9751, 0.9752, 0.9925, 1.0251, 1.0249, 0.9761, 0.9755,\n",
      "        0.9754, 1.0249, 1.0249, 1.0258, 1.0249, 1.0249, 0.9750, 1.0249, 1.0249,\n",
      "        1.0258, 0.9752, 1.0249, 1.0249], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 25 was 8.77%\n",
      "current params: [tensor([1.0260, 0.9742, 0.9741, 0.9743, 0.9913, 1.0261, 1.0259, 0.9753, 0.9745,\n",
      "        0.9745, 1.0259, 1.0259, 1.0269, 1.0259, 1.0259, 0.9740, 1.0259, 1.0258,\n",
      "        1.0269, 0.9742, 1.0259, 1.0259], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 26 was 8.78%\n",
      "current params: [tensor([1.0271, 0.9732, 0.9731, 0.9733, 0.9901, 1.0271, 1.0268, 0.9744, 0.9736,\n",
      "        0.9736, 1.0269, 1.0269, 1.0280, 1.0269, 1.0268, 0.9730, 1.0269, 1.0268,\n",
      "        1.0280, 0.9733, 1.0268, 1.0269], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 27 was 8.78%\n",
      "current params: [tensor([1.0281, 0.9722, 0.9721, 0.9723, 0.9888, 1.0281, 1.0278, 0.9736, 0.9726,\n",
      "        0.9726, 1.0279, 1.0279, 1.0291, 1.0279, 1.0278, 0.9719, 1.0279, 1.0278,\n",
      "        1.0291, 0.9723, 1.0278, 1.0279], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 28 was 8.78%\n",
      "current params: [tensor([1.0291, 0.9713, 0.9711, 0.9713, 0.9876, 1.0291, 1.0288, 0.9727, 0.9717,\n",
      "        0.9717, 1.0289, 1.0289, 1.0301, 1.0288, 1.0288, 0.9709, 1.0288, 1.0288,\n",
      "        1.0302, 0.9713, 1.0288, 1.0289], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 29 was 8.78%\n",
      "current params: [tensor([1.0301, 0.9703, 0.9701, 0.9704, 0.9863, 1.0301, 1.0298, 0.9719, 0.9708,\n",
      "        0.9708, 1.0299, 1.0299, 1.0312, 1.0298, 1.0298, 0.9699, 1.0298, 1.0298,\n",
      "        1.0314, 0.9703, 1.0298, 1.0299], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 30 was 8.78%\n",
      "current params: [tensor([1.0311, 0.9693, 0.9691, 0.9694, 0.9850, 1.0311, 1.0308, 0.9711, 0.9699,\n",
      "        0.9698, 1.0309, 1.0309, 1.0323, 1.0308, 1.0308, 0.9689, 1.0308, 1.0307,\n",
      "        1.0325, 0.9693, 1.0308, 1.0309], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 31 was 8.79%\n",
      "current params: [tensor([1.0321, 0.9684, 0.9681, 0.9685, 0.9837, 1.0322, 1.0318, 0.9704, 0.9689,\n",
      "        0.9689, 1.0319, 1.0319, 1.0334, 1.0318, 1.0317, 0.9679, 1.0318, 1.0317,\n",
      "        1.0336, 0.9684, 1.0318, 1.0318], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 32 was 8.79%\n",
      "current params: [tensor([1.0331, 0.9674, 0.9672, 0.9675, 0.9824, 1.0332, 1.0328, 0.9696, 0.9680,\n",
      "        0.9680, 1.0328, 1.0329, 1.0345, 1.0328, 1.0327, 0.9669, 1.0328, 1.0327,\n",
      "        1.0347, 0.9674, 1.0327, 1.0328], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 33 was 8.79%\n",
      "current params: [tensor([1.0341, 0.9664, 0.9662, 0.9665, 0.9811, 1.0342, 1.0337, 0.9688, 0.9671,\n",
      "        0.9671, 1.0338, 1.0339, 1.0356, 1.0338, 1.0337, 0.9659, 1.0337, 1.0337,\n",
      "        1.0359, 0.9664, 1.0337, 1.0338], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 34 was 8.79%\n",
      "current params: [tensor([1.0351, 0.9655, 0.9652, 0.9656, 0.9797, 1.0352, 1.0347, 0.9681, 0.9662,\n",
      "        0.9662, 1.0348, 1.0349, 1.0367, 1.0347, 1.0347, 0.9649, 1.0347, 1.0346,\n",
      "        1.0370, 0.9654, 1.0347, 1.0348], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 35 was 8.79%\n",
      "current params: [tensor([1.0361, 0.9645, 0.9642, 0.9646, 0.9784, 1.0362, 1.0357, 0.9674, 0.9653,\n",
      "        0.9653, 1.0358, 1.0358, 1.0378, 1.0357, 1.0356, 0.9639, 1.0357, 1.0356,\n",
      "        1.0382, 0.9645, 1.0357, 1.0358], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 36 was 8.80%\n",
      "current params: [tensor([1.0371, 0.9635, 0.9632, 0.9637, 0.9770, 1.0372, 1.0367, 0.9667, 0.9644,\n",
      "        0.9644, 1.0368, 1.0368, 1.0389, 1.0367, 1.0366, 0.9629, 1.0367, 1.0366,\n",
      "        1.0393, 0.9635, 1.0367, 1.0368], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 37 was 8.80%\n",
      "current params: [tensor([1.0381, 0.9626, 0.9622, 0.9627, 0.9756, 1.0382, 1.0376, 0.9660, 0.9635,\n",
      "        0.9635, 1.0378, 1.0378, 1.0400, 1.0377, 1.0376, 0.9619, 1.0376, 1.0376,\n",
      "        1.0405, 0.9625, 1.0376, 1.0377], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 38 was 8.80%\n",
      "current params: [tensor([1.0391, 0.9616, 0.9612, 0.9618, 0.9742, 1.0392, 1.0386, 0.9653, 0.9627,\n",
      "        0.9627, 1.0388, 1.0388, 1.0411, 1.0386, 1.0386, 0.9609, 1.0386, 1.0385,\n",
      "        1.0416, 0.9616, 1.0386, 1.0387], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 39 was 8.80%\n",
      "current params: [tensor([1.0401, 0.9607, 0.9602, 0.9608, 0.9729, 1.0402, 1.0396, 0.9646, 0.9618,\n",
      "        0.9618, 1.0397, 1.0398, 1.0422, 1.0396, 1.0395, 0.9599, 1.0396, 1.0395,\n",
      "        1.0428, 0.9606, 1.0396, 1.0397], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 40 was 8.81%\n",
      "current params: [tensor([1.0412, 0.9597, 0.9593, 0.9599, 0.9715, 1.0413, 1.0406, 0.9640, 0.9609,\n",
      "        0.9609, 1.0407, 1.0408, 1.0433, 1.0406, 1.0405, 0.9589, 1.0405, 1.0405,\n",
      "        1.0440, 0.9596, 1.0406, 1.0407], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 41 was 8.81%\n",
      "current params: [tensor([1.0422, 0.9588, 0.9583, 0.9589, 0.9701, 1.0423, 1.0416, 0.9634, 0.9601,\n",
      "        0.9601, 1.0417, 1.0418, 1.0444, 1.0416, 1.0415, 0.9578, 1.0415, 1.0414,\n",
      "        1.0451, 0.9586, 1.0415, 1.0416], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 42 was 8.81%\n",
      "current params: [tensor([1.0432, 0.9578, 0.9573, 0.9580, 0.9686, 1.0433, 1.0425, 0.9628, 0.9592,\n",
      "        0.9592, 1.0427, 1.0428, 1.0455, 1.0425, 1.0424, 0.9568, 1.0425, 1.0424,\n",
      "        1.0463, 0.9577, 1.0425, 1.0426], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 43 was 8.81%\n",
      "current params: [tensor([1.0442, 0.9569, 0.9563, 0.9570, 0.9672, 1.0443, 1.0435, 0.9622, 0.9584,\n",
      "        0.9584, 1.0437, 1.0437, 1.0466, 1.0435, 1.0434, 0.9558, 1.0434, 1.0434,\n",
      "        1.0475, 0.9567, 1.0435, 1.0436], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 44 was 8.81%\n",
      "current params: [tensor([1.0452, 0.9559, 0.9553, 0.9561, 0.9658, 1.0453, 1.0445, 0.9617, 0.9575,\n",
      "        0.9575, 1.0446, 1.0447, 1.0477, 1.0445, 1.0444, 0.9548, 1.0444, 1.0443,\n",
      "        1.0487, 0.9557, 1.0444, 1.0446], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 45 was 8.82%\n",
      "current params: [tensor([1.0462, 0.9550, 0.9543, 0.9552, 0.9643, 1.0463, 1.0454, 0.9611, 0.9567,\n",
      "        0.9567, 1.0456, 1.0457, 1.0489, 1.0455, 1.0453, 0.9538, 1.0453, 1.0453,\n",
      "        1.0499, 0.9548, 1.0454, 1.0455], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 46 was 8.82%\n",
      "current params: [tensor([1.0472, 0.9540, 0.9533, 0.9542, 0.9629, 1.0473, 1.0464, 0.9606, 0.9558,\n",
      "        0.9559, 1.0466, 1.0467, 1.0500, 1.0464, 1.0463, 0.9528, 1.0463, 1.0462,\n",
      "        1.0511, 0.9538, 1.0464, 1.0465], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 47 was 8.82%\n",
      "current params: [tensor([1.0482, 0.9531, 0.9524, 0.9533, 0.9614, 1.0484, 1.0474, 0.9601, 0.9550,\n",
      "        0.9551, 1.0476, 1.0477, 1.0511, 1.0474, 1.0472, 0.9518, 1.0473, 1.0472,\n",
      "        1.0523, 0.9528, 1.0473, 1.0475], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 48 was 8.82%\n",
      "current params: [tensor([1.0492, 0.9522, 0.9514, 0.9524, 0.9600, 1.0494, 1.0484, 0.9596, 0.9542,\n",
      "        0.9542, 1.0486, 1.0487, 1.0522, 1.0484, 1.0482, 0.9508, 1.0482, 1.0482,\n",
      "        1.0535, 0.9519, 1.0483, 1.0485], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 49 was 8.82%\n",
      "current params: [tensor([1.0502, 0.9512, 0.9504, 0.9514, 0.9585, 1.0504, 1.0493, 0.9592, 0.9534,\n",
      "        0.9534, 1.0495, 1.0496, 1.0533, 1.0493, 1.0492, 0.9498, 1.0492, 1.0491,\n",
      "        1.0547, 0.9509, 1.0493, 1.0494], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 50 was 8.83%\n",
      "current params: [tensor([1.0513, 0.9503, 0.9494, 0.9505, 0.9571, 1.0514, 1.0503, 0.9588, 0.9526,\n",
      "        0.9526, 1.0505, 1.0506, 1.0544, 1.0503, 1.0501, 0.9487, 1.0501, 1.0501,\n",
      "        1.0559, 0.9499, 1.0502, 1.0504], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 51 was 8.83%\n",
      "current params: [tensor([1.0523, 0.9494, 0.9484, 0.9496, 0.9556, 1.0524, 1.0513, 0.9584, 0.9518,\n",
      "        0.9518, 1.0515, 1.0516, 1.0556, 1.0512, 1.0511, 0.9477, 1.0511, 1.0510,\n",
      "        1.0571, 0.9490, 1.0512, 1.0514], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 52 was 8.83%\n",
      "current params: [tensor([1.0533, 0.9484, 0.9474, 0.9487, 0.9541, 1.0534, 1.0522, 0.9580, 0.9510,\n",
      "        0.9511, 1.0525, 1.0526, 1.0567, 1.0522, 1.0520, 0.9467, 1.0520, 1.0520,\n",
      "        1.0583, 0.9480, 1.0522, 1.0523], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 53 was 8.83%\n",
      "current params: [tensor([1.0543, 0.9475, 0.9464, 0.9477, 0.9526, 1.0545, 1.0532, 0.9576, 0.9502,\n",
      "        0.9503, 1.0534, 1.0536, 1.0578, 1.0532, 1.0530, 0.9457, 1.0530, 1.0529,\n",
      "        1.0596, 0.9471, 1.0531, 1.0533], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 54 was 8.83%\n",
      "current params: [tensor([1.0553, 0.9466, 0.9455, 0.9468, 0.9511, 1.0555, 1.0542, 0.9573, 0.9494,\n",
      "        0.9495, 1.0544, 1.0545, 1.0589, 1.0541, 1.0539, 0.9447, 1.0539, 1.0539,\n",
      "        1.0608, 0.9461, 1.0541, 1.0542], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 55 was 8.84%\n",
      "current params: [tensor([1.0563, 0.9457, 0.9445, 0.9459, 0.9496, 1.0565, 1.0551, 0.9570, 0.9487,\n",
      "        0.9488, 1.0554, 1.0555, 1.0600, 1.0551, 1.0549, 0.9437, 1.0548, 1.0548,\n",
      "        1.0620, 0.9451, 1.0551, 1.0552], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 56 was 8.84%\n",
      "current params: [tensor([1.0573, 0.9447, 0.9435, 0.9450, 0.9481, 1.0575, 1.0561, 0.9567, 0.9479,\n",
      "        0.9480, 1.0564, 1.0565, 1.0612, 1.0561, 1.0558, 0.9426, 1.0558, 1.0558,\n",
      "        1.0633, 0.9442, 1.0560, 1.0562], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 57 was 8.84%\n",
      "current params: [tensor([1.0583, 0.9438, 0.9425, 0.9441, 0.9466, 1.0585, 1.0571, 0.9565, 0.9472,\n",
      "        0.9473, 1.0573, 1.0575, 1.0623, 1.0570, 1.0568, 0.9416, 1.0567, 1.0567,\n",
      "        1.0645, 0.9432, 1.0570, 1.0571], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 58 was 8.84%\n",
      "current params: [tensor([1.0594, 0.9429, 0.9415, 0.9432, 0.9451, 1.0595, 1.0580, 0.9563, 0.9464,\n",
      "        0.9465, 1.0583, 1.0584, 1.0634, 1.0580, 1.0577, 0.9406, 1.0577, 1.0577,\n",
      "        1.0657, 0.9423, 1.0579, 1.0581], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 59 was 8.84%\n",
      "current params: [tensor([1.0604, 0.9420, 0.9405, 0.9423, 0.9436, 1.0606, 1.0590, 0.9561, 0.9457,\n",
      "        0.9458, 1.0593, 1.0594, 1.0645, 1.0589, 1.0587, 0.9396, 1.0586, 1.0586,\n",
      "        1.0670, 0.9413, 1.0589, 1.0590], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 60 was 8.85%\n",
      "current params: [tensor([1.0614, 0.9411, 0.9395, 0.9414, 0.9420, 1.0616, 1.0599, 0.9559, 0.9450,\n",
      "        0.9451, 1.0602, 1.0604, 1.0656, 1.0599, 1.0596, 0.9386, 1.0595, 1.0596,\n",
      "        1.0682, 0.9403, 1.0599, 1.0600], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 61 was 8.85%\n",
      "current params: [tensor([1.0624, 0.9402, 0.9386, 0.9405, 0.9405, 1.0626, 1.0609, 0.9558, 0.9442,\n",
      "        0.9444, 1.0612, 1.0614, 1.0668, 1.0608, 1.0606, 0.9376, 1.0605, 1.0605,\n",
      "        1.0695, 0.9394, 1.0608, 1.0609], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 62 was 8.85%\n",
      "current params: [tensor([1.0634, 0.9393, 0.9376, 0.9396, 0.9390, 1.0636, 1.0619, 0.9557, 0.9435,\n",
      "        0.9436, 1.0622, 1.0623, 1.0679, 1.0618, 1.0615, 0.9365, 1.0614, 1.0615,\n",
      "        1.0708, 0.9384, 1.0618, 1.0619], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 63 was 8.85%\n",
      "current params: [tensor([1.0644, 0.9383, 0.9366, 0.9387, 0.9375, 1.0646, 1.0628, 0.9556, 0.9428,\n",
      "        0.9430, 1.0631, 1.0633, 1.0690, 1.0627, 1.0625, 0.9355, 1.0623, 1.0624,\n",
      "        1.0720, 0.9375, 1.0627, 1.0628], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 64 was 8.85%\n",
      "current params: [tensor([1.0654, 0.9374, 0.9356, 0.9378, 0.9359, 1.0657, 1.0638, 0.9555, 0.9421,\n",
      "        0.9423, 1.0641, 1.0643, 1.0700, 1.0637, 1.0634, 0.9345, 1.0632, 1.0633,\n",
      "        1.0733, 0.9365, 1.0637, 1.0638], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 65 was 8.85%\n",
      "current params: [tensor([1.0665, 0.9365, 0.9346, 0.9369, 0.9343, 1.0667, 1.0648, 0.9555, 0.9414,\n",
      "        0.9416, 1.0651, 1.0653, 1.0710, 1.0646, 1.0644, 0.9335, 1.0642, 1.0643,\n",
      "        1.0745, 0.9356, 1.0646, 1.0647], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 66 was 8.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: [tensor([1.0675, 0.9356, 0.9336, 0.9359, 0.9326, 1.0677, 1.0657, 0.9555, 0.9407,\n",
      "        0.9409, 1.0661, 1.0663, 1.0720, 1.0655, 1.0653, 0.9325, 1.0651, 1.0652,\n",
      "        1.0758, 0.9346, 1.0656, 1.0657], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 67 was 8.86%\n",
      "current params: [tensor([1.0685, 0.9347, 0.9325, 0.9350, 0.9310, 1.0687, 1.0667, 0.9556, 0.9400,\n",
      "        0.9402, 1.0670, 1.0672, 1.0728, 1.0665, 1.0663, 0.9314, 1.0660, 1.0662,\n",
      "        1.0771, 0.9337, 1.0666, 1.0666], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 68 was 8.86%\n",
      "current params: [tensor([1.0695, 0.9338, 0.9315, 0.9341, 0.9293, 1.0697, 1.0677, 0.9556, 0.9393,\n",
      "        0.9395, 1.0680, 1.0682, 1.0737, 1.0674, 1.0672, 0.9304, 1.0669, 1.0671,\n",
      "        1.0783, 0.9327, 1.0675, 1.0676], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 69 was 8.86%\n",
      "current params: [tensor([1.0706, 0.9329, 0.9305, 0.9332, 0.9276, 1.0707, 1.0687, 0.9557, 0.9386,\n",
      "        0.9388, 1.0690, 1.0692, 1.0745, 1.0683, 1.0682, 0.9294, 1.0678, 1.0681,\n",
      "        1.0796, 0.9318, 1.0685, 1.0685], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 70 was 8.86%\n",
      "current params: [tensor([1.0716, 0.9319, 0.9294, 0.9323, 0.9259, 1.0718, 1.0697, 0.9559, 0.9379,\n",
      "        0.9382, 1.0699, 1.0702, 1.0752, 1.0692, 1.0691, 0.9284, 1.0687, 1.0691,\n",
      "        1.0808, 0.9309, 1.0695, 1.0694], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 71 was 8.87%\n",
      "current params: [tensor([1.0726, 0.9310, 0.9284, 0.9314, 0.9242, 1.0728, 1.0707, 0.9560, 0.9373,\n",
      "        0.9375, 1.0709, 1.0712, 1.0759, 1.0701, 1.0701, 0.9273, 1.0696, 1.0700,\n",
      "        1.0821, 0.9299, 1.0705, 1.0704], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 72 was 8.87%\n",
      "current params: [tensor([1.0737, 0.9301, 0.9273, 0.9305, 0.9224, 1.0738, 1.0716, 0.9562, 0.9366,\n",
      "        0.9368, 1.0719, 1.0722, 1.0766, 1.0710, 1.0710, 0.9263, 1.0705, 1.0710,\n",
      "        1.0834, 0.9290, 1.0714, 1.0713], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 73 was 8.87%\n",
      "current params: [tensor([1.0747, 0.9292, 0.9262, 0.9296, 0.9207, 1.0748, 1.0726, 0.9565, 0.9359,\n",
      "        0.9362, 1.0729, 1.0731, 1.0772, 1.0719, 1.0719, 0.9253, 1.0713, 1.0719,\n",
      "        1.0847, 0.9280, 1.0724, 1.0722], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 74 was 8.87%\n",
      "current params: [tensor([1.0757, 0.9282, 0.9252, 0.9286, 0.9190, 1.0758, 1.0736, 0.9567, 0.9353,\n",
      "        0.9355, 1.0738, 1.0741, 1.0779, 1.0728, 1.0729, 0.9243, 1.0722, 1.0729,\n",
      "        1.0859, 0.9271, 1.0734, 1.0731], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 75 was 8.87%\n",
      "current params: [tensor([1.0768, 0.9273, 0.9241, 0.9277, 0.9172, 1.0769, 1.0746, 0.9570, 0.9346,\n",
      "        0.9349, 1.0748, 1.0751, 1.0785, 1.0737, 1.0738, 0.9232, 1.0731, 1.0738,\n",
      "        1.0872, 0.9262, 1.0743, 1.0740], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 76 was 8.88%\n",
      "current params: [tensor([1.0778, 0.9264, 0.9230, 0.9268, 0.9155, 1.0779, 1.0756, 0.9573, 0.9340,\n",
      "        0.9343, 1.0758, 1.0761, 1.0790, 1.0745, 1.0748, 0.9222, 1.0740, 1.0748,\n",
      "        1.0885, 0.9252, 1.0753, 1.0750], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 77 was 8.88%\n",
      "current params: [tensor([1.0788, 0.9255, 0.9220, 0.9259, 0.9137, 1.0789, 1.0766, 0.9577, 0.9334,\n",
      "        0.9337, 1.0767, 1.0771, 1.0796, 1.0754, 1.0757, 0.9212, 1.0749, 1.0758,\n",
      "        1.0898, 0.9243, 1.0763, 1.0759], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 78 was 8.88%\n",
      "current params: [tensor([1.0799, 0.9246, 0.9209, 0.9250, 0.9120, 1.0799, 1.0776, 0.9581, 0.9327,\n",
      "        0.9330, 1.0777, 1.0781, 1.0801, 1.0763, 1.0767, 0.9201, 1.0757, 1.0767,\n",
      "        1.0911, 0.9234, 1.0773, 1.0768], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 79 was 8.88%\n",
      "current params: [tensor([1.0809, 0.9236, 0.9198, 0.9241, 0.9103, 1.0810, 1.0786, 0.9585, 0.9321,\n",
      "        0.9324, 1.0787, 1.0791, 1.0806, 1.0772, 1.0776, 0.9191, 1.0766, 1.0777,\n",
      "        1.0924, 0.9225, 1.0782, 1.0777], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 80 was 8.88%\n",
      "current params: [tensor([1.0819, 0.9227, 0.9187, 0.9232, 0.9085, 1.0820, 1.0796, 0.9590, 0.9315,\n",
      "        0.9319, 1.0797, 1.0801, 1.0811, 1.0780, 1.0786, 0.9181, 1.0775, 1.0786,\n",
      "        1.0937, 0.9215, 1.0792, 1.0786], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 81 was 8.89%\n",
      "current params: [tensor([1.0830, 0.9218, 0.9177, 0.9223, 0.9068, 1.0830, 1.0806, 0.9595, 0.9309,\n",
      "        0.9313, 1.0806, 1.0810, 1.0816, 1.0789, 1.0795, 0.9170, 1.0783, 1.0796,\n",
      "        1.0950, 0.9206, 1.0802, 1.0795], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 82 was 8.89%\n",
      "current params: [tensor([1.0840, 0.9209, 0.9166, 0.9214, 0.9050, 1.0840, 1.0816, 0.9600, 0.9303,\n",
      "        0.9307, 1.0816, 1.0820, 1.0821, 1.0797, 1.0805, 0.9160, 1.0792, 1.0806,\n",
      "        1.0963, 0.9197, 1.0812, 1.0804], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 83 was 8.89%\n",
      "current params: [tensor([1.0850, 0.9200, 0.9155, 0.9205, 0.9033, 1.0851, 1.0826, 0.9606, 0.9297,\n",
      "        0.9301, 1.0826, 1.0830, 1.0825, 1.0806, 1.0814, 0.9150, 1.0800, 1.0815,\n",
      "        1.0976, 0.9187, 1.0821, 1.0814], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 84 was 8.89%\n",
      "current params: [tensor([1.0861, 0.9191, 0.9144, 0.9196, 0.9015, 1.0861, 1.0836, 0.9611, 0.9292,\n",
      "        0.9296, 1.0835, 1.0840, 1.0829, 1.0815, 1.0824, 0.9139, 1.0809, 1.0825,\n",
      "        1.0989, 0.9178, 1.0831, 1.0823], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 85 was 8.89%\n",
      "current params: [tensor([1.0871, 0.9182, 0.9133, 0.9187, 0.8998, 1.0871, 1.0846, 0.9618, 0.9286,\n",
      "        0.9290, 1.0845, 1.0850, 1.0834, 1.0823, 1.0833, 0.9129, 1.0817, 1.0834,\n",
      "        1.1002, 0.9169, 1.0841, 1.0832], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 86 was 8.90%\n",
      "current params: [tensor([1.0882, 0.9173, 0.9122, 0.9178, 0.8980, 1.0882, 1.0856, 0.9624, 0.9281,\n",
      "        0.9285, 1.0855, 1.0860, 1.0838, 1.0832, 1.0842, 0.9119, 1.0826, 1.0844,\n",
      "        1.1015, 0.9160, 1.0851, 1.0841], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 87 was 8.90%\n",
      "current params: [tensor([1.0892, 0.9164, 0.9111, 0.9169, 0.8963, 1.0892, 1.0866, 0.9631, 0.9275,\n",
      "        0.9280, 1.0864, 1.0869, 1.0842, 1.0840, 1.0852, 0.9108, 1.0834, 1.0853,\n",
      "        1.1028, 0.9150, 1.0860, 1.0850], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 88 was 8.90%\n",
      "current params: [tensor([1.0902, 0.9155, 0.9100, 0.9160, 0.8946, 1.0902, 1.0876, 0.9638, 0.9270,\n",
      "        0.9275, 1.0874, 1.0879, 1.0845, 1.0849, 1.0861, 0.9098, 1.0843, 1.0863,\n",
      "        1.1042, 0.9141, 1.0870, 1.0859], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 89 was 8.90%\n",
      "current params: [tensor([1.0913, 0.9146, 0.9089, 0.9151, 0.8928, 1.0913, 1.0886, 0.9646, 0.9265,\n",
      "        0.9270, 1.0884, 1.0889, 1.0849, 1.0857, 1.0871, 0.9088, 1.0851, 1.0872,\n",
      "        1.1055, 0.9132, 1.0880, 1.0868], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 90 was 8.90%\n",
      "current params: [tensor([1.0923, 0.9137, 0.9079, 0.9142, 0.8911, 1.0923, 1.0896, 0.9654, 0.9260,\n",
      "        0.9265, 1.0893, 1.0899, 1.0853, 1.0866, 1.0880, 0.9077, 1.0860, 1.0882,\n",
      "        1.1068, 0.9123, 1.0889, 1.0877], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 91 was 8.91%\n",
      "current params: [tensor([1.0934, 0.9128, 0.9068, 0.9133, 0.8893, 1.0933, 1.0906, 0.9662, 0.9255,\n",
      "        0.9261, 1.0903, 1.0909, 1.0856, 1.0874, 1.0889, 0.9067, 1.0868, 1.0891,\n",
      "        1.1082, 0.9113, 1.0899, 1.0886], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 92 was 8.91%\n",
      "current params: [tensor([1.0944, 0.9119, 0.9057, 0.9124, 0.8876, 1.0944, 1.0916, 0.9670, 0.9250,\n",
      "        0.9256, 1.0913, 1.0919, 1.0859, 1.0882, 1.0899, 0.9056, 1.0876, 1.0901,\n",
      "        1.1095, 0.9104, 1.0909, 1.0895], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 93 was 8.91%\n",
      "current params: [tensor([1.0954, 0.9110, 0.9046, 0.9115, 0.8858, 1.0954, 1.0926, 0.9679, 0.9246,\n",
      "        0.9252, 1.0922, 1.0928, 1.0862, 1.0891, 1.0908, 0.9046, 1.0885, 1.0910,\n",
      "        1.1109, 0.9095, 1.0918, 1.0904], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 94 was 8.91%\n",
      "current params: [tensor([1.0965, 0.9102, 0.9035, 0.9107, 0.8841, 1.0965, 1.0936, 0.9688, 0.9241,\n",
      "        0.9247, 1.0932, 1.0938, 1.0865, 1.0899, 1.0917, 0.9036, 1.0893, 1.0920,\n",
      "        1.1122, 0.9086, 1.0928, 1.0913], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 95 was 8.92%\n",
      "current params: [tensor([1.0975, 0.9093, 0.9024, 0.9098, 0.8824, 1.0975, 1.0946, 0.9697, 0.9237,\n",
      "        0.9243, 1.0942, 1.0948, 1.0868, 1.0907, 1.0927, 0.9025, 1.0901, 1.0929,\n",
      "        1.1136, 0.9076, 1.0938, 1.0921], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 96 was 8.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: [tensor([1.0986, 0.9084, 0.9013, 0.9089, 0.8806, 1.0985, 1.0956, 0.9707, 0.9232,\n",
      "        0.9239, 1.0951, 1.0958, 1.0871, 1.0916, 1.0936, 0.9015, 1.0910, 1.0939,\n",
      "        1.1149, 0.9067, 1.0948, 1.0930], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 97 was 8.92%\n",
      "current params: [tensor([1.0996, 0.9075, 0.9002, 0.9080, 0.8789, 1.0996, 1.0966, 0.9717, 0.9228,\n",
      "        0.9235, 1.0961, 1.0967, 1.0874, 1.0924, 1.0945, 0.9005, 1.0918, 1.0948,\n",
      "        1.1163, 0.9058, 1.0957, 1.0939], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 98 was 8.92%\n",
      "current params: [tensor([1.1006, 0.9067, 0.8990, 0.9072, 0.8771, 1.1006, 1.0976, 0.9727, 0.9224,\n",
      "        0.9231, 1.0971, 1.0977, 1.0876, 1.0932, 1.0955, 0.8994, 1.0926, 1.0957,\n",
      "        1.1176, 0.9049, 1.0967, 1.0948], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 99 was 8.92%\n",
      "current params: [tensor([1.1017, 0.9058, 0.8979, 0.9063, 0.8754, 1.1017, 1.0985, 0.9737, 0.9220,\n",
      "        0.9228, 1.0980, 1.0987, 1.0878, 1.0941, 1.0964, 0.8984, 1.0934, 1.0967,\n",
      "        1.1190, 0.9040, 1.0977, 1.0957], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 100 was 8.93%\n",
      "current params: [tensor([1.1027, 0.9049, 0.8968, 0.9054, 0.8736, 1.1027, 1.0995, 0.9748, 0.9216,\n",
      "        0.9224, 1.0990, 1.0997, 1.0881, 1.0949, 1.0973, 0.8973, 1.0943, 1.0976,\n",
      "        1.1204, 0.9030, 1.0986, 1.0966], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 101 was 8.93%\n",
      "current params: [tensor([1.1038, 0.9041, 0.8957, 0.9046, 0.8719, 1.1038, 1.1005, 0.9759, 0.9213,\n",
      "        0.9221, 1.0999, 1.1006, 1.0883, 1.0957, 1.0983, 0.8963, 1.0951, 1.0986,\n",
      "        1.1218, 0.9021, 1.0996, 1.0975], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 102 was 8.93%\n",
      "current params: [tensor([1.1048, 0.9032, 0.8946, 0.9037, 0.8702, 1.1048, 1.1015, 0.9770, 0.9209,\n",
      "        0.9218, 1.1009, 1.1016, 1.0885, 1.0965, 1.0992, 0.8952, 1.0959, 1.0995,\n",
      "        1.1231, 0.9012, 1.1006, 1.0984], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 103 was 8.93%\n",
      "current params: [tensor([1.1058, 0.9023, 0.8935, 0.9028, 0.8684, 1.1059, 1.1025, 0.9781, 0.9206,\n",
      "        0.9215, 1.1019, 1.1026, 1.0886, 1.0973, 1.1001, 0.8942, 1.0967, 1.1004,\n",
      "        1.1245, 0.9003, 1.1015, 1.0992], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 104 was 8.93%\n",
      "current params: [tensor([1.1069, 0.9015, 0.8924, 0.9020, 0.8667, 1.1069, 1.1035, 0.9793, 0.9202,\n",
      "        0.9212, 1.1028, 1.1036, 1.0888, 1.0982, 1.1010, 0.8932, 1.0975, 1.1014,\n",
      "        1.1259, 0.8994, 1.1025, 1.1001], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 105 was 8.94%\n",
      "current params: [tensor([1.1079, 0.9006, 0.8913, 0.9011, 0.8649, 1.1080, 1.1045, 0.9805, 0.9199,\n",
      "        0.9209, 1.1038, 1.1045, 1.0889, 1.0990, 1.1020, 0.8921, 1.0983, 1.1023,\n",
      "        1.1273, 0.8985, 1.1034, 1.1010], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 106 was 8.94%\n",
      "current params: [tensor([1.1089, 0.8998, 0.8902, 0.9003, 0.8632, 1.1090, 1.1055, 0.9817, 0.9196,\n",
      "        0.9206, 1.1047, 1.1055, 1.0890, 1.0998, 1.1029, 0.8911, 1.0991, 1.1033,\n",
      "        1.1287, 0.8975, 1.1044, 1.1019], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 107 was 8.94%\n",
      "current params: [tensor([1.1100, 0.8989, 0.8890, 0.8994, 0.8614, 1.1101, 1.1065, 0.9829, 0.9194,\n",
      "        0.9204, 1.1057, 1.1065, 1.0891, 1.1006, 1.1038, 0.8900, 1.0999, 1.1042,\n",
      "        1.1301, 0.8966, 1.1054, 1.1028], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 108 was 8.94%\n",
      "current params: [tensor([1.1110, 0.8981, 0.8879, 0.8986, 0.8597, 1.1112, 1.1075, 0.9842, 0.9191,\n",
      "        0.9202, 1.1067, 1.1074, 1.0892, 1.1014, 1.1047, 0.8890, 1.1007, 1.1051,\n",
      "        1.1315, 0.8957, 1.1063, 1.1036], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 109 was 8.94%\n",
      "current params: [tensor([1.1121, 0.8973, 0.8868, 0.8977, 0.8579, 1.1122, 1.1085, 0.9854, 0.9188,\n",
      "        0.9200, 1.1076, 1.1084, 1.0893, 1.1022, 1.1057, 0.8879, 1.1015, 1.1061,\n",
      "        1.1329, 0.8948, 1.1073, 1.1045], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 110 was 8.95%\n",
      "current params: [tensor([1.1131, 0.8964, 0.8857, 0.8969, 0.8562, 1.1133, 1.1094, 0.9867, 0.9186,\n",
      "        0.9198, 1.1086, 1.1094, 1.0893, 1.1030, 1.1066, 0.8869, 1.1023, 1.1070,\n",
      "        1.1343, 0.8939, 1.1083, 1.1054], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 111 was 8.95%\n",
      "current params: [tensor([1.1141, 0.8956, 0.8846, 0.8960, 0.8544, 1.1143, 1.1104, 0.9880, 0.9184,\n",
      "        0.9196, 1.1095, 1.1103, 1.0894, 1.1038, 1.1075, 0.8859, 1.1031, 1.1079,\n",
      "        1.1357, 0.8930, 1.1092, 1.1063], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 112 was 8.95%\n",
      "current params: [tensor([1.1152, 0.8948, 0.8834, 0.8952, 0.8527, 1.1154, 1.1114, 0.9893, 0.9182,\n",
      "        0.9194, 1.1105, 1.1113, 1.0894, 1.1046, 1.1084, 0.8848, 1.1039, 1.1089,\n",
      "        1.1371, 0.8921, 1.1102, 1.1071], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 113 was 8.95%\n",
      "current params: [tensor([1.1162, 0.8939, 0.8823, 0.8943, 0.8509, 1.1165, 1.1124, 0.9907, 0.9180,\n",
      "        0.9193, 1.1114, 1.1123, 1.0893, 1.1054, 1.1093, 0.8838, 1.1047, 1.1098,\n",
      "        1.1385, 0.8912, 1.1111, 1.1080], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 114 was 8.95%\n",
      "current params: [tensor([1.1173, 0.8931, 0.8812, 0.8935, 0.8491, 1.1176, 1.1134, 0.9920, 0.9178,\n",
      "        0.9191, 1.1124, 1.1132, 1.0893, 1.1062, 1.1103, 0.8827, 1.1055, 1.1107,\n",
      "        1.1399, 0.8902, 1.1121, 1.1089], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 115 was 8.96%\n",
      "current params: [tensor([1.1183, 0.8923, 0.8800, 0.8927, 0.8474, 1.1186, 1.1144, 0.9934, 0.9176,\n",
      "        0.9190, 1.1134, 1.1142, 1.0892, 1.1070, 1.1112, 0.8817, 1.1062, 1.1116,\n",
      "        1.1414, 0.8893, 1.1131, 1.1097], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 116 was 8.96%\n",
      "current params: [tensor([1.1193, 0.8915, 0.8789, 0.8918, 0.8456, 1.1197, 1.1154, 0.9948, 0.9175,\n",
      "        0.9189, 1.1143, 1.1152, 1.0891, 1.1078, 1.1121, 0.8806, 1.1070, 1.1126,\n",
      "        1.1428, 0.8884, 1.1140, 1.1106], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 117 was 8.96%\n",
      "current params: [tensor([1.1204, 0.8907, 0.8778, 0.8910, 0.8438, 1.1208, 1.1164, 0.9962, 0.9173,\n",
      "        0.9188, 1.1153, 1.1161, 1.0890, 1.1086, 1.1130, 0.8796, 1.1078, 1.1135,\n",
      "        1.1442, 0.8875, 1.1150, 1.1115], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 118 was 8.96%\n",
      "current params: [tensor([1.1214, 0.8898, 0.8766, 0.8902, 0.8421, 1.1218, 1.1174, 0.9976, 0.9172,\n",
      "        0.9188, 1.1162, 1.1171, 1.0889, 1.1094, 1.1139, 0.8785, 1.1086, 1.1144,\n",
      "        1.1456, 0.8866, 1.1159, 1.1123], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 119 was 8.96%\n",
      "current params: [tensor([1.1224, 0.8890, 0.8755, 0.8893, 0.8403, 1.1229, 1.1183, 0.9991, 0.9171,\n",
      "        0.9187, 1.1172, 1.1181, 1.0887, 1.1101, 1.1148, 0.8775, 1.1093, 1.1153,\n",
      "        1.1471, 0.8857, 1.1169, 1.1132], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 120 was 8.97%\n",
      "current params: [tensor([1.1235, 0.8882, 0.8744, 0.8885, 0.8385, 1.1240, 1.1193, 1.0005, 0.9170,\n",
      "        0.9187, 1.1181, 1.1190, 1.0885, 1.1109, 1.1158, 0.8764, 1.1101, 1.1163,\n",
      "        1.1485, 0.8848, 1.1179, 1.1140], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 121 was 8.97%\n",
      "current params: [tensor([1.1245, 0.8874, 0.8732, 0.8877, 0.8368, 1.1251, 1.1203, 1.0020, 0.9170,\n",
      "        0.9187, 1.1191, 1.1200, 1.0883, 1.1117, 1.1167, 0.8754, 1.1109, 1.1172,\n",
      "        1.1499, 0.8839, 1.1188, 1.1149], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 122 was 8.97%\n",
      "current params: [tensor([1.1256, 0.8866, 0.8721, 0.8869, 0.8350, 1.1262, 1.1213, 1.0035, 0.9169,\n",
      "        0.9187, 1.1200, 1.1209, 1.0880, 1.1125, 1.1176, 0.8743, 1.1116, 1.1181,\n",
      "        1.1514, 0.8830, 1.1198, 1.1158], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 123 was 8.97%\n",
      "current params: [tensor([1.1266, 0.8858, 0.8709, 0.8861, 0.8332, 1.1272, 1.1223, 1.0049, 0.9169,\n",
      "        0.9187, 1.1210, 1.1219, 1.0877, 1.1133, 1.1185, 0.8733, 1.1124, 1.1190,\n",
      "        1.1528, 0.8821, 1.1207, 1.1166], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 124 was 8.98%\n",
      "current params: [tensor([1.1276, 0.8850, 0.8698, 0.8852, 0.8314, 1.1283, 1.1233, 1.0064, 0.9168,\n",
      "        0.9188, 1.1219, 1.1229, 1.0874, 1.1140, 1.1194, 0.8722, 1.1131, 1.1200,\n",
      "        1.1543, 0.8812, 1.1217, 1.1175], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 125 was 8.98%\n",
      "current params: [tensor([1.1287, 0.8842, 0.8686, 0.8844, 0.8296, 1.1294, 1.1243, 1.0080, 0.9168,\n",
      "        0.9188, 1.1229, 1.1238, 1.0871, 1.1148, 1.1203, 0.8712, 1.1139, 1.1209,\n",
      "        1.1557, 0.8803, 1.1227, 1.1183], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 126 was 8.98%\n",
      "current params: [tensor([1.1297, 0.8834, 0.8675, 0.8836, 0.8278, 1.1305, 1.1253, 1.0095, 0.9169,\n",
      "        0.9189, 1.1239, 1.1248, 1.0867, 1.1156, 1.1212, 0.8701, 1.1147, 1.1218,\n",
      "        1.1572, 0.8794, 1.1236, 1.1192], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 127 was 8.98%\n",
      "current params: [tensor([1.1308, 0.8827, 0.8663, 0.8828, 0.8260, 1.1316, 1.1262, 1.0110, 0.9169,\n",
      "        0.9190, 1.1248, 1.1257, 1.0863, 1.1163, 1.1221, 0.8691, 1.1154, 1.1227,\n",
      "        1.1586, 0.8785, 1.1246, 1.1200], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 128 was 8.98%\n",
      "current params: [tensor([1.1318, 0.8819, 0.8651, 0.8820, 0.8243, 1.1327, 1.1272, 1.0126, 0.9169,\n",
      "        0.9191, 1.1258, 1.1267, 1.0858, 1.1171, 1.1230, 0.8680, 1.1162, 1.1236,\n",
      "        1.1601, 0.8776, 1.1255, 1.1209], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 129 was 8.99%\n",
      "current params: [tensor([1.1328, 0.8811, 0.8640, 0.8812, 0.8225, 1.1338, 1.1282, 1.0141, 0.9170,\n",
      "        0.9193, 1.1267, 1.1276, 1.0853, 1.1178, 1.1240, 0.8670, 1.1169, 1.1246,\n",
      "        1.1615, 0.8767, 1.1265, 1.1217], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 130 was 8.99%\n",
      "current params: [tensor([1.1339, 0.8803, 0.8628, 0.8804, 0.8207, 1.1349, 1.1292, 1.0157, 0.9171,\n",
      "        0.9194, 1.1277, 1.1286, 1.0848, 1.1186, 1.1249, 0.8659, 1.1176, 1.1255,\n",
      "        1.1630, 0.8758, 1.1274, 1.1226], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 131 was 8.99%\n",
      "current params: [tensor([1.1349, 0.8796, 0.8616, 0.8796, 0.8188, 1.1360, 1.1302, 1.0172, 0.9172,\n",
      "        0.9196, 1.1286, 1.1296, 1.0842, 1.1193, 1.1258, 0.8648, 1.1184, 1.1264,\n",
      "        1.1645, 0.8748, 1.1284, 1.1234], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 132 was 8.99%\n",
      "current params: [tensor([1.1360, 0.8788, 0.8605, 0.8788, 0.8170, 1.1371, 1.1312, 1.0188, 0.9173,\n",
      "        0.9198, 1.1296, 1.1305, 1.0836, 1.1201, 1.1267, 0.8638, 1.1191, 1.1273,\n",
      "        1.1659, 0.8739, 1.1294, 1.1242], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 133 was 8.99%\n",
      "current params: [tensor([1.1370, 0.8780, 0.8593, 0.8780, 0.8152, 1.1382, 1.1322, 1.0204, 0.9174,\n",
      "        0.9200, 1.1305, 1.1315, 1.0830, 1.1208, 1.1276, 0.8627, 1.1198, 1.1282,\n",
      "        1.1674, 0.8730, 1.1303, 1.1251], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 134 was 9.00%\n",
      "current params: [tensor([1.1380, 0.8773, 0.8581, 0.8772, 0.8134, 1.1393, 1.1332, 1.0220, 0.9176,\n",
      "        0.9202, 1.1315, 1.1324, 1.0823, 1.1216, 1.1285, 0.8617, 1.1206, 1.1292,\n",
      "        1.1689, 0.8721, 1.1313, 1.1259], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 135 was 9.00%\n",
      "current params: [tensor([1.1391, 0.8765, 0.8569, 0.8764, 0.8116, 1.1404, 1.1341, 1.0236, 0.9178,\n",
      "        0.9205, 1.1324, 1.1334, 1.0815, 1.1223, 1.1294, 0.8606, 1.1213, 1.1301,\n",
      "        1.1704, 0.8712, 1.1322, 1.1268], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 136 was 9.00%\n",
      "current params: [tensor([1.1401, 0.8757, 0.8557, 0.8756, 0.8098, 1.1415, 1.1351, 1.0252, 0.9180,\n",
      "        0.9208, 1.1334, 1.1343, 1.0808, 1.1231, 1.1303, 0.8596, 1.1220, 1.1310,\n",
      "        1.1718, 0.8704, 1.1332, 1.1276], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 137 was 9.00%\n",
      "current params: [tensor([1.1411, 0.8750, 0.8546, 0.8748, 0.8080, 1.1426, 1.1361, 1.0269, 0.9182,\n",
      "        0.9211, 1.1343, 1.1353, 1.0800, 1.1238, 1.1312, 0.8585, 1.1227, 1.1319,\n",
      "        1.1733, 0.8695, 1.1341, 1.1284], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 138 was 9.00%\n",
      "current params: [tensor([1.1422, 0.8742, 0.8534, 0.8740, 0.8061, 1.1437, 1.1371, 1.0285, 0.9184,\n",
      "        0.9214, 1.1353, 1.1362, 1.0791, 1.1245, 1.1321, 0.8574, 1.1235, 1.1328,\n",
      "        1.1748, 0.8686, 1.1351, 1.1293], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 139 was 9.01%\n",
      "current params: [tensor([1.1432, 0.8735, 0.8522, 0.8732, 0.8043, 1.1448, 1.1381, 1.0301, 0.9186,\n",
      "        0.9217, 1.1362, 1.1372, 1.0782, 1.1253, 1.1330, 0.8564, 1.1242, 1.1337,\n",
      "        1.1763, 0.8677, 1.1361, 1.1301], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 140 was 9.01%\n",
      "current params: [tensor([1.1443, 0.8728, 0.8510, 0.8724, 0.8025, 1.1459, 1.1391, 1.0318, 0.9189,\n",
      "        0.9221, 1.1372, 1.1381, 1.0774, 1.1260, 1.1339, 0.8553, 1.1249, 1.1346,\n",
      "        1.1778, 0.8668, 1.1370, 1.1309], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 141 was 9.01%\n",
      "current params: [tensor([1.1453, 0.8720, 0.8498, 0.8717, 0.8007, 1.1471, 1.1401, 1.0334, 0.9192,\n",
      "        0.9225, 1.1381, 1.1391, 1.0767, 1.1267, 1.1348, 0.8543, 1.1256, 1.1355,\n",
      "        1.1793, 0.8659, 1.1380, 1.1318], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 142 was 9.01%\n",
      "current params: [tensor([1.1463, 0.8713, 0.8486, 0.8709, 0.7989, 1.1482, 1.1410, 1.0351, 0.9195,\n",
      "        0.9229, 1.1391, 1.1400, 1.0760, 1.1275, 1.1357, 0.8532, 1.1263, 1.1364,\n",
      "        1.1808, 0.8650, 1.1389, 1.1326], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 143 was 9.02%\n",
      "current params: [tensor([1.1474, 0.8706, 0.8475, 0.8702, 0.7972, 1.1493, 1.1420, 1.0368, 0.9199,\n",
      "        0.9234, 1.1400, 1.1409, 1.0753, 1.1282, 1.1366, 0.8522, 1.1271, 1.1373,\n",
      "        1.1822, 0.8641, 1.1399, 1.1334], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 144 was 9.02%\n",
      "current params: [tensor([1.1484, 0.8699, 0.8463, 0.8694, 0.7954, 1.1504, 1.1430, 1.0384, 0.9202,\n",
      "        0.9238, 1.1409, 1.1419, 1.0747, 1.1290, 1.1375, 0.8511, 1.1278, 1.1382,\n",
      "        1.1837, 0.8632, 1.1408, 1.1343], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 145 was 9.02%\n",
      "current params: [tensor([1.1494, 0.8692, 0.8452, 0.8687, 0.7937, 1.1515, 1.1439, 1.0401, 0.9206,\n",
      "        0.9243, 1.1419, 1.1428, 1.0741, 1.1298, 1.1384, 0.8500, 1.1285, 1.1391,\n",
      "        1.1852, 0.8623, 1.1417, 1.1351], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 146 was 9.02%\n",
      "current params: [tensor([1.1504, 0.8686, 0.8440, 0.8680, 0.7919, 1.1527, 1.1449, 1.0418, 0.9210,\n",
      "        0.9249, 1.1428, 1.1437, 1.0736, 1.1305, 1.1392, 0.8490, 1.1292, 1.1400,\n",
      "        1.1867, 0.8614, 1.1427, 1.1360], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 147 was 9.02%\n",
      "current params: [tensor([1.1515, 0.8679, 0.8429, 0.8672, 0.7902, 1.1538, 1.1458, 1.0435, 0.9215,\n",
      "        0.9254, 1.1438, 1.1447, 1.0730, 1.1313, 1.1401, 0.8479, 1.1300, 1.1409,\n",
      "        1.1882, 0.8605, 1.1436, 1.1368], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 148 was 9.03%\n",
      "current params: [tensor([1.1525, 0.8672, 0.8417, 0.8665, 0.7885, 1.1549, 1.1468, 1.0452, 0.9219,\n",
      "        0.9260, 1.1447, 1.1456, 1.0725, 1.1321, 1.1410, 0.8469, 1.1307, 1.1418,\n",
      "        1.1897, 0.8596, 1.1445, 1.1376], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 149 was 9.03%\n",
      "current params: [tensor([1.1535, 0.8666, 0.8406, 0.8658, 0.7867, 1.1561, 1.1477, 1.0469, 0.9224,\n",
      "        0.9266, 1.1456, 1.1465, 1.0719, 1.1328, 1.1419, 0.8458, 1.1314, 1.1427,\n",
      "        1.1912, 0.8587, 1.1455, 1.1385], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 150 was 9.03%\n",
      "current params: [tensor([1.1545, 0.8659, 0.8394, 0.8651, 0.7850, 1.1572, 1.1487, 1.0486, 0.9229,\n",
      "        0.9272, 1.1466, 1.1474, 1.0714, 1.1336, 1.1428, 0.8447, 1.1321, 1.1435,\n",
      "        1.1927, 0.8578, 1.1464, 1.1393], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 151 was 9.03%\n",
      "current params: [tensor([1.1555, 0.8653, 0.8383, 0.8644, 0.7833, 1.1583, 1.1496, 1.0503, 0.9234,\n",
      "        0.9278, 1.1475, 1.1484, 1.0708, 1.1344, 1.1436, 0.8437, 1.1329, 1.1444,\n",
      "        1.1942, 0.8569, 1.1473, 1.1402], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 152 was 9.03%\n",
      "current params: [tensor([1.1566, 0.8646, 0.8371, 0.8637, 0.7816, 1.1595, 1.1506, 1.0520, 0.9239,\n",
      "        0.9285, 1.1485, 1.1493, 1.0702, 1.1351, 1.1445, 0.8426, 1.1336, 1.1453,\n",
      "        1.1958, 0.8560, 1.1483, 1.1410], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 153 was 9.04%\n",
      "current params: [tensor([1.1576, 0.8640, 0.8360, 0.8630, 0.7798, 1.1606, 1.1515, 1.0537, 0.9245,\n",
      "        0.9292, 1.1494, 1.1502, 1.0696, 1.1359, 1.1454, 0.8416, 1.1343, 1.1462,\n",
      "        1.1973, 0.8551, 1.1492, 1.1418], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 154 was 9.04%\n",
      "current params: [tensor([1.1586, 0.8634, 0.8348, 0.8623, 0.7781, 1.1617, 1.1525, 1.0554, 0.9251,\n",
      "        0.9299, 1.1503, 1.1511, 1.0690, 1.1367, 1.1463, 0.8405, 1.1350, 1.1470,\n",
      "        1.1988, 0.8542, 1.1501, 1.1427], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 155 was 9.04%\n",
      "current params: [tensor([1.1596, 0.8627, 0.8337, 0.8616, 0.7764, 1.1629, 1.1534, 1.0572, 0.9257,\n",
      "        0.9306, 1.1513, 1.1520, 1.0684, 1.1375, 1.1471, 0.8394, 1.1357, 1.1479,\n",
      "        1.2003, 0.8533, 1.1510, 1.1435], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 156 was 9.04%\n",
      "current params: [tensor([1.1606, 0.8621, 0.8325, 0.8609, 0.7746, 1.1640, 1.1544, 1.0589, 0.9263,\n",
      "        0.9314, 1.1522, 1.1529, 1.0677, 1.1382, 1.1480, 0.8384, 1.1364, 1.1488,\n",
      "        1.2018, 0.8524, 1.1520, 1.1443], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 157 was 9.04%\n",
      "current params: [tensor([1.1616, 0.8615, 0.8313, 0.8602, 0.7729, 1.1651, 1.1553, 1.0606, 0.9269,\n",
      "        0.9321, 1.1531, 1.1539, 1.0669, 1.1390, 1.1489, 0.8373, 1.1372, 1.1497,\n",
      "        1.2033, 0.8516, 1.1529, 1.1452], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 158 was 9.05%\n",
      "current params: [tensor([1.1627, 0.8609, 0.8302, 0.8596, 0.7711, 1.1663, 1.1562, 1.0624, 0.9276,\n",
      "        0.9329, 1.1541, 1.1548, 1.0662, 1.1398, 1.1497, 0.8362, 1.1379, 1.1505,\n",
      "        1.2048, 0.8507, 1.1538, 1.1460], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 159 was 9.05%\n",
      "current params: [tensor([1.1637, 0.8603, 0.8290, 0.8589, 0.7694, 1.1674, 1.1572, 1.0641, 0.9282,\n",
      "        0.9337, 1.1550, 1.1557, 1.0654, 1.1405, 1.1506, 0.8352, 1.1386, 1.1514,\n",
      "        1.2063, 0.8498, 1.1547, 1.1468], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 160 was 9.05%\n",
      "current params: [tensor([1.1647, 0.8597, 0.8278, 0.8582, 0.7676, 1.1686, 1.1581, 1.0658, 0.9289,\n",
      "        0.9345, 1.1559, 1.1566, 1.0645, 1.1413, 1.1515, 0.8341, 1.1393, 1.1523,\n",
      "        1.2079, 0.8489, 1.1557, 1.1477], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 161 was 9.05%\n",
      "current params: [tensor([1.1657, 0.8591, 0.8267, 0.8575, 0.7659, 1.1697, 1.1591, 1.0676, 0.9296,\n",
      "        0.9354, 1.1569, 1.1575, 1.0636, 1.1421, 1.1523, 0.8331, 1.1400, 1.1531,\n",
      "        1.2094, 0.8480, 1.1566, 1.1485], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 162 was 9.05%\n",
      "current params: [tensor([1.1667, 0.8585, 0.8255, 0.8569, 0.7641, 1.1709, 1.1600, 1.0693, 0.9303,\n",
      "        0.9363, 1.1578, 1.1584, 1.0627, 1.1428, 1.1532, 0.8320, 1.1407, 1.1540,\n",
      "        1.2109, 0.8471, 1.1575, 1.1493], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 163 was 9.06%\n",
      "current params: [tensor([1.1677, 0.8579, 0.8243, 0.8562, 0.7623, 1.1720, 1.1610, 1.0711, 0.9311,\n",
      "        0.9371, 1.1587, 1.1593, 1.0617, 1.1436, 1.1541, 0.8309, 1.1414, 1.1549,\n",
      "        1.2124, 0.8462, 1.1585, 1.1501], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 164 was 9.06%\n",
      "current params: [tensor([1.1688, 0.8573, 0.8231, 0.8555, 0.7605, 1.1732, 1.1619, 1.0728, 0.9318,\n",
      "        0.9380, 1.1597, 1.1603, 1.0607, 1.1443, 1.1549, 0.8299, 1.1421, 1.1557,\n",
      "        1.2140, 0.8453, 1.1594, 1.1510], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 165 was 9.06%\n",
      "current params: [tensor([1.1698, 0.8568, 0.8219, 0.8548, 0.7588, 1.1744, 1.1628, 1.0746, 0.9326,\n",
      "        0.9390, 1.1606, 1.1612, 1.0596, 1.1451, 1.1558, 0.8288, 1.1427, 1.1566,\n",
      "        1.2155, 0.8444, 1.1603, 1.1518], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 166 was 9.06%\n",
      "current params: [tensor([1.1708, 0.8562, 0.8207, 0.8542, 0.7570, 1.1755, 1.1638, 1.0763, 0.9334,\n",
      "        0.9399, 1.1615, 1.1621, 1.0584, 1.1458, 1.1567, 0.8277, 1.1434, 1.1575,\n",
      "        1.2170, 0.8435, 1.1612, 1.1526], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 167 was 9.06%\n",
      "current params: [tensor([1.1718, 0.8556, 0.8195, 0.8535, 0.7552, 1.1767, 1.1647, 1.0781, 0.9342,\n",
      "        0.9409, 1.1625, 1.1630, 1.0572, 1.1466, 1.1575, 0.8267, 1.1441, 1.1583,\n",
      "        1.2185, 0.8426, 1.1622, 1.1534], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 168 was 9.07%\n",
      "current params: [tensor([1.1728, 0.8550, 0.8183, 0.8529, 0.7534, 1.1778, 1.1657, 1.0798, 0.9351,\n",
      "        0.9419, 1.1634, 1.1639, 1.0559, 1.1473, 1.1584, 0.8256, 1.1448, 1.1592,\n",
      "        1.2201, 0.8417, 1.1631, 1.1542], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 169 was 9.07%\n",
      "current params: [tensor([1.1739, 0.8545, 0.8171, 0.8522, 0.7516, 1.1790, 1.1666, 1.0816, 0.9359,\n",
      "        0.9428, 1.1643, 1.1648, 1.0546, 1.1481, 1.1593, 0.8245, 1.1455, 1.1601,\n",
      "        1.2216, 0.8408, 1.1640, 1.1550], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 170 was 9.07%\n",
      "current params: [tensor([1.1749, 0.8539, 0.8159, 0.8515, 0.7497, 1.1802, 1.1676, 1.0833, 0.9368,\n",
      "        0.9439, 1.1653, 1.1657, 1.0533, 1.1488, 1.1601, 0.8235, 1.1461, 1.1609,\n",
      "        1.2231, 0.8400, 1.1649, 1.1559], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 171 was 9.07%\n",
      "current params: [tensor([1.1759, 0.8534, 0.8147, 0.8509, 0.7479, 1.1814, 1.1685, 1.0851, 0.9377,\n",
      "        0.9449, 1.1662, 1.1666, 1.0518, 1.1495, 1.1610, 0.8224, 1.1468, 1.1618,\n",
      "        1.2247, 0.8391, 1.1659, 1.1567], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 172 was 9.08%\n",
      "current params: [tensor([1.1769, 0.8528, 0.8134, 0.8502, 0.7461, 1.1825, 1.1695, 1.0869, 0.9386,\n",
      "        0.9459, 1.1672, 1.1675, 1.0504, 1.1503, 1.1619, 0.8213, 1.1475, 1.1627,\n",
      "        1.2262, 0.8382, 1.1668, 1.1575], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 173 was 9.08%\n",
      "current params: [tensor([1.1779, 0.8523, 0.8122, 0.8496, 0.7442, 1.1837, 1.1704, 1.0886, 0.9395,\n",
      "        0.9470, 1.1681, 1.1685, 1.0488, 1.1510, 1.1627, 0.8202, 1.1481, 1.1635,\n",
      "        1.2278, 0.8373, 1.1677, 1.1583], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 174 was 9.08%\n",
      "current params: [tensor([1.1790, 0.8517, 0.8110, 0.8489, 0.7424, 1.1849, 1.1714, 1.0904, 0.9404,\n",
      "        0.9481, 1.1690, 1.1694, 1.0472, 1.1517, 1.1636, 0.8192, 1.1488, 1.1644,\n",
      "        1.2293, 0.8364, 1.1687, 1.1591], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 175 was 9.08%\n",
      "current params: [tensor([1.1800, 0.8512, 0.8097, 0.8483, 0.7405, 1.1861, 1.1723, 1.0922, 0.9414,\n",
      "        0.9492, 1.1700, 1.1703, 1.0456, 1.1524, 1.1644, 0.8181, 1.1494, 1.1653,\n",
      "        1.2308, 0.8355, 1.1696, 1.1599], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 176 was 9.08%\n",
      "current params: [tensor([1.1810, 0.8506, 0.8085, 0.8476, 0.7387, 1.1872, 1.1733, 1.0940, 0.9423,\n",
      "        0.9503, 1.1709, 1.1712, 1.0439, 1.1531, 1.1653, 0.8170, 1.1501, 1.1661,\n",
      "        1.2324, 0.8346, 1.1705, 1.1607], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 177 was 9.09%\n",
      "current params: [tensor([1.1820, 0.8501, 0.8072, 0.8470, 0.7368, 1.1884, 1.1743, 1.0958, 0.9433,\n",
      "        0.9515, 1.1718, 1.1721, 1.0422, 1.1539, 1.1662, 0.8160, 1.1507, 1.1670,\n",
      "        1.2339, 0.8337, 1.1715, 1.1615], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 178 was 9.09%\n",
      "current params: [tensor([1.1830, 0.8496, 0.8060, 0.8463, 0.7349, 1.1896, 1.1752, 1.0975, 0.9443,\n",
      "        0.9526, 1.1728, 1.1730, 1.0404, 1.1546, 1.1670, 0.8149, 1.1514, 1.1678,\n",
      "        1.2355, 0.8328, 1.1724, 1.1623], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 179 was 9.09%\n",
      "current params: [tensor([1.1841, 0.8491, 0.8047, 0.8457, 0.7331, 1.1908, 1.1762, 1.0993, 0.9453,\n",
      "        0.9538, 1.1737, 1.1739, 1.0385, 1.1553, 1.1679, 0.8138, 1.1520, 1.1687,\n",
      "        1.2370, 0.8319, 1.1733, 1.1631], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 180 was 9.09%\n",
      "current params: [tensor([1.1851, 0.8485, 0.8034, 0.8450, 0.7312, 1.1920, 1.1771, 1.1011, 0.9464,\n",
      "        0.9550, 1.1746, 1.1748, 1.0367, 1.1560, 1.1687, 0.8127, 1.1526, 1.1696,\n",
      "        1.2386, 0.8310, 1.1743, 1.1639], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 181 was 9.09%\n",
      "current params: [tensor([1.1861, 0.8480, 0.8021, 0.8444, 0.7293, 1.1932, 1.1781, 1.1029, 0.9474,\n",
      "        0.9562, 1.1756, 1.1757, 1.0347, 1.1566, 1.1696, 0.8117, 1.1533, 1.1704,\n",
      "        1.2401, 0.8301, 1.1752, 1.1647], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 182 was 9.10%\n",
      "current params: [tensor([1.1871, 0.8475, 0.8008, 0.8437, 0.7274, 1.1944, 1.1791, 1.1047, 0.9485,\n",
      "        0.9574, 1.1765, 1.1766, 1.0328, 1.1573, 1.1705, 0.8106, 1.1539, 1.1713,\n",
      "        1.2417, 0.8292, 1.1761, 1.1655], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 183 was 9.10%\n",
      "current params: [tensor([1.1882, 0.8470, 0.7995, 0.8431, 0.7255, 1.1956, 1.1800, 1.1065, 0.9495,\n",
      "        0.9586, 1.1775, 1.1775, 1.0307, 1.1580, 1.1713, 0.8095, 1.1545, 1.1722,\n",
      "        1.2433, 0.8283, 1.1771, 1.1662], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 184 was 9.10%\n",
      "current params: [tensor([1.1892, 0.8465, 0.7982, 0.8424, 0.7235, 1.1968, 1.1810, 1.1083, 0.9506,\n",
      "        0.9599, 1.1784, 1.1784, 1.0287, 1.1587, 1.1722, 0.8084, 1.1551, 1.1730,\n",
      "        1.2448, 0.8274, 1.1780, 1.1670], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 185 was 9.10%\n",
      "current params: [tensor([1.1902, 0.8460, 0.7969, 0.8418, 0.7216, 1.1980, 1.1820, 1.1101, 0.9518,\n",
      "        0.9612, 1.1793, 1.1793, 1.0266, 1.1594, 1.1730, 0.8074, 1.1557, 1.1739,\n",
      "        1.2464, 0.8265, 1.1790, 1.1678], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 186 was 9.11%\n",
      "current params: [tensor([1.1913, 0.8455, 0.7956, 0.8411, 0.7197, 1.1992, 1.1829, 1.1119, 0.9529,\n",
      "        0.9624, 1.1803, 1.1802, 1.0245, 1.1600, 1.1739, 0.8063, 1.1563, 1.1748,\n",
      "        1.2479, 0.8256, 1.1799, 1.1686], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 187 was 9.11%\n",
      "current params: [tensor([1.1923, 0.8450, 0.7943, 0.8405, 0.7177, 1.2004, 1.1839, 1.1137, 0.9540,\n",
      "        0.9637, 1.1812, 1.1812, 1.0223, 1.1607, 1.1748, 0.8052, 1.1569, 1.1756,\n",
      "        1.2495, 0.8247, 1.1808, 1.1694], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 188 was 9.11%\n",
      "current params: [tensor([1.1933, 0.8445, 0.7930, 0.8399, 0.7158, 1.2016, 1.1849, 1.1155, 0.9552,\n",
      "        0.9651, 1.1822, 1.1821, 1.0201, 1.1613, 1.1756, 0.8041, 1.1575, 1.1765,\n",
      "        1.2511, 0.8239, 1.1818, 1.1702], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 189 was 9.11%\n",
      "current params: [tensor([1.1943, 0.8441, 0.7916, 0.8392, 0.7138, 1.2028, 1.1858, 1.1173, 0.9564,\n",
      "        0.9664, 1.1831, 1.1830, 1.0178, 1.1620, 1.1765, 0.8030, 1.1581, 1.1774,\n",
      "        1.2527, 0.8230, 1.1827, 1.1709], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 190 was 9.11%\n",
      "current params: [tensor([1.1954, 0.8436, 0.7903, 0.8386, 0.7119, 1.2040, 1.1868, 1.1191, 0.9575,\n",
      "        0.9677, 1.1841, 1.1839, 1.0156, 1.1626, 1.1773, 0.8020, 1.1587, 1.1782,\n",
      "        1.2542, 0.8221, 1.1837, 1.1717], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 191 was 9.12%\n",
      "current params: [tensor([1.1964, 0.8431, 0.7889, 0.8379, 0.7099, 1.2053, 1.1878, 1.1209, 0.9587,\n",
      "        0.9691, 1.1850, 1.1848, 1.0133, 1.1632, 1.1782, 0.8009, 1.1593, 1.1791,\n",
      "        1.2558, 0.8212, 1.1846, 1.1725], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 192 was 9.12%\n",
      "current params: [tensor([1.1974, 0.8427, 0.7876, 0.8373, 0.7079, 1.2065, 1.1888, 1.1227, 0.9600,\n",
      "        0.9705, 1.1859, 1.1857, 1.0110, 1.1638, 1.1791, 0.7998, 1.1599, 1.1800,\n",
      "        1.2574, 0.8203, 1.1856, 1.1732], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 193 was 9.12%\n",
      "current params: [tensor([1.1985, 0.8422, 0.7862, 0.8367, 0.7059, 1.2077, 1.1897, 1.1245, 0.9612,\n",
      "        0.9719, 1.1869, 1.1866, 1.0086, 1.1645, 1.1799, 0.7987, 1.1604, 1.1808,\n",
      "        1.2590, 0.8194, 1.1865, 1.1740], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 194 was 9.12%\n",
      "current params: [tensor([1.1995, 0.8418, 0.7848, 0.8360, 0.7039, 1.2090, 1.1907, 1.1263, 0.9624,\n",
      "        0.9733, 1.1878, 1.1875, 1.0063, 1.1651, 1.1808, 0.7976, 1.1610, 1.1817,\n",
      "        1.2605, 0.8185, 1.1875, 1.1748], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 195 was 9.13%\n",
      "current params: [tensor([1.2005, 0.8413, 0.7834, 0.8354, 0.7019, 1.2102, 1.1917, 1.1282, 0.9637,\n",
      "        0.9747, 1.1888, 1.1884, 1.0039, 1.1657, 1.1816, 0.7965, 1.1616, 1.1826,\n",
      "        1.2621, 0.8176, 1.1884, 1.1755], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 196 was 9.13%\n",
      "current params: [tensor([1.2016, 0.8409, 0.7820, 0.8347, 0.6999, 1.2114, 1.1927, 1.1300, 0.9650,\n",
      "        0.9761, 1.1897, 1.1893, 1.0015, 1.1663, 1.1825, 0.7955, 1.1621, 1.1834,\n",
      "        1.2637, 0.8166, 1.1894, 1.1763], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 197 was 9.13%\n",
      "current params: [tensor([1.2026, 0.8404, 0.7806, 0.8341, 0.6979, 1.2127, 1.1937, 1.1318, 0.9663,\n",
      "        0.9775, 1.1907, 1.1902, 0.9990, 1.1668, 1.1833, 0.7944, 1.1627, 1.1843,\n",
      "        1.2653, 0.8157, 1.1903, 1.1771], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 198 was 9.13%\n",
      "current params: [tensor([1.2036, 0.8400, 0.7792, 0.8335, 0.6959, 1.2139, 1.1947, 1.1336, 0.9676,\n",
      "        0.9790, 1.1916, 1.1911, 0.9966, 1.1674, 1.1842, 0.7933, 1.1632, 1.1852,\n",
      "        1.2669, 0.8148, 1.1913, 1.1778], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 199 was 9.13%\n",
      "current params: [tensor([1.2047, 0.8396, 0.7778, 0.8328, 0.6939, 1.2151, 1.1956, 1.1355, 0.9689,\n",
      "        0.9805, 1.1926, 1.1920, 0.9941, 1.1680, 1.1851, 0.7922, 1.1638, 1.1860,\n",
      "        1.2685, 0.8139, 1.1922, 1.1786], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 200 was 9.14%\n",
      "current params: [tensor([1.2057, 0.8392, 0.7764, 0.8322, 0.6918, 1.2164, 1.1966, 1.1373, 0.9702,\n",
      "        0.9820, 1.1935, 1.1929, 0.9916, 1.1685, 1.1859, 0.7911, 1.1643, 1.1869,\n",
      "        1.2701, 0.8130, 1.1932, 1.1793], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 201 was 9.14%\n",
      "current params: [tensor([1.2068, 0.8388, 0.7750, 0.8316, 0.6898, 1.2176, 1.1976, 1.1391, 0.9715,\n",
      "        0.9835, 1.1945, 1.1938, 0.9891, 1.1691, 1.1868, 0.7900, 1.1648, 1.1878,\n",
      "        1.2717, 0.8121, 1.1941, 1.1801], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 202 was 9.14%\n",
      "current params: [tensor([1.2078, 0.8383, 0.7735, 0.8309, 0.6878, 1.2189, 1.1986, 1.1410, 0.9729,\n",
      "        0.9850, 1.1954, 1.1947, 0.9866, 1.1696, 1.1876, 0.7889, 1.1654, 1.1886,\n",
      "        1.2733, 0.8112, 1.1951, 1.1808], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 203 was 9.14%\n",
      "current params: [tensor([1.2088, 0.8379, 0.7721, 0.8303, 0.6857, 1.2202, 1.1996, 1.1428, 0.9743,\n",
      "        0.9865, 1.1964, 1.1956, 0.9841, 1.1701, 1.1885, 0.7879, 1.1659, 1.1895,\n",
      "        1.2749, 0.8103, 1.1960, 1.1815], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 204 was 9.15%\n",
      "current params: [tensor([1.2099, 0.8376, 0.7706, 0.8297, 0.6836, 1.2214, 1.2006, 1.1447, 0.9757,\n",
      "        0.9880, 1.1973, 1.1965, 0.9815, 1.1707, 1.1893, 0.7868, 1.1664, 1.1904,\n",
      "        1.2765, 0.8094, 1.1970, 1.1823], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 205 was 9.15%\n",
      "current params: [tensor([1.2109, 0.8372, 0.7691, 0.8290, 0.6816, 1.2227, 1.2016, 1.1465, 0.9770,\n",
      "        0.9896, 1.1983, 1.1974, 0.9790, 1.1712, 1.1902, 0.7857, 1.1669, 1.1913,\n",
      "        1.2782, 0.8085, 1.1980, 1.1830], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 206 was 9.15%\n",
      "current params: [tensor([1.2120, 0.8368, 0.7677, 0.8284, 0.6795, 1.2240, 1.2026, 1.1484, 0.9785,\n",
      "        0.9911, 1.1992, 1.1983, 0.9764, 1.1717, 1.1911, 0.7846, 1.1674, 1.1921,\n",
      "        1.2798, 0.8076, 1.1989, 1.1838], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 207 was 9.15%\n",
      "current params: [tensor([1.2130, 0.8364, 0.7662, 0.8277, 0.6774, 1.2252, 1.2036, 1.1502, 0.9799,\n",
      "        0.9927, 1.2002, 1.1992, 0.9738, 1.1722, 1.1919, 0.7835, 1.1679, 1.1930,\n",
      "        1.2814, 0.8067, 1.1999, 1.1845], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 208 was 9.15%\n",
      "current params: [tensor([1.2141, 0.8360, 0.7647, 0.8271, 0.6753, 1.2265, 1.2046, 1.1521, 0.9813,\n",
      "        0.9943, 1.2011, 1.2001, 0.9712, 1.1727, 1.1928, 0.7824, 1.1684, 1.1939,\n",
      "        1.2830, 0.8058, 1.2008, 1.1852], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 209 was 9.16%\n",
      "current params: [tensor([1.2151, 0.8357, 0.7632, 0.8265, 0.6732, 1.2278, 1.2056, 1.1539, 0.9827,\n",
      "        0.9959, 1.2021, 1.2010, 0.9686, 1.1731, 1.1936, 0.7813, 1.1689, 1.1947,\n",
      "        1.2846, 0.8048, 1.2018, 1.1860], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 210 was 9.16%\n",
      "current params: [tensor([1.2162, 0.8353, 0.7617, 0.8258, 0.6712, 1.2291, 1.2066, 1.1558, 0.9842,\n",
      "        0.9975, 1.2030, 1.2019, 0.9660, 1.1736, 1.1945, 0.7802, 1.1694, 1.1956,\n",
      "        1.2863, 0.8039, 1.2028, 1.1867], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 211 was 9.16%\n",
      "current params: [tensor([1.2172, 0.8350, 0.7602, 0.8252, 0.6690, 1.2303, 1.2077, 1.1576, 0.9857,\n",
      "        0.9991, 1.2040, 1.2028, 0.9634, 1.1740, 1.1953, 0.7791, 1.1699, 1.1965,\n",
      "        1.2879, 0.8030, 1.2037, 1.1874], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 212 was 9.16%\n",
      "current params: [tensor([1.2183, 0.8346, 0.7587, 0.8246, 0.6669, 1.2316, 1.2087, 1.1595, 0.9872,\n",
      "        1.0007, 1.2050, 1.2037, 0.9608, 1.1745, 1.1962, 0.7780, 1.1703, 1.1973,\n",
      "        1.2895, 0.8021, 1.2047, 1.1881], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 213 was 9.17%\n",
      "current params: [tensor([1.2193, 0.8343, 0.7571, 0.8239, 0.6648, 1.2329, 1.2097, 1.1614, 0.9886,\n",
      "        1.0024, 1.2059, 1.2046, 0.9582, 1.1749, 1.1970, 0.7769, 1.1708, 1.1982,\n",
      "        1.2912, 0.8012, 1.2057, 1.1889], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 214 was 9.17%\n",
      "current params: [tensor([1.2204, 0.8340, 0.7556, 0.8233, 0.6627, 1.2342, 1.2107, 1.1632, 0.9901,\n",
      "        1.0040, 1.2069, 1.2055, 0.9556, 1.1753, 1.1979, 0.7759, 1.1713, 1.1991,\n",
      "        1.2928, 0.8002, 1.2067, 1.1896], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 215 was 9.17%\n",
      "current params: [tensor([1.2214, 0.8337, 0.7540, 0.8227, 0.6606, 1.2355, 1.2117, 1.1651, 0.9917,\n",
      "        1.0057, 1.2078, 1.2064, 0.9529, 1.1757, 1.1988, 0.7748, 1.1717, 1.2000,\n",
      "        1.2944, 0.7993, 1.2076, 1.1903], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 216 was 9.17%\n",
      "current params: [tensor([1.2225, 0.8334, 0.7525, 0.8220, 0.6584, 1.2368, 1.2127, 1.1670, 0.9932,\n",
      "        1.0073, 1.2088, 1.2073, 0.9503, 1.1761, 1.1996, 0.7737, 1.1722, 1.2008,\n",
      "        1.2961, 0.7984, 1.2086, 1.1910], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 217 was 9.18%\n",
      "current params: [tensor([1.2235, 0.8330, 0.7509, 0.8214, 0.6563, 1.2381, 1.2138, 1.1688, 0.9947,\n",
      "        1.0090, 1.2098, 1.2082, 0.9476, 1.1765, 1.2005, 0.7726, 1.1726, 1.2017,\n",
      "        1.2977, 0.7975, 1.2096, 1.1917], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 218 was 9.18%\n",
      "current params: [tensor([1.2246, 0.8328, 0.7493, 0.8207, 0.6542, 1.2394, 1.2148, 1.1707, 0.9963,\n",
      "        1.0107, 1.2107, 1.2091, 0.9450, 1.1768, 1.2013, 0.7715, 1.1730, 1.2026,\n",
      "        1.2994, 0.7966, 1.2106, 1.1924], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 219 was 9.18%\n",
      "current params: [tensor([1.2256, 0.8325, 0.7478, 0.8201, 0.6520, 1.2408, 1.2158, 1.1726, 0.9978,\n",
      "        1.0124, 1.2117, 1.2100, 0.9423, 1.1772, 1.2022, 0.7704, 1.1734, 1.2035,\n",
      "        1.3010, 0.7956, 1.2115, 1.1931], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 220 was 9.18%\n",
      "current params: [tensor([1.2267, 0.8322, 0.7462, 0.8195, 0.6498, 1.2421, 1.2168, 1.1745, 0.9994,\n",
      "        1.0141, 1.2127, 1.2109, 0.9397, 1.1775, 1.2030, 0.7693, 1.1739, 1.2043,\n",
      "        1.3027, 0.7947, 1.2125, 1.1938], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 221 was 9.19%\n",
      "current params: [tensor([1.2278, 0.8319, 0.7446, 0.8188, 0.6477, 1.2434, 1.2179, 1.1764, 1.0010,\n",
      "        1.0158, 1.2136, 1.2118, 0.9370, 1.1778, 1.2039, 0.7682, 1.1743, 1.2052,\n",
      "        1.3044, 0.7938, 1.2135, 1.1945], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 222 was 9.19%\n",
      "current params: [tensor([1.2288, 0.8317, 0.7429, 0.8182, 0.6455, 1.2447, 1.2189, 1.1783, 1.0026,\n",
      "        1.0176, 1.2146, 1.2127, 0.9343, 1.1781, 1.2047, 0.7671, 1.1747, 1.2061,\n",
      "        1.3060, 0.7928, 1.2145, 1.1952], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 223 was 9.19%\n",
      "current params: [tensor([1.2299, 0.8314, 0.7413, 0.8175, 0.6433, 1.2460, 1.2199, 1.1802, 1.0042,\n",
      "        1.0193, 1.2156, 1.2136, 0.9317, 1.1784, 1.2056, 0.7660, 1.1751, 1.2070,\n",
      "        1.3077, 0.7919, 1.2155, 1.1959], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 224 was 9.19%\n",
      "current params: [tensor([1.2310, 0.8312, 0.7397, 0.8169, 0.6412, 1.2474, 1.2210, 1.1820, 1.0058,\n",
      "        1.0210, 1.2165, 1.2145, 0.9290, 1.1787, 1.2065, 0.7649, 1.1755, 1.2078,\n",
      "        1.3094, 0.7910, 1.2165, 1.1966], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 225 was 9.20%\n",
      "current params: [tensor([1.2320, 0.8309, 0.7381, 0.8162, 0.6390, 1.2487, 1.2220, 1.1839, 1.0074,\n",
      "        1.0228, 1.2175, 1.2154, 0.9263, 1.1790, 1.2073, 0.7638, 1.1759, 1.2087,\n",
      "        1.3110, 0.7900, 1.2175, 1.1973], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 226 was 9.20%\n",
      "current params: [tensor([1.2331, 0.8307, 0.7364, 0.8156, 0.6368, 1.2500, 1.2231, 1.1858, 1.0090,\n",
      "        1.0245, 1.2185, 1.2163, 0.9237, 1.1792, 1.2082, 0.7627, 1.1762, 1.2096,\n",
      "        1.3127, 0.7891, 1.2184, 1.1980], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 227 was 9.20%\n",
      "current params: [tensor([1.2341, 0.8305, 0.7348, 0.8149, 0.6346, 1.2514, 1.2241, 1.1877, 1.0107,\n",
      "        1.0263, 1.2195, 1.2172, 0.9210, 1.1795, 1.2090, 0.7616, 1.1766, 1.2105,\n",
      "        1.3144, 0.7881, 1.2194, 1.1986], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 228 was 9.20%\n",
      "current params: [tensor([1.2352, 0.8303, 0.7331, 0.8143, 0.6324, 1.2527, 1.2251, 1.1896, 1.0123,\n",
      "        1.0281, 1.2204, 1.2181, 0.9183, 1.1797, 1.2099, 0.7605, 1.1770, 1.2113,\n",
      "        1.3161, 0.7872, 1.2204, 1.1993], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 229 was 9.21%\n",
      "current params: [tensor([1.2363, 0.8301, 0.7314, 0.8136, 0.6302, 1.2541, 1.2262, 1.1916, 1.0140,\n",
      "        1.0299, 1.2214, 1.2190, 0.9156, 1.1799, 1.2107, 0.7594, 1.1773, 1.2122,\n",
      "        1.3177, 0.7862, 1.2214, 1.2000], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 230 was 9.20%\n",
      "current params: [tensor([1.2373, 0.8299, 0.7298, 0.8130, 0.6280, 1.2554, 1.2272, 1.1935, 1.0156,\n",
      "        1.0317, 1.2224, 1.2199, 0.9130, 1.1801, 1.2116, 0.7583, 1.1777, 1.2131,\n",
      "        1.3194, 0.7853, 1.2224, 1.2007], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 231 was 9.21%\n",
      "current params: [tensor([1.2384, 0.8297, 0.7281, 0.8124, 0.6258, 1.2568, 1.2283, 1.1954, 1.0173,\n",
      "        1.0335, 1.2234, 1.2208, 0.9103, 1.1803, 1.2124, 0.7572, 1.1780, 1.2140,\n",
      "        1.3211, 0.7844, 1.2234, 1.2013], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 232 was 9.21%\n",
      "current params: [tensor([1.2395, 0.8295, 0.7264, 0.8117, 0.6237, 1.2581, 1.2293, 1.1973, 1.0190,\n",
      "        1.0353, 1.2244, 1.2217, 0.9077, 1.1805, 1.2133, 0.7561, 1.1784, 1.2148,\n",
      "        1.3228, 0.7834, 1.2244, 1.2020], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 233 was 9.21%\n",
      "current params: [tensor([1.2405, 0.8294, 0.7248, 0.8111, 0.6215, 1.2595, 1.2303, 1.1992, 1.0207,\n",
      "        1.0371, 1.2253, 1.2226, 0.9052, 1.1807, 1.2141, 0.7550, 1.1788, 1.2157,\n",
      "        1.3245, 0.7825, 1.2254, 1.2027], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 234 was 9.21%\n",
      "current params: [tensor([1.2416, 0.8293, 0.7231, 0.8105, 0.6194, 1.2608, 1.2314, 1.2011, 1.0224,\n",
      "        1.0389, 1.2263, 1.2235, 0.9026, 1.1809, 1.2150, 0.7539, 1.1791, 1.2166,\n",
      "        1.3261, 0.7815, 1.2264, 1.2034], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 235 was 9.22%\n",
      "current params: [tensor([1.2426, 0.8292, 0.7215, 0.8099, 0.6172, 1.2622, 1.2324, 1.2030, 1.0241,\n",
      "        1.0407, 1.2273, 1.2244, 0.9000, 1.1811, 1.2158, 0.7527, 1.1795, 1.2174,\n",
      "        1.3278, 0.7806, 1.2273, 1.2041], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 236 was 9.22%\n",
      "current params: [tensor([1.2437, 0.8291, 0.7198, 0.8093, 0.6151, 1.2635, 1.2334, 1.2049, 1.0258,\n",
      "        1.0425, 1.2283, 1.2253, 0.8975, 1.1812, 1.2166, 0.7516, 1.1799, 1.2183,\n",
      "        1.3295, 0.7796, 1.2283, 1.2047], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 237 was 9.22%\n",
      "current params: [tensor([1.2448, 0.8290, 0.7182, 0.8087, 0.6129, 1.2649, 1.2344, 1.2068, 1.0275,\n",
      "        1.0444, 1.2292, 1.2261, 0.8949, 1.1814, 1.2175, 0.7505, 1.1802, 1.2191,\n",
      "        1.3312, 0.7787, 1.2293, 1.2054], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 238 was 9.22%\n",
      "current params: [tensor([1.2458, 0.8290, 0.7165, 0.8081, 0.6108, 1.2663, 1.2355, 1.2087, 1.0293,\n",
      "        1.0462, 1.2302, 1.2270, 0.8924, 1.1816, 1.2183, 0.7494, 1.1806, 1.2200,\n",
      "        1.3329, 0.7777, 1.2303, 1.2061], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 239 was 9.23%\n",
      "current params: [tensor([1.2469, 0.8289, 0.7148, 0.8076, 0.6086, 1.2676, 1.2365, 1.2107, 1.0310,\n",
      "        1.0481, 1.2312, 1.2279, 0.8898, 1.1817, 1.2192, 0.7483, 1.1809, 1.2209,\n",
      "        1.3346, 0.7768, 1.2313, 1.2068], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 240 was 9.23%\n",
      "current params: [tensor([1.2479, 0.8289, 0.7132, 0.8070, 0.6065, 1.2690, 1.2375, 1.2126, 1.0328,\n",
      "        1.0499, 1.2321, 1.2288, 0.8873, 1.1818, 1.2200, 0.7472, 1.1813, 1.2217,\n",
      "        1.3362, 0.7759, 1.2322, 1.2075], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 241 was 9.23%\n",
      "current params: [tensor([1.2490, 0.8289, 0.7115, 0.8064, 0.6043, 1.2704, 1.2385, 1.2145, 1.0345,\n",
      "        1.0518, 1.2331, 1.2297, 0.8848, 1.1819, 1.2208, 0.7461, 1.1816, 1.2226,\n",
      "        1.3379, 0.7749, 1.2332, 1.2081], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 242 was 9.23%\n",
      "current params: [tensor([1.2500, 0.8288, 0.7098, 0.8058, 0.6022, 1.2718, 1.2396, 1.2164, 1.0363,\n",
      "        1.0536, 1.2341, 1.2305, 0.8822, 1.1820, 1.2217, 0.7450, 1.1820, 1.2234,\n",
      "        1.3396, 0.7740, 1.2342, 1.2088], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 243 was 9.24%\n",
      "current params: [tensor([1.2511, 0.8288, 0.7081, 0.8052, 0.6000, 1.2731, 1.2406, 1.2183, 1.0380,\n",
      "        1.0555, 1.2351, 1.2314, 0.8797, 1.1821, 1.2225, 0.7439, 1.1823, 1.2243,\n",
      "        1.3413, 0.7730, 1.2352, 1.2095], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 244 was 9.24%\n",
      "current params: [tensor([1.2521, 0.8289, 0.7064, 0.8047, 0.5979, 1.2745, 1.2416, 1.2203, 1.0398,\n",
      "        1.0574, 1.2361, 1.2323, 0.8771, 1.1822, 1.2233, 0.7428, 1.1826, 1.2251,\n",
      "        1.3430, 0.7720, 1.2362, 1.2101], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 245 was 9.24%\n",
      "current params: [tensor([1.2532, 0.8289, 0.7047, 0.8041, 0.5957, 1.2759, 1.2426, 1.2222, 1.0416,\n",
      "        1.0592, 1.2370, 1.2332, 0.8746, 1.1823, 1.2241, 0.7417, 1.1830, 1.2260,\n",
      "        1.3447, 0.7711, 1.2371, 1.2108], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 246 was 9.25%\n",
      "current params: [tensor([1.2542, 0.8289, 0.7030, 0.8035, 0.5936, 1.2773, 1.2437, 1.2241, 1.0434,\n",
      "        1.0611, 1.2380, 1.2340, 0.8720, 1.1823, 1.2250, 0.7406, 1.1833, 1.2268,\n",
      "        1.3464, 0.7701, 1.2381, 1.2115], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 247 was 9.25%\n",
      "current params: [tensor([1.2553, 0.8290, 0.7013, 0.8029, 0.5914, 1.2787, 1.2447, 1.2260, 1.0452,\n",
      "        1.0630, 1.2390, 1.2349, 0.8695, 1.1823, 1.2258, 0.7395, 1.1836, 1.2277,\n",
      "        1.3481, 0.7692, 1.2391, 1.2121], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 248 was 9.25%\n",
      "current params: [tensor([1.2564, 0.8291, 0.6995, 0.8024, 0.5892, 1.2801, 1.2457, 1.2280, 1.0470,\n",
      "        1.0649, 1.2400, 1.2358, 0.8669, 1.1823, 1.2266, 0.7383, 1.1839, 1.2285,\n",
      "        1.3498, 0.7682, 1.2401, 1.2128], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 249 was 9.25%\n",
      "current params: [tensor([1.2574, 0.8291, 0.6978, 0.8018, 0.5871, 1.2815, 1.2468, 1.2299, 1.0488,\n",
      "        1.0668, 1.2410, 1.2366, 0.8643, 1.1823, 1.2275, 0.7372, 1.1842, 1.2294,\n",
      "        1.3515, 0.7672, 1.2411, 1.2134], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 250 was 9.26%\n",
      "current params: [tensor([1.2585, 0.8292, 0.6961, 0.8012, 0.5849, 1.2829, 1.2478, 1.2318, 1.0506,\n",
      "        1.0687, 1.2420, 1.2375, 0.8617, 1.1823, 1.2283, 0.7361, 1.1845, 1.2302,\n",
      "        1.3532, 0.7663, 1.2421, 1.2141], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 251 was 9.26%\n",
      "current params: [tensor([1.2595, 0.8293, 0.6943, 0.8006, 0.5827, 1.2843, 1.2488, 1.2338, 1.0524,\n",
      "        1.0706, 1.2429, 1.2384, 0.8592, 1.1822, 1.2291, 0.7350, 1.1848, 1.2311,\n",
      "        1.3549, 0.7653, 1.2431, 1.2147], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 252 was 9.26%\n",
      "current params: [tensor([1.2606, 0.8294, 0.6925, 0.8000, 0.5805, 1.2857, 1.2499, 1.2357, 1.0542,\n",
      "        1.0725, 1.2439, 1.2393, 0.8566, 1.1822, 1.2300, 0.7339, 1.1851, 1.2319,\n",
      "        1.3567, 0.7643, 1.2440, 1.2154], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 253 was 9.26%\n",
      "current params: [tensor([1.2617, 0.8296, 0.6908, 0.7994, 0.5783, 1.2871, 1.2509, 1.2377, 1.0560,\n",
      "        1.0744, 1.2449, 1.2401, 0.8540, 1.1821, 1.2308, 0.7328, 1.1853, 1.2328,\n",
      "        1.3584, 0.7633, 1.2450, 1.2160], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 254 was 9.27%\n",
      "current params: [tensor([1.2627, 0.8297, 0.6890, 0.7989, 0.5761, 1.2885, 1.2519, 1.2396, 1.0579,\n",
      "        1.0763, 1.2459, 1.2410, 0.8514, 1.1820, 1.2316, 0.7317, 1.1856, 1.2337,\n",
      "        1.3601, 0.7624, 1.2460, 1.2167], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 255 was 9.27%\n",
      "current params: [tensor([1.2638, 0.8299, 0.6872, 0.7983, 0.5739, 1.2899, 1.2530, 1.2415, 1.0597,\n",
      "        1.0782, 1.2469, 1.2419, 0.8488, 1.1819, 1.2324, 0.7305, 1.1858, 1.2345,\n",
      "        1.3618, 0.7614, 1.2470, 1.2173], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 256 was 9.27%\n",
      "current params: [tensor([1.2648, 0.8300, 0.6854, 0.7977, 0.5717, 1.2913, 1.2540, 1.2435, 1.0615,\n",
      "        1.0801, 1.2479, 1.2427, 0.8462, 1.1817, 1.2333, 0.7294, 1.1861, 1.2354,\n",
      "        1.3635, 0.7604, 1.2480, 1.2179], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 257 was 9.27%\n",
      "current params: [tensor([1.2659, 0.8302, 0.6836, 0.7971, 0.5695, 1.2928, 1.2551, 1.2454, 1.0634,\n",
      "        1.0821, 1.2489, 1.2436, 0.8436, 1.1816, 1.2341, 0.7283, 1.1863, 1.2362,\n",
      "        1.3653, 0.7594, 1.2490, 1.2186], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 258 was 9.28%\n",
      "current params: [tensor([1.2670, 0.8304, 0.6818, 0.7965, 0.5673, 1.2942, 1.2561, 1.2474, 1.0652,\n",
      "        1.0840, 1.2499, 1.2445, 0.8410, 1.1814, 1.2349, 0.7272, 1.1866, 1.2371,\n",
      "        1.3670, 0.7584, 1.2500, 1.2192], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 259 was 9.28%\n",
      "current params: [tensor([1.2680, 0.8306, 0.6800, 0.7959, 0.5651, 1.2956, 1.2572, 1.2493, 1.0671,\n",
      "        1.0859, 1.2509, 1.2454, 0.8383, 1.1812, 1.2358, 0.7261, 1.1868, 1.2379,\n",
      "        1.3687, 0.7574, 1.2510, 1.2198], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 260 was 9.28%\n",
      "current params: [tensor([1.2691, 0.8309, 0.6782, 0.7953, 0.5628, 1.2971, 1.2582, 1.2513, 1.0690,\n",
      "        1.0878, 1.2519, 1.2462, 0.8357, 1.1809, 1.2366, 0.7250, 1.1870, 1.2388,\n",
      "        1.3704, 0.7564, 1.2520, 1.2204], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 261 was 9.29%\n",
      "current params: [tensor([1.2702, 0.8311, 0.6763, 0.7947, 0.5606, 1.2985, 1.2593, 1.2532, 1.0708,\n",
      "        1.0898, 1.2529, 1.2471, 0.8331, 1.1807, 1.2374, 0.7238, 1.1872, 1.2396,\n",
      "        1.3722, 0.7554, 1.2530, 1.2211], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 262 was 9.29%\n",
      "current params: [tensor([1.2712, 0.8313, 0.6745, 0.7941, 0.5584, 1.2999, 1.2603, 1.2552, 1.0727,\n",
      "        1.0917, 1.2539, 1.2480, 0.8304, 1.1804, 1.2382, 0.7227, 1.1874, 1.2405,\n",
      "        1.3739, 0.7544, 1.2540, 1.2217], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 263 was 9.29%\n",
      "current params: [tensor([1.2723, 0.8316, 0.6726, 0.7934, 0.5561, 1.3014, 1.2614, 1.2572, 1.0746,\n",
      "        1.0937, 1.2549, 1.2488, 0.8278, 1.1801, 1.2391, 0.7216, 1.1876, 1.2414,\n",
      "        1.3757, 0.7534, 1.2550, 1.2223], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 264 was 9.29%\n",
      "current params: [tensor([1.2734, 0.8319, 0.6707, 0.7928, 0.5539, 1.3028, 1.2625, 1.2591, 1.0764,\n",
      "        1.0956, 1.2559, 1.2497, 0.8252, 1.1798, 1.2399, 0.7205, 1.1877, 1.2422,\n",
      "        1.3774, 0.7524, 1.2560, 1.2229], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 265 was 9.30%\n",
      "current params: [tensor([1.2744, 0.8322, 0.6689, 0.7922, 0.5516, 1.3043, 1.2635, 1.2611, 1.0783,\n",
      "        1.0976, 1.2569, 1.2506, 0.8225, 1.1794, 1.2407, 0.7194, 1.1879, 1.2431,\n",
      "        1.3792, 0.7514, 1.2571, 1.2235], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 266 was 9.30%\n",
      "current params: [tensor([1.2755, 0.8325, 0.6670, 0.7916, 0.5494, 1.3057, 1.2646, 1.2631, 1.0802,\n",
      "        1.0995, 1.2579, 1.2515, 0.8199, 1.1790, 1.2416, 0.7182, 1.1881, 1.2439,\n",
      "        1.3809, 0.7503, 1.2581, 1.2241], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 267 was 9.30%\n",
      "current params: [tensor([1.2766, 0.8328, 0.6651, 0.7909, 0.5471, 1.3072, 1.2657, 1.2650, 1.0821,\n",
      "        1.1015, 1.2589, 1.2523, 0.8172, 1.1786, 1.2424, 0.7171, 1.1882, 1.2448,\n",
      "        1.3827, 0.7493, 1.2591, 1.2247], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 268 was 9.31%\n",
      "current params: [tensor([1.2777, 0.8331, 0.6632, 0.7903, 0.5448, 1.3086, 1.2667, 1.2670, 1.0840,\n",
      "        1.1034, 1.2600, 1.2532, 0.8145, 1.1782, 1.2432, 0.7160, 1.1883, 1.2456,\n",
      "        1.3844, 0.7483, 1.2601, 1.2253], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 269 was 9.31%\n",
      "current params: [tensor([1.2787, 0.8335, 0.6613, 0.7897, 0.5425, 1.3101, 1.2678, 1.2690, 1.0859,\n",
      "        1.1054, 1.2610, 1.2541, 0.8119, 1.1778, 1.2441, 0.7149, 1.1885, 1.2465,\n",
      "        1.3862, 0.7472, 1.2611, 1.2259], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 270 was 9.31%\n",
      "current params: [tensor([1.2798, 0.8339, 0.6594, 0.7890, 0.5403, 1.3116, 1.2689, 1.2709, 1.0878,\n",
      "        1.1074, 1.2620, 1.2549, 0.8092, 1.1773, 1.2449, 0.7137, 1.1886, 1.2474,\n",
      "        1.3879, 0.7462, 1.2622, 1.2265], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 271 was 9.31%\n",
      "current params: [tensor([1.2809, 0.8342, 0.6574, 0.7884, 0.5380, 1.3130, 1.2700, 1.2729, 1.0897,\n",
      "        1.1093, 1.2630, 1.2558, 0.8065, 1.1768, 1.2457, 0.7126, 1.1887, 1.2482,\n",
      "        1.3897, 0.7452, 1.2632, 1.2270], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 272 was 9.32%\n",
      "current params: [tensor([1.2820, 0.8346, 0.6555, 0.7877, 0.5357, 1.3145, 1.2710, 1.2749, 1.0916,\n",
      "        1.1113, 1.2640, 1.2567, 0.8039, 1.1763, 1.2466, 0.7115, 1.1888, 1.2491,\n",
      "        1.3915, 0.7441, 1.2642, 1.2276], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 273 was 9.32%\n",
      "current params: [tensor([1.2830, 0.8350, 0.6535, 0.7870, 0.5334, 1.3160, 1.2721, 1.2769, 1.0935,\n",
      "        1.1133, 1.2651, 1.2576, 0.8012, 1.1757, 1.2474, 0.7104, 1.1889, 1.2500,\n",
      "        1.3932, 0.7431, 1.2652, 1.2282], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 274 was 9.32%\n",
      "current params: [tensor([1.2841, 0.8355, 0.6516, 0.7864, 0.5311, 1.3175, 1.2732, 1.2789, 1.0954,\n",
      "        1.1153, 1.2661, 1.2584, 0.7985, 1.1751, 1.2482, 0.7092, 1.1890, 1.2508,\n",
      "        1.3950, 0.7420, 1.2663, 1.2287], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 275 was 9.33%\n",
      "current params: [tensor([1.2852, 0.8359, 0.6496, 0.7857, 0.5288, 1.3190, 1.2743, 1.2808, 1.0974,\n",
      "        1.1173, 1.2671, 1.2593, 0.7958, 1.1745, 1.2491, 0.7081, 1.1890, 1.2517,\n",
      "        1.3968, 0.7409, 1.2673, 1.2293], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 276 was 9.33%\n",
      "current params: [tensor([1.2863, 0.8364, 0.6476, 0.7850, 0.5265, 1.3205, 1.2754, 1.2828, 1.0993,\n",
      "        1.1192, 1.2681, 1.2602, 0.7932, 1.1738, 1.2499, 0.7070, 1.1891, 1.2525,\n",
      "        1.3986, 0.7399, 1.2683, 1.2299], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 277 was 9.33%\n",
      "current params: [tensor([1.2874, 0.8368, 0.6457, 0.7843, 0.5242, 1.3220, 1.2765, 1.2848, 1.1012,\n",
      "        1.1212, 1.2692, 1.2610, 0.7905, 1.1732, 1.2507, 0.7058, 1.1891, 1.2534,\n",
      "        1.4003, 0.7388, 1.2694, 1.2304], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 278 was 9.34%\n",
      "current params: [tensor([1.2885, 0.8373, 0.6437, 0.7836, 0.5218, 1.3235, 1.2776, 1.2868, 1.1032,\n",
      "        1.1232, 1.2702, 1.2619, 0.7878, 1.1725, 1.2516, 0.7047, 1.1891, 1.2543,\n",
      "        1.4021, 0.7377, 1.2704, 1.2310], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 279 was 9.34%\n",
      "current params: [tensor([1.2895, 0.8379, 0.6417, 0.7829, 0.5195, 1.3250, 1.2787, 1.2888, 1.1051,\n",
      "        1.1252, 1.2712, 1.2628, 0.7851, 1.1717, 1.2524, 0.7036, 1.1892, 1.2551,\n",
      "        1.4039, 0.7366, 1.2714, 1.2315], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 280 was 9.34%\n",
      "current params: [tensor([1.2906, 0.8384, 0.6397, 0.7822, 0.5172, 1.3265, 1.2798, 1.2908, 1.1070,\n",
      "        1.1272, 1.2723, 1.2637, 0.7824, 1.1710, 1.2532, 0.7025, 1.1892, 1.2560,\n",
      "        1.4057, 0.7355, 1.2725, 1.2321], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 281 was 9.35%\n",
      "current params: [tensor([1.2917, 0.8389, 0.6377, 0.7815, 0.5149, 1.3280, 1.2809, 1.2928, 1.1090,\n",
      "        1.1292, 1.2733, 1.2645, 0.7797, 1.1702, 1.2541, 0.7013, 1.1892, 1.2569,\n",
      "        1.4075, 0.7344, 1.2735, 1.2326], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 282 was 9.35%\n",
      "current params: [tensor([1.2928, 0.8395, 0.6356, 0.7808, 0.5125, 1.3295, 1.2820, 1.2948, 1.1109,\n",
      "        1.1312, 1.2744, 1.2654, 0.7770, 1.1694, 1.2549, 0.7002, 1.1891, 1.2577,\n",
      "        1.4093, 0.7333, 1.2746, 1.2331], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 283 was 9.35%\n",
      "current params: [tensor([1.2939, 0.8401, 0.6336, 0.7801, 0.5102, 1.3310, 1.2831, 1.2968, 1.1129,\n",
      "        1.1332, 1.2754, 1.2663, 0.7743, 1.1685, 1.2557, 0.6991, 1.1891, 1.2586,\n",
      "        1.4111, 0.7322, 1.2756, 1.2337], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 284 was 9.36%\n",
      "current params: [tensor([1.2950, 0.8407, 0.6316, 0.7794, 0.5078, 1.3325, 1.2842, 1.2988, 1.1148,\n",
      "        1.1352, 1.2765, 1.2672, 0.7716, 1.1676, 1.2566, 0.6979, 1.1891, 1.2595,\n",
      "        1.4129, 0.7311, 1.2767, 1.2342], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 285 was 9.36%\n",
      "current params: [tensor([1.2961, 0.8413, 0.6295, 0.7786, 0.5055, 1.3341, 1.2853, 1.3008, 1.1168,\n",
      "        1.1372, 1.2775, 1.2680, 0.7689, 1.1667, 1.2574, 0.6968, 1.1890, 1.2604,\n",
      "        1.4147, 0.7300, 1.2777, 1.2347], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 286 was 9.36%\n",
      "current params: [tensor([1.2972, 0.8419, 0.6275, 0.7779, 0.5031, 1.3356, 1.2864, 1.3028, 1.1188,\n",
      "        1.1392, 1.2786, 1.2689, 0.7662, 1.1658, 1.2583, 0.6956, 1.1889, 1.2612,\n",
      "        1.4165, 0.7289, 1.2788, 1.2352], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 287 was 9.37%\n",
      "current params: [tensor([1.2982, 0.8426, 0.6254, 0.7771, 0.5008, 1.3371, 1.2876, 1.3049, 1.1207,\n",
      "        1.1413, 1.2796, 1.2698, 0.7635, 1.1648, 1.2591, 0.6945, 1.1889, 1.2621,\n",
      "        1.4183, 0.7277, 1.2798, 1.2357], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 288 was 9.37%\n",
      "current params: [tensor([1.2993, 0.8432, 0.6233, 0.7764, 0.4984, 1.3387, 1.2887, 1.3069, 1.1227,\n",
      "        1.1433, 1.2807, 1.2706, 0.7608, 1.1638, 1.2599, 0.6934, 1.1888, 1.2630,\n",
      "        1.4201, 0.7266, 1.2809, 1.2362], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 289 was 9.37%\n",
      "current params: [tensor([1.3004, 0.8439, 0.6212, 0.7756, 0.4960, 1.3402, 1.2898, 1.3089, 1.1247,\n",
      "        1.1453, 1.2817, 1.2715, 0.7580, 1.1627, 1.2608, 0.6922, 1.1887, 1.2638,\n",
      "        1.4220, 0.7255, 1.2820, 1.2367], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 290 was 9.38%\n",
      "current params: [tensor([1.3015, 0.8446, 0.6191, 0.7748, 0.4936, 1.3417, 1.2909, 1.3109, 1.1267,\n",
      "        1.1473, 1.2828, 1.2724, 0.7553, 1.1617, 1.2616, 0.6911, 1.1885, 1.2647,\n",
      "        1.4238, 0.7243, 1.2830, 1.2372], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 291 was 9.38%\n",
      "current params: [tensor([1.3026, 0.8453, 0.6170, 0.7740, 0.4913, 1.3433, 1.2921, 1.3129, 1.1286,\n",
      "        1.1493, 1.2839, 1.2733, 0.7526, 1.1606, 1.2624, 0.6900, 1.1884, 1.2656,\n",
      "        1.4256, 0.7231, 1.2841, 1.2377], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 292 was 9.38%\n",
      "current params: [tensor([1.3037, 0.8461, 0.6149, 0.7732, 0.4889, 1.3448, 1.2932, 1.3150, 1.1306,\n",
      "        1.1514, 1.2849, 1.2741, 0.7499, 1.1594, 1.2633, 0.6888, 1.1883, 1.2665,\n",
      "        1.4274, 0.7220, 1.2852, 1.2382], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 293 was 9.38%\n",
      "current params: [tensor([1.3048, 0.8469, 0.6128, 0.7724, 0.4865, 1.3464, 1.2943, 1.3170, 1.1326,\n",
      "        1.1534, 1.2860, 1.2750, 0.7472, 1.1583, 1.2641, 0.6877, 1.1881, 1.2673,\n",
      "        1.4293, 0.7208, 1.2862, 1.2387], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 294 was 9.38%\n",
      "current params: [tensor([1.3059, 0.8477, 0.6107, 0.7717, 0.4841, 1.3480, 1.2955, 1.3190, 1.1346,\n",
      "        1.1554, 1.2871, 1.2759, 0.7445, 1.1571, 1.2650, 0.6865, 1.1880, 1.2682,\n",
      "        1.4311, 0.7197, 1.2873, 1.2392], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 295 was 9.38%\n",
      "current params: [tensor([1.3070, 0.8485, 0.6087, 0.7709, 0.4818, 1.3495, 1.2966, 1.3211, 1.1366,\n",
      "        1.1575, 1.2881, 1.2768, 0.7418, 1.1559, 1.2658, 0.6854, 1.1878, 1.2691,\n",
      "        1.4329, 0.7185, 1.2884, 1.2396], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 296 was 9.39%\n",
      "current params: [tensor([1.3081, 0.8493, 0.6066, 0.7701, 0.4794, 1.3511, 1.2977, 1.3231, 1.1386,\n",
      "        1.1595, 1.2892, 1.2776, 0.7391, 1.1547, 1.2666, 0.6842, 1.1877, 1.2699,\n",
      "        1.4347, 0.7173, 1.2894, 1.2401], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 297 was 9.39%\n",
      "current params: [tensor([1.3092, 0.8502, 0.6045, 0.7694, 0.4771, 1.3526, 1.2988, 1.3251, 1.1406,\n",
      "        1.1615, 1.2903, 1.2785, 0.7365, 1.1535, 1.2675, 0.6831, 1.1875, 1.2708,\n",
      "        1.4366, 0.7161, 1.2905, 1.2406], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 298 was 9.39%\n",
      "current params: [tensor([1.3102, 0.8511, 0.6024, 0.7686, 0.4747, 1.3542, 1.2999, 1.3271, 1.1426,\n",
      "        1.1635, 1.2913, 1.2794, 0.7338, 1.1522, 1.2683, 0.6820, 1.1874, 1.2717,\n",
      "        1.4384, 0.7150, 1.2915, 1.2411], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 299 was 9.40%\n",
      "current params: [tensor([1.3113, 0.8520, 0.6003, 0.7678, 0.4724, 1.3558, 1.3010, 1.3292, 1.1445,\n",
      "        1.1656, 1.2924, 1.2802, 0.7312, 1.1509, 1.2691, 0.6808, 1.1872, 1.2725,\n",
      "        1.4402, 0.7138, 1.2926, 1.2416], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 300 was 9.40%\n",
      "current params: [tensor([1.3124, 0.8529, 0.5982, 0.7671, 0.4701, 1.3573, 1.3022, 1.3312, 1.1465,\n",
      "        1.1676, 1.2935, 1.2811, 0.7285, 1.1496, 1.2699, 0.6797, 1.1870, 1.2734,\n",
      "        1.4420, 0.7126, 1.2936, 1.2421], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 301 was 9.40%\n",
      "current params: [tensor([1.3135, 0.8538, 0.5961, 0.7663, 0.4677, 1.3589, 1.3033, 1.3332, 1.1485,\n",
      "        1.1696, 1.2946, 1.2819, 0.7259, 1.1483, 1.2708, 0.6785, 1.1868, 1.2743,\n",
      "        1.4438, 0.7114, 1.2947, 1.2425], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 302 was 9.41%\n",
      "current params: [tensor([1.3146, 0.8548, 0.5940, 0.7656, 0.4654, 1.3605, 1.3044, 1.3353, 1.1505,\n",
      "        1.1717, 1.2956, 1.2828, 0.7232, 1.1469, 1.2716, 0.6774, 1.1867, 1.2751,\n",
      "        1.4457, 0.7102, 1.2958, 1.2430], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 303 was 9.41%\n",
      "current params: [tensor([1.3156, 0.8558, 0.5919, 0.7648, 0.4630, 1.3620, 1.3055, 1.3373, 1.1525,\n",
      "        1.1737, 1.2967, 1.2836, 0.7206, 1.1455, 1.2724, 0.6762, 1.1865, 1.2760,\n",
      "        1.4475, 0.7090, 1.2968, 1.2435], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 304 was 9.41%\n",
      "current params: [tensor([1.3167, 0.8568, 0.5898, 0.7640, 0.4607, 1.3636, 1.3066, 1.3393, 1.1545,\n",
      "        1.1757, 1.2978, 1.2845, 0.7179, 1.1441, 1.2732, 0.6751, 1.1863, 1.2768,\n",
      "        1.4493, 0.7078, 1.2979, 1.2439], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 305 was 9.42%\n",
      "current params: [tensor([1.3178, 0.8579, 0.5877, 0.7632, 0.4583, 1.3652, 1.3077, 1.3414, 1.1565,\n",
      "        1.1778, 1.2989, 1.2854, 0.7153, 1.1427, 1.2741, 0.6739, 1.1860, 1.2777,\n",
      "        1.4511, 0.7066, 1.2989, 1.2444], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 306 was 9.42%\n",
      "current params: [tensor([1.3189, 0.8589, 0.5855, 0.7625, 0.4560, 1.3668, 1.3088, 1.3434, 1.1586,\n",
      "        1.1798, 1.2999, 1.2862, 0.7126, 1.1412, 1.2749, 0.6728, 1.1858, 1.2785,\n",
      "        1.4530, 0.7054, 1.3000, 1.2449], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 307 was 9.43%\n",
      "current params: [tensor([1.3200, 0.8600, 0.5834, 0.7617, 0.4536, 1.3684, 1.3100, 1.3455, 1.1606,\n",
      "        1.1819, 1.3010, 1.2871, 0.7100, 1.1397, 1.2757, 0.6716, 1.1856, 1.2794,\n",
      "        1.4548, 0.7042, 1.3011, 1.2453], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 308 was 9.43%\n",
      "current params: [tensor([1.3210, 0.8611, 0.5813, 0.7609, 0.4513, 1.3700, 1.3111, 1.3475, 1.1626,\n",
      "        1.1839, 1.3021, 1.2879, 0.7073, 1.1382, 1.2765, 0.6705, 1.1853, 1.2803,\n",
      "        1.4566, 0.7030, 1.3021, 1.2458], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 309 was 9.43%\n",
      "current params: [tensor([1.3221, 0.8622, 0.5791, 0.7601, 0.4489, 1.3716, 1.3122, 1.3495, 1.1646,\n",
      "        1.1859, 1.3032, 1.2888, 0.7047, 1.1366, 1.2774, 0.6693, 1.1851, 1.2811,\n",
      "        1.4585, 0.7017, 1.3032, 1.2462], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 310 was 9.44%\n",
      "current params: [tensor([1.3232, 0.8634, 0.5770, 0.7593, 0.4465, 1.3732, 1.3133, 1.3516, 1.1666,\n",
      "        1.1880, 1.3043, 1.2896, 0.7020, 1.1350, 1.2782, 0.6682, 1.1848, 1.2820,\n",
      "        1.4603, 0.7005, 1.3043, 1.2466], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 311 was 9.44%\n",
      "current params: [tensor([1.3243, 0.8645, 0.5748, 0.7584, 0.4442, 1.3748, 1.3144, 1.3536, 1.1686,\n",
      "        1.1900, 1.3054, 1.2905, 0.6994, 1.1334, 1.2790, 0.6670, 1.1845, 1.2828,\n",
      "        1.4622, 0.6992, 1.3053, 1.2471], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 312 was 9.44%\n",
      "current params: [tensor([1.3253, 0.8657, 0.5727, 0.7576, 0.4418, 1.3764, 1.3156, 1.3557, 1.1706,\n",
      "        1.1921, 1.3065, 1.2913, 0.6967, 1.1318, 1.2798, 0.6659, 1.1842, 1.2837,\n",
      "        1.4640, 0.6980, 1.3064, 1.2475], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 313 was 9.45%\n",
      "current params: [tensor([1.3264, 0.8669, 0.5705, 0.7568, 0.4394, 1.3780, 1.3167, 1.3577, 1.1727,\n",
      "        1.1941, 1.3076, 1.2922, 0.6940, 1.1301, 1.2807, 0.6647, 1.1839, 1.2845,\n",
      "        1.4659, 0.6967, 1.3075, 1.2479], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 314 was 9.45%\n",
      "current params: [tensor([1.3275, 0.8681, 0.5683, 0.7559, 0.4370, 1.3796, 1.3178, 1.3598, 1.1747,\n",
      "        1.1962, 1.3087, 1.2930, 0.6914, 1.1284, 1.2815, 0.6636, 1.1836, 1.2854,\n",
      "        1.4677, 0.6954, 1.3086, 1.2484], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 315 was 9.46%\n",
      "current params: [tensor([1.3286, 0.8694, 0.5661, 0.7551, 0.4346, 1.3812, 1.3189, 1.3619, 1.1767,\n",
      "        1.1982, 1.3098, 1.2939, 0.6887, 1.1267, 1.2823, 0.6624, 1.1832, 1.2863,\n",
      "        1.4696, 0.6941, 1.3097, 1.2488], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 316 was 9.46%\n",
      "current params: [tensor([1.3296, 0.8707, 0.5640, 0.7542, 0.4322, 1.3828, 1.3201, 1.3639, 1.1787,\n",
      "        1.2003, 1.3109, 1.2948, 0.6860, 1.1249, 1.2831, 0.6613, 1.1828, 1.2871,\n",
      "        1.4714, 0.6928, 1.3107, 1.2492], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 317 was 9.46%\n",
      "current params: [tensor([1.3307, 0.8719, 0.5618, 0.7533, 0.4298, 1.3845, 1.3212, 1.3660, 1.1808,\n",
      "        1.2024, 1.3120, 1.2956, 0.6833, 1.1231, 1.2840, 0.6601, 1.1825, 1.2880,\n",
      "        1.4733, 0.6915, 1.3118, 1.2496], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 318 was 9.47%\n",
      "current params: [tensor([1.3318, 0.8732, 0.5596, 0.7525, 0.4274, 1.3861, 1.3223, 1.3681, 1.1828,\n",
      "        1.2044, 1.3131, 1.2965, 0.6806, 1.1213, 1.2848, 0.6590, 1.1821, 1.2888,\n",
      "        1.4751, 0.6902, 1.3129, 1.2500], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 319 was 9.47%\n",
      "current params: [tensor([1.3329, 0.8746, 0.5573, 0.7516, 0.4250, 1.3877, 1.3235, 1.3701, 1.1848,\n",
      "        1.2065, 1.3142, 1.2973, 0.6779, 1.1194, 1.2856, 0.6578, 1.1817, 1.2897,\n",
      "        1.4770, 0.6888, 1.3140, 1.2503], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 320 was 9.47%\n",
      "current params: [tensor([1.3340, 0.8759, 0.5551, 0.7506, 0.4226, 1.3894, 1.3246, 1.3722, 1.1869,\n",
      "        1.2085, 1.3153, 1.2982, 0.6753, 1.1176, 1.2864, 0.6566, 1.1812, 1.2906,\n",
      "        1.4789, 0.6875, 1.3151, 1.2507], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 321 was 9.48%\n",
      "current params: [tensor([1.3350, 0.8773, 0.5529, 0.7497, 0.4202, 1.3910, 1.3258, 1.3743, 1.1889,\n",
      "        1.2106, 1.3165, 1.2990, 0.6726, 1.1157, 1.2873, 0.6555, 1.1808, 1.2914,\n",
      "        1.4808, 0.6861, 1.3162, 1.2511], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 322 was 9.48%\n",
      "current params: [tensor([1.3361, 0.8787, 0.5507, 0.7488, 0.4178, 1.3927, 1.3269, 1.3764, 1.1910,\n",
      "        1.2127, 1.3176, 1.2999, 0.6699, 1.1137, 1.2881, 0.6543, 1.1803, 1.2923,\n",
      "        1.4826, 0.6848, 1.3173, 1.2515], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 323 was 9.49%\n",
      "current params: [tensor([1.3372, 0.8801, 0.5484, 0.7478, 0.4153, 1.3943, 1.3281, 1.3784, 1.1930,\n",
      "        1.2147, 1.3187, 1.3007, 0.6672, 1.1118, 1.2889, 0.6532, 1.1799, 1.2932,\n",
      "        1.4845, 0.6834, 1.3184, 1.2518], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 324 was 9.49%\n",
      "current params: [tensor([1.3383, 0.8815, 0.5462, 0.7469, 0.4129, 1.3960, 1.3292, 1.3805, 1.1950,\n",
      "        1.2168, 1.3199, 1.3016, 0.6645, 1.1098, 1.2898, 0.6520, 1.1794, 1.2940,\n",
      "        1.4864, 0.6820, 1.3195, 1.2522], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 325 was 9.50%\n",
      "current params: [tensor([1.3393, 0.8829, 0.5439, 0.7459, 0.4105, 1.3976, 1.3304, 1.3826, 1.1971,\n",
      "        1.2189, 1.3210, 1.3024, 0.6617, 1.1078, 1.2906, 0.6508, 1.1788, 1.2949,\n",
      "        1.4883, 0.6806, 1.3206, 1.2525], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 326 was 9.50%\n",
      "current params: [tensor([1.3404, 0.8844, 0.5417, 0.7449, 0.4080, 1.3993, 1.3315, 1.3847, 1.1991,\n",
      "        1.2209, 1.3221, 1.3033, 0.6590, 1.1057, 1.2914, 0.6497, 1.1783, 1.2957,\n",
      "        1.4902, 0.6792, 1.3217, 1.2529], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 327 was 9.50%\n",
      "current params: [tensor([1.3415, 0.8859, 0.5394, 0.7439, 0.4056, 1.4010, 1.3327, 1.3868, 1.2012,\n",
      "        1.2230, 1.3233, 1.3042, 0.6563, 1.1037, 1.2923, 0.6485, 1.1778, 1.2966,\n",
      "        1.4921, 0.6778, 1.3228, 1.2532], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 328 was 9.51%\n",
      "current params: [tensor([1.3426, 0.8874, 0.5371, 0.7429, 0.4031, 1.4026, 1.3338, 1.3889, 1.2032,\n",
      "        1.2251, 1.3244, 1.3050, 0.6536, 1.1016, 1.2931, 0.6473, 1.1772, 1.2975,\n",
      "        1.4940, 0.6764, 1.3239, 1.2535], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 329 was 9.51%\n",
      "current params: [tensor([1.3437, 0.8889, 0.5349, 0.7419, 0.4007, 1.4043, 1.3350, 1.3910, 1.2053,\n",
      "        1.2272, 1.3256, 1.3059, 0.6509, 1.0995, 1.2939, 0.6462, 1.1766, 1.2983,\n",
      "        1.4959, 0.6749, 1.3250, 1.2538], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 330 was 9.52%\n",
      "current params: [tensor([1.3447, 0.8905, 0.5326, 0.7408, 0.3982, 1.4060, 1.3362, 1.3931, 1.2073,\n",
      "        1.2293, 1.3267, 1.3067, 0.6482, 1.0973, 1.2948, 0.6450, 1.1760, 1.2992,\n",
      "        1.4978, 0.6734, 1.3261, 1.2542], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 331 was 9.52%\n",
      "current params: [tensor([1.3458, 0.8920, 0.5303, 0.7397, 0.3957, 1.4077, 1.3373, 1.3952, 1.2094,\n",
      "        1.2313, 1.3279, 1.3076, 0.6454, 1.0952, 1.2956, 0.6438, 1.1754, 1.3001,\n",
      "        1.4997, 0.6720, 1.3272, 1.2545], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 332 was 9.53%\n",
      "current params: [tensor([1.3469, 0.8936, 0.5280, 0.7387, 0.3932, 1.4094, 1.3385, 1.3973, 1.2115,\n",
      "        1.2334, 1.3290, 1.3085, 0.6427, 1.0930, 1.2965, 0.6427, 1.1747, 1.3010,\n",
      "        1.5016, 0.6705, 1.3284, 1.2547], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 333 was 9.53%\n",
      "current params: [tensor([1.3480, 0.8952, 0.5257, 0.7376, 0.3908, 1.4111, 1.3397, 1.3994, 1.2135,\n",
      "        1.2355, 1.3302, 1.3093, 0.6400, 1.0908, 1.2973, 0.6415, 1.1740, 1.3018,\n",
      "        1.5035, 0.6690, 1.3295, 1.2550], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 334 was 9.54%\n",
      "current params: [tensor([1.3491, 0.8968, 0.5234, 0.7365, 0.3883, 1.4128, 1.3409, 1.4015, 1.2156,\n",
      "        1.2376, 1.3314, 1.3102, 0.6372, 1.0886, 1.2981, 0.6403, 1.1733, 1.3027,\n",
      "        1.5054, 0.6675, 1.3306, 1.2553], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 335 was 9.54%\n",
      "current params: [tensor([1.3501, 0.8985, 0.5211, 0.7353, 0.3858, 1.4145, 1.3420, 1.4036, 1.2176,\n",
      "        1.2397, 1.3325, 1.3110, 0.6345, 1.0863, 1.2990, 0.6391, 1.1726, 1.3036,\n",
      "        1.5073, 0.6659, 1.3317, 1.2556], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 336 was 9.54%\n",
      "current params: [tensor([1.3512, 0.9001, 0.5187, 0.7342, 0.3833, 1.4162, 1.3432, 1.4057, 1.2197,\n",
      "        1.2418, 1.3337, 1.3119, 0.6318, 1.0840, 1.2998, 0.6380, 1.1719, 1.3044,\n",
      "        1.5093, 0.6644, 1.3329, 1.2558], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 337 was 9.55%\n",
      "current params: [tensor([1.3523, 0.9018, 0.5164, 0.7330, 0.3808, 1.4180, 1.3444, 1.4079, 1.2218,\n",
      "        1.2439, 1.3349, 1.3128, 0.6290, 1.0817, 1.3007, 0.6368, 1.1711, 1.3053,\n",
      "        1.5112, 0.6628, 1.3340, 1.2561], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 338 was 9.55%\n",
      "current params: [tensor([1.3534, 0.9035, 0.5141, 0.7318, 0.3783, 1.4197, 1.3456, 1.4100, 1.2239,\n",
      "        1.2460, 1.3361, 1.3136, 0.6263, 1.0794, 1.3015, 0.6356, 1.1704, 1.3062,\n",
      "        1.5131, 0.6613, 1.3351, 1.2563], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 339 was 9.56%\n",
      "current params: [tensor([1.3544, 0.9052, 0.5117, 0.7306, 0.3758, 1.4214, 1.3468, 1.4121, 1.2259,\n",
      "        1.2481, 1.3372, 1.3145, 0.6235, 1.0771, 1.3024, 0.6345, 1.1696, 1.3071,\n",
      "        1.5151, 0.6597, 1.3363, 1.2566], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 340 was 9.56%\n",
      "current params: [tensor([1.3555, 0.9070, 0.5094, 0.7294, 0.3732, 1.4231, 1.3480, 1.4142, 1.2280,\n",
      "        1.2502, 1.3384, 1.3154, 0.6208, 1.0748, 1.3032, 0.6333, 1.1688, 1.3079,\n",
      "        1.5170, 0.6581, 1.3374, 1.2568], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 341 was 9.57%\n",
      "current params: [tensor([1.3566, 0.9087, 0.5070, 0.7282, 0.3707, 1.4249, 1.3492, 1.4164, 1.2301,\n",
      "        1.2523, 1.3396, 1.3162, 0.6180, 1.0724, 1.3041, 0.6321, 1.1679, 1.3088,\n",
      "        1.5189, 0.6564, 1.3386, 1.2570], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 342 was 9.57%\n",
      "current params: [tensor([1.3577, 0.9105, 0.5047, 0.7269, 0.3682, 1.4266, 1.3504, 1.4185, 1.2322,\n",
      "        1.2544, 1.3408, 1.3171, 0.6153, 1.0700, 1.3049, 0.6309, 1.1671, 1.3097,\n",
      "        1.5209, 0.6548, 1.3397, 1.2572], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 343 was 9.58%\n",
      "current params: [tensor([1.3587, 0.9123, 0.5023, 0.7256, 0.3657, 1.4284, 1.3515, 1.4206, 1.2342,\n",
      "        1.2565, 1.3420, 1.3179, 0.6125, 1.0676, 1.3058, 0.6297, 1.1662, 1.3106,\n",
      "        1.5228, 0.6532, 1.3409, 1.2574], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 344 was 9.58%\n",
      "current params: [tensor([1.3598, 0.9141, 0.4999, 0.7243, 0.3631, 1.4301, 1.3527, 1.4228, 1.2363,\n",
      "        1.2586, 1.3432, 1.3188, 0.6098, 1.0652, 1.3066, 0.6286, 1.1653, 1.3114,\n",
      "        1.5248, 0.6515, 1.3420, 1.2576], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 345 was 9.59%\n",
      "current params: [tensor([1.3609, 0.9159, 0.4976, 0.7230, 0.3606, 1.4319, 1.3539, 1.4249, 1.2384,\n",
      "        1.2607, 1.3444, 1.3197, 0.6070, 1.0627, 1.3075, 0.6274, 1.1643, 1.3123,\n",
      "        1.5268, 0.6498, 1.3432, 1.2578], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 346 was 9.59%\n",
      "current params: [tensor([1.3620, 0.9177, 0.4952, 0.7216, 0.3580, 1.4337, 1.3552, 1.4271, 1.2405,\n",
      "        1.2628, 1.3456, 1.3205, 0.6042, 1.0603, 1.3083, 0.6262, 1.1634, 1.3132,\n",
      "        1.5287, 0.6481, 1.3443, 1.2579], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 347 was 9.60%\n",
      "current params: [tensor([1.3631, 0.9196, 0.4928, 0.7203, 0.3555, 1.4354, 1.3564, 1.4292, 1.2426,\n",
      "        1.2649, 1.3469, 1.3214, 0.6015, 1.0578, 1.3092, 0.6250, 1.1624, 1.3141,\n",
      "        1.5307, 0.6464, 1.3455, 1.2581], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 348 was 9.60%\n",
      "current params: [tensor([1.3641, 0.9215, 0.4904, 0.7189, 0.3529, 1.4372, 1.3576, 1.4314, 1.2447,\n",
      "        1.2670, 1.3481, 1.3223, 0.5987, 1.0553, 1.3101, 0.6238, 1.1614, 1.3149,\n",
      "        1.5327, 0.6446, 1.3467, 1.2582], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 349 was 9.61%\n",
      "current params: [tensor([1.3652, 0.9234, 0.4880, 0.7175, 0.3503, 1.4390, 1.3588, 1.4336, 1.2467,\n",
      "        1.2691, 1.3493, 1.3232, 0.5959, 1.0528, 1.3109, 0.6226, 1.1604, 1.3158,\n",
      "        1.5346, 0.6429, 1.3478, 1.2583], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 350 was 9.61%\n",
      "current params: [tensor([1.3663, 0.9253, 0.4856, 0.7161, 0.3478, 1.4408, 1.3600, 1.4357, 1.2488,\n",
      "        1.2712, 1.3505, 1.3240, 0.5932, 1.0503, 1.3118, 0.6215, 1.1593, 1.3167,\n",
      "        1.5366, 0.6411, 1.3490, 1.2585], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 351 was 9.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: [tensor([1.3673, 0.9272, 0.4832, 0.7146, 0.3452, 1.4426, 1.3612, 1.4379, 1.2509,\n",
      "        1.2734, 1.3518, 1.3249, 0.5904, 1.0478, 1.3127, 0.6203, 1.1583, 1.3176,\n",
      "        1.5386, 0.6393, 1.3502, 1.2586], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 352 was 9.63%\n",
      "current params: [tensor([1.3684, 0.9291, 0.4808, 0.7131, 0.3426, 1.4444, 1.3624, 1.4400, 1.2530,\n",
      "        1.2755, 1.3530, 1.3258, 0.5876, 1.0452, 1.3135, 0.6191, 1.1572, 1.3185,\n",
      "        1.5406, 0.6375, 1.3514, 1.2587], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 353 was 9.63%\n",
      "current params: [tensor([1.3695, 0.9311, 0.4784, 0.7116, 0.3400, 1.4462, 1.3637, 1.4422, 1.2551,\n",
      "        1.2776, 1.3543, 1.3266, 0.5848, 1.0427, 1.3144, 0.6179, 1.1560, 1.3193,\n",
      "        1.5426, 0.6357, 1.3525, 1.2588], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 354 was 9.64%\n",
      "current params: [tensor([1.3706, 0.9331, 0.4759, 0.7101, 0.3374, 1.4480, 1.3649, 1.4444, 1.2572,\n",
      "        1.2797, 1.3555, 1.3275, 0.5821, 1.0401, 1.3153, 0.6167, 1.1549, 1.3202,\n",
      "        1.5446, 0.6339, 1.3537, 1.2588], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 355 was 9.64%\n",
      "current params: [tensor([1.3716, 0.9351, 0.4735, 0.7085, 0.3348, 1.4498, 1.3661, 1.4466, 1.2593,\n",
      "        1.2819, 1.3568, 1.3284, 0.5793, 1.0375, 1.3161, 0.6155, 1.1537, 1.3211,\n",
      "        1.5466, 0.6320, 1.3549, 1.2589], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 356 was 9.63%\n",
      "current params: [tensor([1.3727, 0.9371, 0.4711, 0.7070, 0.3322, 1.4516, 1.3673, 1.4488, 1.2614,\n",
      "        1.2840, 1.3580, 1.3292, 0.5765, 1.0349, 1.3170, 0.6143, 1.1526, 1.3220,\n",
      "        1.5486, 0.6301, 1.3561, 1.2590], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 357 was 9.64%\n",
      "current params: [tensor([1.3737, 0.9391, 0.4687, 0.7054, 0.3297, 1.4535, 1.3685, 1.4509, 1.2635,\n",
      "        1.2861, 1.3593, 1.3301, 0.5737, 1.0323, 1.3179, 0.6131, 1.1514, 1.3229,\n",
      "        1.5506, 0.6283, 1.3573, 1.2590], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 358 was 9.64%\n",
      "current params: [tensor([1.3748, 0.9411, 0.4662, 0.7038, 0.3271, 1.4553, 1.3698, 1.4531, 1.2656,\n",
      "        1.2882, 1.3605, 1.3310, 0.5710, 1.0297, 1.3187, 0.6119, 1.1502, 1.3237,\n",
      "        1.5526, 0.6264, 1.3584, 1.2591], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 359 was 9.65%\n",
      "current params: [tensor([1.3759, 0.9432, 0.4638, 0.7023, 0.3245, 1.4571, 1.3710, 1.4553, 1.2677,\n",
      "        1.2903, 1.3618, 1.3318, 0.5682, 1.0271, 1.3196, 0.6107, 1.1490, 1.3246,\n",
      "        1.5546, 0.6245, 1.3596, 1.2591], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 360 was 9.65%\n",
      "current params: [tensor([1.3769, 0.9452, 0.4614, 0.7007, 0.3219, 1.4589, 1.3722, 1.4575, 1.2698,\n",
      "        1.2925, 1.3630, 1.3327, 0.5655, 1.0245, 1.3205, 0.6095, 1.1478, 1.3255,\n",
      "        1.5566, 0.6226, 1.3608, 1.2592], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 361 was 9.66%\n",
      "current params: [tensor([1.3779, 0.9473, 0.4590, 0.6991, 0.3193, 1.4607, 1.3734, 1.4596, 1.2719,\n",
      "        1.2946, 1.3643, 1.3336, 0.5627, 1.0219, 1.3213, 0.6084, 1.1466, 1.3263,\n",
      "        1.5586, 0.6207, 1.3620, 1.2592], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 362 was 9.66%\n",
      "current params: [tensor([1.3790, 0.9494, 0.4566, 0.6975, 0.3168, 1.4626, 1.3746, 1.4618, 1.2740,\n",
      "        1.2967, 1.3656, 1.3344, 0.5600, 1.0193, 1.3222, 0.6072, 1.1453, 1.3272,\n",
      "        1.5605, 0.6187, 1.3632, 1.2592], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 363 was 9.67%\n",
      "current params: [tensor([1.3800, 0.9515, 0.4542, 0.6958, 0.3142, 1.4644, 1.3758, 1.4640, 1.2761,\n",
      "        1.2988, 1.3668, 1.3353, 0.5572, 1.0167, 1.3230, 0.6060, 1.1441, 1.3281,\n",
      "        1.5625, 0.6168, 1.3643, 1.2593], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 364 was 9.68%\n",
      "current params: [tensor([1.3811, 0.9536, 0.4517, 0.6942, 0.3116, 1.4662, 1.3770, 1.4662, 1.2782,\n",
      "        1.3010, 1.3681, 1.3362, 0.5545, 1.0140, 1.3239, 0.6048, 1.1428, 1.3289,\n",
      "        1.5645, 0.6149, 1.3655, 1.2593], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 365 was 9.68%\n",
      "current params: [tensor([1.3821, 0.9558, 0.4493, 0.6925, 0.3090, 1.4681, 1.3782, 1.4684, 1.2803,\n",
      "        1.3031, 1.3694, 1.3370, 0.5518, 1.0114, 1.3248, 0.6036, 1.1415, 1.3298,\n",
      "        1.5665, 0.6129, 1.3667, 1.2593], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 366 was 9.69%\n",
      "current params: [tensor([1.3831, 0.9579, 0.4469, 0.6908, 0.3064, 1.4699, 1.3794, 1.4706, 1.2824,\n",
      "        1.3052, 1.3706, 1.3379, 0.5490, 1.0088, 1.3256, 0.6024, 1.1402, 1.3306,\n",
      "        1.5686, 0.6109, 1.3679, 1.2593], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 367 was 9.69%\n",
      "current params: [tensor([1.3842, 0.9601, 0.4445, 0.6891, 0.3038, 1.4717, 1.3806, 1.4728, 1.2845,\n",
      "        1.3073, 1.3719, 1.3387, 0.5463, 1.0061, 1.3265, 0.6011, 1.1389, 1.3315,\n",
      "        1.5706, 0.6089, 1.3691, 1.2593], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 368 was 9.70%\n",
      "current params: [tensor([1.3852, 0.9623, 0.4420, 0.6874, 0.3013, 1.4736, 1.3818, 1.4750, 1.2866,\n",
      "        1.3095, 1.3732, 1.3396, 0.5435, 1.0034, 1.3273, 0.5999, 1.1376, 1.3323,\n",
      "        1.5726, 0.6069, 1.3702, 1.2592], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 369 was 9.71%\n",
      "current params: [tensor([1.3862, 0.9645, 0.4396, 0.6856, 0.2987, 1.4754, 1.3830, 1.4771, 1.2887,\n",
      "        1.3116, 1.3745, 1.3404, 0.5408, 1.0008, 1.3282, 0.5987, 1.1362, 1.3332,\n",
      "        1.5746, 0.6049, 1.3714, 1.2592], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 370 was 9.71%\n",
      "current params: [tensor([1.3872, 0.9667, 0.4372, 0.6838, 0.2961, 1.4773, 1.3842, 1.4793, 1.2907,\n",
      "        1.3137, 1.3758, 1.3413, 0.5380, 0.9981, 1.3291, 0.5975, 1.1348, 1.3341,\n",
      "        1.5766, 0.6028, 1.3726, 1.2592], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 371 was 9.72%\n",
      "current params: [tensor([1.3882, 0.9689, 0.4347, 0.6820, 0.2934, 1.4792, 1.3854, 1.4815, 1.2928,\n",
      "        1.3159, 1.3771, 1.3422, 0.5353, 0.9954, 1.3299, 0.5963, 1.1334, 1.3349,\n",
      "        1.5786, 0.6007, 1.3738, 1.2591], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 372 was 9.73%\n",
      "current params: [tensor([1.3893, 0.9711, 0.4323, 0.6801, 0.2908, 1.4810, 1.3866, 1.4838, 1.2949,\n",
      "        1.3180, 1.3784, 1.3430, 0.5325, 0.9927, 1.3308, 0.5951, 1.1320, 1.3358,\n",
      "        1.5807, 0.5987, 1.3750, 1.2590], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 373 was 9.73%\n",
      "current params: [tensor([1.3903, 0.9733, 0.4298, 0.6783, 0.2882, 1.4829, 1.3879, 1.4860, 1.2971,\n",
      "        1.3201, 1.3797, 1.3439, 0.5298, 0.9900, 1.3317, 0.5939, 1.1305, 1.3366,\n",
      "        1.5827, 0.5966, 1.3762, 1.2589], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 374 was 9.74%\n",
      "current params: [tensor([1.3913, 0.9756, 0.4274, 0.6764, 0.2856, 1.4848, 1.3891, 1.4882, 1.2992,\n",
      "        1.3223, 1.3810, 1.3447, 0.5270, 0.9873, 1.3326, 0.5927, 1.1290, 1.3375,\n",
      "        1.5847, 0.5944, 1.3774, 1.2588], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 375 was 9.75%\n",
      "current params: [tensor([1.3923, 0.9778, 0.4249, 0.6744, 0.2830, 1.4867, 1.3903, 1.4904, 1.3013,\n",
      "        1.3244, 1.3823, 1.3456, 0.5243, 0.9846, 1.3334, 0.5915, 1.1275, 1.3383,\n",
      "        1.5868, 0.5923, 1.3786, 1.2587], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 376 was 9.75%\n",
      "current params: [tensor([1.3933, 0.9801, 0.4225, 0.6725, 0.2803, 1.4885, 1.3915, 1.4926, 1.3034,\n",
      "        1.3265, 1.3836, 1.3465, 0.5215, 0.9819, 1.3343, 0.5903, 1.1260, 1.3391,\n",
      "        1.5888, 0.5901, 1.3798, 1.2586], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 377 was 9.76%\n",
      "current params: [tensor([1.3943, 0.9824, 0.4200, 0.6705, 0.2777, 1.4904, 1.3927, 1.4948, 1.3055,\n",
      "        1.3287, 1.3850, 1.3473, 0.5188, 0.9792, 1.3352, 0.5891, 1.1245, 1.3400,\n",
      "        1.5908, 0.5879, 1.3810, 1.2584], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 378 was 9.77%\n",
      "current params: [tensor([1.3953, 0.9847, 0.4175, 0.6684, 0.2750, 1.4923, 1.3939, 1.4971, 1.3076,\n",
      "        1.3308, 1.3863, 1.3482, 0.5160, 0.9765, 1.3361, 0.5878, 1.1229, 1.3408,\n",
      "        1.5929, 0.5857, 1.3822, 1.2583], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 379 was 9.77%\n",
      "current params: [tensor([1.3963, 0.9870, 0.4151, 0.6664, 0.2724, 1.4942, 1.3951, 1.4993, 1.3097,\n",
      "        1.3330, 1.3876, 1.3490, 0.5132, 0.9737, 1.3369, 0.5866, 1.1213, 1.3417,\n",
      "        1.5949, 0.5835, 1.3834, 1.2581], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 380 was 9.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: [tensor([1.3973, 0.9893, 0.4126, 0.6643, 0.2697, 1.4962, 1.3964, 1.5015, 1.3118,\n",
      "        1.3351, 1.3890, 1.3499, 0.5105, 0.9710, 1.3378, 0.5854, 1.1196, 1.3425,\n",
      "        1.5970, 0.5812, 1.3846, 1.2579], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 381 was 9.79%\n",
      "current params: [tensor([1.3983, 0.9916, 0.4101, 0.6622, 0.2671, 1.4981, 1.3976, 1.5037, 1.3139,\n",
      "        1.3372, 1.3903, 1.3508, 0.5077, 0.9683, 1.3387, 0.5842, 1.1180, 1.3434,\n",
      "        1.5991, 0.5790, 1.3858, 1.2577], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 382 was 9.79%\n",
      "current params: [tensor([1.3993, 0.9939, 0.4076, 0.6600, 0.2644, 1.5000, 1.3988, 1.5060, 1.3160,\n",
      "        1.3394, 1.3917, 1.3516, 0.5049, 0.9655, 1.3396, 0.5830, 1.1163, 1.3442,\n",
      "        1.6011, 0.5767, 1.3870, 1.2575], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 383 was 9.80%\n",
      "current params: [tensor([1.4002, 0.9962, 0.4051, 0.6578, 0.2617, 1.5019, 1.4000, 1.5082, 1.3181,\n",
      "        1.3415, 1.3930, 1.3525, 0.5022, 0.9628, 1.3405, 0.5817, 1.1146, 1.3450,\n",
      "        1.6032, 0.5744, 1.3882, 1.2573], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 384 was 9.81%\n",
      "current params: [tensor([1.4012, 0.9986, 0.4026, 0.6556, 0.2590, 1.5039, 1.4012, 1.5105, 1.3202,\n",
      "        1.3437, 1.3944, 1.3534, 0.4994, 0.9601, 1.3414, 0.5805, 1.1129, 1.3459,\n",
      "        1.6053, 0.5720, 1.3895, 1.2570], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 385 was 9.82%\n",
      "current params: [tensor([1.4022, 1.0009, 0.4001, 0.6533, 0.2564, 1.5058, 1.4025, 1.5127, 1.3223,\n",
      "        1.3458, 1.3957, 1.3542, 0.4966, 0.9573, 1.3423, 0.5793, 1.1111, 1.3467,\n",
      "        1.6074, 0.5697, 1.3907, 1.2567], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 386 was 9.82%\n",
      "current params: [tensor([1.4032, 1.0033, 0.3976, 0.6510, 0.2537, 1.5078, 1.4037, 1.5150, 1.3244,\n",
      "        1.3480, 1.3971, 1.3551, 0.4939, 0.9546, 1.3431, 0.5781, 1.1093, 1.3476,\n",
      "        1.6094, 0.5673, 1.3919, 1.2564], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 387 was 9.83%\n",
      "current params: [tensor([1.4042, 1.0057, 0.3951, 0.6487, 0.2510, 1.5097, 1.4049, 1.5172, 1.3265,\n",
      "        1.3501, 1.3985, 1.3560, 0.4911, 0.9518, 1.3440, 0.5768, 1.1075, 1.3484,\n",
      "        1.6115, 0.5649, 1.3931, 1.2561], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 388 was 9.84%\n",
      "current params: [tensor([1.4051, 1.0080, 0.3926, 0.6463, 0.2483, 1.5117, 1.4061, 1.5195, 1.3287,\n",
      "        1.3523, 1.3999, 1.3568, 0.4883, 0.9490, 1.3449, 0.5756, 1.1057, 1.3492,\n",
      "        1.6136, 0.5625, 1.3944, 1.2558], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 389 was 9.85%\n",
      "current params: [tensor([1.4061, 1.0104, 0.3901, 0.6439, 0.2455, 1.5136, 1.4074, 1.5217, 1.3308,\n",
      "        1.3544, 1.4013, 1.3577, 0.4855, 0.9463, 1.3458, 0.5744, 1.1038, 1.3500,\n",
      "        1.6157, 0.5601, 1.3956, 1.2554], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 390 was 9.85%\n",
      "current params: [tensor([1.4071, 1.0128, 0.3876, 0.6415, 0.2428, 1.5156, 1.4086, 1.5240, 1.3329,\n",
      "        1.3566, 1.4027, 1.3586, 0.4827, 0.9435, 1.3467, 0.5731, 1.1019, 1.3509,\n",
      "        1.6178, 0.5576, 1.3968, 1.2550], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 391 was 9.86%\n",
      "current params: [tensor([1.4080, 1.0152, 0.3851, 0.6390, 0.2401, 1.5176, 1.4098, 1.5263, 1.3350,\n",
      "        1.3588, 1.4041, 1.3595, 0.4800, 0.9407, 1.3477, 0.5719, 1.1000, 1.3517,\n",
      "        1.6200, 0.5551, 1.3981, 1.2547], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 392 was 9.87%\n",
      "current params: [tensor([1.4090, 1.0176, 0.3826, 0.6365, 0.2374, 1.5196, 1.4111, 1.5286, 1.3371,\n",
      "        1.3609, 1.4055, 1.3603, 0.4772, 0.9380, 1.3486, 0.5707, 1.0981, 1.3525,\n",
      "        1.6221, 0.5526, 1.3993, 1.2542], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 393 was 9.88%\n",
      "current params: [tensor([1.4099, 1.0201, 0.3800, 0.6340, 0.2346, 1.5216, 1.4123, 1.5308, 1.3392,\n",
      "        1.3631, 1.4069, 1.3612, 0.4744, 0.9352, 1.3495, 0.5694, 1.0961, 1.3534,\n",
      "        1.6242, 0.5501, 1.4005, 1.2538], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 394 was 9.89%\n",
      "current params: [tensor([1.4109, 1.0225, 0.3775, 0.6314, 0.2319, 1.5236, 1.4136, 1.5331, 1.3413,\n",
      "        1.3652, 1.4083, 1.3621, 0.4716, 0.9324, 1.3504, 0.5682, 1.0941, 1.3542,\n",
      "        1.6263, 0.5476, 1.4018, 1.2534], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 395 was 9.90%\n",
      "current params: [tensor([1.4118, 1.0249, 0.3750, 0.6288, 0.2291, 1.5256, 1.4148, 1.5354, 1.3434,\n",
      "        1.3674, 1.4097, 1.3630, 0.4688, 0.9297, 1.3513, 0.5670, 1.0921, 1.3550,\n",
      "        1.6284, 0.5450, 1.4030, 1.2529], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 396 was 9.90%\n",
      "current params: [tensor([1.4128, 1.0274, 0.3724, 0.6262, 0.2264, 1.5276, 1.4160, 1.5377, 1.3456,\n",
      "        1.3696, 1.4111, 1.3638, 0.4660, 0.9269, 1.3522, 0.5657, 1.0900, 1.3558,\n",
      "        1.6306, 0.5424, 1.4043, 1.2524], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 397 was 9.91%\n",
      "current params: [tensor([1.4137, 1.0298, 0.3699, 0.6235, 0.2236, 1.5296, 1.4173, 1.5400, 1.3477,\n",
      "        1.3717, 1.4126, 1.3647, 0.4632, 0.9241, 1.3531, 0.5645, 1.0879, 1.3566,\n",
      "        1.6327, 0.5398, 1.4056, 1.2518], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 398 was 9.92%\n",
      "current params: [tensor([1.4146, 1.0323, 0.3674, 0.6208, 0.2208, 1.5316, 1.4185, 1.5423, 1.3498,\n",
      "        1.3739, 1.4140, 1.3656, 0.4604, 0.9213, 1.3541, 0.5632, 1.0858, 1.3574,\n",
      "        1.6349, 0.5372, 1.4068, 1.2513], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 399 was 9.93%\n",
      "current params: [tensor([1.4155, 1.0347, 0.3648, 0.6181, 0.2180, 1.5337, 1.4198, 1.5446, 1.3519,\n",
      "        1.3761, 1.4155, 1.3665, 0.4577, 0.9186, 1.3550, 0.5620, 1.0837, 1.3582,\n",
      "        1.6370, 0.5346, 1.4081, 1.2507], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 400 was 9.94%\n",
      "current params: [tensor([1.4165, 1.0372, 0.3623, 0.6153, 0.2153, 1.5357, 1.4210, 1.5469, 1.3540,\n",
      "        1.3782, 1.4169, 1.3674, 0.4549, 0.9158, 1.3559, 0.5607, 1.0816, 1.3590,\n",
      "        1.6392, 0.5319, 1.4093, 1.2501], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 401 was 9.95%\n",
      "current params: [tensor([1.4174, 1.0397, 0.3597, 0.6125, 0.2125, 1.5378, 1.4223, 1.5492, 1.3561,\n",
      "        1.3804, 1.4184, 1.3682, 0.4521, 0.9130, 1.3569, 0.5595, 1.0794, 1.3598,\n",
      "        1.6413, 0.5292, 1.4106, 1.2495], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 402 was 9.96%\n",
      "current params: [tensor([1.4183, 1.0422, 0.3572, 0.6097, 0.2097, 1.5398, 1.4235, 1.5515, 1.3583,\n",
      "        1.3826, 1.4198, 1.3691, 0.4493, 0.9102, 1.3578, 0.5582, 1.0772, 1.3606,\n",
      "        1.6435, 0.5265, 1.4119, 1.2489], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 403 was 9.97%\n",
      "current params: [tensor([1.4192, 1.0447, 0.3546, 0.6068, 0.2068, 1.5419, 1.4248, 1.5538, 1.3604,\n",
      "        1.3848, 1.4213, 1.3700, 0.4465, 0.9074, 1.3587, 0.5570, 1.0750, 1.3614,\n",
      "        1.6457, 0.5238, 1.4131, 1.2482], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 404 was 9.98%\n",
      "current params: [tensor([1.4201, 1.0472, 0.3520, 0.6040, 0.2040, 1.5440, 1.4260, 1.5562, 1.3625,\n",
      "        1.3869, 1.4228, 1.3709, 0.4437, 0.9046, 1.3597, 0.5557, 1.0727, 1.3622,\n",
      "        1.6479, 0.5211, 1.4144, 1.2475], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 405 was 9.99%\n",
      "current params: [tensor([1.4210, 1.0497, 0.3495, 0.6010, 0.2012, 1.5460, 1.4273, 1.5585, 1.3646,\n",
      "        1.3891, 1.4243, 1.3718, 0.4409, 0.9019, 1.3606, 0.5545, 1.0704, 1.3630,\n",
      "        1.6501, 0.5183, 1.4157, 1.2468], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 406 was 10.0%\n",
      "current params: [tensor([1.4219, 1.0522, 0.3469, 0.5981, 0.1984, 1.5481, 1.4285, 1.5608, 1.3667,\n",
      "        1.3913, 1.4258, 1.3727, 0.4381, 0.8991, 1.3616, 0.5532, 1.0681, 1.3638,\n",
      "        1.6522, 0.5155, 1.4170, 1.2460], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 407 was 10.0%\n",
      "current params: [tensor([1.4228, 1.0547, 0.3444, 0.5951, 0.1956, 1.5502, 1.4298, 1.5632, 1.3689,\n",
      "        1.3935, 1.4273, 1.3736, 0.4353, 0.8963, 1.3625, 0.5520, 1.0658, 1.3646,\n",
      "        1.6544, 0.5127, 1.4183, 1.2453], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 408 was 10.0%\n",
      "current params: [tensor([1.4236, 1.0572, 0.3418, 0.5921, 0.1927, 1.5523, 1.4310, 1.5655, 1.3710,\n",
      "        1.3957, 1.4288, 1.3745, 0.4325, 0.8935, 1.3635, 0.5507, 1.0635, 1.3654,\n",
      "        1.6566, 0.5099, 1.4195, 1.2445], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 409 was 10.0%\n",
      "current params: [tensor([1.4245, 1.0597, 0.3392, 0.5891, 0.1899, 1.5544, 1.4323, 1.5678, 1.3731,\n",
      "        1.3978, 1.4303, 1.3754, 0.4297, 0.8907, 1.3645, 0.5494, 1.0611, 1.3661,\n",
      "        1.6588, 0.5071, 1.4208, 1.2436], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 410 was 10.0%\n",
      "current params: [tensor([1.4254, 1.0623, 0.3366, 0.5860, 0.1870, 1.5565, 1.4335, 1.5702, 1.3752,\n",
      "        1.4000, 1.4318, 1.3763, 0.4269, 0.8880, 1.3654, 0.5482, 1.0587, 1.3669,\n",
      "        1.6611, 0.5042, 1.4221, 1.2428], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 411 was 10.0%\n",
      "current params: [tensor([1.4262, 1.0648, 0.3341, 0.5829, 0.1841, 1.5587, 1.4348, 1.5725, 1.3773,\n",
      "        1.4022, 1.4333, 1.3772, 0.4241, 0.8852, 1.3664, 0.5469, 1.0563, 1.3677,\n",
      "        1.6633, 0.5013, 1.4234, 1.2419], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 412 was 10.0%\n",
      "current params: [tensor([1.4271, 1.0673, 0.3315, 0.5798, 0.1813, 1.5608, 1.4360, 1.5749, 1.3795,\n",
      "        1.4044, 1.4349, 1.3781, 0.4213, 0.8824, 1.3674, 0.5456, 1.0539, 1.3684,\n",
      "        1.6655, 0.4984, 1.4247, 1.2409], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 413 was 10.0%\n",
      "current params: [tensor([1.4279, 1.0699, 0.3289, 0.5767, 0.1784, 1.5629, 1.4373, 1.5773, 1.3816,\n",
      "        1.4066, 1.4364, 1.3790, 0.4185, 0.8796, 1.3683, 0.5444, 1.0514, 1.3692,\n",
      "        1.6677, 0.4955, 1.4260, 1.2400], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 414 was 10.0%\n",
      "current params: [tensor([1.4288, 1.0724, 0.3263, 0.5735, 0.1755, 1.5651, 1.4385, 1.5796, 1.3837,\n",
      "        1.4088, 1.4380, 1.3799, 0.4157, 0.8768, 1.3693, 0.5431, 1.0489, 1.3699,\n",
      "        1.6700, 0.4926, 1.4273, 1.2390], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 415 was 10.0%\n",
      "current params: [tensor([1.4296, 1.0750, 0.3238, 0.5703, 0.1726, 1.5672, 1.4398, 1.5820, 1.3858,\n",
      "        1.4110, 1.4395, 1.3808, 0.4129, 0.8741, 1.3703, 0.5418, 1.0464, 1.3707,\n",
      "        1.6722, 0.4896, 1.4286, 1.2380], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 416 was 10.1%\n",
      "current params: [tensor([1.4304, 1.0776, 0.3212, 0.5671, 0.1697, 1.5694, 1.4411, 1.5844, 1.3879,\n",
      "        1.4132, 1.4411, 1.3817, 0.4101, 0.8713, 1.3713, 0.5406, 1.0439, 1.3714,\n",
      "        1.6745, 0.4867, 1.4299, 1.2370], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 417 was 10.1%\n",
      "current params: [tensor([1.4312, 1.0801, 0.3186, 0.5639, 0.1668, 1.5716, 1.4423, 1.5867, 1.3901,\n",
      "        1.4153, 1.4426, 1.3826, 0.4073, 0.8685, 1.3723, 0.5393, 1.0413, 1.3722,\n",
      "        1.6767, 0.4837, 1.4312, 1.2359], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 418 was 10.1%\n",
      "current params: [tensor([1.4320, 1.0827, 0.3160, 0.5606, 0.1639, 1.5738, 1.4436, 1.5891, 1.3922,\n",
      "        1.4175, 1.4442, 1.3835, 0.4045, 0.8657, 1.3733, 0.5380, 1.0388, 1.3729,\n",
      "        1.6790, 0.4807, 1.4325, 1.2348], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 419 was 10.1%\n",
      "current params: [tensor([1.4328, 1.0853, 0.3134, 0.5573, 0.1610, 1.5759, 1.4448, 1.5915, 1.3943,\n",
      "        1.4197, 1.4458, 1.3844, 0.4017, 0.8630, 1.3743, 0.5367, 1.0362, 1.3736,\n",
      "        1.6812, 0.4777, 1.4339, 1.2336], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 420 was 10.1%\n",
      "current params: [tensor([1.4336, 1.0879, 0.3108, 0.5540, 0.1580, 1.5781, 1.4461, 1.5939, 1.3964,\n",
      "        1.4219, 1.4474, 1.3853, 0.3989, 0.8602, 1.3753, 0.5354, 1.0336, 1.3744,\n",
      "        1.6835, 0.4747, 1.4352, 1.2324], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 421 was 10.1%\n",
      "current params: [tensor([1.4344, 1.0905, 0.3082, 0.5507, 0.1551, 1.5803, 1.4473, 1.5963, 1.3985,\n",
      "        1.4241, 1.4490, 1.3862, 0.3961, 0.8574, 1.3763, 0.5341, 1.0309, 1.3751,\n",
      "        1.6858, 0.4716, 1.4365, 1.2312], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 422 was 10.1%\n",
      "current params: [tensor([1.4352, 1.0931, 0.3057, 0.5474, 0.1522, 1.5826, 1.4486, 1.5987, 1.4007,\n",
      "        1.4263, 1.4506, 1.3871, 0.3933, 0.8547, 1.3773, 0.5329, 1.0283, 1.3758,\n",
      "        1.6881, 0.4686, 1.4378, 1.2300], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 423 was 10.1%\n",
      "current params: [tensor([1.4360, 1.0957, 0.3031, 0.5440, 0.1492, 1.5848, 1.4499, 1.6011, 1.4028,\n",
      "        1.4285, 1.4522, 1.3880, 0.3906, 0.8519, 1.3783, 0.5316, 1.0256, 1.3765,\n",
      "        1.6903, 0.4655, 1.4391, 1.2287], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 424 was 10.2%\n",
      "current params: [tensor([1.4367, 1.0983, 0.3005, 0.5406, 0.1463, 1.5870, 1.4511, 1.6035, 1.4049,\n",
      "        1.4307, 1.4538, 1.3890, 0.3878, 0.8491, 1.3793, 0.5303, 1.0229, 1.3772,\n",
      "        1.6926, 0.4624, 1.4405, 1.2274], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 425 was 10.2%\n",
      "current params: [tensor([1.4375, 1.1009, 0.2979, 0.5373, 0.1433, 1.5893, 1.4524, 1.6059, 1.4070,\n",
      "        1.4329, 1.4555, 1.3899, 0.3850, 0.8464, 1.3804, 0.5290, 1.0202, 1.3779,\n",
      "        1.6949, 0.4593, 1.4418, 1.2260], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 426 was 10.2%\n",
      "current params: [tensor([1.4382, 1.1035, 0.2953, 0.5338, 0.1403, 1.5915, 1.4536, 1.6084, 1.4091,\n",
      "        1.4351, 1.4571, 1.3908, 0.3822, 0.8436, 1.3814, 0.5277, 1.0175, 1.3785,\n",
      "        1.6972, 0.4562, 1.4431, 1.2246], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 427 was 10.2%\n",
      "current params: [tensor([1.4389, 1.1061, 0.2927, 0.5304, 0.1373, 1.5938, 1.4549, 1.6108, 1.4112,\n",
      "        1.4373, 1.4587, 1.3917, 0.3794, 0.8408, 1.3824, 0.5264, 1.0147, 1.3792,\n",
      "        1.6996, 0.4530, 1.4445, 1.2232], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 428 was 10.2%\n",
      "current params: [tensor([1.4396, 1.1088, 0.2901, 0.5270, 0.1343, 1.5960, 1.4562, 1.6132, 1.4134,\n",
      "        1.4395, 1.4604, 1.3926, 0.3766, 0.8381, 1.3835, 0.5251, 1.0120, 1.3799,\n",
      "        1.7019, 0.4499, 1.4458, 1.2217], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 429 was 10.2%\n",
      "current params: [tensor([1.4403, 1.1114, 0.2875, 0.5235, 0.1313, 1.5983, 1.4574, 1.6157, 1.4155,\n",
      "        1.4417, 1.4620, 1.3936, 0.3738, 0.8353, 1.3845, 0.5238, 1.0092, 1.3805,\n",
      "        1.7042, 0.4467, 1.4472, 1.2202], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 430 was 10.2%\n",
      "current params: [tensor([1.4410, 1.1140, 0.2849, 0.5200, 0.1283, 1.6006, 1.4587, 1.6181, 1.4176,\n",
      "        1.4439, 1.4637, 1.3945, 0.3710, 0.8325, 1.3856, 0.5225, 1.0064, 1.3812,\n",
      "        1.7065, 0.4435, 1.4485, 1.2187], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 431 was 10.2%\n",
      "current params: [tensor([1.4417, 1.1167, 0.2823, 0.5166, 0.1253, 1.6029, 1.4599, 1.6205, 1.4197,\n",
      "        1.4461, 1.4654, 1.3954, 0.3683, 0.8298, 1.3866, 0.5212, 1.0036, 1.3818,\n",
      "        1.7089, 0.4404, 1.4498, 1.2171], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 432 was 10.3%\n",
      "current params: [tensor([1.4424, 1.1193, 0.2797, 0.5130, 0.1223, 1.6052, 1.4612, 1.6230, 1.4218,\n",
      "        1.4483, 1.4671, 1.3964, 0.3655, 0.8270, 1.3877, 0.5199, 1.0007, 1.3825,\n",
      "        1.7112, 0.4371, 1.4512, 1.2155], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 433 was 10.3%\n",
      "current params: [tensor([1.4430, 1.1220, 0.2771, 0.5095, 0.1193, 1.6075, 1.4624, 1.6255, 1.4239,\n",
      "        1.4506, 1.4688, 1.3973, 0.3627, 0.8243, 1.3888, 0.5186, 0.9979, 1.3831,\n",
      "        1.7136, 0.4339, 1.4525, 1.2138], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 434 was 10.3%\n",
      "current params: [tensor([1.4437, 1.1246, 0.2745, 0.5060, 0.1162, 1.6098, 1.4637, 1.6279, 1.4261,\n",
      "        1.4528, 1.4705, 1.3982, 0.3599, 0.8215, 1.3898, 0.5172, 0.9950, 1.3837,\n",
      "        1.7159, 0.4307, 1.4539, 1.2121], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 435 was 10.3%\n",
      "current params: [tensor([1.4443, 1.1273, 0.2720, 0.5025, 0.1132, 1.6121, 1.4650, 1.6304, 1.4282,\n",
      "        1.4550, 1.4722, 1.3992, 0.3572, 0.8188, 1.3909, 0.5159, 0.9921, 1.3843,\n",
      "        1.7183, 0.4274, 1.4552, 1.2104], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 436 was 10.3%\n",
      "current params: [tensor([1.4449, 1.1299, 0.2694, 0.4989, 0.1101, 1.6145, 1.4662, 1.6329, 1.4303,\n",
      "        1.4572, 1.4739, 1.4001, 0.3544, 0.8160, 1.3920, 0.5146, 0.9892, 1.3849,\n",
      "        1.7206, 0.4242, 1.4566, 1.2086], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 437 was 10.3%\n",
      "current params: [tensor([1.4455, 1.1326, 0.2668, 0.4953, 0.1071, 1.6168, 1.4675, 1.6353, 1.4324,\n",
      "        1.4594, 1.4756, 1.4011, 0.3516, 0.8133, 1.3931, 0.5133, 0.9863, 1.3855,\n",
      "        1.7230, 0.4209, 1.4580, 1.2068], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 438 was 10.3%\n",
      "current params: [tensor([1.4461, 1.1353, 0.2642, 0.4918, 0.1040, 1.6192, 1.4687, 1.6378, 1.4345,\n",
      "        1.4616, 1.4773, 1.4020, 0.3488, 0.8105, 1.3942, 0.5120, 0.9834, 1.3861,\n",
      "        1.7254, 0.4176, 1.4593, 1.2049], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 439 was 10.4%\n",
      "current params: [tensor([1.4467, 1.1379, 0.2616, 0.4882, 0.1009, 1.6215, 1.4700, 1.6403, 1.4366,\n",
      "        1.4638, 1.4791, 1.4029, 0.3461, 0.8078, 1.3953, 0.5106, 0.9804, 1.3867,\n",
      "        1.7278, 0.4143, 1.4607, 1.2030], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 440 was 10.4%\n",
      "current params: [tensor([1.4473, 1.1406, 0.2590, 0.4846, 0.0978, 1.6239, 1.4712, 1.6428, 1.4387,\n",
      "        1.4660, 1.4808, 1.4039, 0.3433, 0.8050, 1.3964, 0.5093, 0.9775, 1.3872,\n",
      "        1.7302, 0.4110, 1.4621, 1.2010], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 441 was 10.4%\n",
      "current params: [tensor([1.4478, 1.1433, 0.2564, 0.4809, 0.0947, 1.6263, 1.4725, 1.6453, 1.4408,\n",
      "        1.4682, 1.4826, 1.4048, 0.3406, 0.8023, 1.3975, 0.5080, 0.9745, 1.3878,\n",
      "        1.7326, 0.4077, 1.4634, 1.1991], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 442 was 10.4%\n",
      "current params: [tensor([1.4484, 1.1460, 0.2538, 0.4773, 0.0916, 1.6287, 1.4737, 1.6478, 1.4429,\n",
      "        1.4704, 1.4844, 1.4058, 0.3378, 0.7995, 1.3986, 0.5066, 0.9715, 1.3883,\n",
      "        1.7350, 0.4044, 1.4648, 1.1970], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 443 was 10.4%\n",
      "current params: [tensor([1.4489, 1.1487, 0.2512, 0.4737, 0.0885, 1.6311, 1.4750, 1.6503, 1.4450,\n",
      "        1.4727, 1.4861, 1.4068, 0.3351, 0.7968, 1.3998, 0.5053, 0.9685, 1.3889,\n",
      "        1.7374, 0.4010, 1.4662, 1.1950], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 444 was 10.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: [tensor([1.4494, 1.1513, 0.2487, 0.4700, 0.0853, 1.6335, 1.4762, 1.6528, 1.4471,\n",
      "        1.4749, 1.4879, 1.4077, 0.3323, 0.7940, 1.4009, 0.5040, 0.9654, 1.3894,\n",
      "        1.7398, 0.3977, 1.4675, 1.1929], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 445 was 10.5%\n",
      "current params: [tensor([1.4499, 1.1540, 0.2461, 0.4664, 0.0822, 1.6360, 1.4775, 1.6553, 1.4492,\n",
      "        1.4771, 1.4897, 1.4087, 0.3296, 0.7913, 1.4020, 0.5026, 0.9624, 1.3899,\n",
      "        1.7422, 0.3943, 1.4689, 1.1907], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 446 was 10.5%\n",
      "current params: [tensor([1.4504, 1.1567, 0.2435, 0.4627, 0.0791, 1.6384, 1.4787, 1.6579, 1.4513,\n",
      "        1.4793, 1.4915, 1.4096, 0.3268, 0.7885, 1.4032, 0.5013, 0.9593, 1.3904,\n",
      "        1.7447, 0.3909, 1.4703, 1.1885], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 447 was 10.5%\n",
      "current params: [tensor([1.4508, 1.1595, 0.2409, 0.4590, 0.0759, 1.6409, 1.4799, 1.6604, 1.4534,\n",
      "        1.4815, 1.4933, 1.4106, 0.3241, 0.7858, 1.4043, 0.4999, 0.9563, 1.3909,\n",
      "        1.7471, 0.3876, 1.4717, 1.1863], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 448 was 10.5%\n",
      "current params: [tensor([1.4512, 1.1622, 0.2384, 0.4553, 0.0727, 1.6433, 1.4812, 1.6629, 1.4555,\n",
      "        1.4837, 1.4952, 1.4116, 0.3214, 0.7830, 1.4055, 0.4986, 0.9532, 1.3913,\n",
      "        1.7495, 0.3842, 1.4731, 1.1840], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 449 was 10.5%\n",
      "current params: [tensor([1.4517, 1.1649, 0.2358, 0.4516, 0.0696, 1.6458, 1.4824, 1.6655, 1.4576,\n",
      "        1.4859, 1.4970, 1.4126, 0.3186, 0.7803, 1.4067, 0.4972, 0.9501, 1.3918,\n",
      "        1.7520, 0.3807, 1.4744, 1.1817], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 450 was 10.6%\n",
      "current params: [tensor([1.4521, 1.1676, 0.2332, 0.4479, 0.0664, 1.6483, 1.4837, 1.6680, 1.4597,\n",
      "        1.4882, 1.4988, 1.4135, 0.3159, 0.7776, 1.4079, 0.4958, 0.9470, 1.3922,\n",
      "        1.7544, 0.3773, 1.4758, 1.1793], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 451 was 10.6%\n",
      "current params: [tensor([1.4524, 1.1703, 0.2307, 0.4442, 0.0632, 1.6508, 1.4849, 1.6706, 1.4618,\n",
      "        1.4904, 1.5007, 1.4145, 0.3132, 0.7748, 1.4090, 0.4945, 0.9439, 1.3927,\n",
      "        1.7569, 0.3739, 1.4772, 1.1769], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 452 was 10.6%\n",
      "current params: [tensor([1.4528, 1.1730, 0.2281, 0.4405, 0.0600, 1.6533, 1.4861, 1.6732, 1.4639,\n",
      "        1.4926, 1.5026, 1.4155, 0.3105, 0.7721, 1.4102, 0.4931, 0.9407, 1.3931,\n",
      "        1.7594, 0.3705, 1.4786, 1.1745], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 453 was 10.6%\n",
      "current params: [tensor([1.4531, 1.1758, 0.2255, 0.4368, 0.0568, 1.6558, 1.4873, 1.6757, 1.4660,\n",
      "        1.4948, 1.5044, 1.4165, 0.3078, 0.7693, 1.4114, 0.4917, 0.9376, 1.3935,\n",
      "        1.7619, 0.3670, 1.4800, 1.1720], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 454 was 10.6%\n",
      "current params: [tensor([1.4535, 1.1785, 0.2230, 0.4330, 0.0585, 1.6583, 1.4886, 1.6783, 1.4681,\n",
      "        1.4970, 1.5063, 1.4175, 0.3051, 0.7666, 1.4127, 0.4904, 0.9344, 1.3939,\n",
      "        1.7643, 0.3635, 1.4814, 1.1695], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 455 was 10.6%\n",
      "current params: [tensor([1.4538, 1.1812, 0.2204, 0.4293, 0.0610, 1.6609, 1.4898, 1.6809, 1.4702,\n",
      "        1.4992, 1.5082, 1.4185, 0.3024, 0.7638, 1.4139, 0.4890, 0.9312, 1.3942,\n",
      "        1.7668, 0.3601, 1.4828, 1.1669], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 456 was 10.7%\n",
      "current params: [tensor([1.4541, 1.1840, 0.2179, 0.4255, 0.0632, 1.6634, 1.4910, 1.6835, 1.4723,\n",
      "        1.5015, 1.5101, 1.4195, 0.2997, 0.7611, 1.4151, 0.4876, 0.9281, 1.3946,\n",
      "        1.7693, 0.3566, 1.4842, 1.1643], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 457 was 10.7%\n",
      "current params: [tensor([1.4543, 1.1867, 0.2153, 0.4218, 0.0652, 1.6660, 1.4922, 1.6861, 1.4744,\n",
      "        1.5037, 1.5120, 1.4205, 0.2970, 0.7584, 1.4163, 0.4862, 0.9249, 1.3949,\n",
      "        1.7718, 0.3531, 1.4856, 1.1617], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 458 was 10.7%\n",
      "current params: [tensor([1.4546, 1.1895, 0.2128, 0.4181, 0.0670, 1.6686, 1.4935, 1.6887, 1.4764,\n",
      "        1.5059, 1.5139, 1.4215, 0.2943, 0.7556, 1.4176, 0.4849, 0.9217, 1.3953,\n",
      "        1.7743, 0.3497, 1.4870, 1.1591], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 459 was 10.7%\n",
      "current params: [tensor([1.4549, 1.1922, 0.2102, 0.4144, 0.0686, 1.6711, 1.4947, 1.6912, 1.4785,\n",
      "        1.5081, 1.5158, 1.4225, 0.2916, 0.7529, 1.4188, 0.4835, 0.9185, 1.3956,\n",
      "        1.7768, 0.3462, 1.4884, 1.1565], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 460 was 10.7%\n",
      "current params: [tensor([1.4551, 1.1949, 0.2077, 0.4107, 0.0700, 1.6737, 1.4959, 1.6938, 1.4806,\n",
      "        1.5103, 1.5177, 1.4235, 0.2889, 0.7503, 1.4201, 0.4821, 0.9154, 1.3958,\n",
      "        1.7793, 0.3428, 1.4897, 1.1538], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 461 was 10.7%\n",
      "current params: [tensor([1.4554, 1.1976, 0.2051, 0.4070, 0.0713, 1.6763, 1.4971, 1.6964, 1.4826,\n",
      "        1.5125, 1.5197, 1.4245, 0.2862, 0.7476, 1.4213, 0.4807, 0.9122, 1.3961,\n",
      "        1.7818, 0.3394, 1.4911, 1.1511], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 462 was 10.7%\n",
      "current params: [tensor([1.4556, 1.2004, 0.2026, 0.4034, 0.0724, 1.6789, 1.4983, 1.6990, 1.4847,\n",
      "        1.5147, 1.5216, 1.4255, 0.2835, 0.7449, 1.4226, 0.4793, 0.9091, 1.3964,\n",
      "        1.7842, 0.3360, 1.4925, 1.1484], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 463 was 10.7%\n",
      "current params: [tensor([1.4558, 1.2031, 0.2001, 0.3997, 0.0734, 1.6815, 1.4994, 1.7016, 1.4867,\n",
      "        1.5170, 1.5235, 1.4265, 0.2809, 0.7423, 1.4238, 0.4779, 0.9059, 1.3966,\n",
      "        1.7867, 0.3326, 1.4938, 1.1457], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 464 was 10.8%\n",
      "current params: [tensor([1.4561, 1.2058, 0.1975, 0.3961, 0.0743, 1.6841, 1.5006, 1.7041, 1.4888,\n",
      "        1.5192, 1.5254, 1.4275, 0.2782, 0.7397, 1.4251, 0.4765, 0.9028, 1.3968,\n",
      "        1.7892, 0.3292, 1.4952, 1.1430], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 465 was 10.8%\n",
      "current params: [tensor([1.4563, 1.2085, 0.1950, 0.3925, 0.0751, 1.6867, 1.5018, 1.7067, 1.4908,\n",
      "        1.5214, 1.5274, 1.4285, 0.2755, 0.7371, 1.4263, 0.4751, 0.8997, 1.3970,\n",
      "        1.7916, 0.3258, 1.4965, 1.1403], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 466 was 10.8%\n",
      "current params: [tensor([1.4566, 1.2112, 0.1924, 0.3889, 0.0758, 1.6893, 1.5030, 1.7093, 1.4929,\n",
      "        1.5236, 1.5293, 1.4295, 0.2728, 0.7345, 1.4276, 0.4737, 0.8966, 1.3972,\n",
      "        1.7941, 0.3225, 1.4979, 1.1376], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 467 was 10.8%\n",
      "current params: [tensor([1.4568, 1.2139, 0.1899, 0.3853, 0.0764, 1.6919, 1.5041, 1.7119, 1.4949,\n",
      "        1.5258, 1.5312, 1.4305, 0.2701, 0.7320, 1.4289, 0.4723, 0.8935, 1.3973,\n",
      "        1.7965, 0.3191, 1.4992, 1.1349], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 468 was 10.8%\n",
      "current params: [tensor([1.4570, 1.2166, 0.1873, 0.3818, 0.0770, 1.6945, 1.5053, 1.7144, 1.4969,\n",
      "        1.5280, 1.5332, 1.4316, 0.2675, 0.7295, 1.4301, 0.4709, 0.8904, 1.3974,\n",
      "        1.7990, 0.3158, 1.5005, 1.1321], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 469 was 10.8%\n",
      "current params: [tensor([1.4573, 1.2193, 0.1848, 0.3783, 0.0774, 1.6971, 1.5064, 1.7170, 1.4989,\n",
      "        1.5302, 1.5351, 1.4326, 0.2648, 0.7270, 1.4314, 0.4694, 0.8874, 1.3975,\n",
      "        1.8014, 0.3125, 1.5018, 1.1294], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 470 was 10.9%\n",
      "current params: [tensor([1.4575, 1.2220, 0.1822, 0.3747, 0.0778, 1.6997, 1.5075, 1.7195, 1.5009,\n",
      "        1.5324, 1.5370, 1.4336, 0.2621, 0.7245, 1.4327, 0.4680, 0.8843, 1.3976,\n",
      "        1.8038, 0.3091, 1.5031, 1.1266], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 471 was 10.9%\n",
      "current params: [tensor([1.4577, 1.2247, 0.1797, 0.3712, 0.0782, 1.7023, 1.5086, 1.7221, 1.5029,\n",
      "        1.5346, 1.5390, 1.4346, 0.2594, 0.7220, 1.4339, 0.4666, 0.8813, 1.3977,\n",
      "        1.8063, 0.3058, 1.5044, 1.1239], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 472 was 10.9%\n",
      "current params: [tensor([1.4580, 1.2274, 0.1771, 0.3677, 0.0785, 1.7049, 1.5098, 1.7246, 1.5049,\n",
      "        1.5368, 1.5409, 1.4356, 0.2568, 0.7196, 1.4352, 0.4652, 0.8782, 1.3977,\n",
      "        1.8087, 0.3026, 1.5057, 1.1211], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 473 was 10.9%\n",
      "current params: [tensor([1.4582, 1.2301, 0.1746, 0.3642, 0.0787, 1.7075, 1.5109, 1.7272, 1.5069,\n",
      "        1.5389, 1.5429, 1.4367, 0.2541, 0.7171, 1.4365, 0.4638, 0.8752, 1.3977,\n",
      "        1.8111, 0.2993, 1.5070, 1.1184], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 474 was 10.9%\n",
      "current params: [tensor([1.4585, 1.2328, 0.1720, 0.3608, 0.0790, 1.7101, 1.5120, 1.7297, 1.5088,\n",
      "        1.5411, 1.5448, 1.4377, 0.2514, 0.7147, 1.4378, 0.4623, 0.8722, 1.3977,\n",
      "        1.8135, 0.2960, 1.5083, 1.1156], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 475 was 10.9%\n",
      "current params: [tensor([1.4587, 1.2354, 0.1695, 0.3573, 0.0791, 1.7127, 1.5130, 1.7322, 1.5108,\n",
      "        1.5433, 1.5467, 1.4387, 0.2488, 0.7123, 1.4391, 0.4609, 0.8692, 1.3977,\n",
      "        1.8159, 0.2928, 1.5095, 1.1128], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 476 was 10.9%\n",
      "current params: [tensor([1.4589, 1.2381, 0.1669, 0.3539, 0.0793, 1.7153, 1.5141, 1.7348, 1.5127,\n",
      "        1.5455, 1.5487, 1.4398, 0.2461, 0.7100, 1.4403, 0.4595, 0.8662, 1.3976,\n",
      "        1.8183, 0.2895, 1.5107, 1.1101], dtype=torch.float64)]\n",
      "Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield on sim iteration 477 was 10.9%\n",
      "current params: [tensor([1.4591, 1.2408, 0.1644, 0.3505, 0.0794, 1.7179, 1.5152, 1.7373, 1.5147,\n",
      "        1.5477, 1.5506, 1.4408, 0.2434, 0.7076, 1.4416, 0.4580, 0.8632, 1.3975,\n",
      "        1.8207, 0.2863, 1.5120, 1.1073], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 478 was 10.9%\n",
      "current params: [tensor([1.4593, 1.2434, 0.1618, 0.3471, 0.0795, 1.7204, 1.5162, 1.7398, 1.5166,\n",
      "        1.5499, 1.5525, 1.4418, 0.2407, 0.7052, 1.4429, 0.4566, 0.8603, 1.3974,\n",
      "        1.8230, 0.2831, 1.5132, 1.1046], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 479 was 11.0%\n",
      "current params: [tensor([1.4596, 1.2461, 0.1592, 0.3437, 0.0795, 1.7230, 1.5173, 1.7423, 1.5186,\n",
      "        1.5520, 1.5545, 1.4428, 0.2380, 0.7029, 1.4442, 0.4551, 0.8573, 1.3973,\n",
      "        1.8254, 0.2799, 1.5144, 1.1019], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 480 was 11.0%\n",
      "current params: [tensor([1.4598, 1.2487, 0.1567, 0.3404, 0.0796, 1.7255, 1.5183, 1.7448, 1.5205,\n",
      "        1.5542, 1.5564, 1.4439, 0.2354, 0.7006, 1.4454, 0.4537, 0.8544, 1.3971,\n",
      "        1.8277, 0.2768, 1.5156, 1.0991], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 481 was 11.0%\n",
      "current params: [tensor([1.4600, 1.2514, 0.1541, 0.3370, 0.0796, 1.7281, 1.5193, 1.7473, 1.5224,\n",
      "        1.5564, 1.5583, 1.4449, 0.2327, 0.6983, 1.4467, 0.4522, 0.8515, 1.3969,\n",
      "        1.8300, 0.2736, 1.5167, 1.0964], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 482 was 11.0%\n",
      "current params: [tensor([1.4602, 1.2540, 0.1516, 0.3337, 0.0796, 1.7306, 1.5203, 1.7498, 1.5243,\n",
      "        1.5586, 1.5603, 1.4459, 0.2300, 0.6960, 1.4480, 0.4508, 0.8486, 1.3967,\n",
      "        1.8324, 0.2704, 1.5179, 1.0937], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 483 was 11.0%\n",
      "current params: [tensor([1.4604, 1.2566, 0.1490, 0.3303, 0.0796, 1.7332, 1.5213, 1.7523, 1.5262,\n",
      "        1.5607, 1.5622, 1.4470, 0.2273, 0.6938, 1.4492, 0.4493, 0.8457, 1.3964,\n",
      "        1.8347, 0.2673, 1.5190, 1.0909], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 484 was 11.0%\n",
      "current params: [tensor([1.4605, 1.2593, 0.1465, 0.3270, 0.0796, 1.7357, 1.5223, 1.7548, 1.5281,\n",
      "        1.5629, 1.5641, 1.4480, 0.2246, 0.6915, 1.4505, 0.4479, 0.8428, 1.3962,\n",
      "        1.8370, 0.2641, 1.5202, 1.0882], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 485 was 11.1%\n",
      "current params: [tensor([1.4607, 1.2619, 0.1439, 0.3237, 0.0795, 1.7383, 1.5233, 1.7573, 1.5300,\n",
      "        1.5651, 1.5661, 1.4490, 0.2220, 0.6893, 1.4518, 0.4464, 0.8399, 1.3959,\n",
      "        1.8393, 0.2610, 1.5213, 1.0855], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 486 was 11.1%\n",
      "current params: [tensor([1.4609, 1.2645, 0.1413, 0.3204, 0.0794, 1.7408, 1.5242, 1.7597, 1.5318,\n",
      "        1.5672, 1.5680, 1.4501, 0.2193, 0.6871, 1.4531, 0.4449, 0.8371, 1.3955,\n",
      "        1.8416, 0.2579, 1.5224, 1.0827], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 487 was 11.1%\n",
      "current params: [tensor([1.4611, 1.2671, 0.1388, 0.3170, 0.0794, 1.7433, 1.5252, 1.7622, 1.5337,\n",
      "        1.5694, 1.5699, 1.4511, 0.2166, 0.6849, 1.4543, 0.4434, 0.8342, 1.3952,\n",
      "        1.8439, 0.2548, 1.5235, 1.0800], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 488 was 11.1%\n",
      "current params: [tensor([1.4613, 1.2697, 0.1362, 0.3137, 0.0793, 1.7459, 1.5261, 1.7647, 1.5356,\n",
      "        1.5715, 1.5719, 1.4521, 0.2139, 0.6827, 1.4556, 0.4420, 0.8313, 1.3948,\n",
      "        1.8462, 0.2516, 1.5246, 1.0772], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 489 was 11.1%\n",
      "current params: [tensor([1.4614, 1.2724, 0.1336, 0.3104, 0.0792, 1.7484, 1.5270, 1.7672, 1.5374,\n",
      "        1.5737, 1.5738, 1.4532, 0.2112, 0.6806, 1.4569, 0.4405, 0.8285, 1.3943,\n",
      "        1.8484, 0.2485, 1.5257, 1.0745], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 490 was 11.2%\n",
      "current params: [tensor([1.4616, 1.2750, 0.1311, 0.3071, 0.0791, 1.7510, 1.5279, 1.7696, 1.5392,\n",
      "        1.5759, 1.5757, 1.4542, 0.2086, 0.6784, 1.4582, 0.4390, 0.8256, 1.3939,\n",
      "        1.8507, 0.2454, 1.5267, 1.0717], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 491 was 11.2%\n",
      "current params: [tensor([1.4618, 1.2776, 0.1285, 0.3038, 0.0790, 1.7535, 1.5288, 1.7721, 1.5411,\n",
      "        1.5780, 1.5777, 1.4553, 0.2059, 0.6763, 1.4595, 0.4375, 0.8228, 1.3934,\n",
      "        1.8530, 0.2423, 1.5278, 1.0690], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 492 was 11.2%\n",
      "current params: [tensor([1.4619, 1.2802, 0.1260, 0.3005, 0.0789, 1.7561, 1.5297, 1.7746, 1.5429,\n",
      "        1.5802, 1.5796, 1.4563, 0.2032, 0.6743, 1.4608, 0.4360, 0.8199, 1.3929,\n",
      "        1.8552, 0.2392, 1.5288, 1.0662], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 493 was 11.2%\n",
      "current params: [tensor([1.4621, 1.2828, 0.1234, 0.2972, 0.0787, 1.7586, 1.5306, 1.7770, 1.5447,\n",
      "        1.5823, 1.5816, 1.4573, 0.2005, 0.6722, 1.4621, 0.4346, 0.8170, 1.3923,\n",
      "        1.8575, 0.2361, 1.5299, 1.0634], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 494 was 11.2%\n",
      "current params: [tensor([1.4623, 1.2854, 0.1208, 0.2939, 0.0786, 1.7612, 1.5315, 1.7795, 1.5465,\n",
      "        1.5844, 1.5835, 1.4584, 0.1979, 0.6702, 1.4634, 0.4331, 0.8142, 1.3917,\n",
      "        1.8597, 0.2330, 1.5309, 1.0607], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 495 was 11.3%\n",
      "current params: [tensor([1.4624, 1.2880, 0.1183, 0.2906, 0.0785, 1.7637, 1.5323, 1.7820, 1.5483,\n",
      "        1.5866, 1.5854, 1.4595, 0.1952, 0.6682, 1.4647, 0.4316, 0.8113, 1.3911,\n",
      "        1.8619, 0.2299, 1.5319, 1.0579], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 496 was 11.3%\n",
      "current params: [tensor([1.4626, 1.2905, 0.1157, 0.2873, 0.0783, 1.7663, 1.5331, 1.7844, 1.5501,\n",
      "        1.5887, 1.5874, 1.4605, 0.1925, 0.6662, 1.4660, 0.4301, 0.8085, 1.3905,\n",
      "        1.8642, 0.2268, 1.5329, 1.0551], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 497 was 11.3%\n",
      "current params: [tensor([1.4627, 1.2931, 0.1131, 0.2840, 0.0782, 1.7689, 1.5340, 1.7869, 1.5518,\n",
      "        1.5909, 1.5893, 1.4616, 0.1898, 0.6642, 1.4673, 0.4286, 0.8057, 1.3898,\n",
      "        1.8664, 0.2237, 1.5338, 1.0523], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 498 was 11.3%\n",
      "current params: [tensor([1.4628, 1.2957, 0.1106, 0.2807, 0.0780, 1.7715, 1.5348, 1.7893, 1.5536,\n",
      "        1.5930, 1.5913, 1.4626, 0.1871, 0.6623, 1.4686, 0.4270, 0.8028, 1.3890,\n",
      "        1.8686, 0.2206, 1.5348, 1.0495], dtype=torch.float64)]\n",
      "Using CPU\n",
      "yield on sim iteration 499 was 11.3%\n",
      "optimization complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<steric_free_simulator.reaction_network.ReactionNetwork at 0xa213f07f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.optimize()\n",
    "final_rn = copy.deepcopy(rn)\n",
    "optim.rn.update_reaction_net(final_rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visulalize the reults. The Optimizer tracks observables across all simulation iterations,\n",
    "and thus we can use its `plot_observables` function to plot the results of a single simulation\n",
    "\n",
    "**Plot the first simulation, before any optimization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(iteration=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the final simulation, after all optimization iterations:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_observable(iteration=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plot the change in complex yield over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the optimizer was able to increase the total yield of the final complex at time 1 second.\n",
    "The explanation for this will be left to the results notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}